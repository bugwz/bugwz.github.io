<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Ceph Crimson 集群部署教程 | 咕咕</title><meta name="author" content="bugwz"><meta name="copyright" content="bugwz"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="当前 ceph 集群搭建部署的方式主要有三种: ceph-ansible ，vstart.sh ， cephadm 。 其中 vstart.sh 脚本用于在开发环境中快速搭建测试集群； ceph-ansible 是一种部署 ceph 集群的老方式，支持在宿主机及容器部署的方式，目前社区已不推荐使用；cephadm 是当前最新的支持部署生产集群的方式，仅支持容器部署。接下来主要介绍通过 vstart">
<meta property="og:type" content="article">
<meta property="og:title" content="Ceph Crimson 集群部署教程">
<meta property="og:url" content="https://bugwz.com/2025/01/12/ceph-crimson-deploy/index.html">
<meta property="og:site_name" content="咕咕">
<meta property="og:description" content="当前 ceph 集群搭建部署的方式主要有三种: ceph-ansible ，vstart.sh ， cephadm 。 其中 vstart.sh 脚本用于在开发环境中快速搭建测试集群； ceph-ansible 是一种部署 ceph 集群的老方式，支持在宿主机及容器部署的方式，目前社区已不推荐使用；cephadm 是当前最新的支持部署生产集群的方式，仅支持容器部署。接下来主要介绍通过 vstart">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://bugwz.com/assets/images/bg/ceph.png">
<meta property="article:published_time" content="2025-01-11T16:00:00.000Z">
<meta property="article:modified_time" content="2025-08-12T13:39:04.896Z">
<meta property="article:author" content="bugwz">
<meta property="article:tag" content="Ceph">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://bugwz.com/assets/images/bg/ceph.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Ceph Crimson 集群部署教程",
  "url": "https://bugwz.com/2025/01/12/ceph-crimson-deploy/",
  "image": "https://bugwz.com/assets/images/bg/ceph.png",
  "datePublished": "2025-01-11T16:00:00.000Z",
  "dateModified": "2025-08-12T13:39:04.896Z",
  "author": [
    {
      "@type": "Person",
      "name": "bugwz",
      "url": "https://bugwz.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/assets/images/bg/favicon.png"><link rel="canonical" href="https://bugwz.com/2025/01/12/ceph-crimson-deploy/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Ceph Crimson 集群部署教程',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/self/github-dark.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/assets/images/bg/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">133</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">135</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags"><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories"><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link"><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/assets/images/bg/ceph.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">咕咕</span></a><a class="nav-page-title" href="/"><span class="site-name">Ceph Crimson 集群部署教程</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags"><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories"><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link"><span> 友链</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Ceph Crimson 集群部署教程</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-01-11T16:00:00.000Z" title="发表于 2025-01-12 00:00:00">2025-01-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-12T13:39:04.896Z" title="更新于 2025-08-12 21:39:04">2025-08-12</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">5.8k</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>当前 ceph 集群搭建部署的方式主要有三种: ceph-ansible, vstart.sh 和 cephadm 。 其中 vstart.sh 脚本用于在开发环境中快速搭建测试集群。 ceph-ansible 是之前推荐的部署 ceph 集群的方式，支持在直接在宿主机上部署或者通过容器部署的方式，目前社区已不推荐使用。 cephadm 是当前最新的支持部署生产集群的方式，仅支持容器部署。接下来主要介绍通过 vstart.sh 和 cephadm 部署 crimson 集群的方式。</p>
<h1 id="一、vstart-sh-搭建集群"><a href="#一、vstart-sh-搭建集群" class="headerlink" title="一、vstart.sh 搭建集群"></a>一、vstart.sh 搭建集群</h1><p>通过这种方式部署的时候理论上对于 Ceph 版本没有特殊的要求，本文中使用的版本为 <a target="_blank" rel="noopener" href="https://github.com/ceph/ceph/tree/v19.2.1">v19.2.1</a> 。</p>
<p>vstart.sh 常用于在开发环境环境中快速搭建集群，且在部署集群前我们需要编译出对应的二进制包。由于编译环境可能会有各种依赖缺失，版本异常等问题，这里推荐使用 <a target="_blank" rel="noopener" href="https://github.com/bugwz/ceph-image/tree/main/squid/centos-9-stream/dev">bugwz&#x2F;ceph-images</a> 中提供的 CentOS Stream 9 的编译打包环境。同时后续的集群的搭建也可以在容器内部进行。</p>
<p><strong>搭建集群操作步骤如下:</strong></p>
<ol>
<li>软件编译: 使用开发容器镜像，编译对应的 ceph 代码，产出对应的二进制运行文件；</li>
<li>集群部署: 在开发容器内部使用 vstart.sh 脚本搭建测试集群；</li>
<li>集群测试: 验证集群功能特性是否正常；</li>
</ol>
<h2 id="1-1、软件编译"><a href="#1-1、软件编译" class="headerlink" title="1.1、软件编译"></a>1.1、软件编译</h2><blockquote>
<p><strong>注意:</strong> 2025年04月03日之后的代码版本中移除了 <code>WITH_SEASTAR</code> 变量，需要使用新变量 <code>WITH_CRIMSON</code> ，相关 <a target="_blank" rel="noopener" href="https://github.com/ceph/ceph/commit/23c33f69ff977f7a05d3e3368e078b20e67a5ced">commit&#x2F;23c33f6</a> 。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 进入上述提供的容器开发环境</span><br><span class="hljs-comment"># 启动容器时需要使用 --privileged=true 参数，避免后续在容器内部部署集群时遇到 OSD 部署的权限问题</span><br><br><span class="hljs-comment"># 编译</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f v19.2.1<br>git submodule update --init --recursive<br><span class="hljs-built_in">export</span> FOR_MAKE_CHECK=<span class="hljs-literal">true</span><br>/root/ceph/install-deps.sh<br>/root/ceph/do_cmake.sh<br><span class="hljs-built_in">cd</span> /root/ceph/build/<br>ninja -j <span class="hljs-string">&quot;<span class="hljs-subst">$(expr $(nproc)</span> / 2)&quot;</span><br><br><br><span class="hljs-comment"># 编译 crimson</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f v19.2.1<br>git submodule update --init --recursive<br><span class="hljs-built_in">export</span> FOR_MAKE_CHECK=<span class="hljs-literal">true</span><br><span class="hljs-comment"># 2025年04月03日之后的代码使用 WITH_CRIMSON 替换了 WITH_SEASTAR</span><br><span class="hljs-built_in">export</span> WITH_SEASTAR=<span class="hljs-literal">true</span><br>/root/ceph/install-deps.sh<br><span class="hljs-comment"># 2025年04月03日之后的代码使用 WITH_CRIMSON 替换了 WITH_SEASTAR</span><br>/root/ceph/do_cmake.sh -DWITH_SEASTAR=ON<br><span class="hljs-built_in">cd</span> /root/ceph/build/<br>ninja -j <span class="hljs-string">&quot;<span class="hljs-subst">$(expr $(nproc)</span> / 2)&quot;</span><br></code></pre></td></tr></table></figure>


<h2 id="1-2、集群部署"><a href="#1-2、集群部署" class="headerlink" title="1.2、集群部署"></a>1.2、集群部署</h2><p>通过 vstart.sh 部署集群依赖 1.1 中产出的二进制文件，因此我们需要在对应的编译环境中搭建测试测试。</p>
<ul>
<li>各组件的配置文件位于 build 目录中的 ceph.conf 文件；</li>
<li>各组件的运行目录位于 build 目录中的 dev 目录；</li>
<li>各组件的日志目录位于 build 目录中的 out 目录；</li>
<li>各组件的管理 socket 位于 build 目录中的 asok 目录；</li>
</ul>
<p><strong>vstart.sh 脚本相关逻辑:</strong></p>
<ul>
<li>部署 <code>crimson-osd</code> 的时候，如果没有指定 <code>--crimson-smp</code> 参数，则默认会将 <code>crimson_smp</code> 参数值设置为 <code>1</code> ，并且在启动每个 <code>OSD</code> 前修改对应的 <code>crimson_seastar_cpu_cores</code> 参数。按照 <code>crimson-osd</code> 的启动逻辑，如果指定了 <code>crimson_seastar_cpu_cores</code> 参数，则不会使用 <code>crimson_seastar_num_threads</code> 配置，因此如果想要 <code>crimson_seastar_num_threads</code> 配置生效，就需要在 <code>vstart.sh</code> 脚本中注释掉位于 <code>start_osd</code> 函数中设置 <code>crimson_seastar_cpu_cores</code> 参数的逻辑。</li>
</ul>
<p><strong>操作如下:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 进入 build 目录</span><br><span class="hljs-comment"># 以下所有操作均位于 build 目录中执行</span><br><span class="hljs-built_in">cd</span> build<br><br><span class="hljs-comment"># 搭建非 crimson 集群</span><br>../src/vstart.sh -d -n<br><br><span class="hljs-comment"># 搭建后端存储为 alienstore(bluestore) 的 crimson 集群</span><br>../src/vstart.sh -d -n \<br>  --without-dashboard --redirect-output \<br>  --bluestore --crimson<br><br><span class="hljs-comment"># 搭建后端存储为 cyanstore(memstore) 的 crimson 集群</span><br>../src/vstart.sh -d -n \<br>  --without-dashboard --redirect-output \<br>  --cyanstore --crimson<br><br><span class="hljs-comment"># 搭建后端存储为 seastore 的 crimson 集群</span><br>../src/vstart.sh -d -n \<br>  --without-dashboard --redirect-output \<br>  --seastore --crimson<br><br><span class="hljs-comment"># 搭建后端存储为 seastore 的 crimson 集群，并调整集群的一些配置</span><br><span class="hljs-comment"># 该方式会在初始化集群配置文件的时候在所有组件中添加指定的配置</span><br>../src/vstart.sh -d -n \<br>  --without-dashboard --redirect-output \<br>  --seastore --crimson \<br>  -o <span class="hljs-string">&quot;<span class="hljs-subst">$(cat new.conf)</span>&quot;</span><br><br><span class="hljs-comment"># 停止非 crimson 集群</span><br>../src/stop.sh<br><br><span class="hljs-comment"># 停止 crimson 集群</span><br>../src/stop.sh --crimson<br><br><span class="hljs-comment"># 查看集群状态</span><br>./bin/ceph -s<br><br><span class="hljs-comment"># 查看集群 osd 组件的后端存储类型</span><br><span class="hljs-built_in">cat</span> ./dev/osd*/type<br></code></pre></td></tr></table></figure>

<h2 id="1-3、功能测试"><a href="#1-3、功能测试" class="headerlink" title="1.3、功能测试"></a>1.3、功能测试</h2><h3 id="1-3-1、测试-RBD-功能"><a href="#1-3-1、测试-RBD-功能" class="headerlink" title="1.3.1、测试 RBD 功能"></a>1.3.1、测试 RBD 功能</h3><p>需要注意，容器环境中可能没有对应的 rbd 内核模块，下面的执行命令可能会失败。</p>
<p><strong>相关命令:</strong> （以下命令执行的相对路径均位于 ceph&#x2F;build 目录中）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 rbd pool</span><br>./bin/ceph osd pool create rbdpool 64 64<br>./bin/ceph osd pool application <span class="hljs-built_in">enable</span> rbdpool rbd<br>./bin/ceph osd pool <span class="hljs-built_in">set</span> rbdpool pg_autoscale_mode off<br><br><span class="hljs-comment"># 创建 rbd image</span><br>./bin/rbd create -p rbdpool --image rbdimg01 --size 10G<br><br><span class="hljs-comment"># 删除 rbd image</span><br>./bin/rbd <span class="hljs-built_in">rm</span> --pool rbdpool --image rbdimg01<br><br><span class="hljs-comment"># 查看 rbd image 信息</span><br>./bin/rbd info rbdpool/rbdimg01<br><br><span class="hljs-comment"># krbd 方式映射 rbd image (默认方式)</span><br><span class="hljs-comment"># 由于 crimson osd 仅支持 message v2, 因此我们需要切换为 message v2进行连接通信</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/tools/rbd/action/Kernel.cc#L120</span><br>./bin/rbd device map -t krbd rbdpool/rbdimg01 -o mount_timeout=5,ms_mode=crc<br><br><span class="hljs-comment"># nbd 方式映射 rbd image</span><br><span class="hljs-comment"># 由于 crimson osd 仅支持 message v2, 因此我们需要切换为 message v2进行连接通信</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/tools/rbd_nbd/rbd-nbd.cc#L2118</span><br>./bin/rbd device map -t nbd rbdpool/rbdimg01<br><br><span class="hljs-comment"># 格式化 krbd 方式映射的 rbd image 并挂载</span><br>mkfs.xfs /dev/rbd0<br><span class="hljs-built_in">mkdir</span> -p /mnt/cephrbd<br>mount /dev/rbd0 /mnt/cephrbd<br><br><span class="hljs-comment"># 格式化 nbd 方式映射的 rbd image 并挂载</span><br>mkfs.xfs /dev/nbd1<br><span class="hljs-built_in">mkdir</span> -p /mnt/cephrbd<br>mount /dev/nbd1 /mnt/cephrbd<br><br><span class="hljs-comment"># 压测 rbd image - 限速写</span><br><span class="hljs-built_in">cd</span> /mnt/cephrbd<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=testfile status=progress<br><br><span class="hljs-comment"># 压测 rbd image - 限速读</span><br><span class="hljs-built_in">cd</span> /mnt/cephrbd<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 在线调整 rbd image 格式化后的文件系统的大小</span><br>xfs_growfs -d /mnt/cephrbd-01<br><br><span class="hljs-comment"># 查看 rbd map devices</span><br>./bin/rbd device list -t krbd<br>./bin/rbd device list -t nbd<br><br><span class="hljs-comment"># 取消挂载 rbd image</span><br>umount /mnt/cephrbd<br>./bin/rbd device unmap rbdpool/rbdimg01 -t krbd<br>./bin/rbd device unmap rbdpool/rbdimg01 -t nbd<br></code></pre></td></tr></table></figure>

<h3 id="1-3-2、测试-FS-功能"><a href="#1-3-2、测试-FS-功能" class="headerlink" title="1.3.2、测试 FS 功能"></a>1.3.2、测试 FS 功能</h3><p>添加 MDS 组件并创建文件系统:  详见 <a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/cephadm/services/mds/#orchestrator-cli-cephfs">Deploy CephFS</a></p>
<p>需要注意，容器环境中可能没有对应的 ceph 内核模块，下面的执行命令可能会失败。</p>
<p><strong>相关命令:</strong> （以下命令执行的相对路径均位于 ceph&#x2F;build 目录中）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># kernel 方式挂载 cephfs</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/mount/mount.ceph.c#L473</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/kernel-cephfs<br>mount -t ceph 10.10.10.1:3300:/ /mnt/kernel-cephfs -o name=admin,secret=AQBVokZoak+LJRAAqgeJr6j77v729bfvBl/Z3g==,ms_mode=crc,mount_timeout=5<br><br><span class="hljs-comment"># fuse 方式挂载 cephfs</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/fuse-cephfs<br>./bin/ceph-fuse -c /etc/ceph/ceph.conf -n client.admin -m 10.10.10.1:3300 /mnt/fuse-cephfs --client_mountpoint /<br><br><span class="hljs-comment"># 测试读写 - 限速写</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/kernel-cephfs/testfile status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/fuse-cephfs/testfile status=progress<br><br><span class="hljs-comment"># 测试读写 - 限速读</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/kernel-cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/fuse-cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 取消挂载 kernel 方式的 cephfs</span><br>umount /mnt/kernel-cephfs<br><br><span class="hljs-comment"># 取消挂载 fuse 方式的 cephfs</span><br>fusermount -u /mnt/fuse-cephfs<br></code></pre></td></tr></table></figure>

<h3 id="1-3-3、测试其他特性"><a href="#1-3-3、测试其他特性" class="headerlink" title="1.3.3、测试其他特性"></a>1.3.3、测试其他特性</h3><p><strong>相关命令:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 测试 crimson osd 后端存储类别是否应用成功（位于 build 目录中测试）</span><br><span class="hljs-built_in">cat</span> ./dev/osd*/type<br></code></pre></td></tr></table></figure>


<h1 id="二、cephadm-搭建集群"><a href="#二、cephadm-搭建集群" class="headerlink" title="二、cephadm 搭建集群"></a>二、cephadm 搭建集群</h1><blockquote>
<p><strong>注意:</strong> 由于目前社区在2025年07月29日之后支持了通过 cephadm 部署 seastore 类型的 osd（<a target="_blank" rel="noopener" href="https://github.com/ceph/ceph/pull/64323">pull&#x2F;64323</a>） ，因此为了部署方便，所以推荐使用最新版本进行部署。</p>
</blockquote>
<p>通过 cephadm 搭建集群需要用到对应版本的 ceph 容器镜像， mon&#x2F;mgr&#x2F;osd 等组件运行在容器环境中，官方提供的 <a target="_blank" rel="noopener" href="https://quay.io/repository/ceph/ceph">Ceph 容器镜像仓库</a>。 但是有时候我们需要修改代码或构建特定版本的镜像，为此就需要自行构建对应的容器镜像，详细步骤下面会介绍。</p>
<p><strong>操作步骤如下:</strong></p>
<ol>
<li>编译打包: 编译 Ceph 并产出 RPM 安装包，之后搭建 Web 服务器提供 RPM 安装包的访问下载地址；</li>
<li>容器构建: 基于上一步产出的 RPM 安装包，构建 Cephadm 依赖的 Ceph 镜像；</li>
<li>集群部署: 基于上一步构建的 Ceph 镜像，开始部署集群；</li>
<li>集群测试: 验证集群功能；</li>
</ol>
<h2 id="2-1、编译打包"><a href="#2-1、编译打包" class="headerlink" title="2.1、编译打包"></a>2.1、编译打包</h2><p>由于最终编译打包生成的 RPM 包需要安装在 CentOS Stream 9 的环境中，因此我们需要基于该环境进行编译打包，这里推荐使用 <a target="_blank" rel="noopener" href="https://github.com/bugwz/ceph-image/tree/main/tentacle/centos-9-stream/dev">bugwz&#x2F;ceph-images</a> 中提供的 CentOS Stream 9 的编译打包环境。</p>
<p><strong>编译打包的详细步骤如下:</strong></p>
<ol>
<li>构建容器编译打包环境: 基于 <a target="_blank" rel="noopener" href="https://github.com/bugwz/ceph-image/tree/main/tentacle/centos-9-stream/dev">bugwz&#x2F;ceph-image</a> 中提供的 Dockerfile 进行构建；</li>
<li>执行编译打包: 基于上一步构建的编译打包环境执行编译、RPM 打包等操作；</li>
<li>搭建 Web 服务器环境: 提供对上一步打包的 RPM 的访问下载服务；</li>
</ol>
<h3 id="2-1-1、构建容器编译打包环境"><a href="#2-1-1、构建容器编译打包环境" class="headerlink" title="2.1.1、构建容器编译打包环境"></a>2.1.1、构建容器编译打包环境</h3><p><strong>操作如下:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 构建 Ceph 开发环境，最终生成一个 ceph-dev:centos9-stream-tentacle 的镜像</span><br>git <span class="hljs-built_in">clone</span> https://github.com/bugwz/ceph-image.git<br><span class="hljs-built_in">cd</span> ./ceph-image/tentacle/centos-9-stream/dev<br>./run.sh<br></code></pre></td></tr></table></figure>

<h3 id="2-1-2、执行编译打包"><a href="#2-1-2、执行编译打包" class="headerlink" title="2.1.2、执行编译打包"></a>2.1.2、执行编译打包</h3><blockquote>
<p><strong>注意:</strong> 2025年04月03日之后的代码版本中移除了 <code>WITH_SEASTAR</code> 变量，需要使用新变量 <code>WITH_CRIMSON</code> ，相关 <a target="_blank" rel="noopener" href="https://github.com/ceph/ceph/commit/23c33f69ff977f7a05d3e3368e078b20e67a5ced">commit&#x2F;23c33f6</a> 。</p>
</blockquote>
<p>这里我指定了我测试使用的版本代码，具体的版本可以根据你的需求变更。</p>
<p><strong>操作如下:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 进入开发环境</span><br>podman run -d --name ceph-build ceph-dev:centos9-stream-tentacle /bin/bash -c <span class="hljs-string">&quot;while true; do sleep 1; done&quot;</span><br>podman <span class="hljs-built_in">exec</span> -it ceph-build /bin/bash<br><br><span class="hljs-comment"># 编译</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br>git submodule update --init --recursive<br><span class="hljs-built_in">export</span> FOR_MAKE_CHECK=<span class="hljs-literal">true</span><br>/root/ceph/install-deps.sh<br>/root/ceph/do_cmake.sh<br><span class="hljs-built_in">cd</span> /root/ceph/build/<br>ninja -j <span class="hljs-string">&quot;<span class="hljs-subst">$(expr $(nproc)</span> / 2)&quot;</span><br><br><br><span class="hljs-comment"># 编译 crimson</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br>git submodule update --init --recursive<br><span class="hljs-built_in">export</span> FOR_MAKE_CHECK=<span class="hljs-literal">true</span><br><span class="hljs-built_in">export</span> WITH_CRIMSON=<span class="hljs-literal">true</span><br>/root/ceph/install-deps.sh<br>/root/ceph/do_cmake.sh -DWITH_CRIMSON=ON<br><span class="hljs-built_in">cd</span> /root/ceph/build/<br>ninja -j <span class="hljs-string">&quot;<span class="hljs-subst">$(expr $(nproc)</span> / 2)&quot;</span><br><br><br><span class="hljs-comment"># 构建 RPM</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br>git submodule update --init --recursive<br>/root/ceph/make-dist<br><span class="hljs-built_in">mkdir</span> -p /root/ceph/rpmbuild/SOURCES<br><span class="hljs-built_in">cp</span> /root/ceph/ceph-*.tar.bz2 /root/ceph/rpmbuild/SOURCES<br>rpmbuild -ba --clean --rmsource --rmspec \<br>    --define=<span class="hljs-string">&quot;_topdir /root/ceph/rpmbuild&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_rpmdir /root/ceph/rpmbuild/RPMS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_builddir /root/ceph/rpmbuild/BUILD&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_sourcedir /root/ceph/rpmbuild/SOURCES&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_specdir /root/ceph/rpmbuild/SPECS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_srcrpmdir /root/ceph/rpmbuild/SRPMS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_unpackaged_files_terminate_build 0&quot;</span> \<br>    ceph.spec --without selinux<br>createrepo /root/ceph/rpmbuild/RPMS/x86_64/<br>createrepo /root/ceph/rpmbuild/RPMS/noarch/<br><br><br><span class="hljs-comment"># 构建 crimson RPM</span><br><span class="hljs-built_in">cd</span> /root/ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br>git submodule update --init --recursive<br>/root/ceph/make-dist<br><span class="hljs-built_in">mkdir</span> -p /root/ceph/rpmbuild/SOURCES<br><span class="hljs-built_in">cp</span> /root/ceph/ceph-*.tar.bz2 /root/ceph/rpmbuild/SOURCES<br>rpmbuild -ba --with crimson --clean --rmsource --rmspec \<br>    --define=<span class="hljs-string">&quot;_topdir /root/ceph/rpmbuild&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_rpmdir /root/ceph/rpmbuild/RPMS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_builddir /root/ceph/rpmbuild/BUILD&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_sourcedir /root/ceph/rpmbuild/SOURCES&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_specdir /root/ceph/rpmbuild/SPECS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_srcrpmdir /root/ceph/rpmbuild/SRPMS&quot;</span> \<br>    --define=<span class="hljs-string">&quot;_unpackaged_files_terminate_build 0&quot;</span> \<br>    ceph.spec --without selinux<br>createrepo /root/ceph/rpmbuild/RPMS/x86_64/<br>createrepo /root/ceph/rpmbuild/RPMS/noarch/<br></code></pre></td></tr></table></figure>

<h3 id="2-1-3、搭建-Web-服务器环境"><a href="#2-1-3、搭建-Web-服务器环境" class="headerlink" title="2.1.3、搭建 Web 服务器环境"></a>2.1.3、搭建 Web 服务器环境</h3><p>这一步的目的是提供一个 Web 环境，以便于在运行构建 Ceph 镜像脚本的时候，在镜像中安装使用我们上一步打包的 RPM 包。</p>
<p>以下操作继续位于 1.2 中提到的名为 ceph-build 的容器中执行。</p>
<p><strong>操作如下:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 CentOS 源所需要的 repo 文件</span><br><span class="hljs-comment"># 该文件完整路径为 /root/ceph/rpmbuild/ceph.repo</span><br><span class="hljs-comment"># 该文件内容如下，需要修改对应的 IP 地址等信息</span><br>[ceph-custom-stable]<br>name=Ceph custom stable <span class="hljs-variable">$basearch</span> repo<br>baseurl=http://127.0.0.1:8080/RPMS/<span class="hljs-variable">$basearch</span><br>enabled=1<br>gpgcheck=0<br>priority=0<br><br>[ceph-custom-stable-noarch]<br>name=Ceph custom stable noarch repo<br>baseurl=http://127.0.0.1:8080/RPMS/noarch<br>enabled=1<br>gpgcheck=0<br>priority=0<br><br><br><span class="hljs-comment"># 使用 Python3 启动一个 Web 服务</span><br><span class="hljs-built_in">cd</span> /root/ceph/rpmbuild/<br>python3 -m http.server 8080<br></code></pre></td></tr></table></figure>


<h2 id="2-2、容器构建"><a href="#2-2、容器构建" class="headerlink" title="2.2、容器构建"></a>2.2、容器构建</h2><p>当构建 crimson RPM 的时候，最后会同时生成 ceph-crimson-osd 和 ceph-osd 两个 rpm 包，但是其内部的 &#x2F;usr&#x2F;bin&#x2F;ceph-osd 和 &#x2F;usr&#x2F;bin&#x2F;crimson-osd 文件完全相同，也就是说在构建 crimson RPM 的场景下，即使最后安装的软件包为 ceph-osd ，实际起作用的也是 crimson osd 。所以即使是构建 crimson osd 的容器环境，在执行容器脚本时对应的 FLAVOR 环境变量也可以使用 default 参数。</p>
<p>以下操作并不位于上面提到的名为 ceph-build 的容器中。</p>
<h3 id="2-2-1、修改构建脚本"><a href="#2-2-1、修改构建脚本" class="headerlink" title="2.2.1、修改构建脚本"></a>2.2.1、修改构建脚本</h3><blockquote>
<p><strong>注意:</strong> 社区当前的打包脚本中并没有提供 CEPH_CUSTOM_REPO 这个参数，该参数是我为了使用自定义的源仓库来新增的参数。需要修改的代码变动如下:</p>
</blockquote>
<p><strong>操作如下:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 下载 Ceph 源码</span><br>git <span class="hljs-built_in">clone</span> https://github.com/ceph/ceph.git<br><span class="hljs-built_in">cd</span> ./ceph<br>git checkout -f 783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br><span class="hljs-built_in">cd</span> ./container<br><br>vi build.sh<br><br>vi Containerfile<br></code></pre></td></tr></table></figure>

<p><strong>build.sh 中的变动如下:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">podman build --pull=<span class="hljs-literal">true</span> --squash -f <span class="hljs-variable">$CFILE</span> -t build.sh.output \<br>    --build-arg FROM_IMAGE=<span class="hljs-variable">$&#123;FROM_IMAGE:-quay.io/centos/centos:stream9&#125;</span> \<br>    --build-arg CEPH_SHA1=<span class="hljs-variable">$&#123;CEPH_SHA1&#125;</span> \<br>    --build-arg CEPH_GIT_REPO=<span class="hljs-variable">$&#123;CEPH_GIT_REPO&#125;</span> \<br>    --build-arg CEPH_REF=<span class="hljs-variable">$&#123;BRANCH:-main&#125;</span> \<br>    --build-arg OSD_FLAVOR=<span class="hljs-variable">$&#123;FLAVOR:-default&#125;</span> \<br>    --build-arg CI_CONTAINER=<span class="hljs-variable">$&#123;CI_CONTAINER:-default&#125;</span> \<br>    --build-arg CEPH_CUSTOM_REPO=<span class="hljs-variable">$&#123;CEPH_CUSTOM_REPO:-&#125;</span> \<br>    --secret=<span class="hljs-built_in">id</span>=prerelease_creds,src=./prerelease.secret.txt \<br>    2&gt;&amp;1 <br></code></pre></td></tr></table></figure>

<p><strong>Containerfile 中的变动如下:</strong></p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># (optional) ceph custom repo (pull ceph packages from the repo)</span><br><span class="hljs-keyword">ARG</span> CEPH_CUSTOM_REPO=<span class="hljs-string">&quot;&quot;</span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> /bin/echo -e <span class="hljs-string">&quot;\</span></span><br><span class="hljs-string"><span class="language-bash">FROM_IMAGE: <span class="hljs-variable">$&#123;FROM_IMAGE&#125;</span>\n\</span></span><br><span class="hljs-string"><span class="language-bash">CEPH_REF: <span class="hljs-variable">$&#123;CEPH_REF&#125;</span>\n\</span></span><br><span class="hljs-string"><span class="language-bash">GANESHA_REPO_BASEURL: <span class="hljs-variable">$&#123;GANESHA_REPO_BASEURL&#125;</span> \n\</span></span><br><span class="hljs-string"><span class="language-bash">OSD_FLAVOR: <span class="hljs-variable">$&#123;OSD_FLAVOR&#125;</span> \n\</span></span><br><span class="hljs-string"><span class="language-bash">CI_CONTAINER: <span class="hljs-variable">$&#123;CI_CONTAINER&#125;</span> \n\</span></span><br><span class="hljs-string"><span class="language-bash">CEPH_CUSTOM_REPO: <span class="hljs-variable">$&#123;CEPH_CUSTOM_REPO&#125;</span>&quot;</span></span><br><br><br><span class="hljs-comment"># Ceph repo</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> --mount=<span class="hljs-built_in">type</span>=secret,<span class="hljs-built_in">id</span>=prerelease_creds <span class="hljs-built_in">set</span> -ex &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-keyword">if</span> [ -z <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CEPH_CUSTOM_REPO&#125;</span>&quot;</span> ]; <span class="hljs-keyword">then</span> \</span><br><span class="language-bash">        rpm --import <span class="hljs-string">&#x27;https://download.ceph.com/keys/release.asc&#x27;</span> &amp;&amp; \</span><br><span class="language-bash">        ARCH=$(<span class="hljs-built_in">arch</span>); <span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;ARCH&#125;</span>&quot;</span> == <span class="hljs-string">&quot;aarch64&quot;</span> ]; <span class="hljs-keyword">then</span> ARCH=<span class="hljs-string">&quot;arm64&quot;</span>; <span class="hljs-keyword">fi</span> ;\</span><br><span class="language-bash">        IS_RELEASE=0 ;\</span><br><span class="language-bash">        <span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CI_CONTAINER&#125;</span>&quot;</span> == <span class="hljs-string">&quot;true&quot;</span> ]] ; <span class="hljs-keyword">then</span> \</span><br><span class="language-bash">            <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> this can return different ceph builds (SHA1) for x86 vs. arm runs. is it important to fix?</span></span><br>            REPO_URL=$(curl -fs <span class="hljs-string">&quot;https://shaman.ceph.com/api/search/?project=ceph&amp;distros=centos/9/$&#123;ARCH&#125;&amp;flavor=$&#123;OSD_FLAVOR&#125;&amp;ref=$&#123;CEPH_REF&#125;&amp;sha1=latest&quot;</span> | jq -r .[<span class="hljs-number">0</span>].url) ;\<br>        else \<br>            IS_RELEASE=<span class="hljs-number">1</span> ;\<br>            source /<span class="hljs-keyword">run</span><span class="language-bash">/secrets/prerelease_creds; \</span><br><span class="language-bash">            REPO_URL=<span class="hljs-string">&quot;https://<span class="hljs-variable">$&#123;PRERELEASE_USERNAME&#125;</span>:<span class="hljs-variable">$&#123;PRERELEASE_PASSWORD&#125;</span>@download.ceph.com/prerelease/ceph/rpm-<span class="hljs-variable">$&#123;CEPH_REF&#125;</span>/el9/&quot;</span> ;\</span><br><span class="language-bash">        <span class="hljs-keyword">fi</span> &amp;&amp; \</span><br><span class="language-bash">        rpm -Uvh <span class="hljs-string">&quot;<span class="hljs-variable">$REPO_URL</span>/noarch/ceph-release-1-<span class="hljs-variable">$&#123;IS_RELEASE&#125;</span>.el9.noarch.rpm&quot;</span> ; \</span><br><span class="language-bash">        <span class="hljs-keyword">if</span> [[ <span class="hljs-string">&quot;<span class="hljs-variable">$IS_RELEASE</span>&quot;</span> == 1 ]] ; <span class="hljs-keyword">then</span> \</span><br><span class="language-bash">            sed -i <span class="hljs-string">&quot;s;http://download.ceph.com/;https://<span class="hljs-variable">$&#123;PRERELEASE_USERNAME&#125;</span>:<span class="hljs-variable">$&#123;PRERELEASE_PASSWORD&#125;</span>@download.ceph.com/prerelease/ceph/;&quot;</span> /etc/yum.repos.d/ceph.repo ; \</span><br><span class="language-bash">            dnf clean expire-cache ; \</span><br><span class="language-bash">        <span class="hljs-keyword">fi</span> \</span><br><span class="language-bash">    <span class="hljs-keyword">else</span> \</span><br><span class="language-bash">        curl -fs -L <span class="hljs-variable">$&#123;CEPH_CUSTOM_REPO&#125;</span> -o /etc/yum.repos.d/ceph.repo ;\</span><br><span class="language-bash">    <span class="hljs-keyword">fi</span></span><br></code></pre></td></tr></table></figure>


<h3 id="2-2-2、执行构建操作"><a href="#2-2-2、执行构建操作" class="headerlink" title="2.2.2、执行构建操作"></a>2.2.2、执行构建操作</h3><p><strong>操作如下:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 构建 Cephadm 所需要的容器镜像</span><br><span class="hljs-built_in">export</span> NO_PUSH=<span class="hljs-literal">true</span><br><span class="hljs-built_in">export</span> CI_CONTAINER=<span class="hljs-literal">true</span><br><span class="hljs-built_in">export</span> FLAVOR=default<br><span class="hljs-built_in">export</span> BRANCH=main<br><span class="hljs-built_in">export</span> CEPH_SHA1=783bf4834fe4ad1a8da57902a7f334c3dfa820b2<br><span class="hljs-built_in">export</span> ARCH=$(<span class="hljs-built_in">arch</span>)<br><span class="hljs-built_in">export</span> CEPH_CUSTOM_REPO=<span class="hljs-string">&quot;http://127.0.0.1:8080/ceph.repo&quot;</span><br>/root/ceph/container/build.sh<br><br><span class="hljs-comment"># 推送容器镜像至内部/外部镜像服务器</span><br>podman push <span class="hljs-variable">$IMAGE_NAME</span><br></code></pre></td></tr></table></figure>

<h2 id="2-3、集群部署"><a href="#2-3、集群部署" class="headerlink" title="2.3、集群部署"></a>2.3、集群部署</h2><p>假设测试环境中拥有三台机器，每台机器上均已安装 ceph-common ，ceph-base 等 Ceph 相关的 CLI 软件，且三台机器的信息如下: </p>
<table>
<thead>
<tr>
<th align="center">机器节点</th>
<th align="center">机器 IP</th>
</tr>
</thead>
<tbody><tr>
<td align="center">ceph01</td>
<td align="center">10.10.10.1</td>
</tr>
<tr>
<td align="center">ceph02</td>
<td align="center">10.10.10.2</td>
</tr>
<tr>
<td align="center">ceph03</td>
<td align="center">10.10.10.3</td>
</tr>
</tbody></table>
<p><strong>使用 cephadm 进行集群的搭建步骤如下:</strong></p>
<ol>
<li>创建新集群:  详见 <a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/cephadm/install/#bootstrap-a-new-cluster">Bootstrap a new cluster</a> ；</li>
<li>添加主机到集群:  详见 <a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/cephadm/host-management/#cephadm-adding-hosts">Adding Hosts</a> ；</li>
<li>添加 OSD 存储:  详见 <a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/cephadm/services/osd/#cephadm-deploy-osds">Deploy OSDs</a> ；</li>
</ol>
<h3 id="2-3-1、创建新集群"><a href="#2-3-1、创建新集群" class="headerlink" title="2.3.1、创建新集群"></a>2.3.1、创建新集群</h3><p><strong>注意:</strong> 如果编译打包的环境和安装 cephadm 的环境中 python 版本不同，这可能会导致 cephadm 无法运行，由于 cephadm 使用固定的 python 路径进行解析执行，所以如果遇到这种问题我们可以尝试修改本地已安装 cephadm 中的 python 路径来解决该问题。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">head</span> -1 $(<span class="hljs-built_in">which</span> cephadm)<br>sudo send -i <span class="hljs-string">&#x27;1s|^.*$|#!/root/.pyenv/shims/python3|&#x27;</span> $(<span class="hljs-built_in">which</span> cephadm)<br></code></pre></td></tr></table></figure>

<p><strong>创建集群相关命令:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建新集群</span><br>cephadm --image <span class="hljs-variable">$IMAGE_NAME</span> bootstrap --config /data/ceph/cephadm.conf --mon-ip 10.10.10.1 --initial-dashboard-password admin --allow-fqdn-hostname --no-minimize-config<br><br><span class="hljs-comment"># 初始化环境配置，调整 crimson 相关配置</span><br>ceph config <span class="hljs-built_in">set</span> osd crimson_seastar_num_threads 1<br>ceph config <span class="hljs-built_in">set</span> global <span class="hljs-string">&#x27;enable_experimental_unrecoverable_data_corrupting_features&#x27;</span> crimson<br>ceph osd set-allow-crimson --yes-i-really-mean-it<br>ceph config <span class="hljs-built_in">set</span> mon osd_pool_default_crimson <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 启用日志文件</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_file <span class="hljs-literal">true</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_file <span class="hljs-literal">true</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_stderr <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_stderr <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global log_to_journald <span class="hljs-literal">false</span><br>ceph config <span class="hljs-built_in">set</span> global mon_cluster_log_to_journald <span class="hljs-literal">false</span><br><br><span class="hljs-comment"># 初始化环境配置: 新主机安装集群 SSH 公钥</span><br>ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph02<br>ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph03<br></code></pre></td></tr></table></figure>

<p><strong>其他命令:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 调整 cephadm 日志配置</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/cephadm/log_level debug<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/cephadm/log_to_cluster <span class="hljs-literal">true</span><br>ceph config <span class="hljs-built_in">set</span> mgr mgr/cephadm/log_to_cluster_level debug<br>ceph config <span class="hljs-built_in">set</span> mgr mgr/cephadm/log_to_file <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># 调整 osd 后端存储类别</span><br><span class="hljs-comment"># 目前 cephadm 部署方式中，调整该参数无效</span><br><span class="hljs-comment"># ceph config set osd osd_objectstore bluestore</span><br><span class="hljs-comment"># ceph config set osd osd_objectstore cyanstore</span><br><span class="hljs-comment"># ceph config set osd osd_objectstore seastore</span><br><br><span class="hljs-comment"># 导出正在运行的服务规范</span><br>ceph orch <span class="hljs-built_in">ls</span> --service-type osd --<span class="hljs-built_in">export</span> &gt; osd.yaml<br>ceph orch <span class="hljs-built_in">ls</span> --<span class="hljs-built_in">export</span> &gt; cluster.yaml<br><br><span class="hljs-comment"># 应用新的服务规范</span><br>ceph orch apply -i osd.new.yaml --dry-run<br><br><span class="hljs-comment"># 销毁集群</span><br>cephadm rm-cluster --force --zap-osds  --fsid 3fab7f2a-39d6-11f0-9b5b-005056854af3<br>dnf remove <span class="hljs-string">&quot;*ceph*&quot;</span><br><span class="hljs-built_in">rm</span> -rf /etc/ceph/*<br><span class="hljs-built_in">rm</span> -rf /var/lib/ceph/*<br><span class="hljs-built_in">rm</span> -rf /var/log/ceph/*<br><br><span class="hljs-comment"># cephadm 重启组件</span><br>ceph orch ps --daemon-type mon<br>ceph orch daemon restart &lt;daemon-name&gt;<br></code></pre></td></tr></table></figure>

<p><strong>Crimson 相关配置参数:</strong></p>
<ul>
<li><code>osd_objectstore</code> : 后端对象存储类型，可选值为 filestore&#x2F;memstore&#x2F;bluestore&#x2F;kstore&#x2F;seastore&#x2F;cyanstore ， 默认值为 bluestore ；<ul>
<li>对应 osd 的配置为: filestore&#x2F;memstore&#x2F;bluestore ；</li>
<li>对应 crimson osd 的配置为: cyanstore&#x2F;seastore&#x2F;bluestore , 在这里 bluestore 前端使用 alienstore 进行代理，但是配置中并没有该参数；</li>
</ul>
</li>
<li><code>crimson_osd_obc_lru_size</code> : 缓存的 Object Context 数量 ， 默认值为 512 ；</li>
<li><code>crimson_osd_scheduler_concurrency</code> : 并发 IO 操作的最大数量，0 代表无限 ， 默认值为 0 ；</li>
<li><code>crimson_alien_op_num_threads</code> : 为 alienized ObjectStore 提供服务的线程数，默认值为 6 ；</li>
<li><code>crimson_alien_thread_cpu_cores</code> : 以 cpuset(7) 格式运行 alienstore 线程的 CPU 核心， 无默认值；</li>
<li><code>crimson_seastar_cpu_cores</code> : 以 cpuset(7) 格式运行 seastar reactor 线程的 CPU 核心，smp::count 从此选项推导， 无默认值；</li>
<li><code>crimson_seastar_num_threads</code> : 不进行 CPU 绑定的情况下用于服务 seastar reactor 的线程数，如果设置了 crimson_seastar_cpu_cores，则会被覆盖 ， 默认值为 0 ；</li>
<li><code>crimson_osd_stat_interval</code> : 定期报告 OSD 状态的时间间隔（以秒为单位），设置为 0 则禁用， 默认值为 0 ；</li>
<li><code>osd_pool_default_crimson</code> : 默认使用 FLAG_CRIMSON 创建池，默认值为 false ；</li>
<li><code>seastore_segment_size</code> : 用于分段管理器的片段大小，默认值为 64M ；</li>
<li><code>seastore_device_size</code> : 创建时用于 SegmentManager 块文件的总大小，默认值为 50G ；</li>
<li><code>seastore_block_create</code> : 如果不存在，请创建 SegmentManager 文件，默认值为 true ；</li>
<li><code>seastore_journal_batch_capacity</code> : 日志批处理中的记录数量限制，默认值为 16 ；</li>
<li><code>seastore_journal_batch_flush_size</code> : 强制清除日志批处理的大小阈值，默认值为 16M ；</li>
<li><code>seastore_journal_iodepth_limit</code> : 用于提交日志记录的 IO 深度限制，默认值为 5 ；</li>
<li><code>seastore_journal_batch_preferred_fullness</code> : 清除日志批处理的记录完整阈值，默认值为 0.95 ；</li>
<li><code>seastore_default_max_object_size</code> : seastore 对象数据的默认逻辑地址空间保留，默认值为 16777216 ；</li>
<li><code>seastore_default_object_metadata_reservation</code> : seastore 对象的元数据的默认逻辑地址空间保留，默认值为 16777216 ；</li>
<li><code>seastore_full_integrity_check</code> : seastore 是否需要完全检查每个范围的完整性，非完全完整性检查意味着在范围重映射期间可能会跳过完整性检查以提高性能，禁用时需谨慎，默认值为 false ；</li>
<li><code>seastore_max_data_allocation_size</code> : 范围可以达到的最大字节大小， 一旦子范围读取&#x2F;校验和实现，seastore_max_data_allocation_size 应该被弃用。默认值为 32K ；</li>
<li><code>seastore_cache_lru_size</code> : 要保留在缓存中的扩展大小（以字节为单位），默认值为 64M ；</li>
<li><code>seastore_obj_data_write_amplification</code> : 如果写入大小的总扩展大小超过这个值，则分割扩展，默认值为 1.25 ；</li>
<li><code>seastore_max_concurrent_transactions</code> : seastore 允许的最大并发事务，默认值为 8 ；</li>
<li><code>seastore_main_device_type</code> : seastore 使用的主设备类型，可选值为 SSD&#x2F;RANDOM_BLOCK_SSD ,默认值为 SSD 。还有当前不支持的 HDD&#x2F;ZBD 配置，其中 ZBD 指的是 ZNS SSD 或者 SMR HDD ；</li>
<li><code>seastore_cbjournal_size</code> : 创建时用于 CircularBoundedJournal 的总大小，只有在 seastore_main_device_type 是 RANDOM_BLOCK 时有效， 默认值为 5G ；</li>
<li><code>seastore_multiple_tiers_stop_evict_ratio</code> : 当主层使用的比率小于这个值时，停止将冷数据驱除到冷层，默认值为 0.5 ；</li>
<li><code>seastore_multiple_tiers_default_evict_ratio</code> : 在使用主层使用比率达到这个值时，开始将冷数据驱除到冷层，默认值为 0.6 ；</li>
<li><code>seastore_multiple_tiers_fast_evict_ratio</code> : 当主层使用比率达到这个值时，立即开始驱除，默认值为 0.7 ；</li>
<li><code>seastore_data_delta_based_overwrite</code> : 如果覆盖大小小于或等于该值，则基于增量覆盖现有数据块，否则基于重映射进行覆盖，设置为 0 强制使用基于重映射的覆盖。默认值为 0 ；</li>
<li><code>seastore_disable_end_to_end_data_protection</code> : 当为 false 时，在 mkfs 时尝试发现 nvme 设备是否支持内部校验和功能而不使用服务器 CPU，然后在可用时启用，设置为 true 则无条件禁用。默认值为 true ；</li>
</ul>
<h3 id="2-3-2、添加主机到集群"><a href="#2-3-2、添加主机到集群" class="headerlink" title="2.3.2、添加主机到集群"></a>2.3.2、添加主机到集群</h3><p><strong>相关命令:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加主机到集群</span><br>ceph orch host add ceph02 10.10.10.2<br>ceph orch host add ceph03 10.10.10.3<br></code></pre></td></tr></table></figure>


<h3 id="2-3-3、添加-OSD-存储"><a href="#2-3-3、添加-OSD-存储" class="headerlink" title="2.3.3、添加 OSD 存储"></a>2.3.3、添加 OSD 存储</h3><blockquote>
<p><strong>注意:</strong> <a target="_blank" rel="noopener" href="https://github.com/ceph/ceph/pull/64323">pull&#x2F;64323</a> 中支持了通过 cephadm 部署 seastore 类型的 osd ，详细操作方式如下。</p>
</blockquote>
<p><strong>相关命令:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加 OSD 存储</span><br>ceph orch device <span class="hljs-built_in">ls</span><br>ceph orch daemon add osd ceph01:data_devices=/dev/sdd,/dev/sde,objectstore=seastore<br>ceph orch daemon add osd ceph02:data_devices=/dev/sdd,/dev/sde,objectstore=seastore<br>ceph orch daemon add osd ceph03:data_devices=/dev/sdd,/dev/sde,objectstore=seastore<br><br><span class="hljs-comment"># 查看 OSD 的存储类型</span><br>ceph tell ceph.* config get osd_objectstore<br></code></pre></td></tr></table></figure>

<h2 id="2-4、集群测试"><a href="#2-4、集群测试" class="headerlink" title="2.4、集群测试"></a>2.4、集群测试</h2><h3 id="2-4-1、测试-RBD-功能"><a href="#2-4-1、测试-RBD-功能" class="headerlink" title="2.4.1、测试 RBD 功能"></a>2.4.1、测试 RBD 功能</h3><p><strong>相关命令:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 rbd pool</span><br>ceph osd pool create rbdpool 64 64<br>ceph osd pool application <span class="hljs-built_in">enable</span> rbdpool rbd<br>ceph osd pool <span class="hljs-built_in">set</span> rbdpool pg_autoscale_mode off<br><br><span class="hljs-comment"># 创建 rbd image</span><br>rbd create -p rbdpool --image rbdimg01 --size 10G<br><br><span class="hljs-comment"># 删除 rbd image</span><br>rbd <span class="hljs-built_in">rm</span> --pool rbdpool --image rbdimg01<br><br><span class="hljs-comment"># 查看 rbd image 信息</span><br>rbd info rbdpool/rbdimg01<br><br><span class="hljs-comment"># krbd 方式映射 rbd image (默认方式)</span><br><span class="hljs-comment"># 由于 crimson osd 仅支持 message v2, 因此我们需要切换为 message v2进行连接通信</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/tools/rbd/action/Kernel.cc#L120</span><br>rbd device map -t krbd rbdpool/rbdimg01 -o mount_timeout=5,ms_mode=crc<br><br><span class="hljs-comment"># nbd 方式映射 rbd image</span><br><span class="hljs-comment"># 由于 crimson osd 仅支持 message v2, 因此我们需要切换为 message v2进行连接通信</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/tools/rbd_nbd/rbd-nbd.cc#L2118</span><br>rbd device map -t nbd rbdpool/rbdimg01<br><br><span class="hljs-comment"># 格式化 krbd 方式映射的 rbd image 并挂载</span><br>mkfs.xfs /dev/rbd0<br><span class="hljs-built_in">mkdir</span> -p /mnt/cephrbd<br>mount /dev/rbd0 /mnt/cephrbd<br><br><span class="hljs-comment"># 格式化 nbd 方式映射的 rbd image 并挂载</span><br>mkfs.xfs /dev/nbd1<br><span class="hljs-built_in">mkdir</span> -p /mnt/cephrbd<br>mount /dev/nbd1 /mnt/cephrbd<br><br><span class="hljs-comment"># 压测 rbd image - 限速写</span><br><span class="hljs-built_in">cd</span> /mnt/cephrbd<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=testfile status=progress<br><br><span class="hljs-comment"># 压测 rbd image - 限速读</span><br><span class="hljs-built_in">cd</span> /mnt/cephrbd<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 在线调整 rbd image 格式化后的文件系统的大小</span><br>xfs_growfs -d /mnt/cephrbd-01<br><br><span class="hljs-comment"># 查看 rbd map devices</span><br>rbd device list -t krbd<br>rbd device list -t nbd<br><br><span class="hljs-comment"># 取消挂载 rbd image</span><br>umount /mnt/cephrbd<br>rbd device unmap rbdpool/rbdimg01 -t krbd<br>rbd device unmap rbdpool/rbdimg01 -t nbd<br></code></pre></td></tr></table></figure>


<h3 id="2-4-2、测试-FS-功能"><a href="#2-4-2、测试-FS-功能" class="headerlink" title="2.4.2、测试 FS 功能"></a>2.4.2、测试 FS 功能</h3><p>添加 MDS 组件并创建文件系统:  详见 <a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/cephadm/services/mds/#orchestrator-cli-cephfs">Deploy CephFS</a> ；</p>
<p><strong>相关命令:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加 MDS 组件并创建文件系统</span><br>ceph fs volume create cephfs<br><br><span class="hljs-comment"># kernel 方式挂载 cephfs</span><br><span class="hljs-comment"># 详细支持的参数列表: https://github.com/ceph/ceph/blob/v19.2.1/src/mount/mount.ceph.c#L473</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/kernel-cephfs<br>mount -t ceph 10.10.10.1:3300:/ /mnt/kernel-cephfs -o name=admin,secret=AQBVokZoak+LJRAAqgeJr6j77v729bfvBl/Z3g==,ms_mode=crc,mount_timeout=5<br><br><span class="hljs-comment"># fuse 方式挂载 cephfs</span><br><span class="hljs-built_in">mkdir</span> -p /mnt/fuse-cephfs<br>ceph-fuse -c /etc/ceph/ceph.conf -n client.admin -m 10.10.10.1:3300 /mnt/fuse-cephfs --client_mountpoint /<br><br><span class="hljs-comment"># 测试读写 - 限速写</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/kernel-cephfs/testfile status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero bs=1M count=1000 | pv -L 3M | <span class="hljs-built_in">dd</span> of=/mnt/fuse-cephfs/testfile status=progress<br><br><span class="hljs-comment"># 测试读写 - 限速读</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/kernel-cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/mnt/fuse-cephfs/testfile bs=1M count=1000 iflag=direct | pv -L 1M | <span class="hljs-built_in">dd</span> of=/dev/null status=progress<br><br><span class="hljs-comment"># 取消挂载 kernel 方式的 cephfs</span><br>umount /mnt/kernel-cephfs<br><br><span class="hljs-comment"># 取消挂载 fuse 方式的 cephfs</span><br>fusermount -u /mnt/fuse-cephfs<br></code></pre></td></tr></table></figure>



<h1 id="三、相关资料"><a href="#三、相关资料" class="headerlink" title="三、相关资料"></a>三、相关资料</h1><ul>
<li><a target="_blank" rel="noopener" href="https://ceph.io/en/news/blog/2025/crimson-T-release/">https://ceph.io/en/news/blog/2025/crimson-T-release/</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/dev/quick_guide">https://docs.ceph.com/en/latest/dev/quick_guide</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/dev/crimson/crimson">https://docs.ceph.com/en/latest/dev/crimson/crimson</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/latest/cephadm/install/#bootstrap-a-new-cluster">https://docs.ceph.com/en/latest/cephadm/install/#bootstrap-a-new-cluster</a></li>
<li><a target="_blank" rel="noopener" href="https://www.51cto.com/article/749735.html">https://www.51cto.com/article/749735.html</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/667949613">https://zhuanlan.zhihu.com/p/667949613</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/7/html/administration_guide/crimson">https://docs.redhat.com/zh-cn/documentation/red_hat_ceph_storage/7/html/administration_guide/crimson</a></li>
<li><a target="_blank" rel="noopener" href="https://ceph.io/en/news/blog/2023/crimson-multi-core-scalability">https://ceph.io/en/news/blog/2023/crimson-multi-core-scalability</a></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://bugwz.com">bugwz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://bugwz.com/2025/01/12/ceph-crimson-deploy/">https://bugwz.com/2025/01/12/ceph-crimson-deploy/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://bugwz.com" target="_blank">咕咕</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Ceph/">Ceph</a></div><div class="post-share"><div class="social-share" data-image="/assets/images/bg/ceph.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/12/01/cephfs-samba/" title="CephFS 对接 Samba 使用教程"><img class="cover" src="/assets/images/bg/ceph.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">CephFS 对接 Samba 使用教程</div></div><div class="info-2"><div class="info-item-1">一、Samba 介绍Samba 是一款基于 GNU 通用公共许可证的自由软件，Samba 项目是软件自由保护协会 (Software Freedom Conservancy) 的成员。自 1992 年以来，Samba 一直为所有使用 SMB&#x2F;CIFS 协议的客户端（例如所有版本的 DOS 和 Windows、OS&#x2F;2、Linux 以及许多其他系统）提供安全、稳定且快速的文件和打印服务。 Samba 项目源码位于 https://git.samba.org/samba.git , 镜像代码仓库地址为 https://github.com/samba-team/samba 。 1.1、二进制包安装部署我们的机器环境为 CentOS 8.5.2111 ， 受限于系统版本较老，导致最终安装版本为 Samba 4.19.4 。以下操作基于这些环境进行。 由于安装的 Samba 软件默认缺少 vfs_ceph...</div></div></div></a><a class="pagination-related" href="/2025/05/23/3fs-deploy/" title="3FS 集群部署笔记"><img class="cover" src="/assets/images/bg/deepseek.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">3FS 集群部署笔记</div></div><div class="info-2"><div class="info-item-1">一、3FS 介绍3FS (Fire-Flyer File System) 是一款高性能分布式文件系统。本文详细介绍了在 CentOS 8.5 环境下，从依赖安装、编译配置到集群部署的全过程，包括 Soft-RoCE 模拟 RDMA、FoundationDB 和 ClickHouse 的配置，以及存储拓扑和客户端挂载。适用于开发者快速搭建高性能存储集群。 3FS (Fire-Flyer File System) 项目仓库: https://github.com/deepseek-ai/3FS 。 二、编译安装为了支持多种运行环境的编译安装，3FS 提供了一些 Dockerfile 可供参考。 2.1、安装依赖软件本测试环境使用的系统版本是 CentOS 8.5.2111 ，是比较老的系统版本，为了能够顺利编译安装 3FS ，需要安装一些依赖软件。 这里是在每台需要运行 3FS 的机器上执行下面的编译安装命令。 &#x2F;etc&#x2F;yum.repos.d&#x2F;centos-all.repo 文件内容: [appstream]name=CentOS-8.5.2111...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2023/04/12/ceph-ansible/" title="ceph-ansible 集群部署运维指南"><img class="cover" src="/assets/images/bg/ceph.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-12</div><div class="info-item-2">ceph-ansible 集群部署运维指南</div></div><div class="info-2"><div class="info-item-1">本文详细介绍了使用 ceph-ansible 部署和运维 Ceph 集群的过程，包括各版本及其依赖的 Ansible 版本的对应关系、自定义模块与任务的结构、集群部署、运维操作及相关示例。特别强调了环境配置、节点连通性验证、MDS 和 OSD 组件的管理，以及安全和性能优化注意事项。 一、项目介绍以下分析基于 ceph-ansible stable-6.0 分支代码。 1.1、版本与对应关系目前 ceph-ansible 采用不同的代码分支来支持部署不同版本的 ceph 集群，且每个代码分支需要特定的 ansible 版本支持，具体的对应关系如下（以下对应关系更新于 2025&#x2F;05&#x2F;23 ）：    ceph-ansible 分支 支持的 ceph 版本 依赖的 ansible 核心版本 依赖的 ansible 发布版本包    stable-3.0 Jewel(V10), Luminous(V12) 2.4 -   stable-3.1 Luminous(V12), Mimic(V13) 2.4 -   stable-3.2 Luminous(V12),...</div></div></div></a><a class="pagination-related" href="/2023/05/01/ceph-cmd/" title="Ceph 常用命令汇总"><img class="cover" src="/assets/images/bg/ceph.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-01</div><div class="info-item-2">Ceph 常用命令汇总</div></div><div class="info-2"><div class="info-item-1">一、常用命令1.1、Pool# 查看 poolceph osd pool ls detail# 创建 poolceph osd pool create testpool 32 32ceph osd pool set testpool pg_autoscale_mode off# 调整 pool pg/pgp , 并关闭自动调整ceph osd pool set testpool pg_num 32ceph osd pool set testpool pgp_num 32ceph osd pool set testpool pg_autoscale_mode off# 设置 pool 最小副本ceph osd pool set testpool min_size 1ceph osd pool set testpool size 1 --yes-i-really-mean-it# 移除 poolceph tell mon.\* injectargs &#x27;--mon-allow-pool-delete=true&#x27;ceph osd pool delete...</div></div></div></a><a class="pagination-related" href="/2024/10/25/ceph-qos/" title="Ceph QoS 机制深入分析"><img class="cover" src="/assets/images/bg/ceph.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-25</div><div class="info-item-2">Ceph QoS 机制深入分析</div></div><div class="info-2"><div class="info-item-1">一、CephFS QoS社区的相关实现：  基于 tokenbucket 算法的目录 QoS : https://github.com/ceph/ceph/pull/29266 基于 dmclock 算法的 subvolume QoS : 来自日本的 line 公司提出的想法，https://github.com/ceph/ceph/pull/38506 ， https://github.com/ceph/ceph/pull/52147  1.1、基于 TokenBucket 算法的目录 QoS该实现并未合并到主分支。  相关材料：  社区的原始PR: https://github.com/ceph/ceph/pull/29266  实现特点：  基于 TokenBucketThrottle 类在客户端侧实现的 TokenBucket 类型的 QoS，用于约束每个独立的客户端的访问请求； QoS 的限制粒度为每个独立的客户端，没有全局的QoS限制； 用于限制目录级别的操作 QoS； 支持 IOPS 和 BPS 的 QoS 限制，且支持突发流量； 仅支持 FUSE...</div></div></div></a><a class="pagination-related" href="/2023/06/30/ceph-crush/" title="Ceph CRUSH 设计实现剖析"><img class="cover" src="/assets/images/bg/ceph.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-30</div><div class="info-item-2">Ceph CRUSH 设计实现剖析</div></div><div class="info-2"><div class="info-item-1">CRUSH（Controlled Replication Under Scalable Hashing）是 Ceph 存储系统中用于数据分布和复制的算法。关于 CRUSH 的论文解析参考: 译 - CRUSH: Controlled, Scalable, Decentralized Placement of Replicated Data 。CRUSH map 是 Ceph 集群中一个关键的配置组件，它定义了数据如何在集群的物理硬件上分布。 CRUSH 算法使得 Ceph 能够在无需中心化或者分布式元数据管理器的情况下，高效、可靠地进行数据复制和恢复。 一、CRUSH map 解析CRUSH map 包含了集群的层次结构和各种规则，这些规则定义了数据应该如何在集群中分布。 CRUSH map 主要包含以下几个部分：  Tunables : 一组可用于调整 CRUSH 算法行为的参数。 Devices : 定义集群中所有可用的存储设备的列表。 Types : 定义存储层次结构中的不同层级类型。 Buckets : 组织和管理存储设备（如 OSDs ）的逻辑容器。 Rules :...</div></div></div></a><a class="pagination-related" href="/2024/03/05/ceph-csi/" title="Ceph CSI 对接 K8S 指南"><img class="cover" src="/assets/images/bg/ceph.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-05</div><div class="info-item-2">Ceph CSI 对接 K8S 指南</div></div><div class="info-2"><div class="info-item-1">一、介绍1.1、Ceph CSI 介绍Ceph CSI 插件实现了支持 CSI 的容器编排器 (CO) 与 Ceph 集群之间的接口。它们支持动态配置 Ceph 卷并将其附加到工作负载。项目地址: https://github.com/ceph/ceph-csi 。该仓库包含用于 RBD、CephFS 和 Kubernetes sidecar 部署 YAML 的 Ceph 容器存储接口 (CSI) 驱动程序，以支持 CSI 功能：provisioner、attacher、resizer、driver-registrar 和 snapper。 本文基于 Ceph CSI v3.14.1 版本进行测试。 Ceph CSI 驱动与测试过的 Kubernetes 版本信息表: (参考 known-to-work-co-platforms)    Ceph CSI 版本 Kubernetes...</div></div></div></a><a class="pagination-related" href="/2024/05/11/ceph-rdma/" title="Ceph RDMA 集群部署教程"><img class="cover" src="/assets/images/bg/ceph.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-11</div><div class="info-item-2">Ceph RDMA 集群部署教程</div></div><div class="info-2"><div class="info-item-1">一、Ceph RDMA 介绍RDMA（Remote Direct Memory Access）是一种远程直接内存访问技术，它允许客户端系统将数据从存储服务器的内存直接复制到该客户端自己的内存中。这种内存直通技术可以提升存储带宽，降低访问时延，同时还可以减少客户端和存储的 CPU 负载。 按照 Ceph 文档给出的介绍，目前虽然 Ceph 已经支持 RDMA 功能，但是除了其功能可能处于实验阶段，并且支持的能力可能受限，参考文档 。所以我的意见是并不建议在生产环境中使用。 1.2、RDMA 环境初始化以下测试工具均基于 CentOS 8.5.2111 进行测试，不同系统类型版本对应的软件包及命令可能存在差异。 查看 RDMA 硬件及驱动信息: # RDMA 相关软件dnf install -y infiniband-diags rdma-core rdma-core-devel perftest \               librdmacm librdmacm-utils libibverbs libibverbs-utils iproute# 查看 ib 网卡信息#...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/assets/images/bg/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">bugwz</div><div class="author-info-description">持续学习，持续进步</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">133</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">135</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/bugwz" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81vstart-sh-%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4"><span class="toc-text">一、vstart.sh 搭建集群</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1%E3%80%81%E8%BD%AF%E4%BB%B6%E7%BC%96%E8%AF%91"><span class="toc-text">1.1、软件编译</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2%E3%80%81%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-text">1.2、集群部署</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3%E3%80%81%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95"><span class="toc-text">1.3、功能测试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-1%E3%80%81%E6%B5%8B%E8%AF%95-RBD-%E5%8A%9F%E8%83%BD"><span class="toc-text">1.3.1、测试 RBD 功能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-2%E3%80%81%E6%B5%8B%E8%AF%95-FS-%E5%8A%9F%E8%83%BD"><span class="toc-text">1.3.2、测试 FS 功能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-3%E3%80%81%E6%B5%8B%E8%AF%95%E5%85%B6%E4%BB%96%E7%89%B9%E6%80%A7"><span class="toc-text">1.3.3、测试其他特性</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81cephadm-%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4"><span class="toc-text">二、cephadm 搭建集群</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1%E3%80%81%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85"><span class="toc-text">2.1、编译打包</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1%E3%80%81%E6%9E%84%E5%BB%BA%E5%AE%B9%E5%99%A8%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E7%8E%AF%E5%A2%83"><span class="toc-text">2.1.1、构建容器编译打包环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-2%E3%80%81%E6%89%A7%E8%A1%8C%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85"><span class="toc-text">2.1.2、执行编译打包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-3%E3%80%81%E6%90%AD%E5%BB%BA-Web-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8E%AF%E5%A2%83"><span class="toc-text">2.1.3、搭建 Web 服务器环境</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2%E3%80%81%E5%AE%B9%E5%99%A8%E6%9E%84%E5%BB%BA"><span class="toc-text">2.2、容器构建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1%E3%80%81%E4%BF%AE%E6%94%B9%E6%9E%84%E5%BB%BA%E8%84%9A%E6%9C%AC"><span class="toc-text">2.2.1、修改构建脚本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2%E3%80%81%E6%89%A7%E8%A1%8C%E6%9E%84%E5%BB%BA%E6%93%8D%E4%BD%9C"><span class="toc-text">2.2.2、执行构建操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3%E3%80%81%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-text">2.3、集群部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1%E3%80%81%E5%88%9B%E5%BB%BA%E6%96%B0%E9%9B%86%E7%BE%A4"><span class="toc-text">2.3.1、创建新集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2%E3%80%81%E6%B7%BB%E5%8A%A0%E4%B8%BB%E6%9C%BA%E5%88%B0%E9%9B%86%E7%BE%A4"><span class="toc-text">2.3.2、添加主机到集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-3%E3%80%81%E6%B7%BB%E5%8A%A0-OSD-%E5%AD%98%E5%82%A8"><span class="toc-text">2.3.3、添加 OSD 存储</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4%E3%80%81%E9%9B%86%E7%BE%A4%E6%B5%8B%E8%AF%95"><span class="toc-text">2.4、集群测试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-1%E3%80%81%E6%B5%8B%E8%AF%95-RBD-%E5%8A%9F%E8%83%BD"><span class="toc-text">2.4.1、测试 RBD 功能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-2%E3%80%81%E6%B5%8B%E8%AF%95-FS-%E5%8A%9F%E8%83%BD"><span class="toc-text">2.4.2、测试 FS 功能</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99"><span class="toc-text">三、相关资料</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/06/01/ceph-cirmson/" title="Ceph Crimson 设计实现深入解析"><img src="/assets/images/bg/ceph.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Ceph Crimson 设计实现深入解析"/></a><div class="content"><a class="title" href="/2025/06/01/ceph-cirmson/" title="Ceph Crimson 设计实现深入解析">Ceph Crimson 设计实现深入解析</a><time datetime="2025-05-31T16:00:00.000Z" title="发表于 2025-06-01 00:00:00">2025-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/05/23/3fs-deploy/" title="3FS 集群部署笔记"><img src="/assets/images/bg/deepseek.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="3FS 集群部署笔记"/></a><div class="content"><a class="title" href="/2025/05/23/3fs-deploy/" title="3FS 集群部署笔记">3FS 集群部署笔记</a><time datetime="2025-05-22T16:00:00.000Z" title="发表于 2025-05-23 00:00:00">2025-05-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/01/12/ceph-crimson-deploy/" title="Ceph Crimson 集群部署教程"><img src="/assets/images/bg/ceph.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Ceph Crimson 集群部署教程"/></a><div class="content"><a class="title" href="/2025/01/12/ceph-crimson-deploy/" title="Ceph Crimson 集群部署教程">Ceph Crimson 集群部署教程</a><time datetime="2025-01-11T16:00:00.000Z" title="发表于 2025-01-12 00:00:00">2025-01-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/01/cephfs-samba/" title="CephFS 对接 Samba 使用教程"><img src="/assets/images/bg/ceph.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CephFS 对接 Samba 使用教程"/></a><div class="content"><a class="title" href="/2024/12/01/cephfs-samba/" title="CephFS 对接 Samba 使用教程">CephFS 对接 Samba 使用教程</a><time datetime="2024-11-30T16:00:00.000Z" title="发表于 2024-12-01 00:00:00">2024-12-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/25/ceph-qos/" title="Ceph QoS 机制深入分析"><img src="/assets/images/bg/ceph.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Ceph QoS 机制深入分析"/></a><div class="content"><a class="title" href="/2024/10/25/ceph-qos/" title="Ceph QoS 机制深入分析">Ceph QoS 机制深入分析</a><time datetime="2024-10-24T16:00:00.000Z" title="发表于 2024-10-25 00:00:00">2024-10-25</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/assets/images/bg/ceph.png);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By bugwz</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 6.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: '6af3be16b94cec39bcf6',
      clientSecret: '13a5202ff773ffcea6300b6c8ff25f455566737c',
      repo: 'bugwz.github.io',
      owner: 'bugwz',
      admin: ['bugwz'],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || '6a817646d5e9f0fa14f757291e56df25'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Gitalk' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><div class="docsearch-wrap"><div id="docsearch" style="display:none"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css/dist/style.min.css"/><script src="https://cdn.jsdelivr.net/npm/@docsearch/js/dist/umd/index.min.js"></script><script>(() => {
  docsearch(Object.assign({
    appId: 'PFB3WGSSCO',
    apiKey: '3e9cd446e41d93f2f130b91698b699f7',
    indexName: 'bugwz',
    container: '#docsearch',
    placeholder: '请输入要搜索的内容',
  }, {"maxResultsPerGroup":10}))

  const handleClick = () => {
    document.querySelector('.DocSearch-Button').click()
  }

  const searchClickFn = () => {
    btf.addEventListenerPjax(document.querySelector('#search-button > .search'), 'click', handleClick)
  }

  searchClickFn()
  window.addEventListener('pjax:complete', searchClickFn)
})()</script></div></div></body></html>